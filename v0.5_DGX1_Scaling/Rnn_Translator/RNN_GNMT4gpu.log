Clearing caches
:::MLPv0.5.0 gnmt 1560382310.200425625 (<string>:1) run_clear_caches
Launching on node dgx1
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=DGX1 -e MULTI_NODE= -e SLURM_JOB_ID=190612105320 -e SLURM_NTASKS_PER_NODE= cont_190612105320 ./run_and_time.sh
Run vars: id 190612105320 gpus 8 mparams 
STARTING TIMING RUN AT 2019-06-12 11:31:50 PM
+ DATASET_DIR=/data
+ RESULTS_DIR=gnmt_wmt16
+ BATCH=128
+ TEST_BATCH_SIZE=128
+ LR=1.25e-3
+ TARGET=21.80
+ WARMUP_ITERS=200
+ REMAIN_STEPS=6000
+ DECAY_STEPS=500
+ echo 'running benchmark'
running benchmark
+ python -m torch.distributed.launch --nproc_per_node 4 train.py --save gnmt_wmt16 --dataset-dir /data --target-bleu 21.80 --epochs 60 --math fp16 --print-freq 10 --batch-size 128 --test-batch-size 128 --model-config '{'\''num_layers'\'': 4, '\''hidden_size'\'': 1024, '\''dropout'\'':0.2, '\''share_embedding'\'': True}' --optimization-config '{'\''optimizer'\'': '\''FusedAdam'\'', '\''lr'\'': 1.25e-3}' --scheduler-config '{'\''lr_method'\'':'\''mlperf'\'', '\''warmup_iters'\'':200, '\''remain_steps'\'':6000, '\''decay_steps'\'':500}'
1: Saving results to: results/gnmt_wmt16
1: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=128, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=60, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=1, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=1, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
1: L2 promotion: 128B
3: Saving results to: results/gnmt_wmt16
3: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=128, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=60, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=3, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=3, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
2: Saving results to: results/gnmt_wmt16
2: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=128, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=60, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=2, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=2, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
3: L2 promotion: 128B
2: L2 promotion: 128B
:::MLPv0.5.0 gnmt 1560382317.466126919 (train.py:242) run_start
0: Saving results to: results/gnmt_wmt16
0: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=128, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=60, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=0, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=128, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
0: L2 promotion: 128B
:::MLPv0.5.0 gnmt 1560382317.468482733 (train.py:265) run_set_random_seed
0: Using random master seed: 3041734226
3: Worker 3 is using worker seed: 603807243
2: Worker 2 is using worker seed: 91313544
1: Worker 1 is using worker seed: 4238406980
0: Worker 0 is using worker seed: 3639067814
1: Building vocabulary from /data/vocab.bpe.32000
3: Building vocabulary from /data/vocab.bpe.32000
0: Building vocabulary from /data/vocab.bpe.32000
2: Building vocabulary from /data/vocab.bpe.32000
1: Size of vocabulary: 32320
0: Size of vocabulary: 32320
3: Size of vocabulary: 32320
2: Size of vocabulary: 32320
:::MLPv0.5.0 gnmt 1560382317.494364738 (train.py:302) preproc_tokenize_training
2: Processing data from /data/train.tok.clean.bpe.32000.en
1: Processing data from /data/train.tok.clean.bpe.32000.en
3: Processing data from /data/train.tok.clean.bpe.32000.en
:::MLPv0.5.0 gnmt 1560382317.494946241 (train.py:304) train_hp_max_sequence_length: 50
0: Processing data from /data/train.tok.clean.bpe.32000.en
2: Processing data from /data/train.tok.clean.bpe.32000.de
3: Processing data from /data/train.tok.clean.bpe.32000.de
1: Processing data from /data/train.tok.clean.bpe.32000.de
0: Processing data from /data/train.tok.clean.bpe.32000.de
3: Filtering data, min len: 0, max len: 50
2: Filtering data, min len: 0, max len: 50
0: Filtering data, min len: 0, max len: 50
1: Filtering data, min len: 0, max len: 50
3: Pairs before: 4068191, after: 3498161
0: Pairs before: 4068191, after: 3498161
1: Pairs before: 4068191, after: 3498161
2: Pairs before: 4068191, after: 3498161
1: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
3: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
2: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
:::MLPv0.5.0 gnmt 1560382327.339833021 (train.py:316) preproc_num_train_examples: 3498161
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
1: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
2: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
3: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
1: Filtering data, min len: 0, max len: 150
1: Pairs before: 5100, after: 5100
3: Filtering data, min len: 0, max len: 150
2: Filtering data, min len: 0, max len: 150
3: Pairs before: 5100, after: 5100
2: Pairs before: 5100, after: 5100
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 5100, after: 5100
3: Processing data from /data/newstest2014.tok.bpe.32000.en
2: Processing data from /data/newstest2014.tok.bpe.32000.en
1: Processing data from /data/newstest2014.tok.bpe.32000.en
:::MLPv0.5.0 gnmt 1560382328.432476044 (train.py:326) preproc_tokenize_eval
0: Processing data from /data/newstest2014.tok.bpe.32000.en
2: Filtering data, min len: 0, max len: 150
0: Filtering data, min len: 0, max len: 150
3: Filtering data, min len: 0, max len: 150
2: Pairs before: 3003, after: 3003
0: Pairs before: 3003, after: 3003
1: Filtering data, min len: 0, max len: 150
3: Pairs before: 3003, after: 3003
1: Pairs before: 3003, after: 3003
:::MLPv0.5.0 gnmt 1560382328.474271536 (train.py:336) preproc_num_eval_examples: 3003
:::MLPv0.5.0 gnmt 1560382328.474902868 (train.py:341) preproc_vocab_size: 32320
:::MLPv0.5.0 gnmt 1560382328.476078272 (seq2seq/models/gnmt.py:37) model_hp_num_layers: 4
:::MLPv0.5.0 gnmt 1560382328.476712942 (seq2seq/models/gnmt.py:39) model_hp_hidden_size: 1024
:::MLPv0.5.0 gnmt 1560382328.477380753 (seq2seq/models/gnmt.py:41) model_hp_dropout: 0.2
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
2: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
2: Building LabelSmoothingLoss (smoothing: 0.1)
1: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
1: Building LabelSmoothingLoss (smoothing: 0.1)
3: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
3: Building LabelSmoothingLoss (smoothing: 0.1)
:::MLPv0.5.0 gnmt 1560382331.657372952 (train.py:208) model_hp_loss_fn: "Cross Entropy with label smoothing"
2: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
3: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
2: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
1: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
3: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
1: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
2: Number of parameters: 160671297
3: Number of parameters: 160671297
:::MLPv0.5.0 gnmt 1560382331.658035278 (train.py:210) model_hp_loss_smoothing: 0.1
1: Number of parameters: 160671297
0: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
0: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
0: Number of parameters: 160671297
:::MLPv0.5.0 gnmt 1560382331.659120798 (train.py:370) input_batch_size: 512
:::MLPv0.5.0 gnmt 1560382331.659622431 (train.py:372) input_size: 3497984
:::MLPv0.5.0 gnmt 1560382331.690707207 (train.py:386) eval_size: 3003
:::MLPv0.5.0 gnmt 1560382331.691970110 (seq2seq/inference/beam_search.py:43) eval_hp_beam_size: 5
:::MLPv0.5.0 gnmt 1560382331.692585945 (seq2seq/inference/beam_search.py:45) eval_hp_max_sequence_length: 150
:::MLPv0.5.0 gnmt 1560382331.693323851 (seq2seq/inference/beam_search.py:47) eval_hp_length_normalization_constant: 5.0
:::MLPv0.5.0 gnmt 1560382331.693919659 (seq2seq/inference/beam_search.py:49) eval_hp_length_normalization_factor: 0.6
2: Saving state of the tokenizer
1: Saving state of the tokenizer
3: Saving state of the tokenizer
:::MLPv0.5.0 gnmt 1560382331.694465876 (seq2seq/inference/beam_search.py:51) eval_hp_coverage_penalty_factor: 0.1
0: Saving state of the tokenizer
1: Initializing fp16 optimizer
1: Initializing fp32 clone weights
3: Initializing fp16 optimizer
3: Initializing fp32 clone weights
0: Initializing fp16 optimizer
0: Initializing fp32 clone weights
2: Initializing fp16 optimizer
2: Initializing fp32 clone weights
:::MLPv0.5.0 gnmt 1560382333.425757408 (seq2seq/train/trainer.py:99) opt_name: "adam"
:::MLPv0.5.0 gnmt 1560382333.426260233 (seq2seq/train/trainer.py:101) opt_learning_rate: 0.00125
:::MLPv0.5.0 gnmt 1560382333.426710129 (seq2seq/train/trainer.py:103) opt_hp_Adam_beta1: 0.9
:::MLPv0.5.0 gnmt 1560382333.427163124 (seq2seq/train/trainer.py:105) opt_hp_Adam_beta2: 0.999
:::MLPv0.5.0 gnmt 1560382333.427605391 (seq2seq/train/trainer.py:107) opt_hp_Adam_epsilon: 1e-08
2: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
3: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)1: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)

0: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
1: Starting epoch 0
3: Starting epoch 0
2: Starting epoch 0
:::MLPv0.5.0 gnmt 1560382333.428196430 (train.py:438) train_loop
0: Starting epoch 0
:::MLPv0.5.0 gnmt 1560382333.428683043 (train.py:443) train_epoch: 0
2: Sampler for epoch 0 uses seed 2171645000
1: Sampler for epoch 0 uses seed 2171645000
3: Sampler for epoch 0 uses seed 2171645000
:::MLPv0.5.0 gnmt 1560382334.168939114 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 2171645000
:::MLPv0.5.0 gnmt 1560382334.248452663 (seq2seq/data/sampler.py:66) input_shard: 40960
3: TRAIN [0][0/6832]	Time 1.423 (0.000)	Data 1.24881 (0.00000)	Tok/s 3491 (0)	Loss/tok 10.3825 (0.0000)	Learning Rate [1.2499999999999968e-05]
1: TRAIN [0][0/6832]	Time 1.423 (0.000)	Data 1.28483 (0.00000)	Tok/s 3419 (0)	Loss/tok 10.3812 (0.0000)	Learning Rate [1.2499999999999968e-05]
2: TRAIN [0][0/6832]	Time 1.423 (0.000)	Data 1.07584 (0.00000)	Tok/s 3419 (0)	Loss/tok 10.3809 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: TRAIN [0][0/6832]	Time 1.423 (0.000)	Data 1.33577 (0.00000)	Tok/s 3418 (0)	Loss/tok 10.3817 (0.0000)	Learning Rate [1.2499999999999968e-05]
2: TRAIN [0][10/6832]	Time 0.114 (0.106)	Data 0.00087 (0.00107)	Tok/s 53945 (57101)	Loss/tok 10.3528 (10.3675)	Learning Rate [1.5736567647427052e-05]
3: TRAIN [0][10/6832]	Time 0.114 (0.106)	Data 0.00084 (0.00102)	Tok/s 54401 (57596)	Loss/tok 10.3535 (10.3675)	Learning Rate [1.5736567647427052e-05]
1: TRAIN [0][10/6832]	Time 0.114 (0.106)	Data 0.00092 (0.00114)	Tok/s 53931 (56722)	Loss/tok 10.3536 (10.3672)	Learning Rate [1.5736567647427052e-05]
0: TRAIN [0][10/6832]	Time 0.114 (0.106)	Data 0.00103 (0.00085)	Tok/s 53948 (56583)	Loss/tok 10.3534 (10.3675)	Learning Rate [1.5736567647427052e-05]
2: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
2: TRAIN [0][20/6832]	Time 0.087 (0.106)	Data 0.00103 (0.00103)	Tok/s 53039 (59947)	Loss/tok 10.2984 (10.3496)	Learning Rate [1.9360207736405973e-05]
3: TRAIN [0][20/6832]	Time 0.087 (0.106)	Data 0.00084 (0.00099)	Tok/s 53882 (60570)	Loss/tok 10.2969 (10.3498)	Learning Rate [1.9360207736405973e-05]
1: TRAIN [0][20/6832]	Time 0.087 (0.106)	Data 0.00089 (0.00107)	Tok/s 52815 (59701)	Loss/tok 10.2994 (10.3498)	Learning Rate [1.9360207736405973e-05]
0: TRAIN [0][20/6832]	Time 0.087 (0.106)	Data 0.00099 (0.00105)	Tok/s 52831 (59571)	Loss/tok 10.2985 (10.3498)	Learning Rate [1.9360207736405973e-05]
1: TRAIN [0][30/6832]	Time 0.112 (0.106)	Data 0.00095 (0.00103)	Tok/s 52369 (58783)	Loss/tok 10.1038 (10.3083)	Learning Rate [2.4373057496975512e-05]
0: TRAIN [0][30/6832]	Time 0.112 (0.106)	Data 0.00101 (0.00102)	Tok/s 52373 (58649)	Loss/tok 10.0904 (10.3072)	Learning Rate [2.4373057496975512e-05]
2: TRAIN [0][30/6832]	Time 0.113 (0.106)	Data 0.00099 (0.00101)	Tok/s 52304 (59022)	Loss/tok 10.0957 (10.3077)	Learning Rate [2.4373057496975512e-05]
3: TRAIN [0][30/6832]	Time 0.113 (0.106)	Data 0.00090 (0.00097)	Tok/s 53020 (59536)	Loss/tok 10.1002 (10.3077)	Learning Rate [2.4373057496975512e-05]
3: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
1: TRAIN [0][40/6832]	Time 0.076 (0.105)	Data 0.00099 (0.00101)	Tok/s 51583 (58723)	Loss/tok 9.1120 (10.1350)	Learning Rate [2.998541148774357e-05]
2: TRAIN [0][40/6832]	Time 0.076 (0.105)	Data 0.00102 (0.00101)	Tok/s 52293 (59091)	Loss/tok 9.0892 (10.1350)	Learning Rate [2.998541148774357e-05]
3: TRAIN [0][40/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00097)	Tok/s 52296 (59615)	Loss/tok 9.0542 (10.1327)	Learning Rate [2.998541148774357e-05]
0: TRAIN [0][40/6832]	Time 0.076 (0.105)	Data 0.00095 (0.00101)	Tok/s 50602 (58459)	Loss/tok 9.0515 (10.1360)	Learning Rate [2.998541148774357e-05]
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 256.0
1: Skipped batch, new scale: 256.0
3: Skipped batch, new scale: 256.0
2: Skipped batch, new scale: 256.0
3: TRAIN [0][50/6832]	Time 0.131 (0.106)	Data 0.00083 (0.00097)	Tok/s 95488 (60159)	Loss/tok 9.3699 (10.0237)	Learning Rate [3.5229786640805606e-05]
0: TRAIN [0][50/6832]	Time 0.131 (0.106)	Data 0.00087 (0.00101)	Tok/s 91308 (59055)	Loss/tok 9.4216 (10.0296)	Learning Rate [3.5229786640805606e-05]
2: TRAIN [0][50/6832]	Time 0.131 (0.106)	Data 0.00129 (0.00103)	Tok/s 93635 (59702)	Loss/tok 9.4696 (10.0338)	Learning Rate [3.5229786640805606e-05]
1: TRAIN [0][50/6832]	Time 0.131 (0.106)	Data 0.00089 (0.00100)	Tok/s 92287 (59320)	Loss/tok 9.4472 (10.0307)	Learning Rate [3.5229786640805606e-05]
2: TRAIN [0][60/6832]	Time 0.077 (0.105)	Data 0.00095 (0.00102)	Tok/s 51685 (59902)	Loss/tok 8.3089 (9.8145)	Learning Rate [4.4351673654196854e-05]
1: TRAIN [0][60/6832]	Time 0.077 (0.105)	Data 0.00092 (0.00099)	Tok/s 51627 (59439)	Loss/tok 8.3599 (9.8153)	Learning Rate [4.4351673654196854e-05]
0: TRAIN [0][60/6832]	Time 0.077 (0.105)	Data 0.00094 (0.00100)	Tok/s 51640 (58976)	Loss/tok 8.3579 (9.8133)	Learning Rate [4.4351673654196854e-05]
3: TRAIN [0][60/6832]	Time 0.077 (0.105)	Data 0.00095 (0.00097)	Tok/s 53148 (60395)	Loss/tok 8.4337 (9.8081)	Learning Rate [4.4351673654196854e-05]
2: TRAIN [0][70/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00101)	Tok/s 58909 (59359)	Loss/tok 8.1986 (9.6199)	Learning Rate [5.58354490188703e-05]
3: TRAIN [0][70/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00096)	Tok/s 58916 (59844)	Loss/tok 8.2986 (9.6182)	Learning Rate [5.58354490188703e-05]
1: TRAIN [0][70/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00099)	Tok/s 58894 (58922)	Loss/tok 8.1866 (9.6206)	Learning Rate [5.58354490188703e-05]
0: TRAIN [0][70/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00099)	Tok/s 58245 (58492)	Loss/tok 8.0981 (9.6180)	Learning Rate [5.58354490188703e-05]
1: TRAIN [0][80/6832]	Time 0.128 (0.106)	Data 0.00092 (0.00098)	Tok/s 71038 (59555)	Loss/tok 8.1117 (9.4034)	Learning Rate [7.029266564879353e-05]
0: TRAIN [0][80/6832]	Time 0.128 (0.106)	Data 0.00094 (0.00098)	Tok/s 71064 (59164)	Loss/tok 8.1028 (9.4023)	Learning Rate [7.029266564879353e-05]
3: TRAIN [0][80/6832]	Time 0.128 (0.106)	Data 0.00086 (0.00096)	Tok/s 72003 (60427)	Loss/tok 7.9930 (9.4039)	Learning Rate [7.029266564879353e-05]
2: TRAIN [0][80/6832]	Time 0.128 (0.106)	Data 0.00114 (0.00100)	Tok/s 71307 (59954)	Loss/tok 8.1203 (9.4067)	Learning Rate [7.029266564879353e-05]
2: TRAIN [0][90/6832]	Time 0.112 (0.106)	Data 0.00091 (0.00100)	Tok/s 52557 (60457)	Loss/tok 7.9178 (9.2349)	Learning Rate [8.849322304801712e-05]
3: TRAIN [0][90/6832]	Time 0.112 (0.106)	Data 0.00089 (0.00096)	Tok/s 52544 (60951)	Loss/tok 7.9851 (9.2366)	Learning Rate [8.849322304801712e-05]
1: TRAIN [0][90/6832]	Time 0.112 (0.106)	Data 0.00094 (0.00098)	Tok/s 52531 (60039)	Loss/tok 7.9925 (9.2320)	Learning Rate [8.849322304801712e-05]
0: TRAIN [0][90/6832]	Time 0.112 (0.106)	Data 0.00092 (0.00098)	Tok/s 51761 (59616)	Loss/tok 7.9686 (9.2335)	Learning Rate [8.849322304801712e-05]
2: TRAIN [0][100/6832]	Time 0.117 (0.106)	Data 0.00093 (0.00100)	Tok/s 50906 (60405)	Loss/tok 7.8387 (9.1051)	Learning Rate [0.00011140636726671805]
0: TRAIN [0][100/6832]	Time 0.116 (0.106)	Data 0.00092 (0.00097)	Tok/s 50576 (59594)	Loss/tok 7.9362 (9.1030)	Learning Rate [0.00011140636726671805]
3: TRAIN [0][100/6832]	Time 0.117 (0.106)	Data 0.00091 (0.00096)	Tok/s 51624 (60888)	Loss/tok 7.9539 (9.1049)	Learning Rate [0.00011140636726671805]
1: TRAIN [0][100/6832]	Time 0.116 (0.106)	Data 0.00094 (0.00097)	Tok/s 50566 (60011)	Loss/tok 7.9680 (9.0998)	Learning Rate [0.00011140636726671805]
2: TRAIN [0][110/6832]	Time 0.132 (0.106)	Data 0.00086 (0.00100)	Tok/s 92817 (60620)	Loss/tok 8.0491 (8.9939)	Learning Rate [0.00014025230678774527]
3: TRAIN [0][110/6832]	Time 0.132 (0.106)	Data 0.00087 (0.00096)	Tok/s 94697 (61105)	Loss/tok 8.0359 (8.9941)	Learning Rate [0.00014025230678774527]
0: TRAIN [0][110/6832]	Time 0.132 (0.106)	Data 0.00088 (0.00096)	Tok/s 90405 (59828)	Loss/tok 8.0024 (8.9929)	Learning Rate [0.00014025230678774527]
1: TRAIN [0][110/6832]	Time 0.132 (0.106)	Data 0.00088 (0.00097)	Tok/s 91577 (60241)	Loss/tok 8.0455 (8.9888)	Learning Rate [0.00014025230678774527]
3: TRAIN [0][120/6832]	Time 0.131 (0.107)	Data 0.00104 (0.00096)	Tok/s 81159 (61426)	Loss/tok 8.0198 (8.8965)	Learning Rate [0.0001765671930778441]
1: TRAIN [0][120/6832]	Time 0.131 (0.107)	Data 0.00094 (0.00096)	Tok/s 80103 (60602)	Loss/tok 7.8454 (8.8877)	Learning Rate [0.0001765671930778441]
0: TRAIN [0][120/6832]	Time 0.131 (0.107)	Data 0.00094 (0.00096)	Tok/s 80073 (60206)	Loss/tok 7.9624 (8.8945)	Learning Rate [0.0001765671930778441]
2: TRAIN [0][120/6832]	Time 0.131 (0.107)	Data 0.00104 (0.00099)	Tok/s 80845 (60971)	Loss/tok 7.8741 (8.8915)	Learning Rate [0.0001765671930778441]
1: TRAIN [0][130/6832]	Time 0.130 (0.106)	Data 0.00114 (0.00096)	Tok/s 75989 (60419)	Loss/tok 7.9678 (8.8195)	Learning Rate [0.00022228492625486513]
2: TRAIN [0][130/6832]	Time 0.130 (0.106)	Data 0.00096 (0.00100)	Tok/s 76741 (60802)	Loss/tok 7.9042 (8.8217)	Learning Rate [0.00022228492625486513]
3: TRAIN [0][130/6832]	Time 0.130 (0.106)	Data 0.00093 (0.00095)	Tok/s 76958 (61247)	Loss/tok 7.9045 (8.8270)	Learning Rate [0.00022228492625486513]
0: TRAIN [0][130/6832]	Time 0.129 (0.106)	Data 0.00128 (0.00096)	Tok/s 76291 (60053)	Loss/tok 7.9564 (8.8249)	Learning Rate [0.00022228492625486513]
2: TRAIN [0][140/6832]	Time 0.126 (0.106)	Data 0.00098 (0.00100)	Tok/s 64894 (60981)	Loss/tok 7.8194 (8.7455)	Learning Rate [0.0002798401423210422]
3: TRAIN [0][140/6832]	Time 0.126 (0.106)	Data 0.00097 (0.00096)	Tok/s 64887 (61430)	Loss/tok 7.9300 (8.7502)	Learning Rate [0.0002798401423210422]
1: TRAIN [0][140/6832]	Time 0.126 (0.106)	Data 0.00094 (0.00096)	Tok/s 64867 (60588)	Loss/tok 7.9430 (8.7451)	Learning Rate [0.0002798401423210422]
0: TRAIN [0][140/6832]	Time 0.126 (0.106)	Data 0.00091 (0.00096)	Tok/s 64882 (60191)	Loss/tok 7.8281 (8.7516)	Learning Rate [0.0002798401423210422]
3: TRAIN [0][150/6832]	Time 0.132 (0.106)	Data 0.00086 (0.00096)	Tok/s 94888 (61361)	Loss/tok 7.8699 (8.6864)	Learning Rate [0.0003522978664080565]
0: TRAIN [0][150/6832]	Time 0.132 (0.106)	Data 0.00095 (0.00096)	Tok/s 90511 (59860)	Loss/tok 7.7840 (8.6920)	Learning Rate [0.0003522978664080565]
1: TRAIN [0][150/6832]	Time 0.132 (0.106)	Data 0.00096 (0.00096)	Tok/s 91575 (60407)	Loss/tok 7.8536 (8.6847)	Learning Rate [0.0003522978664080565]
2: TRAIN [0][150/6832]	Time 0.132 (0.106)	Data 0.00090 (0.00099)	Tok/s 92777 (60862)	Loss/tok 7.6729 (8.6775)	Learning Rate [0.0003522978664080565]
2: TRAIN [0][160/6832]	Time 0.118 (0.106)	Data 0.00087 (0.00099)	Tok/s 53168 (60988)	Loss/tok 7.7530 (8.6153)	Learning Rate [0.00044351673654196904]
3: TRAIN [0][160/6832]	Time 0.118 (0.106)	Data 0.00086 (0.00096)	Tok/s 53164 (61483)	Loss/tok 7.6676 (8.6228)	Learning Rate [0.00044351673654196904]
1: TRAIN [0][160/6832]	Time 0.118 (0.106)	Data 0.00093 (0.00096)	Tok/s 53203 (60539)	Loss/tok 7.6162 (8.6234)	Learning Rate [0.00044351673654196904]
0: TRAIN [0][160/6832]	Time 0.118 (0.106)	Data 0.00107 (0.00096)	Tok/s 53286 (60010)	Loss/tok 7.7474 (8.6292)	Learning Rate [0.00044351673654196904]
1: TRAIN [0][170/6832]	Time 0.120 (0.107)	Data 0.00091 (0.00096)	Tok/s 58721 (60305)	Loss/tok 7.4942 (8.5690)	Learning Rate [0.0005583544901887037]
3: TRAIN [0][170/6832]	Time 0.120 (0.107)	Data 0.00088 (0.00096)	Tok/s 59772 (61218)	Loss/tok 7.7169 (8.5704)	Learning Rate [0.0005583544901887037]
2: TRAIN [0][170/6832]	Time 0.120 (0.107)	Data 0.00086 (0.00099)	Tok/s 59240 (60735)	Loss/tok 7.7970 (8.5618)	Learning Rate [0.0005583544901887037]
0: TRAIN [0][170/6832]	Time 0.120 (0.107)	Data 0.00093 (0.00096)	Tok/s 58722 (59790)	Loss/tok 7.6569 (8.5756)	Learning Rate [0.0005583544901887037]
3: Upscaling, new scale: 512.0
1: Upscaling, new scale: 512.0
0: Upscaling, new scale: 512.0
2: Upscaling, new scale: 512.0
2: TRAIN [0][180/6832]	Time 0.054 (0.105)	Data 0.00087 (0.00099)	Tok/s 50227 (60452)	Loss/tok 6.7558 (8.5183)	Learning Rate [0.000702926656487936]
3: TRAIN [0][180/6832]	Time 0.054 (0.105)	Data 0.00087 (0.00096)	Tok/s 50214 (60937)	Loss/tok 6.7794 (8.5264)	Learning Rate [0.000702926656487936]
0: TRAIN [0][180/6832]	Time 0.053 (0.105)	Data 0.00089 (0.00095)	Tok/s 47856 (59519)	Loss/tok 6.7656 (8.5314)	Learning Rate [0.000702926656487936]
1: TRAIN [0][180/6832]	Time 0.054 (0.105)	Data 0.00092 (0.00096)	Tok/s 49329 (60034)	Loss/tok 6.6989 (8.5238)	Learning Rate [0.000702926656487936]
1: TRAIN [0][190/6832]	Time 0.084 (0.105)	Data 0.00101 (0.00096)	Tok/s 51786 (60132)	Loss/tok 7.2092 (8.4685)	Learning Rate [0.0008849322304801722]
2: TRAIN [0][190/6832]	Time 0.084 (0.105)	Data 0.00112 (0.00099)	Tok/s 51888 (60547)	Loss/tok 7.3133 (8.4654)	Learning Rate [0.0008849322304801722]
0: TRAIN [0][190/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00095)	Tok/s 51771 (59630)	Loss/tok 7.1532 (8.4761)	Learning Rate [0.0008849322304801722]
3: TRAIN [0][190/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00096)	Tok/s 51757 (61023)	Loss/tok 7.3259 (8.4726)	Learning Rate [0.0008849322304801722]
2: TRAIN [0][200/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00099)	Tok/s 70671 (60345)	Loss/tok 7.7202 (8.4180)	Learning Rate [0.001114063672667182]
3: TRAIN [0][200/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00096)	Tok/s 71165 (60838)	Loss/tok 7.6871 (8.4241)	Learning Rate [0.001114063672667182]
1: TRAIN [0][200/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 70138 (59920)	Loss/tok 7.5688 (8.4192)	Learning Rate [0.001114063672667182]
0: TRAIN [0][200/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 70153 (59362)	Loss/tok 7.5941 (8.4291)	Learning Rate [0.001114063672667182]
1: TRAIN [0][210/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00096)	Tok/s 60515 (59778)	Loss/tok 7.2435 (8.3716)	Learning Rate [0.00125]
0: TRAIN [0][210/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00095)	Tok/s 59526 (59222)	Loss/tok 7.2854 (8.3808)	Learning Rate [0.00125]
3: TRAIN [0][210/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00095)	Tok/s 60511 (60698)	Loss/tok 7.2900 (8.3757)	Learning Rate [0.00125]
2: TRAIN [0][210/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00099)	Tok/s 60135 (60202)	Loss/tok 7.2429 (8.3704)	Learning Rate [0.00125]
3: TRAIN [0][220/6832]	Time 0.043 (0.105)	Data 0.00100 (0.00095)	Tok/s 42348 (60474)	Loss/tok 5.7208 (8.3297)	Learning Rate [0.00125]
2: TRAIN [0][220/6832]	Time 0.043 (0.105)	Data 0.00092 (0.00099)	Tok/s 38563 (59965)	Loss/tok 4.8095 (8.3210)	Learning Rate [0.00125]
1: TRAIN [0][220/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00096)	Tok/s 32037 (59519)	Loss/tok 6.1001 (8.3269)	Learning Rate [0.00125]
0: TRAIN [0][220/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00095)	Tok/s 20639 (58921)	Loss/tok 5.4327 (8.3353)	Learning Rate [0.00125]
2: TRAIN [0][230/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00099)	Tok/s 57685 (60170)	Loss/tok 7.1483 (8.2592)	Learning Rate [0.00125]
3: TRAIN [0][230/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00095)	Tok/s 57686 (60679)	Loss/tok 7.1553 (8.2686)	Learning Rate [0.00125]
1: TRAIN [0][230/6832]	Time 0.122 (0.105)	Data 0.00100 (0.00096)	Tok/s 57645 (59724)	Loss/tok 7.0448 (8.2649)	Learning Rate [0.00125]
0: TRAIN [0][230/6832]	Time 0.122 (0.105)	Data 0.00103 (0.00095)	Tok/s 57567 (59129)	Loss/tok 7.1358 (8.2709)	Learning Rate [0.00125]
2: TRAIN [0][240/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00099)	Tok/s 65060 (60287)	Loss/tok 7.0156 (8.2009)	Learning Rate [0.00125]
3: TRAIN [0][240/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 65705 (60794)	Loss/tok 7.2307 (8.2108)	Learning Rate [0.00125]
1: TRAIN [0][240/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00096)	Tok/s 65069 (59851)	Loss/tok 6.8750 (8.2070)	Learning Rate [0.00125]
0: TRAIN [0][240/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 65079 (59264)	Loss/tok 7.0569 (8.2108)	Learning Rate [0.00125]
2: TRAIN [0][250/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00099)	Tok/s 54033 (60447)	Loss/tok 6.8777 (8.1462)	Learning Rate [0.00125]
3: TRAIN [0][250/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00095)	Tok/s 54036 (60956)	Loss/tok 6.8765 (8.1565)	Learning Rate [0.00125]
1: TRAIN [0][250/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00096)	Tok/s 53969 (60005)	Loss/tok 6.8699 (8.1531)	Learning Rate [0.00125]
0: TRAIN [0][250/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00095)	Tok/s 53114 (59431)	Loss/tok 6.8020 (8.1551)	Learning Rate [0.00125]
2: TRAIN [0][260/6832]	Time 0.117 (0.105)	Data 0.00104 (0.00099)	Tok/s 58962 (60358)	Loss/tok 6.6722 (8.0930)	Learning Rate [0.00125]
3: TRAIN [0][260/6832]	Time 0.117 (0.105)	Data 0.00103 (0.00095)	Tok/s 59943 (60866)	Loss/tok 6.7578 (8.1022)	Learning Rate [0.00125]
1: TRAIN [0][260/6832]	Time 0.118 (0.105)	Data 0.00111 (0.00096)	Tok/s 58786 (59914)	Loss/tok 6.7526 (8.0995)	Learning Rate [0.00125]
0: TRAIN [0][260/6832]	Time 0.117 (0.105)	Data 0.00113 (0.00095)	Tok/s 58830 (59346)	Loss/tok 6.7843 (8.1004)	Learning Rate [0.00125]
1: TRAIN [0][270/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00096)	Tok/s 61771 (59659)	Loss/tok 6.6864 (8.0534)	Learning Rate [0.00125]
0: TRAIN [0][270/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00095)	Tok/s 61168 (59105)	Loss/tok 6.6699 (8.0551)	Learning Rate [0.00125]
2: TRAIN [0][270/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00099)	Tok/s 62128 (60095)	Loss/tok 6.7094 (8.0459)	Learning Rate [0.00125]
3: TRAIN [0][270/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00095)	Tok/s 62146 (60605)	Loss/tok 6.6460 (8.0565)	Learning Rate [0.00125]
1: TRAIN [0][280/6832]	Time 0.106 (0.104)	Data 0.00103 (0.00096)	Tok/s 54377 (59585)	Loss/tok 6.5296 (8.0071)	Learning Rate [0.00125]
0: TRAIN [0][280/6832]	Time 0.106 (0.104)	Data 0.00104 (0.00095)	Tok/s 54366 (59036)	Loss/tok 6.6326 (8.0101)	Learning Rate [0.00125]
2: TRAIN [0][280/6832]	Time 0.106 (0.104)	Data 0.00102 (0.00099)	Tok/s 54330 (60025)	Loss/tok 6.4590 (7.9990)	Learning Rate [0.00125]
3: TRAIN [0][280/6832]	Time 0.106 (0.104)	Data 0.00103 (0.00095)	Tok/s 54353 (60536)	Loss/tok 6.5737 (8.0100)	Learning Rate [0.00125]
2: TRAIN [0][290/6832]	Time 0.075 (0.104)	Data 0.00087 (0.00099)	Tok/s 53352 (59943)	Loss/tok 6.2232 (7.9511)	Learning Rate [0.00125]
3: TRAIN [0][290/6832]	Time 0.075 (0.104)	Data 0.00086 (0.00095)	Tok/s 54423 (60452)	Loss/tok 6.2225 (7.9626)	Learning Rate [0.00125]
1: TRAIN [0][290/6832]	Time 0.075 (0.104)	Data 0.00095 (0.00096)	Tok/s 52685 (59507)	Loss/tok 6.1854 (7.9581)	Learning Rate [0.00125]
0: TRAIN [0][290/6832]	Time 0.075 (0.104)	Data 0.00099 (0.00095)	Tok/s 52705 (58972)	Loss/tok 6.2719 (7.9620)	Learning Rate [0.00125]
2: TRAIN [0][300/6832]	Time 0.117 (0.104)	Data 0.00087 (0.00099)	Tok/s 54738 (59888)	Loss/tok 6.4286 (7.9013)	Learning Rate [0.00125]
1: TRAIN [0][300/6832]	Time 0.117 (0.104)	Data 0.00092 (0.00096)	Tok/s 54019 (59457)	Loss/tok 6.4440 (7.9093)	Learning Rate [0.00125]
0: TRAIN [0][300/6832]	Time 0.117 (0.104)	Data 0.00092 (0.00095)	Tok/s 53598 (58923)	Loss/tok 6.4412 (7.9132)	Learning Rate [0.00125]
3: TRAIN [0][300/6832]	Time 0.117 (0.104)	Data 0.00088 (0.00095)	Tok/s 54739 (60397)	Loss/tok 6.4083 (7.9140)	Learning Rate [0.00125]
1: Upscaling, new scale: 1024.0
2: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
3: TRAIN [0][310/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 69027 (60444)	Loss/tok 6.5178 (7.8621)	Learning Rate [0.00125]
1: TRAIN [0][310/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00096)	Tok/s 68639 (59525)	Loss/tok 6.4646 (7.8573)	Learning Rate [0.00125]
0: TRAIN [0][310/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00095)	Tok/s 68631 (59000)	Loss/tok 6.4845 (7.8591)	Learning Rate [0.00125]
2: TRAIN [0][310/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00099)	Tok/s 68139 (59942)	Loss/tok 6.4978 (7.8490)	Learning Rate [0.00125]
2: TRAIN [0][320/6832]	Time 0.084 (0.104)	Data 0.00095 (0.00099)	Tok/s 54924 (59946)	Loss/tok 6.1395 (7.8032)	Learning Rate [0.00125]
3: TRAIN [0][320/6832]	Time 0.084 (0.104)	Data 0.00088 (0.00095)	Tok/s 54930 (60439)	Loss/tok 6.1160 (7.8174)	Learning Rate [0.00125]
1: TRAIN [0][320/6832]	Time 0.084 (0.104)	Data 0.00093 (0.00096)	Tok/s 53906 (59525)	Loss/tok 6.0368 (7.8119)	Learning Rate [0.00125]
0: TRAIN [0][320/6832]	Time 0.084 (0.104)	Data 0.00092 (0.00095)	Tok/s 53393 (59005)	Loss/tok 6.0219 (7.8147)	Learning Rate [0.00125]
2: TRAIN [0][330/6832]	Time 0.120 (0.105)	Data 0.00114 (0.00099)	Tok/s 54477 (60013)	Loss/tok 6.2614 (7.7537)	Learning Rate [0.00125]
3: TRAIN [0][330/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00095)	Tok/s 54813 (60513)	Loss/tok 6.2473 (7.7667)	Learning Rate [0.00125]
1: TRAIN [0][330/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00096)	Tok/s 54212 (59594)	Loss/tok 6.0294 (7.7612)	Learning Rate [0.00125]
0: TRAIN [0][330/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00095)	Tok/s 54223 (59080)	Loss/tok 6.2658 (7.7638)	Learning Rate [0.00125]
2: TRAIN [0][340/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00099)	Tok/s 56327 (60068)	Loss/tok 5.9640 (7.7043)	Learning Rate [0.00125]
3: TRAIN [0][340/6832]	Time 0.122 (0.105)	Data 0.00094 (0.00095)	Tok/s 56833 (60565)	Loss/tok 6.2072 (7.7181)	Learning Rate [0.00125]
1: TRAIN [0][340/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00096)	Tok/s 55743 (59655)	Loss/tok 6.3759 (7.7133)	Learning Rate [0.00125]
0: TRAIN [0][340/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00095)	Tok/s 55745 (59139)	Loss/tok 6.2681 (7.7153)	Learning Rate [0.00125]
3: TRAIN [0][350/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00095)	Tok/s 54248 (60670)	Loss/tok 5.8837 (7.6690)	Learning Rate [0.00125]
2: TRAIN [0][350/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00099)	Tok/s 54203 (60167)	Loss/tok 5.7712 (7.6572)	Learning Rate [0.00125]
0: TRAIN [0][350/6832]	Time 0.071 (0.105)	Data 0.00102 (0.00095)	Tok/s 52757 (59226)	Loss/tok 5.7943 (7.6677)	Learning Rate [0.00125]
1: TRAIN [0][350/6832]	Time 0.071 (0.105)	Data 0.00095 (0.00096)	Tok/s 54264 (59748)	Loss/tok 5.8611 (7.6656)	Learning Rate [0.00125]
2: TRAIN [0][360/6832]	Time 0.102 (0.105)	Data 0.00087 (0.00099)	Tok/s 55862 (60265)	Loss/tok 6.0650 (7.6124)	Learning Rate [0.00125]
3: TRAIN [0][360/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00095)	Tok/s 56371 (60763)	Loss/tok 5.9987 (7.6237)	Learning Rate [0.00125]
1: TRAIN [0][360/6832]	Time 0.102 (0.105)	Data 0.00093 (0.00096)	Tok/s 55086 (59848)	Loss/tok 5.9080 (7.6202)	Learning Rate [0.00125]
0: TRAIN [0][360/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00095)	Tok/s 55102 (59335)	Loss/tok 5.9049 (7.6222)	Learning Rate [0.00125]
1: TRAIN [0][370/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00096)	Tok/s 79715 (59916)	Loss/tok 6.0515 (7.5752)	Learning Rate [0.00125]
3: TRAIN [0][370/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00095)	Tok/s 80307 (60832)	Loss/tok 6.2302 (7.5792)	Learning Rate [0.00125]
0: TRAIN [0][370/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 79263 (59407)	Loss/tok 6.2131 (7.5766)	Learning Rate [0.00125]
2: TRAIN [0][370/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00099)	Tok/s 80217 (60334)	Loss/tok 6.2271 (7.5691)	Learning Rate [0.00125]
2: TRAIN [0][380/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00099)	Tok/s 52035 (60265)	Loss/tok 5.8637 (7.5293)	Learning Rate [0.00125]
3: TRAIN [0][380/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00095)	Tok/s 53111 (60761)	Loss/tok 5.8903 (7.5393)	Learning Rate [0.00125]
0: TRAIN [0][380/6832]	Time 0.113 (0.105)	Data 0.00094 (0.00095)	Tok/s 51944 (59346)	Loss/tok 5.8598 (7.5363)	Learning Rate [0.00125]
1: TRAIN [0][380/6832]	Time 0.113 (0.105)	Data 0.00095 (0.00096)	Tok/s 51940 (59854)	Loss/tok 5.9971 (7.5358)	Learning Rate [0.00125]
3: TRAIN [0][390/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00095)	Tok/s 60274 (60883)	Loss/tok 5.9270 (7.4925)	Learning Rate [0.00125]
2: TRAIN [0][390/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00099)	Tok/s 59998 (60388)	Loss/tok 6.0286 (7.4839)	Learning Rate [0.00125]
1: TRAIN [0][390/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00096)	Tok/s 59129 (59978)	Loss/tok 5.9309 (7.4901)	Learning Rate [0.00125]
0: TRAIN [0][390/6832]	Time 0.121 (0.105)	Data 0.00106 (0.00095)	Tok/s 59134 (59472)	Loss/tok 6.0122 (7.4908)	Learning Rate [0.00125]
1: TRAIN [0][400/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00096)	Tok/s 67810 (59997)	Loss/tok 5.8397 (7.4475)	Learning Rate [0.00125]
3: TRAIN [0][400/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00095)	Tok/s 67907 (60904)	Loss/tok 5.9750 (7.4508)	Learning Rate [0.00125]
0: TRAIN [0][400/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00095)	Tok/s 67810 (59498)	Loss/tok 5.9826 (7.4496)	Learning Rate [0.00125]
2: TRAIN [0][400/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00099)	Tok/s 67850 (60403)	Loss/tok 5.9277 (7.4435)	Learning Rate [0.00125]
2: TRAIN [0][410/6832]	Time 0.124 (0.106)	Data 0.00087 (0.00099)	Tok/s 58674 (60498)	Loss/tok 5.7382 (7.3963)	Learning Rate [0.00125]
3: TRAIN [0][410/6832]	Time 0.124 (0.106)	Data 0.00086 (0.00095)	Tok/s 58675 (60994)	Loss/tok 5.9110 (7.4046)	Learning Rate [0.00125]
1: TRAIN [0][410/6832]	Time 0.124 (0.106)	Data 0.00095 (0.00096)	Tok/s 57784 (60090)	Loss/tok 5.8062 (7.4022)	Learning Rate [0.00125]
0: TRAIN [0][410/6832]	Time 0.124 (0.106)	Data 0.00094 (0.00095)	Tok/s 57653 (59598)	Loss/tok 5.9619 (7.4030)	Learning Rate [0.00125]
0: TRAIN [0][420/6832]	Time 0.110 (0.106)	Data 0.00097 (0.00095)	Tok/s 52199 (59625)	Loss/tok 5.6499 (7.3620)	Learning Rate [0.00125]
1: TRAIN [0][420/6832]	Time 0.110 (0.106)	Data 0.00094 (0.00095)	Tok/s 52198 (60110)	Loss/tok 5.7021 (7.3623)	Learning Rate [0.00125]
3: TRAIN [0][420/6832]	Time 0.110 (0.106)	Data 0.00092 (0.00095)	Tok/s 52214 (61002)	Loss/tok 5.8269 (7.3653)	Learning Rate [0.00125]
2: TRAIN [0][420/6832]	Time 0.110 (0.106)	Data 0.00093 (0.00099)	Tok/s 52184 (60514)	Loss/tok 5.5833 (7.3566)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
2: TRAIN [0][430/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00099)	Tok/s 50825 (60464)	Loss/tok 4.5095 (7.3197)	Learning Rate [0.00125]
1: TRAIN [0][430/6832]	Time 0.053 (0.105)	Data 0.00105 (0.00095)	Tok/s 48687 (60061)	Loss/tok 4.5787 (7.3261)	Learning Rate [0.00125]
0: TRAIN [0][430/6832]	Time 0.053 (0.105)	Data 0.00100 (0.00095)	Tok/s 48355 (59582)	Loss/tok 4.6335 (7.3257)	Learning Rate [0.00125]
3: TRAIN [0][430/6832]	Time 0.053 (0.105)	Data 0.00087 (0.00095)	Tok/s 50646 (60947)	Loss/tok 4.6573 (7.3291)	Learning Rate [0.00125]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
2: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 512.0
1: Skipped batch, new scale: 512.0
2: Skipped batch, new scale: 512.0
3: Skipped batch, new scale: 512.0
1: TRAIN [0][440/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00095)	Tok/s 53266 (60115)	Loss/tok 5.5984 (7.2854)	Learning Rate [0.00125]
3: TRAIN [0][440/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00095)	Tok/s 53261 (60995)	Loss/tok 5.5243 (7.2884)	Learning Rate [0.00125]
2: TRAIN [0][440/6832]	Time 0.110 (0.105)	Data 0.00092 (0.00099)	Tok/s 53542 (60516)	Loss/tok 5.6207 (7.2798)	Learning Rate [0.00125]
0: TRAIN [0][440/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00095)	Tok/s 52537 (59635)	Loss/tok 5.6100 (7.2868)	Learning Rate [0.00125]
2: TRAIN [0][450/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00099)	Tok/s 64679 (60470)	Loss/tok 5.8029 (7.2453)	Learning Rate [0.00125]
1: TRAIN [0][450/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00095)	Tok/s 63750 (60055)	Loss/tok 5.9842 (7.2519)	Learning Rate [0.00125]
3: TRAIN [0][450/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 64694 (60961)	Loss/tok 5.8807 (7.2534)	Learning Rate [0.00125]
0: TRAIN [0][450/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 63636 (59553)	Loss/tok 5.8006 (7.2533)	Learning Rate [0.00125]
1: TRAIN [0][460/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 75017 (60086)	Loss/tok 5.7666 (7.2146)	Learning Rate [0.00125]
2: TRAIN [0][460/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00099)	Tok/s 75233 (60498)	Loss/tok 5.6776 (7.2080)	Learning Rate [0.00125]
3: TRAIN [0][460/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 76007 (60985)	Loss/tok 5.7529 (7.2170)	Learning Rate [0.00125]
0: TRAIN [0][460/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00095)	Tok/s 75080 (59591)	Loss/tok 5.7354 (7.2164)	Learning Rate [0.00125]
2: TRAIN [0][470/6832]	Time 0.078 (0.105)	Data 0.00107 (0.00099)	Tok/s 52706 (60543)	Loss/tok 5.0384 (7.1695)	Learning Rate [0.00125]
3: TRAIN [0][470/6832]	Time 0.078 (0.105)	Data 0.00104 (0.00095)	Tok/s 52731 (61025)	Loss/tok 5.1934 (7.1771)	Learning Rate [0.00125]
1: TRAIN [0][470/6832]	Time 0.078 (0.105)	Data 0.00099 (0.00095)	Tok/s 52687 (60136)	Loss/tok 5.0527 (7.1751)	Learning Rate [0.00125]
0: TRAIN [0][470/6832]	Time 0.078 (0.105)	Data 0.00101 (0.00095)	Tok/s 52723 (59647)	Loss/tok 5.1572 (7.1787)	Learning Rate [0.00125]
2: TRAIN [0][480/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00099)	Tok/s 59855 (60545)	Loss/tok 5.4933 (7.1335)	Learning Rate [0.00125]
3: TRAIN [0][480/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00095)	Tok/s 59856 (61025)	Loss/tok 5.4987 (7.1411)	Learning Rate [0.00125]
1: TRAIN [0][480/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00095)	Tok/s 59818 (60143)	Loss/tok 5.5164 (7.1383)	Learning Rate [0.00125]
0: TRAIN [0][480/6832]	Time 0.124 (0.105)	Data 0.00098 (0.00095)	Tok/s 59849 (59658)	Loss/tok 5.6760 (7.1431)	Learning Rate [0.00125]
1: TRAIN [0][490/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00095)	Tok/s 54837 (60185)	Loss/tok 5.5130 (7.1017)	Learning Rate [0.00125]
2: TRAIN [0][490/6832]	Time 0.114 (0.105)	Data 0.00085 (0.00099)	Tok/s 54827 (60588)	Loss/tok 5.4670 (7.0964)	Learning Rate [0.00125]
3: TRAIN [0][490/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00095)	Tok/s 54822 (61074)	Loss/tok 5.4562 (7.1045)	Learning Rate [0.00125]
0: TRAIN [0][490/6832]	Time 0.114 (0.105)	Data 0.00095 (0.00095)	Tok/s 54838 (59700)	Loss/tok 5.3228 (7.1053)	Learning Rate [0.00125]
2: TRAIN [0][500/6832]	Time 0.072 (0.106)	Data 0.00117 (0.00099)	Tok/s 53037 (60618)	Loss/tok 4.9866 (7.0590)	Learning Rate [0.00125]
3: TRAIN [0][500/6832]	Time 0.073 (0.106)	Data 0.00093 (0.00095)	Tok/s 52936 (61100)	Loss/tok 4.8764 (7.0682)	Learning Rate [0.00125]
1: TRAIN [0][500/6832]	Time 0.073 (0.106)	Data 0.00092 (0.00095)	Tok/s 51257 (60215)	Loss/tok 4.9544 (7.0643)	Learning Rate [0.00125]
0: TRAIN [0][500/6832]	Time 0.073 (0.106)	Data 0.00096 (0.00095)	Tok/s 51118 (59734)	Loss/tok 5.0512 (7.0689)	Learning Rate [0.00125]
2: TRAIN [0][510/6832]	Time 0.082 (0.106)	Data 0.00091 (0.00099)	Tok/s 54318 (60563)	Loss/tok 5.1599 (7.0265)	Learning Rate [0.00125]
1: TRAIN [0][510/6832]	Time 0.083 (0.106)	Data 0.00091 (0.00095)	Tok/s 54251 (60165)	Loss/tok 5.0912 (7.0322)	Learning Rate [0.00125]
3: TRAIN [0][510/6832]	Time 0.082 (0.106)	Data 0.00098 (0.00095)	Tok/s 54325 (61041)	Loss/tok 5.2028 (7.0362)	Learning Rate [0.00125]
0: TRAIN [0][510/6832]	Time 0.083 (0.106)	Data 0.00098 (0.00095)	Tok/s 54298 (59691)	Loss/tok 5.2052 (7.0352)	Learning Rate [0.00125]
2: TRAIN [0][520/6832]	Time 0.091 (0.105)	Data 0.00084 (0.00099)	Tok/s 53565 (60425)	Loss/tok 5.1599 (6.9994)	Learning Rate [0.00125]
1: TRAIN [0][520/6832]	Time 0.091 (0.105)	Data 0.00097 (0.00095)	Tok/s 53590 (60029)	Loss/tok 4.9548 (7.0044)	Learning Rate [0.00125]
0: TRAIN [0][520/6832]	Time 0.091 (0.105)	Data 0.00099 (0.00095)	Tok/s 53595 (59551)	Loss/tok 4.9946 (7.0078)	Learning Rate [0.00125]
3: TRAIN [0][520/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00095)	Tok/s 54653 (60904)	Loss/tok 5.3962 (7.0082)	Learning Rate [0.00125]
2: TRAIN [0][530/6832]	Time 0.065 (0.105)	Data 0.00083 (0.00098)	Tok/s 51395 (60390)	Loss/tok 4.6760 (6.9693)	Learning Rate [0.00125]
1: TRAIN [0][530/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00095)	Tok/s 51114 (59996)	Loss/tok 4.5396 (6.9736)	Learning Rate [0.00125]
3: TRAIN [0][530/6832]	Time 0.065 (0.105)	Data 0.00088 (0.00095)	Tok/s 53092 (60874)	Loss/tok 4.8647 (6.9779)	Learning Rate [0.00125]
0: TRAIN [0][530/6832]	Time 0.065 (0.105)	Data 0.00096 (0.00095)	Tok/s 51090 (59522)	Loss/tok 4.6817 (6.9768)	Learning Rate [0.00125]
2: TRAIN [0][540/6832]	Time 0.099 (0.105)	Data 0.00086 (0.00098)	Tok/s 52032 (60359)	Loss/tok 4.9268 (6.9369)	Learning Rate [0.00125]
1: TRAIN [0][540/6832]	Time 0.099 (0.105)	Data 0.00098 (0.00095)	Tok/s 51877 (59970)	Loss/tok 4.9740 (6.9416)	Learning Rate [0.00125]
0: TRAIN [0][540/6832]	Time 0.099 (0.105)	Data 0.00097 (0.00095)	Tok/s 51858 (59501)	Loss/tok 5.1518 (6.9454)	Learning Rate [0.00125]
3: TRAIN [0][540/6832]	Time 0.099 (0.105)	Data 0.00088 (0.00095)	Tok/s 53184 (60846)	Loss/tok 5.0971 (6.9470)	Learning Rate [0.00125]
2: TRAIN [0][550/6832]	Time 0.050 (0.105)	Data 0.00086 (0.00098)	Tok/s 43303 (60334)	Loss/tok 3.7179 (6.9072)	Learning Rate [0.00125]
0: TRAIN [0][550/6832]	Time 0.050 (0.105)	Data 0.00099 (0.00095)	Tok/s 39100 (59473)	Loss/tok 3.2878 (6.9150)	Learning Rate [0.00125]
3: TRAIN [0][550/6832]	Time 0.050 (0.105)	Data 0.00091 (0.00095)	Tok/s 45834 (60827)	Loss/tok 3.9841 (6.9161)	Learning Rate [0.00125]
1: TRAIN [0][550/6832]	Time 0.050 (0.105)	Data 0.00094 (0.00095)	Tok/s 41443 (59944)	Loss/tok 3.8902 (6.9122)	Learning Rate [0.00125]
2: TRAIN [0][560/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00098)	Tok/s 69556 (60313)	Loss/tok 5.3434 (6.8765)	Learning Rate [0.00125]
1: TRAIN [0][560/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 69568 (59915)	Loss/tok 5.3355 (6.8821)	Learning Rate [0.00125]
0: TRAIN [0][560/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 69556 (59427)	Loss/tok 5.1614 (6.8834)	Learning Rate [0.00125]
3: TRAIN [0][560/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 70538 (60810)	Loss/tok 5.2835 (6.8851)	Learning Rate [0.00125]
2: Upscaling, new scale: 1024.0
1: Upscaling, new scale: 1024.0
0: Upscaling, new scale: 1024.0
3: Upscaling, new scale: 1024.0
2: TRAIN [0][570/6832]	Time 0.130 (0.106)	Data 0.00086 (0.00098)	Tok/s 75151 (60370)	Loss/tok 5.1757 (6.8397)	Learning Rate [0.00125]
0: TRAIN [0][570/6832]	Time 0.130 (0.106)	Data 0.00095 (0.00095)	Tok/s 74703 (59495)	Loss/tok 5.2203 (6.8474)	Learning Rate [0.00125]
1: TRAIN [0][570/6832]	Time 0.130 (0.106)	Data 0.00096 (0.00095)	Tok/s 74763 (59977)	Loss/tok 5.2931 (6.8466)	Learning Rate [0.00125]
3: TRAIN [0][570/6832]	Time 0.130 (0.106)	Data 0.00086 (0.00095)	Tok/s 75697 (60866)	Loss/tok 5.2677 (6.8500)	Learning Rate [0.00125]
2: TRAIN [0][580/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00098)	Tok/s 54688 (60341)	Loss/tok 4.6208 (6.8107)	Learning Rate [0.00125]
1: TRAIN [0][580/6832]	Time 0.080 (0.105)	Data 0.00096 (0.00095)	Tok/s 54643 (59945)	Loss/tok 4.7548 (6.8191)	Learning Rate [0.00125]
3: TRAIN [0][580/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00095)	Tok/s 54685 (60842)	Loss/tok 4.7502 (6.8203)	Learning Rate [0.00125]
0: TRAIN [0][580/6832]	Time 0.080 (0.105)	Data 0.00094 (0.00095)	Tok/s 54682 (59463)	Loss/tok 4.8933 (6.8203)	Learning Rate [0.00125]
2: TRAIN [0][590/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00098)	Tok/s 52019 (60300)	Loss/tok 4.7025 (6.7841)	Learning Rate [0.00125]
1: TRAIN [0][590/6832]	Time 0.089 (0.105)	Data 0.00100 (0.00095)	Tok/s 52047 (59907)	Loss/tok 4.7667 (6.7917)	Learning Rate [0.00125]
3: TRAIN [0][590/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00095)	Tok/s 52238 (60803)	Loss/tok 4.8368 (6.7933)	Learning Rate [0.00125]
0: TRAIN [0][590/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00095)	Tok/s 52045 (59430)	Loss/tok 5.0914 (6.7931)	Learning Rate [0.00125]
2: TRAIN [0][600/6832]	Time 0.111 (0.105)	Data 0.00084 (0.00098)	Tok/s 51992 (60316)	Loss/tok 4.9819 (6.7547)	Learning Rate [0.00125]
3: TRAIN [0][600/6832]	Time 0.111 (0.105)	Data 0.00089 (0.00096)	Tok/s 51985 (60822)	Loss/tok 4.8972 (6.7645)	Learning Rate [0.00125]
1: TRAIN [0][600/6832]	Time 0.111 (0.105)	Data 0.00094 (0.00095)	Tok/s 52000 (59922)	Loss/tok 4.8295 (6.7617)	Learning Rate [0.00125]
0: TRAIN [0][600/6832]	Time 0.111 (0.105)	Data 0.00099 (0.00095)	Tok/s 52021 (59451)	Loss/tok 4.9695 (6.7624)	Learning Rate [0.00125]
2: TRAIN [0][610/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00098)	Tok/s 52016 (60270)	Loss/tok 4.8260 (6.7273)	Learning Rate [0.00125]
1: TRAIN [0][610/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00095)	Tok/s 51957 (59879)	Loss/tok 4.8384 (6.7351)	Learning Rate [0.00125]
0: TRAIN [0][610/6832]	Time 0.113 (0.105)	Data 0.00098 (0.00095)	Tok/s 51427 (59412)	Loss/tok 4.9406 (6.7349)	Learning Rate [0.00125]
3: TRAIN [0][610/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00096)	Tok/s 52032 (60770)	Loss/tok 4.9587 (6.7377)	Learning Rate [0.00125]
2: TRAIN [0][620/6832]	Time 0.112 (0.105)	Data 0.00084 (0.00098)	Tok/s 52658 (60186)	Loss/tok 5.1023 (6.7028)	Learning Rate [0.00125]
1: TRAIN [0][620/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00095)	Tok/s 52417 (59786)	Loss/tok 4.7665 (6.7106)	Learning Rate [0.00125]
3: TRAIN [0][620/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00096)	Tok/s 53587 (60689)	Loss/tok 4.8961 (6.7134)	Learning Rate [0.00125]
0: TRAIN [0][620/6832]	Time 0.112 (0.105)	Data 0.00098 (0.00095)	Tok/s 52445 (59308)	Loss/tok 5.1185 (6.7110)	Learning Rate [0.00125]
2: TRAIN [0][630/6832]	Time 0.090 (0.105)	Data 0.00084 (0.00098)	Tok/s 54110 (60146)	Loss/tok 4.8374 (6.6767)	Learning Rate [0.00125]
1: TRAIN [0][630/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00095)	Tok/s 52871 (59745)	Loss/tok 4.7554 (6.6845)	Learning Rate [0.00125]
3: TRAIN [0][630/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00096)	Tok/s 54104 (60648)	Loss/tok 4.8439 (6.6881)	Learning Rate [0.00125]
0: TRAIN [0][630/6832]	Time 0.090 (0.105)	Data 0.00097 (0.00095)	Tok/s 52684 (59269)	Loss/tok 4.6532 (6.6860)	Learning Rate [0.00125]
2: TRAIN [0][640/6832]	Time 0.127 (0.105)	Data 0.00083 (0.00097)	Tok/s 65761 (60115)	Loss/tok 4.9572 (6.6502)	Learning Rate [0.00125]
0: TRAIN [0][640/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00095)	Tok/s 65373 (59236)	Loss/tok 4.9662 (6.6597)	Learning Rate [0.00125]
3: TRAIN [0][640/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00096)	Tok/s 65724 (60617)	Loss/tok 5.1173 (6.6616)	Learning Rate [0.00125]
1: TRAIN [0][640/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00095)	Tok/s 65812 (59716)	Loss/tok 5.1100 (6.6579)	Learning Rate [0.00125]
2: TRAIN [0][650/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00097)	Tok/s 54479 (60026)	Loss/tok 4.8021 (6.6269)	Learning Rate [0.00125]
1: TRAIN [0][650/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00095)	Tok/s 53704 (59630)	Loss/tok 4.9623 (6.6337)	Learning Rate [0.00125]
0: TRAIN [0][650/6832]	Time 0.119 (0.105)	Data 0.00102 (0.00095)	Tok/s 53694 (59152)	Loss/tok 4.7123 (6.6363)	Learning Rate [0.00125]
3: TRAIN [0][650/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00096)	Tok/s 54797 (60523)	Loss/tok 4.8001 (6.6381)	Learning Rate [0.00125]
2: TRAIN [0][660/6832]	Time 0.100 (0.105)	Data 0.00106 (0.00097)	Tok/s 51394 (60002)	Loss/tok 4.7821 (6.6013)	Learning Rate [0.00125]
0: TRAIN [0][660/6832]	Time 0.100 (0.105)	Data 0.00099 (0.00095)	Tok/s 51295 (59110)	Loss/tok 4.5444 (6.6094)	Learning Rate [0.00125]
1: TRAIN [0][660/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00095)	Tok/s 51282 (59605)	Loss/tok 4.8339 (6.6081)	Learning Rate [0.00125]
3: TRAIN [0][660/6832]	Time 0.100 (0.105)	Data 0.00105 (0.00096)	Tok/s 52315 (60504)	Loss/tok 4.6861 (6.6121)	Learning Rate [0.00125]
2: TRAIN [0][670/6832]	Time 0.067 (0.105)	Data 0.00089 (0.00097)	Tok/s 51931 (59971)	Loss/tok 4.3737 (6.5760)	Learning Rate [0.00125]
1: TRAIN [0][670/6832]	Time 0.067 (0.105)	Data 0.00093 (0.00095)	Tok/s 51892 (59574)	Loss/tok 4.2815 (6.5829)	Learning Rate [0.00125]
3: TRAIN [0][670/6832]	Time 0.067 (0.105)	Data 0.00090 (0.00096)	Tok/s 53715 (60470)	Loss/tok 4.4148 (6.5864)	Learning Rate [0.00125]
0: TRAIN [0][670/6832]	Time 0.067 (0.105)	Data 0.00099 (0.00095)	Tok/s 51850 (59081)	Loss/tok 4.2416 (6.5834)	Learning Rate [0.00125]
1: TRAIN [0][680/6832]	Time 0.075 (0.105)	Data 0.00091 (0.00095)	Tok/s 53201 (59598)	Loss/tok 4.3782 (6.5570)	Learning Rate [0.00125]
2: TRAIN [0][680/6832]	Time 0.075 (0.105)	Data 0.00083 (0.00097)	Tok/s 53189 (59995)	Loss/tok 4.5381 (6.5487)	Learning Rate [0.00125]
0: TRAIN [0][680/6832]	Time 0.075 (0.105)	Data 0.00100 (0.00095)	Tok/s 53256 (59108)	Loss/tok 4.5804 (6.5567)	Learning Rate [0.00125]
3: TRAIN [0][680/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00096)	Tok/s 53200 (60494)	Loss/tok 4.6047 (6.5609)	Learning Rate [0.00125]
2: TRAIN [0][690/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00097)	Tok/s 54302 (59997)	Loss/tok 4.8974 (6.5230)	Learning Rate [0.00125]
3: TRAIN [0][690/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00096)	Tok/s 54345 (60493)	Loss/tok 4.9796 (6.5350)	Learning Rate [0.00125]
1: TRAIN [0][690/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00095)	Tok/s 54230 (59603)	Loss/tok 4.7523 (6.5316)	Learning Rate [0.00125]
0: TRAIN [0][690/6832]	Time 0.118 (0.105)	Data 0.00104 (0.00095)	Tok/s 53458 (59115)	Loss/tok 4.9008 (6.5300)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
3: Gradient norm: inf
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
2: TRAIN [0][700/6832]	Time 0.100 (0.104)	Data 0.00097 (0.00097)	Tok/s 52324 (59986)	Loss/tok 4.7621 (6.4995)	Learning Rate [0.00125]
1: TRAIN [0][700/6832]	Time 0.100 (0.104)	Data 0.00090 (0.00095)	Tok/s 52264 (59591)	Loss/tok 4.6871 (6.5085)	Learning Rate [0.00125]
0: TRAIN [0][700/6832]	Time 0.100 (0.104)	Data 0.00101 (0.00096)	Tok/s 52225 (59106)	Loss/tok 4.7108 (6.5065)	Learning Rate [0.00125]
3: TRAIN [0][700/6832]	Time 0.100 (0.104)	Data 0.00090 (0.00096)	Tok/s 52600 (60483)	Loss/tok 4.7997 (6.5119)	Learning Rate [0.00125]
1: TRAIN [0][710/6832]	Time 0.114 (0.104)	Data 0.00097 (0.00095)	Tok/s 59303 (59584)	Loss/tok 5.0094 (6.4838)	Learning Rate [0.00125]
2: TRAIN [0][710/6832]	Time 0.114 (0.104)	Data 0.00098 (0.00097)	Tok/s 60132 (59976)	Loss/tok 4.8219 (6.4745)	Learning Rate [0.00125]
0: TRAIN [0][710/6832]	Time 0.114 (0.104)	Data 0.00108 (0.00096)	Tok/s 59290 (59103)	Loss/tok 4.9131 (6.4811)	Learning Rate [0.00125]
3: TRAIN [0][710/6832]	Time 0.114 (0.104)	Data 0.00105 (0.00096)	Tok/s 60454 (60470)	Loss/tok 4.7747 (6.4871)	Learning Rate [0.00125]
2: TRAIN [0][720/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00097)	Tok/s 54922 (60026)	Loss/tok 4.7550 (6.4466)	Learning Rate [0.00125]
1: TRAIN [0][720/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00095)	Tok/s 54144 (59633)	Loss/tok 4.8013 (6.4561)	Learning Rate [0.00125]
3: TRAIN [0][720/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00096)	Tok/s 54940 (60516)	Loss/tok 4.6082 (6.4595)	Learning Rate [0.00125]
0: TRAIN [0][720/6832]	Time 0.119 (0.105)	Data 0.00103 (0.00096)	Tok/s 53723 (59157)	Loss/tok 4.5966 (6.4540)	Learning Rate [0.00125]
2: TRAIN [0][730/6832]	Time 0.071 (0.105)	Data 0.00085 (0.00097)	Tok/s 52227 (60065)	Loss/tok 4.3127 (6.4208)	Learning Rate [0.00125]
1: TRAIN [0][730/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00095)	Tok/s 52195 (59675)	Loss/tok 4.4140 (6.4305)	Learning Rate [0.00125]
3: TRAIN [0][730/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00096)	Tok/s 52241 (60552)	Loss/tok 4.3145 (6.4326)	Learning Rate [0.00125]
0: TRAIN [0][730/6832]	Time 0.071 (0.105)	Data 0.00102 (0.00096)	Tok/s 51598 (59203)	Loss/tok 4.3717 (6.4282)	Learning Rate [0.00125]
2: TRAIN [0][740/6832]	Time 0.044 (0.105)	Data 0.00086 (0.00097)	Tok/s 38011 (60061)	Loss/tok 2.3743 (6.3956)	Learning Rate [0.00125]
1: TRAIN [0][740/6832]	Time 0.044 (0.105)	Data 0.00089 (0.00095)	Tok/s 32544 (59667)	Loss/tok 2.9443 (6.4057)	Learning Rate [0.00125]
0: TRAIN [0][740/6832]	Time 0.043 (0.105)	Data 0.00101 (0.00096)	Tok/s 21156 (59185)	Loss/tok 2.0970 (6.4042)	Learning Rate [0.00125]
3: TRAIN [0][740/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00096)	Tok/s 41072 (60553)	Loss/tok 3.0055 (6.4081)	Learning Rate [0.00125]
1: TRAIN [0][750/6832]	Time 0.070 (0.105)	Data 0.00095 (0.00095)	Tok/s 52826 (59668)	Loss/tok 4.1779 (6.3820)	Learning Rate [0.00125]
0: TRAIN [0][750/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00096)	Tok/s 52850 (59191)	Loss/tok 4.4698 (6.3799)	Learning Rate [0.00125]
3: TRAIN [0][750/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00096)	Tok/s 52910 (60550)	Loss/tok 4.3110 (6.3840)	Learning Rate [0.00125]
2: TRAIN [0][750/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00097)	Tok/s 52857 (60060)	Loss/tok 4.2730 (6.3723)	Learning Rate [0.00125]
2: TRAIN [0][760/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00097)	Tok/s 69404 (60021)	Loss/tok 4.8296 (6.3521)	Learning Rate [0.00125]
1: TRAIN [0][760/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00095)	Tok/s 69361 (59622)	Loss/tok 4.8398 (6.3617)	Learning Rate [0.00125]
0: TRAIN [0][760/6832]	Time 0.129 (0.105)	Data 0.00108 (0.00096)	Tok/s 69381 (59127)	Loss/tok 4.9402 (6.3597)	Learning Rate [0.00125]
3: TRAIN [0][760/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00096)	Tok/s 69863 (60519)	Loss/tok 4.7440 (6.3637)	Learning Rate [0.00125]
2: TRAIN [0][770/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00097)	Tok/s 52087 (60001)	Loss/tok 4.4378 (6.3304)	Learning Rate [0.00125]
1: TRAIN [0][770/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00095)	Tok/s 52065 (59597)	Loss/tok 4.6876 (6.3404)	Learning Rate [0.00125]
3: TRAIN [0][770/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00096)	Tok/s 52480 (60502)	Loss/tok 4.7218 (6.3424)	Learning Rate [0.00125]
0: TRAIN [0][770/6832]	Time 0.113 (0.105)	Data 0.00098 (0.00096)	Tok/s 52090 (59104)	Loss/tok 4.6503 (6.3384)	Learning Rate [0.00125]
2: TRAIN [0][780/6832]	Time 0.128 (0.104)	Data 0.00086 (0.00097)	Tok/s 72060 (59957)	Loss/tok 4.8155 (6.3108)	Learning Rate [0.00125]
1: TRAIN [0][780/6832]	Time 0.128 (0.104)	Data 0.00093 (0.00095)	Tok/s 71137 (59551)	Loss/tok 4.8665 (6.3207)	Learning Rate [0.00125]
0: TRAIN [0][780/6832]	Time 0.128 (0.104)	Data 0.00102 (0.00096)	Tok/s 71164 (59061)	Loss/tok 4.8443 (6.3182)	Learning Rate [0.00125]
3: TRAIN [0][780/6832]	Time 0.128 (0.104)	Data 0.00090 (0.00096)	Tok/s 72161 (60457)	Loss/tok 4.8147 (6.3237)	Learning Rate [0.00125]
1: TRAIN [0][790/6832]	Time 0.079 (0.105)	Data 0.00096 (0.00095)	Tok/s 53494 (59567)	Loss/tok 4.3322 (6.2972)	Learning Rate [0.00125]
2: TRAIN [0][790/6832]	Time 0.079 (0.105)	Data 0.00101 (0.00097)	Tok/s 53687 (59970)	Loss/tok 4.3656 (6.2878)	Learning Rate [0.00125]
0: TRAIN [0][790/6832]	Time 0.079 (0.105)	Data 0.00114 (0.00096)	Tok/s 53538 (59078)	Loss/tok 4.4735 (6.2940)	Learning Rate [0.00125]
3: TRAIN [0][790/6832]	Time 0.079 (0.105)	Data 0.00098 (0.00096)	Tok/s 55126 (60467)	Loss/tok 4.1974 (6.3003)	Learning Rate [0.00125]
2: TRAIN [0][800/6832]	Time 0.113 (0.104)	Data 0.00098 (0.00097)	Tok/s 51968 (59891)	Loss/tok 4.2861 (6.2695)	Learning Rate [0.00125]
1: TRAIN [0][800/6832]	Time 0.113 (0.104)	Data 0.00097 (0.00095)	Tok/s 51988 (59491)	Loss/tok 4.4994 (6.2788)	Learning Rate [0.00125]
0: TRAIN [0][800/6832]	Time 0.113 (0.104)	Data 0.00105 (0.00096)	Tok/s 51993 (59003)	Loss/tok 4.5863 (6.2758)	Learning Rate [0.00125]
3: TRAIN [0][800/6832]	Time 0.113 (0.104)	Data 0.00103 (0.00096)	Tok/s 52968 (60385)	Loss/tok 4.7751 (6.2815)	Learning Rate [0.00125]
2: TRAIN [0][810/6832]	Time 0.091 (0.104)	Data 0.00091 (0.00097)	Tok/s 51979 (59908)	Loss/tok 4.5633 (6.2491)	Learning Rate [0.00125]
1: TRAIN [0][810/6832]	Time 0.091 (0.104)	Data 0.00107 (0.00095)	Tok/s 50695 (59509)	Loss/tok 4.2847 (6.2573)	Learning Rate [0.00125]
0: TRAIN [0][810/6832]	Time 0.091 (0.104)	Data 0.00107 (0.00096)	Tok/s 50716 (59022)	Loss/tok 4.4691 (6.2546)	Learning Rate [0.00125]
3: TRAIN [0][810/6832]	Time 0.091 (0.104)	Data 0.00098 (0.00096)	Tok/s 52134 (60402)	Loss/tok 4.3688 (6.2606)	Learning Rate [0.00125]
2: TRAIN [0][820/6832]	Time 0.131 (0.104)	Data 0.00089 (0.00097)	Tok/s 81963 (59878)	Loss/tok 4.6464 (6.2300)	Learning Rate [0.00125]
1: TRAIN [0][820/6832]	Time 0.131 (0.104)	Data 0.00090 (0.00095)	Tok/s 81928 (59480)	Loss/tok 4.7032 (6.2378)	Learning Rate [0.00125]
0: TRAIN [0][820/6832]	Time 0.131 (0.104)	Data 0.00098 (0.00096)	Tok/s 80993 (58996)	Loss/tok 4.5729 (6.2351)	Learning Rate [0.00125]
3: TRAIN [0][820/6832]	Time 0.132 (0.104)	Data 0.00091 (0.00096)	Tok/s 82455 (60370)	Loss/tok 4.7250 (6.2415)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: TRAIN [0][830/6832]	Time 0.083 (0.104)	Data 0.00089 (0.00095)	Tok/s 52680 (59449)	Loss/tok 4.3859 (6.2179)	Learning Rate [0.00125]
2: TRAIN [0][830/6832]	Time 0.083 (0.104)	Data 0.00086 (0.00097)	Tok/s 52649 (59843)	Loss/tok 4.4519 (6.2106)	Learning Rate [0.00125]
0: TRAIN [0][830/6832]	Time 0.083 (0.104)	Data 0.00100 (0.00096)	Tok/s 52678 (58966)	Loss/tok 4.2637 (6.2150)	Learning Rate [0.00125]
3: TRAIN [0][830/6832]	Time 0.083 (0.104)	Data 0.00090 (0.00096)	Tok/s 52657 (60332)	Loss/tok 4.2690 (6.2216)	Learning Rate [0.00125]
2: TRAIN [0][840/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00097)	Tok/s 73653 (59905)	Loss/tok 4.7426 (6.1883)	Learning Rate [0.00125]
1: TRAIN [0][840/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 73653 (59515)	Loss/tok 4.5974 (6.1944)	Learning Rate [0.00125]
0: TRAIN [0][840/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00096)	Tok/s 72813 (59036)	Loss/tok 4.6503 (6.1913)	Learning Rate [0.00125]
3: TRAIN [0][840/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 73664 (60394)	Loss/tok 4.5097 (6.1988)	Learning Rate [0.00125]
2: TRAIN [0][850/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00096)	Tok/s 59900 (59898)	Loss/tok 4.5573 (6.1691)	Learning Rate [0.00125]
3: TRAIN [0][850/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00096)	Tok/s 59915 (60393)	Loss/tok 4.5581 (6.1798)	Learning Rate [0.00125]
0: TRAIN [0][850/6832]	Time 0.113 (0.105)	Data 0.00100 (0.00096)	Tok/s 59454 (59029)	Loss/tok 4.5331 (6.1714)	Learning Rate [0.00125]
1: TRAIN [0][850/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00095)	Tok/s 59489 (59508)	Loss/tok 4.3729 (6.1758)	Learning Rate [0.00125]
2: TRAIN [0][860/6832]	Time 0.112 (0.104)	Data 0.00086 (0.00096)	Tok/s 53625 (59862)	Loss/tok 4.4890 (6.1512)	Learning Rate [0.00125]
1: TRAIN [0][860/6832]	Time 0.112 (0.104)	Data 0.00090 (0.00095)	Tok/s 53629 (59476)	Loss/tok 4.4313 (6.1580)	Learning Rate [0.00125]
0: TRAIN [0][860/6832]	Time 0.112 (0.104)	Data 0.00095 (0.00096)	Tok/s 53641 (59000)	Loss/tok 4.5329 (6.1530)	Learning Rate [0.00125]
3: TRAIN [0][860/6832]	Time 0.112 (0.104)	Data 0.00087 (0.00096)	Tok/s 53628 (60357)	Loss/tok 4.2733 (6.1619)	Learning Rate [0.00125]
2: TRAIN [0][870/6832]	Time 0.128 (0.104)	Data 0.00083 (0.00096)	Tok/s 66955 (59818)	Loss/tok 4.4894 (6.1343)	Learning Rate [0.00125]
3: TRAIN [0][870/6832]	Time 0.128 (0.104)	Data 0.00087 (0.00096)	Tok/s 66987 (60317)	Loss/tok 4.6236 (6.1449)	Learning Rate [0.00125]
1: TRAIN [0][870/6832]	Time 0.128 (0.104)	Data 0.00090 (0.00095)	Tok/s 66974 (59428)	Loss/tok 4.6914 (6.1408)	Learning Rate [0.00125]
0: TRAIN [0][870/6832]	Time 0.128 (0.104)	Data 0.00100 (0.00096)	Tok/s 66523 (58943)	Loss/tok 4.8231 (6.1367)	Learning Rate [0.00125]
1: Gradient norm: inf
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
1: TRAIN [0][880/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 76021 (59578)	Loss/tok 4.6294 (6.1155)	Learning Rate [0.00125]
0: TRAIN [0][880/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00096)	Tok/s 75173 (59093)	Loss/tok 4.7468 (6.1116)	Learning Rate [0.00125]
2: TRAIN [0][880/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00096)	Tok/s 76017 (59966)	Loss/tok 4.7405 (6.1098)	Learning Rate [0.00125]
3: TRAIN [0][880/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 76199 (60463)	Loss/tok 4.5884 (6.1199)	Learning Rate [0.00125]
1: TRAIN [0][890/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00095)	Tok/s 59784 (59589)	Loss/tok 4.3925 (6.0956)	Learning Rate [0.00125]
2: TRAIN [0][890/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00096)	Tok/s 60492 (59976)	Loss/tok 4.5945 (6.0903)	Learning Rate [0.00125]
0: TRAIN [0][890/6832]	Time 0.113 (0.105)	Data 0.00099 (0.00096)	Tok/s 59789 (59106)	Loss/tok 4.6740 (6.0922)	Learning Rate [0.00125]
3: TRAIN [0][890/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00096)	Tok/s 60906 (60470)	Loss/tok 4.6677 (6.1007)	Learning Rate [0.00125]
2: TRAIN [0][900/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00096)	Tok/s 64140 (60000)	Loss/tok 4.6569 (6.0702)	Learning Rate [0.00125]
1: TRAIN [0][900/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 63395 (59614)	Loss/tok 4.4815 (6.0754)	Learning Rate [0.00125]
0: TRAIN [0][900/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00096)	Tok/s 63077 (59134)	Loss/tok 4.6762 (6.0721)	Learning Rate [0.00125]
3: TRAIN [0][900/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 64132 (60494)	Loss/tok 4.6857 (6.0809)	Learning Rate [0.00125]
2: TRAIN [0][910/6832]	Time 0.115 (0.105)	Data 0.00100 (0.00096)	Tok/s 58810 (59979)	Loss/tok 4.4455 (6.0537)	Learning Rate [0.00125]
1: TRAIN [0][910/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00095)	Tok/s 58825 (59591)	Loss/tok 4.3970 (6.0583)	Learning Rate [0.00125]
3: TRAIN [0][910/6832]	Time 0.115 (0.105)	Data 0.00102 (0.00096)	Tok/s 58830 (60473)	Loss/tok 4.2474 (6.0641)	Learning Rate [0.00125]
0: TRAIN [0][910/6832]	Time 0.115 (0.105)	Data 0.00104 (0.00096)	Tok/s 58833 (59110)	Loss/tok 4.3094 (6.0552)	Learning Rate [0.00125]
2: TRAIN [0][920/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00096)	Tok/s 59464 (59981)	Loss/tok 4.4700 (6.0369)	Learning Rate [0.00125]
1: TRAIN [0][920/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00095)	Tok/s 59477 (59591)	Loss/tok 4.2919 (6.0411)	Learning Rate [0.00125]
3: TRAIN [0][920/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00096)	Tok/s 60273 (60478)	Loss/tok 4.4476 (6.0466)	Learning Rate [0.00125]
0: TRAIN [0][920/6832]	Time 0.116 (0.105)	Data 0.00102 (0.00096)	Tok/s 59434 (59113)	Loss/tok 4.3787 (6.0382)	Learning Rate [0.00125]
2: TRAIN [0][930/6832]	Time 0.123 (0.105)	Data 0.00094 (0.00096)	Tok/s 61242 (59980)	Loss/tok 4.7574 (6.0188)	Learning Rate [0.00125]
1: TRAIN [0][930/6832]	Time 0.123 (0.105)	Data 0.00093 (0.00095)	Tok/s 61213 (59592)	Loss/tok 4.6608 (6.0230)	Learning Rate [0.00125]
0: TRAIN [0][930/6832]	Time 0.123 (0.105)	Data 0.00105 (0.00096)	Tok/s 61212 (59118)	Loss/tok 4.3841 (6.0198)	Learning Rate [0.00125]
3: TRAIN [0][930/6832]	Time 0.123 (0.105)	Data 0.00098 (0.00096)	Tok/s 61267 (60474)	Loss/tok 4.5405 (6.0288)	Learning Rate [0.00125]
1: TRAIN [0][940/6832]	Time 0.081 (0.105)	Data 0.00091 (0.00094)	Tok/s 52331 (59580)	Loss/tok 4.0654 (6.0052)	Learning Rate [0.00125]
2: TRAIN [0][940/6832]	Time 0.081 (0.105)	Data 0.00094 (0.00096)	Tok/s 52631 (59965)	Loss/tok 3.9052 (6.0017)	Learning Rate [0.00125]
0: TRAIN [0][940/6832]	Time 0.081 (0.105)	Data 0.00102 (0.00096)	Tok/s 52331 (59110)	Loss/tok 4.1703 (6.0025)	Learning Rate [0.00125]
3: TRAIN [0][940/6832]	Time 0.081 (0.105)	Data 0.00099 (0.00096)	Tok/s 53902 (60458)	Loss/tok 4.1244 (6.0112)	Learning Rate [0.00125]
2: TRAIN [0][950/6832]	Time 0.043 (0.105)	Data 0.00088 (0.00096)	Tok/s 39685 (59922)	Loss/tok 2.4632 (5.9864)	Learning Rate [0.00125]
1: TRAIN [0][950/6832]	Time 0.043 (0.105)	Data 0.00089 (0.00094)	Tok/s 36000 (59536)	Loss/tok 2.6421 (5.9898)	Learning Rate [0.00125]
3: TRAIN [0][950/6832]	Time 0.043 (0.105)	Data 0.00094 (0.00096)	Tok/s 43979 (60416)	Loss/tok 3.0843 (5.9962)	Learning Rate [0.00125]
0: TRAIN [0][950/6832]	Time 0.043 (0.105)	Data 0.00100 (0.00096)	Tok/s 23601 (59055)	Loss/tok 2.1853 (5.9873)	Learning Rate [0.00125]
2: TRAIN [0][960/6832]	Time 0.066 (0.105)	Data 0.00092 (0.00096)	Tok/s 50573 (59981)	Loss/tok 3.8198 (5.9671)	Learning Rate [0.00125]
1: TRAIN [0][960/6832]	Time 0.066 (0.105)	Data 0.00096 (0.00094)	Tok/s 50362 (59594)	Loss/tok 3.8858 (5.9701)	Learning Rate [0.00125]
3: TRAIN [0][960/6832]	Time 0.066 (0.105)	Data 0.00099 (0.00096)	Tok/s 52291 (60477)	Loss/tok 3.8371 (5.9760)	Learning Rate [0.00125]
0: TRAIN [0][960/6832]	Time 0.066 (0.105)	Data 0.00105 (0.00096)	Tok/s 50327 (59115)	Loss/tok 3.8567 (5.9678)	Learning Rate [0.00125]
2: TRAIN [0][970/6832]	Time 0.075 (0.105)	Data 0.00086 (0.00096)	Tok/s 52613 (59944)	Loss/tok 4.2196 (5.9527)	Learning Rate [0.00125]
1: TRAIN [0][970/6832]	Time 0.075 (0.105)	Data 0.00094 (0.00094)	Tok/s 51521 (59557)	Loss/tok 4.2212 (5.9553)	Learning Rate [0.00125]
0: TRAIN [0][970/6832]	Time 0.075 (0.105)	Data 0.00104 (0.00096)	Tok/s 51520 (59081)	Loss/tok 3.9955 (5.9528)	Learning Rate [0.00125]
3: TRAIN [0][970/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00096)	Tok/s 53242 (60440)	Loss/tok 4.0380 (5.9616)	Learning Rate [0.00125]
2: TRAIN [0][980/6832]	Time 0.106 (0.105)	Data 0.00095 (0.00096)	Tok/s 53287 (60011)	Loss/tok 4.2688 (5.9334)	Learning Rate [0.00125]
1: TRAIN [0][980/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00094)	Tok/s 53105 (59625)	Loss/tok 4.4460 (5.9360)	Learning Rate [0.00125]
0: TRAIN [0][980/6832]	Time 0.106 (0.105)	Data 0.00096 (0.00096)	Tok/s 52016 (59151)	Loss/tok 4.2748 (5.9336)	Learning Rate [0.00125]
3: TRAIN [0][980/6832]	Time 0.106 (0.105)	Data 0.00097 (0.00096)	Tok/s 53283 (60503)	Loss/tok 4.2555 (5.9421)	Learning Rate [0.00125]
1: TRAIN [0][990/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00094)	Tok/s 57820 (59533)	Loss/tok 4.3696 (5.9229)	Learning Rate [0.00125]
2: TRAIN [0][990/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00096)	Tok/s 57764 (59924)	Loss/tok 4.3464 (5.9201)	Learning Rate [0.00125]
3: TRAIN [0][990/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00096)	Tok/s 57755 (60416)	Loss/tok 4.6074 (5.9296)	Learning Rate [0.00125]
0: TRAIN [0][990/6832]	Time 0.122 (0.105)	Data 0.00097 (0.00096)	Tok/s 57775 (59051)	Loss/tok 4.5561 (5.9212)	Learning Rate [0.00125]
1: TRAIN [0][1000/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00094)	Tok/s 51458 (59552)	Loss/tok 4.2071 (5.9058)	Learning Rate [0.00125]
2: TRAIN [0][1000/6832]	Time 0.087 (0.105)	Data 0.00120 (0.00096)	Tok/s 52120 (59941)	Loss/tok 4.1841 (5.9028)	Learning Rate [0.00125]
0: TRAIN [0][1000/6832]	Time 0.087 (0.105)	Data 0.00103 (0.00096)	Tok/s 51469 (59070)	Loss/tok 4.0930 (5.9049)	Learning Rate [0.00125]
3: TRAIN [0][1000/6832]	Time 0.087 (0.105)	Data 0.00119 (0.00097)	Tok/s 53099 (60433)	Loss/tok 4.1831 (5.9129)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
2: TRAIN [0][1010/6832]	Time 0.090 (0.105)	Data 0.00090 (0.00096)	Tok/s 54054 (59983)	Loss/tok 4.0663 (5.8852)	Learning Rate [0.00125]
1: TRAIN [0][1010/6832]	Time 0.090 (0.105)	Data 0.00092 (0.00094)	Tok/s 54054 (59594)	Loss/tok 4.2316 (5.8880)	Learning Rate [0.00125]
3: TRAIN [0][1010/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00097)	Tok/s 54078 (60473)	Loss/tok 4.0329 (5.8949)	Learning Rate [0.00125]
0: TRAIN [0][1010/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00096)	Tok/s 54053 (59114)	Loss/tok 4.1515 (5.8873)	Learning Rate [0.00125]
2: TRAIN [0][1020/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00096)	Tok/s 52824 (60041)	Loss/tok 3.9237 (5.8666)	Learning Rate [0.00125]
1: TRAIN [0][1020/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00094)	Tok/s 52745 (59653)	Loss/tok 3.8906 (5.8693)	Learning Rate [0.00125]
3: TRAIN [0][1020/6832]	Time 0.073 (0.105)	Data 0.00090 (0.00097)	Tok/s 52861 (60528)	Loss/tok 4.0006 (5.8764)	Learning Rate [0.00125]
0: TRAIN [0][1020/6832]	Time 0.073 (0.105)	Data 0.00097 (0.00096)	Tok/s 52729 (59174)	Loss/tok 3.7347 (5.8691)	Learning Rate [0.00125]
2: TRAIN [0][1030/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00096)	Tok/s 74348 (60032)	Loss/tok 4.5660 (5.8516)	Learning Rate [0.00125]
1: TRAIN [0][1030/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 74022 (59643)	Loss/tok 4.5053 (5.8539)	Learning Rate [0.00125]
3: TRAIN [0][1030/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00097)	Tok/s 74343 (60517)	Loss/tok 4.6492 (5.8617)	Learning Rate [0.00125]
0: TRAIN [0][1030/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00096)	Tok/s 73320 (59166)	Loss/tok 4.6595 (5.8539)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 1024.0
0: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
1: TRAIN [0][1040/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00094)	Tok/s 56542 (59661)	Loss/tok 4.4164 (5.8380)	Learning Rate [0.00125]
2: TRAIN [0][1040/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00096)	Tok/s 56557 (60050)	Loss/tok 4.3033 (5.8361)	Learning Rate [0.00125]
0: TRAIN [0][1040/6832]	Time 0.120 (0.105)	Data 0.00097 (0.00096)	Tok/s 55510 (59184)	Loss/tok 4.3199 (5.8381)	Learning Rate [0.00125]
3: TRAIN [0][1040/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00097)	Tok/s 56573 (60536)	Loss/tok 4.2033 (5.8463)	Learning Rate [0.00125]
1: TRAIN [0][1050/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00094)	Tok/s 52328 (59616)	Loss/tok 3.9515 (5.8252)	Learning Rate [0.00125]
2: TRAIN [0][1050/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00096)	Tok/s 52438 (60008)	Loss/tok 3.8629 (5.8235)	Learning Rate [0.00125]
0: TRAIN [0][1050/6832]	Time 0.071 (0.105)	Data 0.00098 (0.00096)	Tok/s 50612 (59131)	Loss/tok 3.9906 (5.8255)	Learning Rate [0.00125]
3: TRAIN [0][1050/6832]	Time 0.071 (0.105)	Data 0.00094 (0.00097)	Tok/s 52414 (60493)	Loss/tok 3.8806 (5.8334)	Learning Rate [0.00125]
2: TRAIN [0][1060/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00096)	Tok/s 60396 (60024)	Loss/tok 4.3754 (5.8088)	Learning Rate [0.00125]
3: TRAIN [0][1060/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00097)	Tok/s 60757 (60509)	Loss/tok 4.4580 (5.8181)	Learning Rate [0.00125]
1: TRAIN [0][1060/6832]	Time 0.115 (0.105)	Data 0.00096 (0.00094)	Tok/s 60329 (59633)	Loss/tok 4.2344 (5.8104)	Learning Rate [0.00125]
0: TRAIN [0][1060/6832]	Time 0.115 (0.105)	Data 0.00106 (0.00096)	Tok/s 60359 (59149)	Loss/tok 4.4413 (5.8103)	Learning Rate [0.00125]
2: TRAIN [0][1070/6832]	Time 0.069 (0.105)	Data 0.00085 (0.00096)	Tok/s 53554 (59978)	Loss/tok 3.9152 (5.7967)	Learning Rate [0.00125]
1: TRAIN [0][1070/6832]	Time 0.069 (0.105)	Data 0.00087 (0.00094)	Tok/s 53508 (59587)	Loss/tok 3.8010 (5.7982)	Learning Rate [0.00125]
0: TRAIN [0][1070/6832]	Time 0.069 (0.105)	Data 0.00095 (0.00096)	Tok/s 52518 (59104)	Loss/tok 3.8137 (5.7978)	Learning Rate [0.00125]
3: TRAIN [0][1070/6832]	Time 0.069 (0.105)	Data 0.00086 (0.00097)	Tok/s 53574 (60461)	Loss/tok 3.7430 (5.8063)	Learning Rate [0.00125]
2: TRAIN [0][1080/6832]	Time 0.068 (0.105)	Data 0.00095 (0.00096)	Tok/s 50886 (59912)	Loss/tok 3.8255 (5.7856)	Learning Rate [0.00125]
1: TRAIN [0][1080/6832]	Time 0.068 (0.105)	Data 0.00088 (0.00094)	Tok/s 50859 (59522)	Loss/tok 3.7528 (5.7865)	Learning Rate [0.00125]
0: TRAIN [0][1080/6832]	Time 0.068 (0.105)	Data 0.00095 (0.00096)	Tok/s 50877 (59041)	Loss/tok 3.8273 (5.7861)	Learning Rate [0.00125]
3: TRAIN [0][1080/6832]	Time 0.068 (0.105)	Data 0.00094 (0.00097)	Tok/s 52341 (60395)	Loss/tok 3.8586 (5.7943)	Learning Rate [0.00125]
2: TRAIN [0][1090/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00096)	Tok/s 52968 (59919)	Loss/tok 3.8312 (5.7711)	Learning Rate [0.00125]
1: TRAIN [0][1090/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00094)	Tok/s 52918 (59532)	Loss/tok 3.9103 (5.7720)	Learning Rate [0.00125]
3: TRAIN [0][1090/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00097)	Tok/s 52995 (60401)	Loss/tok 3.7176 (5.7800)	Learning Rate [0.00125]
0: TRAIN [0][1090/6832]	Time 0.070 (0.105)	Data 0.00095 (0.00096)	Tok/s 52915 (59053)	Loss/tok 3.9717 (5.7710)	Learning Rate [0.00125]
2: TRAIN [0][1100/6832]	Time 0.049 (0.105)	Data 0.00088 (0.00096)	Tok/s 44017 (59938)	Loss/tok 3.1926 (5.7570)	Learning Rate [0.00125]
1: TRAIN [0][1100/6832]	Time 0.049 (0.105)	Data 0.00092 (0.00094)	Tok/s 41723 (59548)	Loss/tok 3.1418 (5.7584)	Learning Rate [0.00125]
0: TRAIN [0][1100/6832]	Time 0.049 (0.105)	Data 0.00102 (0.00096)	Tok/s 39140 (59069)	Loss/tok 2.8907 (5.7567)	Learning Rate [0.00125]
3: TRAIN [0][1100/6832]	Time 0.049 (0.105)	Data 0.00094 (0.00097)	Tok/s 45113 (60418)	Loss/tok 3.1894 (5.7660)	Learning Rate [0.00125]
1: TRAIN [0][1110/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 70000 (59556)	Loss/tok 4.4610 (5.7439)	Learning Rate [0.00125]
2: TRAIN [0][1110/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 69949 (59943)	Loss/tok 4.3392 (5.7425)	Learning Rate [0.00125]
0: TRAIN [0][1110/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00096)	Tok/s 69994 (59079)	Loss/tok 4.3258 (5.7419)	Learning Rate [0.00125]
3: TRAIN [0][1110/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00097)	Tok/s 70458 (60422)	Loss/tok 4.5609 (5.7513)	Learning Rate [0.00125]
1: TRAIN [0][1120/6832]	Time 0.108 (0.105)	Data 0.00091 (0.00094)	Tok/s 53323 (59524)	Loss/tok 4.2727 (5.7317)	Learning Rate [0.00125]
2: TRAIN [0][1120/6832]	Time 0.108 (0.105)	Data 0.00095 (0.00096)	Tok/s 53308 (59909)	Loss/tok 4.2239 (5.7308)	Learning Rate [0.00125]
3: TRAIN [0][1120/6832]	Time 0.108 (0.105)	Data 0.00100 (0.00097)	Tok/s 53335 (60385)	Loss/tok 4.3851 (5.7390)	Learning Rate [0.00125]
0: TRAIN [0][1120/6832]	Time 0.108 (0.105)	Data 0.00101 (0.00096)	Tok/s 53302 (59048)	Loss/tok 4.3649 (5.7298)	Learning Rate [0.00125]
1: TRAIN [0][1130/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 59103 (59542)	Loss/tok 4.3631 (5.7174)	Learning Rate [0.00125]
2: TRAIN [0][1130/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00096)	Tok/s 59069 (59926)	Loss/tok 4.2744 (5.7167)	Learning Rate [0.00125]
0: TRAIN [0][1130/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00096)	Tok/s 59093 (59067)	Loss/tok 4.3388 (5.7158)	Learning Rate [0.00125]
3: TRAIN [0][1130/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00097)	Tok/s 59099 (60405)	Loss/tok 4.0718 (5.7248)	Learning Rate [0.00125]
1: TRAIN [0][1140/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00094)	Tok/s 53562 (59550)	Loss/tok 4.4446 (5.7043)	Learning Rate [0.00125]
2: TRAIN [0][1140/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00096)	Tok/s 54497 (59935)	Loss/tok 4.2941 (5.7034)	Learning Rate [0.00125]
3: TRAIN [0][1140/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00097)	Tok/s 54524 (60412)	Loss/tok 4.1508 (5.7113)	Learning Rate [0.00125]
0: TRAIN [0][1140/6832]	Time 0.106 (0.105)	Data 0.00095 (0.00096)	Tok/s 53242 (59076)	Loss/tok 3.9630 (5.7023)	Learning Rate [0.00125]
2: TRAIN [0][1150/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 70057 (59931)	Loss/tok 4.5020 (5.6909)	Learning Rate [0.00125]
1: TRAIN [0][1150/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 69875 (59545)	Loss/tok 4.2749 (5.6909)	Learning Rate [0.00125]
0: TRAIN [0][1150/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00096)	Tok/s 69849 (59075)	Loss/tok 4.3417 (5.6898)	Learning Rate [0.00125]
3: TRAIN [0][1150/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00097)	Tok/s 70912 (60408)	Loss/tok 4.3211 (5.6986)	Learning Rate [0.00125]
1: TRAIN [0][1160/6832]	Time 0.042 (0.105)	Data 0.00091 (0.00094)	Tok/s 34272 (59531)	Loss/tok 2.5714 (5.6789)	Learning Rate [0.00125]
0: TRAIN [0][1160/6832]	Time 0.042 (0.105)	Data 0.00104 (0.00096)	Tok/s 21873 (59053)	Loss/tok 2.3063 (5.6778)	Learning Rate [0.00125]
2: TRAIN [0][1160/6832]	Time 0.042 (0.105)	Data 0.00087 (0.00096)	Tok/s 39530 (59921)	Loss/tok 2.4610 (5.6780)	Learning Rate [0.00125]
3: TRAIN [0][1160/6832]	Time 0.042 (0.105)	Data 0.00093 (0.00097)	Tok/s 43096 (60400)	Loss/tok 2.9707 (5.6860)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
2: TRAIN [0][1170/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00096)	Tok/s 50656 (59900)	Loss/tok 4.3239 (5.6655)	Learning Rate [0.00125]
1: TRAIN [0][1170/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00094)	Tok/s 50622 (59511)	Loss/tok 4.1372 (5.6667)	Learning Rate [0.00125]
3: TRAIN [0][1170/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00097)	Tok/s 50896 (60380)	Loss/tok 4.1866 (5.6735)	Learning Rate [0.00125]
0: TRAIN [0][1170/6832]	Time 0.116 (0.105)	Data 0.00103 (0.00097)	Tok/s 50635 (59037)	Loss/tok 3.9942 (5.6653)	Learning Rate [0.00125]
2: TRAIN [0][1180/6832]	Time 0.107 (0.105)	Data 0.00096 (0.00096)	Tok/s 52796 (59903)	Loss/tok 4.0963 (5.6531)	Learning Rate [0.00125]
1: TRAIN [0][1180/6832]	Time 0.107 (0.105)	Data 0.00088 (0.00094)	Tok/s 51778 (59514)	Loss/tok 3.9811 (5.6541)	Learning Rate [0.00125]
0: TRAIN [0][1180/6832]	Time 0.107 (0.105)	Data 0.00099 (0.00097)	Tok/s 51492 (59042)	Loss/tok 4.1711 (5.6528)	Learning Rate [0.00125]
3: TRAIN [0][1180/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00097)	Tok/s 52793 (60380)	Loss/tok 4.3201 (5.6613)	Learning Rate [0.00125]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
2: TRAIN [0][1190/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 67538 (59905)	Loss/tok 4.4337 (5.6407)	Learning Rate [0.00125]
0: TRAIN [0][1190/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00097)	Tok/s 67170 (59045)	Loss/tok 4.3134 (5.6404)	Learning Rate [0.00125]
3: TRAIN [0][1190/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00097)	Tok/s 67559 (60379)	Loss/tok 4.3940 (5.6492)	Learning Rate [0.00125]
1: TRAIN [0][1190/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 67467 (59517)	Loss/tok 4.4638 (5.6417)	Learning Rate [0.00125]
2: TRAIN [0][1200/6832]	Time 0.123 (0.105)	Data 0.00084 (0.00096)	Tok/s 56344 (59906)	Loss/tok 4.4085 (5.6286)	Learning Rate [0.00125]
1: TRAIN [0][1200/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00094)	Tok/s 56348 (59518)	Loss/tok 4.1660 (5.6292)	Learning Rate [0.00125]
3: TRAIN [0][1200/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00097)	Tok/s 56328 (60380)	Loss/tok 4.3398 (5.6372)	Learning Rate [0.00125]
0: TRAIN [0][1200/6832]	Time 0.121 (0.105)	Data 0.00126 (0.00097)	Tok/s 57172 (59044)	Loss/tok 4.5893 (5.6286)	Learning Rate [0.00125]
2: TRAIN [0][1210/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00096)	Tok/s 69107 (59911)	Loss/tok 4.4362 (5.6168)	Learning Rate [0.00125]
1: TRAIN [0][1210/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 69004 (59526)	Loss/tok 4.4556 (5.6177)	Learning Rate [0.00125]
0: TRAIN [0][1210/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00097)	Tok/s 69039 (59054)	Loss/tok 4.2038 (5.6163)	Learning Rate [0.00125]
3: TRAIN [0][1210/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00097)	Tok/s 69835 (60386)	Loss/tok 4.3845 (5.6253)	Learning Rate [0.00125]
2: TRAIN [0][1220/6832]	Time 0.082 (0.105)	Data 0.00097 (0.00096)	Tok/s 51921 (59896)	Loss/tok 3.8346 (5.6054)	Learning Rate [0.00125]
1: TRAIN [0][1220/6832]	Time 0.082 (0.105)	Data 0.00096 (0.00094)	Tok/s 51410 (59510)	Loss/tok 4.0126 (5.6063)	Learning Rate [0.00125]
0: TRAIN [0][1220/6832]	Time 0.082 (0.105)	Data 0.00104 (0.00097)	Tok/s 51399 (59038)	Loss/tok 4.0488 (5.6055)	Learning Rate [0.00125]
3: TRAIN [0][1220/6832]	Time 0.082 (0.105)	Data 0.00096 (0.00097)	Tok/s 53001 (60370)	Loss/tok 3.9556 (5.6137)	Learning Rate [0.00125]
1: TRAIN [0][1230/6832]	Time 0.100 (0.105)	Data 0.00087 (0.00094)	Tok/s 53573 (59526)	Loss/tok 4.0202 (5.5938)	Learning Rate [0.00125]
3: TRAIN [0][1230/6832]	Time 0.100 (0.105)	Data 0.00087 (0.00097)	Tok/s 54210 (60383)	Loss/tok 4.1277 (5.6010)	Learning Rate [0.00125]
2: TRAIN [0][1230/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00096)	Tok/s 53559 (59911)	Loss/tok 4.0354 (5.5928)	Learning Rate [0.00125]
0: TRAIN [0][1230/6832]	Time 0.100 (0.105)	Data 0.00124 (0.00097)	Tok/s 53936 (59055)	Loss/tok 4.0839 (5.5933)	Learning Rate [0.00125]
1: TRAIN [0][1240/6832]	Time 0.109 (0.105)	Data 0.00099 (0.00094)	Tok/s 51491 (59526)	Loss/tok 4.1867 (5.5822)	Learning Rate [0.00125]
0: TRAIN [0][1240/6832]	Time 0.109 (0.105)	Data 0.00102 (0.00097)	Tok/s 51509 (59059)	Loss/tok 3.9843 (5.5817)	Learning Rate [0.00125]
2: TRAIN [0][1240/6832]	Time 0.110 (0.105)	Data 0.00101 (0.00096)	Tok/s 51413 (59911)	Loss/tok 4.1490 (5.5809)	Learning Rate [0.00125]
3: TRAIN [0][1240/6832]	Time 0.110 (0.105)	Data 0.00098 (0.00097)	Tok/s 51251 (60382)	Loss/tok 4.0450 (5.5891)	Learning Rate [0.00125]
1: TRAIN [0][1250/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00094)	Tok/s 50268 (59498)	Loss/tok 4.1349 (5.5715)	Learning Rate [0.00125]
2: TRAIN [0][1250/6832]	Time 0.122 (0.105)	Data 0.00096 (0.00096)	Tok/s 50228 (59881)	Loss/tok 4.2741 (5.5706)	Learning Rate [0.00125]
3: TRAIN [0][1250/6832]	Time 0.122 (0.105)	Data 0.00098 (0.00097)	Tok/s 50630 (60355)	Loss/tok 4.2073 (5.5788)	Learning Rate [0.00125]
0: TRAIN [0][1250/6832]	Time 0.122 (0.105)	Data 0.00102 (0.00097)	Tok/s 50269 (59033)	Loss/tok 4.2752 (5.5716)	Learning Rate [0.00125]
1: TRAIN [0][1260/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00094)	Tok/s 53164 (59505)	Loss/tok 3.8697 (5.5596)	Learning Rate [0.00125]
2: TRAIN [0][1260/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00096)	Tok/s 53192 (59885)	Loss/tok 3.9262 (5.5594)	Learning Rate [0.00125]
3: TRAIN [0][1260/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00097)	Tok/s 53193 (60357)	Loss/tok 4.0525 (5.5678)	Learning Rate [0.00125]
0: TRAIN [0][1260/6832]	Time 0.096 (0.105)	Data 0.00099 (0.00097)	Tok/s 51901 (59043)	Loss/tok 3.9485 (5.5595)	Learning Rate [0.00125]
1: TRAIN [0][1270/6832]	Time 0.080 (0.105)	Data 0.00098 (0.00094)	Tok/s 54613 (59519)	Loss/tok 3.7842 (5.5481)	Learning Rate [0.00125]
3: TRAIN [0][1270/6832]	Time 0.080 (0.105)	Data 0.00095 (0.00097)	Tok/s 54626 (60370)	Loss/tok 3.7906 (5.5562)	Learning Rate [0.00125]
2: TRAIN [0][1270/6832]	Time 0.080 (0.105)	Data 0.00097 (0.00096)	Tok/s 54619 (59898)	Loss/tok 3.8240 (5.5479)	Learning Rate [0.00125]
0: TRAIN [0][1270/6832]	Time 0.080 (0.105)	Data 0.00103 (0.00097)	Tok/s 54632 (59059)	Loss/tok 3.7161 (5.5480)	Learning Rate [0.00125]
1: TRAIN [0][1280/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00094)	Tok/s 50264 (59500)	Loss/tok 4.2081 (5.5376)	Learning Rate [0.00125]
2: TRAIN [0][1280/6832]	Time 0.111 (0.105)	Data 0.00103 (0.00096)	Tok/s 50708 (59878)	Loss/tok 4.1348 (5.5373)	Learning Rate [0.00125]
3: TRAIN [0][1280/6832]	Time 0.112 (0.105)	Data 0.00094 (0.00097)	Tok/s 50486 (60349)	Loss/tok 4.0505 (5.5457)	Learning Rate [0.00125]
0: TRAIN [0][1280/6832]	Time 0.112 (0.105)	Data 0.00095 (0.00097)	Tok/s 49357 (59041)	Loss/tok 4.1804 (5.5378)	Learning Rate [0.00125]
2: TRAIN [0][1290/6832]	Time 0.067 (0.105)	Data 0.00086 (0.00096)	Tok/s 52364 (59811)	Loss/tok 3.7440 (5.5293)	Learning Rate [0.00125]
3: TRAIN [0][1290/6832]	Time 0.067 (0.105)	Data 0.00086 (0.00097)	Tok/s 53630 (60284)	Loss/tok 3.6718 (5.5376)	Learning Rate [0.00125]
1: TRAIN [0][1290/6832]	Time 0.067 (0.105)	Data 0.00093 (0.00094)	Tok/s 51713 (59428)	Loss/tok 3.5238 (5.5296)	Learning Rate [0.00125]
0: TRAIN [0][1290/6832]	Time 0.067 (0.105)	Data 0.00095 (0.00097)	Tok/s 51696 (58962)	Loss/tok 3.7004 (5.5301)	Learning Rate [0.00125]
2: TRAIN [0][1300/6832]	Time 0.083 (0.105)	Data 0.00098 (0.00096)	Tok/s 54245 (59764)	Loss/tok 3.8688 (5.5204)	Learning Rate [0.00125]
3: TRAIN [0][1300/6832]	Time 0.083 (0.105)	Data 0.00095 (0.00097)	Tok/s 54219 (60235)	Loss/tok 3.9689 (5.5290)	Learning Rate [0.00125]
1: TRAIN [0][1300/6832]	Time 0.083 (0.105)	Data 0.00091 (0.00094)	Tok/s 54168 (59383)	Loss/tok 4.0494 (5.5207)	Learning Rate [0.00125]
0: TRAIN [0][1300/6832]	Time 0.083 (0.105)	Data 0.00099 (0.00097)	Tok/s 54120 (58917)	Loss/tok 4.0164 (5.5215)	Learning Rate [0.00125]
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
1: TRAIN [0][1310/6832]	Time 0.130 (0.105)	Data 0.00104 (0.00094)	Tok/s 64154 (59383)	Loss/tok 4.0969 (5.5093)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
0: TRAIN [0][1310/6832]	Time 0.130 (0.105)	Data 0.00109 (0.00097)	Tok/s 64157 (58911)	Loss/tok 4.2190 (5.5106)	Learning Rate [0.00125]
3: TRAIN [0][1310/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00097)	Tok/s 64042 (60241)	Loss/tok 4.1732 (5.5182)	Learning Rate [0.00125]
2: TRAIN [0][1310/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00096)	Tok/s 64027 (59768)	Loss/tok 4.3750 (5.5098)	Learning Rate [0.00125]
2: TRAIN [0][1320/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00096)	Tok/s 65762 (59792)	Loss/tok 4.1234 (5.4978)	Learning Rate [0.00125]
1: TRAIN [0][1320/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00094)	Tok/s 65749 (59405)	Loss/tok 4.4895 (5.4985)	Learning Rate [0.00125]
3: TRAIN [0][1320/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00096)	Tok/s 66641 (60263)	Loss/tok 4.2584 (5.5071)	Learning Rate [0.00125]
0: TRAIN [0][1320/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00097)	Tok/s 65792 (58934)	Loss/tok 4.1595 (5.4992)	Learning Rate [0.00125]
1: TRAIN [0][1330/6832]	Time 0.127 (0.105)	Data 0.00104 (0.00094)	Tok/s 59371 (59424)	Loss/tok 4.0933 (5.4878)	Learning Rate [0.00125]
3: TRAIN [0][1330/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00096)	Tok/s 59356 (60278)	Loss/tok 4.2340 (5.4960)	Learning Rate [0.00125]
2: TRAIN [0][1330/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00096)	Tok/s 59303 (59808)	Loss/tok 4.1600 (5.4859)	Learning Rate [0.00125]
0: TRAIN [0][1330/6832]	Time 0.127 (0.105)	Data 0.00108 (0.00097)	Tok/s 58808 (58954)	Loss/tok 4.0782 (5.4880)	Learning Rate [0.00125]
1: TRAIN [0][1340/6832]	Time 0.103 (0.105)	Data 0.00087 (0.00094)	Tok/s 52188 (59430)	Loss/tok 4.1115 (5.4777)	Learning Rate [0.00125]
2: TRAIN [0][1340/6832]	Time 0.103 (0.105)	Data 0.00095 (0.00096)	Tok/s 52593 (59814)	Loss/tok 4.0690 (5.4755)	Learning Rate [0.00125]
3: TRAIN [0][1340/6832]	Time 0.103 (0.105)	Data 0.00096 (0.00096)	Tok/s 53420 (60284)	Loss/tok 4.0617 (5.4859)	Learning Rate [0.00125]
0: TRAIN [0][1340/6832]	Time 0.103 (0.105)	Data 0.00106 (0.00097)	Tok/s 52146 (58961)	Loss/tok 3.9259 (5.4779)	Learning Rate [0.00125]
1: TRAIN [0][1350/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 83491 (59464)	Loss/tok 4.1405 (5.4664)	Learning Rate [0.00125]
2: TRAIN [0][1350/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 83879 (59848)	Loss/tok 4.1630 (5.4646)	Learning Rate [0.00125]
3: TRAIN [0][1350/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 84513 (60316)	Loss/tok 4.2872 (5.4747)	Learning Rate [0.00125]
0: TRAIN [0][1350/6832]	Time 0.132 (0.105)	Data 0.00108 (0.00097)	Tok/s 82875 (58995)	Loss/tok 4.1954 (5.4668)	Learning Rate [0.00125]
1: TRAIN [0][1360/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00094)	Tok/s 53237 (59441)	Loss/tok 3.7320 (5.4568)	Learning Rate [0.00125]
2: TRAIN [0][1360/6832]	Time 0.089 (0.105)	Data 0.00099 (0.00096)	Tok/s 53245 (59824)	Loss/tok 3.7831 (5.4549)	Learning Rate [0.00125]
3: TRAIN [0][1360/6832]	Time 0.089 (0.105)	Data 0.00098 (0.00096)	Tok/s 53252 (60290)	Loss/tok 3.8877 (5.4652)	Learning Rate [0.00125]
0: TRAIN [0][1360/6832]	Time 0.089 (0.105)	Data 0.00099 (0.00097)	Tok/s 53254 (58974)	Loss/tok 4.0071 (5.4576)	Learning Rate [0.00125]
1: TRAIN [0][1370/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 69318 (59436)	Loss/tok 4.4383 (5.4471)	Learning Rate [0.00125]
2: TRAIN [0][1370/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00096)	Tok/s 69256 (59818)	Loss/tok 4.3233 (5.4451)	Learning Rate [0.00125]
3: TRAIN [0][1370/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00096)	Tok/s 69529 (60282)	Loss/tok 4.1201 (5.4557)	Learning Rate [0.00125]
0: TRAIN [0][1370/6832]	Time 0.127 (0.105)	Data 0.00104 (0.00097)	Tok/s 69065 (58970)	Loss/tok 4.1171 (5.4480)	Learning Rate [0.00125]
1: TRAIN [0][1380/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 55067 (59448)	Loss/tok 4.0468 (5.4366)	Learning Rate [0.00125]
3: TRAIN [0][1380/6832]	Time 0.119 (0.105)	Data 0.00101 (0.00096)	Tok/s 55261 (60295)	Loss/tok 4.2062 (5.4454)	Learning Rate [0.00125]
2: TRAIN [0][1380/6832]	Time 0.118 (0.105)	Data 0.00116 (0.00096)	Tok/s 55114 (59830)	Loss/tok 4.1100 (5.4352)	Learning Rate [0.00125]
0: TRAIN [0][1380/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00097)	Tok/s 55040 (58982)	Loss/tok 4.1708 (5.4381)	Learning Rate [0.00125]
2: TRAIN [0][1390/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00096)	Tok/s 53747 (59817)	Loss/tok 3.8732 (5.4260)	Learning Rate [0.00125]
1: TRAIN [0][1390/6832]	Time 0.085 (0.105)	Data 0.00085 (0.00094)	Tok/s 52609 (59435)	Loss/tok 3.9501 (5.4274)	Learning Rate [0.00125]
3: TRAIN [0][1390/6832]	Time 0.085 (0.105)	Data 0.00089 (0.00096)	Tok/s 54127 (60281)	Loss/tok 3.7350 (5.4358)	Learning Rate [0.00125]
0: TRAIN [0][1390/6832]	Time 0.086 (0.105)	Data 0.00099 (0.00097)	Tok/s 51870 (58971)	Loss/tok 4.0001 (5.4291)	Learning Rate [0.00125]
2: TRAIN [0][1400/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00096)	Tok/s 52450 (59825)	Loss/tok 3.9957 (5.4165)	Learning Rate [0.00125]
3: TRAIN [0][1400/6832]	Time 0.100 (0.105)	Data 0.00087 (0.00096)	Tok/s 52408 (60287)	Loss/tok 4.0545 (5.4261)	Learning Rate [0.00125]
1: TRAIN [0][1400/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00094)	Tok/s 52319 (59445)	Loss/tok 4.0554 (5.4172)	Learning Rate [0.00125]
0: TRAIN [0][1400/6832]	Time 0.100 (0.105)	Data 0.00100 (0.00097)	Tok/s 52322 (58984)	Loss/tok 3.8063 (5.4189)	Learning Rate [0.00125]
1: TRAIN [0][1410/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00094)	Tok/s 52115 (59436)	Loss/tok 3.9003 (5.4083)	Learning Rate [0.00125]
3: TRAIN [0][1410/6832]	Time 0.083 (0.105)	Data 0.00091 (0.00096)	Tok/s 52177 (60277)	Loss/tok 3.9047 (5.4170)	Learning Rate [0.00125]
2: TRAIN [0][1410/6832]	Time 0.083 (0.105)	Data 0.00122 (0.00096)	Tok/s 52212 (59814)	Loss/tok 3.8279 (5.4071)	Learning Rate [0.00125]
0: TRAIN [0][1410/6832]	Time 0.084 (0.105)	Data 0.00102 (0.00097)	Tok/s 52102 (58978)	Loss/tok 3.7809 (5.4099)	Learning Rate [0.00125]
1: TRAIN [0][1420/6832]	Time 0.085 (0.105)	Data 0.00086 (0.00094)	Tok/s 52887 (59437)	Loss/tok 3.9562 (5.3986)	Learning Rate [0.00125]
2: TRAIN [0][1420/6832]	Time 0.085 (0.105)	Data 0.00096 (0.00096)	Tok/s 52892 (59814)	Loss/tok 3.8765 (5.3971)	Learning Rate [0.00125]
3: TRAIN [0][1420/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00096)	Tok/s 52891 (60276)	Loss/tok 3.7124 (5.4070)	Learning Rate [0.00125]
0: TRAIN [0][1420/6832]	Time 0.085 (0.105)	Data 0.00102 (0.00097)	Tok/s 52876 (58980)	Loss/tok 3.6325 (5.4001)	Learning Rate [0.00125]
1: TRAIN [0][1430/6832]	Time 0.081 (0.105)	Data 0.00088 (0.00093)	Tok/s 51314 (59389)	Loss/tok 3.8604 (5.3910)	Learning Rate [0.00125]
2: TRAIN [0][1430/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00096)	Tok/s 51924 (59767)	Loss/tok 3.9562 (5.3897)	Learning Rate [0.00125]
3: TRAIN [0][1430/6832]	Time 0.081 (0.105)	Data 0.00087 (0.00096)	Tok/s 51909 (60227)	Loss/tok 3.7781 (5.3994)	Learning Rate [0.00125]
0: TRAIN [0][1430/6832]	Time 0.082 (0.105)	Data 0.00103 (0.00097)	Tok/s 50236 (58932)	Loss/tok 3.6972 (5.3924)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
1: TRAIN [0][1440/6832]	Time 0.076 (0.105)	Data 0.00086 (0.00093)	Tok/s 54042 (59390)	Loss/tok 3.8275 (5.3819)	Learning Rate [0.00125]
2: TRAIN [0][1440/6832]	Time 0.076 (0.105)	Data 0.00090 (0.00096)	Tok/s 54103 (59768)	Loss/tok 3.6230 (5.3806)	Learning Rate [0.00125]
3: TRAIN [0][1440/6832]	Time 0.076 (0.105)	Data 0.00089 (0.00096)	Tok/s 54143 (60227)	Loss/tok 3.7980 (5.3904)	Learning Rate [0.00125]
0: TRAIN [0][1440/6832]	Time 0.076 (0.105)	Data 0.00099 (0.00097)	Tok/s 54037 (58934)	Loss/tok 3.9200 (5.3834)	Learning Rate [0.00125]
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
0: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
1: TRAIN [0][1450/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00093)	Tok/s 81427 (59419)	Loss/tok 4.0489 (5.3717)	Learning Rate [0.00125]
0: TRAIN [0][1450/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00097)	Tok/s 81381 (58962)	Loss/tok 4.1462 (5.3735)	Learning Rate [0.00125]
2: TRAIN [0][1450/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00096)	Tok/s 81934 (59796)	Loss/tok 4.1181 (5.3710)	Learning Rate [0.00125]
3: TRAIN [0][1450/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00096)	Tok/s 82363 (60256)	Loss/tok 4.0350 (5.3805)	Learning Rate [0.00125]
1: TRAIN [0][1460/6832]	Time 0.098 (0.105)	Data 0.00090 (0.00093)	Tok/s 53745 (59385)	Loss/tok 3.8071 (5.3646)	Learning Rate [0.00125]
2: TRAIN [0][1460/6832]	Time 0.098 (0.105)	Data 0.00098 (0.00096)	Tok/s 53747 (59760)	Loss/tok 4.0248 (5.3635)	Learning Rate [0.00125]
3: TRAIN [0][1460/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00096)	Tok/s 53761 (60221)	Loss/tok 4.0781 (5.3726)	Learning Rate [0.00125]
0: TRAIN [0][1460/6832]	Time 0.098 (0.105)	Data 0.00105 (0.00097)	Tok/s 53742 (58930)	Loss/tok 3.8867 (5.3657)	Learning Rate [0.00125]
1: TRAIN [0][1470/6832]	Time 0.096 (0.105)	Data 0.00087 (0.00093)	Tok/s 56257 (59362)	Loss/tok 3.8548 (5.3567)	Learning Rate [0.00125]
2: TRAIN [0][1470/6832]	Time 0.096 (0.105)	Data 0.00087 (0.00096)	Tok/s 57578 (59736)	Loss/tok 3.9724 (5.3554)	Learning Rate [0.00125]
3: TRAIN [0][1470/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00096)	Tok/s 57610 (60196)	Loss/tok 4.0849 (5.3645)	Learning Rate [0.00125]
0: TRAIN [0][1470/6832]	Time 0.096 (0.105)	Data 0.00097 (0.00097)	Tok/s 56201 (58909)	Loss/tok 3.9853 (5.3579)	Learning Rate [0.00125]
3: TRAIN [0][1480/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00096)	Tok/s 65530 (60231)	Loss/tok 4.0726 (5.3539)	Learning Rate [0.00125]
1: TRAIN [0][1480/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 65519 (59397)	Loss/tok 4.2053 (5.3467)	Learning Rate [0.00125]
0: TRAIN [0][1480/6832]	Time 0.129 (0.105)	Data 0.00106 (0.00097)	Tok/s 64848 (58945)	Loss/tok 4.3560 (5.3478)	Learning Rate [0.00125]
2: TRAIN [0][1480/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 65144 (59770)	Loss/tok 4.2736 (5.3449)	Learning Rate [0.00125]
1: TRAIN [0][1490/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 66801 (59423)	Loss/tok 4.4087 (5.3372)	Learning Rate [0.00125]
2: TRAIN [0][1490/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00096)	Tok/s 66804 (59796)	Loss/tok 4.0026 (5.3352)	Learning Rate [0.00125]
3: TRAIN [0][1490/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 66785 (60255)	Loss/tok 4.3310 (5.3444)	Learning Rate [0.00125]
0: TRAIN [0][1490/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00097)	Tok/s 65856 (58971)	Loss/tok 4.2829 (5.3381)	Learning Rate [0.00125]
2: TRAIN [0][1500/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00096)	Tok/s 55284 (59759)	Loss/tok 4.1922 (5.3279)	Learning Rate [0.00125]
1: TRAIN [0][1500/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00093)	Tok/s 55258 (59383)	Loss/tok 4.0337 (5.3297)	Learning Rate [0.00125]
3: TRAIN [0][1500/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00096)	Tok/s 55878 (60221)	Loss/tok 4.0832 (5.3365)	Learning Rate [0.00125]
0: TRAIN [0][1500/6832]	Time 0.113 (0.105)	Data 0.00099 (0.00097)	Tok/s 55261 (58925)	Loss/tok 3.9680 (5.3308)	Learning Rate [0.00125]
3: TRAIN [0][1510/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00096)	Tok/s 66880 (60261)	Loss/tok 4.1668 (5.3262)	Learning Rate [0.00125]
2: TRAIN [0][1510/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00096)	Tok/s 66525 (59799)	Loss/tok 4.0841 (5.3175)	Learning Rate [0.00125]
1: TRAIN [0][1510/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 66445 (59423)	Loss/tok 4.2790 (5.3196)	Learning Rate [0.00125]
0: TRAIN [0][1510/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00097)	Tok/s 66452 (58965)	Loss/tok 4.2300 (5.3207)	Learning Rate [0.00125]
1: TRAIN [0][1520/6832]	Time 0.091 (0.105)	Data 0.00113 (0.00093)	Tok/s 54741 (59437)	Loss/tok 3.8296 (5.3105)	Learning Rate [0.00125]
2: TRAIN [0][1520/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00096)	Tok/s 54725 (59813)	Loss/tok 3.8146 (5.3084)	Learning Rate [0.00125]
3: TRAIN [0][1520/6832]	Time 0.091 (0.105)	Data 0.00097 (0.00096)	Tok/s 54724 (60275)	Loss/tok 3.8936 (5.3169)	Learning Rate [0.00125]
0: TRAIN [0][1520/6832]	Time 0.091 (0.105)	Data 0.00101 (0.00097)	Tok/s 54828 (58981)	Loss/tok 3.9283 (5.3115)	Learning Rate [0.00125]
1: TRAIN [0][1530/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00093)	Tok/s 54807 (59440)	Loss/tok 3.9741 (5.3022)	Learning Rate [0.00125]
2: TRAIN [0][1530/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00096)	Tok/s 54806 (59816)	Loss/tok 4.0989 (5.2997)	Learning Rate [0.00125]
3: TRAIN [0][1530/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00096)	Tok/s 54981 (60277)	Loss/tok 3.9042 (5.3083)	Learning Rate [0.00125]
0: TRAIN [0][1530/6832]	Time 0.091 (0.105)	Data 0.00100 (0.00097)	Tok/s 54719 (58986)	Loss/tok 3.8788 (5.3031)	Learning Rate [0.00125]
1: TRAIN [0][1540/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00093)	Tok/s 51413 (59427)	Loss/tok 3.9528 (5.2943)	Learning Rate [0.00125]
3: TRAIN [0][1540/6832]	Time 0.075 (0.105)	Data 0.00101 (0.00096)	Tok/s 53137 (60264)	Loss/tok 3.5892 (5.3005)	Learning Rate [0.00125]
2: TRAIN [0][1540/6832]	Time 0.075 (0.105)	Data 0.00100 (0.00096)	Tok/s 52338 (59802)	Loss/tok 3.7233 (5.2919)	Learning Rate [0.00125]
0: TRAIN [0][1540/6832]	Time 0.075 (0.105)	Data 0.00100 (0.00097)	Tok/s 51423 (58974)	Loss/tok 3.7514 (5.2951)	Learning Rate [0.00125]
2: TRAIN [0][1550/6832]	Time 0.109 (0.105)	Data 0.00096 (0.00096)	Tok/s 54082 (59815)	Loss/tok 3.9534 (5.2831)	Learning Rate [0.00125]
3: TRAIN [0][1550/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00096)	Tok/s 54075 (60277)	Loss/tok 4.0538 (5.2920)	Learning Rate [0.00125]
1: TRAIN [0][1550/6832]	Time 0.109 (0.105)	Data 0.00085 (0.00093)	Tok/s 54019 (59441)	Loss/tok 4.1836 (5.2857)	Learning Rate [0.00125]
0: TRAIN [0][1550/6832]	Time 0.109 (0.105)	Data 0.00100 (0.00097)	Tok/s 53216 (58989)	Loss/tok 4.0895 (5.2865)	Learning Rate [0.00125]
1: TRAIN [0][1560/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00093)	Tok/s 58883 (59450)	Loss/tok 4.0733 (5.2772)	Learning Rate [0.00125]
2: TRAIN [0][1560/6832]	Time 0.120 (0.105)	Data 0.00102 (0.00096)	Tok/s 59212 (59822)	Loss/tok 4.0901 (5.2744)	Learning Rate [0.00125]
3: TRAIN [0][1560/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00096)	Tok/s 59970 (60284)	Loss/tok 4.3310 (5.2834)	Learning Rate [0.00125]
0: TRAIN [0][1560/6832]	Time 0.119 (0.105)	Data 0.00105 (0.00097)	Tok/s 58267 (58998)	Loss/tok 4.3106 (5.2783)	Learning Rate [0.00125]
2: TRAIN [0][1570/6832]	Time 0.131 (0.105)	Data 0.00107 (0.00096)	Tok/s 80651 (59827)	Loss/tok 4.1200 (5.2663)	Learning Rate [0.00125]
3: TRAIN [0][1570/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00096)	Tok/s 81385 (60287)	Loss/tok 3.9551 (5.2750)	Learning Rate [0.00125]
1: TRAIN [0][1570/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00093)	Tok/s 80494 (59456)	Loss/tok 4.2353 (5.2691)	Learning Rate [0.00125]
0: TRAIN [0][1570/6832]	Time 0.130 (0.105)	Data 0.00106 (0.00098)	Tok/s 79862 (59004)	Loss/tok 4.1196 (5.2703)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
0: TRAIN [0][1580/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00098)	Tok/s 86050 (59017)	Loss/tok 3.9841 (5.2624)	Learning Rate [0.00125]
2: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
1: TRAIN [0][1580/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 86001 (59467)	Loss/tok 4.0648 (5.2610)	Learning Rate [0.00125]
2: TRAIN [0][1580/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 86555 (59837)	Loss/tok 3.9641 (5.2583)	Learning Rate [0.00125]
3: TRAIN [0][1580/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00096)	Tok/s 87033 (60296)	Loss/tok 4.0268 (5.2667)	Learning Rate [0.00125]
1: TRAIN [0][1590/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00093)	Tok/s 60568 (59508)	Loss/tok 4.2948 (5.2523)	Learning Rate [0.00125]
2: TRAIN [0][1590/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00096)	Tok/s 61430 (59878)	Loss/tok 4.1673 (5.2492)	Learning Rate [0.00125]
0: TRAIN [0][1590/6832]	Time 0.126 (0.105)	Data 0.00108 (0.00098)	Tok/s 60837 (59057)	Loss/tok 4.1621 (5.2533)	Learning Rate [0.00125]
3: TRAIN [0][1590/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00096)	Tok/s 61480 (60335)	Loss/tok 4.0332 (5.2571)	Learning Rate [0.00125]
1: TRAIN [0][1600/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00093)	Tok/s 53314 (59504)	Loss/tok 3.9270 (5.2449)	Learning Rate [0.00125]
2: TRAIN [0][1600/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00096)	Tok/s 53331 (59872)	Loss/tok 4.0217 (5.2413)	Learning Rate [0.00125]
3: TRAIN [0][1600/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00096)	Tok/s 54267 (60330)	Loss/tok 4.0218 (5.2490)	Learning Rate [0.00125]
0: TRAIN [0][1600/6832]	Time 0.096 (0.105)	Data 0.00096 (0.00098)	Tok/s 53283 (59056)	Loss/tok 3.9389 (5.2454)	Learning Rate [0.00125]
2: TRAIN [0][1610/6832]	Time 0.102 (0.105)	Data 0.00090 (0.00096)	Tok/s 52575 (59862)	Loss/tok 3.8708 (5.2343)	Learning Rate [0.00125]
1: TRAIN [0][1610/6832]	Time 0.102 (0.105)	Data 0.00089 (0.00093)	Tok/s 52536 (59494)	Loss/tok 3.8318 (5.2375)	Learning Rate [0.00125]
0: TRAIN [0][1610/6832]	Time 0.102 (0.105)	Data 0.00093 (0.00097)	Tok/s 52531 (59048)	Loss/tok 3.7558 (5.2378)	Learning Rate [0.00125]
3: TRAIN [0][1610/6832]	Time 0.102 (0.105)	Data 0.00093 (0.00096)	Tok/s 52597 (60319)	Loss/tok 3.9094 (5.2413)	Learning Rate [0.00125]
1: TRAIN [0][1620/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00093)	Tok/s 69967 (59505)	Loss/tok 4.2210 (5.2298)	Learning Rate [0.00125]
0: TRAIN [0][1620/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00097)	Tok/s 69969 (59061)	Loss/tok 4.2767 (5.2301)	Learning Rate [0.00125]
2: TRAIN [0][1620/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 70794 (59873)	Loss/tok 4.0517 (5.2263)	Learning Rate [0.00125]
3: TRAIN [0][1620/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 70909 (60328)	Loss/tok 4.1532 (5.2333)	Learning Rate [0.00125]
1: TRAIN [0][1630/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00093)	Tok/s 58044 (59498)	Loss/tok 4.1500 (5.2226)	Learning Rate [0.00125]
2: TRAIN [0][1630/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00096)	Tok/s 58497 (59864)	Loss/tok 4.0294 (5.2186)	Learning Rate [0.00125]
3: TRAIN [0][1630/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00096)	Tok/s 58528 (60319)	Loss/tok 4.0989 (5.2258)	Learning Rate [0.00125]
0: TRAIN [0][1630/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00097)	Tok/s 57434 (59056)	Loss/tok 4.2024 (5.2224)	Learning Rate [0.00125]
1: TRAIN [0][1640/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00093)	Tok/s 68905 (59482)	Loss/tok 4.1099 (5.2161)	Learning Rate [0.00125]
0: TRAIN [0][1640/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00097)	Tok/s 68893 (59040)	Loss/tok 4.1448 (5.2159)	Learning Rate [0.00125]
3: TRAIN [0][1640/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00096)	Tok/s 69871 (60302)	Loss/tok 4.0458 (5.2190)	Learning Rate [0.00125]
2: TRAIN [0][1640/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 69093 (59848)	Loss/tok 4.0309 (5.2118)	Learning Rate [0.00125]
1: TRAIN [0][1650/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00093)	Tok/s 51026 (59480)	Loss/tok 4.0197 (5.2084)	Learning Rate [0.00125]
2: TRAIN [0][1650/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00096)	Tok/s 51034 (59847)	Loss/tok 3.9842 (5.2042)	Learning Rate [0.00125]
3: TRAIN [0][1650/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00096)	Tok/s 51080 (60301)	Loss/tok 3.9592 (5.2113)	Learning Rate [0.00125]
0: TRAIN [0][1650/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00097)	Tok/s 51005 (59039)	Loss/tok 4.2796 (5.2086)	Learning Rate [0.00125]
1: TRAIN [0][1660/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00093)	Tok/s 53287 (59503)	Loss/tok 3.7971 (5.1999)	Learning Rate [0.00125]
2: TRAIN [0][1660/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00096)	Tok/s 53295 (59870)	Loss/tok 3.7798 (5.1958)	Learning Rate [0.00125]
0: TRAIN [0][1660/6832]	Time 0.101 (0.105)	Data 0.00097 (0.00097)	Tok/s 52771 (59063)	Loss/tok 4.0340 (5.2005)	Learning Rate [0.00125]
3: TRAIN [0][1660/6832]	Time 0.101 (0.105)	Data 0.00096 (0.00096)	Tok/s 53294 (60325)	Loss/tok 3.7825 (5.2031)	Learning Rate [0.00125]
2: TRAIN [0][1670/6832]	Time 0.069 (0.105)	Data 0.00092 (0.00096)	Tok/s 48962 (59861)	Loss/tok 3.6588 (5.1893)	Learning Rate [0.00125]
1: TRAIN [0][1670/6832]	Time 0.069 (0.105)	Data 0.00091 (0.00093)	Tok/s 48073 (59492)	Loss/tok 3.5222 (5.1934)	Learning Rate [0.00125]
3: TRAIN [0][1670/6832]	Time 0.069 (0.105)	Data 0.00095 (0.00096)	Tok/s 49945 (60314)	Loss/tok 3.5781 (5.1963)	Learning Rate [0.00125]
0: TRAIN [0][1670/6832]	Time 0.069 (0.105)	Data 0.00101 (0.00097)	Tok/s 48021 (59053)	Loss/tok 3.5412 (5.1937)	Learning Rate [0.00125]
2: TRAIN [0][1680/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 82322 (59844)	Loss/tok 4.1721 (5.1824)	Learning Rate [0.00125]
1: TRAIN [0][1680/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00093)	Tok/s 82124 (59475)	Loss/tok 4.1728 (5.1865)	Learning Rate [0.00125]
0: TRAIN [0][1680/6832]	Time 0.131 (0.105)	Data 0.00116 (0.00097)	Tok/s 81590 (59036)	Loss/tok 4.0703 (5.1866)	Learning Rate [0.00125]
3: TRAIN [0][1680/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00096)	Tok/s 83157 (60297)	Loss/tok 4.0938 (5.1893)	Learning Rate [0.00125]
1: TRAIN [0][1690/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00093)	Tok/s 58998 (59470)	Loss/tok 4.2392 (5.1795)	Learning Rate [0.00125]
0: TRAIN [0][1690/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00097)	Tok/s 57912 (59032)	Loss/tok 4.0503 (5.1796)	Learning Rate [0.00125]
2: TRAIN [0][1690/6832]	Time 0.117 (0.105)	Data 0.00102 (0.00096)	Tok/s 58988 (59840)	Loss/tok 4.1608 (5.1754)	Learning Rate [0.00125]
3: TRAIN [0][1690/6832]	Time 0.117 (0.105)	Data 0.00100 (0.00096)	Tok/s 58993 (60293)	Loss/tok 3.9963 (5.1821)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
1: Skipped batch, new scale: 1024.0
2: Skipped batch, new scale: 1024.0
3: Skipped batch, new scale: 1024.0
1: TRAIN [0][1700/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00093)	Tok/s 72301 (59471)	Loss/tok 4.1638 (5.1726)	Learning Rate [0.00125]
0: TRAIN [0][1700/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00097)	Tok/s 71701 (59032)	Loss/tok 4.1049 (5.1723)	Learning Rate [0.00125]
2: TRAIN [0][1700/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 72227 (59839)	Loss/tok 4.0410 (5.1681)	Learning Rate [0.00125]
3: TRAIN [0][1700/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 72524 (60293)	Loss/tok 4.0687 (5.1747)	Learning Rate [0.00125]
2: TRAIN [0][1710/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00096)	Tok/s 51642 (59829)	Loss/tok 3.8665 (5.1611)	Learning Rate [0.00125]
0: TRAIN [0][1710/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00097)	Tok/s 51593 (59022)	Loss/tok 3.9399 (5.1655)	Learning Rate [0.00125]
3: TRAIN [0][1710/6832]	Time 0.119 (0.105)	Data 0.00214 (0.00096)	Tok/s 52715 (60283)	Loss/tok 3.9181 (5.1679)	Learning Rate [0.00125]
1: TRAIN [0][1710/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00093)	Tok/s 51603 (59461)	Loss/tok 3.8477 (5.1659)	Learning Rate [0.00125]
1: TRAIN [0][1720/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00093)	Tok/s 61200 (59472)	Loss/tok 4.1641 (5.1587)	Learning Rate [0.00125]
2: TRAIN [0][1720/6832]	Time 0.125 (0.105)	Data 0.00105 (0.00096)	Tok/s 61238 (59840)	Loss/tok 4.2496 (5.1538)	Learning Rate [0.00125]
0: TRAIN [0][1720/6832]	Time 0.125 (0.105)	Data 0.00098 (0.00097)	Tok/s 60273 (59033)	Loss/tok 4.1667 (5.1584)	Learning Rate [0.00125]
3: TRAIN [0][1720/6832]	Time 0.125 (0.105)	Data 0.00099 (0.00096)	Tok/s 61234 (60293)	Loss/tok 3.9602 (5.1608)	Learning Rate [0.00125]
2: TRAIN [0][1730/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 84030 (59853)	Loss/tok 4.0612 (5.1466)	Learning Rate [0.00125]
0: TRAIN [0][1730/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00097)	Tok/s 82914 (59048)	Loss/tok 4.1131 (5.1511)	Learning Rate [0.00125]
1: TRAIN [0][1730/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00093)	Tok/s 83821 (59485)	Loss/tok 3.9729 (5.1514)	Learning Rate [0.00125]
3: TRAIN [0][1730/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 84854 (60305)	Loss/tok 4.0480 (5.1535)	Learning Rate [0.00125]
1: TRAIN [0][1740/6832]	Time 0.104 (0.105)	Data 0.00095 (0.00093)	Tok/s 54174 (59452)	Loss/tok 3.9899 (5.1455)	Learning Rate [0.00125]
2: TRAIN [0][1740/6832]	Time 0.104 (0.105)	Data 0.00095 (0.00096)	Tok/s 54155 (59822)	Loss/tok 3.9313 (5.1408)	Learning Rate [0.00125]
0: TRAIN [0][1740/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00097)	Tok/s 54149 (59016)	Loss/tok 3.7734 (5.1451)	Learning Rate [0.00125]
3: TRAIN [0][1740/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00096)	Tok/s 55122 (60275)	Loss/tok 3.9678 (5.1477)	Learning Rate [0.00125]
1: TRAIN [0][1750/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 85612 (59476)	Loss/tok 4.0715 (5.1383)	Learning Rate [0.00125]
0: TRAIN [0][1750/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00097)	Tok/s 85441 (59041)	Loss/tok 4.0193 (5.1376)	Learning Rate [0.00125]
2: TRAIN [0][1750/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00096)	Tok/s 86382 (59845)	Loss/tok 3.9518 (5.1334)	Learning Rate [0.00125]
3: TRAIN [0][1750/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 86855 (60298)	Loss/tok 4.0137 (5.1398)	Learning Rate [0.00125]
2: TRAIN [0][1760/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00096)	Tok/s 88601 (59873)	Loss/tok 3.9316 (5.1260)	Learning Rate [0.00125]
0: TRAIN [0][1760/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00097)	Tok/s 87050 (59071)	Loss/tok 3.9513 (5.1300)	Learning Rate [0.00125]
1: TRAIN [0][1760/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00093)	Tok/s 87996 (59505)	Loss/tok 3.9302 (5.1310)	Learning Rate [0.00125]
3: TRAIN [0][1760/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 89412 (60326)	Loss/tok 3.8251 (5.1325)	Learning Rate [0.00125]
1: TRAIN [0][1770/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00093)	Tok/s 74749 (59482)	Loss/tok 4.0285 (5.1253)	Learning Rate [0.00125]
0: TRAIN [0][1770/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00097)	Tok/s 74346 (59047)	Loss/tok 4.1059 (5.1241)	Learning Rate [0.00125]
2: TRAIN [0][1770/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00096)	Tok/s 74718 (59849)	Loss/tok 4.0882 (5.1203)	Learning Rate [0.00125]
3: TRAIN [0][1770/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 75517 (60302)	Loss/tok 4.1037 (5.1268)	Learning Rate [0.00125]
1: TRAIN [0][1780/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00093)	Tok/s 60779 (59487)	Loss/tok 4.0755 (5.1189)	Learning Rate [0.00125]
2: TRAIN [0][1780/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00096)	Tok/s 61794 (59852)	Loss/tok 4.0322 (5.1139)	Learning Rate [0.00125]
3: TRAIN [0][1780/6832]	Time 0.116 (0.105)	Data 0.00098 (0.00096)	Tok/s 61856 (60304)	Loss/tok 4.2582 (5.1200)	Learning Rate [0.00125]
0: TRAIN [0][1780/6832]	Time 0.116 (0.105)	Data 0.00101 (0.00097)	Tok/s 60768 (59052)	Loss/tok 3.8868 (5.1173)	Learning Rate [0.00125]
2: TRAIN [0][1790/6832]	Time 0.066 (0.105)	Data 0.00088 (0.00096)	Tok/s 52286 (59872)	Loss/tok 3.3238 (5.1066)	Learning Rate [0.00125]
1: TRAIN [0][1790/6832]	Time 0.066 (0.105)	Data 0.00090 (0.00093)	Tok/s 52116 (59506)	Loss/tok 3.4963 (5.1118)	Learning Rate [0.00125]
3: TRAIN [0][1790/6832]	Time 0.066 (0.105)	Data 0.00091 (0.00096)	Tok/s 52389 (60322)	Loss/tok 3.5514 (5.1130)	Learning Rate [0.00125]
0: TRAIN [0][1790/6832]	Time 0.066 (0.105)	Data 0.00088 (0.00097)	Tok/s 52095 (59071)	Loss/tok 3.5765 (5.1103)	Learning Rate [0.00125]
2: TRAIN [0][1800/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00096)	Tok/s 65292 (59878)	Loss/tok 4.1321 (5.0997)	Learning Rate [0.00125]
1: TRAIN [0][1800/6832]	Time 0.127 (0.105)	Data 0.00103 (0.00093)	Tok/s 65287 (59512)	Loss/tok 4.1844 (5.1049)	Learning Rate [0.00125]
0: TRAIN [0][1800/6832]	Time 0.127 (0.105)	Data 0.00106 (0.00097)	Tok/s 65316 (59078)	Loss/tok 3.8456 (5.1035)	Learning Rate [0.00125]
3: TRAIN [0][1800/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00096)	Tok/s 65301 (60329)	Loss/tok 4.0850 (5.1060)	Learning Rate [0.00125]
1: TRAIN [0][1810/6832]	Time 0.092 (0.105)	Data 0.00095 (0.00093)	Tok/s 54463 (59500)	Loss/tok 3.6459 (5.0988)	Learning Rate [0.00125]
2: TRAIN [0][1810/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00096)	Tok/s 54434 (59865)	Loss/tok 3.6987 (5.0936)	Learning Rate [0.00125]
0: TRAIN [0][1810/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00097)	Tok/s 54468 (59067)	Loss/tok 4.1571 (5.0977)	Learning Rate [0.00125]
3: TRAIN [0][1810/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00096)	Tok/s 54444 (60315)	Loss/tok 3.7924 (5.0998)	Learning Rate [0.00125]
2: TRAIN [0][1820/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00096)	Tok/s 69245 (59858)	Loss/tok 3.9684 (5.0874)	Learning Rate [0.00125]
1: TRAIN [0][1820/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00093)	Tok/s 69262 (59494)	Loss/tok 4.0789 (5.0925)	Learning Rate [0.00125]
0: TRAIN [0][1820/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00097)	Tok/s 69000 (59062)	Loss/tok 4.0131 (5.0915)	Learning Rate [0.00125]
3: TRAIN [0][1820/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 69280 (60307)	Loss/tok 4.0542 (5.0936)	Learning Rate [0.00125]
2: Upscaling, new scale: 2048.0
1: Upscaling, new scale: 2048.0
0: Upscaling, new scale: 2048.0
3: Upscaling, new scale: 2048.0
1: TRAIN [0][1830/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00093)	Tok/s 61083 (59486)	Loss/tok 3.9565 (5.0862)	Learning Rate [0.00125]
2: TRAIN [0][1830/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00096)	Tok/s 61702 (59851)	Loss/tok 4.2095 (5.0815)	Learning Rate [0.00125]
0: TRAIN [0][1830/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00097)	Tok/s 61084 (59054)	Loss/tok 3.9322 (5.0855)	Learning Rate [0.00125]
3: TRAIN [0][1830/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00096)	Tok/s 62184 (60299)	Loss/tok 4.0518 (5.0876)	Learning Rate [0.00125]
1: TRAIN [0][1840/6832]	Time 0.085 (0.105)	Data 0.00098 (0.00093)	Tok/s 54255 (59491)	Loss/tok 3.6607 (5.0799)	Learning Rate [0.00125]
0: TRAIN [0][1840/6832]	Time 0.085 (0.105)	Data 0.00094 (0.00097)	Tok/s 54262 (59060)	Loss/tok 3.6870 (5.0792)	Learning Rate [0.00125]
2: TRAIN [0][1840/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00096)	Tok/s 54199 (59855)	Loss/tok 3.8026 (5.0752)	Learning Rate [0.00125]
3: TRAIN [0][1840/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00096)	Tok/s 54825 (60303)	Loss/tok 3.7349 (5.0813)	Learning Rate [0.00125]
1: TRAIN [0][1850/6832]	Time 0.116 (0.105)	Data 0.00098 (0.00093)	Tok/s 52825 (59481)	Loss/tok 3.9604 (5.0741)	Learning Rate [0.00125]
2: TRAIN [0][1850/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00096)	Tok/s 52838 (59844)	Loss/tok 4.0411 (5.0694)	Learning Rate [0.00125]
0: TRAIN [0][1850/6832]	Time 0.116 (0.105)	Data 0.00101 (0.00097)	Tok/s 51744 (59050)	Loss/tok 4.0362 (5.0731)	Learning Rate [0.00125]
3: TRAIN [0][1850/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00096)	Tok/s 52851 (60291)	Loss/tok 3.9284 (5.0752)	Learning Rate [0.00125]
2: TRAIN [0][1860/6832]	Time 0.096 (0.105)	Data 0.00095 (0.00096)	Tok/s 55937 (59833)	Loss/tok 3.9438 (5.0636)	Learning Rate [0.00125]
1: TRAIN [0][1860/6832]	Time 0.096 (0.105)	Data 0.00095 (0.00093)	Tok/s 54742 (59469)	Loss/tok 3.9799 (5.0683)	Learning Rate [0.00125]
0: TRAIN [0][1860/6832]	Time 0.096 (0.105)	Data 0.00101 (0.00097)	Tok/s 54608 (59039)	Loss/tok 3.9054 (5.0674)	Learning Rate [0.00125]
3: TRAIN [0][1860/6832]	Time 0.096 (0.105)	Data 0.00098 (0.00096)	Tok/s 55944 (60278)	Loss/tok 3.6785 (5.0696)	Learning Rate [0.00125]
1: TRAIN [0][1870/6832]	Time 0.048 (0.105)	Data 0.00089 (0.00093)	Tok/s 43562 (59510)	Loss/tok 2.9673 (5.0616)	Learning Rate [0.00125]
2: TRAIN [0][1870/6832]	Time 0.048 (0.105)	Data 0.00094 (0.00096)	Tok/s 45774 (59874)	Loss/tok 2.6610 (5.0562)	Learning Rate [0.00125]
0: TRAIN [0][1870/6832]	Time 0.048 (0.105)	Data 0.00088 (0.00097)	Tok/s 40849 (59080)	Loss/tok 2.4360 (5.0599)	Learning Rate [0.00125]
3: TRAIN [0][1870/6832]	Time 0.048 (0.105)	Data 0.00094 (0.00096)	Tok/s 48371 (60321)	Loss/tok 2.9711 (5.0624)	Learning Rate [0.00125]
2: TRAIN [0][1880/6832]	Time 0.056 (0.105)	Data 0.00095 (0.00096)	Tok/s 53225 (59836)	Loss/tok 3.3152 (5.0510)	Learning Rate [0.00125]
1: TRAIN [0][1880/6832]	Time 0.056 (0.105)	Data 0.00097 (0.00093)	Tok/s 52244 (59469)	Loss/tok 3.2418 (5.0566)	Learning Rate [0.00125]
0: TRAIN [0][1880/6832]	Time 0.056 (0.105)	Data 0.00094 (0.00097)	Tok/s 52262 (59035)	Loss/tok 3.2459 (5.0547)	Learning Rate [0.00125]
3: TRAIN [0][1880/6832]	Time 0.056 (0.105)	Data 0.00100 (0.00096)	Tok/s 54536 (60284)	Loss/tok 3.3908 (5.0572)	Learning Rate [0.00125]
0: TRAIN [0][1890/6832]	Time 0.066 (0.105)	Data 0.00092 (0.00097)	Tok/s 50752 (59047)	Loss/tok 3.3895 (5.0484)	Learning Rate [0.00125]
1: TRAIN [0][1890/6832]	Time 0.066 (0.105)	Data 0.00095 (0.00093)	Tok/s 50737 (59479)	Loss/tok 3.5197 (5.0500)	Learning Rate [0.00125]
2: TRAIN [0][1890/6832]	Time 0.066 (0.105)	Data 0.00099 (0.00096)	Tok/s 50720 (59847)	Loss/tok 3.5067 (5.0446)	Learning Rate [0.00125]
3: TRAIN [0][1890/6832]	Time 0.066 (0.105)	Data 0.00093 (0.00096)	Tok/s 52664 (60295)	Loss/tok 3.6338 (5.0506)	Learning Rate [0.00125]
2: TRAIN [0][1900/6832]	Time 0.062 (0.105)	Data 0.00086 (0.00096)	Tok/s 51222 (59847)	Loss/tok 3.7178 (5.0387)	Learning Rate [0.00125]
1: TRAIN [0][1900/6832]	Time 0.062 (0.105)	Data 0.00087 (0.00093)	Tok/s 51209 (59481)	Loss/tok 3.5054 (5.0440)	Learning Rate [0.00125]
0: TRAIN [0][1900/6832]	Time 0.062 (0.105)	Data 0.00087 (0.00097)	Tok/s 51236 (59048)	Loss/tok 3.3900 (5.0423)	Learning Rate [0.00125]
3: TRAIN [0][1900/6832]	Time 0.063 (0.105)	Data 0.00092 (0.00096)	Tok/s 52942 (60296)	Loss/tok 3.3442 (5.0451)	Learning Rate [0.00125]
2: TRAIN [0][1910/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00096)	Tok/s 52522 (59834)	Loss/tok 3.4526 (5.0330)	Learning Rate [0.00125]
1: TRAIN [0][1910/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00093)	Tok/s 52475 (59467)	Loss/tok 3.6164 (5.0384)	Learning Rate [0.00125]
3: TRAIN [0][1910/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00096)	Tok/s 52521 (60283)	Loss/tok 3.5347 (5.0399)	Learning Rate [0.00125]
0: TRAIN [0][1910/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00096)	Tok/s 52379 (59035)	Loss/tok 3.5787 (5.0367)	Learning Rate [0.00125]
1: TRAIN [0][1920/6832]	Time 0.101 (0.105)	Data 0.00088 (0.00093)	Tok/s 52155 (59453)	Loss/tok 3.6972 (5.0329)	Learning Rate [0.00125]
2: TRAIN [0][1920/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00096)	Tok/s 53012 (59819)	Loss/tok 4.0590 (5.0275)	Learning Rate [0.00125]
3: TRAIN [0][1920/6832]	Time 0.101 (0.105)	Data 0.00093 (0.00096)	Tok/s 53476 (60267)	Loss/tok 3.8312 (5.0343)	Learning Rate [0.00125]
0: TRAIN [0][1920/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00096)	Tok/s 52167 (59021)	Loss/tok 3.8988 (5.0309)	Learning Rate [0.00125]
1: TRAIN [0][1930/6832]	Time 0.055 (0.105)	Data 0.00092 (0.00093)	Tok/s 51656 (59470)	Loss/tok 3.1750 (5.0264)	Learning Rate [0.00125]
0: TRAIN [0][1930/6832]	Time 0.055 (0.105)	Data 0.00090 (0.00096)	Tok/s 50625 (59038)	Loss/tok 3.2948 (5.0245)	Learning Rate [0.00125]
2: TRAIN [0][1930/6832]	Time 0.055 (0.105)	Data 0.00092 (0.00096)	Tok/s 51426 (59837)	Loss/tok 3.0101 (5.0211)	Learning Rate [0.00125]
3: TRAIN [0][1930/6832]	Time 0.055 (0.105)	Data 0.00092 (0.00096)	Tok/s 52178 (60284)	Loss/tok 3.2786 (5.0282)	Learning Rate [0.00125]
1: TRAIN [0][1940/6832]	Time 0.089 (0.105)	Data 0.00103 (0.00093)	Tok/s 53476 (59486)	Loss/tok 3.7787 (5.0202)	Learning Rate [0.00125]
2: TRAIN [0][1940/6832]	Time 0.089 (0.105)	Data 0.00105 (0.00096)	Tok/s 53461 (59852)	Loss/tok 3.8763 (5.0149)	Learning Rate [0.00125]
0: TRAIN [0][1940/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00096)	Tok/s 52607 (59053)	Loss/tok 3.6036 (5.0183)	Learning Rate [0.00125]
3: TRAIN [0][1940/6832]	Time 0.089 (0.105)	Data 0.00110 (0.00096)	Tok/s 53456 (60298)	Loss/tok 3.7936 (5.0220)	Learning Rate [0.00125]
1: TRAIN [0][1950/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00093)	Tok/s 58522 (59452)	Loss/tok 4.1093 (5.0152)	Learning Rate [0.00125]
2: TRAIN [0][1950/6832]	Time 0.120 (0.105)	Data 0.00102 (0.00096)	Tok/s 58500 (59820)	Loss/tok 4.1258 (5.0101)	Learning Rate [0.00125]
0: TRAIN [0][1950/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00096)	Tok/s 57662 (59015)	Loss/tok 4.1395 (5.0135)	Learning Rate [0.00125]
3: TRAIN [0][1950/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00096)	Tok/s 58517 (60268)	Loss/tok 3.9546 (5.0168)	Learning Rate [0.00125]
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
1: TRAIN [0][1960/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00093)	Tok/s 61016 (59421)	Loss/tok 4.1343 (5.0101)	Learning Rate [0.00125]
0: TRAIN [0][1960/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00096)	Tok/s 61008 (58979)	Loss/tok 4.1984 (5.0088)	Learning Rate [0.00125]
2: TRAIN [0][1960/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00096)	Tok/s 60975 (59789)	Loss/tok 4.0484 (5.0050)	Learning Rate [0.00125]
3: TRAIN [0][1960/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00096)	Tok/s 60961 (60238)	Loss/tok 4.0370 (5.0117)	Learning Rate [0.00125]
2: TRAIN [0][1970/6832]	Time 0.122 (0.105)	Data 0.00094 (0.00096)	Tok/s 54400 (59789)	Loss/tok 3.8926 (4.9995)	Learning Rate [0.00125]
1: TRAIN [0][1970/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00093)	Tok/s 54350 (59422)	Loss/tok 3.9778 (5.0045)	Learning Rate [0.00125]
3: TRAIN [0][1970/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00096)	Tok/s 54867 (60238)	Loss/tok 4.0615 (5.0064)	Learning Rate [0.00125]
0: TRAIN [0][1970/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00096)	Tok/s 54362 (58981)	Loss/tok 3.9466 (5.0032)	Learning Rate [0.00125]
1: TRAIN [0][1980/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00093)	Tok/s 81004 (59401)	Loss/tok 4.2422 (4.9996)	Learning Rate [0.00125]
2: TRAIN [0][1980/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 80992 (59770)	Loss/tok 4.0890 (4.9945)	Learning Rate [0.00125]
0: TRAIN [0][1980/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00096)	Tok/s 80274 (58960)	Loss/tok 4.0732 (4.9983)	Learning Rate [0.00125]
3: TRAIN [0][1980/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00096)	Tok/s 81948 (60218)	Loss/tok 4.0360 (5.0014)	Learning Rate [0.00125]
2: TRAIN [0][1990/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00096)	Tok/s 54646 (59788)	Loss/tok 3.9296 (4.9883)	Learning Rate [0.00125]
0: TRAIN [0][1990/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00096)	Tok/s 54056 (58979)	Loss/tok 3.9460 (4.9928)	Learning Rate [0.00125]
1: TRAIN [0][1990/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00093)	Tok/s 54622 (59420)	Loss/tok 3.8952 (4.9934)	Learning Rate [0.00125]
3: TRAIN [0][1990/6832]	Time 0.112 (0.105)	Data 0.00097 (0.00096)	Tok/s 54664 (60236)	Loss/tok 3.8965 (4.9953)	Learning Rate [0.00125]
1: TRAIN [0][2000/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00093)	Tok/s 53579 (59416)	Loss/tok 4.0256 (4.9882)	Learning Rate [0.00125]
0: TRAIN [0][2000/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00096)	Tok/s 52861 (58976)	Loss/tok 4.0106 (4.9878)	Learning Rate [0.00125]
2: TRAIN [0][2000/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00096)	Tok/s 53541 (59783)	Loss/tok 3.9601 (4.9828)	Learning Rate [0.00125]
3: TRAIN [0][2000/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00096)	Tok/s 53536 (60231)	Loss/tok 3.9866 (4.9900)	Learning Rate [0.00125]
2: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
1: TRAIN [0][2010/6832]	Time 0.052 (0.105)	Data 0.00091 (0.00093)	Tok/s 46868 (59420)	Loss/tok 3.0257 (4.9826)	Learning Rate [0.00125]
2: TRAIN [0][2010/6832]	Time 0.052 (0.105)	Data 0.00098 (0.00096)	Tok/s 46884 (59786)	Loss/tok 3.0883 (4.9774)	Learning Rate [0.00125]
0: TRAIN [0][2010/6832]	Time 0.052 (0.105)	Data 0.00088 (0.00096)	Tok/s 44632 (58979)	Loss/tok 2.8777 (4.9821)	Learning Rate [0.00125]
3: TRAIN [0][2010/6832]	Time 0.052 (0.105)	Data 0.00097 (0.00096)	Tok/s 49158 (60235)	Loss/tok 3.0622 (4.9843)	Learning Rate [0.00125]
1: TRAIN [0][2020/6832]	Time 0.109 (0.105)	Data 0.00099 (0.00093)	Tok/s 52867 (59445)	Loss/tok 3.7797 (4.9767)	Learning Rate [0.00125]
0: TRAIN [0][2020/6832]	Time 0.109 (0.105)	Data 0.00097 (0.00096)	Tok/s 52835 (59006)	Loss/tok 3.9037 (4.9760)	Learning Rate [0.00125]
2: TRAIN [0][2020/6832]	Time 0.109 (0.105)	Data 0.00100 (0.00096)	Tok/s 52787 (59810)	Loss/tok 3.6814 (4.9711)	Learning Rate [0.00125]
3: TRAIN [0][2020/6832]	Time 0.109 (0.105)	Data 0.00099 (0.00096)	Tok/s 52767 (60257)	Loss/tok 3.6677 (4.9781)	Learning Rate [0.00125]
2: TRAIN [0][2030/6832]	Time 0.107 (0.105)	Data 0.00094 (0.00096)	Tok/s 52434 (59799)	Loss/tok 3.7933 (4.9660)	Learning Rate [0.00125]
1: TRAIN [0][2030/6832]	Time 0.107 (0.105)	Data 0.00090 (0.00093)	Tok/s 52404 (59435)	Loss/tok 3.6847 (4.9715)	Learning Rate [0.00125]
3: TRAIN [0][2030/6832]	Time 0.107 (0.105)	Data 0.00093 (0.00096)	Tok/s 53545 (60246)	Loss/tok 4.0374 (4.9733)	Learning Rate [0.00125]
0: TRAIN [0][2030/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00096)	Tok/s 52418 (58997)	Loss/tok 3.8080 (4.9708)	Learning Rate [0.00125]
1: TRAIN [0][2040/6832]	Time 0.106 (0.105)	Data 0.00097 (0.00093)	Tok/s 55290 (59432)	Loss/tok 4.2084 (4.9666)	Learning Rate [0.00125]
0: TRAIN [0][2040/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00096)	Tok/s 55299 (58995)	Loss/tok 3.8622 (4.9657)	Learning Rate [0.00125]
2: TRAIN [0][2040/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00096)	Tok/s 55259 (59795)	Loss/tok 3.8701 (4.9610)	Learning Rate [0.00125]
3: TRAIN [0][2040/6832]	Time 0.107 (0.105)	Data 0.00103 (0.00096)	Tok/s 55266 (60243)	Loss/tok 3.7157 (4.9680)	Learning Rate [0.00125]
1: TRAIN [0][2050/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00093)	Tok/s 52301 (59406)	Loss/tok 3.6805 (4.9618)	Learning Rate [0.00125]
0: TRAIN [0][2050/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00096)	Tok/s 52304 (58970)	Loss/tok 4.0294 (4.9610)	Learning Rate [0.00125]
2: TRAIN [0][2050/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00096)	Tok/s 52207 (59768)	Loss/tok 4.0327 (4.9562)	Learning Rate [0.00125]
3: TRAIN [0][2050/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00096)	Tok/s 52196 (60215)	Loss/tok 4.0601 (4.9633)	Learning Rate [0.00125]
2: TRAIN [0][2060/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 56822 (59762)	Loss/tok 4.1492 (4.9513)	Learning Rate [0.00125]
3: TRAIN [0][2060/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 57620 (60208)	Loss/tok 4.1104 (4.9584)	Learning Rate [0.00125]
0: TRAIN [0][2060/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00096)	Tok/s 56769 (58963)	Loss/tok 4.0959 (4.9558)	Learning Rate [0.00125]
1: TRAIN [0][2060/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 56763 (59400)	Loss/tok 3.8347 (4.9566)	Learning Rate [0.00125]
0: TRAIN [0][2070/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 71385 (58964)	Loss/tok 4.1247 (4.9509)	Learning Rate [0.00125]
1: TRAIN [0][2070/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00093)	Tok/s 71357 (59406)	Loss/tok 3.9429 (4.9512)	Learning Rate [0.00125]
2: TRAIN [0][2070/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 72130 (59770)	Loss/tok 3.8313 (4.9459)	Learning Rate [0.00125]
3: TRAIN [0][2070/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 72380 (60217)	Loss/tok 3.9368 (4.9530)	Learning Rate [0.00125]
1: TRAIN [0][2080/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00093)	Tok/s 52062 (59390)	Loss/tok 3.7323 (4.9465)	Learning Rate [0.00125]
2: TRAIN [0][2080/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00096)	Tok/s 52033 (59755)	Loss/tok 3.5518 (4.9410)	Learning Rate [0.00125]
0: TRAIN [0][2080/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00096)	Tok/s 50322 (58948)	Loss/tok 3.6005 (4.9463)	Learning Rate [0.00125]
3: TRAIN [0][2080/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00096)	Tok/s 52006 (60202)	Loss/tok 3.5060 (4.9482)	Learning Rate [0.00125]
1: TRAIN [0][2090/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00093)	Tok/s 51943 (59404)	Loss/tok 3.7821 (4.9411)	Learning Rate [0.00125]
2: TRAIN [0][2090/6832]	Time 0.086 (0.105)	Data 0.00086 (0.00096)	Tok/s 51974 (59768)	Loss/tok 3.5336 (4.9355)	Learning Rate [0.00125]
3: TRAIN [0][2090/6832]	Time 0.085 (0.105)	Data 0.00087 (0.00096)	Tok/s 52504 (60215)	Loss/tok 3.7187 (4.9424)	Learning Rate [0.00125]
0: TRAIN [0][2090/6832]	Time 0.086 (0.105)	Data 0.00088 (0.00096)	Tok/s 51734 (58962)	Loss/tok 3.7055 (4.9409)	Learning Rate [0.00125]
1: TRAIN [0][2100/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00093)	Tok/s 52233 (59434)	Loss/tok 3.9645 (4.9350)	Learning Rate [0.00125]
0: TRAIN [0][2100/6832]	Time 0.098 (0.105)	Data 0.00090 (0.00096)	Tok/s 52209 (58993)	Loss/tok 4.0015 (4.9349)	Learning Rate [0.00125]
2: TRAIN [0][2100/6832]	Time 0.098 (0.105)	Data 0.00090 (0.00096)	Tok/s 53031 (59798)	Loss/tok 3.6697 (4.9294)	Learning Rate [0.00125]
3: TRAIN [0][2100/6832]	Time 0.098 (0.105)	Data 0.00089 (0.00096)	Tok/s 53522 (60247)	Loss/tok 3.7100 (4.9360)	Learning Rate [0.00125]
2: TRAIN [0][2110/6832]	Time 0.055 (0.105)	Data 0.00091 (0.00096)	Tok/s 44320 (59792)	Loss/tok 3.0296 (4.9241)	Learning Rate [0.00125]
3: TRAIN [0][2110/6832]	Time 0.055 (0.105)	Data 0.00085 (0.00096)	Tok/s 46177 (60242)	Loss/tok 3.0864 (4.9306)	Learning Rate [0.00125]
1: TRAIN [0][2110/6832]	Time 0.055 (0.105)	Data 0.00090 (0.00093)	Tok/s 43885 (59429)	Loss/tok 2.9842 (4.9300)	Learning Rate [0.00125]
0: TRAIN [0][2110/6832]	Time 0.055 (0.105)	Data 0.00087 (0.00096)	Tok/s 42064 (58988)	Loss/tok 2.8733 (4.9298)	Learning Rate [0.00125]
2: TRAIN [0][2120/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00096)	Tok/s 51245 (59781)	Loss/tok 3.5988 (4.9191)	Learning Rate [0.00125]
3: TRAIN [0][2120/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00096)	Tok/s 51235 (60229)	Loss/tok 3.6499 (4.9259)	Learning Rate [0.00125]
1: TRAIN [0][2120/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00093)	Tok/s 51215 (59417)	Loss/tok 3.8797 (4.9253)	Learning Rate [0.00125]
0: TRAIN [0][2120/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00096)	Tok/s 51204 (58976)	Loss/tok 3.8817 (4.9250)	Learning Rate [0.00125]
1: TRAIN [0][2130/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00093)	Tok/s 59880 (59389)	Loss/tok 4.0725 (4.9211)	Learning Rate [0.00125]
0: TRAIN [0][2130/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00096)	Tok/s 58927 (58942)	Loss/tok 3.9781 (4.9207)	Learning Rate [0.00125]
2: TRAIN [0][2130/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00096)	Tok/s 59868 (59753)	Loss/tok 3.9593 (4.9145)	Learning Rate [0.00125]
3: TRAIN [0][2130/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00096)	Tok/s 59863 (60202)	Loss/tok 4.0958 (4.9216)	Learning Rate [0.00125]
3: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
2: TRAIN [0][2140/6832]	Time 0.116 (0.105)	Data 0.00119 (0.00096)	Tok/s 57937 (59767)	Loss/tok 3.8092 (4.9092)	Learning Rate [0.00125]
3: TRAIN [0][2140/6832]	Time 0.116 (0.105)	Data 0.00107 (0.00096)	Tok/s 58335 (60215)	Loss/tok 3.9068 (4.9164)	Learning Rate [0.00125]
1: TRAIN [0][2140/6832]	Time 0.116 (0.105)	Data 0.00100 (0.00093)	Tok/s 57166 (59403)	Loss/tok 3.9369 (4.9157)	Learning Rate [0.00125]
0: TRAIN [0][2140/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00096)	Tok/s 57185 (58957)	Loss/tok 3.8130 (4.9154)	Learning Rate [0.00125]
1: TRAIN [0][2150/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 83363 (59385)	Loss/tok 3.9073 (4.9110)	Learning Rate [0.00125]
0: TRAIN [0][2150/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00096)	Tok/s 82795 (58933)	Loss/tok 3.8162 (4.9108)	Learning Rate [0.00125]
2: TRAIN [0][2150/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 83794 (59751)	Loss/tok 3.8821 (4.9045)	Learning Rate [0.00125]
3: TRAIN [0][2150/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00096)	Tok/s 84314 (60199)	Loss/tok 3.9070 (4.9119)	Learning Rate [0.00125]
1: TRAIN [0][2160/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00093)	Tok/s 56015 (59373)	Loss/tok 3.9598 (4.9069)	Learning Rate [0.00125]
0: TRAIN [0][2160/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00096)	Tok/s 55589 (58922)	Loss/tok 3.9082 (4.9064)	Learning Rate [0.00125]
2: TRAIN [0][2160/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00096)	Tok/s 56558 (59739)	Loss/tok 4.0005 (4.8999)	Learning Rate [0.00125]
3: TRAIN [0][2160/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00096)	Tok/s 56526 (60186)	Loss/tok 3.8864 (4.9075)	Learning Rate [0.00125]
1: TRAIN [0][2170/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00093)	Tok/s 72462 (59377)	Loss/tok 3.8488 (4.9020)	Learning Rate [0.00125]
0: TRAIN [0][2170/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00096)	Tok/s 71830 (58927)	Loss/tok 3.9506 (4.9016)	Learning Rate [0.00125]
2: TRAIN [0][2170/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00096)	Tok/s 72770 (59741)	Loss/tok 4.0314 (4.8951)	Learning Rate [0.00125]
3: TRAIN [0][2170/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00096)	Tok/s 73055 (60188)	Loss/tok 3.9694 (4.9026)	Learning Rate [0.00125]
2: TRAIN [0][2180/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00096)	Tok/s 51427 (59772)	Loss/tok 3.4264 (4.8893)	Learning Rate [0.00125]
1: TRAIN [0][2180/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00093)	Tok/s 51561 (59408)	Loss/tok 3.5010 (4.8965)	Learning Rate [0.00125]
0: TRAIN [0][2180/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00096)	Tok/s 51510 (58960)	Loss/tok 3.4915 (4.8960)	Learning Rate [0.00125]
3: TRAIN [0][2180/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00096)	Tok/s 51480 (60219)	Loss/tok 3.7460 (4.8969)	Learning Rate [0.00125]
1: TRAIN [0][2190/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00093)	Tok/s 53020 (59409)	Loss/tok 3.8137 (4.8915)	Learning Rate [0.00125]
0: TRAIN [0][2190/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00096)	Tok/s 53035 (58962)	Loss/tok 3.6810 (4.8911)	Learning Rate [0.00125]
2: TRAIN [0][2190/6832]	Time 0.104 (0.105)	Data 0.00094 (0.00096)	Tok/s 53027 (59772)	Loss/tok 3.9321 (4.8843)	Learning Rate [0.00125]
3: TRAIN [0][2190/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00096)	Tok/s 53033 (60218)	Loss/tok 3.7373 (4.8919)	Learning Rate [0.00125]
2: TRAIN [0][2200/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00096)	Tok/s 78087 (59776)	Loss/tok 3.9614 (4.8794)	Learning Rate [0.00125]
1: TRAIN [0][2200/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 77475 (59415)	Loss/tok 3.9931 (4.8868)	Learning Rate [0.00125]
0: TRAIN [0][2200/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 77485 (58967)	Loss/tok 3.9286 (4.8862)	Learning Rate [0.00125]
3: TRAIN [0][2200/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00096)	Tok/s 78466 (60221)	Loss/tok 3.9582 (4.8870)	Learning Rate [0.00125]
1: TRAIN [0][2210/6832]	Time 0.082 (0.105)	Data 0.00093 (0.00093)	Tok/s 51293 (59414)	Loss/tok 3.6195 (4.8822)	Learning Rate [0.00125]
0: TRAIN [0][2210/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00096)	Tok/s 51298 (58968)	Loss/tok 3.8069 (4.8815)	Learning Rate [0.00125]
2: TRAIN [0][2210/6832]	Time 0.082 (0.105)	Data 0.00091 (0.00096)	Tok/s 51796 (59775)	Loss/tok 3.7174 (4.8746)	Learning Rate [0.00125]
3: TRAIN [0][2210/6832]	Time 0.082 (0.105)	Data 0.00098 (0.00096)	Tok/s 52905 (60220)	Loss/tok 3.7542 (4.8825)	Learning Rate [0.00125]
2: TRAIN [0][2220/6832]	Time 0.093 (0.105)	Data 0.00093 (0.00096)	Tok/s 54818 (59769)	Loss/tok 3.5431 (4.8703)	Learning Rate [0.00125]
1: TRAIN [0][2220/6832]	Time 0.094 (0.105)	Data 0.00087 (0.00093)	Tok/s 54732 (59407)	Loss/tok 3.7092 (4.8777)	Learning Rate [0.00125]
0: TRAIN [0][2220/6832]	Time 0.094 (0.105)	Data 0.00089 (0.00096)	Tok/s 54759 (58962)	Loss/tok 3.7060 (4.8772)	Learning Rate [0.00125]
3: TRAIN [0][2220/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00096)	Tok/s 55217 (60213)	Loss/tok 3.6157 (4.8777)	Learning Rate [0.00125]
1: TRAIN [0][2230/6832]	Time 0.095 (0.105)	Data 0.00103 (0.00093)	Tok/s 54001 (59398)	Loss/tok 3.8056 (4.8730)	Learning Rate [0.00125]
2: TRAIN [0][2230/6832]	Time 0.095 (0.105)	Data 0.00100 (0.00096)	Tok/s 54131 (59761)	Loss/tok 3.5629 (4.8659)	Learning Rate [0.00125]
0: TRAIN [0][2230/6832]	Time 0.095 (0.105)	Data 0.00106 (0.00096)	Tok/s 54012 (58949)	Loss/tok 3.6521 (4.8726)	Learning Rate [0.00125]
3: TRAIN [0][2230/6832]	Time 0.095 (0.105)	Data 0.00103 (0.00096)	Tok/s 55376 (60205)	Loss/tok 3.6428 (4.8731)	Learning Rate [0.00125]
2: TRAIN [0][2240/6832]	Time 0.050 (0.105)	Data 0.00094 (0.00096)	Tok/s 48217 (59746)	Loss/tok 2.9402 (4.8617)	Learning Rate [0.00125]
3: TRAIN [0][2240/6832]	Time 0.050 (0.105)	Data 0.00096 (0.00096)	Tok/s 49727 (60192)	Loss/tok 3.1237 (4.8685)	Learning Rate [0.00125]
1: TRAIN [0][2240/6832]	Time 0.050 (0.105)	Data 0.00088 (0.00093)	Tok/s 47257 (59384)	Loss/tok 2.9967 (4.8687)	Learning Rate [0.00125]
0: TRAIN [0][2240/6832]	Time 0.050 (0.105)	Data 0.00097 (0.00096)	Tok/s 45659 (58934)	Loss/tok 3.0956 (4.8685)	Learning Rate [0.00125]
1: TRAIN [0][2250/6832]	Time 0.129 (0.105)	Data 0.00105 (0.00093)	Tok/s 75149 (59373)	Loss/tok 3.8910 (4.8644)	Learning Rate [0.00125]
0: TRAIN [0][2250/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00096)	Tok/s 75142 (58923)	Loss/tok 3.8363 (4.8646)	Learning Rate [0.00125]
2: TRAIN [0][2250/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00096)	Tok/s 75222 (59735)	Loss/tok 4.0081 (4.8577)	Learning Rate [0.00125]
3: TRAIN [0][2250/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00096)	Tok/s 76105 (60181)	Loss/tok 4.0161 (4.8646)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [0][2260/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00093)	Tok/s 75756 (59401)	Loss/tok 3.9131 (4.8589)	Learning Rate [0.00125]
0: TRAIN [0][2260/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 75600 (58951)	Loss/tok 3.8486 (4.8593)	Learning Rate [0.00125]
2: TRAIN [0][2260/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00096)	Tok/s 76778 (59763)	Loss/tok 3.9045 (4.8523)	Learning Rate [0.00125]
3: TRAIN [0][2260/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00096)	Tok/s 76771 (60209)	Loss/tok 3.8889 (4.8591)	Learning Rate [0.00125]
1: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
2: TRAIN [0][2270/6832]	Time 0.051 (0.105)	Data 0.00091 (0.00096)	Tok/s 51719 (59777)	Loss/tok 2.9952 (4.8474)	Learning Rate [0.00125]
1: TRAIN [0][2270/6832]	Time 0.051 (0.105)	Data 0.00090 (0.00093)	Tok/s 49721 (59413)	Loss/tok 3.2663 (4.8543)	Learning Rate [0.00125]
3: TRAIN [0][2270/6832]	Time 0.051 (0.105)	Data 0.00085 (0.00096)	Tok/s 52259 (60225)	Loss/tok 2.9321 (4.8540)	Learning Rate [0.00125]
0: TRAIN [0][2270/6832]	Time 0.051 (0.105)	Data 0.00090 (0.00096)	Tok/s 49760 (58957)	Loss/tok 2.9456 (4.8546)	Learning Rate [0.00125]
0: TRAIN [0][2280/6832]	Time 0.128 (0.105)	Data 0.00100 (0.00096)	Tok/s 65493 (58931)	Loss/tok 3.9556 (4.8508)	Learning Rate [0.00125]
1: TRAIN [0][2280/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00093)	Tok/s 65937 (59386)	Loss/tok 4.0583 (4.8504)	Learning Rate [0.00125]
2: TRAIN [0][2280/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00096)	Tok/s 65949 (59750)	Loss/tok 3.9420 (4.8437)	Learning Rate [0.00125]
3: TRAIN [0][2280/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00096)	Tok/s 65950 (60198)	Loss/tok 4.1827 (4.8503)	Learning Rate [0.00125]
2: TRAIN [0][2290/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00096)	Tok/s 52896 (59752)	Loss/tok 3.4696 (4.8391)	Learning Rate [0.00125]
1: TRAIN [0][2290/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00093)	Tok/s 52836 (59388)	Loss/tok 3.3326 (4.8457)	Learning Rate [0.00125]
3: TRAIN [0][2290/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00096)	Tok/s 53753 (60200)	Loss/tok 3.7123 (4.8458)	Learning Rate [0.00125]
0: TRAIN [0][2290/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00096)	Tok/s 52825 (58934)	Loss/tok 3.4004 (4.8462)	Learning Rate [0.00125]
1: TRAIN [0][2300/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00093)	Tok/s 52924 (59384)	Loss/tok 3.7318 (4.8414)	Learning Rate [0.00125]
3: TRAIN [0][2300/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00096)	Tok/s 54036 (60194)	Loss/tok 3.6610 (4.8413)	Learning Rate [0.00125]
2: TRAIN [0][2300/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00096)	Tok/s 53994 (59748)	Loss/tok 3.9140 (4.8347)	Learning Rate [0.00125]
0: TRAIN [0][2300/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00096)	Tok/s 52930 (58931)	Loss/tok 3.9652 (4.8419)	Learning Rate [0.00125]
1: TRAIN [0][2310/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00093)	Tok/s 58954 (59410)	Loss/tok 3.8722 (4.8362)	Learning Rate [0.00125]
3: TRAIN [0][2310/6832]	Time 0.122 (0.105)	Data 0.00097 (0.00096)	Tok/s 59861 (60220)	Loss/tok 3.7533 (4.8361)	Learning Rate [0.00125]
0: TRAIN [0][2310/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00096)	Tok/s 58854 (58957)	Loss/tok 3.8292 (4.8366)	Learning Rate [0.00125]
2: TRAIN [0][2310/6832]	Time 0.122 (0.105)	Data 0.00101 (0.00096)	Tok/s 59869 (59775)	Loss/tok 3.8917 (4.8298)	Learning Rate [0.00125]
1: TRAIN [0][2320/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00093)	Tok/s 88332 (59419)	Loss/tok 3.7172 (4.8316)	Learning Rate [0.00125]
0: TRAIN [0][2320/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 87514 (58968)	Loss/tok 3.7162 (4.8320)	Learning Rate [0.00125]
2: TRAIN [0][2320/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00096)	Tok/s 88741 (59784)	Loss/tok 3.8307 (4.8254)	Learning Rate [0.00125]
3: TRAIN [0][2320/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 89425 (60228)	Loss/tok 3.7551 (4.8313)	Learning Rate [0.00125]
2: TRAIN [0][2330/6832]	Time 0.099 (0.105)	Data 0.00094 (0.00096)	Tok/s 51770 (59788)	Loss/tok 3.7631 (4.8207)	Learning Rate [0.00125]
3: TRAIN [0][2330/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00096)	Tok/s 51826 (60231)	Loss/tok 3.5604 (4.8265)	Learning Rate [0.00125]
1: TRAIN [0][2330/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00093)	Tok/s 50409 (59424)	Loss/tok 3.7247 (4.8273)	Learning Rate [0.00125]
0: TRAIN [0][2330/6832]	Time 0.099 (0.105)	Data 0.00091 (0.00095)	Tok/s 50436 (58974)	Loss/tok 3.8503 (4.8276)	Learning Rate [0.00125]
1: TRAIN [0][2340/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00093)	Tok/s 56901 (59419)	Loss/tok 3.9970 (4.8234)	Learning Rate [0.00125]
2: TRAIN [0][2340/6832]	Time 0.121 (0.105)	Data 0.00102 (0.00096)	Tok/s 57022 (59782)	Loss/tok 3.9060 (4.8164)	Learning Rate [0.00125]
3: TRAIN [0][2340/6832]	Time 0.121 (0.105)	Data 0.00099 (0.00096)	Tok/s 57070 (60225)	Loss/tok 3.8667 (4.8224)	Learning Rate [0.00125]
0: TRAIN [0][2340/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00095)	Tok/s 56005 (58969)	Loss/tok 3.6704 (4.8232)	Learning Rate [0.00125]
1: TRAIN [0][2350/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00093)	Tok/s 80134 (59435)	Loss/tok 3.8295 (4.8187)	Learning Rate [0.00125]
0: TRAIN [0][2350/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 79984 (58987)	Loss/tok 3.9002 (4.8184)	Learning Rate [0.00125]
2: TRAIN [0][2350/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 80726 (59798)	Loss/tok 4.0157 (4.8119)	Learning Rate [0.00125]
3: TRAIN [0][2350/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00096)	Tok/s 81134 (60242)	Loss/tok 3.7138 (4.8178)	Learning Rate [0.00125]
1: TRAIN [0][2360/6832]	Time 0.054 (0.105)	Data 0.00089 (0.00093)	Tok/s 47717 (59439)	Loss/tok 3.2203 (4.8143)	Learning Rate [0.00125]
3: TRAIN [0][2360/6832]	Time 0.054 (0.105)	Data 0.00094 (0.00096)	Tok/s 49415 (60246)	Loss/tok 3.2421 (4.8134)	Learning Rate [0.00125]
2: TRAIN [0][2360/6832]	Time 0.054 (0.105)	Data 0.00095 (0.00096)	Tok/s 49397 (59802)	Loss/tok 2.9815 (4.8075)	Learning Rate [0.00125]
0: TRAIN [0][2360/6832]	Time 0.054 (0.105)	Data 0.00088 (0.00095)	Tok/s 47087 (58991)	Loss/tok 3.1559 (4.8139)	Learning Rate [0.00125]
1: TRAIN [0][2370/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00093)	Tok/s 52601 (59425)	Loss/tok 3.8225 (4.8105)	Learning Rate [0.00125]
2: TRAIN [0][2370/6832]	Time 0.088 (0.105)	Data 0.00092 (0.00096)	Tok/s 53977 (59789)	Loss/tok 3.8053 (4.8038)	Learning Rate [0.00125]
3: TRAIN [0][2370/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00096)	Tok/s 54055 (60232)	Loss/tok 3.8475 (4.8100)	Learning Rate [0.00125]
0: TRAIN [0][2370/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00095)	Tok/s 52617 (58978)	Loss/tok 3.3894 (4.8099)	Learning Rate [0.00125]
1: TRAIN [0][2380/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00093)	Tok/s 62119 (59424)	Loss/tok 3.9167 (4.8062)	Learning Rate [0.00125]
0: TRAIN [0][2380/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 62124 (58972)	Loss/tok 4.0977 (4.8057)	Learning Rate [0.00125]
2: TRAIN [0][2380/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00096)	Tok/s 62443 (59789)	Loss/tok 3.6749 (4.7993)	Learning Rate [0.00125]
3: TRAIN [0][2380/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 63104 (60232)	Loss/tok 4.0137 (4.8058)	Learning Rate [0.00125]
1: TRAIN [0][2390/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 75158 (59402)	Loss/tok 3.9843 (4.8027)	Learning Rate [0.00125]
2: TRAIN [0][2390/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 75122 (59770)	Loss/tok 3.9933 (4.7957)	Learning Rate [0.00125]
0: TRAIN [0][2390/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 74920 (58946)	Loss/tok 4.0068 (4.8023)	Learning Rate [0.00125]
3: TRAIN [0][2390/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00096)	Tok/s 75914 (60215)	Loss/tok 3.9502 (4.8021)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [0][2400/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 66613 (59425)	Loss/tok 3.8286 (4.7979)	Learning Rate [0.00125]
0: TRAIN [0][2400/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 66604 (58971)	Loss/tok 3.8715 (4.7973)	Learning Rate [0.00125]
2: TRAIN [0][2400/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 66959 (59793)	Loss/tok 3.9734 (4.7912)	Learning Rate [0.00125]
3: TRAIN [0][2400/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 67544 (60237)	Loss/tok 3.7651 (4.7970)	Learning Rate [0.00125]
1: TRAIN [0][2410/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00093)	Tok/s 81399 (59436)	Loss/tok 3.8278 (4.7934)	Learning Rate [0.00125]
2: TRAIN [0][2410/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00096)	Tok/s 81918 (59803)	Loss/tok 3.9099 (4.7871)	Learning Rate [0.00125]
3: TRAIN [0][2410/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00096)	Tok/s 82327 (60248)	Loss/tok 3.7458 (4.7926)	Learning Rate [0.00125]
0: TRAIN [0][2410/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 80952 (58982)	Loss/tok 3.9372 (4.7929)	Learning Rate [0.00125]
3: TRAIN [0][2420/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00096)	Tok/s 62356 (60256)	Loss/tok 3.9947 (4.7885)	Learning Rate [0.00125]
2: TRAIN [0][2420/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00096)	Tok/s 62332 (59810)	Loss/tok 3.9946 (4.7831)	Learning Rate [0.00125]
0: TRAIN [0][2420/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00095)	Tok/s 62305 (58988)	Loss/tok 4.0122 (4.7887)	Learning Rate [0.00125]
1: TRAIN [0][2420/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 62262 (59444)	Loss/tok 4.1144 (4.7894)	Learning Rate [0.00125]
1: TRAIN [0][2430/6832]	Time 0.087 (0.105)	Data 0.00094 (0.00093)	Tok/s 54405 (59436)	Loss/tok 3.6280 (4.7855)	Learning Rate [0.00125]
0: TRAIN [0][2430/6832]	Time 0.087 (0.105)	Data 0.00093 (0.00095)	Tok/s 54380 (58979)	Loss/tok 3.6985 (4.7848)	Learning Rate [0.00125]
2: TRAIN [0][2430/6832]	Time 0.087 (0.105)	Data 0.00098 (0.00096)	Tok/s 54353 (59804)	Loss/tok 3.7292 (4.7790)	Learning Rate [0.00125]
3: TRAIN [0][2430/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00096)	Tok/s 54363 (60248)	Loss/tok 3.7518 (4.7844)	Learning Rate [0.00125]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [0][2440/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 81830 (59446)	Loss/tok 3.9442 (4.7811)	Learning Rate [0.00125]
0: TRAIN [0][2440/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 81191 (58989)	Loss/tok 3.7796 (4.7804)	Learning Rate [0.00125]
2: TRAIN [0][2440/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00096)	Tok/s 81917 (59813)	Loss/tok 3.6554 (4.7747)	Learning Rate [0.00125]
3: TRAIN [0][2440/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 82696 (60257)	Loss/tok 3.7806 (4.7800)	Learning Rate [0.00125]
1: TRAIN [0][2450/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00093)	Tok/s 60722 (59445)	Loss/tok 3.7947 (4.7773)	Learning Rate [0.00125]
0: TRAIN [0][2450/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00095)	Tok/s 60727 (58990)	Loss/tok 3.9227 (4.7764)	Learning Rate [0.00125]
2: TRAIN [0][2450/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00096)	Tok/s 60662 (59813)	Loss/tok 3.9829 (4.7708)	Learning Rate [0.00125]
3: TRAIN [0][2450/6832]	Time 0.125 (0.105)	Data 0.00086 (0.00096)	Tok/s 60649 (60256)	Loss/tok 3.9813 (4.7763)	Learning Rate [0.00125]
1: TRAIN [0][2460/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00093)	Tok/s 57853 (59425)	Loss/tok 3.7195 (4.7736)	Learning Rate [0.00125]
2: TRAIN [0][2460/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00096)	Tok/s 57823 (59793)	Loss/tok 3.8664 (4.7672)	Learning Rate [0.00125]
3: TRAIN [0][2460/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00096)	Tok/s 57817 (60235)	Loss/tok 4.0632 (4.7727)	Learning Rate [0.00125]
0: TRAIN [0][2460/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00095)	Tok/s 57831 (58971)	Loss/tok 4.0409 (4.7731)	Learning Rate [0.00125]
2: TRAIN [0][2470/6832]	Time 0.055 (0.105)	Data 0.00090 (0.00096)	Tok/s 50848 (59779)	Loss/tok 3.0612 (4.7635)	Learning Rate [0.00125]
3: TRAIN [0][2470/6832]	Time 0.055 (0.105)	Data 0.00088 (0.00096)	Tok/s 51521 (60222)	Loss/tok 3.1178 (4.7692)	Learning Rate [0.00125]
1: TRAIN [0][2470/6832]	Time 0.055 (0.105)	Data 0.00089 (0.00093)	Tok/s 50769 (59412)	Loss/tok 3.2990 (4.7701)	Learning Rate [0.00125]
0: TRAIN [0][2470/6832]	Time 0.056 (0.105)	Data 0.00090 (0.00095)	Tok/s 49255 (58958)	Loss/tok 3.1066 (4.7695)	Learning Rate [0.00125]
2: TRAIN [0][2480/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00096)	Tok/s 54696 (59775)	Loss/tok 3.8219 (4.7596)	Learning Rate [0.00125]
3: TRAIN [0][2480/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00096)	Tok/s 54706 (60217)	Loss/tok 3.8224 (4.7655)	Learning Rate [0.00125]
1: TRAIN [0][2480/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00093)	Tok/s 54700 (59408)	Loss/tok 3.6864 (4.7661)	Learning Rate [0.00125]
0: TRAIN [0][2480/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00095)	Tok/s 54694 (58955)	Loss/tok 3.9178 (4.7657)	Learning Rate [0.00125]
2: TRAIN [0][2490/6832]	Time 0.106 (0.105)	Data 0.00092 (0.00096)	Tok/s 50947 (59778)	Loss/tok 3.9207 (4.7558)	Learning Rate [0.00125]
1: TRAIN [0][2490/6832]	Time 0.106 (0.105)	Data 0.00100 (0.00093)	Tok/s 50899 (59412)	Loss/tok 3.5657 (4.7619)	Learning Rate [0.00125]
3: TRAIN [0][2490/6832]	Time 0.106 (0.105)	Data 0.00093 (0.00096)	Tok/s 52113 (60220)	Loss/tok 3.7961 (4.7615)	Learning Rate [0.00125]
0: TRAIN [0][2490/6832]	Time 0.106 (0.105)	Data 0.00097 (0.00095)	Tok/s 50896 (58959)	Loss/tok 3.8614 (4.7619)	Learning Rate [0.00125]
2: TRAIN [0][2500/6832]	Time 0.106 (0.105)	Data 0.00087 (0.00096)	Tok/s 53170 (59754)	Loss/tok 3.8160 (4.7525)	Learning Rate [0.00125]
3: TRAIN [0][2500/6832]	Time 0.106 (0.105)	Data 0.00092 (0.00096)	Tok/s 54341 (60195)	Loss/tok 3.6542 (4.7583)	Learning Rate [0.00125]
0: TRAIN [0][2500/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00095)	Tok/s 53126 (58936)	Loss/tok 3.7078 (4.7587)	Learning Rate [0.00125]
1: TRAIN [0][2500/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00093)	Tok/s 53119 (59388)	Loss/tok 3.6331 (4.7585)	Learning Rate [0.00125]
2: TRAIN [0][2510/6832]	Time 0.055 (0.105)	Data 0.00096 (0.00096)	Tok/s 51602 (59735)	Loss/tok 3.0083 (4.7493)	Learning Rate [0.00125]
1: TRAIN [0][2510/6832]	Time 0.055 (0.105)	Data 0.00101 (0.00093)	Tok/s 51585 (59370)	Loss/tok 3.1499 (4.7552)	Learning Rate [0.00125]
3: TRAIN [0][2510/6832]	Time 0.055 (0.105)	Data 0.00090 (0.00096)	Tok/s 52222 (60176)	Loss/tok 3.3344 (4.7552)	Learning Rate [0.00125]
0: TRAIN [0][2510/6832]	Time 0.055 (0.105)	Data 0.00100 (0.00095)	Tok/s 50562 (58918)	Loss/tok 3.1431 (4.7555)	Learning Rate [0.00125]
1: TRAIN [0][2520/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 73705 (59375)	Loss/tok 3.9256 (4.7515)	Learning Rate [0.00125]
0: TRAIN [0][2520/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 72756 (58924)	Loss/tok 3.9633 (4.7517)	Learning Rate [0.00125]
2: TRAIN [0][2520/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 73683 (59739)	Loss/tok 3.8806 (4.7457)	Learning Rate [0.00125]
3: TRAIN [0][2520/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00096)	Tok/s 73701 (60180)	Loss/tok 3.7709 (4.7515)	Learning Rate [0.00125]
1: TRAIN [0][2530/6832]	Time 0.122 (0.105)	Data 0.00094 (0.00093)	Tok/s 56599 (59379)	Loss/tok 3.9192 (4.7478)	Learning Rate [0.00125]
3: TRAIN [0][2530/6832]	Time 0.122 (0.105)	Data 0.00098 (0.00096)	Tok/s 56722 (60183)	Loss/tok 4.0503 (4.7476)	Learning Rate [0.00125]
0: TRAIN [0][2530/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00095)	Tok/s 56603 (58929)	Loss/tok 3.8390 (4.7477)	Learning Rate [0.00125]
2: TRAIN [0][2530/6832]	Time 0.122 (0.105)	Data 0.00099 (0.00096)	Tok/s 56618 (59742)	Loss/tok 4.0791 (4.7420)	Learning Rate [0.00125]
2: TRAIN [0][2540/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00096)	Tok/s 55260 (59742)	Loss/tok 3.5903 (4.7385)	Learning Rate [0.00125]
1: TRAIN [0][2540/6832]	Time 0.093 (0.105)	Data 0.00093 (0.00093)	Tok/s 54463 (59378)	Loss/tok 3.7186 (4.7439)	Learning Rate [0.00125]
3: TRAIN [0][2540/6832]	Time 0.093 (0.105)	Data 0.00088 (0.00096)	Tok/s 55244 (60182)	Loss/tok 3.8184 (4.7438)	Learning Rate [0.00125]
0: TRAIN [0][2540/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00095)	Tok/s 53862 (58929)	Loss/tok 3.7356 (4.7442)	Learning Rate [0.00125]
1: TRAIN [0][2550/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00093)	Tok/s 88078 (59375)	Loss/tok 3.7746 (4.7401)	Learning Rate [0.00125]
0: TRAIN [0][2550/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00095)	Tok/s 87374 (58927)	Loss/tok 3.9534 (4.7407)	Learning Rate [0.00125]
2: TRAIN [0][2550/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00096)	Tok/s 88688 (59739)	Loss/tok 3.7806 (4.7347)	Learning Rate [0.00125]
3: TRAIN [0][2550/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00096)	Tok/s 89435 (60178)	Loss/tok 3.6816 (4.7402)	Learning Rate [0.00125]
1: Gradient norm: inf
0: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
2: Gradient norm: inf
3: Gradient norm: inf
3: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
2: TRAIN [0][2560/6832]	Time 0.124 (0.105)	Data 0.00104 (0.00096)	Tok/s 61971 (59739)	Loss/tok 3.9808 (4.7310)	Learning Rate [0.00125]
3: TRAIN [0][2560/6832]	Time 0.124 (0.105)	Data 0.00094 (0.00096)	Tok/s 61952 (60179)	Loss/tok 3.8795 (4.7364)	Learning Rate [0.00125]
1: TRAIN [0][2560/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00093)	Tok/s 61480 (59375)	Loss/tok 3.8511 (4.7365)	Learning Rate [0.00125]
0: TRAIN [0][2560/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00095)	Tok/s 60809 (58928)	Loss/tok 3.8568 (4.7370)	Learning Rate [0.00125]
2: TRAIN [0][2570/6832]	Time 0.124 (0.105)	Data 0.00097 (0.00096)	Tok/s 52775 (59744)	Loss/tok 3.4098 (4.7270)	Learning Rate [0.00125]
3: TRAIN [0][2570/6832]	Time 0.123 (0.105)	Data 0.00094 (0.00096)	Tok/s 52861 (60184)	Loss/tok 3.8326 (4.7323)	Learning Rate [0.00125]
1: TRAIN [0][2570/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00093)	Tok/s 51756 (59381)	Loss/tok 3.7153 (4.7326)	Learning Rate [0.00125]
0: TRAIN [0][2570/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00095)	Tok/s 51747 (58934)	Loss/tok 3.6770 (4.7332)	Learning Rate [0.00125]
2: TRAIN [0][2580/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00096)	Tok/s 51665 (59742)	Loss/tok 3.5298 (4.7234)	Learning Rate [0.00125]
1: TRAIN [0][2580/6832]	Time 0.077 (0.105)	Data 0.00090 (0.00093)	Tok/s 51623 (59377)	Loss/tok 3.4111 (4.7291)	Learning Rate [0.00125]
0: TRAIN [0][2580/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00095)	Tok/s 51654 (58932)	Loss/tok 3.5845 (4.7297)	Learning Rate [0.00125]
3: TRAIN [0][2580/6832]	Time 0.077 (0.105)	Data 0.00090 (0.00096)	Tok/s 53172 (60182)	Loss/tok 3.6860 (4.7289)	Learning Rate [0.00125]
1: TRAIN [0][2590/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00093)	Tok/s 77896 (59388)	Loss/tok 3.9563 (4.7253)	Learning Rate [0.00125]
0: TRAIN [0][2590/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00095)	Tok/s 77930 (58937)	Loss/tok 3.6979 (4.7255)	Learning Rate [0.00125]
3: TRAIN [0][2590/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 78847 (60197)	Loss/tok 3.7338 (4.7248)	Learning Rate [0.00125]
2: TRAIN [0][2590/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00096)	Tok/s 78638 (59755)	Loss/tok 3.8613 (4.7195)	Learning Rate [0.00125]
1: TRAIN [0][2600/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00093)	Tok/s 54307 (59384)	Loss/tok 3.6123 (4.7220)	Learning Rate [0.00125]
0: TRAIN [0][2600/6832]	Time 0.077 (0.105)	Data 0.00094 (0.00095)	Tok/s 53330 (58934)	Loss/tok 3.6152 (4.7221)	Learning Rate [0.00125]
2: TRAIN [0][2600/6832]	Time 0.077 (0.105)	Data 0.00092 (0.00096)	Tok/s 54925 (59752)	Loss/tok 3.6179 (4.7160)	Learning Rate [0.00125]
3: TRAIN [0][2600/6832]	Time 0.077 (0.105)	Data 0.00087 (0.00096)	Tok/s 54923 (60195)	Loss/tok 3.6592 (4.7213)	Learning Rate [0.00125]
1: TRAIN [0][2610/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 77882 (59394)	Loss/tok 3.7016 (4.7184)	Learning Rate [0.00125]
0: TRAIN [0][2610/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 77665 (58944)	Loss/tok 3.8159 (4.7181)	Learning Rate [0.00125]
2: TRAIN [0][2610/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 78203 (59761)	Loss/tok 3.7824 (4.7121)	Learning Rate [0.00125]
3: TRAIN [0][2610/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 78833 (60204)	Loss/tok 3.9599 (4.7178)	Learning Rate [0.00125]
2: TRAIN [0][2620/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 70760 (59756)	Loss/tok 3.8221 (4.7086)	Learning Rate [0.00125]
3: TRAIN [0][2620/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00096)	Tok/s 71290 (60199)	Loss/tok 3.8095 (4.7141)	Learning Rate [0.00125]
0: TRAIN [0][2620/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00095)	Tok/s 70340 (58939)	Loss/tok 4.0517 (4.7146)	Learning Rate [0.00125]
1: TRAIN [0][2620/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00093)	Tok/s 70327 (59388)	Loss/tok 4.0555 (4.7152)	Learning Rate [0.00125]
2: TRAIN [0][2630/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00096)	Tok/s 75656 (59770)	Loss/tok 3.9327 (4.7046)	Learning Rate [0.00125]
1: TRAIN [0][2630/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00093)	Tok/s 75159 (59401)	Loss/tok 3.9383 (4.7115)	Learning Rate [0.00125]
0: TRAIN [0][2630/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 75194 (58953)	Loss/tok 3.8739 (4.7107)	Learning Rate [0.00125]
3: TRAIN [0][2630/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00096)	Tok/s 76162 (60212)	Loss/tok 3.9051 (4.7103)	Learning Rate [0.00125]
2: TRAIN [0][2640/6832]	Time 0.088 (0.105)	Data 0.00098 (0.00096)	Tok/s 53883 (59793)	Loss/tok 3.7287 (4.7006)	Learning Rate [0.00125]
1: TRAIN [0][2640/6832]	Time 0.088 (0.105)	Data 0.00091 (0.00093)	Tok/s 53838 (59425)	Loss/tok 3.8086 (4.7075)	Learning Rate [0.00125]
3: TRAIN [0][2640/6832]	Time 0.088 (0.105)	Data 0.00097 (0.00096)	Tok/s 53871 (60235)	Loss/tok 3.8065 (4.7064)	Learning Rate [0.00125]
0: TRAIN [0][2640/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00095)	Tok/s 53311 (58975)	Loss/tok 3.5301 (4.7067)	Learning Rate [0.00125]
2: TRAIN [0][2650/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00096)	Tok/s 52441 (59798)	Loss/tok 3.7520 (4.6967)	Learning Rate [0.00125]
3: TRAIN [0][2650/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00096)	Tok/s 52448 (60240)	Loss/tok 3.6501 (4.7025)	Learning Rate [0.00125]
0: TRAIN [0][2650/6832]	Time 0.112 (0.105)	Data 0.00093 (0.00095)	Tok/s 51502 (58979)	Loss/tok 3.7491 (4.7032)	Learning Rate [0.00125]
1: TRAIN [0][2650/6832]	Time 0.112 (0.105)	Data 0.00097 (0.00093)	Tok/s 52449 (59429)	Loss/tok 3.6757 (4.7036)	Learning Rate [0.00125]
1: TRAIN [0][2660/6832]	Time 0.110 (0.105)	Data 0.00093 (0.00093)	Tok/s 53738 (59413)	Loss/tok 3.7454 (4.7005)	Learning Rate [0.00125]
2: TRAIN [0][2660/6832]	Time 0.110 (0.105)	Data 0.00085 (0.00096)	Tok/s 53706 (59782)	Loss/tok 3.7601 (4.6936)	Learning Rate [0.00125]
0: TRAIN [0][2660/6832]	Time 0.110 (0.105)	Data 0.00092 (0.00095)	Tok/s 53715 (58964)	Loss/tok 3.8386 (4.7000)	Learning Rate [0.00125]
3: TRAIN [0][2660/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00096)	Tok/s 54720 (60223)	Loss/tok 3.8012 (4.6993)	Learning Rate [0.00125]
3: TRAIN [0][2670/6832]	Time 0.064 (0.105)	Data 0.00094 (0.00096)	Tok/s 50006 (60200)	Loss/tok 3.2700 (4.6961)	Learning Rate [0.00125]
2: TRAIN [0][2670/6832]	Time 0.064 (0.105)	Data 0.00096 (0.00096)	Tok/s 48643 (59759)	Loss/tok 3.1885 (4.6906)	Learning Rate [0.00125]
1: TRAIN [0][2670/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00093)	Tok/s 47948 (59390)	Loss/tok 3.2839 (4.6975)	Learning Rate [0.00125]
0: TRAIN [0][2670/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00095)	Tok/s 47958 (58942)	Loss/tok 3.3968 (4.6970)	Learning Rate [0.00125]
1: TRAIN [0][2680/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00093)	Tok/s 60323 (59376)	Loss/tok 3.9658 (4.6944)	Learning Rate [0.00125]
0: TRAIN [0][2680/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00095)	Tok/s 59586 (58928)	Loss/tok 3.7144 (4.6937)	Learning Rate [0.00125]
3: TRAIN [0][2680/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00096)	Tok/s 60226 (60183)	Loss/tok 3.9269 (4.6930)	Learning Rate [0.00125]
2: TRAIN [0][2680/6832]	Time 0.119 (0.105)	Data 0.00099 (0.00096)	Tok/s 60207 (59743)	Loss/tok 3.9612 (4.6876)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
3: TRAIN [0][2690/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 75188 (60186)	Loss/tok 3.8414 (4.6898)	Learning Rate [0.00125]
2: TRAIN [0][2690/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 74338 (59745)	Loss/tok 4.0075 (4.6840)	Learning Rate [0.00125]
0: TRAIN [0][2690/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 74207 (58925)	Loss/tok 3.9644 (4.6905)	Learning Rate [0.00125]
1: TRAIN [0][2690/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 74318 (59376)	Loss/tok 3.8465 (4.6908)	Learning Rate [0.00125]
1: TRAIN [0][2700/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00093)	Tok/s 83487 (59385)	Loss/tok 3.8499 (4.6874)	Learning Rate [0.00125]
0: TRAIN [0][2700/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00095)	Tok/s 82609 (58935)	Loss/tok 3.8003 (4.6870)	Learning Rate [0.00125]
3: TRAIN [0][2700/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00096)	Tok/s 84503 (60194)	Loss/tok 3.8199 (4.6864)	Learning Rate [0.00125]
2: TRAIN [0][2700/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00096)	Tok/s 83624 (59753)	Loss/tok 3.8417 (4.6807)	Learning Rate [0.00125]
1: TRAIN [0][2710/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00093)	Tok/s 66589 (59386)	Loss/tok 3.9919 (4.6839)	Learning Rate [0.00125]
3: TRAIN [0][2710/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00096)	Tok/s 66577 (60194)	Loss/tok 3.9601 (4.6828)	Learning Rate [0.00125]
0: TRAIN [0][2710/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 66126 (58936)	Loss/tok 3.8937 (4.6838)	Learning Rate [0.00125]
2: TRAIN [0][2710/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 66544 (59754)	Loss/tok 4.0568 (4.6775)	Learning Rate [0.00125]
2: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
2: TRAIN [0][2720/6832]	Time 0.077 (0.105)	Data 0.00094 (0.00096)	Tok/s 53231 (59762)	Loss/tok 3.4716 (4.6737)	Learning Rate [0.00125]
1: TRAIN [0][2720/6832]	Time 0.078 (0.105)	Data 0.00095 (0.00093)	Tok/s 52787 (59394)	Loss/tok 3.5226 (4.6803)	Learning Rate [0.00125]
3: TRAIN [0][2720/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00096)	Tok/s 52809 (60202)	Loss/tok 3.7143 (4.6791)	Learning Rate [0.00125]
0: TRAIN [0][2720/6832]	Time 0.078 (0.105)	Data 0.00094 (0.00095)	Tok/s 52817 (58944)	Loss/tok 3.4405 (4.6802)	Learning Rate [0.00125]
2: TRAIN [0][2730/6832]	Time 0.056 (0.105)	Data 0.00092 (0.00096)	Tok/s 50155 (59769)	Loss/tok 3.2448 (4.6703)	Learning Rate [0.00125]
3: TRAIN [0][2730/6832]	Time 0.056 (0.105)	Data 0.00091 (0.00096)	Tok/s 52183 (60210)	Loss/tok 3.3885 (4.6753)	Learning Rate [0.00125]
0: TRAIN [0][2730/6832]	Time 0.056 (0.105)	Data 0.00098 (0.00095)	Tok/s 49841 (58952)	Loss/tok 3.1624 (4.6766)	Learning Rate [0.00125]
1: TRAIN [0][2730/6832]	Time 0.056 (0.105)	Data 0.00099 (0.00093)	Tok/s 50089 (59401)	Loss/tok 3.2507 (4.6768)	Learning Rate [0.00125]
1: TRAIN [0][2740/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00093)	Tok/s 53889 (59400)	Loss/tok 3.6365 (4.6733)	Learning Rate [0.00125]
0: TRAIN [0][2740/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00095)	Tok/s 53884 (58951)	Loss/tok 3.6703 (4.6730)	Learning Rate [0.00125]
3: TRAIN [0][2740/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00096)	Tok/s 54735 (60207)	Loss/tok 3.7663 (4.6717)	Learning Rate [0.00125]
2: TRAIN [0][2740/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00096)	Tok/s 53841 (59768)	Loss/tok 3.7516 (4.6669)	Learning Rate [0.00125]
0: TRAIN [0][2750/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 80485 (58975)	Loss/tok 3.7467 (4.6690)	Learning Rate [0.00125]
1: TRAIN [0][2750/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00093)	Tok/s 81191 (59424)	Loss/tok 3.7384 (4.6693)	Learning Rate [0.00125]
2: TRAIN [0][2750/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00096)	Tok/s 81402 (59791)	Loss/tok 3.7671 (4.6630)	Learning Rate [0.00125]
3: TRAIN [0][2750/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 82149 (60230)	Loss/tok 3.8159 (4.6679)	Learning Rate [0.00125]
1: TRAIN [0][2760/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00093)	Tok/s 78479 (59436)	Loss/tok 3.8430 (4.6657)	Learning Rate [0.00125]
3: TRAIN [0][2760/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 79501 (60243)	Loss/tok 3.8236 (4.6643)	Learning Rate [0.00125]
0: TRAIN [0][2760/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 78499 (58988)	Loss/tok 3.7248 (4.6652)	Learning Rate [0.00125]
2: TRAIN [0][2760/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 79336 (59804)	Loss/tok 3.8847 (4.6594)	Learning Rate [0.00125]
2: TRAIN [0][2770/6832]	Time 0.053 (0.105)	Data 0.00093 (0.00096)	Tok/s 50763 (59814)	Loss/tok 3.0993 (4.6562)	Learning Rate [0.00125]
1: TRAIN [0][2770/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00093)	Tok/s 49683 (59447)	Loss/tok 3.1002 (4.6624)	Learning Rate [0.00125]
3: TRAIN [0][2770/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00096)	Tok/s 50707 (60253)	Loss/tok 3.0975 (4.6607)	Learning Rate [0.00125]
0: TRAIN [0][2770/6832]	Time 0.053 (0.105)	Data 0.00091 (0.00095)	Tok/s 48290 (58999)	Loss/tok 3.1970 (4.6617)	Learning Rate [0.00125]
2: TRAIN [0][2780/6832]	Time 0.059 (0.105)	Data 0.00087 (0.00096)	Tok/s 51875 (59793)	Loss/tok 3.4147 (4.6536)	Learning Rate [0.00125]
1: TRAIN [0][2780/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00093)	Tok/s 51873 (59427)	Loss/tok 3.4021 (4.6595)	Learning Rate [0.00125]
3: TRAIN [0][2780/6832]	Time 0.059 (0.105)	Data 0.00085 (0.00096)	Tok/s 53264 (60233)	Loss/tok 3.1890 (4.6578)	Learning Rate [0.00125]
0: TRAIN [0][2780/6832]	Time 0.059 (0.105)	Data 0.00090 (0.00095)	Tok/s 51873 (58981)	Loss/tok 3.1938 (4.6590)	Learning Rate [0.00125]
1: TRAIN [0][2790/6832]	Time 0.094 (0.105)	Data 0.00090 (0.00093)	Tok/s 54337 (59434)	Loss/tok 3.6411 (4.6561)	Learning Rate [0.00125]
0: TRAIN [0][2790/6832]	Time 0.094 (0.105)	Data 0.00091 (0.00095)	Tok/s 52994 (58988)	Loss/tok 3.7703 (4.6555)	Learning Rate [0.00125]
3: TRAIN [0][2790/6832]	Time 0.094 (0.105)	Data 0.00092 (0.00096)	Tok/s 54384 (60239)	Loss/tok 3.6568 (4.6545)	Learning Rate [0.00125]
2: TRAIN [0][2790/6832]	Time 0.094 (0.105)	Data 0.00096 (0.00096)	Tok/s 54375 (59800)	Loss/tok 3.7085 (4.6503)	Learning Rate [0.00125]
2: TRAIN [0][2800/6832]	Time 0.061 (0.105)	Data 0.00105 (0.00096)	Tok/s 49103 (59798)	Loss/tok 3.2916 (4.6468)	Learning Rate [0.00125]
3: TRAIN [0][2800/6832]	Time 0.061 (0.105)	Data 0.00103 (0.00096)	Tok/s 50554 (60237)	Loss/tok 3.2832 (4.6512)	Learning Rate [0.00125]
0: TRAIN [0][2800/6832]	Time 0.061 (0.105)	Data 0.00094 (0.00095)	Tok/s 48327 (58986)	Loss/tok 3.2126 (4.6524)	Learning Rate [0.00125]
1: TRAIN [0][2800/6832]	Time 0.061 (0.105)	Data 0.00090 (0.00093)	Tok/s 48287 (59432)	Loss/tok 3.1652 (4.6529)	Learning Rate [0.00125]
1: TRAIN [0][2810/6832]	Time 0.064 (0.105)	Data 0.00096 (0.00093)	Tok/s 47700 (59428)	Loss/tok 3.3536 (4.6496)	Learning Rate [0.00125]
2: TRAIN [0][2810/6832]	Time 0.064 (0.105)	Data 0.00096 (0.00096)	Tok/s 47929 (59795)	Loss/tok 3.3851 (4.6438)	Learning Rate [0.00125]
0: TRAIN [0][2810/6832]	Time 0.064 (0.105)	Data 0.00092 (0.00095)	Tok/s 47650 (58983)	Loss/tok 3.2317 (4.6491)	Learning Rate [0.00125]
3: TRAIN [0][2810/6832]	Time 0.064 (0.105)	Data 0.00093 (0.00096)	Tok/s 49616 (60234)	Loss/tok 3.3263 (4.6480)	Learning Rate [0.00125]
1: TRAIN [0][2820/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00093)	Tok/s 52557 (59426)	Loss/tok 3.2218 (4.6466)	Learning Rate [0.00125]
2: TRAIN [0][2820/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00096)	Tok/s 52984 (59792)	Loss/tok 3.4296 (4.6407)	Learning Rate [0.00125]
3: TRAIN [0][2820/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00096)	Tok/s 54340 (60232)	Loss/tok 3.4627 (4.6448)	Learning Rate [0.00125]
0: TRAIN [0][2820/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00095)	Tok/s 52558 (58981)	Loss/tok 3.4333 (4.6461)	Learning Rate [0.00125]
2: TRAIN [0][2830/6832]	Time 0.099 (0.105)	Data 0.00087 (0.00096)	Tok/s 54266 (59777)	Loss/tok 3.6279 (4.6378)	Learning Rate [0.00125]
1: TRAIN [0][2830/6832]	Time 0.099 (0.105)	Data 0.00089 (0.00093)	Tok/s 54195 (59411)	Loss/tok 3.6529 (4.6436)	Learning Rate [0.00125]
3: TRAIN [0][2830/6832]	Time 0.099 (0.105)	Data 0.00089 (0.00096)	Tok/s 54270 (60217)	Loss/tok 3.5651 (4.6420)	Learning Rate [0.00125]
0: TRAIN [0][2830/6832]	Time 0.099 (0.105)	Data 0.00089 (0.00095)	Tok/s 54210 (58967)	Loss/tok 3.6363 (4.6431)	Learning Rate [0.00125]
2: TRAIN [0][2840/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00096)	Tok/s 63623 (59773)	Loss/tok 3.7288 (4.6346)	Learning Rate [0.00125]
1: TRAIN [0][2840/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00093)	Tok/s 63610 (59407)	Loss/tok 4.0934 (4.6406)	Learning Rate [0.00125]
3: TRAIN [0][2840/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00096)	Tok/s 64021 (60213)	Loss/tok 3.8774 (4.6389)	Learning Rate [0.00125]
0: TRAIN [0][2840/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00095)	Tok/s 63622 (58965)	Loss/tok 3.7568 (4.6399)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
2: TRAIN [0][2850/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00096)	Tok/s 55831 (59783)	Loss/tok 3.9367 (4.6313)	Learning Rate [0.00125]
1: TRAIN [0][2850/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00093)	Tok/s 54870 (59417)	Loss/tok 3.9111 (4.6374)	Learning Rate [0.00125]
3: TRAIN [0][2850/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00096)	Tok/s 55829 (60223)	Loss/tok 3.9687 (4.6355)	Learning Rate [0.00125]
0: TRAIN [0][2850/6832]	Time 0.121 (0.105)	Data 0.00102 (0.00095)	Tok/s 54782 (58976)	Loss/tok 3.6398 (4.6362)	Learning Rate [0.00125]
1: TRAIN [0][2860/6832]	Time 0.123 (0.105)	Data 0.00092 (0.00093)	Tok/s 53093 (59416)	Loss/tok 3.6717 (4.6343)	Learning Rate [0.00125]
2: TRAIN [0][2860/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00096)	Tok/s 53063 (59782)	Loss/tok 3.8349 (4.6282)	Learning Rate [0.00125]
3: TRAIN [0][2860/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00096)	Tok/s 53315 (60221)	Loss/tok 3.8016 (4.6324)	Learning Rate [0.00125]
0: TRAIN [0][2860/6832]	Time 0.123 (0.105)	Data 0.00102 (0.00095)	Tok/s 53090 (58976)	Loss/tok 3.6739 (4.6332)	Learning Rate [0.00125]
1: TRAIN [0][2870/6832]	Time 0.085 (0.105)	Data 0.00086 (0.00093)	Tok/s 52581 (59415)	Loss/tok 3.5836 (4.6311)	Learning Rate [0.00125]
2: TRAIN [0][2870/6832]	Time 0.085 (0.105)	Data 0.00093 (0.00096)	Tok/s 52902 (59781)	Loss/tok 3.4802 (4.6251)	Learning Rate [0.00125]
3: TRAIN [0][2870/6832]	Time 0.085 (0.105)	Data 0.00084 (0.00096)	Tok/s 52567 (60220)	Loss/tok 3.7538 (4.6296)	Learning Rate [0.00125]
0: TRAIN [0][2870/6832]	Time 0.085 (0.105)	Data 0.00098 (0.00095)	Tok/s 52232 (58976)	Loss/tok 3.6553 (4.6302)	Learning Rate [0.00125]
1: TRAIN [0][2880/6832]	Time 0.058 (0.105)	Data 0.00086 (0.00093)	Tok/s 48732 (59395)	Loss/tok 3.0544 (4.6283)	Learning Rate [0.00125]
2: TRAIN [0][2880/6832]	Time 0.058 (0.105)	Data 0.00086 (0.00096)	Tok/s 48704 (59761)	Loss/tok 3.0290 (4.6224)	Learning Rate [0.00125]
3: TRAIN [0][2880/6832]	Time 0.058 (0.105)	Data 0.00085 (0.00096)	Tok/s 49993 (60199)	Loss/tok 3.0001 (4.6269)	Learning Rate [0.00125]
0: TRAIN [0][2880/6832]	Time 0.058 (0.105)	Data 0.00098 (0.00095)	Tok/s 48325 (58956)	Loss/tok 3.1460 (4.6274)	Learning Rate [0.00125]
1: TRAIN [0][2890/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00093)	Tok/s 71960 (59400)	Loss/tok 3.8635 (4.6251)	Learning Rate [0.00125]
2: TRAIN [0][2890/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00096)	Tok/s 72836 (59767)	Loss/tok 3.8585 (4.6193)	Learning Rate [0.00125]
3: TRAIN [0][2890/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 72849 (60204)	Loss/tok 3.7890 (4.6238)	Learning Rate [0.00125]
0: TRAIN [0][2890/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00095)	Tok/s 71831 (58961)	Loss/tok 3.6336 (4.6241)	Learning Rate [0.00125]
2: TRAIN [0][2900/6832]	Time 0.084 (0.105)	Data 0.00091 (0.00096)	Tok/s 53553 (59767)	Loss/tok 3.3675 (4.6161)	Learning Rate [0.00125]
3: TRAIN [0][2900/6832]	Time 0.084 (0.105)	Data 0.00091 (0.00096)	Tok/s 53536 (60203)	Loss/tok 3.6341 (4.6208)	Learning Rate [0.00125]
1: TRAIN [0][2900/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00093)	Tok/s 53450 (59401)	Loss/tok 3.4785 (4.6220)	Learning Rate [0.00125]
0: TRAIN [0][2900/6832]	Time 0.084 (0.105)	Data 0.00104 (0.00095)	Tok/s 52705 (58961)	Loss/tok 3.5140 (4.6209)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
1: TRAIN [0][2910/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00093)	Tok/s 59732 (59400)	Loss/tok 3.9715 (4.6186)	Learning Rate [0.00125]
2: TRAIN [0][2910/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00096)	Tok/s 60479 (59767)	Loss/tok 3.8602 (4.6130)	Learning Rate [0.00125]
3: TRAIN [0][2910/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00096)	Tok/s 60488 (60203)	Loss/tok 3.8151 (4.6177)	Learning Rate [0.00125]
0: TRAIN [0][2910/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00095)	Tok/s 59523 (58962)	Loss/tok 3.8928 (4.6177)	Learning Rate [0.00125]
1: TRAIN [0][2920/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 69554 (59398)	Loss/tok 4.0235 (4.6157)	Learning Rate [0.00125]
2: TRAIN [0][2920/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00096)	Tok/s 69485 (59763)	Loss/tok 3.9598 (4.6102)	Learning Rate [0.00125]
3: TRAIN [0][2920/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00096)	Tok/s 69938 (60200)	Loss/tok 4.0984 (4.6148)	Learning Rate [0.00125]
0: TRAIN [0][2920/6832]	Time 0.129 (0.105)	Data 0.00103 (0.00095)	Tok/s 69564 (58961)	Loss/tok 3.9060 (4.6149)	Learning Rate [0.00125]
1: TRAIN [0][2930/6832]	Time 0.119 (0.105)	Data 0.00099 (0.00093)	Tok/s 55038 (59385)	Loss/tok 3.6461 (4.6131)	Learning Rate [0.00125]
3: TRAIN [0][2930/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00096)	Tok/s 56101 (60188)	Loss/tok 3.7779 (4.6121)	Learning Rate [0.00125]
2: TRAIN [0][2930/6832]	Time 0.119 (0.105)	Data 0.00101 (0.00096)	Tok/s 55020 (59750)	Loss/tok 3.6813 (4.6075)	Learning Rate [0.00125]
0: TRAIN [0][2930/6832]	Time 0.118 (0.105)	Data 0.00112 (0.00095)	Tok/s 55113 (58950)	Loss/tok 3.8344 (4.6122)	Learning Rate [0.00125]
1: TRAIN [0][2940/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 72982 (59404)	Loss/tok 3.8665 (4.6098)	Learning Rate [0.00125]
3: TRAIN [0][2940/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00096)	Tok/s 73228 (60208)	Loss/tok 3.8813 (4.6088)	Learning Rate [0.00125]
2: TRAIN [0][2940/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00096)	Tok/s 73225 (59769)	Loss/tok 4.0059 (4.6043)	Learning Rate [0.00125]
0: TRAIN [0][2940/6832]	Time 0.129 (0.105)	Data 0.00107 (0.00095)	Tok/s 72294 (58968)	Loss/tok 3.9834 (4.6087)	Learning Rate [0.00125]
1: TRAIN [0][2950/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00093)	Tok/s 67354 (59385)	Loss/tok 3.7830 (4.6072)	Learning Rate [0.00125]
2: TRAIN [0][2950/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00096)	Tok/s 67366 (59751)	Loss/tok 3.9723 (4.6017)	Learning Rate [0.00125]
3: TRAIN [0][2950/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00096)	Tok/s 68335 (60192)	Loss/tok 3.8601 (4.6062)	Learning Rate [0.00125]
0: TRAIN [0][2950/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00095)	Tok/s 67362 (58946)	Loss/tok 4.0004 (4.6064)	Learning Rate [0.00125]
2: TRAIN [0][2960/6832]	Time 0.074 (0.105)	Data 0.00104 (0.00096)	Tok/s 51746 (59743)	Loss/tok 3.3536 (4.5988)	Learning Rate [0.00125]
3: TRAIN [0][2960/6832]	Time 0.074 (0.105)	Data 0.00098 (0.00096)	Tok/s 51766 (60185)	Loss/tok 3.5554 (4.6034)	Learning Rate [0.00125]
1: TRAIN [0][2960/6832]	Time 0.074 (0.105)	Data 0.00092 (0.00093)	Tok/s 51754 (59376)	Loss/tok 3.5303 (4.6045)	Learning Rate [0.00125]
0: TRAIN [0][2960/6832]	Time 0.074 (0.105)	Data 0.00116 (0.00095)	Tok/s 51538 (58936)	Loss/tok 3.5413 (4.6039)	Learning Rate [0.00125]
1: TRAIN [0][2970/6832]	Time 0.053 (0.105)	Data 0.00086 (0.00093)	Tok/s 45812 (59377)	Loss/tok 2.9299 (4.6012)	Learning Rate [0.00125]
2: TRAIN [0][2970/6832]	Time 0.053 (0.105)	Data 0.00087 (0.00096)	Tok/s 46003 (59744)	Loss/tok 2.8060 (4.5957)	Learning Rate [0.00125]
3: TRAIN [0][2970/6832]	Time 0.053 (0.105)	Data 0.00084 (0.00096)	Tok/s 47830 (60187)	Loss/tok 3.0564 (4.6004)	Learning Rate [0.00125]
0: TRAIN [0][2970/6832]	Time 0.053 (0.105)	Data 0.00105 (0.00095)	Tok/s 43570 (58933)	Loss/tok 3.0486 (4.6010)	Learning Rate [0.00125]
1: TRAIN [0][2980/6832]	Time 0.068 (0.105)	Data 0.00088 (0.00093)	Tok/s 50640 (59366)	Loss/tok 3.3558 (4.5985)	Learning Rate [0.00125]
2: TRAIN [0][2980/6832]	Time 0.068 (0.105)	Data 0.00087 (0.00096)	Tok/s 50624 (59733)	Loss/tok 3.4862 (4.5931)	Learning Rate [0.00125]
3: TRAIN [0][2980/6832]	Time 0.068 (0.105)	Data 0.00087 (0.00096)	Tok/s 51926 (60177)	Loss/tok 3.3907 (4.5977)	Learning Rate [0.00125]
0: TRAIN [0][2980/6832]	Time 0.068 (0.105)	Data 0.00105 (0.00095)	Tok/s 50661 (58922)	Loss/tok 3.3291 (4.5983)	Learning Rate [0.00125]
2: TRAIN [0][2990/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00096)	Tok/s 72181 (59751)	Loss/tok 3.8970 (4.5898)	Learning Rate [0.00125]
3: TRAIN [0][2990/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00096)	Tok/s 72174 (60194)	Loss/tok 3.8176 (4.5944)	Learning Rate [0.00125]
1: TRAIN [0][2990/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00093)	Tok/s 71694 (59384)	Loss/tok 3.7740 (4.5951)	Learning Rate [0.00125]
0: TRAIN [0][2990/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00095)	Tok/s 71040 (58940)	Loss/tok 4.1189 (4.5951)	Learning Rate [0.00125]
2: TRAIN [0][3000/6832]	Time 0.108 (0.105)	Data 0.00091 (0.00096)	Tok/s 52131 (59731)	Loss/tok 3.9149 (4.5873)	Learning Rate [0.00125]
1: TRAIN [0][3000/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00093)	Tok/s 52124 (59364)	Loss/tok 3.5939 (4.5927)	Learning Rate [0.00125]
3: TRAIN [0][3000/6832]	Time 0.108 (0.105)	Data 0.00092 (0.00096)	Tok/s 52581 (60173)	Loss/tok 3.7020 (4.5918)	Learning Rate [0.00125]
0: TRAIN [0][3000/6832]	Time 0.108 (0.105)	Data 0.00117 (0.00095)	Tok/s 52131 (58920)	Loss/tok 3.6224 (4.5924)	Learning Rate [0.00125]
1: TRAIN [0][3010/6832]	Time 0.122 (0.105)	Data 0.00103 (0.00093)	Tok/s 55647 (59363)	Loss/tok 3.8067 (4.5896)	Learning Rate [0.00125]
3: TRAIN [0][3010/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00096)	Tok/s 55662 (60172)	Loss/tok 3.6867 (4.5888)	Learning Rate [0.00125]
2: TRAIN [0][3010/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00096)	Tok/s 55653 (59730)	Loss/tok 3.7926 (4.5843)	Learning Rate [0.00125]
0: TRAIN [0][3010/6832]	Time 0.122 (0.105)	Data 0.00104 (0.00095)	Tok/s 55225 (58920)	Loss/tok 3.7679 (4.5895)	Learning Rate [0.00125]
1: TRAIN [0][3020/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00093)	Tok/s 53457 (59378)	Loss/tok 3.3696 (4.5861)	Learning Rate [0.00125]
2: TRAIN [0][3020/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00096)	Tok/s 53585 (59746)	Loss/tok 3.3662 (4.5810)	Learning Rate [0.00125]
3: TRAIN [0][3020/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00096)	Tok/s 53592 (60188)	Loss/tok 3.4045 (4.5858)	Learning Rate [0.00125]
0: TRAIN [0][3020/6832]	Time 0.079 (0.105)	Data 0.00105 (0.00095)	Tok/s 51930 (58935)	Loss/tok 3.4111 (4.5861)	Learning Rate [0.00125]
1: TRAIN [0][3030/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00093)	Tok/s 81945 (59393)	Loss/tok 3.6964 (4.5827)	Learning Rate [0.00125]
3: TRAIN [0][3030/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00096)	Tok/s 82879 (60203)	Loss/tok 3.8026 (4.5825)	Learning Rate [0.00125]
0: TRAIN [0][3030/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00095)	Tok/s 81572 (58950)	Loss/tok 3.6214 (4.5828)	Learning Rate [0.00125]
2: TRAIN [0][3030/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00096)	Tok/s 81271 (59761)	Loss/tok 3.8136 (4.5776)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
1: TRAIN [0][3040/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00093)	Tok/s 73482 (59383)	Loss/tok 3.8240 (4.5802)	Learning Rate [0.00125]
2: TRAIN [0][3040/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00096)	Tok/s 73429 (59754)	Loss/tok 3.8950 (4.5750)	Learning Rate [0.00125]
3: TRAIN [0][3040/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00096)	Tok/s 73711 (60195)	Loss/tok 3.7953 (4.5799)	Learning Rate [0.00125]
0: TRAIN [0][3040/6832]	Time 0.131 (0.105)	Data 0.00108 (0.00095)	Tok/s 72985 (58938)	Loss/tok 3.8756 (4.5803)	Learning Rate [0.00125]
2: TRAIN [0][3050/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00096)	Tok/s 83862 (59745)	Loss/tok 3.6638 (4.5724)	Learning Rate [0.00125]
1: TRAIN [0][3050/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 83774 (59373)	Loss/tok 3.7287 (4.5777)	Learning Rate [0.00125]
3: TRAIN [0][3050/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00096)	Tok/s 84776 (60188)	Loss/tok 3.8962 (4.5774)	Learning Rate [0.00125]
0: TRAIN [0][3050/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00095)	Tok/s 82997 (58924)	Loss/tok 3.7417 (4.5778)	Learning Rate [0.00125]
1: TRAIN [0][3060/6832]	Time 0.062 (0.105)	Data 0.00093 (0.00093)	Tok/s 51873 (59374)	Loss/tok 3.2843 (4.5751)	Learning Rate [0.00125]
2: TRAIN [0][3060/6832]	Time 0.062 (0.105)	Data 0.00094 (0.00096)	Tok/s 51855 (59747)	Loss/tok 3.0796 (4.5695)	Learning Rate [0.00125]
3: TRAIN [0][3060/6832]	Time 0.062 (0.105)	Data 0.00095 (0.00096)	Tok/s 52520 (60189)	Loss/tok 3.2020 (4.5748)	Learning Rate [0.00125]
0: TRAIN [0][3060/6832]	Time 0.062 (0.105)	Data 0.00104 (0.00095)	Tok/s 51906 (58926)	Loss/tok 3.4780 (4.5753)	Learning Rate [0.00125]
2: TRAIN [0][3070/6832]	Time 0.078 (0.105)	Data 0.00102 (0.00096)	Tok/s 53927 (59749)	Loss/tok 3.4114 (4.5668)	Learning Rate [0.00125]
1: TRAIN [0][3070/6832]	Time 0.078 (0.105)	Data 0.00105 (0.00093)	Tok/s 53478 (59377)	Loss/tok 3.5754 (4.5724)	Learning Rate [0.00125]
3: TRAIN [0][3070/6832]	Time 0.078 (0.105)	Data 0.00100 (0.00096)	Tok/s 53958 (60192)	Loss/tok 3.5381 (4.5720)	Learning Rate [0.00125]
0: TRAIN [0][3070/6832]	Time 0.078 (0.105)	Data 0.00109 (0.00095)	Tok/s 52384 (58929)	Loss/tok 3.3999 (4.5726)	Learning Rate [0.00125]
2: TRAIN [0][3080/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00096)	Tok/s 51201 (59751)	Loss/tok 3.7048 (4.5640)	Learning Rate [0.00125]
1: TRAIN [0][3080/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00092)	Tok/s 51161 (59379)	Loss/tok 3.9193 (4.5695)	Learning Rate [0.00125]
3: TRAIN [0][3080/6832]	Time 0.108 (0.105)	Data 0.00093 (0.00096)	Tok/s 51190 (60192)	Loss/tok 3.6395 (4.5691)	Learning Rate [0.00125]
0: TRAIN [0][3080/6832]	Time 0.108 (0.105)	Data 0.00104 (0.00095)	Tok/s 51146 (58931)	Loss/tok 3.7956 (4.5697)	Learning Rate [0.00125]
1: TRAIN [0][3090/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00092)	Tok/s 63847 (59361)	Loss/tok 3.7553 (4.5669)	Learning Rate [0.00125]
2: TRAIN [0][3090/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00096)	Tok/s 63856 (59735)	Loss/tok 3.7147 (4.5614)	Learning Rate [0.00125]
3: TRAIN [0][3090/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 63894 (60177)	Loss/tok 3.6938 (4.5665)	Learning Rate [0.00125]
0: TRAIN [0][3090/6832]	Time 0.128 (0.105)	Data 0.00110 (0.00095)	Tok/s 63852 (58911)	Loss/tok 3.9162 (4.5674)	Learning Rate [0.00125]
1: TRAIN [0][3100/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 65717 (59362)	Loss/tok 4.0054 (4.5641)	Learning Rate [0.00125]
2: TRAIN [0][3100/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00096)	Tok/s 65719 (59735)	Loss/tok 3.8419 (4.5586)	Learning Rate [0.00125]
3: TRAIN [0][3100/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00096)	Tok/s 65745 (60179)	Loss/tok 3.7798 (4.5637)	Learning Rate [0.00125]
0: TRAIN [0][3100/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00095)	Tok/s 65528 (58911)	Loss/tok 3.7713 (4.5644)	Learning Rate [0.00125]
1: TRAIN [0][3110/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00092)	Tok/s 70230 (59359)	Loss/tok 3.9772 (4.5615)	Learning Rate [0.00125]
2: TRAIN [0][3110/6832]	Time 0.128 (0.105)	Data 0.00104 (0.00096)	Tok/s 70171 (59732)	Loss/tok 3.7932 (4.5558)	Learning Rate [0.00125]
3: TRAIN [0][3110/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00096)	Tok/s 71157 (60176)	Loss/tok 3.7891 (4.5612)	Learning Rate [0.00125]
0: TRAIN [0][3110/6832]	Time 0.128 (0.105)	Data 0.00103 (0.00095)	Tok/s 70208 (58908)	Loss/tok 3.9321 (4.5619)	Learning Rate [0.00125]
1: TRAIN [0][3120/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00092)	Tok/s 70249 (59348)	Loss/tok 3.8604 (4.5592)	Learning Rate [0.00125]
3: TRAIN [0][3120/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00096)	Tok/s 71319 (60167)	Loss/tok 3.8771 (4.5589)	Learning Rate [0.00125]
2: TRAIN [0][3120/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00096)	Tok/s 70442 (59722)	Loss/tok 4.0099 (4.5535)	Learning Rate [0.00125]
0: TRAIN [0][3120/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00095)	Tok/s 70292 (58897)	Loss/tok 3.6091 (4.5593)	Learning Rate [0.00125]
1: TRAIN [0][3130/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00092)	Tok/s 91124 (59354)	Loss/tok 3.6203 (4.5561)	Learning Rate [0.00125]
2: TRAIN [0][3130/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00096)	Tok/s 92443 (59727)	Loss/tok 3.6023 (4.5506)	Learning Rate [0.00125]
3: TRAIN [0][3130/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 94289 (60172)	Loss/tok 3.6027 (4.5560)	Learning Rate [0.00125]
0: TRAIN [0][3130/6832]	Time 0.132 (0.105)	Data 0.00109 (0.00095)	Tok/s 90158 (58904)	Loss/tok 3.5463 (4.5564)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
1: TRAIN [0][3140/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00092)	Tok/s 54274 (59357)	Loss/tok 3.6201 (4.5532)	Learning Rate [0.00125]
2: TRAIN [0][3140/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00096)	Tok/s 54288 (59729)	Loss/tok 3.6379 (4.5480)	Learning Rate [0.00125]
3: TRAIN [0][3140/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00096)	Tok/s 54287 (60174)	Loss/tok 3.7588 (4.5534)	Learning Rate [0.00125]
0: TRAIN [0][3140/6832]	Time 0.123 (0.105)	Data 0.00102 (0.00095)	Tok/s 54270 (58908)	Loss/tok 3.5877 (4.5537)	Learning Rate [0.00125]
1: TRAIN [0][3150/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00092)	Tok/s 49868 (59355)	Loss/tok 3.5796 (4.5505)	Learning Rate [0.00125]
2: TRAIN [0][3150/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00096)	Tok/s 49912 (59729)	Loss/tok 3.9125 (4.5452)	Learning Rate [0.00125]
3: TRAIN [0][3150/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00096)	Tok/s 49900 (60175)	Loss/tok 3.7039 (4.5505)	Learning Rate [0.00125]
0: TRAIN [0][3150/6832]	Time 0.121 (0.105)	Data 0.00104 (0.00095)	Tok/s 49863 (58903)	Loss/tok 3.7924 (4.5511)	Learning Rate [0.00125]
2: TRAIN [0][3160/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00096)	Tok/s 55526 (59732)	Loss/tok 3.6513 (4.5423)	Learning Rate [0.00125]
1: TRAIN [0][3160/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00092)	Tok/s 55374 (59359)	Loss/tok 3.7223 (4.5478)	Learning Rate [0.00125]
3: TRAIN [0][3160/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00096)	Tok/s 55526 (60177)	Loss/tok 3.7551 (4.5480)	Learning Rate [0.00125]
0: TRAIN [0][3160/6832]	Time 0.115 (0.105)	Data 0.00105 (0.00095)	Tok/s 54414 (58906)	Loss/tok 3.7598 (4.5484)	Learning Rate [0.00125]
1: TRAIN [0][3170/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00092)	Tok/s 50281 (59360)	Loss/tok 3.1542 (4.5451)	Learning Rate [0.00125]
2: TRAIN [0][3170/6832]	Time 0.059 (0.105)	Data 0.00097 (0.00096)	Tok/s 50277 (59732)	Loss/tok 3.1527 (4.5398)	Learning Rate [0.00125]
3: TRAIN [0][3170/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00096)	Tok/s 51624 (60178)	Loss/tok 3.3016 (4.5457)	Learning Rate [0.00125]
0: TRAIN [0][3170/6832]	Time 0.059 (0.105)	Data 0.00103 (0.00095)	Tok/s 50269 (58908)	Loss/tok 3.0685 (4.5457)	Learning Rate [0.00125]
1: TRAIN [0][3180/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00092)	Tok/s 51677 (59363)	Loss/tok 3.3323 (4.5423)	Learning Rate [0.00125]
2: TRAIN [0][3180/6832]	Time 0.089 (0.105)	Data 0.00085 (0.00096)	Tok/s 51830 (59736)	Loss/tok 3.6662 (4.5370)	Learning Rate [0.00125]
3: TRAIN [0][3180/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00096)	Tok/s 53161 (60182)	Loss/tok 3.5549 (4.5428)	Learning Rate [0.00125]
0: TRAIN [0][3180/6832]	Time 0.089 (0.105)	Data 0.00106 (0.00096)	Tok/s 51722 (58912)	Loss/tok 3.5177 (4.5428)	Learning Rate [0.00125]
1: TRAIN [0][3190/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00092)	Tok/s 51181 (59346)	Loss/tok 3.4069 (4.5400)	Learning Rate [0.00125]
2: TRAIN [0][3190/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00096)	Tok/s 51198 (59718)	Loss/tok 3.7397 (4.5349)	Learning Rate [0.00125]
3: TRAIN [0][3190/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00096)	Tok/s 51210 (60165)	Loss/tok 3.8971 (4.5405)	Learning Rate [0.00125]
0: TRAIN [0][3190/6832]	Time 0.118 (0.105)	Data 0.00106 (0.00096)	Tok/s 51150 (58896)	Loss/tok 3.6321 (4.5405)	Learning Rate [0.00125]
1: TRAIN [0][3200/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 63167 (59355)	Loss/tok 3.7245 (4.5372)	Learning Rate [0.00125]
2: TRAIN [0][3200/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00096)	Tok/s 63170 (59727)	Loss/tok 3.8703 (4.5321)	Learning Rate [0.00125]
3: TRAIN [0][3200/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00096)	Tok/s 63150 (60174)	Loss/tok 3.7891 (4.5380)	Learning Rate [0.00125]
0: TRAIN [0][3200/6832]	Time 0.130 (0.105)	Data 0.00106 (0.00096)	Tok/s 63231 (58907)	Loss/tok 3.8218 (4.5379)	Learning Rate [0.00125]
1: TRAIN [0][3210/6832]	Time 0.102 (0.105)	Data 0.00092 (0.00092)	Tok/s 53714 (59334)	Loss/tok 3.6634 (4.5350)	Learning Rate [0.00125]
2: TRAIN [0][3210/6832]	Time 0.102 (0.105)	Data 0.00090 (0.00096)	Tok/s 54163 (59705)	Loss/tok 3.7538 (4.5300)	Learning Rate [0.00125]
3: TRAIN [0][3210/6832]	Time 0.102 (0.105)	Data 0.00088 (0.00096)	Tok/s 54523 (60152)	Loss/tok 3.6795 (4.5357)	Learning Rate [0.00125]
0: TRAIN [0][3210/6832]	Time 0.102 (0.105)	Data 0.00109 (0.00096)	Tok/s 52889 (58886)	Loss/tok 3.5694 (4.5356)	Learning Rate [0.00125]
1: TRAIN [0][3220/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00092)	Tok/s 54190 (59326)	Loss/tok 3.4975 (4.5325)	Learning Rate [0.00125]
2: TRAIN [0][3220/6832]	Time 0.090 (0.105)	Data 0.00095 (0.00096)	Tok/s 54147 (59696)	Loss/tok 3.5447 (4.5278)	Learning Rate [0.00125]
3: TRAIN [0][3220/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00096)	Tok/s 54209 (60143)	Loss/tok 3.5699 (4.5334)	Learning Rate [0.00125]
0: TRAIN [0][3220/6832]	Time 0.090 (0.105)	Data 0.00107 (0.00096)	Tok/s 54201 (58879)	Loss/tok 3.6844 (4.5334)	Learning Rate [0.00125]
1: TRAIN [0][3230/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00092)	Tok/s 74619 (59330)	Loss/tok 3.8686 (4.5299)	Learning Rate [0.00125]
2: TRAIN [0][3230/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 74717 (59701)	Loss/tok 3.8301 (4.5251)	Learning Rate [0.00125]
3: TRAIN [0][3230/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 75678 (60147)	Loss/tok 3.8120 (4.5308)	Learning Rate [0.00125]
0: TRAIN [0][3230/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00096)	Tok/s 74382 (58884)	Loss/tok 3.7828 (4.5307)	Learning Rate [0.00125]
1: TRAIN [0][3240/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00092)	Tok/s 61132 (59335)	Loss/tok 3.9432 (4.5273)	Learning Rate [0.00125]
2: TRAIN [0][3240/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00096)	Tok/s 61751 (59706)	Loss/tok 3.9239 (4.5225)	Learning Rate [0.00125]
3: TRAIN [0][3240/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00096)	Tok/s 62113 (60152)	Loss/tok 3.8778 (4.5279)	Learning Rate [0.00125]
0: TRAIN [0][3240/6832]	Time 0.128 (0.105)	Data 0.00115 (0.00096)	Tok/s 61102 (58890)	Loss/tok 3.7748 (4.5279)	Learning Rate [0.00125]
1: TRAIN [0][3250/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00092)	Tok/s 59829 (59352)	Loss/tok 3.9145 (4.5245)	Learning Rate [0.00125]
2: TRAIN [0][3250/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00096)	Tok/s 59998 (59723)	Loss/tok 3.8823 (4.5197)	Learning Rate [0.00125]
3: TRAIN [0][3250/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00096)	Tok/s 60856 (60169)	Loss/tok 3.8957 (4.5251)	Learning Rate [0.00125]
0: TRAIN [0][3250/6832]	Time 0.122 (0.105)	Data 0.00104 (0.00096)	Tok/s 59838 (58908)	Loss/tok 3.9119 (4.5252)	Learning Rate [0.00125]
2: TRAIN [0][3260/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00096)	Tok/s 86227 (59720)	Loss/tok 3.7247 (4.5173)	Learning Rate [0.00125]
1: TRAIN [0][3260/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00092)	Tok/s 85378 (59349)	Loss/tok 3.6266 (4.5221)	Learning Rate [0.00125]
3: TRAIN [0][3260/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00096)	Tok/s 86594 (60166)	Loss/tok 3.8287 (4.5229)	Learning Rate [0.00125]
0: TRAIN [0][3260/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00096)	Tok/s 85062 (58905)	Loss/tok 3.5808 (4.5226)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
1: TRAIN [0][3270/6832]	Time 0.113 (0.105)	Data 0.00094 (0.00092)	Tok/s 50873 (59342)	Loss/tok 3.7294 (4.5200)	Learning Rate [0.00125]
0: TRAIN [0][3270/6832]	Time 0.113 (0.105)	Data 0.00100 (0.00096)	Tok/s 50857 (58898)	Loss/tok 3.7705 (4.5203)	Learning Rate [0.00125]
2: TRAIN [0][3270/6832]	Time 0.113 (0.105)	Data 0.00098 (0.00096)	Tok/s 50820 (59713)	Loss/tok 3.5330 (4.5148)	Learning Rate [0.00125]
3: TRAIN [0][3270/6832]	Time 0.113 (0.105)	Data 0.00104 (0.00096)	Tok/s 50846 (60159)	Loss/tok 3.5311 (4.5205)	Learning Rate [0.00125]
2: Gradient norm: inf
3: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
0: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
1: TRAIN [0][3280/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00092)	Tok/s 52994 (59353)	Loss/tok 3.4481 (4.5168)	Learning Rate [0.00125]
0: TRAIN [0][3280/6832]	Time 0.080 (0.105)	Data 0.00097 (0.00096)	Tok/s 53008 (58909)	Loss/tok 3.5801 (4.5176)	Learning Rate [0.00125]
2: TRAIN [0][3280/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00096)	Tok/s 52875 (59724)	Loss/tok 3.2068 (4.5118)	Learning Rate [0.00125]
3: TRAIN [0][3280/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00096)	Tok/s 52880 (60171)	Loss/tok 3.3773 (4.5175)	Learning Rate [0.00125]
1: TRAIN [0][3290/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00092)	Tok/s 52614 (59341)	Loss/tok 3.3364 (4.5148)	Learning Rate [0.00125]
2: TRAIN [0][3290/6832]	Time 0.061 (0.105)	Data 0.00084 (0.00096)	Tok/s 53949 (59712)	Loss/tok 3.3495 (4.5096)	Learning Rate [0.00125]
3: TRAIN [0][3290/6832]	Time 0.061 (0.105)	Data 0.00085 (0.00096)	Tok/s 54737 (60158)	Loss/tok 3.3741 (4.5153)	Learning Rate [0.00125]
0: TRAIN [0][3290/6832]	Time 0.061 (0.105)	Data 0.00093 (0.00096)	Tok/s 52627 (58898)	Loss/tok 3.3078 (4.5155)	Learning Rate [0.00125]
2: TRAIN [0][3300/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00096)	Tok/s 52722 (59700)	Loss/tok 3.5402 (4.5073)	Learning Rate [0.00125]
3: TRAIN [0][3300/6832]	Time 0.097 (0.105)	Data 0.00086 (0.00096)	Tok/s 53491 (60147)	Loss/tok 3.4979 (4.5132)	Learning Rate [0.00125]
1: TRAIN [0][3300/6832]	Time 0.097 (0.105)	Data 0.00091 (0.00092)	Tok/s 52649 (59329)	Loss/tok 3.7796 (4.5126)	Learning Rate [0.00125]
0: TRAIN [0][3300/6832]	Time 0.097 (0.105)	Data 0.00095 (0.00096)	Tok/s 52638 (58887)	Loss/tok 3.7206 (4.5133)	Learning Rate [0.00125]
2: TRAIN [0][3310/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00096)	Tok/s 59890 (59711)	Loss/tok 3.8457 (4.5046)	Learning Rate [0.00125]
1: TRAIN [0][3310/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00092)	Tok/s 59863 (59340)	Loss/tok 3.8805 (4.5099)	Learning Rate [0.00125]
3: TRAIN [0][3310/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00096)	Tok/s 60440 (60158)	Loss/tok 3.6808 (4.5102)	Learning Rate [0.00125]
0: TRAIN [0][3310/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00096)	Tok/s 59851 (58899)	Loss/tok 3.6162 (4.5105)	Learning Rate [0.00125]
1: TRAIN [0][3320/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00092)	Tok/s 31754 (59334)	Loss/tok 2.4552 (4.5075)	Learning Rate [0.00125]
2: TRAIN [0][3320/6832]	Time 0.043 (0.105)	Data 0.00087 (0.00096)	Tok/s 38226 (59706)	Loss/tok 2.2013 (4.5023)	Learning Rate [0.00125]
3: TRAIN [0][3320/6832]	Time 0.043 (0.105)	Data 0.00091 (0.00096)	Tok/s 42098 (60153)	Loss/tok 2.5228 (4.5077)	Learning Rate [0.00125]
0: TRAIN [0][3320/6832]	Time 0.043 (0.105)	Data 0.00092 (0.00096)	Tok/s 19968 (58890)	Loss/tok 1.8595 (4.5083)	Learning Rate [0.00125]
2: TRAIN [0][3330/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00096)	Tok/s 73470 (59695)	Loss/tok 3.5863 (4.5001)	Learning Rate [0.00125]
1: TRAIN [0][3330/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00092)	Tok/s 72839 (59323)	Loss/tok 3.5916 (4.5053)	Learning Rate [0.00125]
3: TRAIN [0][3330/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00096)	Tok/s 73460 (60143)	Loss/tok 3.7028 (4.5055)	Learning Rate [0.00125]
0: TRAIN [0][3330/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00096)	Tok/s 72454 (58880)	Loss/tok 3.8769 (4.5061)	Learning Rate [0.00125]
2: TRAIN [0][3340/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 67312 (59690)	Loss/tok 3.7025 (4.4977)	Learning Rate [0.00125]
1: TRAIN [0][3340/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00092)	Tok/s 67320 (59317)	Loss/tok 4.0023 (4.5029)	Learning Rate [0.00125]
0: TRAIN [0][3340/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00096)	Tok/s 67233 (58872)	Loss/tok 3.7658 (4.5038)	Learning Rate [0.00125]
3: TRAIN [0][3340/6832]	Time 0.131 (0.105)	Data 0.00111 (0.00096)	Tok/s 67457 (60139)	Loss/tok 4.0628 (4.5030)	Learning Rate [0.00125]
2: TRAIN [0][3350/6832]	Time 0.050 (0.105)	Data 0.00085 (0.00096)	Tok/s 48521 (59688)	Loss/tok 2.8664 (4.4955)	Learning Rate [0.00125]
1: TRAIN [0][3350/6832]	Time 0.050 (0.105)	Data 0.00092 (0.00092)	Tok/s 47966 (59315)	Loss/tok 2.9203 (4.5004)	Learning Rate [0.00125]
0: TRAIN [0][3350/6832]	Time 0.050 (0.105)	Data 0.00097 (0.00096)	Tok/s 45960 (58870)	Loss/tok 2.8975 (4.5014)	Learning Rate [0.00125]
3: TRAIN [0][3350/6832]	Time 0.050 (0.105)	Data 0.00089 (0.00096)	Tok/s 50356 (60138)	Loss/tok 3.0011 (4.5008)	Learning Rate [0.00125]
2: TRAIN [0][3360/6832]	Time 0.064 (0.105)	Data 0.00094 (0.00096)	Tok/s 46111 (59682)	Loss/tok 3.2801 (4.4933)	Learning Rate [0.00125]
3: TRAIN [0][3360/6832]	Time 0.064 (0.105)	Data 0.00096 (0.00096)	Tok/s 47933 (60131)	Loss/tok 3.3503 (4.4987)	Learning Rate [0.00125]
0: TRAIN [0][3360/6832]	Time 0.064 (0.105)	Data 0.00104 (0.00096)	Tok/s 46100 (58864)	Loss/tok 3.2477 (4.4991)	Learning Rate [0.00125]
1: TRAIN [0][3360/6832]	Time 0.064 (0.105)	Data 0.00106 (0.00092)	Tok/s 46009 (59309)	Loss/tok 3.1613 (4.4982)	Learning Rate [0.00125]
2: TRAIN [0][3370/6832]	Time 0.089 (0.105)	Data 0.00096 (0.00096)	Tok/s 53309 (59673)	Loss/tok 3.7574 (4.4913)	Learning Rate [0.00125]
3: TRAIN [0][3370/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00096)	Tok/s 53314 (60123)	Loss/tok 3.5090 (4.4964)	Learning Rate [0.00125]
1: TRAIN [0][3370/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00092)	Tok/s 53233 (59299)	Loss/tok 3.4449 (4.4960)	Learning Rate [0.00125]
0: TRAIN [0][3370/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00096)	Tok/s 53211 (58851)	Loss/tok 3.4539 (4.4968)	Learning Rate [0.00125]
2: TRAIN [0][3380/6832]	Time 0.074 (0.105)	Data 0.00086 (0.00096)	Tok/s 48313 (59672)	Loss/tok 3.2491 (4.4888)	Learning Rate [0.00125]
1: TRAIN [0][3380/6832]	Time 0.074 (0.105)	Data 0.00091 (0.00092)	Tok/s 48284 (59298)	Loss/tok 3.3799 (4.4934)	Learning Rate [0.00125]
0: TRAIN [0][3380/6832]	Time 0.074 (0.105)	Data 0.00100 (0.00096)	Tok/s 48295 (58851)	Loss/tok 3.2347 (4.4946)	Learning Rate [0.00125]
3: TRAIN [0][3380/6832]	Time 0.074 (0.105)	Data 0.00095 (0.00096)	Tok/s 48964 (60121)	Loss/tok 3.2437 (4.4941)	Learning Rate [0.00125]
1: TRAIN [0][3390/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00092)	Tok/s 54767 (59295)	Loss/tok 3.6849 (4.4911)	Learning Rate [0.00125]
2: TRAIN [0][3390/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00096)	Tok/s 54776 (59669)	Loss/tok 3.8165 (4.4864)	Learning Rate [0.00125]
0: TRAIN [0][3390/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00096)	Tok/s 54749 (58849)	Loss/tok 3.6762 (4.4921)	Learning Rate [0.00125]
3: TRAIN [0][3390/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00096)	Tok/s 54805 (60118)	Loss/tok 3.8404 (4.4918)	Learning Rate [0.00125]
2: TRAIN [0][3400/6832]	Time 0.097 (0.105)	Data 0.00086 (0.00096)	Tok/s 52553 (59670)	Loss/tok 3.5235 (4.4840)	Learning Rate [0.00125]
1: TRAIN [0][3400/6832]	Time 0.097 (0.105)	Data 0.00091 (0.00092)	Tok/s 52525 (59297)	Loss/tok 3.6523 (4.4888)	Learning Rate [0.00125]
0: TRAIN [0][3400/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00096)	Tok/s 52533 (58851)	Loss/tok 3.6235 (4.4899)	Learning Rate [0.00125]
3: TRAIN [0][3400/6832]	Time 0.097 (0.105)	Data 0.00092 (0.00096)	Tok/s 53780 (60120)	Loss/tok 3.7029 (4.4894)	Learning Rate [0.00125]
2: Upscaling, new scale: 4096.0
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
1: TRAIN [0][3410/6832]	Time 0.074 (0.105)	Data 0.00088 (0.00092)	Tok/s 51621 (59301)	Loss/tok 3.4015 (4.4865)	Learning Rate [0.00125]
2: TRAIN [0][3410/6832]	Time 0.074 (0.105)	Data 0.00086 (0.00096)	Tok/s 53267 (59675)	Loss/tok 3.3326 (4.4816)	Learning Rate [0.00125]
0: TRAIN [0][3410/6832]	Time 0.074 (0.105)	Data 0.00088 (0.00096)	Tok/s 51627 (58856)	Loss/tok 3.4417 (4.4873)	Learning Rate [0.00125]
3: TRAIN [0][3410/6832]	Time 0.074 (0.105)	Data 0.00093 (0.00096)	Tok/s 53321 (60124)	Loss/tok 3.6051 (4.4869)	Learning Rate [0.00125]
1: TRAIN [0][3420/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00092)	Tok/s 73038 (59321)	Loss/tok 3.8595 (4.4836)	Learning Rate [0.00125]
0: TRAIN [0][3420/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 72877 (58875)	Loss/tok 3.8273 (4.4845)	Learning Rate [0.00125]
2: TRAIN [0][3420/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 73853 (59694)	Loss/tok 3.8392 (4.4788)	Learning Rate [0.00125]
3: TRAIN [0][3420/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00096)	Tok/s 73891 (60144)	Loss/tok 3.7632 (4.4838)	Learning Rate [0.00125]
0: TRAIN [0][3430/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00096)	Tok/s 52423 (58885)	Loss/tok 3.5723 (4.4819)	Learning Rate [0.00125]
1: TRAIN [0][3430/6832]	Time 0.107 (0.105)	Data 0.00090 (0.00092)	Tok/s 52395 (59330)	Loss/tok 3.5947 (4.4808)	Learning Rate [0.00125]
2: TRAIN [0][3430/6832]	Time 0.108 (0.105)	Data 0.00087 (0.00096)	Tok/s 52249 (59704)	Loss/tok 3.5921 (4.4762)	Learning Rate [0.00125]
3: TRAIN [0][3430/6832]	Time 0.108 (0.105)	Data 0.00091 (0.00096)	Tok/s 52437 (60152)	Loss/tok 3.6138 (4.4812)	Learning Rate [0.00125]
2: TRAIN [0][3440/6832]	Time 0.104 (0.105)	Data 0.00085 (0.00096)	Tok/s 51487 (59691)	Loss/tok 3.6641 (4.4741)	Learning Rate [0.00125]
1: TRAIN [0][3440/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00092)	Tok/s 51468 (59316)	Loss/tok 3.6694 (4.4788)	Learning Rate [0.00125]
3: TRAIN [0][3440/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00096)	Tok/s 51483 (60141)	Loss/tok 3.4689 (4.4790)	Learning Rate [0.00125]
0: TRAIN [0][3440/6832]	Time 0.104 (0.105)	Data 0.00099 (0.00096)	Tok/s 51364 (58868)	Loss/tok 3.7098 (4.4798)	Learning Rate [0.00125]
1: TRAIN [0][3450/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00092)	Tok/s 57366 (59305)	Loss/tok 3.6958 (4.4769)	Learning Rate [0.00125]
2: TRAIN [0][3450/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00096)	Tok/s 58324 (59679)	Loss/tok 3.6796 (4.4720)	Learning Rate [0.00125]
0: TRAIN [0][3450/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00095)	Tok/s 57332 (58857)	Loss/tok 3.7588 (4.4777)	Learning Rate [0.00125]
3: TRAIN [0][3450/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00096)	Tok/s 58334 (60128)	Loss/tok 3.7807 (4.4770)	Learning Rate [0.00125]
0: TRAIN [0][3460/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00095)	Tok/s 68290 (58865)	Loss/tok 3.8954 (4.4752)	Learning Rate [0.00125]
1: TRAIN [0][3460/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00092)	Tok/s 68275 (59312)	Loss/tok 3.8498 (4.4746)	Learning Rate [0.00125]
3: TRAIN [0][3460/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00096)	Tok/s 68412 (60134)	Loss/tok 3.7370 (4.4745)	Learning Rate [0.00125]
2: TRAIN [0][3460/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00096)	Tok/s 68258 (59686)	Loss/tok 3.8427 (4.4696)	Learning Rate [0.00125]
1: TRAIN [0][3470/6832]	Time 0.105 (0.105)	Data 0.00095 (0.00092)	Tok/s 54940 (59320)	Loss/tok 3.6436 (4.4723)	Learning Rate [0.00125]
2: TRAIN [0][3470/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00096)	Tok/s 54906 (59693)	Loss/tok 3.7656 (4.4675)	Learning Rate [0.00125]
0: TRAIN [0][3470/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00095)	Tok/s 54921 (58874)	Loss/tok 3.6865 (4.4730)	Learning Rate [0.00125]
3: TRAIN [0][3470/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00096)	Tok/s 54913 (60141)	Loss/tok 3.5567 (4.4722)	Learning Rate [0.00125]
2: TRAIN [0][3480/6832]	Time 0.095 (0.105)	Data 0.00111 (0.00096)	Tok/s 52354 (59691)	Loss/tok 3.5316 (4.4653)	Learning Rate [0.00125]
3: TRAIN [0][3480/6832]	Time 0.095 (0.105)	Data 0.00110 (0.00096)	Tok/s 52345 (60138)	Loss/tok 3.6397 (4.4701)	Learning Rate [0.00125]
0: TRAIN [0][3480/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00095)	Tok/s 52277 (58873)	Loss/tok 3.5259 (4.4708)	Learning Rate [0.00125]
1: TRAIN [0][3480/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00092)	Tok/s 52262 (59319)	Loss/tok 3.6313 (4.4702)	Learning Rate [0.00125]
1: TRAIN [0][3490/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00092)	Tok/s 54098 (59318)	Loss/tok 3.5679 (4.4678)	Learning Rate [0.00125]
0: TRAIN [0][3490/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00095)	Tok/s 53494 (58872)	Loss/tok 3.2817 (4.4686)	Learning Rate [0.00125]
3: TRAIN [0][3490/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00096)	Tok/s 54127 (60138)	Loss/tok 3.3916 (4.4679)	Learning Rate [0.00125]
2: TRAIN [0][3490/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00096)	Tok/s 54114 (59691)	Loss/tok 3.5320 (4.4631)	Learning Rate [0.00125]
1: TRAIN [0][3500/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00092)	Tok/s 52886 (59320)	Loss/tok 3.2935 (4.4655)	Learning Rate [0.00125]
2: TRAIN [0][3500/6832]	Time 0.077 (0.105)	Data 0.00090 (0.00096)	Tok/s 52890 (59692)	Loss/tok 3.5089 (4.4608)	Learning Rate [0.00125]
3: TRAIN [0][3500/6832]	Time 0.077 (0.105)	Data 0.00095 (0.00096)	Tok/s 52891 (60139)	Loss/tok 3.3661 (4.4657)	Learning Rate [0.00125]
0: TRAIN [0][3500/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00095)	Tok/s 52874 (58875)	Loss/tok 3.5551 (4.4661)	Learning Rate [0.00125]
2: TRAIN [0][3510/6832]	Time 0.115 (0.105)	Data 0.00097 (0.00096)	Tok/s 59015 (59693)	Loss/tok 3.8723 (4.4587)	Learning Rate [0.00125]
3: TRAIN [0][3510/6832]	Time 0.115 (0.105)	Data 0.00098 (0.00096)	Tok/s 59012 (60139)	Loss/tok 3.5840 (4.4632)	Learning Rate [0.00125]
1: TRAIN [0][3510/6832]	Time 0.115 (0.105)	Data 0.00100 (0.00092)	Tok/s 58345 (59320)	Loss/tok 3.6443 (4.4633)	Learning Rate [0.00125]
0: TRAIN [0][3510/6832]	Time 0.115 (0.105)	Data 0.00096 (0.00095)	Tok/s 57937 (58876)	Loss/tok 3.8485 (4.4640)	Learning Rate [0.00125]
2: TRAIN [0][3520/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00096)	Tok/s 65954 (59681)	Loss/tok 3.9347 (4.4568)	Learning Rate [0.00125]
3: TRAIN [0][3520/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00096)	Tok/s 66914 (60128)	Loss/tok 3.7356 (4.4613)	Learning Rate [0.00125]
0: TRAIN [0][3520/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 65956 (58864)	Loss/tok 3.8586 (4.4622)	Learning Rate [0.00125]
1: TRAIN [0][3520/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00092)	Tok/s 65977 (59309)	Loss/tok 3.6836 (4.4613)	Learning Rate [0.00125]
0: TRAIN [0][3530/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00095)	Tok/s 60627 (58889)	Loss/tok 3.9299 (4.4594)	Learning Rate [0.00125]
1: TRAIN [0][3530/6832]	Time 0.125 (0.105)	Data 0.00092 (0.00092)	Tok/s 61563 (59334)	Loss/tok 3.7086 (4.4584)	Learning Rate [0.00125]
2: TRAIN [0][3530/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00096)	Tok/s 61599 (59706)	Loss/tok 3.9716 (4.4542)	Learning Rate [0.00125]
3: TRAIN [0][3530/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00096)	Tok/s 61617 (60152)	Loss/tok 3.9447 (4.4585)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [0][3540/6832]	Time 0.097 (0.105)	Data 0.00100 (0.00092)	Tok/s 53880 (59344)	Loss/tok 3.5856 (4.4561)	Learning Rate [0.00125]
2: TRAIN [0][3540/6832]	Time 0.097 (0.105)	Data 0.00091 (0.00096)	Tok/s 53844 (59716)	Loss/tok 3.5019 (4.4520)	Learning Rate [0.00125]
3: TRAIN [0][3540/6832]	Time 0.097 (0.105)	Data 0.00095 (0.00096)	Tok/s 53857 (60161)	Loss/tok 3.6776 (4.4562)	Learning Rate [0.00125]
0: TRAIN [0][3540/6832]	Time 0.097 (0.105)	Data 0.00106 (0.00095)	Tok/s 53854 (58900)	Loss/tok 3.4502 (4.4568)	Learning Rate [0.00125]
1: TRAIN [0][3550/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00092)	Tok/s 61247 (59340)	Loss/tok 3.8633 (4.4541)	Learning Rate [0.00125]
0: TRAIN [0][3550/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00095)	Tok/s 60654 (58896)	Loss/tok 3.8107 (4.4548)	Learning Rate [0.00125]
2: TRAIN [0][3550/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00096)	Tok/s 61663 (59712)	Loss/tok 3.7954 (4.4499)	Learning Rate [0.00125]
3: TRAIN [0][3550/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00096)	Tok/s 61667 (60157)	Loss/tok 3.6775 (4.4540)	Learning Rate [0.00125]
1: TRAIN [0][3560/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00092)	Tok/s 57435 (59340)	Loss/tok 3.8573 (4.4517)	Learning Rate [0.00125]
0: TRAIN [0][3560/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00095)	Tok/s 57433 (58897)	Loss/tok 3.6730 (4.4527)	Learning Rate [0.00125]
2: TRAIN [0][3560/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00096)	Tok/s 57373 (59712)	Loss/tok 3.6237 (4.4477)	Learning Rate [0.00125]
3: TRAIN [0][3560/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00096)	Tok/s 57386 (60157)	Loss/tok 3.7187 (4.4519)	Learning Rate [0.00125]
2: TRAIN [0][3570/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00096)	Tok/s 62338 (59715)	Loss/tok 3.8322 (4.4455)	Learning Rate [0.00125]
3: TRAIN [0][3570/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00096)	Tok/s 62826 (60160)	Loss/tok 3.8466 (4.4495)	Learning Rate [0.00125]
0: TRAIN [0][3570/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00095)	Tok/s 61807 (58900)	Loss/tok 3.6021 (4.4502)	Learning Rate [0.00125]
1: TRAIN [0][3570/6832]	Time 0.126 (0.105)	Data 0.00110 (0.00092)	Tok/s 61812 (59342)	Loss/tok 3.7739 (4.4493)	Learning Rate [0.00125]
1: TRAIN [0][3580/6832]	Time 0.128 (0.105)	Data 0.00103 (0.00092)	Tok/s 62178 (59350)	Loss/tok 3.7808 (4.4468)	Learning Rate [0.00125]
2: TRAIN [0][3580/6832]	Time 0.128 (0.105)	Data 0.00106 (0.00096)	Tok/s 62146 (59723)	Loss/tok 3.7489 (4.4430)	Learning Rate [0.00125]
3: TRAIN [0][3580/6832]	Time 0.128 (0.105)	Data 0.00112 (0.00096)	Tok/s 63068 (60170)	Loss/tok 3.9100 (4.4470)	Learning Rate [0.00125]
0: TRAIN [0][3580/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 62165 (58905)	Loss/tok 3.7596 (4.4478)	Learning Rate [0.00125]
1: TRAIN [0][3590/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00092)	Tok/s 76841 (59350)	Loss/tok 3.8409 (4.4448)	Learning Rate [0.00125]
0: TRAIN [0][3590/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 76269 (58905)	Loss/tok 3.6917 (4.4457)	Learning Rate [0.00125]
2: TRAIN [0][3590/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00096)	Tok/s 77213 (59723)	Loss/tok 3.7728 (4.4409)	Learning Rate [0.00125]
3: TRAIN [0][3590/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00096)	Tok/s 77400 (60169)	Loss/tok 3.9709 (4.4449)	Learning Rate [0.00125]
1: TRAIN [0][3600/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00092)	Tok/s 53036 (59344)	Loss/tok 3.7899 (4.4428)	Learning Rate [0.00125]
0: TRAIN [0][3600/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00095)	Tok/s 52494 (58899)	Loss/tok 3.8147 (4.4436)	Learning Rate [0.00125]
3: TRAIN [0][3600/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00096)	Tok/s 53573 (60163)	Loss/tok 3.8181 (4.4429)	Learning Rate [0.00125]
2: TRAIN [0][3600/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00096)	Tok/s 53575 (59717)	Loss/tok 3.8254 (4.4391)	Learning Rate [0.00125]
2: TRAIN [0][3610/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00096)	Tok/s 58780 (59721)	Loss/tok 3.5936 (4.4369)	Learning Rate [0.00125]
3: TRAIN [0][3610/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00095)	Tok/s 58799 (60167)	Loss/tok 3.7444 (4.4408)	Learning Rate [0.00125]
1: TRAIN [0][3610/6832]	Time 0.118 (0.105)	Data 0.00112 (0.00092)	Tok/s 58706 (59348)	Loss/tok 4.0107 (4.4408)	Learning Rate [0.00125]
0: TRAIN [0][3610/6832]	Time 0.118 (0.105)	Data 0.00103 (0.00095)	Tok/s 58695 (58904)	Loss/tok 3.6514 (4.4415)	Learning Rate [0.00125]
2: TRAIN [0][3620/6832]	Time 0.095 (0.105)	Data 0.00107 (0.00096)	Tok/s 52357 (59718)	Loss/tok 3.5146 (4.4347)	Learning Rate [0.00125]
1: TRAIN [0][3620/6832]	Time 0.095 (0.105)	Data 0.00118 (0.00092)	Tok/s 52353 (59346)	Loss/tok 3.5911 (4.4387)	Learning Rate [0.00125]
0: TRAIN [0][3620/6832]	Time 0.095 (0.105)	Data 0.00100 (0.00095)	Tok/s 52105 (58902)	Loss/tok 3.4170 (4.4393)	Learning Rate [0.00125]
3: TRAIN [0][3620/6832]	Time 0.095 (0.105)	Data 0.00117 (0.00096)	Tok/s 52361 (60163)	Loss/tok 3.7051 (4.4387)	Learning Rate [0.00125]
2: TRAIN [0][3630/6832]	Time 0.042 (0.105)	Data 0.00087 (0.00096)	Tok/s 38968 (59709)	Loss/tok 2.0379 (4.4328)	Learning Rate [0.00125]
1: TRAIN [0][3630/6832]	Time 0.042 (0.105)	Data 0.00090 (0.00092)	Tok/s 32944 (59335)	Loss/tok 2.3494 (4.4367)	Learning Rate [0.00125]
3: TRAIN [0][3630/6832]	Time 0.042 (0.105)	Data 0.00088 (0.00095)	Tok/s 42841 (60155)	Loss/tok 2.4487 (4.4367)	Learning Rate [0.00125]
0: TRAIN [0][3630/6832]	Time 0.042 (0.105)	Data 0.00087 (0.00095)	Tok/s 21827 (58889)	Loss/tok 2.0161 (4.4373)	Learning Rate [0.00125]
1: TRAIN [0][3640/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00092)	Tok/s 60866 (59324)	Loss/tok 3.8971 (4.4348)	Learning Rate [0.00125]
0: TRAIN [0][3640/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 60664 (58879)	Loss/tok 3.7931 (4.4353)	Learning Rate [0.00125]
2: TRAIN [0][3640/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00096)	Tok/s 61650 (59698)	Loss/tok 3.8882 (4.4309)	Learning Rate [0.00125]
3: TRAIN [0][3640/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 61645 (60143)	Loss/tok 3.6960 (4.4348)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
1: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
2: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
2: TRAIN [0][3650/6832]	Time 0.092 (0.105)	Data 0.00088 (0.00096)	Tok/s 52820 (59708)	Loss/tok 3.4810 (4.4285)	Learning Rate [0.00125]
3: TRAIN [0][3650/6832]	Time 0.092 (0.105)	Data 0.00086 (0.00095)	Tok/s 52814 (60153)	Loss/tok 3.4831 (4.4323)	Learning Rate [0.00125]
0: TRAIN [0][3650/6832]	Time 0.092 (0.105)	Data 0.00088 (0.00095)	Tok/s 52768 (58889)	Loss/tok 3.5594 (4.4331)	Learning Rate [0.00125]
1: TRAIN [0][3650/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00092)	Tok/s 52775 (59334)	Loss/tok 3.5366 (4.4326)	Learning Rate [0.00125]
3: TRAIN [0][3660/6832]	Time 0.043 (0.105)	Data 0.00089 (0.00095)	Tok/s 41585 (60138)	Loss/tok 2.6235 (4.4303)	Learning Rate [0.00125]
2: TRAIN [0][3660/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00096)	Tok/s 38468 (59692)	Loss/tok 2.1179 (4.4264)	Learning Rate [0.00125]
1: TRAIN [0][3660/6832]	Time 0.043 (0.105)	Data 0.00110 (0.00092)	Tok/s 33361 (59318)	Loss/tok 2.3711 (4.4306)	Learning Rate [0.00125]
0: TRAIN [0][3660/6832]	Time 0.043 (0.105)	Data 0.00122 (0.00095)	Tok/s 22240 (58871)	Loss/tok 1.9938 (4.4312)	Learning Rate [0.00125]
1: TRAIN [0][3670/6832]	Time 0.090 (0.105)	Data 0.00100 (0.00092)	Tok/s 52881 (59320)	Loss/tok 3.7591 (4.4285)	Learning Rate [0.00125]
2: TRAIN [0][3670/6832]	Time 0.090 (0.105)	Data 0.00097 (0.00096)	Tok/s 52836 (59694)	Loss/tok 3.5597 (4.4242)	Learning Rate [0.00125]
3: TRAIN [0][3670/6832]	Time 0.090 (0.105)	Data 0.00095 (0.00095)	Tok/s 52836 (60140)	Loss/tok 3.4108 (4.4281)	Learning Rate [0.00125]
0: TRAIN [0][3670/6832]	Time 0.090 (0.105)	Data 0.00107 (0.00095)	Tok/s 52819 (58873)	Loss/tok 3.4357 (4.4290)	Learning Rate [0.00125]
2: TRAIN [0][3680/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00096)	Tok/s 59598 (59702)	Loss/tok 3.7483 (4.4219)	Learning Rate [0.00125]
1: TRAIN [0][3680/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00092)	Tok/s 59562 (59328)	Loss/tok 3.7254 (4.4263)	Learning Rate [0.00125]
3: TRAIN [0][3680/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00095)	Tok/s 59700 (60148)	Loss/tok 3.7115 (4.4260)	Learning Rate [0.00125]
0: TRAIN [0][3680/6832]	Time 0.125 (0.105)	Data 0.00101 (0.00095)	Tok/s 59573 (58882)	Loss/tok 3.7570 (4.4268)	Learning Rate [0.00125]
2: TRAIN [0][3690/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00096)	Tok/s 59870 (59693)	Loss/tok 3.8128 (4.4201)	Learning Rate [0.00125]
3: TRAIN [0][3690/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00095)	Tok/s 59896 (60139)	Loss/tok 3.8679 (4.4241)	Learning Rate [0.00125]
1: TRAIN [0][3690/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00092)	Tok/s 58943 (59317)	Loss/tok 3.6065 (4.4243)	Learning Rate [0.00125]
0: TRAIN [0][3690/6832]	Time 0.122 (0.105)	Data 0.00100 (0.00095)	Tok/s 58853 (58869)	Loss/tok 4.0070 (4.4250)	Learning Rate [0.00125]
1: TRAIN [0][3700/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00092)	Tok/s 74478 (59325)	Loss/tok 3.5436 (4.4220)	Learning Rate [0.00125]
2: TRAIN [0][3700/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 75355 (59700)	Loss/tok 3.7537 (4.4179)	Learning Rate [0.00125]
0: TRAIN [0][3700/6832]	Time 0.131 (0.105)	Data 0.00113 (0.00095)	Tok/s 74407 (58877)	Loss/tok 3.7911 (4.4228)	Learning Rate [0.00125]
3: TRAIN [0][3700/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 75370 (60146)	Loss/tok 3.8859 (4.4219)	Learning Rate [0.00125]
2: TRAIN [0][3710/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00096)	Tok/s 72122 (59699)	Loss/tok 3.5916 (4.4157)	Learning Rate [0.00125]
3: TRAIN [0][3710/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00095)	Tok/s 72868 (60145)	Loss/tok 3.7866 (4.4198)	Learning Rate [0.00125]
1: TRAIN [0][3710/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00092)	Tok/s 71661 (59324)	Loss/tok 3.6647 (4.4200)	Learning Rate [0.00125]
0: TRAIN [0][3710/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00095)	Tok/s 71668 (58876)	Loss/tok 3.9631 (4.4208)	Learning Rate [0.00125]
1: TRAIN [0][3720/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 67455 (59332)	Loss/tok 3.8424 (4.4180)	Learning Rate [0.00125]
2: TRAIN [0][3720/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00096)	Tok/s 67660 (59707)	Loss/tok 4.0012 (4.4135)	Learning Rate [0.00125]
3: TRAIN [0][3720/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00095)	Tok/s 67702 (60153)	Loss/tok 3.8809 (4.4176)	Learning Rate [0.00125]
0: TRAIN [0][3720/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 66826 (58884)	Loss/tok 3.6656 (4.4186)	Learning Rate [0.00125]
2: TRAIN [0][3730/6832]	Time 0.061 (0.105)	Data 0.00096 (0.00096)	Tok/s 51214 (59721)	Loss/tok 3.1808 (4.4111)	Learning Rate [0.00125]
1: TRAIN [0][3730/6832]	Time 0.061 (0.105)	Data 0.00093 (0.00092)	Tok/s 50346 (59346)	Loss/tok 3.1337 (4.4156)	Learning Rate [0.00125]
0: TRAIN [0][3730/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00095)	Tok/s 50347 (58899)	Loss/tok 3.1529 (4.4162)	Learning Rate [0.00125]
3: TRAIN [0][3730/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00095)	Tok/s 52416 (60166)	Loss/tok 3.3200 (4.4153)	Learning Rate [0.00125]
1: TRAIN [0][3740/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00092)	Tok/s 80034 (59350)	Loss/tok 3.7173 (4.4134)	Learning Rate [0.00125]
2: TRAIN [0][3740/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 80068 (59725)	Loss/tok 3.6734 (4.4091)	Learning Rate [0.00125]
0: TRAIN [0][3740/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00095)	Tok/s 79404 (58904)	Loss/tok 3.7550 (4.4142)	Learning Rate [0.00125]
3: TRAIN [0][3740/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 80969 (60170)	Loss/tok 3.6281 (4.4132)	Learning Rate [0.00125]
2: TRAIN [0][3750/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00096)	Tok/s 66539 (59719)	Loss/tok 3.9130 (4.4070)	Learning Rate [0.00125]
3: TRAIN [0][3750/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00095)	Tok/s 66523 (60165)	Loss/tok 3.7525 (4.4114)	Learning Rate [0.00125]
1: TRAIN [0][3750/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00092)	Tok/s 66527 (59343)	Loss/tok 4.0696 (4.4115)	Learning Rate [0.00125]
0: TRAIN [0][3750/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 66528 (58894)	Loss/tok 3.6920 (4.4124)	Learning Rate [0.00125]
2: TRAIN [0][3760/6832]	Time 0.061 (0.105)	Data 0.00090 (0.00096)	Tok/s 50312 (59717)	Loss/tok 3.0981 (4.4051)	Learning Rate [0.00125]
3: TRAIN [0][3760/6832]	Time 0.061 (0.105)	Data 0.00088 (0.00095)	Tok/s 52034 (60163)	Loss/tok 3.1999 (4.4095)	Learning Rate [0.00125]
1: TRAIN [0][3760/6832]	Time 0.061 (0.105)	Data 0.00104 (0.00092)	Tok/s 50336 (59342)	Loss/tok 3.1441 (4.4097)	Learning Rate [0.00125]
0: TRAIN [0][3760/6832]	Time 0.061 (0.105)	Data 0.00098 (0.00095)	Tok/s 50354 (58894)	Loss/tok 3.3531 (4.4105)	Learning Rate [0.00125]
1: TRAIN [0][3770/6832]	Time 0.075 (0.105)	Data 0.00094 (0.00092)	Tok/s 54307 (59344)	Loss/tok 3.5116 (4.4077)	Learning Rate [0.00125]
2: TRAIN [0][3770/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00096)	Tok/s 54280 (59719)	Loss/tok 3.5757 (4.4031)	Learning Rate [0.00125]
3: TRAIN [0][3770/6832]	Time 0.075 (0.105)	Data 0.00086 (0.00095)	Tok/s 54257 (60165)	Loss/tok 3.4785 (4.4075)	Learning Rate [0.00125]
0: TRAIN [0][3770/6832]	Time 0.075 (0.105)	Data 0.00091 (0.00095)	Tok/s 54290 (58897)	Loss/tok 3.3191 (4.4085)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
1: TRAIN [0][3780/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00092)	Tok/s 60272 (59345)	Loss/tok 3.7527 (4.4056)	Learning Rate [0.00125]
0: TRAIN [0][3780/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00095)	Tok/s 59596 (58899)	Loss/tok 3.9999 (4.4068)	Learning Rate [0.00125]
2: TRAIN [0][3780/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00096)	Tok/s 60636 (59720)	Loss/tok 3.6861 (4.4011)	Learning Rate [0.00125]
3: TRAIN [0][3780/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00095)	Tok/s 60632 (60166)	Loss/tok 3.9459 (4.4055)	Learning Rate [0.00125]
1: TRAIN [0][3790/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00092)	Tok/s 60750 (59341)	Loss/tok 3.5495 (4.4035)	Learning Rate [0.00125]
2: TRAIN [0][3790/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00096)	Tok/s 60759 (59715)	Loss/tok 3.7885 (4.3993)	Learning Rate [0.00125]
0: TRAIN [0][3790/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00095)	Tok/s 59709 (58894)	Loss/tok 3.6956 (4.4048)	Learning Rate [0.00125]
3: TRAIN [0][3790/6832]	Time 0.118 (0.105)	Data 0.00084 (0.00095)	Tok/s 60749 (60160)	Loss/tok 3.7947 (4.4037)	Learning Rate [0.00125]
2: TRAIN [0][3800/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00096)	Tok/s 53702 (59719)	Loss/tok 3.4578 (4.3972)	Learning Rate [0.00125]
3: TRAIN [0][3800/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00095)	Tok/s 53724 (60164)	Loss/tok 3.8080 (4.4018)	Learning Rate [0.00125]
1: TRAIN [0][3800/6832]	Time 0.100 (0.105)	Data 0.00094 (0.00092)	Tok/s 52900 (59345)	Loss/tok 3.7393 (4.4013)	Learning Rate [0.00125]
0: TRAIN [0][3800/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00095)	Tok/s 52462 (58898)	Loss/tok 3.6239 (4.4027)	Learning Rate [0.00125]
2: TRAIN [0][3810/6832]	Time 0.061 (0.105)	Data 0.00090 (0.00096)	Tok/s 53011 (59710)	Loss/tok 3.3656 (4.3953)	Learning Rate [0.00125]
3: TRAIN [0][3810/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00095)	Tok/s 54836 (60156)	Loss/tok 3.1323 (4.4000)	Learning Rate [0.00125]
1: TRAIN [0][3810/6832]	Time 0.061 (0.105)	Data 0.00096 (0.00092)	Tok/s 52736 (59335)	Loss/tok 3.1318 (4.3995)	Learning Rate [0.00125]
0: TRAIN [0][3810/6832]	Time 0.061 (0.105)	Data 0.00093 (0.00095)	Tok/s 52725 (58886)	Loss/tok 3.2381 (4.4008)	Learning Rate [0.00125]
2: TRAIN [0][3820/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00096)	Tok/s 52749 (59698)	Loss/tok 3.7316 (4.3936)	Learning Rate [0.00125]
1: TRAIN [0][3820/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00092)	Tok/s 52737 (59324)	Loss/tok 3.8494 (4.3979)	Learning Rate [0.00125]
0: TRAIN [0][3820/6832]	Time 0.104 (0.105)	Data 0.00089 (0.00095)	Tok/s 52742 (58875)	Loss/tok 3.6878 (4.3992)	Learning Rate [0.00125]
3: TRAIN [0][3820/6832]	Time 0.104 (0.105)	Data 0.00085 (0.00095)	Tok/s 52740 (60144)	Loss/tok 3.8162 (4.3982)	Learning Rate [0.00125]
2: TRAIN [0][3830/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00096)	Tok/s 54815 (59694)	Loss/tok 3.6335 (4.3917)	Learning Rate [0.00125]
3: TRAIN [0][3830/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00095)	Tok/s 54823 (60140)	Loss/tok 3.9677 (4.3964)	Learning Rate [0.00125]
0: TRAIN [0][3830/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00095)	Tok/s 53978 (58871)	Loss/tok 3.8116 (4.3974)	Learning Rate [0.00125]
1: TRAIN [0][3830/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00092)	Tok/s 54801 (59319)	Loss/tok 3.5267 (4.3960)	Learning Rate [0.00125]
2: TRAIN [0][3840/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00096)	Tok/s 62021 (59694)	Loss/tok 3.8467 (4.3898)	Learning Rate [0.00125]
3: TRAIN [0][3840/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00095)	Tok/s 62007 (60140)	Loss/tok 3.7283 (4.3945)	Learning Rate [0.00125]
1: TRAIN [0][3840/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00092)	Tok/s 61705 (59320)	Loss/tok 3.7579 (4.3940)	Learning Rate [0.00125]
0: TRAIN [0][3840/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00095)	Tok/s 60919 (58872)	Loss/tok 3.5387 (4.3953)	Learning Rate [0.00125]
3: TRAIN [0][3850/6832]	Time 0.052 (0.105)	Data 0.00097 (0.00095)	Tok/s 47818 (60130)	Loss/tok 2.7670 (4.3927)	Learning Rate [0.00125]
2: TRAIN [0][3850/6832]	Time 0.052 (0.105)	Data 0.00098 (0.00096)	Tok/s 46614 (59685)	Loss/tok 2.7396 (4.3880)	Learning Rate [0.00125]
1: TRAIN [0][3850/6832]	Time 0.052 (0.105)	Data 0.00108 (0.00092)	Tok/s 45652 (59311)	Loss/tok 2.7379 (4.3923)	Learning Rate [0.00125]
0: TRAIN [0][3850/6832]	Time 0.052 (0.105)	Data 0.00113 (0.00095)	Tok/s 44219 (58862)	Loss/tok 2.7270 (4.3936)	Learning Rate [0.00125]
2: TRAIN [0][3860/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00096)	Tok/s 54493 (59684)	Loss/tok 3.6753 (4.3860)	Learning Rate [0.00125]
1: TRAIN [0][3860/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00092)	Tok/s 54492 (59310)	Loss/tok 3.6236 (4.3905)	Learning Rate [0.00125]
3: TRAIN [0][3860/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00095)	Tok/s 54490 (60128)	Loss/tok 3.8514 (4.3908)	Learning Rate [0.00125]
0: TRAIN [0][3860/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00095)	Tok/s 54503 (58862)	Loss/tok 3.7015 (4.3917)	Learning Rate [0.00125]
2: TRAIN [0][3870/6832]	Time 0.091 (0.105)	Data 0.00103 (0.00096)	Tok/s 53512 (59685)	Loss/tok 3.5067 (4.3840)	Learning Rate [0.00125]
1: TRAIN [0][3870/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00092)	Tok/s 53497 (59311)	Loss/tok 3.3342 (4.3885)	Learning Rate [0.00125]
3: TRAIN [0][3870/6832]	Time 0.091 (0.105)	Data 0.00097 (0.00095)	Tok/s 53504 (60129)	Loss/tok 3.7699 (4.3887)	Learning Rate [0.00125]
0: TRAIN [0][3870/6832]	Time 0.091 (0.105)	Data 0.00093 (0.00095)	Tok/s 53322 (58863)	Loss/tok 3.4705 (4.3897)	Learning Rate [0.00125]
2: TRAIN [0][3880/6832]	Time 0.057 (0.105)	Data 0.00086 (0.00096)	Tok/s 52804 (59672)	Loss/tok 3.0485 (4.3823)	Learning Rate [0.00125]
3: TRAIN [0][3880/6832]	Time 0.057 (0.105)	Data 0.00085 (0.00095)	Tok/s 53687 (60116)	Loss/tok 3.3011 (4.3870)	Learning Rate [0.00125]
1: TRAIN [0][3880/6832]	Time 0.057 (0.105)	Data 0.00092 (0.00092)	Tok/s 51505 (59298)	Loss/tok 3.1433 (4.3869)	Learning Rate [0.00125]
0: TRAIN [0][3880/6832]	Time 0.057 (0.105)	Data 0.00094 (0.00095)	Tok/s 51524 (58850)	Loss/tok 3.2585 (4.3880)	Learning Rate [0.00125]
1: TRAIN [0][3890/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00092)	Tok/s 64082 (59312)	Loss/tok 3.6656 (4.3847)	Learning Rate [0.00125]
0: TRAIN [0][3890/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 64072 (58865)	Loss/tok 3.6637 (4.3858)	Learning Rate [0.00125]
2: TRAIN [0][3890/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00096)	Tok/s 64048 (59686)	Loss/tok 3.9221 (4.3802)	Learning Rate [0.00125]
3: TRAIN [0][3890/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 64067 (60129)	Loss/tok 3.8327 (4.3849)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [0][3900/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00092)	Tok/s 83151 (59311)	Loss/tok 3.9521 (4.3827)	Learning Rate [0.00125]
0: TRAIN [0][3900/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 82255 (58861)	Loss/tok 3.5440 (4.3836)	Learning Rate [0.00125]
2: TRAIN [0][3900/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 83442 (59688)	Loss/tok 3.6204 (4.3781)	Learning Rate [0.00125]
3: TRAIN [0][3900/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 84080 (60132)	Loss/tok 3.8521 (4.3828)	Learning Rate [0.00125]
1: TRAIN [0][3910/6832]	Time 0.054 (0.105)	Data 0.00086 (0.00092)	Tok/s 48378 (59315)	Loss/tok 3.1927 (4.3807)	Learning Rate [0.00125]
0: TRAIN [0][3910/6832]	Time 0.054 (0.105)	Data 0.00092 (0.00095)	Tok/s 47008 (58865)	Loss/tok 3.0726 (4.3817)	Learning Rate [0.00125]
2: TRAIN [0][3910/6832]	Time 0.054 (0.105)	Data 0.00094 (0.00096)	Tok/s 49340 (59691)	Loss/tok 2.9326 (4.3762)	Learning Rate [0.00125]
3: TRAIN [0][3910/6832]	Time 0.054 (0.105)	Data 0.00095 (0.00095)	Tok/s 49346 (60135)	Loss/tok 2.7260 (4.3809)	Learning Rate [0.00125]
3: TRAIN [0][3920/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00095)	Tok/s 53952 (60120)	Loss/tok 3.5212 (4.3792)	Learning Rate [0.00125]
2: TRAIN [0][3920/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00096)	Tok/s 53946 (59676)	Loss/tok 3.5625 (4.3746)	Learning Rate [0.00125]
1: TRAIN [0][3920/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00092)	Tok/s 53927 (59297)	Loss/tok 3.4241 (4.3790)	Learning Rate [0.00125]
0: TRAIN [0][3920/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00095)	Tok/s 52782 (58844)	Loss/tok 3.4414 (4.3800)	Learning Rate [0.00125]
1: TRAIN [0][3930/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00092)	Tok/s 52436 (59299)	Loss/tok 3.8102 (4.3771)	Learning Rate [0.00125]
2: TRAIN [0][3930/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00096)	Tok/s 52426 (59678)	Loss/tok 3.5494 (4.3727)	Learning Rate [0.00125]
0: TRAIN [0][3930/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00095)	Tok/s 52408 (58847)	Loss/tok 3.5626 (4.3781)	Learning Rate [0.00125]
3: TRAIN [0][3930/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00095)	Tok/s 52418 (60122)	Loss/tok 3.5914 (4.3772)	Learning Rate [0.00125]
1: TRAIN [0][3940/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00092)	Tok/s 52575 (59303)	Loss/tok 3.7314 (4.3754)	Learning Rate [0.00125]
2: TRAIN [0][3940/6832]	Time 0.105 (0.105)	Data 0.00099 (0.00096)	Tok/s 52574 (59681)	Loss/tok 3.4891 (4.3708)	Learning Rate [0.00125]
0: TRAIN [0][3940/6832]	Time 0.105 (0.105)	Data 0.00097 (0.00095)	Tok/s 52555 (58851)	Loss/tok 3.6209 (4.3763)	Learning Rate [0.00125]
3: TRAIN [0][3940/6832]	Time 0.105 (0.105)	Data 0.00099 (0.00095)	Tok/s 53458 (60126)	Loss/tok 3.5092 (4.3753)	Learning Rate [0.00125]
2: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][3950/6832]	Time 0.096 (0.105)	Data 0.00099 (0.00096)	Tok/s 54456 (59674)	Loss/tok 3.4630 (4.3689)	Learning Rate [0.00125]
3: TRAIN [0][3950/6832]	Time 0.096 (0.105)	Data 0.00096 (0.00095)	Tok/s 54450 (60119)	Loss/tok 3.7198 (4.3734)	Learning Rate [0.00125]
1: TRAIN [0][3950/6832]	Time 0.096 (0.105)	Data 0.00117 (0.00092)	Tok/s 54469 (59296)	Loss/tok 3.5169 (4.3735)	Learning Rate [0.00125]
0: TRAIN [0][3950/6832]	Time 0.096 (0.105)	Data 0.00118 (0.00095)	Tok/s 54460 (58844)	Loss/tok 3.8059 (4.3745)	Learning Rate [0.00125]
1: TRAIN [0][3960/6832]	Time 0.094 (0.105)	Data 0.00086 (0.00092)	Tok/s 54431 (59295)	Loss/tok 3.4474 (4.3717)	Learning Rate [0.00125]
0: TRAIN [0][3960/6832]	Time 0.094 (0.105)	Data 0.00090 (0.00095)	Tok/s 53427 (58843)	Loss/tok 3.5042 (4.3727)	Learning Rate [0.00125]
2: TRAIN [0][3960/6832]	Time 0.094 (0.105)	Data 0.00088 (0.00096)	Tok/s 54406 (59672)	Loss/tok 3.5657 (4.3672)	Learning Rate [0.00125]
3: TRAIN [0][3960/6832]	Time 0.094 (0.105)	Data 0.00172 (0.00095)	Tok/s 54407 (60117)	Loss/tok 3.5119 (4.3716)	Learning Rate [0.00125]
1: TRAIN [0][3970/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00092)	Tok/s 58368 (59301)	Loss/tok 3.6154 (4.3697)	Learning Rate [0.00125]
2: TRAIN [0][3970/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00096)	Tok/s 58890 (59679)	Loss/tok 3.6648 (4.3653)	Learning Rate [0.00125]
0: TRAIN [0][3970/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00095)	Tok/s 57778 (58850)	Loss/tok 3.7237 (4.3709)	Learning Rate [0.00125]
3: TRAIN [0][3970/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00095)	Tok/s 58857 (60123)	Loss/tok 3.7395 (4.3698)	Learning Rate [0.00125]
1: TRAIN [0][3980/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 77874 (59322)	Loss/tok 3.6311 (4.3675)	Learning Rate [0.00125]
2: TRAIN [0][3980/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 77816 (59699)	Loss/tok 3.8936 (4.3631)	Learning Rate [0.00125]
0: TRAIN [0][3980/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 77289 (58871)	Loss/tok 3.6451 (4.3687)	Learning Rate [0.00125]
3: TRAIN [0][3980/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 78782 (60143)	Loss/tok 3.6465 (4.3676)	Learning Rate [0.00125]
1: TRAIN [0][3990/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00092)	Tok/s 55469 (59322)	Loss/tok 3.6285 (4.3655)	Learning Rate [0.00125]
0: TRAIN [0][3990/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00095)	Tok/s 55461 (58871)	Loss/tok 3.5963 (4.3667)	Learning Rate [0.00125]
2: TRAIN [0][3990/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00096)	Tok/s 55290 (59698)	Loss/tok 3.7424 (4.3612)	Learning Rate [0.00125]
3: TRAIN [0][3990/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00095)	Tok/s 55547 (60142)	Loss/tok 3.6067 (4.3657)	Learning Rate [0.00125]
1: TRAIN [0][4000/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00092)	Tok/s 53073 (59313)	Loss/tok 3.5646 (4.3639)	Learning Rate [0.00125]
0: TRAIN [0][4000/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00095)	Tok/s 53074 (58862)	Loss/tok 3.4954 (4.3650)	Learning Rate [0.00125]
2: TRAIN [0][4000/6832]	Time 0.087 (0.105)	Data 0.00088 (0.00096)	Tok/s 53044 (59688)	Loss/tok 3.7033 (4.3597)	Learning Rate [0.00125]
3: TRAIN [0][4000/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00095)	Tok/s 53035 (60133)	Loss/tok 3.3875 (4.3640)	Learning Rate [0.00125]
1: TRAIN [0][4010/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00092)	Tok/s 68979 (59305)	Loss/tok 3.7487 (4.3620)	Learning Rate [0.00125]
2: TRAIN [0][4010/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00096)	Tok/s 68955 (59679)	Loss/tok 3.8968 (4.3581)	Learning Rate [0.00125]
0: TRAIN [0][4010/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 68917 (58854)	Loss/tok 3.7815 (4.3634)	Learning Rate [0.00125]
3: TRAIN [0][4010/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00095)	Tok/s 69419 (60123)	Loss/tok 3.8043 (4.3625)	Learning Rate [0.00125]
2: TRAIN [0][4020/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00096)	Tok/s 53721 (59677)	Loss/tok 3.4377 (4.3564)	Learning Rate [0.00125]
1: TRAIN [0][4020/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00092)	Tok/s 53647 (59303)	Loss/tok 3.5262 (4.3603)	Learning Rate [0.00125]
0: TRAIN [0][4020/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00095)	Tok/s 53647 (58853)	Loss/tok 3.2688 (4.3616)	Learning Rate [0.00125]
3: TRAIN [0][4020/6832]	Time 0.091 (0.105)	Data 0.00089 (0.00095)	Tok/s 54186 (60120)	Loss/tok 3.3601 (4.3607)	Learning Rate [0.00125]
1: TRAIN [0][4030/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00092)	Tok/s 71082 (59307)	Loss/tok 3.7081 (4.3586)	Learning Rate [0.00125]
3: TRAIN [0][4030/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 71579 (60124)	Loss/tok 3.8472 (4.3590)	Learning Rate [0.00125]
0: TRAIN [0][4030/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 71066 (58857)	Loss/tok 3.6835 (4.3598)	Learning Rate [0.00125]
2: TRAIN [0][4030/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00096)	Tok/s 71119 (59681)	Loss/tok 3.7183 (4.3546)	Learning Rate [0.00125]
2: TRAIN [0][4040/6832]	Time 0.081 (0.105)	Data 0.00093 (0.00096)	Tok/s 53134 (59679)	Loss/tok 3.5318 (4.3530)	Learning Rate [0.00125]
1: TRAIN [0][4040/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00092)	Tok/s 52314 (59305)	Loss/tok 3.5923 (4.3569)	Learning Rate [0.00125]
0: TRAIN [0][4040/6832]	Time 0.081 (0.105)	Data 0.00088 (0.00095)	Tok/s 52310 (58856)	Loss/tok 3.4289 (4.3581)	Learning Rate [0.00125]
3: TRAIN [0][4040/6832]	Time 0.081 (0.105)	Data 0.00092 (0.00095)	Tok/s 53853 (60123)	Loss/tok 3.3105 (4.3573)	Learning Rate [0.00125]
1: TRAIN [0][4050/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00092)	Tok/s 53224 (59300)	Loss/tok 3.7610 (4.3555)	Learning Rate [0.00125]
2: TRAIN [0][4050/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00096)	Tok/s 53206 (59674)	Loss/tok 3.7135 (4.3514)	Learning Rate [0.00125]
0: TRAIN [0][4050/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00095)	Tok/s 53237 (58851)	Loss/tok 3.5985 (4.3563)	Learning Rate [0.00125]
3: TRAIN [0][4050/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00095)	Tok/s 53745 (60118)	Loss/tok 3.6618 (4.3556)	Learning Rate [0.00125]
1: TRAIN [0][4060/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00092)	Tok/s 81839 (59296)	Loss/tok 3.5244 (4.3538)	Learning Rate [0.00125]
2: TRAIN [0][4060/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00096)	Tok/s 82747 (59669)	Loss/tok 3.5450 (4.3496)	Learning Rate [0.00125]
3: TRAIN [0][4060/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00095)	Tok/s 82851 (60113)	Loss/tok 3.6215 (4.3540)	Learning Rate [0.00125]
0: TRAIN [0][4060/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 81835 (58846)	Loss/tok 3.7512 (4.3545)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [0][4070/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00092)	Tok/s 58358 (59290)	Loss/tok 3.5705 (4.3521)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
0: TRAIN [0][4070/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00095)	Tok/s 57719 (58837)	Loss/tok 3.5256 (4.3527)	Learning Rate [0.00125]
3: Upscaling, new scale: 8192.0
2: TRAIN [0][4070/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00096)	Tok/s 58714 (59664)	Loss/tok 3.7052 (4.3480)	Learning Rate [0.00125]
3: TRAIN [0][4070/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00095)	Tok/s 58668 (60108)	Loss/tok 3.7240 (4.3522)	Learning Rate [0.00125]
1: TRAIN [0][4080/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 65081 (59295)	Loss/tok 3.8689 (4.3503)	Learning Rate [0.00125]
0: TRAIN [0][4080/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 65095 (58842)	Loss/tok 3.8446 (4.3511)	Learning Rate [0.00125]
2: TRAIN [0][4080/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 65115 (59669)	Loss/tok 3.7564 (4.3463)	Learning Rate [0.00125]
3: TRAIN [0][4080/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 65856 (60112)	Loss/tok 3.9430 (4.3504)	Learning Rate [0.00125]
1: TRAIN [0][4090/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00092)	Tok/s 60404 (59285)	Loss/tok 3.7487 (4.3488)	Learning Rate [0.00125]
0: TRAIN [0][4090/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00095)	Tok/s 60422 (58830)	Loss/tok 3.7580 (4.3495)	Learning Rate [0.00125]
2: TRAIN [0][4090/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00096)	Tok/s 60403 (59660)	Loss/tok 3.7760 (4.3447)	Learning Rate [0.00125]
3: TRAIN [0][4090/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00095)	Tok/s 61440 (60105)	Loss/tok 3.8571 (4.3489)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
2: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
3: Skipped batch, new scale: 4096.0
1: TRAIN [0][4100/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00092)	Tok/s 65567 (59294)	Loss/tok 4.0175 (4.3469)	Learning Rate [0.00125]
0: TRAIN [0][4100/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00095)	Tok/s 65390 (58840)	Loss/tok 3.7979 (4.3476)	Learning Rate [0.00125]
2: TRAIN [0][4100/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00096)	Tok/s 65521 (59669)	Loss/tok 3.8102 (4.3428)	Learning Rate [0.00125]
3: TRAIN [0][4100/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00095)	Tok/s 65544 (60113)	Loss/tok 3.7858 (4.3470)	Learning Rate [0.00125]
1: TRAIN [0][4110/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00092)	Tok/s 49795 (59285)	Loss/tok 3.5519 (4.3453)	Learning Rate [0.00125]
0: TRAIN [0][4110/6832]	Time 0.108 (0.105)	Data 0.00094 (0.00095)	Tok/s 49577 (58831)	Loss/tok 3.5883 (4.3460)	Learning Rate [0.00125]
2: TRAIN [0][4110/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00096)	Tok/s 50637 (59660)	Loss/tok 3.5727 (4.3412)	Learning Rate [0.00125]
3: TRAIN [0][4110/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00095)	Tok/s 50661 (60103)	Loss/tok 3.5554 (4.3454)	Learning Rate [0.00125]
1: TRAIN [0][4120/6832]	Time 0.088 (0.105)	Data 0.00084 (0.00092)	Tok/s 53795 (59280)	Loss/tok 3.2412 (4.3437)	Learning Rate [0.00125]
2: TRAIN [0][4120/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00096)	Tok/s 53817 (59655)	Loss/tok 3.5702 (4.3396)	Learning Rate [0.00125]
0: TRAIN [0][4120/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00095)	Tok/s 53845 (58826)	Loss/tok 3.5945 (4.3443)	Learning Rate [0.00125]
3: TRAIN [0][4120/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00095)	Tok/s 53821 (60098)	Loss/tok 3.5224 (4.3437)	Learning Rate [0.00125]
1: TRAIN [0][4130/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00092)	Tok/s 57083 (59287)	Loss/tok 3.9086 (4.3420)	Learning Rate [0.00125]
2: TRAIN [0][4130/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00096)	Tok/s 57797 (59661)	Loss/tok 3.6616 (4.3379)	Learning Rate [0.00125]
0: TRAIN [0][4130/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00095)	Tok/s 57069 (58834)	Loss/tok 3.5964 (4.3424)	Learning Rate [0.00125]
3: TRAIN [0][4130/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00095)	Tok/s 58156 (60103)	Loss/tok 3.8486 (4.3418)	Learning Rate [0.00125]
2: TRAIN [0][4140/6832]	Time 0.067 (0.105)	Data 0.00088 (0.00096)	Tok/s 49919 (59648)	Loss/tok 3.3257 (4.3364)	Learning Rate [0.00125]
1: TRAIN [0][4140/6832]	Time 0.067 (0.105)	Data 0.00088 (0.00092)	Tok/s 49913 (59274)	Loss/tok 3.2927 (4.3405)	Learning Rate [0.00125]
3: TRAIN [0][4140/6832]	Time 0.067 (0.105)	Data 0.00087 (0.00095)	Tok/s 51487 (60091)	Loss/tok 3.2630 (4.3403)	Learning Rate [0.00125]
0: TRAIN [0][4140/6832]	Time 0.067 (0.105)	Data 0.00089 (0.00095)	Tok/s 49941 (58820)	Loss/tok 3.1878 (4.3409)	Learning Rate [0.00125]
2: TRAIN [0][4150/6832]	Time 0.068 (0.105)	Data 0.00088 (0.00095)	Tok/s 50661 (59654)	Loss/tok 3.2272 (4.3345)	Learning Rate [0.00125]
1: TRAIN [0][4150/6832]	Time 0.068 (0.105)	Data 0.00084 (0.00092)	Tok/s 50613 (59281)	Loss/tok 3.2011 (4.3387)	Learning Rate [0.00125]
3: TRAIN [0][4150/6832]	Time 0.068 (0.105)	Data 0.00087 (0.00095)	Tok/s 52231 (60097)	Loss/tok 3.3175 (4.3385)	Learning Rate [0.00125]
0: TRAIN [0][4150/6832]	Time 0.068 (0.105)	Data 0.00089 (0.00095)	Tok/s 50655 (58827)	Loss/tok 3.2714 (4.3391)	Learning Rate [0.00125]
1: TRAIN [0][4160/6832]	Time 0.073 (0.105)	Data 0.00085 (0.00092)	Tok/s 50744 (59274)	Loss/tok 3.3526 (4.3371)	Learning Rate [0.00125]
0: TRAIN [0][4160/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00095)	Tok/s 50703 (58820)	Loss/tok 3.4046 (4.3375)	Learning Rate [0.00125]
2: TRAIN [0][4160/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00095)	Tok/s 52463 (59648)	Loss/tok 3.5282 (4.3329)	Learning Rate [0.00125]
3: TRAIN [0][4160/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00095)	Tok/s 52447 (60091)	Loss/tok 3.1921 (4.3369)	Learning Rate [0.00125]
1: TRAIN [0][4170/6832]	Time 0.093 (0.105)	Data 0.00104 (0.00092)	Tok/s 53708 (59269)	Loss/tok 3.6156 (4.3355)	Learning Rate [0.00125]
0: TRAIN [0][4170/6832]	Time 0.093 (0.105)	Data 0.00104 (0.00095)	Tok/s 53693 (58815)	Loss/tok 3.4918 (4.3360)	Learning Rate [0.00125]
2: TRAIN [0][4170/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00095)	Tok/s 53702 (59643)	Loss/tok 3.4076 (4.3314)	Learning Rate [0.00125]
3: TRAIN [0][4170/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00095)	Tok/s 53727 (60085)	Loss/tok 3.6012 (4.3355)	Learning Rate [0.00125]
2: TRAIN [0][4180/6832]	Time 0.118 (0.105)	Data 0.00103 (0.00095)	Tok/s 57462 (59641)	Loss/tok 3.6759 (4.3296)	Learning Rate [0.00125]
3: TRAIN [0][4180/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00095)	Tok/s 57478 (60083)	Loss/tok 3.5993 (4.3338)	Learning Rate [0.00125]
1: TRAIN [0][4180/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00092)	Tok/s 57406 (59268)	Loss/tok 3.7167 (4.3339)	Learning Rate [0.00125]
0: TRAIN [0][4180/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00095)	Tok/s 57391 (58815)	Loss/tok 3.4331 (4.3342)	Learning Rate [0.00125]
1: TRAIN [0][4190/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00092)	Tok/s 74206 (59285)	Loss/tok 3.6869 (4.3319)	Learning Rate [0.00125]
0: TRAIN [0][4190/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00095)	Tok/s 73961 (58832)	Loss/tok 3.6723 (4.3321)	Learning Rate [0.00125]
2: TRAIN [0][4190/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00095)	Tok/s 74128 (59658)	Loss/tok 3.5427 (4.3274)	Learning Rate [0.00125]
3: TRAIN [0][4190/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 74692 (60101)	Loss/tok 3.6741 (4.3316)	Learning Rate [0.00125]
1: TRAIN [0][4200/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00092)	Tok/s 91079 (59290)	Loss/tok 3.5777 (4.3302)	Learning Rate [0.00125]
0: TRAIN [0][4200/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 90182 (58837)	Loss/tok 3.4508 (4.3302)	Learning Rate [0.00125]
2: TRAIN [0][4200/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 92656 (59663)	Loss/tok 3.6521 (4.3256)	Learning Rate [0.00125]
3: TRAIN [0][4200/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00095)	Tok/s 94547 (60106)	Loss/tok 3.5782 (4.3299)	Learning Rate [0.00125]
1: TRAIN [0][4210/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00092)	Tok/s 53369 (59297)	Loss/tok 3.6258 (4.3285)	Learning Rate [0.00125]
2: TRAIN [0][4210/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00095)	Tok/s 54347 (59670)	Loss/tok 3.5859 (4.3236)	Learning Rate [0.00125]
3: TRAIN [0][4210/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00095)	Tok/s 54324 (60113)	Loss/tok 3.5584 (4.3280)	Learning Rate [0.00125]
0: TRAIN [0][4210/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00095)	Tok/s 53282 (58845)	Loss/tok 3.6774 (4.3284)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
3: Gradient norm: inf
2: Gradient norm: inf
1: Skipped batch, new scale: 2048.0
2: Skipped batch, new scale: 2048.0
3: Skipped batch, new scale: 2048.0
1: TRAIN [0][4220/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00092)	Tok/s 66071 (59321)	Loss/tok 3.7934 (4.3264)	Learning Rate [0.00125]
0: TRAIN [0][4220/6832]	Time 0.126 (0.105)	Data 0.00100 (0.00095)	Tok/s 66065 (58870)	Loss/tok 3.6392 (4.3261)	Learning Rate [0.00125]
2: TRAIN [0][4220/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00095)	Tok/s 66049 (59695)	Loss/tok 3.8828 (4.3213)	Learning Rate [0.00125]
3: TRAIN [0][4220/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00095)	Tok/s 66910 (60139)	Loss/tok 4.0123 (4.3259)	Learning Rate [0.00125]
1: TRAIN [0][4230/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00092)	Tok/s 66420 (59315)	Loss/tok 3.8585 (4.3248)	Learning Rate [0.00125]
0: TRAIN [0][4230/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00095)	Tok/s 66417 (58863)	Loss/tok 3.6294 (4.3244)	Learning Rate [0.00125]
2: TRAIN [0][4230/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 66385 (59689)	Loss/tok 3.6133 (4.3197)	Learning Rate [0.00125]
3: TRAIN [0][4230/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00095)	Tok/s 66597 (60133)	Loss/tok 3.8858 (4.3243)	Learning Rate [0.00125]
2: TRAIN [0][4240/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00095)	Tok/s 50769 (59690)	Loss/tok 3.5267 (4.3180)	Learning Rate [0.00125]
1: TRAIN [0][4240/6832]	Time 0.088 (0.105)	Data 0.00103 (0.00092)	Tok/s 50768 (59317)	Loss/tok 3.3665 (4.3231)	Learning Rate [0.00125]
3: TRAIN [0][4240/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00095)	Tok/s 50756 (60134)	Loss/tok 3.2887 (4.3226)	Learning Rate [0.00125]
0: TRAIN [0][4240/6832]	Time 0.088 (0.105)	Data 0.00108 (0.00095)	Tok/s 50371 (58865)	Loss/tok 3.6994 (4.3226)	Learning Rate [0.00125]
1: TRAIN [0][4250/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00092)	Tok/s 51502 (59318)	Loss/tok 3.5000 (4.3213)	Learning Rate [0.00125]
2: TRAIN [0][4250/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00095)	Tok/s 51767 (59691)	Loss/tok 3.5626 (4.3163)	Learning Rate [0.00125]
0: TRAIN [0][4250/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00095)	Tok/s 51503 (58868)	Loss/tok 3.5901 (4.3211)	Learning Rate [0.00125]
3: TRAIN [0][4250/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00095)	Tok/s 52630 (60135)	Loss/tok 3.6347 (4.3209)	Learning Rate [0.00125]
1: TRAIN [0][4260/6832]	Time 0.058 (0.105)	Data 0.00082 (0.00092)	Tok/s 51074 (59329)	Loss/tok 3.1564 (4.3194)	Learning Rate [0.00125]
2: TRAIN [0][4260/6832]	Time 0.058 (0.105)	Data 0.00099 (0.00095)	Tok/s 51157 (59702)	Loss/tok 3.1266 (4.3144)	Learning Rate [0.00125]
0: TRAIN [0][4260/6832]	Time 0.058 (0.105)	Data 0.00091 (0.00095)	Tok/s 50567 (58878)	Loss/tok 2.9860 (4.3191)	Learning Rate [0.00125]
3: TRAIN [0][4260/6832]	Time 0.058 (0.105)	Data 0.00097 (0.00095)	Tok/s 51532 (60146)	Loss/tok 3.0138 (4.3189)	Learning Rate [0.00125]
2: TRAIN [0][4270/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00095)	Tok/s 53238 (59701)	Loss/tok 3.4086 (4.3129)	Learning Rate [0.00125]
1: TRAIN [0][4270/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00092)	Tok/s 52055 (59328)	Loss/tok 3.4452 (4.3178)	Learning Rate [0.00125]
3: TRAIN [0][4270/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00095)	Tok/s 53870 (60145)	Loss/tok 3.5314 (4.3173)	Learning Rate [0.00125]
0: TRAIN [0][4270/6832]	Time 0.071 (0.105)	Data 0.00099 (0.00095)	Tok/s 52051 (58879)	Loss/tok 3.4826 (4.3176)	Learning Rate [0.00125]
1: TRAIN [0][4280/6832]	Time 0.077 (0.105)	Data 0.00101 (0.00092)	Tok/s 51309 (59319)	Loss/tok 3.3010 (4.3164)	Learning Rate [0.00125]
0: TRAIN [0][4280/6832]	Time 0.077 (0.105)	Data 0.00097 (0.00095)	Tok/s 51296 (58871)	Loss/tok 3.2762 (4.3160)	Learning Rate [0.00125]
2: TRAIN [0][4280/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00095)	Tok/s 51315 (59692)	Loss/tok 3.2752 (4.3113)	Learning Rate [0.00125]
3: TRAIN [0][4280/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00095)	Tok/s 52564 (60137)	Loss/tok 3.4917 (4.3158)	Learning Rate [0.00125]
1: TRAIN [0][4290/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00092)	Tok/s 77346 (59328)	Loss/tok 3.6840 (4.3145)	Learning Rate [0.00125]
0: TRAIN [0][4290/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 76984 (58878)	Loss/tok 3.6769 (4.3142)	Learning Rate [0.00125]
2: TRAIN [0][4290/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 77415 (59702)	Loss/tok 3.7455 (4.3094)	Learning Rate [0.00125]
3: TRAIN [0][4290/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 78331 (60147)	Loss/tok 3.7245 (4.3141)	Learning Rate [0.00125]
1: TRAIN [0][4300/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00092)	Tok/s 57211 (59342)	Loss/tok 3.6716 (4.3126)	Learning Rate [0.00125]
2: TRAIN [0][4300/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00095)	Tok/s 57204 (59716)	Loss/tok 3.5241 (4.3076)	Learning Rate [0.00125]
3: TRAIN [0][4300/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00095)	Tok/s 57457 (60161)	Loss/tok 3.6388 (4.3123)	Learning Rate [0.00125]
0: TRAIN [0][4300/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00095)	Tok/s 57171 (58892)	Loss/tok 3.6870 (4.3122)	Learning Rate [0.00125]
0: TRAIN [0][4310/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 67142 (58896)	Loss/tok 3.9554 (4.3106)	Learning Rate [0.00125]
1: TRAIN [0][4310/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00092)	Tok/s 67108 (59346)	Loss/tok 3.7109 (4.3109)	Learning Rate [0.00125]
2: TRAIN [0][4310/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 67004 (59719)	Loss/tok 3.6182 (4.3060)	Learning Rate [0.00125]
3: TRAIN [0][4310/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 67436 (60165)	Loss/tok 3.6108 (4.3106)	Learning Rate [0.00125]
2: TRAIN [0][4320/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00095)	Tok/s 54400 (59726)	Loss/tok 3.7084 (4.3043)	Learning Rate [0.00125]
3: TRAIN [0][4320/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00095)	Tok/s 54567 (60171)	Loss/tok 3.7302 (4.3090)	Learning Rate [0.00125]
1: TRAIN [0][4320/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00092)	Tok/s 53386 (59352)	Loss/tok 3.7465 (4.3092)	Learning Rate [0.00125]
0: TRAIN [0][4320/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00095)	Tok/s 53416 (58903)	Loss/tok 3.6051 (4.3088)	Learning Rate [0.00125]
2: TRAIN [0][4330/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 88956 (59730)	Loss/tok 3.3851 (4.3026)	Learning Rate [0.00125]
1: TRAIN [0][4330/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00092)	Tok/s 88263 (59356)	Loss/tok 3.6459 (4.3076)	Learning Rate [0.00125]
0: TRAIN [0][4330/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 87401 (58907)	Loss/tok 3.5923 (4.3072)	Learning Rate [0.00125]
3: TRAIN [0][4330/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 89645 (60175)	Loss/tok 3.4116 (4.3073)	Learning Rate [0.00125]
2: TRAIN [0][4340/6832]	Time 0.080 (0.105)	Data 0.00095 (0.00095)	Tok/s 52555 (59727)	Loss/tok 3.5359 (4.3010)	Learning Rate [0.00125]
1: TRAIN [0][4340/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00092)	Tok/s 51841 (59353)	Loss/tok 3.6396 (4.3061)	Learning Rate [0.00125]
0: TRAIN [0][4340/6832]	Time 0.080 (0.105)	Data 0.00093 (0.00095)	Tok/s 50973 (58905)	Loss/tok 3.2749 (4.3057)	Learning Rate [0.00125]
3: TRAIN [0][4340/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00095)	Tok/s 52552 (60172)	Loss/tok 3.4629 (4.3058)	Learning Rate [0.00125]
1: Upscaling, new scale: 4096.0
0: Upscaling, new scale: 4096.0
2: Upscaling, new scale: 4096.0
3: Upscaling, new scale: 4096.0
1: TRAIN [0][4350/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00092)	Tok/s 76260 (59357)	Loss/tok 3.6843 (4.3043)	Learning Rate [0.00125]
2: TRAIN [0][4350/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00095)	Tok/s 77215 (59731)	Loss/tok 3.8832 (4.2994)	Learning Rate [0.00125]
0: TRAIN [0][4350/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00095)	Tok/s 76288 (58909)	Loss/tok 3.6279 (4.3039)	Learning Rate [0.00125]
3: TRAIN [0][4350/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00095)	Tok/s 77266 (60175)	Loss/tok 3.7826 (4.3041)	Learning Rate [0.00125]
1: TRAIN [0][4360/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00092)	Tok/s 83962 (59363)	Loss/tok 3.5863 (4.3026)	Learning Rate [0.00125]
0: TRAIN [0][4360/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 83482 (58916)	Loss/tok 3.6393 (4.3022)	Learning Rate [0.00125]
2: TRAIN [0][4360/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 84556 (59737)	Loss/tok 3.4640 (4.2975)	Learning Rate [0.00125]
3: TRAIN [0][4360/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00095)	Tok/s 84926 (60181)	Loss/tok 3.5138 (4.3023)	Learning Rate [0.00125]
1: TRAIN [0][4370/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00092)	Tok/s 51763 (59357)	Loss/tok 3.4868 (4.3012)	Learning Rate [0.00125]
0: TRAIN [0][4370/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00095)	Tok/s 51765 (58910)	Loss/tok 3.7254 (4.3006)	Learning Rate [0.00125]
2: TRAIN [0][4370/6832]	Time 0.114 (0.105)	Data 0.00095 (0.00095)	Tok/s 51998 (59730)	Loss/tok 3.6598 (4.2960)	Learning Rate [0.00125]
3: TRAIN [0][4370/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00095)	Tok/s 52879 (60173)	Loss/tok 3.6071 (4.3007)	Learning Rate [0.00125]
1: TRAIN [0][4380/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00092)	Tok/s 53669 (59355)	Loss/tok 3.6839 (4.2997)	Learning Rate [0.00125]
2: TRAIN [0][4380/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00095)	Tok/s 53663 (59728)	Loss/tok 3.5119 (4.2946)	Learning Rate [0.00125]
0: TRAIN [0][4380/6832]	Time 0.093 (0.105)	Data 0.00088 (0.00095)	Tok/s 53661 (58907)	Loss/tok 3.5402 (4.2993)	Learning Rate [0.00125]
3: TRAIN [0][4380/6832]	Time 0.093 (0.105)	Data 0.00088 (0.00095)	Tok/s 53658 (60171)	Loss/tok 3.6898 (4.2993)	Learning Rate [0.00125]
1: TRAIN [0][4390/6832]	Time 0.095 (0.105)	Data 0.00084 (0.00092)	Tok/s 52745 (59352)	Loss/tok 3.5243 (4.2983)	Learning Rate [0.00125]
2: TRAIN [0][4390/6832]	Time 0.095 (0.105)	Data 0.00091 (0.00095)	Tok/s 54127 (59726)	Loss/tok 3.3076 (4.2929)	Learning Rate [0.00125]
3: TRAIN [0][4390/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00095)	Tok/s 54113 (60169)	Loss/tok 3.6280 (4.2977)	Learning Rate [0.00125]
0: TRAIN [0][4390/6832]	Time 0.095 (0.105)	Data 0.00097 (0.00095)	Tok/s 52726 (58902)	Loss/tok 3.4664 (4.2977)	Learning Rate [0.00125]
1: TRAIN [0][4400/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00092)	Tok/s 67853 (59349)	Loss/tok 3.7682 (4.2968)	Learning Rate [0.00125]
0: TRAIN [0][4400/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 66926 (58899)	Loss/tok 3.6686 (4.2962)	Learning Rate [0.00125]
2: TRAIN [0][4400/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 67906 (59722)	Loss/tok 3.7612 (4.2915)	Learning Rate [0.00125]
3: TRAIN [0][4400/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 67877 (60166)	Loss/tok 3.5976 (4.2963)	Learning Rate [0.00125]
2: TRAIN [0][4410/6832]	Time 0.055 (0.105)	Data 0.00089 (0.00095)	Tok/s 49027 (59705)	Loss/tok 2.8669 (4.2902)	Learning Rate [0.00125]
1: TRAIN [0][4410/6832]	Time 0.055 (0.105)	Data 0.00084 (0.00092)	Tok/s 48683 (59331)	Loss/tok 2.9366 (4.2955)	Learning Rate [0.00125]
3: TRAIN [0][4410/6832]	Time 0.055 (0.105)	Data 0.00086 (0.00095)	Tok/s 49427 (60148)	Loss/tok 2.7936 (4.2948)	Learning Rate [0.00125]
0: TRAIN [0][4410/6832]	Time 0.055 (0.105)	Data 0.00093 (0.00095)	Tok/s 46681 (58882)	Loss/tok 2.9772 (4.2949)	Learning Rate [0.00125]
2: TRAIN [0][4420/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00095)	Tok/s 63564 (59708)	Loss/tok 3.8644 (4.2887)	Learning Rate [0.00125]
3: TRAIN [0][4420/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00095)	Tok/s 63557 (60151)	Loss/tok 3.6018 (4.2933)	Learning Rate [0.00125]
1: TRAIN [0][4420/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00092)	Tok/s 63569 (59334)	Loss/tok 3.6418 (4.2940)	Learning Rate [0.00125]
0: TRAIN [0][4420/6832]	Time 0.127 (0.105)	Data 0.00098 (0.00095)	Tok/s 63546 (58885)	Loss/tok 3.7115 (4.2934)	Learning Rate [0.00125]
1: TRAIN [0][4430/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00092)	Tok/s 69511 (59339)	Loss/tok 3.7004 (4.2923)	Learning Rate [0.00125]
0: TRAIN [0][4430/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 69517 (58892)	Loss/tok 3.6039 (4.2917)	Learning Rate [0.00125]
2: TRAIN [0][4430/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 69488 (59713)	Loss/tok 3.6706 (4.2869)	Learning Rate [0.00125]
3: TRAIN [0][4430/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 70246 (60156)	Loss/tok 3.8454 (4.2917)	Learning Rate [0.00125]
2: TRAIN [0][4440/6832]	Time 0.063 (0.105)	Data 0.00089 (0.00095)	Tok/s 46838 (59715)	Loss/tok 3.0503 (4.2854)	Learning Rate [0.00125]
1: TRAIN [0][4440/6832]	Time 0.063 (0.105)	Data 0.00087 (0.00092)	Tok/s 46829 (59341)	Loss/tok 2.9981 (4.2906)	Learning Rate [0.00125]
0: TRAIN [0][4440/6832]	Time 0.063 (0.105)	Data 0.00091 (0.00095)	Tok/s 46815 (58894)	Loss/tok 3.2815 (4.2902)	Learning Rate [0.00125]
3: TRAIN [0][4440/6832]	Time 0.063 (0.105)	Data 0.00086 (0.00095)	Tok/s 48796 (60158)	Loss/tok 3.2074 (4.2902)	Learning Rate [0.00125]
2: TRAIN [0][4450/6832]	Time 0.058 (0.105)	Data 0.00089 (0.00095)	Tok/s 48678 (59718)	Loss/tok 2.8485 (4.2838)	Learning Rate [0.00125]
1: TRAIN [0][4450/6832]	Time 0.058 (0.105)	Data 0.00088 (0.00092)	Tok/s 48277 (59345)	Loss/tok 3.0196 (4.2890)	Learning Rate [0.00125]
0: TRAIN [0][4450/6832]	Time 0.058 (0.105)	Data 0.00094 (0.00095)	Tok/s 46482 (58898)	Loss/tok 2.8793 (4.2885)	Learning Rate [0.00125]
3: TRAIN [0][4450/6832]	Time 0.058 (0.105)	Data 0.00087 (0.00095)	Tok/s 48669 (60162)	Loss/tok 3.0369 (4.2887)	Learning Rate [0.00125]
1: TRAIN [0][4460/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00092)	Tok/s 52888 (59340)	Loss/tok 3.4073 (4.2873)	Learning Rate [0.00125]
2: TRAIN [0][4460/6832]	Time 0.090 (0.105)	Data 0.00097 (0.00095)	Tok/s 52887 (59713)	Loss/tok 3.5540 (4.2823)	Learning Rate [0.00125]
0: TRAIN [0][4460/6832]	Time 0.089 (0.105)	Data 0.00098 (0.00095)	Tok/s 52919 (58893)	Loss/tok 3.5479 (4.2870)	Learning Rate [0.00125]
3: TRAIN [0][4460/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00095)	Tok/s 52885 (60156)	Loss/tok 3.4268 (4.2872)	Learning Rate [0.00125]
1: TRAIN [0][4470/6832]	Time 0.103 (0.105)	Data 0.00082 (0.00092)	Tok/s 53609 (59342)	Loss/tok 3.6182 (4.2858)	Learning Rate [0.00125]
2: TRAIN [0][4470/6832]	Time 0.103 (0.105)	Data 0.00087 (0.00095)	Tok/s 53598 (59716)	Loss/tok 3.6604 (4.2806)	Learning Rate [0.00125]
3: TRAIN [0][4470/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00095)	Tok/s 53594 (60158)	Loss/tok 3.4872 (4.2857)	Learning Rate [0.00125]
0: TRAIN [0][4470/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00095)	Tok/s 53576 (58895)	Loss/tok 3.5000 (4.2854)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [0][4480/6832]	Time 0.127 (0.105)	Data 0.00098 (0.00092)	Tok/s 64382 (59351)	Loss/tok 3.9147 (4.2841)	Learning Rate [0.00125]
0: TRAIN [0][4480/6832]	Time 0.127 (0.105)	Data 0.00102 (0.00095)	Tok/s 64359 (58905)	Loss/tok 3.5552 (4.2838)	Learning Rate [0.00125]
2: TRAIN [0][4480/6832]	Time 0.127 (0.105)	Data 0.00099 (0.00095)	Tok/s 64326 (59724)	Loss/tok 3.5869 (4.2789)	Learning Rate [0.00125]
3: TRAIN [0][4480/6832]	Time 0.127 (0.105)	Data 0.00107 (0.00095)	Tok/s 65230 (60167)	Loss/tok 3.6430 (4.2841)	Learning Rate [0.00125]
2: Gradient norm: inf
3: Gradient norm: inf
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
1: TRAIN [0][4490/6832]	Time 0.061 (0.105)	Data 0.00091 (0.00092)	Tok/s 48555 (59356)	Loss/tok 3.1169 (4.2826)	Learning Rate [0.00125]
2: TRAIN [0][4490/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00095)	Tok/s 48661 (59729)	Loss/tok 3.1192 (4.2773)	Learning Rate [0.00125]
0: TRAIN [0][4490/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00095)	Tok/s 48547 (58910)	Loss/tok 3.2254 (4.2821)	Learning Rate [0.00125]
3: TRAIN [0][4490/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00095)	Tok/s 50521 (60172)	Loss/tok 3.0933 (4.2825)	Learning Rate [0.00125]
1: TRAIN [0][4500/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00092)	Tok/s 51452 (59343)	Loss/tok 3.8310 (4.2812)	Learning Rate [0.00125]
2: TRAIN [0][4500/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00095)	Tok/s 51517 (59717)	Loss/tok 3.5169 (4.2759)	Learning Rate [0.00125]
0: TRAIN [0][4500/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00095)	Tok/s 50495 (58896)	Loss/tok 3.8004 (4.2808)	Learning Rate [0.00125]
3: TRAIN [0][4500/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00095)	Tok/s 51531 (60160)	Loss/tok 3.5974 (4.2811)	Learning Rate [0.00125]
3: TRAIN [0][4510/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00095)	Tok/s 84905 (60163)	Loss/tok 3.6701 (4.2794)	Learning Rate [0.00125]
2: TRAIN [0][4510/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00095)	Tok/s 84421 (59720)	Loss/tok 3.5142 (4.2742)	Learning Rate [0.00125]
1: TRAIN [0][4510/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 83928 (59346)	Loss/tok 3.5012 (4.2796)	Learning Rate [0.00125]
0: TRAIN [0][4510/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00095)	Tok/s 83486 (58898)	Loss/tok 3.5840 (4.2792)	Learning Rate [0.00125]
1: TRAIN [0][4520/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00092)	Tok/s 65348 (59360)	Loss/tok 3.6646 (4.2780)	Learning Rate [0.00125]
2: TRAIN [0][4520/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00095)	Tok/s 65347 (59734)	Loss/tok 3.8589 (4.2726)	Learning Rate [0.00125]
3: TRAIN [0][4520/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 65340 (60177)	Loss/tok 3.7887 (4.2777)	Learning Rate [0.00125]
0: TRAIN [0][4520/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00095)	Tok/s 65125 (58913)	Loss/tok 3.8787 (4.2777)	Learning Rate [0.00125]
1: TRAIN [0][4530/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00092)	Tok/s 53510 (59367)	Loss/tok 3.7107 (4.2763)	Learning Rate [0.00125]
0: TRAIN [0][4530/6832]	Time 0.120 (0.105)	Data 0.00096 (0.00095)	Tok/s 53403 (58919)	Loss/tok 3.4871 (4.2761)	Learning Rate [0.00125]
2: TRAIN [0][4530/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00095)	Tok/s 54428 (59740)	Loss/tok 3.6359 (4.2710)	Learning Rate [0.00125]
3: TRAIN [0][4530/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00095)	Tok/s 54431 (60183)	Loss/tok 3.5779 (4.2760)	Learning Rate [0.00125]
1: TRAIN [0][4540/6832]	Time 0.072 (0.105)	Data 0.00086 (0.00092)	Tok/s 51405 (59382)	Loss/tok 3.3066 (4.2745)	Learning Rate [0.00125]
2: TRAIN [0][4540/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00095)	Tok/s 51395 (59755)	Loss/tok 3.2256 (4.2692)	Learning Rate [0.00125]
0: TRAIN [0][4540/6832]	Time 0.072 (0.105)	Data 0.00092 (0.00095)	Tok/s 51285 (58935)	Loss/tok 3.1357 (4.2743)	Learning Rate [0.00125]
3: TRAIN [0][4540/6832]	Time 0.072 (0.105)	Data 0.00087 (0.00095)	Tok/s 51349 (60198)	Loss/tok 3.2870 (4.2743)	Learning Rate [0.00125]
3: TRAIN [0][4550/6832]	Time 0.102 (0.105)	Data 0.00099 (0.00095)	Tok/s 56136 (60193)	Loss/tok 3.5477 (4.2730)	Learning Rate [0.00125]
2: TRAIN [0][4550/6832]	Time 0.102 (0.105)	Data 0.00088 (0.00095)	Tok/s 55129 (59751)	Loss/tok 3.5772 (4.2679)	Learning Rate [0.00125]
1: TRAIN [0][4550/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00092)	Tok/s 55035 (59377)	Loss/tok 3.6085 (4.2731)	Learning Rate [0.00125]
0: TRAIN [0][4550/6832]	Time 0.102 (0.105)	Data 0.00093 (0.00095)	Tok/s 55030 (58930)	Loss/tok 3.5704 (4.2728)	Learning Rate [0.00125]
3: TRAIN [0][4560/6832]	Time 0.078 (0.105)	Data 0.00086 (0.00095)	Tok/s 52226 (60186)	Loss/tok 3.3396 (4.2716)	Learning Rate [0.00125]
2: TRAIN [0][4560/6832]	Time 0.078 (0.105)	Data 0.00086 (0.00095)	Tok/s 52210 (59744)	Loss/tok 3.2516 (4.2666)	Learning Rate [0.00125]
1: TRAIN [0][4560/6832]	Time 0.078 (0.105)	Data 0.00086 (0.00092)	Tok/s 52210 (59371)	Loss/tok 3.2776 (4.2718)	Learning Rate [0.00125]
0: TRAIN [0][4560/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00095)	Tok/s 52266 (58925)	Loss/tok 3.5711 (4.2714)	Learning Rate [0.00125]
1: TRAIN [0][4570/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00092)	Tok/s 67901 (59383)	Loss/tok 3.4864 (4.2701)	Learning Rate [0.00125]
2: TRAIN [0][4570/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00095)	Tok/s 67880 (59756)	Loss/tok 3.6564 (4.2650)	Learning Rate [0.00125]
3: TRAIN [0][4570/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00095)	Tok/s 67908 (60198)	Loss/tok 3.6921 (4.2699)	Learning Rate [0.00125]
0: TRAIN [0][4570/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00095)	Tok/s 66924 (58938)	Loss/tok 3.7594 (4.2698)	Learning Rate [0.00125]
2: TRAIN [0][4580/6832]	Time 0.101 (0.105)	Data 0.00084 (0.00095)	Tok/s 52803 (59757)	Loss/tok 3.6128 (4.2634)	Learning Rate [0.00125]
1: TRAIN [0][4580/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00092)	Tok/s 51895 (59384)	Loss/tok 3.4689 (4.2686)	Learning Rate [0.00125]
3: TRAIN [0][4580/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00095)	Tok/s 53179 (60199)	Loss/tok 3.3321 (4.2684)	Learning Rate [0.00125]
0: TRAIN [0][4580/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00095)	Tok/s 51929 (58939)	Loss/tok 3.6030 (4.2683)	Learning Rate [0.00125]
1: TRAIN [0][4590/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 77811 (59393)	Loss/tok 3.5592 (4.2670)	Learning Rate [0.00125]
0: TRAIN [0][4590/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 77427 (58948)	Loss/tok 3.5190 (4.2666)	Learning Rate [0.00125]
3: TRAIN [0][4590/6832]	Time 0.130 (0.105)	Data 0.00104 (0.00095)	Tok/s 78688 (60208)	Loss/tok 3.5894 (4.2670)	Learning Rate [0.00125]
2: TRAIN [0][4590/6832]	Time 0.130 (0.105)	Data 0.00107 (0.00095)	Tok/s 77661 (59765)	Loss/tok 3.6811 (4.2617)	Learning Rate [0.00125]
1: TRAIN [0][4600/6832]	Time 0.081 (0.105)	Data 0.00084 (0.00092)	Tok/s 53337 (59393)	Loss/tok 3.3301 (4.2655)	Learning Rate [0.00125]
2: TRAIN [0][4600/6832]	Time 0.081 (0.105)	Data 0.00094 (0.00095)	Tok/s 53836 (59766)	Loss/tok 3.4145 (4.2602)	Learning Rate [0.00125]
3: TRAIN [0][4600/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00095)	Tok/s 53828 (60208)	Loss/tok 3.3341 (4.2656)	Learning Rate [0.00125]
0: TRAIN [0][4600/6832]	Time 0.081 (0.105)	Data 0.00093 (0.00095)	Tok/s 52241 (58949)	Loss/tok 3.3725 (4.2651)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [0][4610/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00092)	Tok/s 52622 (59379)	Loss/tok 3.5105 (4.2643)	Learning Rate [0.00125]
2: TRAIN [0][4610/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00095)	Tok/s 52650 (59752)	Loss/tok 3.6889 (4.2589)	Learning Rate [0.00125]
3: TRAIN [0][4610/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00095)	Tok/s 52609 (60194)	Loss/tok 3.7356 (4.2644)	Learning Rate [0.00125]
0: TRAIN [0][4610/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00095)	Tok/s 51930 (58935)	Loss/tok 3.5924 (4.2639)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
2: TRAIN [0][4620/6832]	Time 0.102 (0.105)	Data 0.00101 (0.00095)	Tok/s 51462 (59757)	Loss/tok 3.6359 (4.2574)	Learning Rate [0.00125]
1: TRAIN [0][4620/6832]	Time 0.102 (0.105)	Data 0.00087 (0.00092)	Tok/s 51423 (59385)	Loss/tok 3.5849 (4.2627)	Learning Rate [0.00125]
0: TRAIN [0][4620/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00095)	Tok/s 51405 (58941)	Loss/tok 3.5261 (4.2625)	Learning Rate [0.00125]
3: TRAIN [0][4620/6832]	Time 0.102 (0.105)	Data 0.00119 (0.00095)	Tok/s 51478 (60199)	Loss/tok 3.4053 (4.2631)	Learning Rate [0.00125]
1: TRAIN [0][4630/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00092)	Tok/s 60122 (59390)	Loss/tok 3.8033 (4.2611)	Learning Rate [0.00125]
0: TRAIN [0][4630/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 59830 (58947)	Loss/tok 3.4690 (4.2609)	Learning Rate [0.00125]
2: TRAIN [0][4630/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00095)	Tok/s 60037 (59763)	Loss/tok 3.7241 (4.2558)	Learning Rate [0.00125]
3: TRAIN [0][4630/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00095)	Tok/s 60009 (60204)	Loss/tok 3.7534 (4.2614)	Learning Rate [0.00125]
1: TRAIN [0][4640/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00092)	Tok/s 53211 (59394)	Loss/tok 3.8287 (4.2596)	Learning Rate [0.00125]
2: TRAIN [0][4640/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00095)	Tok/s 53194 (59766)	Loss/tok 3.4429 (4.2544)	Learning Rate [0.00125]
0: TRAIN [0][4640/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00095)	Tok/s 52472 (58951)	Loss/tok 3.6317 (4.2593)	Learning Rate [0.00125]
3: TRAIN [0][4640/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00095)	Tok/s 53185 (60208)	Loss/tok 3.4318 (4.2599)	Learning Rate [0.00125]
1: TRAIN [0][4650/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 73969 (59400)	Loss/tok 3.5762 (4.2579)	Learning Rate [0.00125]
2: TRAIN [0][4650/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 73975 (59772)	Loss/tok 3.6524 (4.2528)	Learning Rate [0.00125]
0: TRAIN [0][4650/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 73469 (58957)	Loss/tok 3.6151 (4.2578)	Learning Rate [0.00125]
3: TRAIN [0][4650/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00095)	Tok/s 74232 (60213)	Loss/tok 3.6169 (4.2582)	Learning Rate [0.00125]
1: TRAIN [0][4660/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00092)	Tok/s 61653 (59396)	Loss/tok 3.6715 (4.2566)	Learning Rate [0.00125]
3: TRAIN [0][4660/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 61757 (60208)	Loss/tok 3.9556 (4.2571)	Learning Rate [0.00125]
2: TRAIN [0][4660/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 61665 (59767)	Loss/tok 3.7272 (4.2515)	Learning Rate [0.00125]
0: TRAIN [0][4660/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00095)	Tok/s 61637 (58954)	Loss/tok 3.5732 (4.2564)	Learning Rate [0.00125]
1: TRAIN [0][4670/6832]	Time 0.107 (0.105)	Data 0.00087 (0.00092)	Tok/s 53757 (59391)	Loss/tok 3.4808 (4.2553)	Learning Rate [0.00125]
2: TRAIN [0][4670/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00095)	Tok/s 53710 (59762)	Loss/tok 3.7082 (4.2501)	Learning Rate [0.00125]
0: TRAIN [0][4670/6832]	Time 0.107 (0.105)	Data 0.00091 (0.00095)	Tok/s 53796 (58949)	Loss/tok 3.5241 (4.2550)	Learning Rate [0.00125]
3: TRAIN [0][4670/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00095)	Tok/s 53718 (60203)	Loss/tok 3.4820 (4.2556)	Learning Rate [0.00125]
1: TRAIN [0][4680/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00092)	Tok/s 50780 (59379)	Loss/tok 3.4149 (4.2541)	Learning Rate [0.00125]
2: TRAIN [0][4680/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00095)	Tok/s 51511 (59749)	Loss/tok 3.1976 (4.2490)	Learning Rate [0.00125]
3: TRAIN [0][4680/6832]	Time 0.076 (0.105)	Data 0.00086 (0.00095)	Tok/s 52483 (60191)	Loss/tok 3.3595 (4.2543)	Learning Rate [0.00125]
0: TRAIN [0][4680/6832]	Time 0.076 (0.105)	Data 0.00090 (0.00095)	Tok/s 50815 (58936)	Loss/tok 3.3345 (4.2537)	Learning Rate [0.00125]
1: TRAIN [0][4690/6832]	Time 0.082 (0.105)	Data 0.00085 (0.00092)	Tok/s 52801 (59380)	Loss/tok 3.5785 (4.2528)	Learning Rate [0.00125]
2: TRAIN [0][4690/6832]	Time 0.082 (0.105)	Data 0.00091 (0.00095)	Tok/s 52838 (59750)	Loss/tok 3.3522 (4.2475)	Learning Rate [0.00125]
3: TRAIN [0][4690/6832]	Time 0.082 (0.105)	Data 0.00088 (0.00095)	Tok/s 52826 (60192)	Loss/tok 3.4125 (4.2529)	Learning Rate [0.00125]
0: TRAIN [0][4690/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00095)	Tok/s 52815 (58938)	Loss/tok 3.4234 (4.2522)	Learning Rate [0.00125]
2: TRAIN [0][4700/6832]	Time 0.111 (0.105)	Data 0.00086 (0.00095)	Tok/s 52049 (59746)	Loss/tok 3.2734 (4.2460)	Learning Rate [0.00125]
3: TRAIN [0][4700/6832]	Time 0.111 (0.105)	Data 0.00085 (0.00095)	Tok/s 52085 (60187)	Loss/tok 3.4821 (4.2515)	Learning Rate [0.00125]
1: TRAIN [0][4700/6832]	Time 0.111 (0.105)	Data 0.00107 (0.00092)	Tok/s 52120 (59375)	Loss/tok 3.6712 (4.2514)	Learning Rate [0.00125]
0: TRAIN [0][4700/6832]	Time 0.111 (0.105)	Data 0.00127 (0.00095)	Tok/s 52112 (58934)	Loss/tok 3.5329 (4.2509)	Learning Rate [0.00125]
1: TRAIN [0][4710/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00092)	Tok/s 76640 (59377)	Loss/tok 3.6504 (4.2500)	Learning Rate [0.00125]
0: TRAIN [0][4710/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 76613 (58933)	Loss/tok 3.6811 (4.2493)	Learning Rate [0.00125]
2: TRAIN [0][4710/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 77119 (59748)	Loss/tok 3.7678 (4.2445)	Learning Rate [0.00125]
3: TRAIN [0][4710/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00095)	Tok/s 77584 (60190)	Loss/tok 3.6210 (4.2500)	Learning Rate [0.00125]
1: TRAIN [0][4720/6832]	Time 0.095 (0.105)	Data 0.00084 (0.00092)	Tok/s 52663 (59380)	Loss/tok 3.4491 (4.2486)	Learning Rate [0.00125]
2: TRAIN [0][4720/6832]	Time 0.095 (0.105)	Data 0.00089 (0.00095)	Tok/s 52663 (59750)	Loss/tok 3.7088 (4.2431)	Learning Rate [0.00125]
0: TRAIN [0][4720/6832]	Time 0.095 (0.105)	Data 0.00097 (0.00095)	Tok/s 52684 (58937)	Loss/tok 3.4158 (4.2478)	Learning Rate [0.00125]
3: TRAIN [0][4720/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00095)	Tok/s 52671 (60192)	Loss/tok 3.6563 (4.2486)	Learning Rate [0.00125]
2: TRAIN [0][4730/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 83611 (59755)	Loss/tok 3.6553 (4.2417)	Learning Rate [0.00125]
3: TRAIN [0][4730/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00095)	Tok/s 84492 (60196)	Loss/tok 3.5521 (4.2471)	Learning Rate [0.00125]
0: TRAIN [0][4730/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00095)	Tok/s 82449 (58942)	Loss/tok 3.5649 (4.2464)	Learning Rate [0.00125]
1: TRAIN [0][4730/6832]	Time 0.132 (0.105)	Data 0.00083 (0.00092)	Tok/s 83444 (59384)	Loss/tok 3.5957 (4.2472)	Learning Rate [0.00125]
2: TRAIN [0][4740/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 70583 (59766)	Loss/tok 3.7135 (4.2399)	Learning Rate [0.00125]
3: TRAIN [0][4740/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 71114 (60208)	Loss/tok 3.8640 (4.2456)	Learning Rate [0.00125]
0: TRAIN [0][4740/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 70112 (58954)	Loss/tok 3.7412 (4.2446)	Learning Rate [0.00125]
1: TRAIN [0][4740/6832]	Time 0.130 (0.105)	Data 0.00104 (0.00092)	Tok/s 70084 (59396)	Loss/tok 3.6877 (4.2455)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [0][4750/6832]	Time 0.077 (0.105)	Data 0.00097 (0.00095)	Tok/s 53029 (59759)	Loss/tok 3.4070 (4.2387)	Learning Rate [0.00125]
3: TRAIN [0][4750/6832]	Time 0.077 (0.105)	Data 0.00093 (0.00095)	Tok/s 53657 (60201)	Loss/tok 3.2924 (4.2443)	Learning Rate [0.00125]
0: TRAIN [0][4750/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00095)	Tok/s 52994 (58946)	Loss/tok 3.4282 (4.2434)	Learning Rate [0.00125]
1: TRAIN [0][4750/6832]	Time 0.077 (0.105)	Data 0.00106 (0.00092)	Tok/s 52998 (59389)	Loss/tok 3.4462 (4.2444)	Learning Rate [0.00125]
2: TRAIN [0][4760/6832]	Time 0.117 (0.105)	Data 0.00105 (0.00095)	Tok/s 54890 (59757)	Loss/tok 3.6349 (4.2372)	Learning Rate [0.00125]
3: TRAIN [0][4760/6832]	Time 0.117 (0.105)	Data 0.00100 (0.00095)	Tok/s 54865 (60198)	Loss/tok 3.7676 (4.2430)	Learning Rate [0.00125]
0: TRAIN [0][4760/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00095)	Tok/s 54789 (58944)	Loss/tok 3.6236 (4.2421)	Learning Rate [0.00125]
1: TRAIN [0][4760/6832]	Time 0.117 (0.105)	Data 0.00106 (0.00092)	Tok/s 54836 (59387)	Loss/tok 3.5833 (4.2430)	Learning Rate [0.00125]
0: TRAIN [0][4770/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 77234 (58948)	Loss/tok 3.6950 (4.2407)	Learning Rate [0.00125]
2: TRAIN [0][4770/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 77684 (59760)	Loss/tok 3.6256 (4.2358)	Learning Rate [0.00125]
3: TRAIN [0][4770/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 78156 (60201)	Loss/tok 3.5967 (4.2416)	Learning Rate [0.00125]
1: TRAIN [0][4770/6832]	Time 0.131 (0.105)	Data 0.00106 (0.00092)	Tok/s 77255 (59390)	Loss/tok 3.8070 (4.2416)	Learning Rate [0.00125]
2: TRAIN [0][4780/6832]	Time 0.103 (0.105)	Data 0.00099 (0.00095)	Tok/s 54524 (59753)	Loss/tok 3.6055 (4.2346)	Learning Rate [0.00125]
3: TRAIN [0][4780/6832]	Time 0.104 (0.105)	Data 0.00100 (0.00095)	Tok/s 54407 (60195)	Loss/tok 3.4854 (4.2404)	Learning Rate [0.00125]
0: TRAIN [0][4780/6832]	Time 0.104 (0.105)	Data 0.00108 (0.00095)	Tok/s 53065 (58939)	Loss/tok 3.4738 (4.2395)	Learning Rate [0.00125]
1: TRAIN [0][4780/6832]	Time 0.104 (0.105)	Data 0.00107 (0.00092)	Tok/s 53057 (59382)	Loss/tok 3.5678 (4.2404)	Learning Rate [0.00125]
3: TRAIN [0][4790/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00095)	Tok/s 58997 (60208)	Loss/tok 3.5713 (4.2388)	Learning Rate [0.00125]
2: TRAIN [0][4790/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00095)	Tok/s 57931 (59766)	Loss/tok 3.7110 (4.2331)	Learning Rate [0.00125]
0: TRAIN [0][4790/6832]	Time 0.119 (0.105)	Data 0.00104 (0.00095)	Tok/s 57956 (58952)	Loss/tok 3.8190 (4.2379)	Learning Rate [0.00125]
1: TRAIN [0][4790/6832]	Time 0.119 (0.105)	Data 0.00113 (0.00092)	Tok/s 57952 (59396)	Loss/tok 3.6803 (4.2389)	Learning Rate [0.00125]
2: TRAIN [0][4800/6832]	Time 0.122 (0.105)	Data 0.00100 (0.00095)	Tok/s 58921 (59769)	Loss/tok 3.6426 (4.2318)	Learning Rate [0.00125]
3: TRAIN [0][4800/6832]	Time 0.122 (0.105)	Data 0.00101 (0.00095)	Tok/s 58928 (60211)	Loss/tok 3.5503 (4.2375)	Learning Rate [0.00125]
0: TRAIN [0][4800/6832]	Time 0.122 (0.105)	Data 0.00097 (0.00095)	Tok/s 57880 (58956)	Loss/tok 3.7474 (4.2364)	Learning Rate [0.00125]
1: TRAIN [0][4800/6832]	Time 0.122 (0.105)	Data 0.00109 (0.00092)	Tok/s 57951 (59399)	Loss/tok 3.7308 (4.2375)	Learning Rate [0.00125]
2: TRAIN [0][4810/6832]	Time 0.092 (0.105)	Data 0.00093 (0.00095)	Tok/s 52962 (59767)	Loss/tok 3.3935 (4.2303)	Learning Rate [0.00125]
3: TRAIN [0][4810/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00095)	Tok/s 54113 (60210)	Loss/tok 3.4141 (4.2361)	Learning Rate [0.00125]
0: TRAIN [0][4810/6832]	Time 0.092 (0.105)	Data 0.00094 (0.00095)	Tok/s 52970 (58953)	Loss/tok 3.4688 (4.2351)	Learning Rate [0.00125]
1: TRAIN [0][4810/6832]	Time 0.092 (0.105)	Data 0.00236 (0.00092)	Tok/s 52962 (59397)	Loss/tok 3.3425 (4.2361)	Learning Rate [0.00125]
2: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][4820/6832]	Time 0.127 (0.105)	Data 0.00102 (0.00095)	Tok/s 63387 (59774)	Loss/tok 3.6266 (4.2290)	Learning Rate [0.00125]
3: TRAIN [0][4820/6832]	Time 0.127 (0.105)	Data 0.00104 (0.00095)	Tok/s 63885 (60216)	Loss/tok 3.8038 (4.2348)	Learning Rate [0.00125]
0: TRAIN [0][4820/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00095)	Tok/s 63302 (58961)	Loss/tok 3.6862 (4.2337)	Learning Rate [0.00125]
1: TRAIN [0][4820/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00092)	Tok/s 63065 (59404)	Loss/tok 3.7929 (4.2346)	Learning Rate [0.00125]
2: TRAIN [0][4830/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00095)	Tok/s 61422 (59781)	Loss/tok 3.7530 (4.2275)	Learning Rate [0.00125]
3: TRAIN [0][4830/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00095)	Tok/s 61417 (60222)	Loss/tok 3.6735 (4.2332)	Learning Rate [0.00125]
0: TRAIN [0][4830/6832]	Time 0.123 (0.105)	Data 0.00086 (0.00095)	Tok/s 60344 (58968)	Loss/tok 3.6767 (4.2322)	Learning Rate [0.00125]
1: TRAIN [0][4830/6832]	Time 0.123 (0.105)	Data 0.00105 (0.00092)	Tok/s 61250 (59411)	Loss/tok 3.5094 (4.2331)	Learning Rate [0.00125]
2: TRAIN [0][4840/6832]	Time 0.108 (0.105)	Data 0.00087 (0.00095)	Tok/s 53131 (59782)	Loss/tok 3.4130 (4.2261)	Learning Rate [0.00125]
3: TRAIN [0][4840/6832]	Time 0.108 (0.105)	Data 0.00086 (0.00095)	Tok/s 53140 (60223)	Loss/tok 3.4822 (4.2317)	Learning Rate [0.00125]
0: TRAIN [0][4840/6832]	Time 0.108 (0.105)	Data 0.00093 (0.00095)	Tok/s 53125 (58970)	Loss/tok 3.7668 (4.2309)	Learning Rate [0.00125]
1: TRAIN [0][4840/6832]	Time 0.108 (0.105)	Data 0.00104 (0.00092)	Tok/s 53118 (59413)	Loss/tok 3.6386 (4.2317)	Learning Rate [0.00125]
2: TRAIN [0][4850/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 86357 (59784)	Loss/tok 3.6253 (4.2248)	Learning Rate [0.00125]
3: TRAIN [0][4850/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00095)	Tok/s 86716 (60225)	Loss/tok 3.4798 (4.2304)	Learning Rate [0.00125]
0: TRAIN [0][4850/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 85155 (58973)	Loss/tok 3.5981 (4.2295)	Learning Rate [0.00125]
1: TRAIN [0][4850/6832]	Time 0.132 (0.105)	Data 0.00104 (0.00092)	Tok/s 85491 (59415)	Loss/tok 3.5677 (4.2305)	Learning Rate [0.00125]
2: TRAIN [0][4860/6832]	Time 0.118 (0.105)	Data 0.00084 (0.00095)	Tok/s 55270 (59788)	Loss/tok 3.6331 (4.2233)	Learning Rate [0.00125]
3: TRAIN [0][4860/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00095)	Tok/s 55284 (60228)	Loss/tok 3.6030 (4.2289)	Learning Rate [0.00125]
0: TRAIN [0][4860/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00095)	Tok/s 54123 (58977)	Loss/tok 3.4979 (4.2279)	Learning Rate [0.00125]
1: TRAIN [0][4860/6832]	Time 0.118 (0.105)	Data 0.00102 (0.00092)	Tok/s 54370 (59419)	Loss/tok 3.6538 (4.2291)	Learning Rate [0.00125]
3: TRAIN [0][4870/6832]	Time 0.109 (0.105)	Data 0.00085 (0.00095)	Tok/s 51477 (60240)	Loss/tok 3.5477 (4.2273)	Learning Rate [0.00125]
2: TRAIN [0][4870/6832]	Time 0.109 (0.105)	Data 0.00086 (0.00095)	Tok/s 51480 (59799)	Loss/tok 3.4372 (4.2218)	Learning Rate [0.00125]
0: TRAIN [0][4870/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00095)	Tok/s 51474 (58989)	Loss/tok 3.7244 (4.2266)	Learning Rate [0.00125]
1: TRAIN [0][4870/6832]	Time 0.109 (0.105)	Data 0.00105 (0.00092)	Tok/s 51467 (59430)	Loss/tok 3.6511 (4.2278)	Learning Rate [0.00125]
2: TRAIN [0][4880/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00095)	Tok/s 62507 (59803)	Loss/tok 3.6779 (4.2204)	Learning Rate [0.00125]
0: TRAIN [0][4880/6832]	Time 0.129 (0.105)	Data 0.00104 (0.00095)	Tok/s 61683 (58989)	Loss/tok 3.6757 (4.2252)	Learning Rate [0.00125]
3: TRAIN [0][4880/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 62509 (60244)	Loss/tok 3.5648 (4.2257)	Learning Rate [0.00125]
1: TRAIN [0][4880/6832]	Time 0.129 (0.105)	Data 0.00105 (0.00092)	Tok/s 62578 (59433)	Loss/tok 3.8892 (4.2264)	Learning Rate [0.00125]
3: TRAIN [0][4890/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 79769 (60254)	Loss/tok 3.6813 (4.2242)	Learning Rate [0.00125]
2: TRAIN [0][4890/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 79744 (59814)	Loss/tok 3.5684 (4.2190)	Learning Rate [0.00125]
0: TRAIN [0][4890/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 78741 (59000)	Loss/tok 3.6349 (4.2238)	Learning Rate [0.00125]
1: TRAIN [0][4890/6832]	Time 0.130 (0.105)	Data 0.00108 (0.00092)	Tok/s 79212 (59444)	Loss/tok 3.6748 (4.2251)	Learning Rate [0.00125]
2: TRAIN [0][4900/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00095)	Tok/s 62654 (59817)	Loss/tok 3.5906 (4.2177)	Learning Rate [0.00125]
3: TRAIN [0][4900/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00095)	Tok/s 62655 (60257)	Loss/tok 3.6846 (4.2228)	Learning Rate [0.00125]
0: TRAIN [0][4900/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00095)	Tok/s 62015 (59004)	Loss/tok 3.7635 (4.2225)	Learning Rate [0.00125]
1: TRAIN [0][4900/6832]	Time 0.123 (0.105)	Data 0.00109 (0.00092)	Tok/s 62674 (59448)	Loss/tok 3.5447 (4.2236)	Learning Rate [0.00125]
2: TRAIN [0][4910/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00095)	Tok/s 59800 (59814)	Loss/tok 3.6635 (4.2165)	Learning Rate [0.00125]
3: TRAIN [0][4910/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00095)	Tok/s 60603 (60253)	Loss/tok 3.6837 (4.2216)	Learning Rate [0.00125]
0: TRAIN [0][4910/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00095)	Tok/s 59529 (58999)	Loss/tok 3.6478 (4.2210)	Learning Rate [0.00125]
1: TRAIN [0][4910/6832]	Time 0.118 (0.105)	Data 0.00103 (0.00092)	Tok/s 59492 (59444)	Loss/tok 3.5972 (4.2224)	Learning Rate [0.00125]
0: TRAIN [0][4920/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00095)	Tok/s 53541 (58987)	Loss/tok 3.6341 (4.2198)	Learning Rate [0.00125]
2: TRAIN [0][4920/6832]	Time 0.119 (0.105)	Data 0.00101 (0.00095)	Tok/s 53788 (59801)	Loss/tok 3.5321 (4.2153)	Learning Rate [0.00125]
3: TRAIN [0][4920/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00095)	Tok/s 53795 (60240)	Loss/tok 3.6869 (4.2205)	Learning Rate [0.00125]
1: TRAIN [0][4920/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00092)	Tok/s 53727 (59431)	Loss/tok 3.5205 (4.2212)	Learning Rate [0.00125]
3: TRAIN [0][4930/6832]	Time 0.109 (0.105)	Data 0.00086 (0.00095)	Tok/s 55035 (60252)	Loss/tok 3.6455 (4.2189)	Learning Rate [0.00125]
0: TRAIN [0][4930/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00095)	Tok/s 54984 (59000)	Loss/tok 3.6356 (4.2182)	Learning Rate [0.00125]
2: TRAIN [0][4930/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00095)	Tok/s 55035 (59813)	Loss/tok 3.5959 (4.2137)	Learning Rate [0.00125]
1: TRAIN [0][4930/6832]	Time 0.109 (0.105)	Data 0.00104 (0.00092)	Tok/s 55001 (59443)	Loss/tok 3.6183 (4.2196)	Learning Rate [0.00125]
2: TRAIN [0][4940/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 63875 (59808)	Loss/tok 3.5829 (4.2124)	Learning Rate [0.00125]
3: TRAIN [0][4940/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 63980 (60248)	Loss/tok 3.6161 (4.2178)	Learning Rate [0.00125]
0: TRAIN [0][4940/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00095)	Tok/s 63850 (58995)	Loss/tok 3.8912 (4.2171)	Learning Rate [0.00125]
1: TRAIN [0][4940/6832]	Time 0.128 (0.105)	Data 0.00104 (0.00092)	Tok/s 63840 (59438)	Loss/tok 3.7391 (4.2185)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [0][4950/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00095)	Tok/s 54542 (59808)	Loss/tok 3.5969 (4.2113)	Learning Rate [0.00125]
3: TRAIN [0][4950/6832]	Time 0.085 (0.105)	Data 0.00088 (0.00095)	Tok/s 55608 (60248)	Loss/tok 3.4031 (4.2164)	Learning Rate [0.00125]
0: TRAIN [0][4950/6832]	Time 0.085 (0.105)	Data 0.00087 (0.00095)	Tok/s 54528 (58996)	Loss/tok 3.4574 (4.2158)	Learning Rate [0.00125]
1: TRAIN [0][4950/6832]	Time 0.085 (0.105)	Data 0.00105 (0.00092)	Tok/s 54524 (59438)	Loss/tok 3.5888 (4.2172)	Learning Rate [0.00125]
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][4960/6832]	Time 0.083 (0.105)	Data 0.00093 (0.00095)	Tok/s 55546 (59817)	Loss/tok 3.1879 (4.2097)	Learning Rate [0.00125]
3: TRAIN [0][4960/6832]	Time 0.083 (0.105)	Data 0.00094 (0.00095)	Tok/s 55537 (60257)	Loss/tok 3.3415 (4.2151)	Learning Rate [0.00125]
0: TRAIN [0][4960/6832]	Time 0.083 (0.105)	Data 0.00089 (0.00095)	Tok/s 54031 (59005)	Loss/tok 3.4646 (4.2144)	Learning Rate [0.00125]
1: TRAIN [0][4960/6832]	Time 0.083 (0.105)	Data 0.00111 (0.00092)	Tok/s 54697 (59448)	Loss/tok 3.3346 (4.2157)	Learning Rate [0.00125]
2: TRAIN [0][4970/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00095)	Tok/s 74143 (59818)	Loss/tok 3.6774 (4.2083)	Learning Rate [0.00125]
0: TRAIN [0][4970/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 73956 (59006)	Loss/tok 3.7634 (4.2131)	Learning Rate [0.00125]
3: TRAIN [0][4970/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00095)	Tok/s 75055 (60258)	Loss/tok 3.7094 (4.2137)	Learning Rate [0.00125]
1: TRAIN [0][4970/6832]	Time 0.130 (0.105)	Data 0.00104 (0.00092)	Tok/s 74127 (59448)	Loss/tok 3.6168 (4.2144)	Learning Rate [0.00125]
2: TRAIN [0][4980/6832]	Time 0.094 (0.105)	Data 0.00105 (0.00095)	Tok/s 51475 (59825)	Loss/tok 3.5142 (4.2070)	Learning Rate [0.00125]
3: TRAIN [0][4980/6832]	Time 0.094 (0.105)	Data 0.00102 (0.00095)	Tok/s 52015 (60265)	Loss/tok 3.5734 (4.2124)	Learning Rate [0.00125]
0: TRAIN [0][4980/6832]	Time 0.094 (0.105)	Data 0.00099 (0.00095)	Tok/s 51478 (59013)	Loss/tok 3.6301 (4.2117)	Learning Rate [0.00125]
1: TRAIN [0][4980/6832]	Time 0.094 (0.105)	Data 0.00105 (0.00092)	Tok/s 51516 (59456)	Loss/tok 3.3869 (4.2132)	Learning Rate [0.00125]
3: TRAIN [0][4990/6832]	Time 0.060 (0.105)	Data 0.00086 (0.00095)	Tok/s 51608 (60263)	Loss/tok 3.1335 (4.2111)	Learning Rate [0.00125]
2: TRAIN [0][4990/6832]	Time 0.060 (0.105)	Data 0.00086 (0.00095)	Tok/s 50126 (59823)	Loss/tok 3.2348 (4.2058)	Learning Rate [0.00125]
0: TRAIN [0][4990/6832]	Time 0.059 (0.105)	Data 0.00091 (0.00095)	Tok/s 49484 (59011)	Loss/tok 3.0976 (4.2103)	Learning Rate [0.00125]
1: TRAIN [0][4990/6832]	Time 0.059 (0.105)	Data 0.00102 (0.00092)	Tok/s 49536 (59453)	Loss/tok 3.0078 (4.2120)	Learning Rate [0.00125]
2: TRAIN [0][5000/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00095)	Tok/s 52959 (59819)	Loss/tok 3.4680 (4.2046)	Learning Rate [0.00125]
0: TRAIN [0][5000/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00095)	Tok/s 51711 (59007)	Loss/tok 3.5717 (4.2091)	Learning Rate [0.00125]
3: TRAIN [0][5000/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00095)	Tok/s 52957 (60259)	Loss/tok 3.4444 (4.2100)	Learning Rate [0.00125]
1: TRAIN [0][5000/6832]	Time 0.104 (0.105)	Data 0.00106 (0.00092)	Tok/s 52916 (59449)	Loss/tok 3.6575 (4.2108)	Learning Rate [0.00125]
2: TRAIN [0][5010/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00095)	Tok/s 64207 (59817)	Loss/tok 3.7821 (4.2035)	Learning Rate [0.00125]
3: TRAIN [0][5010/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00095)	Tok/s 65021 (60257)	Loss/tok 3.6182 (4.2087)	Learning Rate [0.00125]
0: TRAIN [0][5010/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00095)	Tok/s 64186 (59006)	Loss/tok 3.8037 (4.2079)	Learning Rate [0.00125]
1: TRAIN [0][5010/6832]	Time 0.126 (0.105)	Data 0.00104 (0.00092)	Tok/s 64149 (59448)	Loss/tok 3.6867 (4.2095)	Learning Rate [0.00125]
2: TRAIN [0][5020/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 69725 (59807)	Loss/tok 3.7794 (4.2025)	Learning Rate [0.00125]
0: TRAIN [0][5020/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 69754 (58993)	Loss/tok 3.8593 (4.2068)	Learning Rate [0.00125]
3: TRAIN [0][5020/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 70586 (60247)	Loss/tok 3.7336 (4.2076)	Learning Rate [0.00125]
1: TRAIN [0][5020/6832]	Time 0.130 (0.105)	Data 0.00102 (0.00092)	Tok/s 69750 (59436)	Loss/tok 3.8095 (4.2084)	Learning Rate [0.00125]
2: TRAIN [0][5030/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00095)	Tok/s 52804 (59805)	Loss/tok 3.2451 (4.2012)	Learning Rate [0.00125]
3: TRAIN [0][5030/6832]	Time 0.073 (0.105)	Data 0.00088 (0.00095)	Tok/s 52610 (60244)	Loss/tok 3.2703 (4.2064)	Learning Rate [0.00125]
0: TRAIN [0][5030/6832]	Time 0.073 (0.105)	Data 0.00085 (0.00095)	Tok/s 50769 (58991)	Loss/tok 3.2475 (4.2055)	Learning Rate [0.00125]
1: TRAIN [0][5030/6832]	Time 0.073 (0.105)	Data 0.00103 (0.00092)	Tok/s 51765 (59434)	Loss/tok 3.3066 (4.2072)	Learning Rate [0.00125]
2: TRAIN [0][5040/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00095)	Tok/s 56882 (59790)	Loss/tok 3.5404 (4.2001)	Learning Rate [0.00125]
0: TRAIN [0][5040/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00095)	Tok/s 55841 (58976)	Loss/tok 3.6122 (4.2044)	Learning Rate [0.00125]
3: TRAIN [0][5040/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00095)	Tok/s 56904 (60230)	Loss/tok 3.8615 (4.2054)	Learning Rate [0.00125]
1: TRAIN [0][5040/6832]	Time 0.122 (0.105)	Data 0.00100 (0.00092)	Tok/s 55854 (59419)	Loss/tok 3.5489 (4.2062)	Learning Rate [0.00125]
2: TRAIN [0][5050/6832]	Time 0.047 (0.105)	Data 0.00086 (0.00095)	Tok/s 45226 (59780)	Loss/tok 2.5984 (4.1990)	Learning Rate [0.00125]
0: TRAIN [0][5050/6832]	Time 0.047 (0.105)	Data 0.00089 (0.00095)	Tok/s 40661 (58965)	Loss/tok 2.4731 (4.2034)	Learning Rate [0.00125]
3: TRAIN [0][5050/6832]	Time 0.047 (0.105)	Data 0.00088 (0.00095)	Tok/s 46588 (60220)	Loss/tok 2.5708 (4.2042)	Learning Rate [0.00125]
1: TRAIN [0][5050/6832]	Time 0.047 (0.105)	Data 0.00107 (0.00092)	Tok/s 42573 (59408)	Loss/tok 2.5961 (4.2052)	Learning Rate [0.00125]
2: TRAIN [0][5060/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00095)	Tok/s 66733 (59781)	Loss/tok 3.7691 (4.1977)	Learning Rate [0.00125]
0: TRAIN [0][5060/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00095)	Tok/s 66522 (58966)	Loss/tok 3.6268 (4.2021)	Learning Rate [0.00125]
3: TRAIN [0][5060/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00095)	Tok/s 66723 (60220)	Loss/tok 3.8767 (4.2031)	Learning Rate [0.00125]
1: TRAIN [0][5060/6832]	Time 0.127 (0.105)	Data 0.00105 (0.00093)	Tok/s 66728 (59409)	Loss/tok 3.8656 (4.2039)	Learning Rate [0.00125]
2: TRAIN [0][5070/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00095)	Tok/s 48936 (59785)	Loss/tok 3.2156 (4.1963)	Learning Rate [0.00125]
0: TRAIN [0][5070/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00095)	Tok/s 47745 (58970)	Loss/tok 3.0835 (4.2007)	Learning Rate [0.00125]
3: TRAIN [0][5070/6832]	Time 0.070 (0.105)	Data 0.00095 (0.00095)	Tok/s 49520 (60225)	Loss/tok 2.9924 (4.2017)	Learning Rate [0.00125]
1: TRAIN [0][5070/6832]	Time 0.070 (0.105)	Data 0.00105 (0.00093)	Tok/s 47758 (59413)	Loss/tok 3.2423 (4.2025)	Learning Rate [0.00125]
2: TRAIN [0][5080/6832]	Time 0.067 (0.105)	Data 0.00084 (0.00095)	Tok/s 51354 (59779)	Loss/tok 3.0914 (4.1952)	Learning Rate [0.00125]
3: TRAIN [0][5080/6832]	Time 0.067 (0.105)	Data 0.00084 (0.00095)	Tok/s 51699 (60219)	Loss/tok 3.2536 (4.2005)	Learning Rate [0.00125]
0: TRAIN [0][5080/6832]	Time 0.067 (0.105)	Data 0.00094 (0.00095)	Tok/s 49794 (58964)	Loss/tok 3.2219 (4.1996)	Learning Rate [0.00125]
1: TRAIN [0][5080/6832]	Time 0.069 (0.105)	Data 0.00097 (0.00093)	Tok/s 48434 (59407)	Loss/tok 3.1552 (4.2013)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [0][5090/6832]	Time 0.081 (0.105)	Data 0.00087 (0.00095)	Tok/s 53417 (59771)	Loss/tok 3.3820 (4.1940)	Learning Rate [0.00125]
3: TRAIN [0][5090/6832]	Time 0.081 (0.105)	Data 0.00087 (0.00095)	Tok/s 53832 (60210)	Loss/tok 3.3229 (4.1994)	Learning Rate [0.00125]
0: TRAIN [0][5090/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00095)	Tok/s 52239 (58956)	Loss/tok 3.2590 (4.1984)	Learning Rate [0.00125]
1: TRAIN [0][5090/6832]	Time 0.081 (0.105)	Data 0.00097 (0.00093)	Tok/s 52259 (59398)	Loss/tok 3.2553 (4.2001)	Learning Rate [0.00125]
2: TRAIN [0][5100/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00095)	Tok/s 51405 (59771)	Loss/tok 3.6871 (4.1929)	Learning Rate [0.00125]
0: TRAIN [0][5100/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00095)	Tok/s 50574 (58956)	Loss/tok 3.5022 (4.1972)	Learning Rate [0.00125]
1: TRAIN [0][5100/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00093)	Tok/s 51433 (59398)	Loss/tok 3.7546 (4.1988)	Learning Rate [0.00125]
3: TRAIN [0][5100/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00095)	Tok/s 50914 (60210)	Loss/tok 3.6331 (4.1981)	Learning Rate [0.00125]
2: TRAIN [0][5110/6832]	Time 0.106 (0.105)	Data 0.00085 (0.00095)	Tok/s 51728 (59768)	Loss/tok 3.4137 (4.1916)	Learning Rate [0.00125]
0: TRAIN [0][5110/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00095)	Tok/s 51363 (58954)	Loss/tok 3.5753 (4.1960)	Learning Rate [0.00125]
3: TRAIN [0][5110/6832]	Time 0.106 (0.105)	Data 0.00094 (0.00095)	Tok/s 51715 (60207)	Loss/tok 3.4048 (4.1970)	Learning Rate [0.00125]
1: TRAIN [0][5110/6832]	Time 0.106 (0.105)	Data 0.00120 (0.00093)	Tok/s 51749 (59396)	Loss/tok 3.4844 (4.1975)	Learning Rate [0.00125]
2: TRAIN [0][5120/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00095)	Tok/s 63933 (59765)	Loss/tok 3.6312 (4.1905)	Learning Rate [0.00125]
0: TRAIN [0][5120/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00095)	Tok/s 63943 (58952)	Loss/tok 3.7022 (4.1949)	Learning Rate [0.00125]
3: TRAIN [0][5120/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00095)	Tok/s 64268 (60204)	Loss/tok 3.5634 (4.1958)	Learning Rate [0.00125]
1: TRAIN [0][5120/6832]	Time 0.126 (0.105)	Data 0.00100 (0.00093)	Tok/s 63922 (59393)	Loss/tok 3.6895 (4.1963)	Learning Rate [0.00125]
2: TRAIN [0][5130/6832]	Time 0.124 (0.105)	Data 0.00086 (0.00095)	Tok/s 55393 (59775)	Loss/tok 3.6669 (4.1890)	Learning Rate [0.00125]
0: TRAIN [0][5130/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00095)	Tok/s 54477 (58962)	Loss/tok 3.7711 (4.1936)	Learning Rate [0.00125]
3: TRAIN [0][5130/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00095)	Tok/s 55534 (60213)	Loss/tok 3.8222 (4.1945)	Learning Rate [0.00125]
1: TRAIN [0][5130/6832]	Time 0.124 (0.105)	Data 0.00106 (0.00093)	Tok/s 54495 (59403)	Loss/tok 3.5803 (4.1948)	Learning Rate [0.00125]
2: TRAIN [0][5140/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00095)	Tok/s 51000 (59772)	Loss/tok 3.5196 (4.1879)	Learning Rate [0.00125]
0: TRAIN [0][5140/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00095)	Tok/s 50958 (58961)	Loss/tok 3.3535 (4.1926)	Learning Rate [0.00125]
3: TRAIN [0][5140/6832]	Time 0.111 (0.105)	Data 0.00092 (0.00095)	Tok/s 52097 (60211)	Loss/tok 3.6425 (4.1934)	Learning Rate [0.00125]
1: TRAIN [0][5140/6832]	Time 0.111 (0.105)	Data 0.00108 (0.00093)	Tok/s 50872 (59401)	Loss/tok 3.5257 (4.1937)	Learning Rate [0.00125]
2: TRAIN [0][5150/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00095)	Tok/s 52664 (59764)	Loss/tok 3.5360 (4.1868)	Learning Rate [0.00125]
3: TRAIN [0][5150/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00095)	Tok/s 52986 (60204)	Loss/tok 3.3128 (4.1923)	Learning Rate [0.00125]
0: TRAIN [0][5150/6832]	Time 0.092 (0.105)	Data 0.00092 (0.00095)	Tok/s 51570 (58952)	Loss/tok 3.5956 (4.1913)	Learning Rate [0.00125]
1: TRAIN [0][5150/6832]	Time 0.092 (0.105)	Data 0.00112 (0.00093)	Tok/s 51556 (59393)	Loss/tok 3.5173 (4.1926)	Learning Rate [0.00125]
2: TRAIN [0][5160/6832]	Time 0.100 (0.105)	Data 0.00088 (0.00095)	Tok/s 52528 (59760)	Loss/tok 3.7389 (4.1857)	Learning Rate [0.00125]
3: TRAIN [0][5160/6832]	Time 0.100 (0.105)	Data 0.00087 (0.00095)	Tok/s 52543 (60200)	Loss/tok 3.5406 (4.1911)	Learning Rate [0.00125]
0: TRAIN [0][5160/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00094)	Tok/s 52550 (58949)	Loss/tok 3.4558 (4.1901)	Learning Rate [0.00125]
1: TRAIN [0][5160/6832]	Time 0.100 (0.105)	Data 0.00098 (0.00093)	Tok/s 52516 (59389)	Loss/tok 3.3662 (4.1915)	Learning Rate [0.00125]
2: TRAIN [0][5170/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00095)	Tok/s 55009 (59760)	Loss/tok 3.8707 (4.1846)	Learning Rate [0.00125]
3: TRAIN [0][5170/6832]	Time 0.114 (0.105)	Data 0.00085 (0.00095)	Tok/s 56106 (60200)	Loss/tok 3.5840 (4.1899)	Learning Rate [0.00125]
0: TRAIN [0][5170/6832]	Time 0.114 (0.105)	Data 0.00102 (0.00095)	Tok/s 54988 (58950)	Loss/tok 3.6595 (4.1890)	Learning Rate [0.00125]
1: TRAIN [0][5170/6832]	Time 0.114 (0.105)	Data 0.00104 (0.00093)	Tok/s 54929 (59389)	Loss/tok 3.4194 (4.1901)	Learning Rate [0.00125]
1: Gradient norm: inf
2: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][5180/6832]	Time 0.085 (0.105)	Data 0.00100 (0.00095)	Tok/s 54237 (59767)	Loss/tok 3.3562 (4.1834)	Learning Rate [0.00125]
0: TRAIN [0][5180/6832]	Time 0.085 (0.105)	Data 0.00090 (0.00094)	Tok/s 52588 (58956)	Loss/tok 3.3717 (4.1876)	Learning Rate [0.00125]
3: TRAIN [0][5180/6832]	Time 0.085 (0.105)	Data 0.00099 (0.00095)	Tok/s 54212 (60205)	Loss/tok 3.5770 (4.1886)	Learning Rate [0.00125]
1: TRAIN [0][5180/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00093)	Tok/s 52698 (59395)	Loss/tok 3.5206 (4.1888)	Learning Rate [0.00125]
2: TRAIN [0][5190/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 68844 (59771)	Loss/tok 3.6046 (4.1821)	Learning Rate [0.00125]
0: TRAIN [0][5190/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00094)	Tok/s 68827 (58960)	Loss/tok 3.8041 (4.1864)	Learning Rate [0.00125]
3: TRAIN [0][5190/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00095)	Tok/s 69754 (60210)	Loss/tok 3.6199 (4.1875)	Learning Rate [0.00125]
1: TRAIN [0][5190/6832]	Time 0.128 (0.105)	Data 0.00106 (0.00093)	Tok/s 68797 (59400)	Loss/tok 3.6175 (4.1876)	Learning Rate [0.00125]
2: TRAIN [0][5200/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00095)	Tok/s 69417 (59764)	Loss/tok 3.8449 (4.1811)	Learning Rate [0.00125]
0: TRAIN [0][5200/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 69364 (58954)	Loss/tok 3.6533 (4.1852)	Learning Rate [0.00125]
3: TRAIN [0][5200/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 70331 (60204)	Loss/tok 3.7481 (4.1864)	Learning Rate [0.00125]
1: TRAIN [0][5200/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00093)	Tok/s 69343 (59394)	Loss/tok 3.7285 (4.1866)	Learning Rate [0.00125]
2: TRAIN [0][5210/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00095)	Tok/s 51301 (59766)	Loss/tok 3.4411 (4.1798)	Learning Rate [0.00125]
0: TRAIN [0][5210/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00094)	Tok/s 51306 (58957)	Loss/tok 3.6296 (4.1840)	Learning Rate [0.00125]
3: TRAIN [0][5210/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00095)	Tok/s 52078 (60206)	Loss/tok 3.5861 (4.1852)	Learning Rate [0.00125]
1: TRAIN [0][5210/6832]	Time 0.120 (0.105)	Data 0.00103 (0.00093)	Tok/s 51326 (59396)	Loss/tok 3.4089 (4.1853)	Learning Rate [0.00125]
2: TRAIN [0][5220/6832]	Time 0.111 (0.105)	Data 0.00086 (0.00095)	Tok/s 53148 (59765)	Loss/tok 3.4770 (4.1787)	Learning Rate [0.00125]
3: TRAIN [0][5220/6832]	Time 0.111 (0.105)	Data 0.00089 (0.00095)	Tok/s 53165 (60205)	Loss/tok 3.5154 (4.1840)	Learning Rate [0.00125]
0: TRAIN [0][5220/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00094)	Tok/s 53136 (58957)	Loss/tok 3.4198 (4.1828)	Learning Rate [0.00125]
1: TRAIN [0][5220/6832]	Time 0.111 (0.105)	Data 0.00099 (0.00093)	Tok/s 53132 (59395)	Loss/tok 3.5030 (4.1841)	Learning Rate [0.00125]
2: TRAIN [0][5230/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00095)	Tok/s 53049 (59776)	Loss/tok 3.4000 (4.1774)	Learning Rate [0.00125]
0: TRAIN [0][5230/6832]	Time 0.087 (0.105)	Data 0.00088 (0.00094)	Tok/s 51439 (58968)	Loss/tok 3.2845 (4.1815)	Learning Rate [0.00125]
3: TRAIN [0][5230/6832]	Time 0.087 (0.105)	Data 0.00093 (0.00095)	Tok/s 53019 (60216)	Loss/tok 3.4851 (4.1826)	Learning Rate [0.00125]
1: TRAIN [0][5230/6832]	Time 0.087 (0.105)	Data 0.00103 (0.00093)	Tok/s 51541 (59406)	Loss/tok 3.2305 (4.1828)	Learning Rate [0.00125]
2: TRAIN [0][5240/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00095)	Tok/s 55667 (59795)	Loss/tok 3.5753 (4.1757)	Learning Rate [0.00125]
0: TRAIN [0][5240/6832]	Time 0.123 (0.105)	Data 0.00094 (0.00094)	Tok/s 55168 (58987)	Loss/tok 3.5495 (4.1798)	Learning Rate [0.00125]
3: TRAIN [0][5240/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00095)	Tok/s 56182 (60236)	Loss/tok 3.7444 (4.1809)	Learning Rate [0.00125]
1: TRAIN [0][5240/6832]	Time 0.123 (0.105)	Data 0.00102 (0.00093)	Tok/s 55144 (59425)	Loss/tok 3.6143 (4.1809)	Learning Rate [0.00125]
0: TRAIN [0][5250/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 62596 (58983)	Loss/tok 3.8340 (4.1787)	Learning Rate [0.00125]
2: TRAIN [0][5250/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00095)	Tok/s 62839 (59790)	Loss/tok 3.7185 (4.1745)	Learning Rate [0.00125]
3: TRAIN [0][5250/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00095)	Tok/s 63548 (60231)	Loss/tok 3.7288 (4.1798)	Learning Rate [0.00125]
1: TRAIN [0][5250/6832]	Time 0.129 (0.105)	Data 0.00104 (0.00093)	Tok/s 62604 (59420)	Loss/tok 3.4934 (4.1797)	Learning Rate [0.00125]
0: TRAIN [0][5260/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 57618 (58976)	Loss/tok 3.5333 (4.1774)	Learning Rate [0.00125]
2: TRAIN [0][5260/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00095)	Tok/s 57521 (59783)	Loss/tok 3.5925 (4.1733)	Learning Rate [0.00125]
3: TRAIN [0][5260/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00095)	Tok/s 58298 (60225)	Loss/tok 3.5517 (4.1787)	Learning Rate [0.00125]
1: TRAIN [0][5260/6832]	Time 0.128 (0.105)	Data 0.00102 (0.00093)	Tok/s 57040 (59414)	Loss/tok 3.7605 (4.1787)	Learning Rate [0.00125]
2: TRAIN [0][5270/6832]	Time 0.092 (0.105)	Data 0.00085 (0.00095)	Tok/s 54395 (59777)	Loss/tok 3.4825 (4.1723)	Learning Rate [0.00125]
3: TRAIN [0][5270/6832]	Time 0.092 (0.105)	Data 0.00088 (0.00095)	Tok/s 54433 (60218)	Loss/tok 3.3270 (4.1776)	Learning Rate [0.00125]
0: TRAIN [0][5270/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00094)	Tok/s 54407 (58970)	Loss/tok 3.4552 (4.1762)	Learning Rate [0.00125]
1: TRAIN [0][5270/6832]	Time 0.092 (0.105)	Data 0.00101 (0.00093)	Tok/s 54456 (59408)	Loss/tok 3.5671 (4.1776)	Learning Rate [0.00125]
2: TRAIN [0][5280/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 63235 (59775)	Loss/tok 3.5716 (4.1710)	Learning Rate [0.00125]
0: TRAIN [0][5280/6832]	Time 0.127 (0.105)	Data 0.00102 (0.00094)	Tok/s 63289 (58969)	Loss/tok 3.5905 (4.1752)	Learning Rate [0.00125]
3: TRAIN [0][5280/6832]	Time 0.128 (0.105)	Data 0.00107 (0.00095)	Tok/s 63718 (60216)	Loss/tok 3.6767 (4.1766)	Learning Rate [0.00125]
1: TRAIN [0][5280/6832]	Time 0.128 (0.105)	Data 0.00110 (0.00093)	Tok/s 63228 (59406)	Loss/tok 3.6055 (4.1764)	Learning Rate [0.00125]
2: TRAIN [0][5290/6832]	Time 0.085 (0.105)	Data 0.00087 (0.00095)	Tok/s 52962 (59780)	Loss/tok 3.4763 (4.1697)	Learning Rate [0.00125]
3: TRAIN [0][5290/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00095)	Tok/s 52960 (60221)	Loss/tok 3.4208 (4.1754)	Learning Rate [0.00125]
0: TRAIN [0][5290/6832]	Time 0.085 (0.105)	Data 0.00107 (0.00094)	Tok/s 51890 (58970)	Loss/tok 3.4119 (4.1740)	Learning Rate [0.00125]
1: TRAIN [0][5290/6832]	Time 0.085 (0.105)	Data 0.00103 (0.00093)	Tok/s 52981 (59410)	Loss/tok 3.2890 (4.1752)	Learning Rate [0.00125]
2: TRAIN [0][5300/6832]	Time 0.056 (0.105)	Data 0.00088 (0.00095)	Tok/s 47604 (59776)	Loss/tok 2.8352 (4.1684)	Learning Rate [0.00125]
0: TRAIN [0][5300/6832]	Time 0.056 (0.105)	Data 0.00089 (0.00094)	Tok/s 45319 (58964)	Loss/tok 3.0256 (4.1729)	Learning Rate [0.00125]
3: TRAIN [0][5300/6832]	Time 0.056 (0.105)	Data 0.00092 (0.00095)	Tok/s 47611 (60218)	Loss/tok 2.8917 (4.1742)	Learning Rate [0.00125]
1: TRAIN [0][5300/6832]	Time 0.057 (0.105)	Data 0.00101 (0.00093)	Tok/s 46336 (59405)	Loss/tok 2.7915 (4.1741)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [0][5310/6832]	Time 0.058 (0.105)	Data 0.00089 (0.00095)	Tok/s 50353 (59779)	Loss/tok 3.1483 (4.1671)	Learning Rate [0.00125]
0: TRAIN [0][5310/6832]	Time 0.058 (0.105)	Data 0.00092 (0.00094)	Tok/s 50345 (58966)	Loss/tok 3.1097 (4.1718)	Learning Rate [0.00125]
3: TRAIN [0][5310/6832]	Time 0.058 (0.105)	Data 0.00094 (0.00095)	Tok/s 51894 (60221)	Loss/tok 3.1971 (4.1729)	Learning Rate [0.00125]
1: TRAIN [0][5310/6832]	Time 0.058 (0.105)	Data 0.00103 (0.00093)	Tok/s 50352 (59408)	Loss/tok 3.0607 (4.1730)	Learning Rate [0.00125]
2: TRAIN [0][5320/6832]	Time 0.082 (0.105)	Data 0.00085 (0.00095)	Tok/s 54340 (59775)	Loss/tok 3.4835 (4.1661)	Learning Rate [0.00125]
0: TRAIN [0][5320/6832]	Time 0.082 (0.105)	Data 0.00091 (0.00094)	Tok/s 54382 (58963)	Loss/tok 3.4194 (4.1706)	Learning Rate [0.00125]
3: TRAIN [0][5320/6832]	Time 0.082 (0.105)	Data 0.00087 (0.00095)	Tok/s 54351 (60217)	Loss/tok 3.3795 (4.1718)	Learning Rate [0.00125]
1: TRAIN [0][5320/6832]	Time 0.082 (0.105)	Data 0.00095 (0.00093)	Tok/s 54389 (59404)	Loss/tok 3.4298 (4.1719)	Learning Rate [0.00125]
2: TRAIN [0][5330/6832]	Time 0.086 (0.105)	Data 0.00090 (0.00095)	Tok/s 53277 (59776)	Loss/tok 3.4967 (4.1651)	Learning Rate [0.00125]
0: TRAIN [0][5330/6832]	Time 0.086 (0.105)	Data 0.00095 (0.00094)	Tok/s 53272 (58964)	Loss/tok 3.3848 (4.1695)	Learning Rate [0.00125]
3: TRAIN [0][5330/6832]	Time 0.087 (0.105)	Data 0.00096 (0.00095)	Tok/s 54034 (60218)	Loss/tok 3.4854 (4.1707)	Learning Rate [0.00125]
1: TRAIN [0][5330/6832]	Time 0.087 (0.105)	Data 0.00102 (0.00093)	Tok/s 53263 (59406)	Loss/tok 3.5325 (4.1707)	Learning Rate [0.00125]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][5340/6832]	Time 0.048 (0.105)	Data 0.00087 (0.00095)	Tok/s 45360 (59777)	Loss/tok 2.5641 (4.1639)	Learning Rate [0.00125]
0: TRAIN [0][5340/6832]	Time 0.048 (0.105)	Data 0.00091 (0.00094)	Tok/s 41353 (58961)	Loss/tok 2.4856 (4.1684)	Learning Rate [0.00125]
3: TRAIN [0][5340/6832]	Time 0.048 (0.105)	Data 0.00085 (0.00095)	Tok/s 47973 (60220)	Loss/tok 2.7322 (4.1693)	Learning Rate [0.00125]
1: TRAIN [0][5340/6832]	Time 0.048 (0.105)	Data 0.00097 (0.00093)	Tok/s 43657 (59405)	Loss/tok 2.5423 (4.1695)	Learning Rate [0.00125]
2: TRAIN [0][5350/6832]	Time 0.121 (0.105)	Data 0.00084 (0.00095)	Tok/s 56180 (59783)	Loss/tok 3.4845 (4.1626)	Learning Rate [0.00125]
0: TRAIN [0][5350/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00094)	Tok/s 55929 (58968)	Loss/tok 3.7484 (4.1671)	Learning Rate [0.00125]
3: TRAIN [0][5350/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00095)	Tok/s 57011 (60226)	Loss/tok 3.8736 (4.1682)	Learning Rate [0.00125]
1: TRAIN [0][5350/6832]	Time 0.121 (0.105)	Data 0.00105 (0.00093)	Tok/s 55934 (59411)	Loss/tok 3.8320 (4.1682)	Learning Rate [0.00125]
2: TRAIN [0][5360/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 80392 (59781)	Loss/tok 3.6054 (4.1615)	Learning Rate [0.00125]
0: TRAIN [0][5360/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 79565 (58964)	Loss/tok 3.6729 (4.1659)	Learning Rate [0.00125]
3: TRAIN [0][5360/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 80926 (60225)	Loss/tok 3.5234 (4.1671)	Learning Rate [0.00125]
1: TRAIN [0][5360/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00093)	Tok/s 79844 (59409)	Loss/tok 3.6283 (4.1672)	Learning Rate [0.00125]
2: TRAIN [0][5370/6832]	Time 0.116 (0.105)	Data 0.00084 (0.00095)	Tok/s 54991 (59785)	Loss/tok 3.5974 (4.1603)	Learning Rate [0.00125]
3: TRAIN [0][5370/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00095)	Tok/s 55015 (60228)	Loss/tok 3.7674 (4.1660)	Learning Rate [0.00125]
0: TRAIN [0][5370/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00094)	Tok/s 53908 (58969)	Loss/tok 3.5511 (4.1647)	Learning Rate [0.00125]
1: TRAIN [0][5370/6832]	Time 0.116 (0.105)	Data 0.00099 (0.00093)	Tok/s 53899 (59413)	Loss/tok 3.4804 (4.1660)	Learning Rate [0.00125]
2: TRAIN [0][5380/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00095)	Tok/s 74054 (59790)	Loss/tok 3.6494 (4.1592)	Learning Rate [0.00125]
3: TRAIN [0][5380/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 74909 (60233)	Loss/tok 3.7969 (4.1648)	Learning Rate [0.00125]
0: TRAIN [0][5380/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00095)	Tok/s 73791 (58973)	Loss/tok 3.8021 (4.1636)	Learning Rate [0.00125]
1: TRAIN [0][5380/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00093)	Tok/s 73934 (59418)	Loss/tok 3.6436 (4.1646)	Learning Rate [0.00125]
2: TRAIN [0][5390/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00095)	Tok/s 73834 (59801)	Loss/tok 3.6147 (4.1579)	Learning Rate [0.00125]
0: TRAIN [0][5390/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 73303 (58986)	Loss/tok 3.6604 (4.1622)	Learning Rate [0.00125]
3: TRAIN [0][5390/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00095)	Tok/s 74077 (60244)	Loss/tok 3.6500 (4.1635)	Learning Rate [0.00125]
1: TRAIN [0][5390/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00093)	Tok/s 73800 (59430)	Loss/tok 3.7364 (4.1634)	Learning Rate [0.00125]
2: TRAIN [0][5400/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00095)	Tok/s 50720 (59799)	Loss/tok 3.7762 (4.1569)	Learning Rate [0.00125]
0: TRAIN [0][5400/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00095)	Tok/s 50725 (58984)	Loss/tok 3.6308 (4.1612)	Learning Rate [0.00125]
3: TRAIN [0][5400/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00095)	Tok/s 50717 (60241)	Loss/tok 3.7504 (4.1625)	Learning Rate [0.00125]
1: TRAIN [0][5400/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00093)	Tok/s 50731 (59428)	Loss/tok 3.5442 (4.1623)	Learning Rate [0.00125]
2: TRAIN [0][5410/6832]	Time 0.114 (0.105)	Data 0.00099 (0.00095)	Tok/s 51835 (59800)	Loss/tok 3.4949 (4.1557)	Learning Rate [0.00125]
0: TRAIN [0][5410/6832]	Time 0.114 (0.105)	Data 0.00104 (0.00095)	Tok/s 51842 (58984)	Loss/tok 3.3506 (4.1600)	Learning Rate [0.00125]
3: TRAIN [0][5410/6832]	Time 0.114 (0.105)	Data 0.00104 (0.00095)	Tok/s 52833 (60243)	Loss/tok 3.4830 (4.1613)	Learning Rate [0.00125]
1: TRAIN [0][5410/6832]	Time 0.114 (0.105)	Data 0.00104 (0.00093)	Tok/s 51870 (59428)	Loss/tok 3.5231 (4.1612)	Learning Rate [0.00125]
2: TRAIN [0][5420/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00095)	Tok/s 62940 (59803)	Loss/tok 3.6701 (4.1546)	Learning Rate [0.00125]
0: TRAIN [0][5420/6832]	Time 0.126 (0.105)	Data 0.00108 (0.00095)	Tok/s 62964 (58988)	Loss/tok 3.7124 (4.1589)	Learning Rate [0.00125]
3: TRAIN [0][5420/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00095)	Tok/s 63550 (60246)	Loss/tok 3.7843 (4.1601)	Learning Rate [0.00125]
1: TRAIN [0][5420/6832]	Time 0.126 (0.105)	Data 0.00097 (0.00093)	Tok/s 63023 (59431)	Loss/tok 3.7659 (4.1601)	Learning Rate [0.00125]
2: TRAIN [0][5430/6832]	Time 0.083 (0.105)	Data 0.00084 (0.00095)	Tok/s 55667 (59800)	Loss/tok 3.4694 (4.1534)	Learning Rate [0.00125]
0: TRAIN [0][5430/6832]	Time 0.083 (0.105)	Data 0.00092 (0.00095)	Tok/s 54170 (58985)	Loss/tok 3.2817 (4.1578)	Learning Rate [0.00125]
3: TRAIN [0][5430/6832]	Time 0.083 (0.105)	Data 0.00086 (0.00095)	Tok/s 55679 (60242)	Loss/tok 3.4216 (4.1590)	Learning Rate [0.00125]
1: TRAIN [0][5430/6832]	Time 0.083 (0.105)	Data 0.00096 (0.00093)	Tok/s 54878 (59428)	Loss/tok 3.3728 (4.1591)	Learning Rate [0.00125]
2: TRAIN [0][5440/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00095)	Tok/s 50755 (59798)	Loss/tok 2.9387 (4.1525)	Learning Rate [0.00125]
0: TRAIN [0][5440/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00095)	Tok/s 48322 (58983)	Loss/tok 3.2441 (4.1568)	Learning Rate [0.00125]
3: TRAIN [0][5440/6832]	Time 0.053 (0.105)	Data 0.00098 (0.00095)	Tok/s 50757 (60240)	Loss/tok 2.9657 (4.1580)	Learning Rate [0.00125]
1: TRAIN [0][5440/6832]	Time 0.053 (0.105)	Data 0.00102 (0.00093)	Tok/s 49901 (59427)	Loss/tok 2.8508 (4.1580)	Learning Rate [0.00125]
2: TRAIN [0][5450/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00095)	Tok/s 62744 (59796)	Loss/tok 3.8478 (4.1515)	Learning Rate [0.00125]
3: TRAIN [0][5450/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00095)	Tok/s 62780 (60238)	Loss/tok 3.6650 (4.1571)	Learning Rate [0.00125]
0: TRAIN [0][5450/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00095)	Tok/s 62635 (58981)	Loss/tok 3.7143 (4.1556)	Learning Rate [0.00125]
1: TRAIN [0][5450/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00093)	Tok/s 62676 (59425)	Loss/tok 3.6656 (4.1570)	Learning Rate [0.00125]
2: TRAIN [0][5460/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00095)	Tok/s 58063 (59789)	Loss/tok 3.5759 (4.1505)	Learning Rate [0.00125]
3: TRAIN [0][5460/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00095)	Tok/s 58094 (60231)	Loss/tok 3.4633 (4.1562)	Learning Rate [0.00125]
0: TRAIN [0][5460/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00095)	Tok/s 58059 (58975)	Loss/tok 3.4864 (4.1546)	Learning Rate [0.00125]
1: TRAIN [0][5460/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00093)	Tok/s 58086 (59418)	Loss/tok 3.7492 (4.1560)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [0][5470/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00095)	Tok/s 63718 (59782)	Loss/tok 3.5857 (4.1495)	Learning Rate [0.00125]
0: TRAIN [0][5470/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00095)	Tok/s 63732 (58969)	Loss/tok 3.7959 (4.1536)	Learning Rate [0.00125]
3: TRAIN [0][5470/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00095)	Tok/s 64721 (60224)	Loss/tok 3.6025 (4.1551)	Learning Rate [0.00125]
1: TRAIN [0][5470/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00093)	Tok/s 63754 (59412)	Loss/tok 3.5990 (4.1551)	Learning Rate [0.00125]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
0: TRAIN [0][5480/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 88447 (58966)	Loss/tok 3.6428 (4.1525)	Learning Rate [0.00125]
1: TRAIN [0][5480/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00093)	Tok/s 89542 (59409)	Loss/tok 3.3425 (4.1540)	Learning Rate [0.00125]
2: TRAIN [0][5480/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 89668 (59779)	Loss/tok 3.4360 (4.1485)	Learning Rate [0.00125]
3: TRAIN [0][5480/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 90590 (60221)	Loss/tok 3.3483 (4.1540)	Learning Rate [0.00125]
2: TRAIN [0][5490/6832]	Time 0.082 (0.105)	Data 0.00094 (0.00095)	Tok/s 51638 (59775)	Loss/tok 3.3042 (4.1475)	Learning Rate [0.00125]
0: TRAIN [0][5490/6832]	Time 0.082 (0.105)	Data 0.00098 (0.00095)	Tok/s 50224 (58963)	Loss/tok 3.5138 (4.1516)	Learning Rate [0.00125]
3: TRAIN [0][5490/6832]	Time 0.082 (0.105)	Data 0.00097 (0.00095)	Tok/s 51663 (60217)	Loss/tok 3.5993 (4.1529)	Learning Rate [0.00125]
1: TRAIN [0][5490/6832]	Time 0.082 (0.105)	Data 0.00097 (0.00093)	Tok/s 51742 (59405)	Loss/tok 3.3457 (4.1530)	Learning Rate [0.00125]
2: TRAIN [0][5500/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00095)	Tok/s 58964 (59783)	Loss/tok 3.6293 (4.1463)	Learning Rate [0.00125]
1: TRAIN [0][5500/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00093)	Tok/s 58943 (59413)	Loss/tok 3.5963 (4.1518)	Learning Rate [0.00125]
3: TRAIN [0][5500/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00095)	Tok/s 59304 (60224)	Loss/tok 3.7586 (4.1516)	Learning Rate [0.00125]
0: TRAIN [0][5500/6832]	Time 0.122 (0.105)	Data 0.00101 (0.00095)	Tok/s 58956 (58971)	Loss/tok 3.6302 (4.1505)	Learning Rate [0.00125]
2: TRAIN [0][5510/6832]	Time 0.060 (0.105)	Data 0.00083 (0.00095)	Tok/s 48810 (59768)	Loss/tok 3.0820 (4.1455)	Learning Rate [0.00125]
1: TRAIN [0][5510/6832]	Time 0.060 (0.105)	Data 0.00088 (0.00093)	Tok/s 48780 (59398)	Loss/tok 3.2270 (4.1509)	Learning Rate [0.00125]
0: TRAIN [0][5510/6832]	Time 0.060 (0.105)	Data 0.00098 (0.00095)	Tok/s 48672 (58955)	Loss/tok 2.7743 (4.1496)	Learning Rate [0.00125]
3: TRAIN [0][5510/6832]	Time 0.060 (0.105)	Data 0.00085 (0.00095)	Tok/s 50239 (60210)	Loss/tok 3.0355 (4.1507)	Learning Rate [0.00125]
1: TRAIN [0][5520/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00093)	Tok/s 53808 (59392)	Loss/tok 3.6007 (4.1499)	Learning Rate [0.00125]
0: TRAIN [0][5520/6832]	Time 0.090 (0.105)	Data 0.00100 (0.00095)	Tok/s 53735 (58948)	Loss/tok 3.3796 (4.1485)	Learning Rate [0.00125]
2: TRAIN [0][5520/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00095)	Tok/s 53722 (59763)	Loss/tok 3.4993 (4.1445)	Learning Rate [0.00125]
3: TRAIN [0][5520/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00095)	Tok/s 53717 (60206)	Loss/tok 3.6011 (4.1497)	Learning Rate [0.00125]
2: TRAIN [0][5530/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00095)	Tok/s 52197 (59749)	Loss/tok 3.8107 (4.1436)	Learning Rate [0.00125]
1: TRAIN [0][5530/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00093)	Tok/s 52189 (59378)	Loss/tok 3.6463 (4.1490)	Learning Rate [0.00125]
0: TRAIN [0][5530/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00095)	Tok/s 52227 (58933)	Loss/tok 3.5746 (4.1476)	Learning Rate [0.00125]
3: TRAIN [0][5530/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00095)	Tok/s 52333 (60192)	Loss/tok 3.3305 (4.1487)	Learning Rate [0.00125]
2: TRAIN [0][5540/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00095)	Tok/s 53039 (59753)	Loss/tok 3.4256 (4.1424)	Learning Rate [0.00125]
1: TRAIN [0][5540/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00093)	Tok/s 53002 (59382)	Loss/tok 3.4435 (4.1479)	Learning Rate [0.00125]
0: TRAIN [0][5540/6832]	Time 0.106 (0.105)	Data 0.00097 (0.00095)	Tok/s 52994 (58937)	Loss/tok 3.4470 (4.1465)	Learning Rate [0.00125]
3: TRAIN [0][5540/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00095)	Tok/s 54001 (60195)	Loss/tok 3.4989 (4.1475)	Learning Rate [0.00125]
2: TRAIN [0][5550/6832]	Time 0.086 (0.105)	Data 0.00083 (0.00095)	Tok/s 54852 (59743)	Loss/tok 3.3353 (4.1414)	Learning Rate [0.00125]
1: TRAIN [0][5550/6832]	Time 0.086 (0.105)	Data 0.00087 (0.00093)	Tok/s 54840 (59372)	Loss/tok 3.4534 (4.1468)	Learning Rate [0.00125]
0: TRAIN [0][5550/6832]	Time 0.086 (0.105)	Data 0.00096 (0.00095)	Tok/s 53921 (58927)	Loss/tok 3.4724 (4.1455)	Learning Rate [0.00125]
3: TRAIN [0][5550/6832]	Time 0.086 (0.105)	Data 0.00085 (0.00095)	Tok/s 54841 (60185)	Loss/tok 3.4081 (4.1465)	Learning Rate [0.00125]
2: TRAIN [0][5560/6832]	Time 0.052 (0.105)	Data 0.00091 (0.00095)	Tok/s 51294 (59736)	Loss/tok 2.7881 (4.1404)	Learning Rate [0.00125]
1: TRAIN [0][5560/6832]	Time 0.052 (0.105)	Data 0.00103 (0.00094)	Tok/s 50790 (59365)	Loss/tok 2.9296 (4.1459)	Learning Rate [0.00125]
3: TRAIN [0][5560/6832]	Time 0.052 (0.105)	Data 0.00091 (0.00095)	Tok/s 51361 (60178)	Loss/tok 2.9026 (4.1454)	Learning Rate [0.00125]
0: TRAIN [0][5560/6832]	Time 0.052 (0.105)	Data 0.00108 (0.00095)	Tok/s 48966 (58920)	Loss/tok 2.9892 (4.1447)	Learning Rate [0.00125]
2: TRAIN [0][5570/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00095)	Tok/s 82191 (59740)	Loss/tok 3.6286 (4.1393)	Learning Rate [0.00125]
1: TRAIN [0][5570/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 82200 (59369)	Loss/tok 3.6447 (4.1449)	Learning Rate [0.00125]
0: TRAIN [0][5570/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00095)	Tok/s 81513 (58924)	Loss/tok 3.5984 (4.1435)	Learning Rate [0.00125]
3: TRAIN [0][5570/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 83076 (60182)	Loss/tok 3.4447 (4.1443)	Learning Rate [0.00125]
2: TRAIN [0][5580/6832]	Time 0.068 (0.105)	Data 0.00085 (0.00095)	Tok/s 51206 (59738)	Loss/tok 3.0500 (4.1382)	Learning Rate [0.00125]
1: TRAIN [0][5580/6832]	Time 0.068 (0.105)	Data 0.00086 (0.00094)	Tok/s 50613 (59368)	Loss/tok 3.1763 (4.1439)	Learning Rate [0.00125]
0: TRAIN [0][5580/6832]	Time 0.068 (0.105)	Data 0.00095 (0.00095)	Tok/s 50620 (58923)	Loss/tok 3.0821 (4.1425)	Learning Rate [0.00125]
3: TRAIN [0][5580/6832]	Time 0.068 (0.105)	Data 0.00085 (0.00095)	Tok/s 52495 (60180)	Loss/tok 3.3060 (4.1432)	Learning Rate [0.00125]
1: TRAIN [0][5590/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 81787 (59367)	Loss/tok 3.5350 (4.1429)	Learning Rate [0.00125]
2: TRAIN [0][5590/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 82036 (59738)	Loss/tok 3.4180 (4.1371)	Learning Rate [0.00125]
0: TRAIN [0][5590/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00095)	Tok/s 81440 (58920)	Loss/tok 3.4522 (4.1415)	Learning Rate [0.00125]
3: TRAIN [0][5590/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00095)	Tok/s 82747 (60180)	Loss/tok 3.5926 (4.1421)	Learning Rate [0.00125]
1: TRAIN [0][5600/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00094)	Tok/s 67878 (59364)	Loss/tok 3.7686 (4.1419)	Learning Rate [0.00125]
2: TRAIN [0][5600/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00095)	Tok/s 67798 (59735)	Loss/tok 3.5670 (4.1360)	Learning Rate [0.00125]
0: TRAIN [0][5600/6832]	Time 0.126 (0.105)	Data 0.00103 (0.00095)	Tok/s 67829 (58917)	Loss/tok 3.5714 (4.1405)	Learning Rate [0.00125]
3: TRAIN [0][5600/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00095)	Tok/s 67866 (60176)	Loss/tok 3.7064 (4.1411)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [0][5610/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00095)	Tok/s 53590 (59732)	Loss/tok 3.4930 (4.1350)	Learning Rate [0.00125]
1: TRAIN [0][5610/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00094)	Tok/s 53558 (59361)	Loss/tok 3.6662 (4.1409)	Learning Rate [0.00125]
0: TRAIN [0][5610/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00095)	Tok/s 53566 (58915)	Loss/tok 3.7078 (4.1395)	Learning Rate [0.00125]
3: TRAIN [0][5610/6832]	Time 0.119 (0.105)	Data 0.00102 (0.00095)	Tok/s 53586 (60173)	Loss/tok 3.6712 (4.1401)	Learning Rate [0.00125]
2: TRAIN [0][5620/6832]	Time 0.097 (0.105)	Data 0.00094 (0.00095)	Tok/s 52017 (59731)	Loss/tok 3.4744 (4.1339)	Learning Rate [0.00125]
1: TRAIN [0][5620/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00094)	Tok/s 51597 (59361)	Loss/tok 3.6084 (4.1400)	Learning Rate [0.00125]
0: TRAIN [0][5620/6832]	Time 0.097 (0.105)	Data 0.00098 (0.00095)	Tok/s 51621 (58914)	Loss/tok 3.5677 (4.1384)	Learning Rate [0.00125]
3: TRAIN [0][5620/6832]	Time 0.097 (0.105)	Data 0.00103 (0.00095)	Tok/s 52977 (60172)	Loss/tok 3.4863 (4.1391)	Learning Rate [0.00125]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][5630/6832]	Time 0.061 (0.105)	Data 0.00083 (0.00095)	Tok/s 48590 (59729)	Loss/tok 2.9728 (4.1329)	Learning Rate [0.00125]
1: TRAIN [0][5630/6832]	Time 0.061 (0.105)	Data 0.00091 (0.00094)	Tok/s 48513 (59358)	Loss/tok 3.1479 (4.1389)	Learning Rate [0.00125]
3: TRAIN [0][5630/6832]	Time 0.061 (0.105)	Data 0.00085 (0.00095)	Tok/s 50008 (60171)	Loss/tok 3.1227 (4.1381)	Learning Rate [0.00125]
0: TRAIN [0][5630/6832]	Time 0.061 (0.105)	Data 0.00098 (0.00095)	Tok/s 48495 (58910)	Loss/tok 3.0674 (4.1374)	Learning Rate [0.00125]
2: TRAIN [0][5640/6832]	Time 0.060 (0.105)	Data 0.00083 (0.00095)	Tok/s 49298 (59733)	Loss/tok 3.1364 (4.1317)	Learning Rate [0.00125]
1: TRAIN [0][5640/6832]	Time 0.060 (0.105)	Data 0.00087 (0.00094)	Tok/s 49297 (59361)	Loss/tok 3.0981 (4.1377)	Learning Rate [0.00125]
0: TRAIN [0][5640/6832]	Time 0.060 (0.105)	Data 0.00097 (0.00095)	Tok/s 49291 (58913)	Loss/tok 2.8755 (4.1362)	Learning Rate [0.00125]
3: TRAIN [0][5640/6832]	Time 0.060 (0.105)	Data 0.00089 (0.00095)	Tok/s 50666 (60174)	Loss/tok 3.1566 (4.1369)	Learning Rate [0.00125]
2: TRAIN [0][5650/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 74492 (59730)	Loss/tok 3.5417 (4.1307)	Learning Rate [0.00125]
3: TRAIN [0][5650/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 75178 (60172)	Loss/tok 3.7883 (4.1359)	Learning Rate [0.00125]
1: TRAIN [0][5650/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 74107 (59358)	Loss/tok 3.6059 (4.1367)	Learning Rate [0.00125]
0: TRAIN [0][5650/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 74168 (58910)	Loss/tok 3.5551 (4.1351)	Learning Rate [0.00125]
1: TRAIN [0][5660/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00094)	Tok/s 52743 (59350)	Loss/tok 3.5407 (4.1358)	Learning Rate [0.00125]
2: TRAIN [0][5660/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00095)	Tok/s 53510 (59722)	Loss/tok 3.3877 (4.1298)	Learning Rate [0.00125]
0: TRAIN [0][5660/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00095)	Tok/s 52745 (58901)	Loss/tok 3.1610 (4.1341)	Learning Rate [0.00125]
3: TRAIN [0][5660/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00095)	Tok/s 54414 (60164)	Loss/tok 3.4340 (4.1350)	Learning Rate [0.00125]
2: TRAIN [0][5670/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00095)	Tok/s 57563 (59728)	Loss/tok 3.5271 (4.1286)	Learning Rate [0.00125]
1: TRAIN [0][5670/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00094)	Tok/s 57180 (59355)	Loss/tok 3.6723 (4.1346)	Learning Rate [0.00125]
0: TRAIN [0][5670/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00095)	Tok/s 56473 (58906)	Loss/tok 3.6610 (4.1330)	Learning Rate [0.00125]
3: TRAIN [0][5670/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00095)	Tok/s 57550 (60170)	Loss/tok 3.6869 (4.1338)	Learning Rate [0.00125]
1: TRAIN [0][5680/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 65099 (59354)	Loss/tok 3.6892 (4.1336)	Learning Rate [0.00125]
2: TRAIN [0][5680/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00095)	Tok/s 65046 (59726)	Loss/tok 3.5688 (4.1275)	Learning Rate [0.00125]
0: TRAIN [0][5680/6832]	Time 0.128 (0.105)	Data 0.00102 (0.00095)	Tok/s 65085 (58904)	Loss/tok 3.5137 (4.1319)	Learning Rate [0.00125]
3: TRAIN [0][5680/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 65671 (60168)	Loss/tok 3.7700 (4.1328)	Learning Rate [0.00125]
2: TRAIN [0][5690/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 79068 (59725)	Loss/tok 3.5684 (4.1264)	Learning Rate [0.00125]
1: TRAIN [0][5690/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 79013 (59353)	Loss/tok 3.5794 (4.1326)	Learning Rate [0.00125]
0: TRAIN [0][5690/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00095)	Tok/s 78115 (58904)	Loss/tok 3.6235 (4.1309)	Learning Rate [0.00125]
3: TRAIN [0][5690/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 79545 (60167)	Loss/tok 3.6534 (4.1319)	Learning Rate [0.00125]
1: TRAIN [0][5700/6832]	Time 0.090 (0.105)	Data 0.00088 (0.00094)	Tok/s 54190 (59347)	Loss/tok 3.4870 (4.1315)	Learning Rate [0.00125]
2: TRAIN [0][5700/6832]	Time 0.090 (0.105)	Data 0.00090 (0.00095)	Tok/s 55050 (59719)	Loss/tok 3.5610 (4.1254)	Learning Rate [0.00125]
3: TRAIN [0][5700/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00095)	Tok/s 55710 (60161)	Loss/tok 3.3482 (4.1309)	Learning Rate [0.00125]
0: TRAIN [0][5700/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00095)	Tok/s 54185 (58898)	Loss/tok 3.4257 (4.1300)	Learning Rate [0.00125]
1: TRAIN [0][5710/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00094)	Tok/s 60132 (59344)	Loss/tok 3.6428 (4.1305)	Learning Rate [0.00125]
0: TRAIN [0][5710/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00095)	Tok/s 59688 (58893)	Loss/tok 3.5839 (4.1290)	Learning Rate [0.00125]
2: TRAIN [0][5710/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00095)	Tok/s 60122 (59717)	Loss/tok 3.7066 (4.1244)	Learning Rate [0.00125]
3: TRAIN [0][5710/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00095)	Tok/s 60117 (60159)	Loss/tok 3.6646 (4.1299)	Learning Rate [0.00125]
2: TRAIN [0][5720/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00095)	Tok/s 51492 (59724)	Loss/tok 3.2038 (4.1232)	Learning Rate [0.00125]
1: TRAIN [0][5720/6832]	Time 0.070 (0.105)	Data 0.00094 (0.00094)	Tok/s 51425 (59351)	Loss/tok 3.1861 (4.1293)	Learning Rate [0.00125]
3: TRAIN [0][5720/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00095)	Tok/s 51518 (60166)	Loss/tok 3.3286 (4.1288)	Learning Rate [0.00125]
0: TRAIN [0][5720/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00095)	Tok/s 51461 (58900)	Loss/tok 3.1208 (4.1278)	Learning Rate [0.00125]
2: TRAIN [0][5730/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00095)	Tok/s 59802 (59719)	Loss/tok 3.6354 (4.1222)	Learning Rate [0.00125]
1: TRAIN [0][5730/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00094)	Tok/s 59398 (59345)	Loss/tok 3.7031 (4.1284)	Learning Rate [0.00125]
3: TRAIN [0][5730/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00095)	Tok/s 60491 (60161)	Loss/tok 3.6076 (4.1278)	Learning Rate [0.00125]
0: TRAIN [0][5730/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00095)	Tok/s 59401 (58891)	Loss/tok 3.6679 (4.1268)	Learning Rate [0.00125]
1: TRAIN [0][5740/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00094)	Tok/s 50383 (59341)	Loss/tok 3.0393 (4.1274)	Learning Rate [0.00125]
2: TRAIN [0][5740/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00095)	Tok/s 50658 (59716)	Loss/tok 3.1416 (4.1213)	Learning Rate [0.00125]
3: TRAIN [0][5740/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00095)	Tok/s 52377 (60159)	Loss/tok 3.2866 (4.1268)	Learning Rate [0.00125]
0: TRAIN [0][5740/6832]	Time 0.063 (0.105)	Data 0.00094 (0.00095)	Tok/s 50406 (58887)	Loss/tok 3.1892 (4.1259)	Learning Rate [0.00125]
2: TRAIN [0][5750/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00095)	Tok/s 68022 (59711)	Loss/tok 3.7200 (4.1204)	Learning Rate [0.00125]
3: TRAIN [0][5750/6832]	Time 0.130 (0.105)	Data 0.00082 (0.00095)	Tok/s 68434 (60155)	Loss/tok 3.6412 (4.1258)	Learning Rate [0.00125]
1: TRAIN [0][5750/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 67995 (59336)	Loss/tok 3.7127 (4.1265)	Learning Rate [0.00125]
0: TRAIN [0][5750/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00095)	Tok/s 67996 (58882)	Loss/tok 3.7863 (4.1250)	Learning Rate [0.00125]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Gradient norm: inf
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][5760/6832]	Time 0.101 (0.105)	Data 0.00096 (0.00095)	Tok/s 52128 (59704)	Loss/tok 3.4869 (4.1194)	Learning Rate [0.00125]
1: TRAIN [0][5760/6832]	Time 0.101 (0.105)	Data 0.00098 (0.00094)	Tok/s 52165 (59328)	Loss/tok 3.5461 (4.1254)	Learning Rate [0.00125]
3: TRAIN [0][5760/6832]	Time 0.101 (0.105)	Data 0.00095 (0.00095)	Tok/s 52111 (60147)	Loss/tok 3.4440 (4.1248)	Learning Rate [0.00125]
0: TRAIN [0][5760/6832]	Time 0.101 (0.105)	Data 0.00100 (0.00095)	Tok/s 51489 (58873)	Loss/tok 3.4879 (4.1239)	Learning Rate [0.00125]
1: TRAIN [0][5770/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 69948 (59339)	Loss/tok 3.5704 (4.1242)	Learning Rate [0.00125]
2: TRAIN [0][5770/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 69923 (59714)	Loss/tok 3.6971 (4.1182)	Learning Rate [0.00125]
0: TRAIN [0][5770/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00095)	Tok/s 69951 (58884)	Loss/tok 3.5876 (4.1228)	Learning Rate [0.00125]
3: TRAIN [0][5770/6832]	Time 0.128 (0.105)	Data 0.00083 (0.00095)	Tok/s 70247 (60158)	Loss/tok 3.7695 (4.1236)	Learning Rate [0.00125]
1: TRAIN [0][5780/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 85773 (59347)	Loss/tok 3.4408 (4.1231)	Learning Rate [0.00125]
0: TRAIN [0][5780/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 85237 (58892)	Loss/tok 3.5033 (4.1216)	Learning Rate [0.00125]
2: TRAIN [0][5780/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00095)	Tok/s 86524 (59721)	Loss/tok 3.4136 (4.1171)	Learning Rate [0.00125]
3: TRAIN [0][5780/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00095)	Tok/s 87008 (60165)	Loss/tok 3.4838 (4.1224)	Learning Rate [0.00125]
2: TRAIN [0][5790/6832]	Time 0.108 (0.105)	Data 0.00088 (0.00095)	Tok/s 54722 (59720)	Loss/tok 3.3793 (4.1159)	Learning Rate [0.00125]
1: TRAIN [0][5790/6832]	Time 0.108 (0.105)	Data 0.00094 (0.00094)	Tok/s 54756 (59345)	Loss/tok 3.6682 (4.1220)	Learning Rate [0.00125]
3: TRAIN [0][5790/6832]	Time 0.108 (0.105)	Data 0.00088 (0.00095)	Tok/s 55274 (60164)	Loss/tok 3.4113 (4.1213)	Learning Rate [0.00125]
0: TRAIN [0][5790/6832]	Time 0.107 (0.105)	Data 0.00098 (0.00095)	Tok/s 54773 (58888)	Loss/tok 3.5189 (4.1206)	Learning Rate [0.00125]
1: TRAIN [0][5800/6832]	Time 0.078 (0.105)	Data 0.00095 (0.00094)	Tok/s 52793 (59345)	Loss/tok 3.2661 (4.1212)	Learning Rate [0.00125]
0: TRAIN [0][5800/6832]	Time 0.077 (0.105)	Data 0.00092 (0.00095)	Tok/s 52533 (58888)	Loss/tok 3.2522 (4.1196)	Learning Rate [0.00125]
2: TRAIN [0][5800/6832]	Time 0.078 (0.105)	Data 0.00085 (0.00095)	Tok/s 52754 (59720)	Loss/tok 3.2900 (4.1149)	Learning Rate [0.00125]
3: TRAIN [0][5800/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00095)	Tok/s 52775 (60164)	Loss/tok 3.1251 (4.1204)	Learning Rate [0.00125]
1: TRAIN [0][5810/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00094)	Tok/s 58336 (59353)	Loss/tok 3.5194 (4.1201)	Learning Rate [0.00125]
2: TRAIN [0][5810/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00095)	Tok/s 59149 (59728)	Loss/tok 3.6840 (4.1138)	Learning Rate [0.00125]
0: TRAIN [0][5810/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00095)	Tok/s 58032 (58897)	Loss/tok 3.6305 (4.1185)	Learning Rate [0.00125]
3: TRAIN [0][5810/6832]	Time 0.115 (0.105)	Data 0.00082 (0.00095)	Tok/s 59185 (60172)	Loss/tok 3.6151 (4.1192)	Learning Rate [0.00125]
1: TRAIN [0][5820/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 62404 (59348)	Loss/tok 3.7386 (4.1191)	Learning Rate [0.00125]
0: TRAIN [0][5820/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00095)	Tok/s 62419 (58890)	Loss/tok 3.6821 (4.1176)	Learning Rate [0.00125]
2: TRAIN [0][5820/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00095)	Tok/s 62419 (59724)	Loss/tok 3.6087 (4.1128)	Learning Rate [0.00125]
3: TRAIN [0][5820/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00095)	Tok/s 62426 (60168)	Loss/tok 3.8373 (4.1183)	Learning Rate [0.00125]
2: TRAIN [0][5830/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00095)	Tok/s 86229 (59729)	Loss/tok 3.5068 (4.1117)	Learning Rate [0.00125]
1: TRAIN [0][5830/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 85350 (59354)	Loss/tok 3.4637 (4.1180)	Learning Rate [0.00125]
0: TRAIN [0][5830/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00095)	Tok/s 84978 (58895)	Loss/tok 3.4967 (4.1164)	Learning Rate [0.00125]
3: TRAIN [0][5830/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00095)	Tok/s 86546 (60173)	Loss/tok 3.5667 (4.1172)	Learning Rate [0.00125]
2: TRAIN [0][5840/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00095)	Tok/s 52999 (59727)	Loss/tok 3.5450 (4.1107)	Learning Rate [0.00125]
3: TRAIN [0][5840/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00095)	Tok/s 53545 (60170)	Loss/tok 3.7084 (4.1162)	Learning Rate [0.00125]
1: TRAIN [0][5840/6832]	Time 0.121 (0.105)	Data 0.00105 (0.00094)	Tok/s 53020 (59352)	Loss/tok 3.8585 (4.1171)	Learning Rate [0.00125]
0: TRAIN [0][5840/6832]	Time 0.121 (0.105)	Data 0.00106 (0.00095)	Tok/s 53008 (58894)	Loss/tok 3.5896 (4.1155)	Learning Rate [0.00125]
1: TRAIN [0][5850/6832]	Time 0.090 (0.105)	Data 0.00087 (0.00094)	Tok/s 51052 (59363)	Loss/tok 3.3892 (4.1159)	Learning Rate [0.00125]
2: TRAIN [0][5850/6832]	Time 0.090 (0.105)	Data 0.00086 (0.00095)	Tok/s 51060 (59737)	Loss/tok 3.3775 (4.1096)	Learning Rate [0.00125]
3: TRAIN [0][5850/6832]	Time 0.090 (0.105)	Data 0.00084 (0.00095)	Tok/s 51632 (60181)	Loss/tok 3.5430 (4.1152)	Learning Rate [0.00125]
0: TRAIN [0][5850/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00095)	Tok/s 51043 (58905)	Loss/tok 3.3581 (4.1144)	Learning Rate [0.00125]
2: TRAIN [0][5860/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00095)	Tok/s 71396 (59733)	Loss/tok 3.6525 (4.1087)	Learning Rate [0.00125]
3: TRAIN [0][5860/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00095)	Tok/s 71866 (60176)	Loss/tok 3.5695 (4.1143)	Learning Rate [0.00125]
0: TRAIN [0][5860/6832]	Time 0.128 (0.105)	Data 0.00100 (0.00095)	Tok/s 70888 (58901)	Loss/tok 3.6830 (4.1135)	Learning Rate [0.00125]
1: TRAIN [0][5860/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 70844 (59358)	Loss/tok 3.5021 (4.1149)	Learning Rate [0.00125]
1: TRAIN [0][5870/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 62859 (59370)	Loss/tok 3.7879 (4.1137)	Learning Rate [0.00125]
2: TRAIN [0][5870/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 62816 (59745)	Loss/tok 3.6645 (4.1075)	Learning Rate [0.00125]
0: TRAIN [0][5870/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00095)	Tok/s 62864 (58913)	Loss/tok 3.6814 (4.1123)	Learning Rate [0.00125]
3: TRAIN [0][5870/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 63488 (60188)	Loss/tok 3.8286 (4.1132)	Learning Rate [0.00125]
1: TRAIN [0][5880/6832]	Time 0.096 (0.105)	Data 0.00089 (0.00094)	Tok/s 50895 (59365)	Loss/tok 3.3617 (4.1128)	Learning Rate [0.00125]
0: TRAIN [0][5880/6832]	Time 0.096 (0.105)	Data 0.00095 (0.00095)	Tok/s 50922 (58908)	Loss/tok 3.3551 (4.1114)	Learning Rate [0.00125]
3: TRAIN [0][5880/6832]	Time 0.096 (0.105)	Data 0.00085 (0.00095)	Tok/s 52215 (60182)	Loss/tok 3.4861 (4.1122)	Learning Rate [0.00125]
2: TRAIN [0][5880/6832]	Time 0.096 (0.105)	Data 0.00087 (0.00095)	Tok/s 50919 (59739)	Loss/tok 3.3770 (4.1066)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][5890/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00095)	Tok/s 88917 (59747)	Loss/tok 3.4418 (4.1054)	Learning Rate [0.00125]
1: TRAIN [0][5890/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 88259 (59373)	Loss/tok 3.5457 (4.1116)	Learning Rate [0.00125]
3: TRAIN [0][5890/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00095)	Tok/s 89755 (60191)	Loss/tok 3.3571 (4.1110)	Learning Rate [0.00125]
0: TRAIN [0][5890/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00095)	Tok/s 87518 (58916)	Loss/tok 3.4736 (4.1102)	Learning Rate [0.00125]
1: TRAIN [0][5900/6832]	Time 0.106 (0.105)	Data 0.00087 (0.00094)	Tok/s 53228 (59378)	Loss/tok 3.4857 (4.1106)	Learning Rate [0.00125]
0: TRAIN [0][5900/6832]	Time 0.106 (0.105)	Data 0.00101 (0.00095)	Tok/s 52037 (58921)	Loss/tok 3.4897 (4.1092)	Learning Rate [0.00125]
2: TRAIN [0][5900/6832]	Time 0.106 (0.105)	Data 0.00085 (0.00095)	Tok/s 53155 (59752)	Loss/tok 3.5644 (4.1044)	Learning Rate [0.00125]
3: TRAIN [0][5900/6832]	Time 0.106 (0.105)	Data 0.00085 (0.00095)	Tok/s 53118 (60196)	Loss/tok 3.3806 (4.1099)	Learning Rate [0.00125]
2: TRAIN [0][5910/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00095)	Tok/s 65201 (59757)	Loss/tok 3.6705 (4.1033)	Learning Rate [0.00125]
1: TRAIN [0][5910/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00093)	Tok/s 65178 (59383)	Loss/tok 3.8636 (4.1095)	Learning Rate [0.00125]
3: TRAIN [0][5910/6832]	Time 0.126 (0.105)	Data 0.00083 (0.00095)	Tok/s 65659 (60201)	Loss/tok 3.7186 (4.1089)	Learning Rate [0.00125]
0: TRAIN [0][5910/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00095)	Tok/s 65172 (58927)	Loss/tok 3.5629 (4.1082)	Learning Rate [0.00125]
1: TRAIN [0][5920/6832]	Time 0.128 (0.105)	Data 0.00083 (0.00093)	Tok/s 69847 (59384)	Loss/tok 3.6290 (4.1085)	Learning Rate [0.00125]
2: TRAIN [0][5920/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 70147 (59758)	Loss/tok 3.6631 (4.1022)	Learning Rate [0.00125]
0: TRAIN [0][5920/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 69853 (58927)	Loss/tok 3.5065 (4.1071)	Learning Rate [0.00125]
3: TRAIN [0][5920/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00094)	Tok/s 70840 (60202)	Loss/tok 3.6363 (4.1079)	Learning Rate [0.00125]
2: TRAIN [0][5930/6832]	Time 0.106 (0.105)	Data 0.00084 (0.00095)	Tok/s 53247 (59761)	Loss/tok 3.5291 (4.1013)	Learning Rate [0.00125]
3: TRAIN [0][5930/6832]	Time 0.106 (0.105)	Data 0.00083 (0.00094)	Tok/s 53250 (60204)	Loss/tok 3.5653 (4.1068)	Learning Rate [0.00125]
1: TRAIN [0][5930/6832]	Time 0.106 (0.105)	Data 0.00083 (0.00093)	Tok/s 53159 (59386)	Loss/tok 3.5761 (4.1076)	Learning Rate [0.00125]
0: TRAIN [0][5930/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00095)	Tok/s 52537 (58930)	Loss/tok 3.6036 (4.1063)	Learning Rate [0.00125]
2: TRAIN [0][5940/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00095)	Tok/s 63976 (59762)	Loss/tok 3.4682 (4.1002)	Learning Rate [0.00125]
1: TRAIN [0][5940/6832]	Time 0.126 (0.105)	Data 0.00084 (0.00093)	Tok/s 63128 (59388)	Loss/tok 3.7659 (4.1066)	Learning Rate [0.00125]
0: TRAIN [0][5940/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00095)	Tok/s 63170 (58932)	Loss/tok 3.5059 (4.1053)	Learning Rate [0.00125]
3: TRAIN [0][5940/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00094)	Tok/s 64170 (60205)	Loss/tok 3.5897 (4.1058)	Learning Rate [0.00125]
1: TRAIN [0][5950/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00093)	Tok/s 50861 (59392)	Loss/tok 3.5928 (4.1056)	Learning Rate [0.00125]
0: TRAIN [0][5950/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00095)	Tok/s 50856 (58936)	Loss/tok 3.3322 (4.1042)	Learning Rate [0.00125]
2: TRAIN [0][5950/6832]	Time 0.101 (0.105)	Data 0.00088 (0.00095)	Tok/s 51435 (59766)	Loss/tok 3.3126 (4.0992)	Learning Rate [0.00125]
3: TRAIN [0][5950/6832]	Time 0.101 (0.105)	Data 0.00088 (0.00094)	Tok/s 52031 (60208)	Loss/tok 3.6134 (4.1048)	Learning Rate [0.00125]
2: TRAIN [0][5960/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00095)	Tok/s 53838 (59756)	Loss/tok 3.5536 (4.0984)	Learning Rate [0.00125]
1: TRAIN [0][5960/6832]	Time 0.107 (0.105)	Data 0.00090 (0.00093)	Tok/s 53798 (59382)	Loss/tok 3.5025 (4.1047)	Learning Rate [0.00125]
3: TRAIN [0][5960/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00094)	Tok/s 53824 (60199)	Loss/tok 3.3273 (4.1039)	Learning Rate [0.00125]
0: TRAIN [0][5960/6832]	Time 0.107 (0.105)	Data 0.00096 (0.00095)	Tok/s 53801 (58927)	Loss/tok 3.4420 (4.1034)	Learning Rate [0.00125]
2: TRAIN [0][5970/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 68061 (59763)	Loss/tok 3.7045 (4.0974)	Learning Rate [0.00125]
3: TRAIN [0][5970/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 68082 (60205)	Loss/tok 3.6611 (4.1028)	Learning Rate [0.00125]
1: TRAIN [0][5970/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00093)	Tok/s 67900 (59389)	Loss/tok 3.6142 (4.1036)	Learning Rate [0.00125]
0: TRAIN [0][5970/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00095)	Tok/s 67020 (58934)	Loss/tok 3.8776 (4.1024)	Learning Rate [0.00125]
1: TRAIN [0][5980/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00093)	Tok/s 85400 (59400)	Loss/tok 3.3804 (4.1025)	Learning Rate [0.00125]
0: TRAIN [0][5980/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 85053 (58945)	Loss/tok 3.4582 (4.1014)	Learning Rate [0.00125]
2: TRAIN [0][5980/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00095)	Tok/s 86110 (59773)	Loss/tok 3.4934 (4.0964)	Learning Rate [0.00125]
3: TRAIN [0][5980/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 86490 (60216)	Loss/tok 3.6530 (4.1016)	Learning Rate [0.00125]
1: TRAIN [0][5990/6832]	Time 0.127 (0.105)	Data 0.00096 (0.00093)	Tok/s 61722 (59397)	Loss/tok 3.6783 (4.1016)	Learning Rate [0.00125]
0: TRAIN [0][5990/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00095)	Tok/s 61745 (58941)	Loss/tok 3.6466 (4.1004)	Learning Rate [0.00125]
2: TRAIN [0][5990/6832]	Time 0.127 (0.105)	Data 0.00123 (0.00095)	Tok/s 62445 (59771)	Loss/tok 3.6106 (4.0955)	Learning Rate [0.00125]
3: TRAIN [0][5990/6832]	Time 0.127 (0.105)	Data 0.00102 (0.00094)	Tok/s 62576 (60214)	Loss/tok 3.4446 (4.1008)	Learning Rate [0.00125]
1: TRAIN [0][6000/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 85211 (59396)	Loss/tok 3.4379 (4.1007)	Learning Rate [0.00125]
2: TRAIN [0][6000/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00095)	Tok/s 86043 (59770)	Loss/tok 3.3736 (4.0945)	Learning Rate [0.00125]
0: TRAIN [0][6000/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 84941 (58940)	Loss/tok 3.4472 (4.0996)	Learning Rate [0.00125]
3: TRAIN [0][6000/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 86249 (60212)	Loss/tok 3.4771 (4.0998)	Learning Rate [0.00125]
1: TRAIN [0][6010/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 85468 (59394)	Loss/tok 3.5990 (4.0997)	Learning Rate [0.00125]
0: TRAIN [0][6010/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 84875 (58939)	Loss/tok 3.4234 (4.0985)	Learning Rate [0.00125]
2: TRAIN [0][6010/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00095)	Tok/s 85919 (59768)	Loss/tok 3.5134 (4.0935)	Learning Rate [0.00125]
3: TRAIN [0][6010/6832]	Time 0.132 (0.105)	Data 0.00082 (0.00094)	Tok/s 86487 (60211)	Loss/tok 3.4157 (4.0988)	Learning Rate [0.00125]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [0][6020/6832]	Time 0.110 (0.105)	Data 0.00085 (0.00093)	Tok/s 51264 (59393)	Loss/tok 3.4215 (4.0987)	Learning Rate [0.00125]
0: TRAIN [0][6020/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00095)	Tok/s 51259 (58938)	Loss/tok 3.4879 (4.0977)	Learning Rate [0.00125]
2: TRAIN [0][6020/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00095)	Tok/s 51714 (59767)	Loss/tok 3.5936 (4.0926)	Learning Rate [0.00125]
3: TRAIN [0][6020/6832]	Time 0.110 (0.105)	Data 0.00086 (0.00094)	Tok/s 52440 (60210)	Loss/tok 3.6434 (4.0979)	Learning Rate [0.00125]
2: TRAIN [0][6030/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00095)	Tok/s 59174 (59766)	Loss/tok 3.5451 (4.0917)	Learning Rate [0.00125]
1: TRAIN [0][6030/6832]	Time 0.123 (0.105)	Data 0.00093 (0.00093)	Tok/s 58553 (59392)	Loss/tok 3.6622 (4.0979)	Learning Rate [0.00125]
3: TRAIN [0][6030/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00094)	Tok/s 59180 (60209)	Loss/tok 3.8980 (4.0971)	Learning Rate [0.00125]
0: TRAIN [0][6030/6832]	Time 0.123 (0.105)	Data 0.00097 (0.00095)	Tok/s 58161 (58937)	Loss/tok 3.5931 (4.0968)	Learning Rate [0.00125]
1: TRAIN [0][6040/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00093)	Tok/s 60889 (59397)	Loss/tok 3.6998 (4.0969)	Learning Rate [0.000625]
2: TRAIN [0][6040/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00095)	Tok/s 60874 (59771)	Loss/tok 3.5439 (4.0907)	Learning Rate [0.000625]
3: TRAIN [0][6040/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 61033 (60214)	Loss/tok 3.7282 (4.0962)	Learning Rate [0.000625]
0: TRAIN [0][6040/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00095)	Tok/s 60856 (58942)	Loss/tok 3.6056 (4.0959)	Learning Rate [0.000625]
1: TRAIN [0][6050/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00093)	Tok/s 61020 (59397)	Loss/tok 3.5303 (4.0959)	Learning Rate [0.000625]
2: TRAIN [0][6050/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 61441 (59771)	Loss/tok 3.5624 (4.0898)	Learning Rate [0.000625]
0: TRAIN [0][6050/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 61036 (58943)	Loss/tok 3.5002 (4.0949)	Learning Rate [0.000625]
3: TRAIN [0][6050/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 62072 (60213)	Loss/tok 3.7179 (4.0953)	Learning Rate [0.000625]
2: TRAIN [0][6060/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00095)	Tok/s 48676 (59778)	Loss/tok 3.3282 (4.0889)	Learning Rate [0.000625]
1: TRAIN [0][6060/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00093)	Tok/s 48683 (59405)	Loss/tok 3.1882 (4.0948)	Learning Rate [0.000625]
0: TRAIN [0][6060/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00095)	Tok/s 48677 (58951)	Loss/tok 3.3318 (4.0938)	Learning Rate [0.000625]
3: TRAIN [0][6060/6832]	Time 0.084 (0.105)	Data 0.00092 (0.00094)	Tok/s 48682 (60220)	Loss/tok 3.3095 (4.0941)	Learning Rate [0.000625]
1: TRAIN [0][6070/6832]	Time 0.123 (0.105)	Data 0.00086 (0.00093)	Tok/s 58151 (59396)	Loss/tok 3.3447 (4.0939)	Learning Rate [0.000625]
2: TRAIN [0][6070/6832]	Time 0.123 (0.105)	Data 0.00086 (0.00095)	Tok/s 58253 (59770)	Loss/tok 3.6121 (4.0880)	Learning Rate [0.000625]
0: TRAIN [0][6070/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00095)	Tok/s 57226 (58941)	Loss/tok 3.6803 (4.0930)	Learning Rate [0.000625]
3: TRAIN [0][6070/6832]	Time 0.123 (0.105)	Data 0.00084 (0.00094)	Tok/s 58257 (60212)	Loss/tok 3.6778 (4.0933)	Learning Rate [0.000625]
1: TRAIN [0][6080/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00093)	Tok/s 68885 (59398)	Loss/tok 3.6342 (4.0929)	Learning Rate [0.000625]
2: TRAIN [0][6080/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 68914 (59772)	Loss/tok 3.5749 (4.0869)	Learning Rate [0.000625]
0: TRAIN [0][6080/6832]	Time 0.130 (0.105)	Data 0.00107 (0.00095)	Tok/s 68902 (58943)	Loss/tok 3.6322 (4.0919)	Learning Rate [0.000625]
3: TRAIN [0][6080/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 69590 (60213)	Loss/tok 3.5808 (4.0922)	Learning Rate [0.000625]
1: TRAIN [0][6090/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00093)	Tok/s 51098 (59391)	Loss/tok 3.5384 (4.0920)	Learning Rate [0.000625]
2: TRAIN [0][6090/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00095)	Tok/s 51952 (59764)	Loss/tok 3.5051 (4.0861)	Learning Rate [0.000625]
0: TRAIN [0][6090/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00095)	Tok/s 51107 (58937)	Loss/tok 3.4437 (4.0911)	Learning Rate [0.000625]
3: TRAIN [0][6090/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00094)	Tok/s 52296 (60206)	Loss/tok 3.5176 (4.0913)	Learning Rate [0.000625]
2: TRAIN [0][6100/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00095)	Tok/s 53155 (59760)	Loss/tok 3.2054 (4.0851)	Learning Rate [0.000625]
1: TRAIN [0][6100/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00093)	Tok/s 53130 (59386)	Loss/tok 3.3033 (4.0911)	Learning Rate [0.000625]
0: TRAIN [0][6100/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00095)	Tok/s 53177 (58933)	Loss/tok 3.2255 (4.0901)	Learning Rate [0.000625]
3: TRAIN [0][6100/6832]	Time 0.084 (0.105)	Data 0.00085 (0.00094)	Tok/s 53147 (60202)	Loss/tok 3.4893 (4.0905)	Learning Rate [0.000625]
2: TRAIN [0][6110/6832]	Time 0.109 (0.105)	Data 0.00086 (0.00095)	Tok/s 51752 (59762)	Loss/tok 3.6707 (4.0841)	Learning Rate [0.000625]
1: TRAIN [0][6110/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00093)	Tok/s 51581 (59388)	Loss/tok 3.3805 (4.0899)	Learning Rate [0.000625]
3: TRAIN [0][6110/6832]	Time 0.109 (0.105)	Data 0.00085 (0.00094)	Tok/s 51762 (60203)	Loss/tok 3.3376 (4.0894)	Learning Rate [0.000625]
0: TRAIN [0][6110/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00095)	Tok/s 50565 (58934)	Loss/tok 3.5810 (4.0892)	Learning Rate [0.000625]
2: TRAIN [0][6120/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00095)	Tok/s 73689 (59763)	Loss/tok 3.5810 (4.0831)	Learning Rate [0.000625]
3: TRAIN [0][6120/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00094)	Tok/s 73807 (60204)	Loss/tok 3.6163 (4.0884)	Learning Rate [0.000625]
1: TRAIN [0][6120/6832]	Time 0.127 (0.105)	Data 0.00109 (0.00093)	Tok/s 72782 (59389)	Loss/tok 3.6468 (4.0890)	Learning Rate [0.000625]
0: TRAIN [0][6120/6832]	Time 0.127 (0.105)	Data 0.00103 (0.00095)	Tok/s 72828 (58936)	Loss/tok 3.4867 (4.0882)	Learning Rate [0.000625]
2: TRAIN [0][6130/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00095)	Tok/s 51842 (59760)	Loss/tok 3.2694 (4.0822)	Learning Rate [0.000625]
3: TRAIN [0][6130/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00094)	Tok/s 52167 (60201)	Loss/tok 3.4270 (4.0874)	Learning Rate [0.000625]
1: TRAIN [0][6130/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00093)	Tok/s 51690 (59387)	Loss/tok 3.4067 (4.0880)	Learning Rate [0.000625]
0: TRAIN [0][6130/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00095)	Tok/s 51699 (58934)	Loss/tok 3.4280 (4.0873)	Learning Rate [0.000625]
2: TRAIN [0][6140/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00095)	Tok/s 59731 (59758)	Loss/tok 3.5593 (4.0812)	Learning Rate [0.000625]
3: TRAIN [0][6140/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00094)	Tok/s 60623 (60199)	Loss/tok 3.6338 (4.0865)	Learning Rate [0.000625]
0: TRAIN [0][6140/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00095)	Tok/s 59671 (58928)	Loss/tok 3.5748 (4.0864)	Learning Rate [0.000625]
1: TRAIN [0][6140/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00093)	Tok/s 59705 (59383)	Loss/tok 3.5863 (4.0871)	Learning Rate [0.000625]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [0][6150/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00095)	Tok/s 45937 (59756)	Loss/tok 2.9231 (4.0802)	Learning Rate [0.000625]
1: TRAIN [0][6150/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00093)	Tok/s 45686 (59382)	Loss/tok 2.7616 (4.0862)	Learning Rate [0.000625]
0: TRAIN [0][6150/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00095)	Tok/s 43517 (58927)	Loss/tok 2.7140 (4.0854)	Learning Rate [0.000625]
3: TRAIN [0][6150/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00094)	Tok/s 47491 (60198)	Loss/tok 2.7564 (4.0854)	Learning Rate [0.000625]
1: TRAIN [0][6160/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00093)	Tok/s 51100 (59378)	Loss/tok 3.3443 (4.0853)	Learning Rate [0.000625]
2: TRAIN [0][6160/6832]	Time 0.070 (0.105)	Data 0.00086 (0.00095)	Tok/s 51103 (59753)	Loss/tok 3.0027 (4.0794)	Learning Rate [0.000625]
0: TRAIN [0][6160/6832]	Time 0.070 (0.105)	Data 0.00098 (0.00095)	Tok/s 50641 (58924)	Loss/tok 3.0506 (4.0844)	Learning Rate [0.000625]
3: TRAIN [0][6160/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00094)	Tok/s 51113 (60194)	Loss/tok 3.1731 (4.0845)	Learning Rate [0.000625]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [0][6170/6832]	Time 0.076 (0.105)	Data 0.00089 (0.00093)	Tok/s 55776 (59385)	Loss/tok 3.1676 (4.0842)	Learning Rate [0.000625]
2: TRAIN [0][6170/6832]	Time 0.076 (0.105)	Data 0.00090 (0.00095)	Tok/s 55855 (59760)	Loss/tok 3.1091 (4.0782)	Learning Rate [0.000625]
3: TRAIN [0][6170/6832]	Time 0.076 (0.105)	Data 0.00092 (0.00094)	Tok/s 55857 (60201)	Loss/tok 3.0864 (4.0834)	Learning Rate [0.000625]
0: TRAIN [0][6170/6832]	Time 0.076 (0.105)	Data 0.00090 (0.00095)	Tok/s 55090 (58931)	Loss/tok 3.1219 (4.0834)	Learning Rate [0.000625]
1: TRAIN [0][6180/6832]	Time 0.116 (0.105)	Data 0.00084 (0.00093)	Tok/s 57327 (59378)	Loss/tok 3.5708 (4.0833)	Learning Rate [0.000625]
0: TRAIN [0][6180/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00095)	Tok/s 57365 (58924)	Loss/tok 3.5650 (4.0826)	Learning Rate [0.000625]
2: TRAIN [0][6180/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00095)	Tok/s 57344 (59754)	Loss/tok 3.6356 (4.0775)	Learning Rate [0.000625]
3: TRAIN [0][6180/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00094)	Tok/s 57354 (60195)	Loss/tok 3.4825 (4.0825)	Learning Rate [0.000625]
1: TRAIN [0][6190/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00093)	Tok/s 54987 (59370)	Loss/tok 3.3830 (4.0824)	Learning Rate [0.000625]
0: TRAIN [0][6190/6832]	Time 0.123 (0.105)	Data 0.00093 (0.00095)	Tok/s 55021 (58915)	Loss/tok 3.4864 (4.0818)	Learning Rate [0.000625]
2: TRAIN [0][6190/6832]	Time 0.123 (0.105)	Data 0.00083 (0.00095)	Tok/s 54936 (59745)	Loss/tok 3.4243 (4.0767)	Learning Rate [0.000625]
3: TRAIN [0][6190/6832]	Time 0.123 (0.105)	Data 0.00086 (0.00094)	Tok/s 55912 (60186)	Loss/tok 3.4810 (4.0817)	Learning Rate [0.000625]
2: TRAIN [0][6200/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00095)	Tok/s 71794 (59745)	Loss/tok 3.5267 (4.0757)	Learning Rate [0.000625]
1: TRAIN [0][6200/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00093)	Tok/s 70928 (59369)	Loss/tok 3.5140 (4.0814)	Learning Rate [0.000625]
3: TRAIN [0][6200/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 71922 (60186)	Loss/tok 3.6616 (4.0807)	Learning Rate [0.000625]
0: TRAIN [0][6200/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00095)	Tok/s 70969 (58913)	Loss/tok 3.5405 (4.0807)	Learning Rate [0.000625]
1: TRAIN [0][6210/6832]	Time 0.111 (0.105)	Data 0.00416 (0.00093)	Tok/s 52949 (59369)	Loss/tok 3.4411 (4.0804)	Learning Rate [0.000625]
2: TRAIN [0][6210/6832]	Time 0.111 (0.105)	Data 0.00100 (0.00095)	Tok/s 53267 (59745)	Loss/tok 3.5133 (4.0747)	Learning Rate [0.000625]
3: TRAIN [0][6210/6832]	Time 0.111 (0.105)	Data 0.00100 (0.00094)	Tok/s 54089 (60185)	Loss/tok 3.4142 (4.0798)	Learning Rate [0.000625]
0: TRAIN [0][6210/6832]	Time 0.111 (0.105)	Data 0.00095 (0.00095)	Tok/s 52996 (58914)	Loss/tok 3.3404 (4.0797)	Learning Rate [0.000625]
2: TRAIN [0][6220/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00095)	Tok/s 86166 (59752)	Loss/tok 3.3863 (4.0736)	Learning Rate [0.000625]
3: TRAIN [0][6220/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00094)	Tok/s 86657 (60193)	Loss/tok 3.4711 (4.0787)	Learning Rate [0.000625]
1: TRAIN [0][6220/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 85491 (59377)	Loss/tok 3.4678 (4.0793)	Learning Rate [0.000625]
0: TRAIN [0][6220/6832]	Time 0.132 (0.105)	Data 0.00106 (0.00095)	Tok/s 84898 (58921)	Loss/tok 3.5680 (4.0787)	Learning Rate [0.000625]
2: TRAIN [0][6230/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00095)	Tok/s 54046 (59746)	Loss/tok 3.1239 (4.0728)	Learning Rate [0.000625]
3: TRAIN [0][6230/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00094)	Tok/s 54076 (60187)	Loss/tok 3.2811 (4.0778)	Learning Rate [0.000625]
1: TRAIN [0][6230/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00093)	Tok/s 54011 (59370)	Loss/tok 3.2004 (4.0785)	Learning Rate [0.000625]
0: TRAIN [0][6230/6832]	Time 0.071 (0.105)	Data 0.00099 (0.00095)	Tok/s 52859 (58913)	Loss/tok 3.3828 (4.0779)	Learning Rate [0.000625]
1: TRAIN [0][6240/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00093)	Tok/s 51070 (59369)	Loss/tok 3.3079 (4.0776)	Learning Rate [0.000625]
2: TRAIN [0][6240/6832]	Time 0.075 (0.105)	Data 0.00085 (0.00095)	Tok/s 52717 (59744)	Loss/tok 3.4702 (4.0719)	Learning Rate [0.000625]
0: TRAIN [0][6240/6832]	Time 0.075 (0.105)	Data 0.00094 (0.00095)	Tok/s 51085 (58912)	Loss/tok 3.1832 (4.0770)	Learning Rate [0.000625]
3: TRAIN [0][6240/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00094)	Tok/s 52724 (60185)	Loss/tok 3.1215 (4.0769)	Learning Rate [0.000625]
1: TRAIN [0][6250/6832]	Time 0.086 (0.105)	Data 0.00096 (0.00093)	Tok/s 52427 (59364)	Loss/tok 3.4070 (4.0767)	Learning Rate [0.000625]
2: TRAIN [0][6250/6832]	Time 0.086 (0.105)	Data 0.00091 (0.00095)	Tok/s 53766 (59739)	Loss/tok 3.3372 (4.0710)	Learning Rate [0.000625]
3: TRAIN [0][6250/6832]	Time 0.086 (0.105)	Data 0.00100 (0.00094)	Tok/s 53761 (60180)	Loss/tok 3.2574 (4.0759)	Learning Rate [0.000625]
0: TRAIN [0][6250/6832]	Time 0.086 (0.105)	Data 0.00099 (0.00095)	Tok/s 52333 (58907)	Loss/tok 3.4402 (4.0760)	Learning Rate [0.000625]
2: TRAIN [0][6260/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00095)	Tok/s 56708 (59742)	Loss/tok 3.3837 (4.0701)	Learning Rate [0.000625]
1: TRAIN [0][6260/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00093)	Tok/s 55579 (59366)	Loss/tok 3.5858 (4.0758)	Learning Rate [0.000625]
3: TRAIN [0][6260/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00094)	Tok/s 56694 (60182)	Loss/tok 3.4963 (4.0749)	Learning Rate [0.000625]
0: TRAIN [0][6260/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00095)	Tok/s 55602 (58910)	Loss/tok 3.4627 (4.0751)	Learning Rate [0.000625]
1: TRAIN [0][6270/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00093)	Tok/s 51917 (59367)	Loss/tok 3.2264 (4.0747)	Learning Rate [0.000625]
2: TRAIN [0][6270/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00095)	Tok/s 51943 (59742)	Loss/tok 3.1677 (4.0691)	Learning Rate [0.000625]
3: TRAIN [0][6270/6832]	Time 0.072 (0.105)	Data 0.00084 (0.00094)	Tok/s 51894 (60183)	Loss/tok 3.1940 (4.0739)	Learning Rate [0.000625]
0: TRAIN [0][6270/6832]	Time 0.072 (0.105)	Data 0.00096 (0.00095)	Tok/s 51375 (58911)	Loss/tok 3.3043 (4.0741)	Learning Rate [0.000625]
1: TRAIN [0][6280/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 91534 (59377)	Loss/tok 3.5239 (4.0736)	Learning Rate [0.000625]
2: TRAIN [0][6280/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 92651 (59752)	Loss/tok 3.3623 (4.0681)	Learning Rate [0.000625]
0: TRAIN [0][6280/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 90468 (58921)	Loss/tok 3.3901 (4.0731)	Learning Rate [0.000625]
3: TRAIN [0][6280/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 94238 (60193)	Loss/tok 3.3319 (4.0728)	Learning Rate [0.000625]
1: TRAIN [0][6290/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00093)	Tok/s 53998 (59370)	Loss/tok 3.2145 (4.0727)	Learning Rate [0.000625]
0: TRAIN [0][6290/6832]	Time 0.073 (0.105)	Data 0.00094 (0.00095)	Tok/s 53992 (58914)	Loss/tok 3.3409 (4.0722)	Learning Rate [0.000625]
3: TRAIN [0][6290/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00094)	Tok/s 54599 (60186)	Loss/tok 3.2181 (4.0719)	Learning Rate [0.000625]
2: TRAIN [0][6290/6832]	Time 0.074 (0.105)	Data 0.00097 (0.00095)	Tok/s 53862 (59746)	Loss/tok 3.3992 (4.0671)	Learning Rate [0.000625]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: TRAIN [0][6300/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00094)	Tok/s 54942 (60188)	Loss/tok 3.5382 (4.0709)	Learning Rate [0.000625]
1: TRAIN [0][6300/6832]	Time 0.112 (0.105)	Data 0.00093 (0.00093)	Tok/s 54827 (59371)	Loss/tok 3.3933 (4.0716)	Learning Rate [0.000625]
2: TRAIN [0][6300/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00095)	Tok/s 54915 (59747)	Loss/tok 3.5978 (4.0662)	Learning Rate [0.000625]
0: TRAIN [0][6300/6832]	Time 0.112 (0.105)	Data 0.00107 (0.00095)	Tok/s 54373 (58916)	Loss/tok 3.4431 (4.0712)	Learning Rate [0.000625]
1: TRAIN [0][6310/6832]	Time 0.071 (0.105)	Data 0.00085 (0.00093)	Tok/s 52502 (59367)	Loss/tok 3.2572 (4.0707)	Learning Rate [0.000625]
0: TRAIN [0][6310/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00095)	Tok/s 52529 (58912)	Loss/tok 3.2086 (4.0704)	Learning Rate [0.000625]
2: TRAIN [0][6310/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00095)	Tok/s 52570 (59743)	Loss/tok 3.3519 (4.0654)	Learning Rate [0.000625]
3: TRAIN [0][6310/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00094)	Tok/s 52561 (60183)	Loss/tok 3.3214 (4.0701)	Learning Rate [0.000625]
3: TRAIN [0][6320/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 74453 (60186)	Loss/tok 3.6270 (4.0692)	Learning Rate [0.000625]
2: TRAIN [0][6320/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 74465 (59746)	Loss/tok 3.5618 (4.0644)	Learning Rate [0.000625]
1: TRAIN [0][6320/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 74442 (59371)	Loss/tok 3.6542 (4.0697)	Learning Rate [0.000625]
0: TRAIN [0][6320/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00095)	Tok/s 73447 (58916)	Loss/tok 3.7226 (4.0694)	Learning Rate [0.000625]
1: TRAIN [0][6330/6832]	Time 0.088 (0.105)	Data 0.00084 (0.00093)	Tok/s 52306 (59366)	Loss/tok 3.2476 (4.0688)	Learning Rate [0.000625]
2: TRAIN [0][6330/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00095)	Tok/s 53402 (59742)	Loss/tok 3.4811 (4.0636)	Learning Rate [0.000625]
3: TRAIN [0][6330/6832]	Time 0.088 (0.105)	Data 0.00083 (0.00094)	Tok/s 53826 (60183)	Loss/tok 3.3601 (4.0682)	Learning Rate [0.000625]
0: TRAIN [0][6330/6832]	Time 0.088 (0.105)	Data 0.00091 (0.00095)	Tok/s 52332 (58908)	Loss/tok 3.2129 (4.0684)	Learning Rate [0.000625]
1: TRAIN [0][6340/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00093)	Tok/s 52246 (59368)	Loss/tok 3.1766 (4.0678)	Learning Rate [0.000625]
0: TRAIN [0][6340/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00095)	Tok/s 51231 (58910)	Loss/tok 3.2494 (4.0675)	Learning Rate [0.000625]
3: TRAIN [0][6340/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00094)	Tok/s 53023 (60185)	Loss/tok 3.3597 (4.0672)	Learning Rate [0.000625]
2: TRAIN [0][6340/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00095)	Tok/s 52998 (59744)	Loss/tok 3.1512 (4.0626)	Learning Rate [0.000625]
1: TRAIN [0][6350/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00093)	Tok/s 59857 (59363)	Loss/tok 3.5404 (4.0670)	Learning Rate [0.000625]
0: TRAIN [0][6350/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00095)	Tok/s 59487 (58904)	Loss/tok 3.4550 (4.0667)	Learning Rate [0.000625]
2: TRAIN [0][6350/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 59809 (59740)	Loss/tok 3.6070 (4.0618)	Learning Rate [0.000625]
3: TRAIN [0][6350/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00094)	Tok/s 59789 (60181)	Loss/tok 3.3962 (4.0664)	Learning Rate [0.000625]
3: Gradient norm: inf
2: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
1: TRAIN [0][6360/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00093)	Tok/s 55703 (59365)	Loss/tok 3.5503 (4.0660)	Learning Rate [0.000625]
0: TRAIN [0][6360/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00095)	Tok/s 54965 (58905)	Loss/tok 3.5744 (4.0657)	Learning Rate [0.000625]
2: TRAIN [0][6360/6832]	Time 0.122 (0.105)	Data 0.00096 (0.00095)	Tok/s 55734 (59742)	Loss/tok 3.5638 (4.0607)	Learning Rate [0.000625]
3: TRAIN [0][6360/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00094)	Tok/s 55735 (60183)	Loss/tok 3.7111 (4.0654)	Learning Rate [0.000625]
1: TRAIN [0][6370/6832]	Time 0.076 (0.105)	Data 0.00085 (0.00093)	Tok/s 54019 (59367)	Loss/tok 3.3080 (4.0649)	Learning Rate [0.000625]
3: TRAIN [0][6370/6832]	Time 0.076 (0.105)	Data 0.00089 (0.00094)	Tok/s 54123 (60185)	Loss/tok 3.4282 (4.0644)	Learning Rate [0.000625]
2: TRAIN [0][6370/6832]	Time 0.076 (0.105)	Data 0.00098 (0.00095)	Tok/s 54159 (59744)	Loss/tok 3.2961 (4.0597)	Learning Rate [0.000625]
0: TRAIN [0][6370/6832]	Time 0.076 (0.105)	Data 0.00093 (0.00095)	Tok/s 54048 (58908)	Loss/tok 3.2406 (4.0647)	Learning Rate [0.000625]
1: TRAIN [0][6380/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00093)	Tok/s 53541 (59367)	Loss/tok 3.2783 (4.0640)	Learning Rate [0.000625]
0: TRAIN [0][6380/6832]	Time 0.079 (0.105)	Data 0.00092 (0.00095)	Tok/s 53549 (58908)	Loss/tok 3.2023 (4.0637)	Learning Rate [0.000625]
3: TRAIN [0][6380/6832]	Time 0.079 (0.105)	Data 0.00086 (0.00094)	Tok/s 54894 (60184)	Loss/tok 3.3819 (4.0635)	Learning Rate [0.000625]
2: TRAIN [0][6380/6832]	Time 0.079 (0.105)	Data 0.00091 (0.00095)	Tok/s 53482 (59744)	Loss/tok 3.3259 (4.0588)	Learning Rate [0.000625]
1: TRAIN [0][6390/6832]	Time 0.117 (0.105)	Data 0.00084 (0.00093)	Tok/s 58009 (59363)	Loss/tok 3.4526 (4.0630)	Learning Rate [0.000625]
0: TRAIN [0][6390/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00095)	Tok/s 58009 (58904)	Loss/tok 3.5340 (4.0629)	Learning Rate [0.000625]
2: TRAIN [0][6390/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00095)	Tok/s 57998 (59740)	Loss/tok 3.4607 (4.0579)	Learning Rate [0.000625]
3: TRAIN [0][6390/6832]	Time 0.117 (0.105)	Data 0.00083 (0.00094)	Tok/s 57973 (60180)	Loss/tok 3.4768 (4.0626)	Learning Rate [0.000625]
1: TRAIN [0][6400/6832]	Time 0.092 (0.105)	Data 0.00085 (0.00093)	Tok/s 52399 (59358)	Loss/tok 3.4444 (4.0622)	Learning Rate [0.000625]
3: TRAIN [0][6400/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00094)	Tok/s 52702 (60176)	Loss/tok 3.1587 (4.0617)	Learning Rate [0.000625]
2: TRAIN [0][6400/6832]	Time 0.092 (0.105)	Data 0.00107 (0.00095)	Tok/s 52695 (59735)	Loss/tok 3.3241 (4.0571)	Learning Rate [0.000625]
0: TRAIN [0][6400/6832]	Time 0.092 (0.105)	Data 0.00094 (0.00095)	Tok/s 51296 (58900)	Loss/tok 3.3389 (4.0620)	Learning Rate [0.000625]
2: TRAIN [0][6410/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00095)	Tok/s 52588 (59737)	Loss/tok 3.2960 (4.0562)	Learning Rate [0.000625]
3: TRAIN [0][6410/6832]	Time 0.088 (0.105)	Data 0.00083 (0.00094)	Tok/s 52537 (60178)	Loss/tok 3.4488 (4.0607)	Learning Rate [0.000625]
1: TRAIN [0][6410/6832]	Time 0.088 (0.105)	Data 0.00095 (0.00093)	Tok/s 52608 (59360)	Loss/tok 3.3154 (4.0612)	Learning Rate [0.000625]
0: TRAIN [0][6410/6832]	Time 0.088 (0.105)	Data 0.00102 (0.00095)	Tok/s 51356 (58902)	Loss/tok 3.4593 (4.0611)	Learning Rate [0.000625]
1: TRAIN [0][6420/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00093)	Tok/s 52476 (59363)	Loss/tok 3.3382 (4.0603)	Learning Rate [0.000625]
3: TRAIN [0][6420/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00094)	Tok/s 52455 (60180)	Loss/tok 3.4272 (4.0598)	Learning Rate [0.000625]
2: TRAIN [0][6420/6832]	Time 0.110 (0.105)	Data 0.00094 (0.00095)	Tok/s 52456 (59739)	Loss/tok 3.4704 (4.0553)	Learning Rate [0.000625]
0: TRAIN [0][6420/6832]	Time 0.110 (0.105)	Data 0.00096 (0.00095)	Tok/s 52487 (58905)	Loss/tok 3.4975 (4.0601)	Learning Rate [0.000625]
1: TRAIN [0][6430/6832]	Time 0.070 (0.105)	Data 0.00084 (0.00093)	Tok/s 52715 (59359)	Loss/tok 3.1787 (4.0594)	Learning Rate [0.000625]
2: TRAIN [0][6430/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00095)	Tok/s 52780 (59736)	Loss/tok 3.1700 (4.0544)	Learning Rate [0.000625]
3: TRAIN [0][6430/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00094)	Tok/s 52762 (60177)	Loss/tok 3.1475 (4.0589)	Learning Rate [0.000625]
0: TRAIN [0][6430/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00095)	Tok/s 50927 (58899)	Loss/tok 2.9291 (4.0592)	Learning Rate [0.000625]
1: TRAIN [0][6440/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00093)	Tok/s 53022 (59350)	Loss/tok 3.5916 (4.0586)	Learning Rate [0.000625]
3: TRAIN [0][6440/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00094)	Tok/s 53066 (60168)	Loss/tok 3.5597 (4.0582)	Learning Rate [0.000625]
2: TRAIN [0][6440/6832]	Time 0.101 (0.105)	Data 0.00094 (0.00095)	Tok/s 53050 (59727)	Loss/tok 3.4515 (4.0536)	Learning Rate [0.000625]
0: TRAIN [0][6440/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00095)	Tok/s 52740 (58891)	Loss/tok 3.3671 (4.0584)	Learning Rate [0.000625]
1: TRAIN [0][6450/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00093)	Tok/s 55631 (59344)	Loss/tok 3.6268 (4.0577)	Learning Rate [0.000625]
2: TRAIN [0][6450/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00095)	Tok/s 55567 (59722)	Loss/tok 3.4731 (4.0526)	Learning Rate [0.000625]
0: TRAIN [0][6450/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00095)	Tok/s 55580 (58884)	Loss/tok 3.6629 (4.0575)	Learning Rate [0.000625]
3: TRAIN [0][6450/6832]	Time 0.120 (0.105)	Data 0.00083 (0.00094)	Tok/s 55574 (60164)	Loss/tok 3.5407 (4.0572)	Learning Rate [0.000625]
1: TRAIN [0][6460/6832]	Time 0.078 (0.105)	Data 0.00084 (0.00093)	Tok/s 50611 (59341)	Loss/tok 3.2498 (4.0568)	Learning Rate [0.000625]
2: TRAIN [0][6460/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00095)	Tok/s 50615 (59718)	Loss/tok 3.2596 (4.0517)	Learning Rate [0.000625]
3: TRAIN [0][6460/6832]	Time 0.078 (0.105)	Data 0.00085 (0.00094)	Tok/s 50910 (60160)	Loss/tok 3.1894 (4.0563)	Learning Rate [0.000625]
0: TRAIN [0][6460/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00095)	Tok/s 50640 (58881)	Loss/tok 3.3706 (4.0567)	Learning Rate [0.000625]
2: TRAIN [0][6470/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 64341 (59718)	Loss/tok 3.4953 (4.0507)	Learning Rate [0.000625]
3: TRAIN [0][6470/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 64811 (60159)	Loss/tok 3.5853 (4.0554)	Learning Rate [0.000625]
1: TRAIN [0][6470/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 64320 (59340)	Loss/tok 3.6969 (4.0559)	Learning Rate [0.000625]
0: TRAIN [0][6470/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00095)	Tok/s 64304 (58881)	Loss/tok 3.6035 (4.0558)	Learning Rate [0.000625]
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [0][6480/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 88093 (59340)	Loss/tok 3.4112 (4.0549)	Learning Rate [0.000625]
3: TRAIN [0][6480/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 89707 (60159)	Loss/tok 3.4304 (4.0544)	Learning Rate [0.000625]
0: TRAIN [0][6480/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 87602 (58880)	Loss/tok 3.2214 (4.0548)	Learning Rate [0.000625]
2: TRAIN [0][6480/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 88718 (59717)	Loss/tok 3.2316 (4.0496)	Learning Rate [0.000625]
3: TRAIN [0][6490/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 83026 (60159)	Loss/tok 3.4116 (4.0534)	Learning Rate [0.000625]
2: TRAIN [0][6490/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 82207 (59716)	Loss/tok 3.3755 (4.0487)	Learning Rate [0.000625]
1: TRAIN [0][6490/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00093)	Tok/s 82116 (59339)	Loss/tok 3.5200 (4.0539)	Learning Rate [0.000625]
0: TRAIN [0][6490/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 81178 (58878)	Loss/tok 3.5113 (4.0538)	Learning Rate [0.000625]
3: TRAIN [0][6500/6832]	Time 0.082 (0.105)	Data 0.00083 (0.00094)	Tok/s 53754 (60154)	Loss/tok 3.3099 (4.0526)	Learning Rate [0.000625]
2: TRAIN [0][6500/6832]	Time 0.082 (0.105)	Data 0.00088 (0.00095)	Tok/s 52961 (59711)	Loss/tok 3.3212 (4.0478)	Learning Rate [0.000625]
1: TRAIN [0][6500/6832]	Time 0.082 (0.105)	Data 0.00092 (0.00093)	Tok/s 53000 (59334)	Loss/tok 3.1208 (4.0531)	Learning Rate [0.000625]
0: TRAIN [0][6500/6832]	Time 0.082 (0.105)	Data 0.00095 (0.00095)	Tok/s 53014 (58873)	Loss/tok 3.2969 (4.0530)	Learning Rate [0.000625]
1: Gradient norm: inf
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [0][6510/6832]	Time 0.051 (0.105)	Data 0.00099 (0.00095)	Tok/s 47987 (59718)	Loss/tok 2.8003 (4.0469)	Learning Rate [0.000625]
3: TRAIN [0][6510/6832]	Time 0.051 (0.105)	Data 0.00086 (0.00094)	Tok/s 50369 (60162)	Loss/tok 2.8343 (4.0517)	Learning Rate [0.000625]
0: TRAIN [0][6510/6832]	Time 0.051 (0.105)	Data 0.00112 (0.00095)	Tok/s 45503 (58880)	Loss/tok 2.7128 (4.0518)	Learning Rate [0.000625]
1: TRAIN [0][6510/6832]	Time 0.051 (0.105)	Data 0.00113 (0.00093)	Tok/s 47961 (59341)	Loss/tok 2.7249 (4.0521)	Learning Rate [0.000625]
3: TRAIN [0][6520/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00094)	Tok/s 58155 (60156)	Loss/tok 3.5780 (4.0509)	Learning Rate [0.000625]
2: TRAIN [0][6520/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00095)	Tok/s 58156 (59713)	Loss/tok 3.4749 (4.0461)	Learning Rate [0.000625]
0: TRAIN [0][6520/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00095)	Tok/s 57996 (58876)	Loss/tok 3.6014 (4.0511)	Learning Rate [0.000625]
1: TRAIN [0][6520/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00093)	Tok/s 58150 (59337)	Loss/tok 3.5561 (4.0513)	Learning Rate [0.000625]
1: TRAIN [0][6530/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00093)	Tok/s 60249 (59332)	Loss/tok 3.5986 (4.0505)	Learning Rate [0.000625]
0: TRAIN [0][6530/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00095)	Tok/s 60252 (58872)	Loss/tok 3.3981 (4.0501)	Learning Rate [0.000625]
2: TRAIN [0][6530/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 60636 (59709)	Loss/tok 3.6287 (4.0453)	Learning Rate [0.000625]
3: TRAIN [0][6530/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 61177 (60152)	Loss/tok 3.5990 (4.0501)	Learning Rate [0.000625]
2: TRAIN [0][6540/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00095)	Tok/s 52909 (59701)	Loss/tok 3.3554 (4.0444)	Learning Rate [0.0003125]
3: TRAIN [0][6540/6832]	Time 0.090 (0.105)	Data 0.00085 (0.00094)	Tok/s 52902 (60143)	Loss/tok 3.4243 (4.0493)	Learning Rate [0.0003125]
1: TRAIN [0][6540/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00093)	Tok/s 52921 (59325)	Loss/tok 3.4444 (4.0496)	Learning Rate [0.0003125]
0: TRAIN [0][6540/6832]	Time 0.090 (0.105)	Data 0.00092 (0.00095)	Tok/s 52906 (58865)	Loss/tok 3.3120 (4.0493)	Learning Rate [0.0003125]
0: TRAIN [0][6550/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00095)	Tok/s 55250 (58863)	Loss/tok 3.3949 (4.0485)	Learning Rate [0.0003125]
1: TRAIN [0][6550/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00093)	Tok/s 55225 (59322)	Loss/tok 3.4966 (4.0488)	Learning Rate [0.0003125]
2: TRAIN [0][6550/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00095)	Tok/s 55075 (59698)	Loss/tok 3.4547 (4.0437)	Learning Rate [0.0003125]
3: TRAIN [0][6550/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 55156 (60140)	Loss/tok 3.4080 (4.0485)	Learning Rate [0.0003125]
1: TRAIN [0][6560/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 65709 (59315)	Loss/tok 3.5004 (4.0479)	Learning Rate [0.0003125]
3: TRAIN [0][6560/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00094)	Tok/s 65756 (60133)	Loss/tok 3.6879 (4.0477)	Learning Rate [0.0003125]
0: TRAIN [0][6560/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00095)	Tok/s 65721 (58856)	Loss/tok 3.6679 (4.0477)	Learning Rate [0.0003125]
2: TRAIN [0][6560/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00095)	Tok/s 65737 (59691)	Loss/tok 3.6654 (4.0429)	Learning Rate [0.0003125]
0: TRAIN [0][6570/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 80153 (58854)	Loss/tok 3.6877 (4.0469)	Learning Rate [0.0003125]
1: TRAIN [0][6570/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00093)	Tok/s 80117 (59312)	Loss/tok 3.3878 (4.0468)	Learning Rate [0.0003125]
3: TRAIN [0][6570/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 81061 (60130)	Loss/tok 3.4974 (4.0468)	Learning Rate [0.0003125]
2: TRAIN [0][6570/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 80570 (59688)	Loss/tok 3.4596 (4.0420)	Learning Rate [0.0003125]
1: TRAIN [0][6580/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00093)	Tok/s 51825 (59312)	Loss/tok 3.3655 (4.0459)	Learning Rate [0.0003125]
2: TRAIN [0][6580/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00095)	Tok/s 52584 (59687)	Loss/tok 3.4950 (4.0411)	Learning Rate [0.0003125]
3: TRAIN [0][6580/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00094)	Tok/s 52603 (60129)	Loss/tok 3.4153 (4.0460)	Learning Rate [0.0003125]
0: TRAIN [0][6580/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00095)	Tok/s 51431 (58854)	Loss/tok 3.4450 (4.0459)	Learning Rate [0.0003125]
1: TRAIN [0][6590/6832]	Time 0.073 (0.105)	Data 0.00093 (0.00093)	Tok/s 51385 (59315)	Loss/tok 3.4037 (4.0450)	Learning Rate [0.0003125]
0: TRAIN [0][6590/6832]	Time 0.073 (0.105)	Data 0.00088 (0.00095)	Tok/s 50950 (58856)	Loss/tok 3.1812 (4.0449)	Learning Rate [0.0003125]
2: TRAIN [0][6590/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00095)	Tok/s 52687 (59691)	Loss/tok 3.2304 (4.0400)	Learning Rate [0.0003125]
3: TRAIN [0][6590/6832]	Time 0.073 (0.105)	Data 0.00086 (0.00094)	Tok/s 52689 (60133)	Loss/tok 3.3277 (4.0450)	Learning Rate [0.0003125]
0: TRAIN [0][6600/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 79687 (58862)	Loss/tok 3.3655 (4.0439)	Learning Rate [0.0003125]
3: TRAIN [0][6600/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 81038 (60138)	Loss/tok 3.3464 (4.0440)	Learning Rate [0.0003125]
1: TRAIN [0][6600/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00093)	Tok/s 80073 (59320)	Loss/tok 3.5121 (4.0440)	Learning Rate [0.0003125]
2: TRAIN [0][6600/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 80240 (59696)	Loss/tok 3.3628 (4.0390)	Learning Rate [0.0003125]
2: TRAIN [0][6610/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00095)	Tok/s 53967 (59695)	Loss/tok 3.3495 (4.0381)	Learning Rate [0.0003125]
3: TRAIN [0][6610/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00094)	Tok/s 53969 (60137)	Loss/tok 3.2425 (4.0430)	Learning Rate [0.0003125]
0: TRAIN [0][6610/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00095)	Tok/s 52928 (58861)	Loss/tok 3.3378 (4.0429)	Learning Rate [0.0003125]
1: TRAIN [0][6610/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00093)	Tok/s 53972 (59320)	Loss/tok 3.2862 (4.0432)	Learning Rate [0.0003125]
3: TRAIN [0][6620/6832]	Time 0.102 (0.105)	Data 0.00097 (0.00094)	Tok/s 53699 (60143)	Loss/tok 3.6212 (4.0420)	Learning Rate [0.0003125]
2: TRAIN [0][6620/6832]	Time 0.103 (0.105)	Data 0.00098 (0.00095)	Tok/s 53684 (59701)	Loss/tok 3.3659 (4.0372)	Learning Rate [0.0003125]
1: TRAIN [0][6620/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00093)	Tok/s 53664 (59326)	Loss/tok 3.5109 (4.0421)	Learning Rate [0.0003125]
0: TRAIN [0][6620/6832]	Time 0.103 (0.105)	Data 0.00091 (0.00095)	Tok/s 53690 (58867)	Loss/tok 3.5796 (4.0419)	Learning Rate [0.0003125]
0: TRAIN [0][6630/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00095)	Tok/s 70831 (58862)	Loss/tok 3.6976 (4.0411)	Learning Rate [0.0003125]
1: TRAIN [0][6630/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00093)	Tok/s 71033 (59321)	Loss/tok 3.6913 (4.0412)	Learning Rate [0.0003125]
2: TRAIN [0][6630/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 71776 (59696)	Loss/tok 3.7416 (4.0364)	Learning Rate [0.0003125]
3: TRAIN [0][6630/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 71774 (60139)	Loss/tok 3.5165 (4.0412)	Learning Rate [0.0003125]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: TRAIN [0][6640/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00094)	Tok/s 52016 (60132)	Loss/tok 3.3426 (4.0404)	Learning Rate [0.0003125]
1: TRAIN [0][6640/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00093)	Tok/s 51966 (59314)	Loss/tok 3.3379 (4.0403)	Learning Rate [0.0003125]
0: TRAIN [0][6640/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00095)	Tok/s 51966 (58856)	Loss/tok 3.4027 (4.0403)	Learning Rate [0.0003125]
2: TRAIN [0][6640/6832]	Time 0.101 (0.105)	Data 0.00095 (0.00095)	Tok/s 51998 (59690)	Loss/tok 3.2607 (4.0356)	Learning Rate [0.0003125]
2: TRAIN [0][6650/6832]	Time 0.067 (0.105)	Data 0.00093 (0.00095)	Tok/s 51459 (59698)	Loss/tok 3.3695 (4.0345)	Learning Rate [0.0003125]
3: TRAIN [0][6650/6832]	Time 0.067 (0.105)	Data 0.00086 (0.00094)	Tok/s 51450 (60140)	Loss/tok 3.0590 (4.0392)	Learning Rate [0.0003125]
1: TRAIN [0][6650/6832]	Time 0.067 (0.105)	Data 0.00094 (0.00093)	Tok/s 50086 (59322)	Loss/tok 2.9460 (4.0392)	Learning Rate [0.0003125]
0: TRAIN [0][6650/6832]	Time 0.067 (0.105)	Data 0.00088 (0.00095)	Tok/s 49489 (58864)	Loss/tok 3.1452 (4.0392)	Learning Rate [0.0003125]
1: TRAIN [0][6660/6832]	Time 0.083 (0.105)	Data 0.00091 (0.00093)	Tok/s 54173 (59313)	Loss/tok 3.3691 (4.0384)	Learning Rate [0.0003125]
3: TRAIN [0][6660/6832]	Time 0.083 (0.105)	Data 0.00088 (0.00094)	Tok/s 55719 (60131)	Loss/tok 3.3587 (4.0385)	Learning Rate [0.0003125]
2: TRAIN [0][6660/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00095)	Tok/s 55597 (59689)	Loss/tok 3.2050 (4.0337)	Learning Rate [0.0003125]
0: TRAIN [0][6660/6832]	Time 0.083 (0.105)	Data 0.00092 (0.00095)	Tok/s 54140 (58855)	Loss/tok 3.3644 (4.0385)	Learning Rate [0.0003125]
1: TRAIN [0][6670/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00093)	Tok/s 58303 (59310)	Loss/tok 3.5594 (4.0376)	Learning Rate [0.0003125]
2: TRAIN [0][6670/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00095)	Tok/s 58931 (59686)	Loss/tok 3.5878 (4.0328)	Learning Rate [0.0003125]
0: TRAIN [0][6670/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00095)	Tok/s 58273 (58853)	Loss/tok 3.4864 (4.0377)	Learning Rate [0.0003125]
3: TRAIN [0][6670/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00094)	Tok/s 59304 (60128)	Loss/tok 3.6290 (4.0376)	Learning Rate [0.0003125]
3: TRAIN [0][6680/6832]	Time 0.092 (0.105)	Data 0.00105 (0.00094)	Tok/s 52778 (60127)	Loss/tok 3.4270 (4.0367)	Learning Rate [0.0003125]
2: TRAIN [0][6680/6832]	Time 0.092 (0.105)	Data 0.00106 (0.00095)	Tok/s 52576 (59685)	Loss/tok 3.2563 (4.0319)	Learning Rate [0.0003125]
1: TRAIN [0][6680/6832]	Time 0.092 (0.105)	Data 0.00096 (0.00093)	Tok/s 51385 (59310)	Loss/tok 3.2564 (4.0366)	Learning Rate [0.0003125]
0: TRAIN [0][6680/6832]	Time 0.092 (0.105)	Data 0.00097 (0.00095)	Tok/s 51379 (58853)	Loss/tok 3.3690 (4.0368)	Learning Rate [0.0003125]
1: TRAIN [0][6690/6832]	Time 0.098 (0.105)	Data 0.00086 (0.00093)	Tok/s 53797 (59298)	Loss/tok 3.2541 (4.0358)	Learning Rate [0.0003125]
2: TRAIN [0][6690/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00095)	Tok/s 53846 (59674)	Loss/tok 3.4133 (4.0311)	Learning Rate [0.0003125]
0: TRAIN [0][6690/6832]	Time 0.097 (0.105)	Data 0.00091 (0.00094)	Tok/s 53853 (58839)	Loss/tok 3.2524 (4.0360)	Learning Rate [0.0003125]
3: TRAIN [0][6690/6832]	Time 0.097 (0.105)	Data 0.00085 (0.00094)	Tok/s 53863 (60116)	Loss/tok 3.3394 (4.0358)	Learning Rate [0.0003125]
1: TRAIN [0][6700/6832]	Time 0.096 (0.105)	Data 0.00099 (0.00093)	Tok/s 54725 (59298)	Loss/tok 3.2874 (4.0349)	Learning Rate [0.0003125]
0: TRAIN [0][6700/6832]	Time 0.096 (0.105)	Data 0.00099 (0.00094)	Tok/s 54725 (58839)	Loss/tok 3.3512 (4.0351)	Learning Rate [0.0003125]
3: TRAIN [0][6700/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00094)	Tok/s 54695 (60116)	Loss/tok 3.2061 (4.0350)	Learning Rate [0.0003125]
2: TRAIN [0][6700/6832]	Time 0.096 (0.105)	Data 0.00099 (0.00095)	Tok/s 54705 (59674)	Loss/tok 3.3534 (4.0302)	Learning Rate [0.0003125]
3: TRAIN [0][6710/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 62378 (60108)	Loss/tok 3.4984 (4.0342)	Learning Rate [0.0003125]
2: TRAIN [0][6710/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00095)	Tok/s 62031 (59666)	Loss/tok 3.6946 (4.0295)	Learning Rate [0.0003125]
1: TRAIN [0][6710/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00093)	Tok/s 61358 (59290)	Loss/tok 3.5657 (4.0341)	Learning Rate [0.0003125]
0: TRAIN [0][6710/6832]	Time 0.129 (0.105)	Data 0.00103 (0.00094)	Tok/s 61352 (58832)	Loss/tok 3.6577 (4.0343)	Learning Rate [0.0003125]
1: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
2: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
2: TRAIN [0][6720/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00095)	Tok/s 53622 (59677)	Loss/tok 3.1683 (4.0283)	Learning Rate [0.0003125]
1: TRAIN [0][6720/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00093)	Tok/s 51943 (59301)	Loss/tok 3.3069 (4.0331)	Learning Rate [0.0003125]
3: TRAIN [0][6720/6832]	Time 0.072 (0.105)	Data 0.00087 (0.00094)	Tok/s 53606 (60119)	Loss/tok 3.0531 (4.0330)	Learning Rate [0.0003125]
0: TRAIN [0][6720/6832]	Time 0.072 (0.105)	Data 0.00092 (0.00094)	Tok/s 51848 (58843)	Loss/tok 3.0214 (4.0332)	Learning Rate [0.0003125]
1: TRAIN [0][6730/6832]	Time 0.090 (0.105)	Data 0.00092 (0.00093)	Tok/s 52899 (59299)	Loss/tok 3.3116 (4.0322)	Learning Rate [0.0003125]
3: TRAIN [0][6730/6832]	Time 0.090 (0.105)	Data 0.00084 (0.00094)	Tok/s 52885 (60116)	Loss/tok 3.2522 (4.0322)	Learning Rate [0.0003125]
2: TRAIN [0][6730/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00095)	Tok/s 52887 (59675)	Loss/tok 3.4938 (4.0276)	Learning Rate [0.0003125]
0: TRAIN [0][6730/6832]	Time 0.090 (0.105)	Data 0.00090 (0.00094)	Tok/s 52857 (58841)	Loss/tok 3.2516 (4.0324)	Learning Rate [0.0003125]
1: TRAIN [0][6740/6832]	Time 0.077 (0.105)	Data 0.00088 (0.00093)	Tok/s 51435 (59292)	Loss/tok 3.1125 (4.0315)	Learning Rate [0.0003125]
2: TRAIN [0][6740/6832]	Time 0.077 (0.105)	Data 0.00097 (0.00095)	Tok/s 53017 (59668)	Loss/tok 3.1769 (4.0268)	Learning Rate [0.0003125]
0: TRAIN [0][6740/6832]	Time 0.077 (0.105)	Data 0.00085 (0.00094)	Tok/s 51415 (58835)	Loss/tok 3.2521 (4.0315)	Learning Rate [0.0003125]
3: TRAIN [0][6740/6832]	Time 0.077 (0.105)	Data 0.00088 (0.00094)	Tok/s 53082 (60108)	Loss/tok 3.3509 (4.0314)	Learning Rate [0.0003125]
0: TRAIN [0][6750/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00094)	Tok/s 51886 (58834)	Loss/tok 3.3859 (4.0307)	Learning Rate [0.0003125]
1: TRAIN [0][6750/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00093)	Tok/s 51874 (59291)	Loss/tok 3.5996 (4.0306)	Learning Rate [0.0003125]
3: TRAIN [0][6750/6832]	Time 0.109 (0.105)	Data 0.00084 (0.00094)	Tok/s 51886 (60107)	Loss/tok 3.2815 (4.0305)	Learning Rate [0.0003125]
2: TRAIN [0][6750/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00095)	Tok/s 51890 (59666)	Loss/tok 3.4439 (4.0260)	Learning Rate [0.0003125]
3: TRAIN [0][6760/6832]	Time 0.055 (0.105)	Data 0.00089 (0.00094)	Tok/s 51914 (60101)	Loss/tok 2.9429 (4.0297)	Learning Rate [0.0003125]
1: TRAIN [0][6760/6832]	Time 0.055 (0.105)	Data 0.00093 (0.00093)	Tok/s 51324 (59285)	Loss/tok 2.9449 (4.0299)	Learning Rate [0.0003125]
2: TRAIN [0][6760/6832]	Time 0.055 (0.105)	Data 0.00093 (0.00095)	Tok/s 51311 (59660)	Loss/tok 2.9267 (4.0252)	Learning Rate [0.0003125]
0: TRAIN [0][6760/6832]	Time 0.055 (0.105)	Data 0.00088 (0.00094)	Tok/s 49697 (58828)	Loss/tok 2.7395 (4.0299)	Learning Rate [0.0003125]
0: TRAIN [0][6770/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 64608 (58836)	Loss/tok 3.5147 (4.0289)	Learning Rate [0.0003125]
2: TRAIN [0][6770/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 64607 (59669)	Loss/tok 3.4800 (4.0242)	Learning Rate [0.0003125]
3: TRAIN [0][6770/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 65345 (60109)	Loss/tok 3.5177 (4.0288)	Learning Rate [0.0003125]
1: TRAIN [0][6770/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00093)	Tok/s 64587 (59293)	Loss/tok 3.5173 (4.0289)	Learning Rate [0.0003125]
3: TRAIN [0][6780/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 74266 (60107)	Loss/tok 3.5042 (4.0279)	Learning Rate [0.0003125]
2: TRAIN [0][6780/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00095)	Tok/s 74273 (59666)	Loss/tok 3.5286 (4.0233)	Learning Rate [0.0003125]
1: TRAIN [0][6780/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00093)	Tok/s 73364 (59289)	Loss/tok 3.5206 (4.0280)	Learning Rate [0.0003125]
0: TRAIN [0][6780/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 73262 (58831)	Loss/tok 3.4648 (4.0280)	Learning Rate [0.0003125]
1: TRAIN [0][6790/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00093)	Tok/s 52370 (59288)	Loss/tok 3.5869 (4.0272)	Learning Rate [0.0003125]
2: TRAIN [0][6790/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00095)	Tok/s 52348 (59664)	Loss/tok 3.4432 (4.0224)	Learning Rate [0.0003125]
3: TRAIN [0][6790/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 52331 (60105)	Loss/tok 3.4009 (4.0270)	Learning Rate [0.0003125]
0: TRAIN [0][6790/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 52366 (58830)	Loss/tok 3.5996 (4.0272)	Learning Rate [0.0003125]
3: TRAIN [0][6800/6832]	Time 0.078 (0.105)	Data 0.00096 (0.00094)	Tok/s 52811 (60105)	Loss/tok 3.2745 (4.0262)	Learning Rate [0.0003125]
2: TRAIN [0][6800/6832]	Time 0.078 (0.105)	Data 0.00098 (0.00095)	Tok/s 52786 (59664)	Loss/tok 3.1646 (4.0215)	Learning Rate [0.0003125]
1: TRAIN [0][6800/6832]	Time 0.078 (0.105)	Data 0.00128 (0.00093)	Tok/s 52701 (59288)	Loss/tok 3.1026 (4.0264)	Learning Rate [0.0003125]
0: TRAIN [0][6800/6832]	Time 0.078 (0.105)	Data 0.00125 (0.00094)	Tok/s 52766 (58830)	Loss/tok 3.3037 (4.0263)	Learning Rate [0.0003125]
3: TRAIN [0][6810/6832]	Time 0.065 (0.105)	Data 0.00091 (0.00094)	Tok/s 51005 (60098)	Loss/tok 3.1796 (4.0254)	Learning Rate [0.0003125]
2: TRAIN [0][6810/6832]	Time 0.065 (0.105)	Data 0.00095 (0.00095)	Tok/s 50844 (59657)	Loss/tok 2.9414 (4.0208)	Learning Rate [0.0003125]
1: TRAIN [0][6810/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00093)	Tok/s 49059 (59280)	Loss/tok 2.9897 (4.0256)	Learning Rate [0.0003125]
0: TRAIN [0][6810/6832]	Time 0.065 (0.105)	Data 0.00098 (0.00094)	Tok/s 49054 (58823)	Loss/tok 2.9856 (4.0256)	Learning Rate [0.0003125]
1: TRAIN [0][6820/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00093)	Tok/s 81189 (59276)	Loss/tok 3.4943 (4.0247)	Learning Rate [0.0003125]
3: TRAIN [0][6820/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00094)	Tok/s 82185 (60095)	Loss/tok 3.5292 (4.0246)	Learning Rate [0.0003125]
2: TRAIN [0][6820/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00095)	Tok/s 81967 (59653)	Loss/tok 3.3460 (4.0198)	Learning Rate [0.0003125]
0: TRAIN [0][6820/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 81023 (58815)	Loss/tok 3.4777 (4.0249)	Learning Rate [0.0003125]
3: TRAIN [0][6830/6832]	Time 0.098 (0.105)	Data 0.00102 (0.00094)	Tok/s 54993 (60099)	Loss/tok 3.3172 (4.0237)	Learning Rate [0.0003125]
2: TRAIN [0][6830/6832]	Time 0.098 (0.105)	Data 0.00105 (0.00095)	Tok/s 54664 (59658)	Loss/tok 3.3407 (4.0189)	Learning Rate [0.0003125]
1: TRAIN [0][6830/6832]	Time 0.098 (0.105)	Data 0.00093 (0.00094)	Tok/s 54604 (59280)	Loss/tok 3.1432 (4.0238)	Learning Rate [0.0003125]
0: TRAIN [0][6830/6832]	Time 0.098 (0.105)	Data 0.00097 (0.00095)	Tok/s 54631 (58820)	Loss/tok 3.3074 (4.0239)	Learning Rate [0.0003125]
3: Running validation on dev set
1: Running validation on dev set
0: Running validation on dev set
2: Running validation on dev set
3: VALIDATION [0][0/20]	Time 0.036 (0.000)	Data 0.00210 (0.00000)	Tok/s 200734 (0)	Loss/tok 3.3471 (0.0000)	Learning Rate [0.0003125]
1: VALIDATION [0][0/20]	Time 0.041 (0.000)	Data 0.00208 (0.00000)	Tok/s 203578 (0)	Loss/tok 3.4405 (0.0000)	Learning Rate [0.0003125]
2: VALIDATION [0][0/20]	Time 0.040 (0.000)	Data 0.00244 (0.00000)	Tok/s 193122 (0)	Loss/tok 3.4260 (0.0000)	Learning Rate [0.0003125]
0: VALIDATION [0][0/20]	Time 0.069 (0.000)	Data 0.00324 (0.00000)	Tok/s 147774 (0)	Loss/tok 3.5350 (0.0000)	Learning Rate [0.0003125]
3: VALIDATION [0][10/20]	Time 0.015 (0.021)	Data 0.00178 (0.00205)	Tok/s 197025 (205277)	Loss/tok 3.1988 (3.3035)	Learning Rate [0.0003125]
1: VALIDATION [0][10/20]	Time 0.015 (0.022)	Data 0.00173 (0.00179)	Tok/s 202595 (208644)	Loss/tok 3.1852 (3.3115)	Learning Rate [0.0003125]
2: VALIDATION [0][10/20]	Time 0.015 (0.021)	Data 0.00179 (0.00191)	Tok/s 198181 (206298)	Loss/tok 3.0982 (3.2622)	Learning Rate [0.0003125]
0: VALIDATION [0][10/20]	Time 0.017 (0.024)	Data 0.00232 (0.00240)	Tok/s 186214 (195820)	Loss/tok 3.2323 (3.2706)	Learning Rate [0.0003125]
2: Running evaluation on test set
1: Running evaluation on test set
3: Running evaluation on test set
:::MLPv0.5.0 gnmt 1560383054.356994867 (train.py:459) eval_start: 0
0: Running evaluation on test set
3: TEST [0][0/6]	Time 1.318 (1.318)	Decoder iters 85.0 (85.0)	Tok/s 5790 (5790)
1: TEST [0][0/6]	Time 1.319 (1.319)	Decoder iters 149.0 (149.0)	Tok/s 5834 (5834)
2: TEST [0][0/6]	Time 1.319 (1.319)	Decoder iters 149.0 (149.0)	Tok/s 5664 (5664)
0: TEST [0][0/6]	Time 1.319 (1.319)	Decoder iters 143.0 (143.0)	Tok/s 5297 (5297)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
1: Finished evaluation on test set
2: Finished evaluation on test set
3: Finished evaluation on test set
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560383066.303166628 (train.py:464) eval_accuracy: {"epoch": 0, "value": 19.65999984741211}
:::MLPv0.5.0 gnmt 1560383066.303879261 (train.py:466) eval_target: 21.8
2: Summary: Epoch: 0	Training Loss 4.0225
3: Summary: Epoch: 0	Training Loss 4.0225
1: Summary: Epoch: 0	Training Loss 4.0225
3: Performance: Epoch: 0	Training: 237858 Tok/s
2: Performance: Epoch: 0	Training: 237858 Tok/s
3: Finished epoch 0
2: Finished epoch 0
1: Performance: Epoch: 0	Training: 237858 Tok/s
2: Starting epoch 1
3: Starting epoch 1
1: Finished epoch 0
1: Starting epoch 1
:::MLPv0.5.0 gnmt 1560383066.304502726 (train.py:467) eval_stop
0: Summary: Epoch: 0	Training Loss: 4.0225	Validation Loss: 3.2511	Test BLEU: 19.66
0: Performance: Epoch: 0	Training: 237858 Tok/s	Validation: 693938 Tok/s
0: Finished epoch 0
0: Starting epoch 1
:::MLPv0.5.0 gnmt 1560383066.305359840 (train.py:443) train_epoch: 1
1: Sampler for epoch 1 uses seed 3215289342
3: Sampler for epoch 1 uses seed 3215289342
2: Sampler for epoch 1 uses seed 3215289342
:::MLPv0.5.0 gnmt 1560383066.562125683 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 1 uses seed 3215289342
:::MLPv0.5.0 gnmt 1560383066.651680470 (seq2seq/data/sampler.py:66) input_shard: 40960
1: TRAIN [1][0/6832]	Time 1.349 (0.000)	Data 1.23341 (0.00000)	Tok/s 5030 (0)	Loss/tok 3.6218 (0.0000)	Learning Rate [0.0003125]
3: TRAIN [1][0/6832]	Time 1.349 (0.000)	Data 1.10214 (0.00000)	Tok/s 5031 (0)	Loss/tok 3.5569 (0.0000)	Learning Rate [0.0003125]
2: TRAIN [1][0/6832]	Time 1.349 (0.000)	Data 0.88895 (0.00000)	Tok/s 5029 (0)	Loss/tok 3.3968 (0.0000)	Learning Rate [0.0003125]
0: TRAIN [1][0/6832]	Time 1.349 (0.000)	Data 1.04057 (0.00000)	Tok/s 5029 (0)	Loss/tok 3.3362 (0.0000)	Learning Rate [0.0003125]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][10/6832]	Time 0.132 (0.110)	Data 0.00102 (0.00102)	Tok/s 85302 (63199)	Loss/tok 3.3056 (3.2872)	Learning Rate [0.0003125]
2: TRAIN [1][10/6832]	Time 0.132 (0.110)	Data 0.00102 (0.00105)	Tok/s 86301 (63647)	Loss/tok 3.3391 (3.2987)	Learning Rate [0.0003125]
3: TRAIN [1][10/6832]	Time 0.132 (0.110)	Data 0.00109 (0.00106)	Tok/s 86663 (64011)	Loss/tok 3.2885 (3.2587)	Learning Rate [0.0003125]
0: TRAIN [1][10/6832]	Time 0.132 (0.110)	Data 0.00131 (0.00092)	Tok/s 85267 (62712)	Loss/tok 3.1724 (3.2803)	Learning Rate [0.0003125]
2: TRAIN [1][20/6832]	Time 0.127 (0.106)	Data 0.00095 (0.00101)	Tok/s 63630 (62107)	Loss/tok 3.5867 (3.2948)	Learning Rate [0.0003125]
3: TRAIN [1][20/6832]	Time 0.127 (0.106)	Data 0.00098 (0.00103)	Tok/s 64437 (62432)	Loss/tok 3.4310 (3.2823)	Learning Rate [0.0003125]
1: TRAIN [1][20/6832]	Time 0.127 (0.106)	Data 0.00099 (0.00098)	Tok/s 63422 (61753)	Loss/tok 3.3381 (3.3012)	Learning Rate [0.0003125]
0: TRAIN [1][20/6832]	Time 0.127 (0.106)	Data 0.00097 (0.00100)	Tok/s 63445 (61441)	Loss/tok 3.4349 (3.2974)	Learning Rate [0.0003125]
2: TRAIN [1][30/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00099)	Tok/s 66882 (62977)	Loss/tok 3.4902 (3.2802)	Learning Rate [0.0003125]
1: TRAIN [1][30/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00099)	Tok/s 66888 (62602)	Loss/tok 3.3898 (3.2922)	Learning Rate [0.0003125]
3: TRAIN [1][30/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00102)	Tok/s 67000 (63469)	Loss/tok 3.5391 (3.2856)	Learning Rate [0.0003125]
0: TRAIN [1][30/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00100)	Tok/s 66767 (62255)	Loss/tok 3.4311 (3.2949)	Learning Rate [0.0003125]
2: TRAIN [1][40/6832]	Time 0.058 (0.102)	Data 0.00094 (0.00097)	Tok/s 50525 (61804)	Loss/tok 2.9454 (3.2758)	Learning Rate [0.0003125]
3: TRAIN [1][40/6832]	Time 0.058 (0.102)	Data 0.00098 (0.00100)	Tok/s 51730 (62333)	Loss/tok 2.9298 (3.2802)	Learning Rate [0.0003125]
0: TRAIN [1][40/6832]	Time 0.058 (0.102)	Data 0.00102 (0.00098)	Tok/s 50449 (61161)	Loss/tok 2.6629 (3.2898)	Learning Rate [0.0003125]
1: TRAIN [1][40/6832]	Time 0.058 (0.102)	Data 0.00143 (0.00099)	Tok/s 50523 (61480)	Loss/tok 2.8720 (3.2884)	Learning Rate [0.0003125]
2: TRAIN [1][50/6832]	Time 0.056 (0.101)	Data 0.00085 (0.00095)	Tok/s 52415 (60571)	Loss/tok 2.9793 (3.2805)	Learning Rate [0.0003125]
3: TRAIN [1][50/6832]	Time 0.056 (0.101)	Data 0.00089 (0.00099)	Tok/s 52979 (61030)	Loss/tok 2.8751 (3.2766)	Learning Rate [0.0003125]
0: TRAIN [1][50/6832]	Time 0.056 (0.101)	Data 0.00093 (0.00097)	Tok/s 51850 (59982)	Loss/tok 2.8188 (3.2873)	Learning Rate [0.0003125]
1: TRAIN [1][50/6832]	Time 0.056 (0.101)	Data 0.00093 (0.00099)	Tok/s 52458 (60300)	Loss/tok 2.8397 (3.2826)	Learning Rate [0.0003125]
1: TRAIN [1][60/6832]	Time 0.058 (0.102)	Data 0.00095 (0.00098)	Tok/s 48441 (60470)	Loss/tok 2.8577 (3.3017)	Learning Rate [0.0003125]
2: TRAIN [1][60/6832]	Time 0.059 (0.102)	Data 0.00090 (0.00095)	Tok/s 48203 (60754)	Loss/tok 2.8201 (3.2975)	Learning Rate [0.0003125]
0: TRAIN [1][60/6832]	Time 0.058 (0.102)	Data 0.00092 (0.00098)	Tok/s 48482 (60196)	Loss/tok 2.8663 (3.2917)	Learning Rate [0.0003125]
3: TRAIN [1][60/6832]	Time 0.059 (0.102)	Data 0.00094 (0.00099)	Tok/s 50275 (61244)	Loss/tok 2.8676 (3.2856)	Learning Rate [0.0003125]
1: TRAIN [1][70/6832]	Time 0.131 (0.102)	Data 0.00092 (0.00098)	Tok/s 81800 (60088)	Loss/tok 3.3512 (3.3003)	Learning Rate [0.0003125]
0: TRAIN [1][70/6832]	Time 0.131 (0.102)	Data 0.00091 (0.00098)	Tok/s 81542 (59810)	Loss/tok 3.3654 (3.2927)	Learning Rate [0.0003125]
3: TRAIN [1][70/6832]	Time 0.132 (0.102)	Data 0.00090 (0.00098)	Tok/s 82731 (60848)	Loss/tok 3.3170 (3.2867)	Learning Rate [0.0003125]
2: TRAIN [1][70/6832]	Time 0.132 (0.102)	Data 0.00084 (0.00094)	Tok/s 82428 (60374)	Loss/tok 3.3898 (3.2999)	Learning Rate [0.0003125]
2: TRAIN [1][80/6832]	Time 0.130 (0.103)	Data 0.00086 (0.00094)	Tok/s 76451 (60508)	Loss/tok 3.4104 (3.3052)	Learning Rate [0.0003125]
3: TRAIN [1][80/6832]	Time 0.130 (0.103)	Data 0.00091 (0.00097)	Tok/s 76587 (60948)	Loss/tok 3.3810 (3.2958)	Learning Rate [0.0003125]
1: TRAIN [1][80/6832]	Time 0.130 (0.103)	Data 0.00095 (0.00097)	Tok/s 75580 (60201)	Loss/tok 3.5092 (3.3080)	Learning Rate [0.0003125]
0: TRAIN [1][80/6832]	Time 0.130 (0.103)	Data 0.00093 (0.00097)	Tok/s 75599 (59921)	Loss/tok 3.2719 (3.2889)	Learning Rate [0.0003125]
3: TRAIN [1][90/6832]	Time 0.131 (0.102)	Data 0.00102 (0.00097)	Tok/s 71101 (60701)	Loss/tok 3.3737 (3.2981)	Learning Rate [0.0003125]
1: TRAIN [1][90/6832]	Time 0.132 (0.102)	Data 0.00097 (0.00097)	Tok/s 70080 (59910)	Loss/tok 3.2224 (3.3020)	Learning Rate [0.0003125]
0: TRAIN [1][90/6832]	Time 0.131 (0.102)	Data 0.00092 (0.00097)	Tok/s 70092 (59621)	Loss/tok 3.4782 (3.2927)	Learning Rate [0.0003125]
2: TRAIN [1][90/6832]	Time 0.131 (0.102)	Data 0.00093 (0.00094)	Tok/s 71085 (60256)	Loss/tok 3.4096 (3.3035)	Learning Rate [0.0003125]
2: TRAIN [1][100/6832]	Time 0.132 (0.103)	Data 0.00089 (0.00094)	Tok/s 88730 (60519)	Loss/tok 3.2773 (3.2993)	Learning Rate [0.0003125]
3: TRAIN [1][100/6832]	Time 0.132 (0.103)	Data 0.00092 (0.00097)	Tok/s 89470 (60992)	Loss/tok 3.1437 (3.2928)	Learning Rate [0.0003125]
0: TRAIN [1][100/6832]	Time 0.132 (0.103)	Data 0.00098 (0.00098)	Tok/s 87147 (59725)	Loss/tok 3.2324 (3.2897)	Learning Rate [0.0003125]
1: TRAIN [1][100/6832]	Time 0.132 (0.103)	Data 0.00100 (0.00097)	Tok/s 87990 (60120)	Loss/tok 3.2038 (3.2986)	Learning Rate [0.0003125]
0: TRAIN [1][110/6832]	Time 0.132 (0.102)	Data 0.00093 (0.00098)	Tok/s 87502 (59607)	Loss/tok 3.2967 (3.2862)	Learning Rate [0.0003125]
1: TRAIN [1][110/6832]	Time 0.132 (0.102)	Data 0.00092 (0.00097)	Tok/s 87992 (60002)	Loss/tok 3.3414 (3.2972)	Learning Rate [0.0003125]
2: TRAIN [1][110/6832]	Time 0.132 (0.102)	Data 0.00084 (0.00093)	Tok/s 88496 (60399)	Loss/tok 3.2544 (3.2938)	Learning Rate [0.0003125]
3: TRAIN [1][110/6832]	Time 0.132 (0.102)	Data 0.00090 (0.00097)	Tok/s 89240 (60891)	Loss/tok 3.2858 (3.2879)	Learning Rate [0.0003125]
2: TRAIN [1][120/6832]	Time 0.124 (0.102)	Data 0.00084 (0.00093)	Tok/s 64433 (60167)	Loss/tok 3.5336 (3.2906)	Learning Rate [0.0003125]
1: TRAIN [1][120/6832]	Time 0.124 (0.101)	Data 0.00094 (0.00097)	Tok/s 63806 (59777)	Loss/tok 3.5090 (3.2975)	Learning Rate [0.0003125]
0: TRAIN [1][120/6832]	Time 0.124 (0.101)	Data 0.00090 (0.00098)	Tok/s 63820 (59394)	Loss/tok 3.4411 (3.2808)	Learning Rate [0.0003125]
3: TRAIN [1][120/6832]	Time 0.124 (0.102)	Data 0.00088 (0.00097)	Tok/s 64790 (60681)	Loss/tok 3.3552 (3.2841)	Learning Rate [0.0003125]
2: TRAIN [1][130/6832]	Time 0.096 (0.102)	Data 0.00086 (0.00093)	Tok/s 53241 (59999)	Loss/tok 3.3834 (3.2927)	Learning Rate [0.0003125]
3: TRAIN [1][130/6832]	Time 0.096 (0.102)	Data 0.00091 (0.00097)	Tok/s 53240 (60512)	Loss/tok 3.3394 (3.2841)	Learning Rate [0.0003125]
1: TRAIN [1][130/6832]	Time 0.096 (0.102)	Data 0.00093 (0.00097)	Tok/s 52180 (59621)	Loss/tok 3.3518 (3.2931)	Learning Rate [0.0003125]
0: TRAIN [1][130/6832]	Time 0.096 (0.102)	Data 0.00090 (0.00098)	Tok/s 51905 (59257)	Loss/tok 3.1438 (3.2833)	Learning Rate [0.0003125]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][140/6832]	Time 0.111 (0.102)	Data 0.00084 (0.00093)	Tok/s 55425 (59957)	Loss/tok 3.3229 (3.2990)	Learning Rate [0.0003125]
3: TRAIN [1][140/6832]	Time 0.111 (0.102)	Data 0.00094 (0.00097)	Tok/s 55451 (60473)	Loss/tok 3.3672 (3.2870)	Learning Rate [0.0003125]
1: TRAIN [1][140/6832]	Time 0.111 (0.102)	Data 0.00095 (0.00097)	Tok/s 55406 (59599)	Loss/tok 3.3338 (3.2946)	Learning Rate [0.0003125]
0: TRAIN [1][140/6832]	Time 0.111 (0.102)	Data 0.00095 (0.00098)	Tok/s 55426 (59246)	Loss/tok 3.4583 (3.2863)	Learning Rate [0.0003125]
2: TRAIN [1][150/6832]	Time 0.083 (0.102)	Data 0.00087 (0.00093)	Tok/s 52465 (59969)	Loss/tok 3.0531 (3.2970)	Learning Rate [0.0003125]
1: TRAIN [1][150/6832]	Time 0.083 (0.102)	Data 0.00091 (0.00096)	Tok/s 52444 (59610)	Loss/tok 3.1916 (3.2911)	Learning Rate [0.0003125]
3: TRAIN [1][150/6832]	Time 0.083 (0.102)	Data 0.00091 (0.00097)	Tok/s 53739 (60494)	Loss/tok 3.1452 (3.2879)	Learning Rate [0.0003125]
0: TRAIN [1][150/6832]	Time 0.083 (0.102)	Data 0.00091 (0.00098)	Tok/s 52456 (59245)	Loss/tok 3.1274 (3.2846)	Learning Rate [0.0003125]
1: TRAIN [1][160/6832]	Time 0.129 (0.102)	Data 0.00094 (0.00096)	Tok/s 73667 (59802)	Loss/tok 3.2924 (3.2985)	Learning Rate [0.0003125]
0: TRAIN [1][160/6832]	Time 0.129 (0.102)	Data 0.00099 (0.00097)	Tok/s 72708 (59440)	Loss/tok 3.4453 (3.2936)	Learning Rate [0.0003125]
2: TRAIN [1][160/6832]	Time 0.129 (0.102)	Data 0.00087 (0.00093)	Tok/s 73607 (60147)	Loss/tok 3.3803 (3.3043)	Learning Rate [0.0003125]
3: TRAIN [1][160/6832]	Time 0.129 (0.102)	Data 0.00091 (0.00097)	Tok/s 73595 (60658)	Loss/tok 3.4880 (3.2957)	Learning Rate [0.0003125]
2: TRAIN [1][170/6832]	Time 0.105 (0.102)	Data 0.00085 (0.00093)	Tok/s 51196 (59848)	Loss/tok 3.4133 (3.3069)	Learning Rate [0.0003125]
3: TRAIN [1][170/6832]	Time 0.105 (0.102)	Data 0.00089 (0.00097)	Tok/s 51188 (60363)	Loss/tok 3.3918 (3.2961)	Learning Rate [0.0003125]
1: TRAIN [1][170/6832]	Time 0.105 (0.102)	Data 0.00089 (0.00096)	Tok/s 51183 (59502)	Loss/tok 3.1741 (3.2964)	Learning Rate [0.0003125]
0: TRAIN [1][170/6832]	Time 0.103 (0.102)	Data 0.00101 (0.00097)	Tok/s 51498 (59141)	Loss/tok 3.2512 (3.2950)	Learning Rate [0.0003125]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [1][180/6832]	Time 0.069 (0.102)	Data 0.00086 (0.00093)	Tok/s 52255 (59749)	Loss/tok 2.8913 (3.3060)	Learning Rate [0.0003125]
0: TRAIN [1][180/6832]	Time 0.069 (0.102)	Data 0.00091 (0.00097)	Tok/s 52298 (59051)	Loss/tok 3.1114 (3.2916)	Learning Rate [0.0003125]
1: TRAIN [1][180/6832]	Time 0.069 (0.102)	Data 0.00092 (0.00096)	Tok/s 52221 (59407)	Loss/tok 3.1199 (3.2979)	Learning Rate [0.0003125]
3: TRAIN [1][180/6832]	Time 0.069 (0.102)	Data 0.00090 (0.00097)	Tok/s 52949 (60262)	Loss/tok 3.0848 (3.2943)	Learning Rate [0.0003125]
1: TRAIN [1][190/6832]	Time 0.059 (0.102)	Data 0.00089 (0.00096)	Tok/s 50076 (59301)	Loss/tok 2.9512 (3.3013)	Learning Rate [0.0003125]
2: TRAIN [1][190/6832]	Time 0.059 (0.102)	Data 0.00085 (0.00092)	Tok/s 50172 (59637)	Loss/tok 2.8465 (3.3088)	Learning Rate [0.0003125]
0: TRAIN [1][190/6832]	Time 0.059 (0.102)	Data 0.00094 (0.00097)	Tok/s 50079 (58959)	Loss/tok 2.8509 (3.2925)	Learning Rate [0.0003125]
3: TRAIN [1][190/6832]	Time 0.059 (0.102)	Data 0.00086 (0.00097)	Tok/s 52184 (60144)	Loss/tok 3.0283 (3.2987)	Learning Rate [0.0003125]
2: TRAIN [1][200/6832]	Time 0.129 (0.103)	Data 0.00084 (0.00092)	Tok/s 66239 (59423)	Loss/tok 3.5021 (3.3077)	Learning Rate [0.0003125]
3: TRAIN [1][200/6832]	Time 0.129 (0.103)	Data 0.00089 (0.00097)	Tok/s 66535 (59908)	Loss/tok 3.4737 (3.2996)	Learning Rate [0.0003125]
1: TRAIN [1][200/6832]	Time 0.129 (0.103)	Data 0.00091 (0.00095)	Tok/s 66232 (59104)	Loss/tok 3.5155 (3.3040)	Learning Rate [0.0003125]
0: TRAIN [1][200/6832]	Time 0.129 (0.103)	Data 0.00089 (0.00097)	Tok/s 66238 (58771)	Loss/tok 3.4039 (3.2958)	Learning Rate [0.0003125]
2: TRAIN [1][210/6832]	Time 0.126 (0.102)	Data 0.00085 (0.00092)	Tok/s 65238 (59478)	Loss/tok 3.4503 (3.3103)	Learning Rate [0.0003125]
3: TRAIN [1][210/6832]	Time 0.126 (0.102)	Data 0.00086 (0.00097)	Tok/s 65855 (59966)	Loss/tok 3.6204 (3.3003)	Learning Rate [0.0003125]
1: TRAIN [1][210/6832]	Time 0.126 (0.102)	Data 0.00091 (0.00095)	Tok/s 65224 (59170)	Loss/tok 3.4063 (3.3024)	Learning Rate [0.0003125]
0: TRAIN [1][210/6832]	Time 0.126 (0.102)	Data 0.00089 (0.00097)	Tok/s 65199 (58843)	Loss/tok 3.4546 (3.2964)	Learning Rate [0.0003125]
2: TRAIN [1][220/6832]	Time 0.113 (0.103)	Data 0.00088 (0.00092)	Tok/s 53384 (59548)	Loss/tok 3.2756 (3.3087)	Learning Rate [0.00015625]
1: TRAIN [1][220/6832]	Time 0.113 (0.103)	Data 0.00098 (0.00096)	Tok/s 53416 (59228)	Loss/tok 3.5306 (3.3035)	Learning Rate [0.00015625]
0: TRAIN [1][220/6832]	Time 0.113 (0.103)	Data 0.00093 (0.00097)	Tok/s 53399 (58895)	Loss/tok 3.2651 (3.2993)	Learning Rate [0.00015625]
3: TRAIN [1][220/6832]	Time 0.113 (0.103)	Data 0.00088 (0.00097)	Tok/s 53375 (60031)	Loss/tok 3.5182 (3.3002)	Learning Rate [0.00015625]
1: TRAIN [1][230/6832]	Time 0.092 (0.102)	Data 0.00101 (0.00096)	Tok/s 54044 (59055)	Loss/tok 3.2212 (3.3030)	Learning Rate [0.00015625]
2: TRAIN [1][230/6832]	Time 0.092 (0.102)	Data 0.00097 (0.00092)	Tok/s 54023 (59365)	Loss/tok 3.2939 (3.3087)	Learning Rate [0.00015625]
3: TRAIN [1][230/6832]	Time 0.092 (0.102)	Data 0.00098 (0.00097)	Tok/s 54022 (59847)	Loss/tok 3.3921 (3.3012)	Learning Rate [0.00015625]
0: TRAIN [1][230/6832]	Time 0.092 (0.102)	Data 0.00094 (0.00097)	Tok/s 54054 (58731)	Loss/tok 3.1659 (3.2979)	Learning Rate [0.00015625]
2: TRAIN [1][240/6832]	Time 0.117 (0.103)	Data 0.00098 (0.00092)	Tok/s 55697 (59489)	Loss/tok 3.4248 (3.3111)	Learning Rate [0.00015625]
3: TRAIN [1][240/6832]	Time 0.117 (0.103)	Data 0.00106 (0.00097)	Tok/s 56646 (59972)	Loss/tok 3.4372 (3.3038)	Learning Rate [0.00015625]
1: TRAIN [1][240/6832]	Time 0.117 (0.103)	Data 0.00097 (0.00096)	Tok/s 55662 (59178)	Loss/tok 3.3941 (3.3065)	Learning Rate [0.00015625]
0: TRAIN [1][240/6832]	Time 0.117 (0.103)	Data 0.00096 (0.00097)	Tok/s 55658 (58860)	Loss/tok 3.3779 (3.3031)	Learning Rate [0.00015625]
2: TRAIN [1][250/6832]	Time 0.107 (0.103)	Data 0.00087 (0.00092)	Tok/s 52877 (59497)	Loss/tok 3.1226 (3.3089)	Learning Rate [0.00015625]
3: TRAIN [1][250/6832]	Time 0.107 (0.103)	Data 0.00100 (0.00097)	Tok/s 52849 (59980)	Loss/tok 3.1461 (3.3030)	Learning Rate [0.00015625]
0: TRAIN [1][250/6832]	Time 0.107 (0.103)	Data 0.00092 (0.00096)	Tok/s 51743 (58864)	Loss/tok 3.1958 (3.3034)	Learning Rate [0.00015625]
1: TRAIN [1][250/6832]	Time 0.107 (0.103)	Data 0.00091 (0.00096)	Tok/s 52762 (59193)	Loss/tok 3.2390 (3.3041)	Learning Rate [0.00015625]
2: TRAIN [1][260/6832]	Time 0.121 (0.103)	Data 0.00086 (0.00092)	Tok/s 55951 (59505)	Loss/tok 3.4727 (3.3124)	Learning Rate [0.00015625]
3: TRAIN [1][260/6832]	Time 0.121 (0.103)	Data 0.00092 (0.00097)	Tok/s 55949 (59981)	Loss/tok 3.2355 (3.3049)	Learning Rate [0.00015625]
0: TRAIN [1][260/6832]	Time 0.121 (0.103)	Data 0.00088 (0.00096)	Tok/s 55913 (58875)	Loss/tok 3.4726 (3.3063)	Learning Rate [0.00015625]
1: TRAIN [1][260/6832]	Time 0.121 (0.103)	Data 0.00092 (0.00096)	Tok/s 55903 (59205)	Loss/tok 3.3236 (3.3051)	Learning Rate [0.00015625]
2: TRAIN [1][270/6832]	Time 0.127 (0.103)	Data 0.00084 (0.00092)	Tok/s 63719 (59543)	Loss/tok 3.5404 (3.3117)	Learning Rate [0.00015625]
3: TRAIN [1][270/6832]	Time 0.127 (0.103)	Data 0.00086 (0.00097)	Tok/s 64146 (60029)	Loss/tok 3.4082 (3.3032)	Learning Rate [0.00015625]
1: TRAIN [1][270/6832]	Time 0.127 (0.103)	Data 0.00088 (0.00096)	Tok/s 63702 (59230)	Loss/tok 3.5347 (3.3069)	Learning Rate [0.00015625]
0: TRAIN [1][270/6832]	Time 0.127 (0.103)	Data 0.00090 (0.00096)	Tok/s 63686 (58856)	Loss/tok 3.5702 (3.3068)	Learning Rate [0.00015625]
2: TRAIN [1][280/6832]	Time 0.051 (0.103)	Data 0.00084 (0.00092)	Tok/s 47234 (59516)	Loss/tok 2.6412 (3.3105)	Learning Rate [0.00015625]
3: TRAIN [1][280/6832]	Time 0.051 (0.103)	Data 0.00094 (0.00097)	Tok/s 49604 (60006)	Loss/tok 2.6881 (3.3034)	Learning Rate [0.00015625]
1: TRAIN [1][280/6832]	Time 0.052 (0.103)	Data 0.00096 (0.00096)	Tok/s 47160 (59208)	Loss/tok 2.7054 (3.3069)	Learning Rate [0.00015625]
0: TRAIN [1][280/6832]	Time 0.052 (0.103)	Data 0.00091 (0.00096)	Tok/s 45065 (58824)	Loss/tok 2.5904 (3.3076)	Learning Rate [0.00015625]
2: TRAIN [1][290/6832]	Time 0.131 (0.103)	Data 0.00085 (0.00092)	Tok/s 80086 (59500)	Loss/tok 3.3046 (3.3127)	Learning Rate [0.00015625]
3: TRAIN [1][290/6832]	Time 0.131 (0.103)	Data 0.00090 (0.00097)	Tok/s 80898 (59987)	Loss/tok 3.3351 (3.3063)	Learning Rate [0.00015625]
0: TRAIN [1][290/6832]	Time 0.131 (0.103)	Data 0.00091 (0.00096)	Tok/s 79491 (58824)	Loss/tok 3.4557 (3.3123)	Learning Rate [0.00015625]
1: TRAIN [1][290/6832]	Time 0.131 (0.103)	Data 0.00091 (0.00096)	Tok/s 79890 (59199)	Loss/tok 3.3271 (3.3082)	Learning Rate [0.00015625]
3: TRAIN [1][300/6832]	Time 0.118 (0.104)	Data 0.00087 (0.00098)	Tok/s 58736 (59902)	Loss/tok 3.6297 (3.3076)	Learning Rate [0.00015625]
2: TRAIN [1][300/6832]	Time 0.118 (0.104)	Data 0.00085 (0.00092)	Tok/s 58727 (59414)	Loss/tok 3.2971 (3.3117)	Learning Rate [0.00015625]
1: TRAIN [1][300/6832]	Time 0.118 (0.104)	Data 0.00094 (0.00096)	Tok/s 58754 (59101)	Loss/tok 3.2508 (3.3088)	Learning Rate [0.00015625]
0: TRAIN [1][300/6832]	Time 0.118 (0.104)	Data 0.00090 (0.00096)	Tok/s 58754 (58690)	Loss/tok 3.3289 (3.3104)	Learning Rate [0.00015625]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][310/6832]	Time 0.107 (0.103)	Data 0.00084 (0.00092)	Tok/s 53779 (59229)	Loss/tok 3.3679 (3.3099)	Learning Rate [0.00015625]
1: TRAIN [1][310/6832]	Time 0.107 (0.103)	Data 0.00091 (0.00096)	Tok/s 53802 (58916)	Loss/tok 3.3086 (3.3064)	Learning Rate [0.00015625]
3: TRAIN [1][310/6832]	Time 0.107 (0.103)	Data 0.00087 (0.00098)	Tok/s 53756 (59712)	Loss/tok 3.2179 (3.3054)	Learning Rate [0.00015625]
0: TRAIN [1][310/6832]	Time 0.107 (0.103)	Data 0.00090 (0.00096)	Tok/s 53771 (58515)	Loss/tok 3.3130 (3.3084)	Learning Rate [0.00015625]
2: TRAIN [1][320/6832]	Time 0.052 (0.103)	Data 0.00091 (0.00092)	Tok/s 51869 (59212)	Loss/tok 2.8230 (3.3104)	Learning Rate [0.00015625]
3: TRAIN [1][320/6832]	Time 0.052 (0.103)	Data 0.00090 (0.00098)	Tok/s 51900 (59689)	Loss/tok 2.7853 (3.3033)	Learning Rate [0.00015625]
1: TRAIN [1][320/6832]	Time 0.052 (0.103)	Data 0.00092 (0.00096)	Tok/s 50396 (58900)	Loss/tok 2.7758 (3.3053)	Learning Rate [0.00015625]
0: TRAIN [1][320/6832]	Time 0.052 (0.103)	Data 0.00091 (0.00096)	Tok/s 49557 (58496)	Loss/tok 2.7009 (3.3084)	Learning Rate [0.00015625]
2: TRAIN [1][330/6832]	Time 0.128 (0.103)	Data 0.00084 (0.00092)	Tok/s 68804 (59441)	Loss/tok 3.6438 (3.3140)	Learning Rate [0.00015625]
3: TRAIN [1][330/6832]	Time 0.128 (0.103)	Data 0.00089 (0.00098)	Tok/s 69332 (59917)	Loss/tok 3.5518 (3.3067)	Learning Rate [0.00015625]
1: TRAIN [1][330/6832]	Time 0.128 (0.103)	Data 0.00093 (0.00096)	Tok/s 68825 (59132)	Loss/tok 3.2988 (3.3060)	Learning Rate [0.00015625]
0: TRAIN [1][330/6832]	Time 0.128 (0.103)	Data 0.00092 (0.00096)	Tok/s 68831 (58733)	Loss/tok 3.4596 (3.3113)	Learning Rate [0.00015625]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][340/6832]	Time 0.124 (0.103)	Data 0.00091 (0.00096)	Tok/s 58612 (59154)	Loss/tok 3.3889 (3.3058)	Learning Rate [0.00015625]
0: TRAIN [1][340/6832]	Time 0.124 (0.103)	Data 0.00101 (0.00096)	Tok/s 58746 (58759)	Loss/tok 3.5348 (3.3106)	Learning Rate [0.00015625]
2: TRAIN [1][340/6832]	Time 0.125 (0.103)	Data 0.00086 (0.00092)	Tok/s 58568 (59463)	Loss/tok 3.4227 (3.3114)	Learning Rate [0.00015625]
3: TRAIN [1][340/6832]	Time 0.125 (0.103)	Data 0.00088 (0.00098)	Tok/s 59559 (59940)	Loss/tok 3.3250 (3.3066)	Learning Rate [0.00015625]
1: TRAIN [1][350/6832]	Time 0.127 (0.104)	Data 0.00095 (0.00096)	Tok/s 67607 (59149)	Loss/tok 3.3317 (3.3076)	Learning Rate [0.00015625]
0: TRAIN [1][350/6832]	Time 0.127 (0.104)	Data 0.00089 (0.00096)	Tok/s 67629 (58727)	Loss/tok 3.4953 (3.3115)	Learning Rate [0.00015625]
2: TRAIN [1][350/6832]	Time 0.127 (0.104)	Data 0.00089 (0.00092)	Tok/s 67542 (59468)	Loss/tok 3.4824 (3.3116)	Learning Rate [0.00015625]
3: TRAIN [1][350/6832]	Time 0.127 (0.104)	Data 0.00107 (0.00098)	Tok/s 67909 (59951)	Loss/tok 3.3941 (3.3075)	Learning Rate [0.00015625]
2: TRAIN [1][360/6832]	Time 0.071 (0.104)	Data 0.00086 (0.00092)	Tok/s 52478 (59389)	Loss/tok 2.7955 (3.3119)	Learning Rate [0.00015625]
1: TRAIN [1][360/6832]	Time 0.071 (0.104)	Data 0.00093 (0.00096)	Tok/s 52438 (59073)	Loss/tok 3.0514 (3.3082)	Learning Rate [0.00015625]
3: TRAIN [1][360/6832]	Time 0.071 (0.104)	Data 0.00093 (0.00098)	Tok/s 52516 (59863)	Loss/tok 3.0543 (3.3106)	Learning Rate [0.00015625]
0: TRAIN [1][360/6832]	Time 0.071 (0.104)	Data 0.00088 (0.00096)	Tok/s 52407 (58661)	Loss/tok 3.0215 (3.3132)	Learning Rate [0.00015625]
1: TRAIN [1][370/6832]	Time 0.129 (0.104)	Data 0.00095 (0.00095)	Tok/s 61663 (59073)	Loss/tok 3.5301 (3.3081)	Learning Rate [0.00015625]
2: TRAIN [1][370/6832]	Time 0.130 (0.104)	Data 0.00087 (0.00092)	Tok/s 62225 (59396)	Loss/tok 3.4577 (3.3135)	Learning Rate [0.00015625]
0: TRAIN [1][370/6832]	Time 0.130 (0.104)	Data 0.00093 (0.00096)	Tok/s 61268 (58657)	Loss/tok 3.5340 (3.3129)	Learning Rate [0.00015625]
3: TRAIN [1][370/6832]	Time 0.130 (0.104)	Data 0.00093 (0.00098)	Tok/s 62234 (59866)	Loss/tok 3.4116 (3.3105)	Learning Rate [0.00015625]
2: TRAIN [1][380/6832]	Time 0.087 (0.104)	Data 0.00094 (0.00092)	Tok/s 53161 (59467)	Loss/tok 3.1060 (3.3132)	Learning Rate [0.00015625]
1: TRAIN [1][380/6832]	Time 0.087 (0.104)	Data 0.00096 (0.00095)	Tok/s 53088 (59148)	Loss/tok 3.3210 (3.3082)	Learning Rate [0.00015625]
0: TRAIN [1][380/6832]	Time 0.087 (0.104)	Data 0.00096 (0.00096)	Tok/s 53115 (58739)	Loss/tok 2.9922 (3.3141)	Learning Rate [0.00015625]
3: TRAIN [1][380/6832]	Time 0.087 (0.104)	Data 0.00109 (0.00099)	Tok/s 54005 (59935)	Loss/tok 3.1119 (3.3088)	Learning Rate [0.00015625]
2: TRAIN [1][390/6832]	Time 0.086 (0.104)	Data 0.00086 (0.00092)	Tok/s 55214 (59535)	Loss/tok 3.3235 (3.3149)	Learning Rate [0.00015625]
1: TRAIN [1][390/6832]	Time 0.086 (0.104)	Data 0.00099 (0.00095)	Tok/s 55219 (59215)	Loss/tok 3.0711 (3.3095)	Learning Rate [0.00015625]
0: TRAIN [1][390/6832]	Time 0.086 (0.104)	Data 0.00091 (0.00096)	Tok/s 55189 (58812)	Loss/tok 3.0563 (3.3139)	Learning Rate [0.00015625]
3: TRAIN [1][390/6832]	Time 0.086 (0.104)	Data 0.00098 (0.00099)	Tok/s 55225 (60004)	Loss/tok 3.1604 (3.3088)	Learning Rate [0.00015625]
2: TRAIN [1][400/6832]	Time 0.063 (0.104)	Data 0.00086 (0.00092)	Tok/s 51202 (59650)	Loss/tok 3.0588 (3.3167)	Learning Rate [0.00015625]
1: TRAIN [1][400/6832]	Time 0.063 (0.104)	Data 0.00092 (0.00095)	Tok/s 51101 (59329)	Loss/tok 2.9016 (3.3109)	Learning Rate [0.00015625]
3: TRAIN [1][400/6832]	Time 0.063 (0.104)	Data 0.00089 (0.00099)	Tok/s 52980 (60123)	Loss/tok 2.8936 (3.3102)	Learning Rate [0.00015625]
0: TRAIN [1][400/6832]	Time 0.063 (0.104)	Data 0.00088 (0.00096)	Tok/s 51078 (58931)	Loss/tok 2.8818 (3.3146)	Learning Rate [0.00015625]
2: TRAIN [1][410/6832]	Time 0.067 (0.104)	Data 0.00091 (0.00092)	Tok/s 51366 (59604)	Loss/tok 3.0766 (3.3153)	Learning Rate [0.00015625]
3: TRAIN [1][410/6832]	Time 0.067 (0.104)	Data 0.00094 (0.00099)	Tok/s 53219 (60076)	Loss/tok 3.0161 (3.3097)	Learning Rate [0.00015625]
0: TRAIN [1][410/6832]	Time 0.067 (0.104)	Data 0.00096 (0.00096)	Tok/s 51347 (58899)	Loss/tok 2.9496 (3.3134)	Learning Rate [0.00015625]
1: TRAIN [1][410/6832]	Time 0.067 (0.104)	Data 0.00099 (0.00095)	Tok/s 51302 (59289)	Loss/tok 2.9971 (3.3112)	Learning Rate [0.00015625]
2: TRAIN [1][420/6832]	Time 0.117 (0.104)	Data 0.00096 (0.00092)	Tok/s 62095 (59529)	Loss/tok 3.3679 (3.3157)	Learning Rate [0.00015625]
3: TRAIN [1][420/6832]	Time 0.117 (0.104)	Data 0.00105 (0.00099)	Tok/s 62111 (59999)	Loss/tok 3.2217 (3.3102)	Learning Rate [0.00015625]
0: TRAIN [1][420/6832]	Time 0.118 (0.104)	Data 0.00088 (0.00095)	Tok/s 61078 (58821)	Loss/tok 3.1499 (3.3135)	Learning Rate [0.00015625]
1: TRAIN [1][420/6832]	Time 0.118 (0.104)	Data 0.00098 (0.00095)	Tok/s 62045 (59213)	Loss/tok 3.3155 (3.3107)	Learning Rate [0.00015625]
2: TRAIN [1][430/6832]	Time 0.127 (0.104)	Data 0.00088 (0.00092)	Tok/s 63714 (59492)	Loss/tok 3.4881 (3.3144)	Learning Rate [0.00015625]
1: TRAIN [1][430/6832]	Time 0.127 (0.104)	Data 0.00098 (0.00095)	Tok/s 63721 (59180)	Loss/tok 3.4159 (3.3082)	Learning Rate [0.00015625]
0: TRAIN [1][430/6832]	Time 0.127 (0.104)	Data 0.00092 (0.00095)	Tok/s 63729 (58795)	Loss/tok 3.4447 (3.3119)	Learning Rate [0.00015625]
3: TRAIN [1][430/6832]	Time 0.127 (0.104)	Data 0.00086 (0.00098)	Tok/s 63718 (59965)	Loss/tok 3.4403 (3.3083)	Learning Rate [0.00015625]
2: TRAIN [1][440/6832]	Time 0.110 (0.104)	Data 0.00085 (0.00092)	Tok/s 59517 (59444)	Loss/tok 3.4219 (3.3119)	Learning Rate [0.00015625]
3: TRAIN [1][440/6832]	Time 0.110 (0.104)	Data 0.00086 (0.00098)	Tok/s 59545 (59915)	Loss/tok 3.4039 (3.3071)	Learning Rate [0.00015625]
1: TRAIN [1][440/6832]	Time 0.110 (0.104)	Data 0.00096 (0.00095)	Tok/s 58376 (59126)	Loss/tok 3.2475 (3.3058)	Learning Rate [0.00015625]
0: TRAIN [1][440/6832]	Time 0.110 (0.104)	Data 0.00091 (0.00095)	Tok/s 58390 (58744)	Loss/tok 3.3463 (3.3101)	Learning Rate [0.00015625]
2: TRAIN [1][450/6832]	Time 0.113 (0.103)	Data 0.00096 (0.00092)	Tok/s 50990 (59392)	Loss/tok 3.2897 (3.3113)	Learning Rate [0.00015625]
3: TRAIN [1][450/6832]	Time 0.113 (0.103)	Data 0.00104 (0.00098)	Tok/s 51417 (59868)	Loss/tok 3.2877 (3.3059)	Learning Rate [0.00015625]
1: TRAIN [1][450/6832]	Time 0.113 (0.103)	Data 0.00102 (0.00095)	Tok/s 50987 (59065)	Loss/tok 3.2043 (3.3049)	Learning Rate [0.00015625]
0: TRAIN [1][450/6832]	Time 0.113 (0.103)	Data 0.00099 (0.00095)	Tok/s 50986 (58661)	Loss/tok 3.2528 (3.3094)	Learning Rate [0.00015625]
2: TRAIN [1][460/6832]	Time 0.124 (0.103)	Data 0.00086 (0.00092)	Tok/s 60901 (59270)	Loss/tok 3.7269 (3.3107)	Learning Rate [0.00015625]
1: TRAIN [1][460/6832]	Time 0.124 (0.103)	Data 0.00094 (0.00095)	Tok/s 60908 (58946)	Loss/tok 3.6161 (3.3049)	Learning Rate [0.00015625]
3: TRAIN [1][460/6832]	Time 0.124 (0.103)	Data 0.00098 (0.00098)	Tok/s 60901 (59741)	Loss/tok 3.4287 (3.3050)	Learning Rate [0.00015625]
0: TRAIN [1][460/6832]	Time 0.124 (0.103)	Data 0.00091 (0.00095)	Tok/s 60760 (58542)	Loss/tok 3.2693 (3.3080)	Learning Rate [0.00015625]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][470/6832]	Time 0.131 (0.104)	Data 0.00095 (0.00092)	Tok/s 84426 (59370)	Loss/tok 3.3368 (3.3118)	Learning Rate [0.00015625]
3: TRAIN [1][470/6832]	Time 0.131 (0.104)	Data 0.00103 (0.00098)	Tok/s 84932 (59840)	Loss/tok 3.1615 (3.3056)	Learning Rate [0.00015625]
0: TRAIN [1][470/6832]	Time 0.131 (0.104)	Data 0.00092 (0.00095)	Tok/s 83236 (58653)	Loss/tok 3.3301 (3.3097)	Learning Rate [0.00015625]
1: TRAIN [1][470/6832]	Time 0.131 (0.104)	Data 0.00096 (0.00095)	Tok/s 83892 (59050)	Loss/tok 3.2706 (3.3070)	Learning Rate [0.00015625]
2: TRAIN [1][480/6832]	Time 0.119 (0.104)	Data 0.00085 (0.00092)	Tok/s 52758 (59350)	Loss/tok 3.2282 (3.3117)	Learning Rate [0.00015625]
3: TRAIN [1][480/6832]	Time 0.119 (0.104)	Data 0.00092 (0.00098)	Tok/s 52746 (59822)	Loss/tok 3.4781 (3.3078)	Learning Rate [0.00015625]
1: TRAIN [1][480/6832]	Time 0.119 (0.104)	Data 0.00093 (0.00095)	Tok/s 52741 (59030)	Loss/tok 3.5095 (3.3078)	Learning Rate [0.00015625]
0: TRAIN [1][480/6832]	Time 0.119 (0.104)	Data 0.00090 (0.00095)	Tok/s 52735 (58638)	Loss/tok 3.3561 (3.3098)	Learning Rate [0.00015625]
2: TRAIN [1][490/6832]	Time 0.086 (0.104)	Data 0.00085 (0.00092)	Tok/s 53836 (59296)	Loss/tok 3.2441 (3.3124)	Learning Rate [0.00015625]
0: TRAIN [1][490/6832]	Time 0.086 (0.104)	Data 0.00090 (0.00095)	Tok/s 53842 (58548)	Loss/tok 3.2697 (3.3095)	Learning Rate [0.00015625]
1: TRAIN [1][490/6832]	Time 0.086 (0.104)	Data 0.00097 (0.00095)	Tok/s 53821 (58962)	Loss/tok 3.0429 (3.3065)	Learning Rate [0.00015625]
3: TRAIN [1][490/6832]	Time 0.086 (0.104)	Data 0.00093 (0.00098)	Tok/s 53839 (59768)	Loss/tok 3.0956 (3.3068)	Learning Rate [0.00015625]
2: TRAIN [1][500/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00092)	Tok/s 80752 (59383)	Loss/tok 3.3133 (3.3117)	Learning Rate [0.00015625]
3: TRAIN [1][500/6832]	Time 0.132 (0.104)	Data 0.00091 (0.00098)	Tok/s 80748 (59854)	Loss/tok 3.3863 (3.3058)	Learning Rate [0.00015625]
0: TRAIN [1][500/6832]	Time 0.132 (0.104)	Data 0.00087 (0.00095)	Tok/s 79767 (58633)	Loss/tok 3.3094 (3.3082)	Learning Rate [0.00015625]
1: TRAIN [1][500/6832]	Time 0.132 (0.104)	Data 0.00096 (0.00095)	Tok/s 79774 (59046)	Loss/tok 3.2645 (3.3051)	Learning Rate [0.00015625]
2: TRAIN [1][510/6832]	Time 0.128 (0.104)	Data 0.00088 (0.00092)	Tok/s 74758 (59387)	Loss/tok 3.4318 (3.3111)	Learning Rate [0.00015625]
3: TRAIN [1][510/6832]	Time 0.128 (0.104)	Data 0.00093 (0.00098)	Tok/s 74747 (59857)	Loss/tok 3.4013 (3.3050)	Learning Rate [0.00015625]
0: TRAIN [1][510/6832]	Time 0.129 (0.104)	Data 0.00086 (0.00095)	Tok/s 73708 (58644)	Loss/tok 3.3679 (3.3091)	Learning Rate [0.00015625]
1: TRAIN [1][510/6832]	Time 0.129 (0.104)	Data 0.00096 (0.00095)	Tok/s 74687 (59057)	Loss/tok 3.3535 (3.3059)	Learning Rate [0.00015625]
2: TRAIN [1][520/6832]	Time 0.124 (0.104)	Data 0.00098 (0.00092)	Tok/s 59934 (59504)	Loss/tok 3.1811 (3.3121)	Learning Rate [0.00015625]
3: TRAIN [1][520/6832]	Time 0.124 (0.104)	Data 0.00103 (0.00098)	Tok/s 59958 (59970)	Loss/tok 3.3780 (3.3074)	Learning Rate [0.00015625]
0: TRAIN [1][520/6832]	Time 0.124 (0.104)	Data 0.00085 (0.00095)	Tok/s 59912 (58766)	Loss/tok 3.5063 (3.3115)	Learning Rate [0.00015625]
1: TRAIN [1][520/6832]	Time 0.124 (0.104)	Data 0.00105 (0.00096)	Tok/s 59918 (59177)	Loss/tok 3.5103 (3.3079)	Learning Rate [0.00015625]
2: TRAIN [1][530/6832]	Time 0.122 (0.104)	Data 0.00085 (0.00092)	Tok/s 62080 (59575)	Loss/tok 3.5801 (3.3128)	Learning Rate [0.00015625]
3: TRAIN [1][530/6832]	Time 0.122 (0.104)	Data 0.00093 (0.00098)	Tok/s 62073 (60039)	Loss/tok 3.4943 (3.3070)	Learning Rate [0.00015625]
1: TRAIN [1][530/6832]	Time 0.122 (0.104)	Data 0.00100 (0.00096)	Tok/s 62062 (59248)	Loss/tok 3.2309 (3.3064)	Learning Rate [0.00015625]
0: TRAIN [1][530/6832]	Time 0.122 (0.104)	Data 0.00090 (0.00095)	Tok/s 61796 (58840)	Loss/tok 3.3043 (3.3114)	Learning Rate [0.00015625]
2: TRAIN [1][540/6832]	Time 0.131 (0.104)	Data 0.00085 (0.00092)	Tok/s 73373 (59535)	Loss/tok 3.3752 (3.3126)	Learning Rate [0.00015625]
3: TRAIN [1][540/6832]	Time 0.131 (0.104)	Data 0.00088 (0.00098)	Tok/s 73766 (60003)	Loss/tok 3.3696 (3.3057)	Learning Rate [0.00015625]
0: TRAIN [1][540/6832]	Time 0.131 (0.104)	Data 0.00092 (0.00095)	Tok/s 72766 (58771)	Loss/tok 3.3012 (3.3104)	Learning Rate [0.00015625]
1: TRAIN [1][540/6832]	Time 0.131 (0.104)	Data 0.00095 (0.00096)	Tok/s 73328 (59198)	Loss/tok 3.2926 (3.3062)	Learning Rate [0.00015625]
1: TRAIN [1][550/6832]	Time 0.133 (0.104)	Data 0.00094 (0.00096)	Tok/s 91137 (59235)	Loss/tok 3.2303 (3.3052)	Learning Rate [0.00015625]
0: TRAIN [1][550/6832]	Time 0.133 (0.104)	Data 0.00099 (0.00095)	Tok/s 90145 (58808)	Loss/tok 3.2633 (3.3098)	Learning Rate [0.00015625]
2: TRAIN [1][550/6832]	Time 0.133 (0.104)	Data 0.00088 (0.00092)	Tok/s 92190 (59577)	Loss/tok 3.2151 (3.3115)	Learning Rate [0.00015625]
3: TRAIN [1][550/6832]	Time 0.133 (0.104)	Data 0.00088 (0.00098)	Tok/s 94191 (60044)	Loss/tok 3.1961 (3.3050)	Learning Rate [0.00015625]
2: TRAIN [1][560/6832]	Time 0.074 (0.104)	Data 0.00086 (0.00092)	Tok/s 52077 (59552)	Loss/tok 3.0766 (3.3111)	Learning Rate [0.00015625]
3: TRAIN [1][560/6832]	Time 0.074 (0.104)	Data 0.00088 (0.00098)	Tok/s 52074 (60018)	Loss/tok 3.0591 (3.3044)	Learning Rate [0.00015625]
1: TRAIN [1][560/6832]	Time 0.074 (0.104)	Data 0.00097 (0.00096)	Tok/s 52117 (59210)	Loss/tok 3.0747 (3.3050)	Learning Rate [0.00015625]
0: TRAIN [1][560/6832]	Time 0.074 (0.104)	Data 0.00098 (0.00095)	Tok/s 51042 (58784)	Loss/tok 3.0316 (3.3093)	Learning Rate [0.00015625]
2: TRAIN [1][570/6832]	Time 0.098 (0.104)	Data 0.00086 (0.00092)	Tok/s 52175 (59512)	Loss/tok 3.2398 (3.3102)	Learning Rate [0.00015625]
3: TRAIN [1][570/6832]	Time 0.098 (0.104)	Data 0.00088 (0.00098)	Tok/s 52162 (59974)	Loss/tok 3.1428 (3.3042)	Learning Rate [0.00015625]
1: TRAIN [1][570/6832]	Time 0.098 (0.104)	Data 0.00093 (0.00096)	Tok/s 52102 (59168)	Loss/tok 3.2871 (3.3033)	Learning Rate [0.00015625]
0: TRAIN [1][570/6832]	Time 0.098 (0.104)	Data 0.00100 (0.00095)	Tok/s 50865 (58739)	Loss/tok 3.2042 (3.3082)	Learning Rate [0.00015625]
2: TRAIN [1][580/6832]	Time 0.114 (0.104)	Data 0.00085 (0.00092)	Tok/s 56308 (59512)	Loss/tok 3.4288 (3.3092)	Learning Rate [0.00015625]
3: TRAIN [1][580/6832]	Time 0.114 (0.104)	Data 0.00087 (0.00098)	Tok/s 56288 (59969)	Loss/tok 3.4641 (3.3036)	Learning Rate [0.00015625]
0: TRAIN [1][580/6832]	Time 0.114 (0.104)	Data 0.00097 (0.00095)	Tok/s 56276 (58739)	Loss/tok 3.2609 (3.3077)	Learning Rate [0.00015625]
1: TRAIN [1][580/6832]	Time 0.114 (0.104)	Data 0.00092 (0.00096)	Tok/s 56295 (59169)	Loss/tok 3.3716 (3.3029)	Learning Rate [0.00015625]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [1][590/6832]	Time 0.132 (0.104)	Data 0.00096 (0.00096)	Tok/s 85395 (59249)	Loss/tok 3.1969 (3.3036)	Learning Rate [0.00015625]
2: TRAIN [1][590/6832]	Time 0.132 (0.104)	Data 0.00095 (0.00092)	Tok/s 86371 (59598)	Loss/tok 3.2318 (3.3096)	Learning Rate [0.00015625]
3: TRAIN [1][590/6832]	Time 0.132 (0.104)	Data 0.00105 (0.00098)	Tok/s 86852 (60054)	Loss/tok 3.3545 (3.3045)	Learning Rate [0.00015625]
0: TRAIN [1][590/6832]	Time 0.132 (0.104)	Data 0.00093 (0.00095)	Tok/s 85032 (58818)	Loss/tok 3.2209 (3.3085)	Learning Rate [0.00015625]
2: TRAIN [1][600/6832]	Time 0.048 (0.104)	Data 0.00103 (0.00092)	Tok/s 44982 (59502)	Loss/tok 2.3653 (3.3087)	Learning Rate [0.00015625]
1: TRAIN [1][600/6832]	Time 0.048 (0.104)	Data 0.00135 (0.00096)	Tok/s 43305 (59142)	Loss/tok 2.4604 (3.3031)	Learning Rate [0.00015625]
3: TRAIN [1][600/6832]	Time 0.048 (0.104)	Data 0.00110 (0.00098)	Tok/s 46957 (59968)	Loss/tok 2.5658 (3.3032)	Learning Rate [0.00015625]
0: TRAIN [1][600/6832]	Time 0.048 (0.104)	Data 0.00137 (0.00095)	Tok/s 40957 (58695)	Loss/tok 2.3030 (3.3076)	Learning Rate [0.00015625]
1: TRAIN [1][610/6832]	Time 0.120 (0.104)	Data 0.00096 (0.00096)	Tok/s 54194 (59187)	Loss/tok 3.4506 (3.3023)	Learning Rate [0.00015625]
2: TRAIN [1][610/6832]	Time 0.120 (0.104)	Data 0.00101 (0.00092)	Tok/s 54234 (59547)	Loss/tok 3.2573 (3.3074)	Learning Rate [0.00015625]
3: TRAIN [1][610/6832]	Time 0.120 (0.104)	Data 0.00106 (0.00098)	Tok/s 55297 (60020)	Loss/tok 3.2191 (3.3020)	Learning Rate [0.00015625]
0: TRAIN [1][610/6832]	Time 0.120 (0.104)	Data 0.00097 (0.00095)	Tok/s 54194 (58737)	Loss/tok 3.3526 (3.3072)	Learning Rate [0.00015625]
2: TRAIN [1][620/6832]	Time 0.131 (0.104)	Data 0.00089 (0.00092)	Tok/s 68484 (59665)	Loss/tok 3.5335 (3.3078)	Learning Rate [0.00015625]
1: TRAIN [1][620/6832]	Time 0.131 (0.104)	Data 0.00096 (0.00096)	Tok/s 68521 (59305)	Loss/tok 3.4359 (3.3030)	Learning Rate [0.00015625]
0: TRAIN [1][620/6832]	Time 0.131 (0.104)	Data 0.00099 (0.00095)	Tok/s 68569 (58858)	Loss/tok 3.4278 (3.3078)	Learning Rate [0.00015625]
3: TRAIN [1][620/6832]	Time 0.131 (0.104)	Data 0.00089 (0.00098)	Tok/s 69452 (60138)	Loss/tok 3.4192 (3.3034)	Learning Rate [0.00015625]
2: TRAIN [1][630/6832]	Time 0.131 (0.104)	Data 0.00088 (0.00092)	Tok/s 76469 (59633)	Loss/tok 3.4128 (3.3082)	Learning Rate [0.00015625]
1: TRAIN [1][630/6832]	Time 0.131 (0.104)	Data 0.00097 (0.00096)	Tok/s 76431 (59278)	Loss/tok 3.4098 (3.3031)	Learning Rate [0.00015625]
3: TRAIN [1][630/6832]	Time 0.131 (0.104)	Data 0.00091 (0.00098)	Tok/s 76640 (60100)	Loss/tok 3.4086 (3.3035)	Learning Rate [0.00015625]
0: TRAIN [1][630/6832]	Time 0.131 (0.104)	Data 0.00104 (0.00095)	Tok/s 75476 (58837)	Loss/tok 3.3592 (3.3087)	Learning Rate [0.00015625]
1: TRAIN [1][640/6832]	Time 0.121 (0.104)	Data 0.00091 (0.00096)	Tok/s 54159 (59316)	Loss/tok 3.3037 (3.3034)	Learning Rate [0.00015625]
0: TRAIN [1][640/6832]	Time 0.121 (0.104)	Data 0.00098 (0.00095)	Tok/s 54173 (58874)	Loss/tok 3.2518 (3.3083)	Learning Rate [0.00015625]
2: TRAIN [1][640/6832]	Time 0.121 (0.104)	Data 0.00092 (0.00092)	Tok/s 54157 (59668)	Loss/tok 3.1021 (3.3088)	Learning Rate [0.00015625]
3: TRAIN [1][640/6832]	Time 0.121 (0.104)	Data 0.00093 (0.00098)	Tok/s 54932 (60134)	Loss/tok 3.3557 (3.3042)	Learning Rate [0.00015625]
2: TRAIN [1][650/6832]	Time 0.115 (0.104)	Data 0.00099 (0.00092)	Tok/s 55616 (59641)	Loss/tok 3.2970 (3.3082)	Learning Rate [0.00015625]
1: TRAIN [1][650/6832]	Time 0.115 (0.104)	Data 0.00101 (0.00096)	Tok/s 55527 (59284)	Loss/tok 3.3517 (3.3030)	Learning Rate [0.00015625]
3: TRAIN [1][650/6832]	Time 0.115 (0.104)	Data 0.00106 (0.00098)	Tok/s 55613 (60107)	Loss/tok 3.1924 (3.3037)	Learning Rate [0.00015625]
0: TRAIN [1][650/6832]	Time 0.115 (0.104)	Data 0.00103 (0.00095)	Tok/s 54552 (58840)	Loss/tok 3.3930 (3.3081)	Learning Rate [0.00015625]
2: TRAIN [1][660/6832]	Time 0.115 (0.104)	Data 0.00094 (0.00092)	Tok/s 54518 (59628)	Loss/tok 3.3441 (3.3078)	Learning Rate [0.00015625]
1: TRAIN [1][660/6832]	Time 0.115 (0.104)	Data 0.00095 (0.00096)	Tok/s 53633 (59270)	Loss/tok 3.3502 (3.3022)	Learning Rate [0.00015625]
3: TRAIN [1][660/6832]	Time 0.115 (0.104)	Data 0.00091 (0.00098)	Tok/s 54720 (60094)	Loss/tok 3.3364 (3.3032)	Learning Rate [0.00015625]
0: TRAIN [1][660/6832]	Time 0.115 (0.104)	Data 0.00099 (0.00095)	Tok/s 53623 (58827)	Loss/tok 3.3286 (3.3073)	Learning Rate [0.00015625]
2: TRAIN [1][670/6832]	Time 0.103 (0.104)	Data 0.00087 (0.00092)	Tok/s 53352 (59672)	Loss/tok 3.3073 (3.3078)	Learning Rate [0.00015625]
3: TRAIN [1][670/6832]	Time 0.103 (0.104)	Data 0.00092 (0.00098)	Tok/s 53371 (60138)	Loss/tok 3.1680 (3.3039)	Learning Rate [0.00015625]
1: TRAIN [1][670/6832]	Time 0.103 (0.104)	Data 0.00092 (0.00096)	Tok/s 53291 (59316)	Loss/tok 3.2453 (3.3039)	Learning Rate [0.00015625]
0: TRAIN [1][670/6832]	Time 0.103 (0.104)	Data 0.00097 (0.00096)	Tok/s 53317 (58879)	Loss/tok 3.2735 (3.3083)	Learning Rate [0.00015625]
2: TRAIN [1][680/6832]	Time 0.129 (0.104)	Data 0.00086 (0.00092)	Tok/s 62308 (59651)	Loss/tok 3.3714 (3.3068)	Learning Rate [0.00015625]
1: TRAIN [1][680/6832]	Time 0.129 (0.104)	Data 0.00095 (0.00096)	Tok/s 61566 (59291)	Loss/tok 3.3618 (3.3037)	Learning Rate [0.00015625]
0: TRAIN [1][680/6832]	Time 0.129 (0.104)	Data 0.00094 (0.00096)	Tok/s 61596 (58858)	Loss/tok 3.4160 (3.3078)	Learning Rate [0.00015625]
3: TRAIN [1][680/6832]	Time 0.129 (0.104)	Data 0.00092 (0.00098)	Tok/s 62574 (60113)	Loss/tok 3.2549 (3.3039)	Learning Rate [0.00015625]
2: TRAIN [1][690/6832]	Time 0.132 (0.104)	Data 0.00085 (0.00092)	Tok/s 88671 (59788)	Loss/tok 3.2898 (3.3055)	Learning Rate [0.00015625]
1: TRAIN [1][690/6832]	Time 0.132 (0.104)	Data 0.00095 (0.00095)	Tok/s 88108 (59425)	Loss/tok 3.3486 (3.3034)	Learning Rate [0.00015625]
0: TRAIN [1][690/6832]	Time 0.132 (0.104)	Data 0.00092 (0.00095)	Tok/s 87330 (58994)	Loss/tok 3.1313 (3.3070)	Learning Rate [0.00015625]
3: TRAIN [1][690/6832]	Time 0.132 (0.104)	Data 0.00094 (0.00098)	Tok/s 89389 (60252)	Loss/tok 3.2419 (3.3031)	Learning Rate [0.00015625]
2: TRAIN [1][700/6832]	Time 0.101 (0.104)	Data 0.00089 (0.00092)	Tok/s 53076 (59821)	Loss/tok 3.2619 (3.3046)	Learning Rate [0.00015625]
3: TRAIN [1][700/6832]	Time 0.101 (0.104)	Data 0.00092 (0.00098)	Tok/s 53138 (60287)	Loss/tok 3.1202 (3.3026)	Learning Rate [0.00015625]
1: TRAIN [1][700/6832]	Time 0.101 (0.104)	Data 0.00098 (0.00096)	Tok/s 53101 (59455)	Loss/tok 3.0584 (3.3014)	Learning Rate [0.00015625]
0: TRAIN [1][700/6832]	Time 0.101 (0.104)	Data 0.00092 (0.00096)	Tok/s 53120 (59022)	Loss/tok 3.2297 (3.3057)	Learning Rate [0.00015625]
2: TRAIN [1][710/6832]	Time 0.059 (0.104)	Data 0.00083 (0.00092)	Tok/s 52615 (59862)	Loss/tok 2.7317 (3.3038)	Learning Rate [0.00015625]
3: TRAIN [1][710/6832]	Time 0.059 (0.104)	Data 0.00090 (0.00098)	Tok/s 54416 (60332)	Loss/tok 2.8301 (3.3016)	Learning Rate [0.00015625]
1: TRAIN [1][710/6832]	Time 0.059 (0.104)	Data 0.00093 (0.00095)	Tok/s 52193 (59490)	Loss/tok 2.9725 (3.3011)	Learning Rate [0.00015625]
0: TRAIN [1][710/6832]	Time 0.059 (0.104)	Data 0.00092 (0.00095)	Tok/s 52188 (59057)	Loss/tok 2.8511 (3.3046)	Learning Rate [0.00015625]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][720/6832]	Time 0.131 (0.104)	Data 0.00108 (0.00092)	Tok/s 71469 (59861)	Loss/tok 3.4072 (3.3047)	Learning Rate [7.8125e-05]
1: TRAIN [1][720/6832]	Time 0.131 (0.104)	Data 0.00106 (0.00095)	Tok/s 70503 (59493)	Loss/tok 3.6006 (3.3025)	Learning Rate [7.8125e-05]
0: TRAIN [1][720/6832]	Time 0.131 (0.104)	Data 0.00110 (0.00095)	Tok/s 70532 (59060)	Loss/tok 3.5443 (3.3056)	Learning Rate [7.8125e-05]
3: TRAIN [1][720/6832]	Time 0.131 (0.104)	Data 0.00111 (0.00098)	Tok/s 71493 (60325)	Loss/tok 3.5432 (3.3029)	Learning Rate [7.8125e-05]
1: TRAIN [1][730/6832]	Time 0.117 (0.104)	Data 0.00095 (0.00095)	Tok/s 53496 (59437)	Loss/tok 3.3428 (3.3028)	Learning Rate [7.8125e-05]
2: TRAIN [1][730/6832]	Time 0.117 (0.104)	Data 0.00086 (0.00092)	Tok/s 53744 (59803)	Loss/tok 3.3516 (3.3044)	Learning Rate [7.8125e-05]
0: TRAIN [1][730/6832]	Time 0.117 (0.104)	Data 0.00106 (0.00095)	Tok/s 52699 (59002)	Loss/tok 3.3128 (3.3058)	Learning Rate [7.8125e-05]
3: TRAIN [1][730/6832]	Time 0.117 (0.104)	Data 0.00089 (0.00098)	Tok/s 53745 (60264)	Loss/tok 3.3959 (3.3034)	Learning Rate [7.8125e-05]
2: TRAIN [1][740/6832]	Time 0.101 (0.105)	Data 0.00088 (0.00092)	Tok/s 53565 (59783)	Loss/tok 3.3427 (3.3055)	Learning Rate [7.8125e-05]
1: TRAIN [1][740/6832]	Time 0.101 (0.105)	Data 0.00099 (0.00095)	Tok/s 53387 (59418)	Loss/tok 3.3924 (3.3035)	Learning Rate [7.8125e-05]
0: TRAIN [1][740/6832]	Time 0.101 (0.105)	Data 0.00100 (0.00095)	Tok/s 53405 (58986)	Loss/tok 3.3681 (3.3067)	Learning Rate [7.8125e-05]
3: TRAIN [1][740/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00098)	Tok/s 54718 (60246)	Loss/tok 3.3077 (3.3049)	Learning Rate [7.8125e-05]
2: TRAIN [1][750/6832]	Time 0.041 (0.105)	Data 0.00089 (0.00092)	Tok/s 40263 (59715)	Loss/tok 2.0141 (3.3051)	Learning Rate [7.8125e-05]
1: TRAIN [1][750/6832]	Time 0.041 (0.105)	Data 0.00094 (0.00095)	Tok/s 34794 (59346)	Loss/tok 2.2209 (3.3028)	Learning Rate [7.8125e-05]
3: TRAIN [1][750/6832]	Time 0.041 (0.105)	Data 0.00096 (0.00098)	Tok/s 43971 (60180)	Loss/tok 2.3284 (3.3053)	Learning Rate [7.8125e-05]
0: TRAIN [1][750/6832]	Time 0.041 (0.105)	Data 0.00094 (0.00095)	Tok/s 21973 (58901)	Loss/tok 1.7817 (3.3065)	Learning Rate [7.8125e-05]
0: TRAIN [1][760/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00095)	Tok/s 51974 (58859)	Loss/tok 3.1347 (3.3058)	Learning Rate [7.8125e-05]
3: TRAIN [1][760/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00098)	Tok/s 53036 (60131)	Loss/tok 3.2475 (3.3061)	Learning Rate [7.8125e-05]
1: TRAIN [1][760/6832]	Time 0.118 (0.105)	Data 0.00131 (0.00095)	Tok/s 52376 (59302)	Loss/tok 3.3186 (3.3032)	Learning Rate [7.8125e-05]
2: TRAIN [1][760/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00092)	Tok/s 53039 (59668)	Loss/tok 3.1190 (3.3050)	Learning Rate [7.8125e-05]
2: TRAIN [1][770/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00092)	Tok/s 53089 (59637)	Loss/tok 3.1633 (3.3055)	Learning Rate [7.8125e-05]
1: TRAIN [1][770/6832]	Time 0.073 (0.105)	Data 0.00094 (0.00095)	Tok/s 52311 (59274)	Loss/tok 3.0013 (3.3036)	Learning Rate [7.8125e-05]
0: TRAIN [1][770/6832]	Time 0.073 (0.105)	Data 0.00101 (0.00095)	Tok/s 52281 (58836)	Loss/tok 3.1083 (3.3054)	Learning Rate [7.8125e-05]
3: TRAIN [1][770/6832]	Time 0.073 (0.105)	Data 0.00097 (0.00098)	Tok/s 54102 (60101)	Loss/tok 3.0595 (3.3062)	Learning Rate [7.8125e-05]
2: TRAIN [1][780/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00092)	Tok/s 53727 (59641)	Loss/tok 3.3314 (3.3049)	Learning Rate [7.8125e-05]
1: TRAIN [1][780/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00095)	Tok/s 53727 (59277)	Loss/tok 3.3260 (3.3027)	Learning Rate [7.8125e-05]
3: TRAIN [1][780/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00098)	Tok/s 54347 (60104)	Loss/tok 3.3555 (3.3060)	Learning Rate [7.8125e-05]
0: TRAIN [1][780/6832]	Time 0.121 (0.105)	Data 0.00096 (0.00095)	Tok/s 53780 (58842)	Loss/tok 3.5476 (3.3048)	Learning Rate [7.8125e-05]
1: TRAIN [1][790/6832]	Time 0.078 (0.104)	Data 0.00097 (0.00095)	Tok/s 53907 (59241)	Loss/tok 3.0820 (3.3016)	Learning Rate [7.8125e-05]
0: TRAIN [1][790/6832]	Time 0.078 (0.104)	Data 0.00099 (0.00095)	Tok/s 53060 (58805)	Loss/tok 3.1756 (3.3031)	Learning Rate [7.8125e-05]
2: TRAIN [1][790/6832]	Time 0.078 (0.104)	Data 0.00088 (0.00092)	Tok/s 53889 (59606)	Loss/tok 3.1198 (3.3040)	Learning Rate [7.8125e-05]
3: TRAIN [1][790/6832]	Time 0.078 (0.104)	Data 0.00095 (0.00098)	Tok/s 53921 (60067)	Loss/tok 3.1256 (3.3044)	Learning Rate [7.8125e-05]
2: TRAIN [1][800/6832]	Time 0.132 (0.104)	Data 0.00085 (0.00092)	Tok/s 88885 (59645)	Loss/tok 3.2801 (3.3040)	Learning Rate [7.8125e-05]
1: TRAIN [1][800/6832]	Time 0.132 (0.104)	Data 0.00094 (0.00095)	Tok/s 88162 (59281)	Loss/tok 3.1920 (3.3019)	Learning Rate [7.8125e-05]
0: TRAIN [1][800/6832]	Time 0.132 (0.104)	Data 0.00092 (0.00095)	Tok/s 87510 (58847)	Loss/tok 3.3144 (3.3028)	Learning Rate [7.8125e-05]
3: TRAIN [1][800/6832]	Time 0.132 (0.104)	Data 0.00091 (0.00098)	Tok/s 89667 (60106)	Loss/tok 3.1981 (3.3041)	Learning Rate [7.8125e-05]
1: TRAIN [1][810/6832]	Time 0.070 (0.104)	Data 0.00095 (0.00095)	Tok/s 50941 (59218)	Loss/tok 3.0801 (3.3010)	Learning Rate [7.8125e-05]
2: TRAIN [1][810/6832]	Time 0.070 (0.104)	Data 0.00084 (0.00092)	Tok/s 50881 (59579)	Loss/tok 2.9426 (3.3032)	Learning Rate [7.8125e-05]
0: TRAIN [1][810/6832]	Time 0.070 (0.104)	Data 0.00092 (0.00095)	Tok/s 50908 (58785)	Loss/tok 2.9886 (3.3027)	Learning Rate [7.8125e-05]
3: TRAIN [1][810/6832]	Time 0.070 (0.104)	Data 0.00094 (0.00098)	Tok/s 50928 (60037)	Loss/tok 2.9039 (3.3033)	Learning Rate [7.8125e-05]
1: TRAIN [1][820/6832]	Time 0.125 (0.104)	Data 0.00090 (0.00095)	Tok/s 60339 (59150)	Loss/tok 3.4269 (3.3014)	Learning Rate [7.8125e-05]
2: TRAIN [1][820/6832]	Time 0.125 (0.104)	Data 0.00085 (0.00092)	Tok/s 60525 (59524)	Loss/tok 3.4902 (3.3025)	Learning Rate [7.8125e-05]
0: TRAIN [1][820/6832]	Time 0.125 (0.104)	Data 0.00091 (0.00095)	Tok/s 59518 (58694)	Loss/tok 3.3238 (3.3033)	Learning Rate [7.8125e-05]
3: TRAIN [1][820/6832]	Time 0.125 (0.104)	Data 0.00090 (0.00098)	Tok/s 60539 (59986)	Loss/tok 3.4390 (3.3033)	Learning Rate [7.8125e-05]
2: TRAIN [1][830/6832]	Time 0.130 (0.104)	Data 0.00093 (0.00092)	Tok/s 59465 (59569)	Loss/tok 3.3825 (3.3023)	Learning Rate [7.8125e-05]
1: TRAIN [1][830/6832]	Time 0.131 (0.104)	Data 0.00097 (0.00095)	Tok/s 58836 (59196)	Loss/tok 3.5357 (3.3008)	Learning Rate [7.8125e-05]
0: TRAIN [1][830/6832]	Time 0.130 (0.104)	Data 0.00100 (0.00095)	Tok/s 58860 (58739)	Loss/tok 3.3439 (3.3031)	Learning Rate [7.8125e-05]
3: TRAIN [1][830/6832]	Time 0.130 (0.104)	Data 0.00100 (0.00098)	Tok/s 59842 (60032)	Loss/tok 3.3200 (3.3024)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [1][840/6832]	Time 0.087 (0.104)	Data 0.00090 (0.00092)	Tok/s 53133 (59601)	Loss/tok 3.1313 (3.3018)	Learning Rate [7.8125e-05]
1: TRAIN [1][840/6832]	Time 0.087 (0.104)	Data 0.00092 (0.00095)	Tok/s 52602 (59225)	Loss/tok 3.2120 (3.3004)	Learning Rate [7.8125e-05]
0: TRAIN [1][840/6832]	Time 0.087 (0.104)	Data 0.00092 (0.00095)	Tok/s 51686 (58770)	Loss/tok 3.2139 (3.3028)	Learning Rate [7.8125e-05]
3: TRAIN [1][840/6832]	Time 0.087 (0.104)	Data 0.00090 (0.00098)	Tok/s 53187 (60068)	Loss/tok 3.1470 (3.3015)	Learning Rate [7.8125e-05]
2: TRAIN [1][850/6832]	Time 0.132 (0.104)	Data 0.00093 (0.00092)	Tok/s 83914 (59627)	Loss/tok 3.4042 (3.3024)	Learning Rate [7.8125e-05]
1: TRAIN [1][850/6832]	Time 0.132 (0.104)	Data 0.00117 (0.00095)	Tok/s 83352 (59245)	Loss/tok 3.3559 (3.3009)	Learning Rate [7.8125e-05]
0: TRAIN [1][850/6832]	Time 0.132 (0.104)	Data 0.00115 (0.00095)	Tok/s 83031 (58780)	Loss/tok 3.3449 (3.3024)	Learning Rate [7.8125e-05]
3: TRAIN [1][850/6832]	Time 0.132 (0.104)	Data 0.00101 (0.00098)	Tok/s 84278 (60098)	Loss/tok 3.2387 (3.3010)	Learning Rate [7.8125e-05]
2: TRAIN [1][860/6832]	Time 0.130 (0.104)	Data 0.00086 (0.00092)	Tok/s 71864 (59644)	Loss/tok 3.5082 (3.3014)	Learning Rate [7.8125e-05]
1: TRAIN [1][860/6832]	Time 0.130 (0.104)	Data 0.00099 (0.00095)	Tok/s 71042 (59260)	Loss/tok 3.3654 (3.2994)	Learning Rate [7.8125e-05]
3: TRAIN [1][860/6832]	Time 0.130 (0.104)	Data 0.00092 (0.00098)	Tok/s 71877 (60119)	Loss/tok 3.2356 (3.2990)	Learning Rate [7.8125e-05]
0: TRAIN [1][860/6832]	Time 0.130 (0.104)	Data 0.00108 (0.00095)	Tok/s 70882 (58794)	Loss/tok 3.3497 (3.3008)	Learning Rate [7.8125e-05]
2: TRAIN [1][870/6832]	Time 0.078 (0.104)	Data 0.00094 (0.00092)	Tok/s 54262 (59619)	Loss/tok 3.0353 (3.3014)	Learning Rate [7.8125e-05]
1: TRAIN [1][870/6832]	Time 0.078 (0.104)	Data 0.00095 (0.00095)	Tok/s 54260 (59235)	Loss/tok 3.2076 (3.2992)	Learning Rate [7.8125e-05]
0: TRAIN [1][870/6832]	Time 0.078 (0.104)	Data 0.00092 (0.00095)	Tok/s 53596 (58771)	Loss/tok 3.1938 (3.3002)	Learning Rate [7.8125e-05]
3: TRAIN [1][870/6832]	Time 0.078 (0.104)	Data 0.00099 (0.00098)	Tok/s 54312 (60092)	Loss/tok 3.0872 (3.2986)	Learning Rate [7.8125e-05]
2: TRAIN [1][880/6832]	Time 0.069 (0.104)	Data 0.00086 (0.00092)	Tok/s 49990 (59655)	Loss/tok 2.9831 (3.3020)	Learning Rate [7.8125e-05]
1: TRAIN [1][880/6832]	Time 0.069 (0.104)	Data 0.00092 (0.00095)	Tok/s 49964 (59272)	Loss/tok 2.8403 (3.2996)	Learning Rate [7.8125e-05]
3: TRAIN [1][880/6832]	Time 0.069 (0.104)	Data 0.00093 (0.00098)	Tok/s 50028 (60129)	Loss/tok 2.8954 (3.2986)	Learning Rate [7.8125e-05]
0: TRAIN [1][880/6832]	Time 0.069 (0.104)	Data 0.00094 (0.00095)	Tok/s 49981 (58811)	Loss/tok 2.8203 (3.3001)	Learning Rate [7.8125e-05]
2: TRAIN [1][890/6832]	Time 0.091 (0.104)	Data 0.00086 (0.00092)	Tok/s 50456 (59651)	Loss/tok 3.2086 (3.3018)	Learning Rate [7.8125e-05]
1: TRAIN [1][890/6832]	Time 0.091 (0.104)	Data 0.00097 (0.00095)	Tok/s 50457 (59272)	Loss/tok 3.2109 (3.3000)	Learning Rate [7.8125e-05]
0: TRAIN [1][890/6832]	Time 0.091 (0.104)	Data 0.00096 (0.00095)	Tok/s 50497 (58812)	Loss/tok 3.1495 (3.3002)	Learning Rate [7.8125e-05]
3: TRAIN [1][890/6832]	Time 0.091 (0.104)	Data 0.00093 (0.00098)	Tok/s 51492 (60126)	Loss/tok 3.1477 (3.2980)	Learning Rate [7.8125e-05]
2: TRAIN [1][900/6832]	Time 0.129 (0.104)	Data 0.00094 (0.00092)	Tok/s 56624 (59633)	Loss/tok 3.2626 (3.3021)	Learning Rate [7.8125e-05]
1: TRAIN [1][900/6832]	Time 0.129 (0.104)	Data 0.00099 (0.00095)	Tok/s 56590 (59257)	Loss/tok 3.3681 (3.3000)	Learning Rate [7.8125e-05]
0: TRAIN [1][900/6832]	Time 0.129 (0.104)	Data 0.00101 (0.00096)	Tok/s 55624 (58799)	Loss/tok 3.5263 (3.3012)	Learning Rate [7.8125e-05]
3: TRAIN [1][900/6832]	Time 0.129 (0.104)	Data 0.00097 (0.00098)	Tok/s 56641 (60106)	Loss/tok 3.2626 (3.2977)	Learning Rate [7.8125e-05]
2: TRAIN [1][910/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00092)	Tok/s 82000 (59706)	Loss/tok 3.3952 (3.3019)	Learning Rate [7.8125e-05]
0: TRAIN [1][910/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00096)	Tok/s 81332 (58876)	Loss/tok 3.3844 (3.3007)	Learning Rate [7.8125e-05]
1: TRAIN [1][910/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 81891 (59332)	Loss/tok 3.3909 (3.3006)	Learning Rate [7.8125e-05]
3: TRAIN [1][910/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00098)	Tok/s 82911 (60179)	Loss/tok 3.3242 (3.2976)	Learning Rate [7.8125e-05]
2: TRAIN [1][920/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00092)	Tok/s 88475 (59747)	Loss/tok 3.3483 (3.3024)	Learning Rate [7.8125e-05]
1: TRAIN [1][920/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00095)	Tok/s 87877 (59374)	Loss/tok 3.2274 (3.3016)	Learning Rate [7.8125e-05]
3: TRAIN [1][920/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00098)	Tok/s 89309 (60218)	Loss/tok 3.1789 (3.2978)	Learning Rate [7.8125e-05]
0: TRAIN [1][920/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 87276 (58920)	Loss/tok 3.2285 (3.3013)	Learning Rate [7.8125e-05]
1: TRAIN [1][930/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 61787 (59382)	Loss/tok 3.4085 (3.3016)	Learning Rate [7.8125e-05]
2: TRAIN [1][930/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00092)	Tok/s 61774 (59753)	Loss/tok 3.2331 (3.3023)	Learning Rate [7.8125e-05]
3: TRAIN [1][930/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00098)	Tok/s 62652 (60224)	Loss/tok 3.3345 (3.2974)	Learning Rate [7.8125e-05]
0: TRAIN [1][930/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 61805 (58929)	Loss/tok 3.2098 (3.3010)	Learning Rate [7.8125e-05]
2: TRAIN [1][940/6832]	Time 0.108 (0.105)	Data 0.00096 (0.00092)	Tok/s 52161 (59738)	Loss/tok 3.2545 (3.3021)	Learning Rate [7.8125e-05]
1: TRAIN [1][940/6832]	Time 0.108 (0.105)	Data 0.00097 (0.00095)	Tok/s 52169 (59365)	Loss/tok 2.9864 (3.3010)	Learning Rate [7.8125e-05]
3: TRAIN [1][940/6832]	Time 0.108 (0.105)	Data 0.00100 (0.00098)	Tok/s 52182 (60209)	Loss/tok 3.1709 (3.2971)	Learning Rate [7.8125e-05]
0: TRAIN [1][940/6832]	Time 0.108 (0.105)	Data 0.00102 (0.00096)	Tok/s 51986 (58910)	Loss/tok 3.1828 (3.3005)	Learning Rate [7.8125e-05]
2: TRAIN [1][950/6832]	Time 0.071 (0.105)	Data 0.00084 (0.00092)	Tok/s 52163 (59709)	Loss/tok 3.0546 (3.3028)	Learning Rate [7.8125e-05]
1: TRAIN [1][950/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00095)	Tok/s 52161 (59338)	Loss/tok 3.0278 (3.3018)	Learning Rate [7.8125e-05]
3: TRAIN [1][950/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00098)	Tok/s 52173 (60179)	Loss/tok 2.9516 (3.2975)	Learning Rate [7.8125e-05]
0: TRAIN [1][950/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00096)	Tok/s 52138 (58886)	Loss/tok 3.0323 (3.3007)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [1][960/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 79738 (59762)	Loss/tok 3.2686 (3.3030)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
1: TRAIN [1][960/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00095)	Tok/s 79372 (59392)	Loss/tok 3.2745 (3.3021)	Learning Rate [7.8125e-05]
0: TRAIN [1][960/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00096)	Tok/s 78501 (58941)	Loss/tok 3.3831 (3.3010)	Learning Rate [7.8125e-05]
3: TRAIN [1][960/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00098)	Tok/s 79962 (60228)	Loss/tok 3.4174 (3.2976)	Learning Rate [7.8125e-05]
2: TRAIN [1][970/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00092)	Tok/s 59791 (59721)	Loss/tok 3.4156 (3.3029)	Learning Rate [7.8125e-05]
1: TRAIN [1][970/6832]	Time 0.118 (0.105)	Data 0.00102 (0.00095)	Tok/s 59829 (59353)	Loss/tok 3.3414 (3.3019)	Learning Rate [7.8125e-05]
0: TRAIN [1][970/6832]	Time 0.118 (0.105)	Data 0.00105 (0.00096)	Tok/s 59827 (58902)	Loss/tok 3.2954 (3.3006)	Learning Rate [7.8125e-05]
3: TRAIN [1][970/6832]	Time 0.118 (0.105)	Data 0.00099 (0.00098)	Tok/s 59815 (60185)	Loss/tok 3.2921 (3.2971)	Learning Rate [7.8125e-05]
2: TRAIN [1][980/6832]	Time 0.063 (0.104)	Data 0.00108 (0.00092)	Tok/s 51836 (59656)	Loss/tok 3.0026 (3.3023)	Learning Rate [7.8125e-05]
1: TRAIN [1][980/6832]	Time 0.063 (0.104)	Data 0.00113 (0.00095)	Tok/s 51093 (59282)	Loss/tok 2.9238 (3.3015)	Learning Rate [7.8125e-05]
3: TRAIN [1][980/6832]	Time 0.063 (0.104)	Data 0.00111 (0.00098)	Tok/s 53061 (60125)	Loss/tok 2.8342 (3.2964)	Learning Rate [7.8125e-05]
0: TRAIN [1][980/6832]	Time 0.062 (0.104)	Data 0.00113 (0.00096)	Tok/s 51205 (58822)	Loss/tok 2.6440 (3.2997)	Learning Rate [7.8125e-05]
1: TRAIN [1][990/6832]	Time 0.131 (0.104)	Data 0.00092 (0.00095)	Tok/s 78816 (59289)	Loss/tok 3.2407 (3.3007)	Learning Rate [7.8125e-05]
2: TRAIN [1][990/6832]	Time 0.131 (0.104)	Data 0.00096 (0.00092)	Tok/s 79415 (59668)	Loss/tok 3.4699 (3.3022)	Learning Rate [7.8125e-05]
3: TRAIN [1][990/6832]	Time 0.131 (0.104)	Data 0.00104 (0.00098)	Tok/s 79502 (60140)	Loss/tok 3.2985 (3.2958)	Learning Rate [7.8125e-05]
0: TRAIN [1][990/6832]	Time 0.131 (0.104)	Data 0.00099 (0.00096)	Tok/s 78403 (58818)	Loss/tok 3.5216 (3.2992)	Learning Rate [7.8125e-05]
1: TRAIN [1][1000/6832]	Time 0.130 (0.104)	Data 0.00090 (0.00095)	Tok/s 67020 (59267)	Loss/tok 3.4159 (3.3008)	Learning Rate [7.8125e-05]
2: TRAIN [1][1000/6832]	Time 0.129 (0.104)	Data 0.00099 (0.00092)	Tok/s 67541 (59644)	Loss/tok 3.4044 (3.3027)	Learning Rate [7.8125e-05]
3: TRAIN [1][1000/6832]	Time 0.130 (0.104)	Data 0.00087 (0.00098)	Tok/s 67900 (60119)	Loss/tok 3.2327 (3.2960)	Learning Rate [7.8125e-05]
0: TRAIN [1][1000/6832]	Time 0.130 (0.104)	Data 0.00096 (0.00096)	Tok/s 67071 (58802)	Loss/tok 3.5136 (3.2989)	Learning Rate [7.8125e-05]
1: TRAIN [1][1010/6832]	Time 0.132 (0.104)	Data 0.00092 (0.00095)	Tok/s 85526 (59256)	Loss/tok 3.2882 (3.3002)	Learning Rate [7.8125e-05]
0: TRAIN [1][1010/6832]	Time 0.132 (0.104)	Data 0.00095 (0.00096)	Tok/s 84898 (58792)	Loss/tok 3.2219 (3.2981)	Learning Rate [7.8125e-05]
2: TRAIN [1][1010/6832]	Time 0.132 (0.104)	Data 0.00090 (0.00092)	Tok/s 86188 (59631)	Loss/tok 3.2348 (3.3020)	Learning Rate [7.8125e-05]
3: TRAIN [1][1010/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00098)	Tok/s 86605 (60106)	Loss/tok 3.2895 (3.2958)	Learning Rate [7.8125e-05]
2: TRAIN [1][1020/6832]	Time 0.104 (0.104)	Data 0.00097 (0.00092)	Tok/s 51791 (59638)	Loss/tok 3.2606 (3.3022)	Learning Rate [7.8125e-05]
3: TRAIN [1][1020/6832]	Time 0.104 (0.104)	Data 0.00096 (0.00098)	Tok/s 51790 (60111)	Loss/tok 3.2088 (3.2961)	Learning Rate [7.8125e-05]
1: TRAIN [1][1020/6832]	Time 0.104 (0.104)	Data 0.00096 (0.00095)	Tok/s 51715 (59266)	Loss/tok 3.2217 (3.3007)	Learning Rate [7.8125e-05]
0: TRAIN [1][1020/6832]	Time 0.104 (0.104)	Data 0.00100 (0.00096)	Tok/s 51717 (58803)	Loss/tok 3.0427 (3.2984)	Learning Rate [7.8125e-05]
1: TRAIN [1][1030/6832]	Time 0.123 (0.104)	Data 0.00089 (0.00095)	Tok/s 60134 (59252)	Loss/tok 3.3864 (3.3004)	Learning Rate [7.8125e-05]
2: TRAIN [1][1030/6832]	Time 0.123 (0.104)	Data 0.00088 (0.00092)	Tok/s 60158 (59623)	Loss/tok 3.5572 (3.3018)	Learning Rate [7.8125e-05]
3: TRAIN [1][1030/6832]	Time 0.123 (0.104)	Data 0.00084 (0.00098)	Tok/s 60130 (60095)	Loss/tok 3.7635 (3.2963)	Learning Rate [7.8125e-05]
0: TRAIN [1][1030/6832]	Time 0.123 (0.104)	Data 0.00097 (0.00096)	Tok/s 60141 (58792)	Loss/tok 3.3135 (3.2979)	Learning Rate [7.8125e-05]
1: TRAIN [1][1040/6832]	Time 0.112 (0.104)	Data 0.00090 (0.00095)	Tok/s 51390 (59196)	Loss/tok 3.2943 (3.2997)	Learning Rate [7.8125e-05]
2: TRAIN [1][1040/6832]	Time 0.112 (0.104)	Data 0.00094 (0.00092)	Tok/s 51444 (59566)	Loss/tok 3.2720 (3.3013)	Learning Rate [7.8125e-05]
3: TRAIN [1][1040/6832]	Time 0.112 (0.104)	Data 0.00090 (0.00098)	Tok/s 51436 (60039)	Loss/tok 3.1825 (3.2960)	Learning Rate [7.8125e-05]
0: TRAIN [1][1040/6832]	Time 0.112 (0.104)	Data 0.00098 (0.00096)	Tok/s 51398 (58735)	Loss/tok 3.4168 (3.2978)	Learning Rate [7.8125e-05]
1: TRAIN [1][1050/6832]	Time 0.064 (0.104)	Data 0.00091 (0.00095)	Tok/s 50309 (59180)	Loss/tok 2.9424 (3.2988)	Learning Rate [7.8125e-05]
2: TRAIN [1][1050/6832]	Time 0.064 (0.104)	Data 0.00090 (0.00092)	Tok/s 51216 (59553)	Loss/tok 2.9574 (3.3008)	Learning Rate [7.8125e-05]
3: TRAIN [1][1050/6832]	Time 0.064 (0.104)	Data 0.00088 (0.00098)	Tok/s 52322 (60028)	Loss/tok 2.9935 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][1050/6832]	Time 0.064 (0.104)	Data 0.00100 (0.00096)	Tok/s 50293 (58717)	Loss/tok 2.9523 (3.2969)	Learning Rate [7.8125e-05]
1: TRAIN [1][1060/6832]	Time 0.118 (0.104)	Data 0.00092 (0.00095)	Tok/s 57453 (59220)	Loss/tok 3.2018 (3.2997)	Learning Rate [7.8125e-05]
3: TRAIN [1][1060/6832]	Time 0.118 (0.104)	Data 0.00094 (0.00098)	Tok/s 58500 (60065)	Loss/tok 3.3677 (3.2954)	Learning Rate [7.8125e-05]
2: TRAIN [1][1060/6832]	Time 0.118 (0.104)	Data 0.00096 (0.00092)	Tok/s 58474 (59593)	Loss/tok 3.1962 (3.3011)	Learning Rate [7.8125e-05]
0: TRAIN [1][1060/6832]	Time 0.118 (0.104)	Data 0.00100 (0.00096)	Tok/s 57372 (58761)	Loss/tok 3.2758 (3.2974)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][1070/6832]	Time 0.096 (0.104)	Data 0.00090 (0.00095)	Tok/s 52735 (59222)	Loss/tok 3.2239 (3.3003)	Learning Rate [7.8125e-05]
0: TRAIN [1][1070/6832]	Time 0.096 (0.104)	Data 0.00097 (0.00096)	Tok/s 52209 (58764)	Loss/tok 3.2077 (3.2969)	Learning Rate [7.8125e-05]
2: TRAIN [1][1070/6832]	Time 0.096 (0.104)	Data 0.00088 (0.00092)	Tok/s 53547 (59593)	Loss/tok 3.1507 (3.3003)	Learning Rate [7.8125e-05]
3: TRAIN [1][1070/6832]	Time 0.096 (0.104)	Data 0.00087 (0.00098)	Tok/s 53542 (60065)	Loss/tok 3.1573 (3.2954)	Learning Rate [7.8125e-05]
1: TRAIN [1][1080/6832]	Time 0.129 (0.104)	Data 0.00091 (0.00095)	Tok/s 66594 (59243)	Loss/tok 3.3587 (3.3006)	Learning Rate [7.8125e-05]
2: TRAIN [1][1080/6832]	Time 0.129 (0.104)	Data 0.00091 (0.00092)	Tok/s 66554 (59613)	Loss/tok 3.3672 (3.3012)	Learning Rate [7.8125e-05]
0: TRAIN [1][1080/6832]	Time 0.129 (0.104)	Data 0.00100 (0.00096)	Tok/s 66571 (58788)	Loss/tok 3.3200 (3.2972)	Learning Rate [7.8125e-05]
3: TRAIN [1][1080/6832]	Time 0.129 (0.104)	Data 0.00092 (0.00098)	Tok/s 66602 (60082)	Loss/tok 3.3054 (3.2963)	Learning Rate [7.8125e-05]
2: TRAIN [1][1090/6832]	Time 0.111 (0.104)	Data 0.00086 (0.00092)	Tok/s 52865 (59633)	Loss/tok 3.1848 (3.3014)	Learning Rate [7.8125e-05]
1: TRAIN [1][1090/6832]	Time 0.111 (0.104)	Data 0.00088 (0.00095)	Tok/s 52835 (59266)	Loss/tok 3.2395 (3.2999)	Learning Rate [7.8125e-05]
3: TRAIN [1][1090/6832]	Time 0.111 (0.104)	Data 0.00088 (0.00098)	Tok/s 53957 (60105)	Loss/tok 3.2453 (3.2966)	Learning Rate [7.8125e-05]
0: TRAIN [1][1090/6832]	Time 0.111 (0.104)	Data 0.00099 (0.00096)	Tok/s 52833 (58813)	Loss/tok 3.3021 (3.2978)	Learning Rate [7.8125e-05]
1: TRAIN [1][1100/6832]	Time 0.119 (0.104)	Data 0.00089 (0.00095)	Tok/s 49275 (59249)	Loss/tok 3.2316 (3.2996)	Learning Rate [7.8125e-05]
2: TRAIN [1][1100/6832]	Time 0.119 (0.104)	Data 0.00089 (0.00092)	Tok/s 49276 (59613)	Loss/tok 3.2297 (3.3014)	Learning Rate [7.8125e-05]
0: TRAIN [1][1100/6832]	Time 0.119 (0.104)	Data 0.00096 (0.00096)	Tok/s 49288 (58800)	Loss/tok 3.2858 (3.2977)	Learning Rate [7.8125e-05]
3: TRAIN [1][1100/6832]	Time 0.120 (0.104)	Data 0.00088 (0.00098)	Tok/s 49252 (60085)	Loss/tok 3.1639 (3.2967)	Learning Rate [7.8125e-05]
1: TRAIN [1][1110/6832]	Time 0.079 (0.104)	Data 0.00090 (0.00095)	Tok/s 53753 (59265)	Loss/tok 3.0883 (3.3004)	Learning Rate [7.8125e-05]
2: TRAIN [1][1110/6832]	Time 0.079 (0.104)	Data 0.00095 (0.00092)	Tok/s 53763 (59632)	Loss/tok 2.9096 (3.3012)	Learning Rate [7.8125e-05]
0: TRAIN [1][1110/6832]	Time 0.079 (0.104)	Data 0.00101 (0.00096)	Tok/s 53761 (58817)	Loss/tok 2.9501 (3.2975)	Learning Rate [7.8125e-05]
3: TRAIN [1][1110/6832]	Time 0.079 (0.104)	Data 0.00099 (0.00098)	Tok/s 54906 (60105)	Loss/tok 3.0754 (3.2966)	Learning Rate [7.8125e-05]
1: TRAIN [1][1120/6832]	Time 0.044 (0.104)	Data 0.00087 (0.00094)	Tok/s 33433 (59267)	Loss/tok 2.1660 (3.3000)	Learning Rate [7.8125e-05]
2: TRAIN [1][1120/6832]	Time 0.043 (0.104)	Data 0.00095 (0.00092)	Tok/s 38483 (59636)	Loss/tok 1.9705 (3.3014)	Learning Rate [7.8125e-05]
3: TRAIN [1][1120/6832]	Time 0.043 (0.104)	Data 0.00110 (0.00098)	Tok/s 42398 (60110)	Loss/tok 2.4700 (3.2963)	Learning Rate [7.8125e-05]
0: TRAIN [1][1120/6832]	Time 0.043 (0.104)	Data 0.00096 (0.00096)	Tok/s 22464 (58811)	Loss/tok 1.7256 (3.2975)	Learning Rate [7.8125e-05]
1: TRAIN [1][1130/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00094)	Tok/s 52882 (59267)	Loss/tok 3.3761 (3.3003)	Learning Rate [7.8125e-05]
0: TRAIN [1][1130/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00096)	Tok/s 52868 (58812)	Loss/tok 3.2882 (3.2981)	Learning Rate [7.8125e-05]
2: TRAIN [1][1130/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00092)	Tok/s 52856 (59634)	Loss/tok 3.2730 (3.3018)	Learning Rate [7.8125e-05]
3: TRAIN [1][1130/6832]	Time 0.121 (0.105)	Data 0.00130 (0.00098)	Tok/s 53084 (60106)	Loss/tok 3.2712 (3.2969)	Learning Rate [7.8125e-05]
1: TRAIN [1][1140/6832]	Time 0.123 (0.104)	Data 0.00089 (0.00094)	Tok/s 57050 (59228)	Loss/tok 3.5513 (3.3004)	Learning Rate [7.8125e-05]
0: TRAIN [1][1140/6832]	Time 0.123 (0.104)	Data 0.00090 (0.00096)	Tok/s 57056 (58774)	Loss/tok 3.3684 (3.2978)	Learning Rate [7.8125e-05]
2: TRAIN [1][1140/6832]	Time 0.123 (0.104)	Data 0.00097 (0.00092)	Tok/s 57060 (59596)	Loss/tok 3.4194 (3.3012)	Learning Rate [7.8125e-05]
3: TRAIN [1][1140/6832]	Time 0.123 (0.104)	Data 0.00098 (0.00098)	Tok/s 57077 (60067)	Loss/tok 3.3682 (3.2972)	Learning Rate [7.8125e-05]
2: TRAIN [1][1150/6832]	Time 0.055 (0.105)	Data 0.00110 (0.00092)	Tok/s 44756 (59605)	Loss/tok 2.6083 (3.3010)	Learning Rate [7.8125e-05]
0: TRAIN [1][1150/6832]	Time 0.055 (0.105)	Data 0.00103 (0.00096)	Tok/s 42485 (58782)	Loss/tok 2.7856 (3.2975)	Learning Rate [7.8125e-05]
3: TRAIN [1][1150/6832]	Time 0.055 (0.105)	Data 0.00115 (0.00098)	Tok/s 46641 (60076)	Loss/tok 2.7087 (3.2971)	Learning Rate [7.8125e-05]
1: TRAIN [1][1150/6832]	Time 0.055 (0.105)	Data 0.00101 (0.00094)	Tok/s 44234 (59236)	Loss/tok 2.5760 (3.3004)	Learning Rate [7.8125e-05]
1: TRAIN [1][1160/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00094)	Tok/s 57571 (59250)	Loss/tok 3.2136 (3.3012)	Learning Rate [7.8125e-05]
0: TRAIN [1][1160/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00096)	Tok/s 57576 (58796)	Loss/tok 3.2803 (3.2982)	Learning Rate [7.8125e-05]
2: TRAIN [1][1160/6832]	Time 0.116 (0.105)	Data 0.00093 (0.00092)	Tok/s 57524 (59616)	Loss/tok 3.3208 (3.3012)	Learning Rate [7.8125e-05]
3: TRAIN [1][1160/6832]	Time 0.116 (0.105)	Data 0.00107 (0.00098)	Tok/s 57539 (60086)	Loss/tok 3.3552 (3.2973)	Learning Rate [7.8125e-05]
2: TRAIN [1][1170/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00092)	Tok/s 77248 (59624)	Loss/tok 3.2708 (3.3017)	Learning Rate [7.8125e-05]
1: TRAIN [1][1170/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 77070 (59260)	Loss/tok 3.3412 (3.3017)	Learning Rate [7.8125e-05]
3: TRAIN [1][1170/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00098)	Tok/s 77610 (60093)	Loss/tok 3.4823 (3.2979)	Learning Rate [7.8125e-05]
0: TRAIN [1][1170/6832]	Time 0.131 (0.105)	Data 0.00116 (0.00096)	Tok/s 76213 (58807)	Loss/tok 3.3796 (3.2984)	Learning Rate [7.8125e-05]
1: TRAIN [1][1180/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00094)	Tok/s 60153 (59283)	Loss/tok 3.4675 (3.3021)	Learning Rate [7.8125e-05]
0: TRAIN [1][1180/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00096)	Tok/s 60157 (58833)	Loss/tok 3.4795 (3.2991)	Learning Rate [7.8125e-05]
2: TRAIN [1][1180/6832]	Time 0.123 (0.105)	Data 0.00101 (0.00092)	Tok/s 60149 (59645)	Loss/tok 3.4097 (3.3019)	Learning Rate [7.8125e-05]
3: TRAIN [1][1180/6832]	Time 0.123 (0.105)	Data 0.00109 (0.00098)	Tok/s 60136 (60113)	Loss/tok 3.6008 (3.2981)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][1190/6832]	Time 0.061 (0.105)	Data 0.00109 (0.00092)	Tok/s 50845 (59607)	Loss/tok 3.0118 (3.3013)	Learning Rate [7.8125e-05]
1: TRAIN [1][1190/6832]	Time 0.061 (0.105)	Data 0.00091 (0.00094)	Tok/s 50519 (59246)	Loss/tok 2.7715 (3.3016)	Learning Rate [7.8125e-05]
0: TRAIN [1][1190/6832]	Time 0.061 (0.105)	Data 0.00098 (0.00096)	Tok/s 50594 (58799)	Loss/tok 2.8877 (3.2987)	Learning Rate [7.8125e-05]
3: TRAIN [1][1190/6832]	Time 0.061 (0.105)	Data 0.00103 (0.00098)	Tok/s 52846 (60074)	Loss/tok 2.9988 (3.2980)	Learning Rate [7.8125e-05]
1: TRAIN [1][1200/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00094)	Tok/s 58619 (59244)	Loss/tok 3.3306 (3.3020)	Learning Rate [7.8125e-05]
2: TRAIN [1][1200/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00093)	Tok/s 59093 (59605)	Loss/tok 3.2981 (3.3016)	Learning Rate [7.8125e-05]
0: TRAIN [1][1200/6832]	Time 0.121 (0.105)	Data 0.00102 (0.00096)	Tok/s 58050 (58799)	Loss/tok 3.1863 (3.2994)	Learning Rate [7.8125e-05]
3: TRAIN [1][1200/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00098)	Tok/s 59076 (60071)	Loss/tok 3.3156 (3.2983)	Learning Rate [7.8125e-05]
1: TRAIN [1][1210/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 83550 (59247)	Loss/tok 3.2006 (3.3022)	Learning Rate [7.8125e-05]
2: TRAIN [1][1210/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 84083 (59607)	Loss/tok 3.3361 (3.3015)	Learning Rate [7.8125e-05]
0: TRAIN [1][1210/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00096)	Tok/s 82993 (58804)	Loss/tok 3.3058 (3.2993)	Learning Rate [7.8125e-05]
3: TRAIN [1][1210/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00098)	Tok/s 84512 (60071)	Loss/tok 3.3162 (3.2987)	Learning Rate [7.8125e-05]
1: TRAIN [1][1220/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 77049 (59257)	Loss/tok 3.2783 (3.3019)	Learning Rate [7.8125e-05]
0: TRAIN [1][1220/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 76093 (58814)	Loss/tok 3.3913 (3.2995)	Learning Rate [7.8125e-05]
2: TRAIN [1][1220/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00093)	Tok/s 77054 (59617)	Loss/tok 3.3158 (3.3014)	Learning Rate [7.8125e-05]
3: TRAIN [1][1220/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00098)	Tok/s 77125 (60079)	Loss/tok 3.4047 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1230/6832]	Time 0.089 (0.105)	Data 0.00108 (0.00094)	Tok/s 54396 (59272)	Loss/tok 3.0128 (3.3023)	Learning Rate [7.8125e-05]
0: TRAIN [1][1230/6832]	Time 0.089 (0.105)	Data 0.00116 (0.00096)	Tok/s 54359 (58832)	Loss/tok 3.0375 (3.2996)	Learning Rate [7.8125e-05]
2: TRAIN [1][1230/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00093)	Tok/s 54387 (59630)	Loss/tok 3.2489 (3.3015)	Learning Rate [7.8125e-05]
3: TRAIN [1][1230/6832]	Time 0.089 (0.105)	Data 0.00098 (0.00098)	Tok/s 55370 (60092)	Loss/tok 3.0493 (3.2993)	Learning Rate [7.8125e-05]
1: TRAIN [1][1240/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 83037 (59333)	Loss/tok 3.2141 (3.3017)	Learning Rate [7.8125e-05]
2: TRAIN [1][1240/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00093)	Tok/s 83157 (59694)	Loss/tok 3.2645 (3.3011)	Learning Rate [7.8125e-05]
0: TRAIN [1][1240/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00096)	Tok/s 82154 (58893)	Loss/tok 3.2118 (3.2992)	Learning Rate [7.8125e-05]
3: TRAIN [1][1240/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00098)	Tok/s 83940 (60157)	Loss/tok 3.3173 (3.2993)	Learning Rate [7.8125e-05]
1: TRAIN [1][1250/6832]	Time 0.077 (0.105)	Data 0.00096 (0.00094)	Tok/s 53515 (59346)	Loss/tok 2.9872 (3.3010)	Learning Rate [7.8125e-05]
2: TRAIN [1][1250/6832]	Time 0.076 (0.105)	Data 0.00096 (0.00093)	Tok/s 53590 (59705)	Loss/tok 3.1332 (3.3010)	Learning Rate [7.8125e-05]
0: TRAIN [1][1250/6832]	Time 0.076 (0.105)	Data 0.00099 (0.00096)	Tok/s 53575 (58905)	Loss/tok 3.1826 (3.2993)	Learning Rate [7.8125e-05]
3: TRAIN [1][1250/6832]	Time 0.076 (0.105)	Data 0.00101 (0.00098)	Tok/s 53597 (60166)	Loss/tok 3.0398 (3.2991)	Learning Rate [7.8125e-05]
1: TRAIN [1][1260/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00094)	Tok/s 82256 (59387)	Loss/tok 3.1875 (3.3010)	Learning Rate [7.8125e-05]
2: TRAIN [1][1260/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00093)	Tok/s 82723 (59744)	Loss/tok 3.3028 (3.3008)	Learning Rate [7.8125e-05]
0: TRAIN [1][1260/6832]	Time 0.131 (0.105)	Data 0.00111 (0.00096)	Tok/s 81736 (58943)	Loss/tok 3.4032 (3.2994)	Learning Rate [7.8125e-05]
3: TRAIN [1][1260/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00098)	Tok/s 83217 (60205)	Loss/tok 3.2878 (3.2991)	Learning Rate [7.8125e-05]
1: TRAIN [1][1270/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00094)	Tok/s 47931 (59382)	Loss/tok 2.9223 (3.3013)	Learning Rate [7.8125e-05]
0: TRAIN [1][1270/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00096)	Tok/s 47914 (58941)	Loss/tok 2.9378 (3.2992)	Learning Rate [7.8125e-05]
2: TRAIN [1][1270/6832]	Time 0.062 (0.105)	Data 0.00088 (0.00093)	Tok/s 48792 (59739)	Loss/tok 2.8997 (3.3007)	Learning Rate [7.8125e-05]
3: TRAIN [1][1270/6832]	Time 0.062 (0.105)	Data 0.00091 (0.00098)	Tok/s 49916 (60201)	Loss/tok 3.0177 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1280/6832]	Time 0.064 (0.105)	Data 0.00093 (0.00094)	Tok/s 51666 (59410)	Loss/tok 2.9826 (3.3013)	Learning Rate [7.8125e-05]
2: TRAIN [1][1280/6832]	Time 0.064 (0.105)	Data 0.00096 (0.00093)	Tok/s 52231 (59768)	Loss/tok 3.0544 (3.3008)	Learning Rate [7.8125e-05]
3: TRAIN [1][1280/6832]	Time 0.064 (0.105)	Data 0.00093 (0.00098)	Tok/s 53662 (60230)	Loss/tok 3.0851 (3.2991)	Learning Rate [7.8125e-05]
0: TRAIN [1][1280/6832]	Time 0.065 (0.105)	Data 0.00104 (0.00096)	Tok/s 51405 (58970)	Loss/tok 3.0530 (3.2995)	Learning Rate [7.8125e-05]
1: TRAIN [1][1290/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00094)	Tok/s 51418 (59389)	Loss/tok 3.3887 (3.3015)	Learning Rate [7.8125e-05]
2: TRAIN [1][1290/6832]	Time 0.122 (0.105)	Data 0.00097 (0.00093)	Tok/s 51427 (59747)	Loss/tok 3.4418 (3.3010)	Learning Rate [7.8125e-05]
3: TRAIN [1][1290/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00098)	Tok/s 51558 (60209)	Loss/tok 3.4059 (3.2996)	Learning Rate [7.8125e-05]
0: TRAIN [1][1290/6832]	Time 0.122 (0.105)	Data 0.00105 (0.00097)	Tok/s 51304 (58952)	Loss/tok 3.2766 (3.2996)	Learning Rate [7.8125e-05]
2: TRAIN [1][1300/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00093)	Tok/s 58181 (59746)	Loss/tok 3.2787 (3.3017)	Learning Rate [7.8125e-05]
3: TRAIN [1][1300/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00098)	Tok/s 59213 (60208)	Loss/tok 3.3024 (3.3001)	Learning Rate [7.8125e-05]
1: TRAIN [1][1300/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00094)	Tok/s 58145 (59389)	Loss/tok 3.3610 (3.3026)	Learning Rate [7.8125e-05]
0: TRAIN [1][1300/6832]	Time 0.117 (0.105)	Data 0.00109 (0.00097)	Tok/s 57973 (58955)	Loss/tok 3.1727 (3.2998)	Learning Rate [7.8125e-05]
1: TRAIN [1][1310/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 74027 (59367)	Loss/tok 3.5095 (3.3024)	Learning Rate [7.8125e-05]
2: TRAIN [1][1310/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 74040 (59728)	Loss/tok 3.4181 (3.3013)	Learning Rate [7.8125e-05]
3: TRAIN [1][1310/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00098)	Tok/s 74038 (60191)	Loss/tok 3.3918 (3.2998)	Learning Rate [7.8125e-05]
0: TRAIN [1][1310/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00097)	Tok/s 72941 (58926)	Loss/tok 3.2145 (3.2991)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [1][1320/6832]	Time 0.062 (0.105)	Data 0.00091 (0.00094)	Tok/s 49781 (59337)	Loss/tok 2.8787 (3.3022)	Learning Rate [7.8125e-05]
2: TRAIN [1][1320/6832]	Time 0.062 (0.105)	Data 0.00100 (0.00093)	Tok/s 50249 (59699)	Loss/tok 2.8029 (3.3011)	Learning Rate [7.8125e-05]
3: TRAIN [1][1320/6832]	Time 0.062 (0.105)	Data 0.00104 (0.00098)	Tok/s 51867 (60162)	Loss/tok 3.0628 (3.2996)	Learning Rate [7.8125e-05]
0: TRAIN [1][1320/6832]	Time 0.062 (0.105)	Data 0.00103 (0.00097)	Tok/s 49602 (58899)	Loss/tok 2.6881 (3.2987)	Learning Rate [7.8125e-05]
2: TRAIN [1][1330/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00093)	Tok/s 55258 (59709)	Loss/tok 3.2054 (3.3015)	Learning Rate [7.8125e-05]
3: TRAIN [1][1330/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00098)	Tok/s 55852 (60172)	Loss/tok 3.6200 (3.3001)	Learning Rate [7.8125e-05]
1: TRAIN [1][1330/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00094)	Tok/s 54771 (59348)	Loss/tok 3.4669 (3.3025)	Learning Rate [7.8125e-05]
0: TRAIN [1][1330/6832]	Time 0.121 (0.105)	Data 0.00094 (0.00097)	Tok/s 54794 (58912)	Loss/tok 3.3610 (3.2992)	Learning Rate [7.8125e-05]
2: TRAIN [1][1340/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00093)	Tok/s 61971 (59714)	Loss/tok 3.5811 (3.3017)	Learning Rate [7.8125e-05]
1: TRAIN [1][1340/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00094)	Tok/s 61954 (59352)	Loss/tok 3.3886 (3.3022)	Learning Rate [7.8125e-05]
3: TRAIN [1][1340/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00098)	Tok/s 61952 (60178)	Loss/tok 3.4649 (3.2996)	Learning Rate [7.8125e-05]
0: TRAIN [1][1340/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00097)	Tok/s 60928 (58916)	Loss/tok 3.4974 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1350/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00094)	Tok/s 63686 (59362)	Loss/tok 3.3593 (3.3027)	Learning Rate [7.8125e-05]
0: TRAIN [1][1350/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00097)	Tok/s 62802 (58928)	Loss/tok 3.3706 (3.2990)	Learning Rate [7.8125e-05]
2: TRAIN [1][1350/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00093)	Tok/s 63740 (59725)	Loss/tok 3.3497 (3.3022)	Learning Rate [7.8125e-05]
3: TRAIN [1][1350/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00098)	Tok/s 63736 (60186)	Loss/tok 3.5064 (3.3000)	Learning Rate [7.8125e-05]
2: TRAIN [1][1360/6832]	Time 0.098 (0.105)	Data 0.00098 (0.00093)	Tok/s 53501 (59723)	Loss/tok 3.3633 (3.3018)	Learning Rate [7.8125e-05]
1: TRAIN [1][1360/6832]	Time 0.098 (0.105)	Data 0.00107 (0.00094)	Tok/s 53516 (59359)	Loss/tok 3.0671 (3.3019)	Learning Rate [7.8125e-05]
3: TRAIN [1][1360/6832]	Time 0.098 (0.105)	Data 0.00102 (0.00098)	Tok/s 53515 (60184)	Loss/tok 3.2726 (3.2995)	Learning Rate [7.8125e-05]
0: TRAIN [1][1360/6832]	Time 0.098 (0.105)	Data 0.00110 (0.00097)	Tok/s 53537 (58925)	Loss/tok 3.1851 (3.2987)	Learning Rate [7.8125e-05]
1: TRAIN [1][1370/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 85565 (59358)	Loss/tok 3.2187 (3.3012)	Learning Rate [7.8125e-05]
0: TRAIN [1][1370/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00097)	Tok/s 84976 (58926)	Loss/tok 3.1524 (3.2984)	Learning Rate [7.8125e-05]
2: TRAIN [1][1370/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00093)	Tok/s 86097 (59721)	Loss/tok 3.1540 (3.3017)	Learning Rate [7.8125e-05]
3: TRAIN [1][1370/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00098)	Tok/s 86456 (60179)	Loss/tok 3.1669 (3.2995)	Learning Rate [7.8125e-05]
2: TRAIN [1][1380/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00093)	Tok/s 52092 (59742)	Loss/tok 3.1173 (3.3019)	Learning Rate [7.8125e-05]
1: TRAIN [1][1380/6832]	Time 0.079 (0.105)	Data 0.00111 (0.00094)	Tok/s 52058 (59379)	Loss/tok 3.1426 (3.3015)	Learning Rate [7.8125e-05]
3: TRAIN [1][1380/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00098)	Tok/s 52326 (60199)	Loss/tok 3.0903 (3.2994)	Learning Rate [7.8125e-05]
0: TRAIN [1][1380/6832]	Time 0.079 (0.105)	Data 0.00111 (0.00097)	Tok/s 52070 (58949)	Loss/tok 3.1787 (3.2980)	Learning Rate [7.8125e-05]
1: TRAIN [1][1390/6832]	Time 0.124 (0.105)	Data 0.00094 (0.00094)	Tok/s 60819 (59388)	Loss/tok 3.3944 (3.3019)	Learning Rate [7.8125e-05]
2: TRAIN [1][1390/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00093)	Tok/s 60771 (59750)	Loss/tok 3.4718 (3.3018)	Learning Rate [7.8125e-05]
0: TRAIN [1][1390/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00097)	Tok/s 60811 (58959)	Loss/tok 3.3900 (3.2986)	Learning Rate [7.8125e-05]
3: TRAIN [1][1390/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00098)	Tok/s 60785 (60206)	Loss/tok 3.3346 (3.2995)	Learning Rate [7.8125e-05]
2: TRAIN [1][1400/6832]	Time 0.098 (0.105)	Data 0.00086 (0.00093)	Tok/s 52241 (59794)	Loss/tok 3.1704 (3.3014)	Learning Rate [7.8125e-05]
3: TRAIN [1][1400/6832]	Time 0.098 (0.105)	Data 0.00089 (0.00098)	Tok/s 52274 (60253)	Loss/tok 3.1722 (3.2994)	Learning Rate [7.8125e-05]
1: TRAIN [1][1400/6832]	Time 0.098 (0.105)	Data 0.00087 (0.00094)	Tok/s 52229 (59433)	Loss/tok 3.2139 (3.3018)	Learning Rate [7.8125e-05]
0: TRAIN [1][1400/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00097)	Tok/s 52986 (59005)	Loss/tok 3.2071 (3.2980)	Learning Rate [7.8125e-05]
2: TRAIN [1][1410/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00093)	Tok/s 55974 (59767)	Loss/tok 3.3244 (3.3011)	Learning Rate [7.8125e-05]
1: TRAIN [1][1410/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 55965 (59405)	Loss/tok 3.1943 (3.3014)	Learning Rate [7.8125e-05]
3: TRAIN [1][1410/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00098)	Tok/s 55985 (60225)	Loss/tok 3.4016 (3.2994)	Learning Rate [7.8125e-05]
0: TRAIN [1][1410/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00097)	Tok/s 55978 (58977)	Loss/tok 3.2131 (3.2980)	Learning Rate [7.8125e-05]
2: TRAIN [1][1420/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00093)	Tok/s 54315 (59727)	Loss/tok 3.0755 (3.3008)	Learning Rate [7.8125e-05]
1: TRAIN [1][1420/6832]	Time 0.092 (0.105)	Data 0.00088 (0.00094)	Tok/s 54230 (59367)	Loss/tok 3.1737 (3.3011)	Learning Rate [7.8125e-05]
0: TRAIN [1][1420/6832]	Time 0.092 (0.105)	Data 0.00098 (0.00097)	Tok/s 54280 (58941)	Loss/tok 3.2213 (3.2981)	Learning Rate [7.8125e-05]
3: TRAIN [1][1420/6832]	Time 0.092 (0.105)	Data 0.00096 (0.00098)	Tok/s 54285 (60184)	Loss/tok 3.1538 (3.2992)	Learning Rate [7.8125e-05]
1: TRAIN [1][1430/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00094)	Tok/s 50908 (59358)	Loss/tok 2.9377 (3.3004)	Learning Rate [7.8125e-05]
0: TRAIN [1][1430/6832]	Time 0.070 (0.105)	Data 0.00095 (0.00097)	Tok/s 50912 (58931)	Loss/tok 2.9949 (3.2976)	Learning Rate [7.8125e-05]
2: TRAIN [1][1430/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00093)	Tok/s 50913 (59719)	Loss/tok 3.0730 (3.3004)	Learning Rate [7.8125e-05]
3: TRAIN [1][1430/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00098)	Tok/s 51223 (60177)	Loss/tok 2.8570 (3.2984)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][1440/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00094)	Tok/s 54325 (59375)	Loss/tok 3.1351 (3.3002)	Learning Rate [7.8125e-05]
0: TRAIN [1][1440/6832]	Time 0.101 (0.105)	Data 0.00097 (0.00097)	Tok/s 54349 (58950)	Loss/tok 3.3681 (3.2980)	Learning Rate [7.8125e-05]
2: TRAIN [1][1440/6832]	Time 0.101 (0.105)	Data 0.00103 (0.00093)	Tok/s 54329 (59737)	Loss/tok 3.3453 (3.3010)	Learning Rate [7.8125e-05]
3: TRAIN [1][1440/6832]	Time 0.101 (0.105)	Data 0.00103 (0.00098)	Tok/s 54324 (60196)	Loss/tok 3.2565 (3.2984)	Learning Rate [7.8125e-05]
2: TRAIN [1][1450/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00093)	Tok/s 75703 (59761)	Loss/tok 3.3106 (3.3012)	Learning Rate [7.8125e-05]
3: TRAIN [1][1450/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00098)	Tok/s 75694 (60220)	Loss/tok 3.3594 (3.2987)	Learning Rate [7.8125e-05]
1: TRAIN [1][1450/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00094)	Tok/s 74782 (59400)	Loss/tok 3.3622 (3.3003)	Learning Rate [7.8125e-05]
0: TRAIN [1][1450/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00097)	Tok/s 74746 (58976)	Loss/tok 3.4457 (3.2979)	Learning Rate [7.8125e-05]
2: TRAIN [1][1460/6832]	Time 0.082 (0.105)	Data 0.00088 (0.00093)	Tok/s 54804 (59747)	Loss/tok 3.3330 (3.3013)	Learning Rate [7.8125e-05]
1: TRAIN [1][1460/6832]	Time 0.082 (0.105)	Data 0.00087 (0.00094)	Tok/s 54734 (59388)	Loss/tok 3.2202 (3.3002)	Learning Rate [7.8125e-05]
0: TRAIN [1][1460/6832]	Time 0.082 (0.105)	Data 0.00091 (0.00097)	Tok/s 54785 (58964)	Loss/tok 3.2392 (3.2980)	Learning Rate [7.8125e-05]
3: TRAIN [1][1460/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00098)	Tok/s 54795 (60204)	Loss/tok 3.1704 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1470/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 70755 (59382)	Loss/tok 3.3158 (3.3003)	Learning Rate [7.8125e-05]
2: TRAIN [1][1470/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 70707 (59738)	Loss/tok 3.3270 (3.3013)	Learning Rate [7.8125e-05]
0: TRAIN [1][1470/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00097)	Tok/s 70771 (58959)	Loss/tok 3.4568 (3.2982)	Learning Rate [7.8125e-05]
3: TRAIN [1][1470/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00098)	Tok/s 71312 (60195)	Loss/tok 3.3782 (3.2989)	Learning Rate [7.8125e-05]
2: TRAIN [1][1480/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00093)	Tok/s 54069 (59803)	Loss/tok 3.2578 (3.3015)	Learning Rate [7.8125e-05]
1: TRAIN [1][1480/6832]	Time 0.104 (0.105)	Data 0.00087 (0.00094)	Tok/s 54005 (59447)	Loss/tok 3.2296 (3.3007)	Learning Rate [7.8125e-05]
0: TRAIN [1][1480/6832]	Time 0.104 (0.105)	Data 0.00089 (0.00097)	Tok/s 52968 (59025)	Loss/tok 3.2677 (3.2985)	Learning Rate [7.8125e-05]
3: TRAIN [1][1480/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00098)	Tok/s 53967 (60258)	Loss/tok 3.4871 (3.2992)	Learning Rate [7.8125e-05]
2: TRAIN [1][1490/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00093)	Tok/s 52502 (59805)	Loss/tok 3.1516 (3.3012)	Learning Rate [7.8125e-05]
1: TRAIN [1][1490/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00094)	Tok/s 51792 (59448)	Loss/tok 3.2308 (3.3002)	Learning Rate [7.8125e-05]
3: TRAIN [1][1490/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00098)	Tok/s 52497 (60259)	Loss/tok 3.2283 (3.2987)	Learning Rate [7.8125e-05]
0: TRAIN [1][1490/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00097)	Tok/s 51065 (59027)	Loss/tok 3.1348 (3.2979)	Learning Rate [7.8125e-05]
2: TRAIN [1][1500/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 64014 (59793)	Loss/tok 3.4562 (3.3013)	Learning Rate [7.8125e-05]
1: TRAIN [1][1500/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 64009 (59439)	Loss/tok 3.3723 (3.3004)	Learning Rate [7.8125e-05]
0: TRAIN [1][1500/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00097)	Tok/s 64018 (59015)	Loss/tok 3.4301 (3.2981)	Learning Rate [7.8125e-05]
3: TRAIN [1][1500/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00098)	Tok/s 64909 (60247)	Loss/tok 3.3408 (3.2990)	Learning Rate [7.8125e-05]
1: TRAIN [1][1510/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 78445 (59497)	Loss/tok 3.3040 (3.3004)	Learning Rate [7.8125e-05]
0: TRAIN [1][1510/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00097)	Tok/s 78448 (59075)	Loss/tok 3.2857 (3.2981)	Learning Rate [7.8125e-05]
2: TRAIN [1][1510/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 79268 (59852)	Loss/tok 3.3102 (3.3015)	Learning Rate [7.8125e-05]
3: TRAIN [1][1510/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00098)	Tok/s 79405 (60306)	Loss/tok 3.2450 (3.2989)	Learning Rate [7.8125e-05]
2: TRAIN [1][1520/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00093)	Tok/s 53355 (59807)	Loss/tok 3.2463 (3.3009)	Learning Rate [7.8125e-05]
1: TRAIN [1][1520/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00094)	Tok/s 53325 (59454)	Loss/tok 3.1040 (3.2999)	Learning Rate [7.8125e-05]
3: TRAIN [1][1520/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00098)	Tok/s 53967 (60263)	Loss/tok 3.0155 (3.2987)	Learning Rate [7.8125e-05]
0: TRAIN [1][1520/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00097)	Tok/s 53312 (59032)	Loss/tok 3.1419 (3.2973)	Learning Rate [7.8125e-05]
1: TRAIN [1][1530/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00094)	Tok/s 52360 (59427)	Loss/tok 3.2311 (3.2991)	Learning Rate [7.8125e-05]
2: TRAIN [1][1530/6832]	Time 0.081 (0.105)	Data 0.00086 (0.00093)	Tok/s 52919 (59786)	Loss/tok 3.2015 (3.3000)	Learning Rate [7.8125e-05]
0: TRAIN [1][1530/6832]	Time 0.081 (0.105)	Data 0.00092 (0.00097)	Tok/s 52335 (58989)	Loss/tok 3.0402 (3.2970)	Learning Rate [7.8125e-05]
3: TRAIN [1][1530/6832]	Time 0.081 (0.105)	Data 0.00092 (0.00098)	Tok/s 53896 (60247)	Loss/tok 3.2048 (3.2979)	Learning Rate [7.8125e-05]
2: TRAIN [1][1540/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00093)	Tok/s 60226 (59803)	Loss/tok 3.2331 (3.2998)	Learning Rate [7.8125e-05]
3: TRAIN [1][1540/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00098)	Tok/s 60217 (60262)	Loss/tok 3.4113 (3.2980)	Learning Rate [7.8125e-05]
1: TRAIN [1][1540/6832]	Time 0.123 (0.105)	Data 0.00086 (0.00094)	Tok/s 60161 (59444)	Loss/tok 3.3042 (3.2994)	Learning Rate [7.8125e-05]
0: TRAIN [1][1540/6832]	Time 0.123 (0.105)	Data 0.00095 (0.00097)	Tok/s 60169 (59007)	Loss/tok 3.3994 (3.2972)	Learning Rate [7.8125e-05]
2: TRAIN [1][1550/6832]	Time 0.062 (0.105)	Data 0.00094 (0.00093)	Tok/s 52249 (59818)	Loss/tok 2.9222 (3.2993)	Learning Rate [7.8125e-05]
3: TRAIN [1][1550/6832]	Time 0.062 (0.105)	Data 0.00102 (0.00098)	Tok/s 53307 (60276)	Loss/tok 2.8708 (3.2972)	Learning Rate [7.8125e-05]
1: TRAIN [1][1550/6832]	Time 0.063 (0.105)	Data 0.00093 (0.00094)	Tok/s 51193 (59459)	Loss/tok 3.0617 (3.2990)	Learning Rate [7.8125e-05]
0: TRAIN [1][1550/6832]	Time 0.063 (0.105)	Data 0.00092 (0.00097)	Tok/s 51118 (59023)	Loss/tok 2.9286 (3.2969)	Learning Rate [7.8125e-05]
1: TRAIN [1][1560/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 72115 (59447)	Loss/tok 3.5935 (3.2990)	Learning Rate [7.8125e-05]
0: TRAIN [1][1560/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00097)	Tok/s 72134 (59012)	Loss/tok 3.4544 (3.2966)	Learning Rate [7.8125e-05]
2: TRAIN [1][1560/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00093)	Tok/s 72362 (59805)	Loss/tok 3.4061 (3.2991)	Learning Rate [7.8125e-05]
3: TRAIN [1][1560/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00097)	Tok/s 72870 (60262)	Loss/tok 3.5135 (3.2968)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][1570/6832]	Time 0.099 (0.105)	Data 0.00098 (0.00093)	Tok/s 54265 (59785)	Loss/tok 3.1573 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1570/6832]	Time 0.099 (0.105)	Data 0.00095 (0.00094)	Tok/s 54273 (59426)	Loss/tok 3.4533 (3.2989)	Learning Rate [7.8125e-05]
3: TRAIN [1][1570/6832]	Time 0.099 (0.105)	Data 0.00101 (0.00098)	Tok/s 54244 (60241)	Loss/tok 3.2512 (3.2965)	Learning Rate [7.8125e-05]
0: TRAIN [1][1570/6832]	Time 0.099 (0.105)	Data 0.00102 (0.00097)	Tok/s 54270 (58992)	Loss/tok 3.3713 (3.2963)	Learning Rate [7.8125e-05]
2: TRAIN [1][1580/6832]	Time 0.106 (0.105)	Data 0.00092 (0.00093)	Tok/s 53109 (59769)	Loss/tok 3.1873 (3.2986)	Learning Rate [7.8125e-05]
1: TRAIN [1][1580/6832]	Time 0.106 (0.105)	Data 0.00094 (0.00094)	Tok/s 53111 (59410)	Loss/tok 3.3020 (3.2984)	Learning Rate [7.8125e-05]
3: TRAIN [1][1580/6832]	Time 0.106 (0.105)	Data 0.00097 (0.00098)	Tok/s 53116 (60224)	Loss/tok 3.2503 (3.2965)	Learning Rate [7.8125e-05]
0: TRAIN [1][1580/6832]	Time 0.106 (0.105)	Data 0.00094 (0.00097)	Tok/s 53031 (58977)	Loss/tok 3.2337 (3.2961)	Learning Rate [7.8125e-05]
2: TRAIN [1][1590/6832]	Time 0.123 (0.105)	Data 0.00099 (0.00093)	Tok/s 63585 (59779)	Loss/tok 3.4318 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1590/6832]	Time 0.123 (0.105)	Data 0.00096 (0.00094)	Tok/s 63091 (59420)	Loss/tok 3.5940 (3.2987)	Learning Rate [7.8125e-05]
0: TRAIN [1][1590/6832]	Time 0.123 (0.105)	Data 0.00102 (0.00097)	Tok/s 62500 (58989)	Loss/tok 3.3868 (3.2958)	Learning Rate [7.8125e-05]
3: TRAIN [1][1590/6832]	Time 0.123 (0.105)	Data 0.00097 (0.00098)	Tok/s 63601 (60233)	Loss/tok 3.3118 (3.2966)	Learning Rate [7.8125e-05]
2: TRAIN [1][1600/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 68641 (59779)	Loss/tok 3.3968 (3.2986)	Learning Rate [7.8125e-05]
3: TRAIN [1][1600/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00098)	Tok/s 69378 (60234)	Loss/tok 3.3577 (3.2971)	Learning Rate [7.8125e-05]
1: TRAIN [1][1600/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 68615 (59421)	Loss/tok 3.2693 (3.2986)	Learning Rate [7.8125e-05]
0: TRAIN [1][1600/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00097)	Tok/s 68642 (58991)	Loss/tok 3.2935 (3.2960)	Learning Rate [7.8125e-05]
2: TRAIN [1][1610/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00093)	Tok/s 63927 (59801)	Loss/tok 3.3474 (3.2994)	Learning Rate [7.8125e-05]
1: TRAIN [1][1610/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 63102 (59442)	Loss/tok 3.5160 (3.2991)	Learning Rate [7.8125e-05]
3: TRAIN [1][1610/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00098)	Tok/s 63896 (60254)	Loss/tok 3.2788 (3.2973)	Learning Rate [7.8125e-05]
0: TRAIN [1][1610/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00097)	Tok/s 62898 (59014)	Loss/tok 3.3360 (3.2966)	Learning Rate [7.8125e-05]
2: TRAIN [1][1620/6832]	Time 0.081 (0.105)	Data 0.00086 (0.00093)	Tok/s 53489 (59778)	Loss/tok 3.1449 (3.2992)	Learning Rate [7.8125e-05]
1: TRAIN [1][1620/6832]	Time 0.081 (0.105)	Data 0.00087 (0.00094)	Tok/s 53492 (59420)	Loss/tok 3.1132 (3.2991)	Learning Rate [7.8125e-05]
0: TRAIN [1][1620/6832]	Time 0.081 (0.105)	Data 0.00088 (0.00097)	Tok/s 53483 (58992)	Loss/tok 3.2472 (3.2965)	Learning Rate [7.8125e-05]
3: TRAIN [1][1620/6832]	Time 0.081 (0.105)	Data 0.00101 (0.00098)	Tok/s 54094 (60230)	Loss/tok 3.1034 (3.2975)	Learning Rate [7.8125e-05]
2: TRAIN [1][1630/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00093)	Tok/s 56086 (59748)	Loss/tok 3.1702 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1630/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00094)	Tok/s 56068 (59390)	Loss/tok 3.5645 (3.2989)	Learning Rate [7.8125e-05]
0: TRAIN [1][1630/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00097)	Tok/s 55677 (58963)	Loss/tok 3.3041 (3.2961)	Learning Rate [7.8125e-05]
3: TRAIN [1][1630/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00098)	Tok/s 56076 (60199)	Loss/tok 3.2435 (3.2977)	Learning Rate [7.8125e-05]
1: TRAIN [1][1640/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00094)	Tok/s 53025 (59405)	Loss/tok 3.0652 (3.2986)	Learning Rate [7.8125e-05]
0: TRAIN [1][1640/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00097)	Tok/s 53033 (58979)	Loss/tok 3.2932 (3.2962)	Learning Rate [7.8125e-05]
2: TRAIN [1][1640/6832]	Time 0.097 (0.105)	Data 0.00086 (0.00093)	Tok/s 52989 (59762)	Loss/tok 3.3543 (3.2987)	Learning Rate [7.8125e-05]
3: TRAIN [1][1640/6832]	Time 0.097 (0.105)	Data 0.00103 (0.00098)	Tok/s 53653 (60214)	Loss/tok 3.0763 (3.2978)	Learning Rate [7.8125e-05]
1: TRAIN [1][1650/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00094)	Tok/s 53425 (59406)	Loss/tok 3.3715 (3.2987)	Learning Rate [7.8125e-05]
2: TRAIN [1][1650/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00093)	Tok/s 54202 (59762)	Loss/tok 3.2535 (3.2988)	Learning Rate [7.8125e-05]
0: TRAIN [1][1650/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00097)	Tok/s 53411 (58980)	Loss/tok 3.2199 (3.2961)	Learning Rate [7.8125e-05]
3: TRAIN [1][1650/6832]	Time 0.115 (0.105)	Data 0.00099 (0.00098)	Tok/s 54524 (60213)	Loss/tok 3.1370 (3.2976)	Learning Rate [7.8125e-05]
2: TRAIN [1][1660/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00093)	Tok/s 53595 (59793)	Loss/tok 3.1178 (3.2990)	Learning Rate [7.8125e-05]
1: TRAIN [1][1660/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00094)	Tok/s 53172 (59437)	Loss/tok 3.2314 (3.2988)	Learning Rate [7.8125e-05]
0: TRAIN [1][1660/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00097)	Tok/s 52214 (59011)	Loss/tok 3.1854 (3.2968)	Learning Rate [7.8125e-05]
3: TRAIN [1][1660/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00098)	Tok/s 53605 (60245)	Loss/tok 3.3120 (3.2977)	Learning Rate [7.8125e-05]
1: TRAIN [1][1670/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00094)	Tok/s 54201 (59426)	Loss/tok 3.3235 (3.2987)	Learning Rate [7.8125e-05]
0: TRAIN [1][1670/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00096)	Tok/s 54224 (58995)	Loss/tok 3.3162 (3.2967)	Learning Rate [7.8125e-05]
2: TRAIN [1][1670/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00093)	Tok/s 54138 (59783)	Loss/tok 3.2259 (3.2992)	Learning Rate [7.8125e-05]
3: TRAIN [1][1670/6832]	Time 0.092 (0.105)	Data 0.00095 (0.00098)	Tok/s 54172 (60234)	Loss/tok 3.1680 (3.2979)	Learning Rate [7.8125e-05]
1: TRAIN [1][1680/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00094)	Tok/s 59861 (59402)	Loss/tok 3.4002 (3.2985)	Learning Rate [7.8125e-05]
2: TRAIN [1][1680/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00093)	Tok/s 59815 (59759)	Loss/tok 3.2511 (3.2992)	Learning Rate [7.8125e-05]
0: TRAIN [1][1680/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00096)	Tok/s 59832 (58973)	Loss/tok 3.3279 (3.2966)	Learning Rate [7.8125e-05]
3: TRAIN [1][1680/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00098)	Tok/s 59817 (60209)	Loss/tok 3.1702 (3.2977)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: TRAIN [1][1690/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00096)	Tok/s 51179 (58978)	Loss/tok 3.2586 (3.2971)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
2: TRAIN [1][1690/6832]	Time 0.105 (0.105)	Data 0.00088 (0.00093)	Tok/s 51112 (59761)	Loss/tok 3.2229 (3.2997)	Learning Rate [7.8125e-05]
1: TRAIN [1][1690/6832]	Time 0.105 (0.105)	Data 0.00088 (0.00094)	Tok/s 51092 (59405)	Loss/tok 3.2483 (3.2990)	Learning Rate [7.8125e-05]
3: TRAIN [1][1690/6832]	Time 0.105 (0.105)	Data 0.00101 (0.00098)	Tok/s 51217 (60210)	Loss/tok 3.2919 (3.2978)	Learning Rate [7.8125e-05]
2: TRAIN [1][1700/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00093)	Tok/s 54998 (59734)	Loss/tok 3.3010 (3.2996)	Learning Rate [7.8125e-05]
1: TRAIN [1][1700/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00093)	Tok/s 53963 (59377)	Loss/tok 3.2827 (3.2987)	Learning Rate [7.8125e-05]
0: TRAIN [1][1700/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00096)	Tok/s 53960 (58952)	Loss/tok 3.3470 (3.2970)	Learning Rate [7.8125e-05]
3: TRAIN [1][1700/6832]	Time 0.119 (0.105)	Data 0.00108 (0.00098)	Tok/s 55072 (60183)	Loss/tok 3.2131 (3.2974)	Learning Rate [7.8125e-05]
1: TRAIN [1][1710/6832]	Time 0.083 (0.105)	Data 0.00092 (0.00093)	Tok/s 53958 (59375)	Loss/tok 3.1113 (3.2985)	Learning Rate [7.8125e-05]
2: TRAIN [1][1710/6832]	Time 0.083 (0.105)	Data 0.00086 (0.00093)	Tok/s 53904 (59732)	Loss/tok 3.2229 (3.2993)	Learning Rate [7.8125e-05]
0: TRAIN [1][1710/6832]	Time 0.083 (0.105)	Data 0.00091 (0.00096)	Tok/s 53043 (58948)	Loss/tok 3.0627 (3.2970)	Learning Rate [7.8125e-05]
3: TRAIN [1][1710/6832]	Time 0.083 (0.105)	Data 0.00091 (0.00098)	Tok/s 53937 (60182)	Loss/tok 3.3060 (3.2974)	Learning Rate [7.8125e-05]
2: TRAIN [1][1720/6832]	Time 0.048 (0.105)	Data 0.00083 (0.00093)	Tok/s 45536 (59741)	Loss/tok 2.4312 (3.2996)	Learning Rate [7.8125e-05]
1: TRAIN [1][1720/6832]	Time 0.048 (0.105)	Data 0.00088 (0.00093)	Tok/s 44015 (59383)	Loss/tok 2.5222 (3.2986)	Learning Rate [7.8125e-05]
0: TRAIN [1][1720/6832]	Time 0.048 (0.105)	Data 0.00088 (0.00096)	Tok/s 41542 (58956)	Loss/tok 2.3807 (3.2968)	Learning Rate [7.8125e-05]
3: TRAIN [1][1720/6832]	Time 0.048 (0.105)	Data 0.00089 (0.00098)	Tok/s 48154 (60192)	Loss/tok 2.5037 (3.2972)	Learning Rate [7.8125e-05]
2: TRAIN [1][1730/6832]	Time 0.054 (0.105)	Data 0.00085 (0.00093)	Tok/s 49564 (59761)	Loss/tok 2.5994 (3.2993)	Learning Rate [7.8125e-05]
1: TRAIN [1][1730/6832]	Time 0.054 (0.105)	Data 0.00110 (0.00093)	Tok/s 48102 (59401)	Loss/tok 2.6706 (3.2986)	Learning Rate [7.8125e-05]
0: TRAIN [1][1730/6832]	Time 0.054 (0.105)	Data 0.00106 (0.00096)	Tok/s 47336 (58975)	Loss/tok 2.6977 (3.2963)	Learning Rate [7.8125e-05]
3: TRAIN [1][1730/6832]	Time 0.054 (0.105)	Data 0.00090 (0.00098)	Tok/s 49624 (60212)	Loss/tok 2.6901 (3.2971)	Learning Rate [7.8125e-05]
0: TRAIN [1][1740/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 62058 (58936)	Loss/tok 3.4406 (3.2964)	Learning Rate [7.8125e-05]
1: TRAIN [1][1740/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 62038 (59366)	Loss/tok 3.5368 (3.2988)	Learning Rate [7.8125e-05]
2: TRAIN [1][1740/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00093)	Tok/s 62057 (59727)	Loss/tok 3.3344 (3.2993)	Learning Rate [7.8125e-05]
3: TRAIN [1][1740/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00098)	Tok/s 62068 (60178)	Loss/tok 3.4751 (3.2970)	Learning Rate [7.8125e-05]
2: TRAIN [1][1750/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00093)	Tok/s 88011 (59742)	Loss/tok 3.1408 (3.2993)	Learning Rate [7.8125e-05]
0: TRAIN [1][1750/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00096)	Tok/s 86940 (58951)	Loss/tok 3.3546 (3.2965)	Learning Rate [7.8125e-05]
1: TRAIN [1][1750/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00093)	Tok/s 87442 (59381)	Loss/tok 3.2236 (3.2986)	Learning Rate [7.8125e-05]
3: TRAIN [1][1750/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00098)	Tok/s 88960 (60195)	Loss/tok 3.2085 (3.2970)	Learning Rate [7.8125e-05]
2: TRAIN [1][1760/6832]	Time 0.076 (0.105)	Data 0.00094 (0.00093)	Tok/s 52038 (59749)	Loss/tok 3.1276 (3.2994)	Learning Rate [7.8125e-05]
1: TRAIN [1][1760/6832]	Time 0.076 (0.105)	Data 0.00093 (0.00093)	Tok/s 51971 (59389)	Loss/tok 3.0395 (3.2981)	Learning Rate [7.8125e-05]
0: TRAIN [1][1760/6832]	Time 0.076 (0.105)	Data 0.00091 (0.00096)	Tok/s 51965 (58959)	Loss/tok 3.1165 (3.2962)	Learning Rate [7.8125e-05]
3: TRAIN [1][1760/6832]	Time 0.076 (0.105)	Data 0.00096 (0.00098)	Tok/s 53045 (60202)	Loss/tok 3.1073 (3.2971)	Learning Rate [7.8125e-05]
1: TRAIN [1][1770/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00093)	Tok/s 59112 (59413)	Loss/tok 3.5277 (3.2985)	Learning Rate [7.8125e-05]
0: TRAIN [1][1770/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00096)	Tok/s 58426 (58984)	Loss/tok 3.4165 (3.2960)	Learning Rate [7.8125e-05]
2: TRAIN [1][1770/6832]	Time 0.127 (0.105)	Data 0.00099 (0.00093)	Tok/s 59633 (59772)	Loss/tok 3.5030 (3.2997)	Learning Rate [7.8125e-05]
3: TRAIN [1][1770/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00098)	Tok/s 59354 (60226)	Loss/tok 3.4238 (3.2970)	Learning Rate [7.8125e-05]
2: TRAIN [1][1780/6832]	Time 0.125 (0.105)	Data 0.00085 (0.00093)	Tok/s 58129 (59757)	Loss/tok 3.3349 (3.2999)	Learning Rate [7.8125e-05]
1: TRAIN [1][1780/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00093)	Tok/s 57327 (59399)	Loss/tok 3.4493 (3.2988)	Learning Rate [7.8125e-05]
0: TRAIN [1][1780/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00096)	Tok/s 57335 (58971)	Loss/tok 3.2123 (3.2963)	Learning Rate [7.8125e-05]
3: TRAIN [1][1780/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00098)	Tok/s 58390 (60209)	Loss/tok 3.3983 (3.2974)	Learning Rate [7.8125e-05]
1: TRAIN [1][1790/6832]	Time 0.058 (0.105)	Data 0.00089 (0.00093)	Tok/s 52857 (59391)	Loss/tok 2.8713 (3.2987)	Learning Rate [7.8125e-05]
2: TRAIN [1][1790/6832]	Time 0.058 (0.105)	Data 0.00084 (0.00093)	Tok/s 52834 (59750)	Loss/tok 2.8455 (3.2995)	Learning Rate [7.8125e-05]
0: TRAIN [1][1790/6832]	Time 0.058 (0.105)	Data 0.00088 (0.00096)	Tok/s 52853 (58963)	Loss/tok 2.8682 (3.2961)	Learning Rate [7.8125e-05]
3: TRAIN [1][1790/6832]	Time 0.058 (0.105)	Data 0.00091 (0.00098)	Tok/s 54740 (60202)	Loss/tok 2.8809 (3.2975)	Learning Rate [7.8125e-05]
2: TRAIN [1][1800/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00093)	Tok/s 81927 (59738)	Loss/tok 3.1511 (3.2989)	Learning Rate [7.8125e-05]
1: TRAIN [1][1800/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00093)	Tok/s 81594 (59380)	Loss/tok 3.4033 (3.2983)	Learning Rate [7.8125e-05]
0: TRAIN [1][1800/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00096)	Tok/s 81337 (58952)	Loss/tok 3.2662 (3.2955)	Learning Rate [7.8125e-05]
3: TRAIN [1][1800/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00098)	Tok/s 82599 (60193)	Loss/tok 3.2481 (3.2970)	Learning Rate [7.8125e-05]
2: TRAIN [1][1810/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00093)	Tok/s 62524 (59800)	Loss/tok 3.4287 (3.2996)	Learning Rate [7.8125e-05]
1: TRAIN [1][1810/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00093)	Tok/s 61518 (59441)	Loss/tok 3.3222 (3.2981)	Learning Rate [7.8125e-05]
0: TRAIN [1][1810/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00096)	Tok/s 61518 (59013)	Loss/tok 3.5443 (3.2959)	Learning Rate [7.8125e-05]
3: TRAIN [1][1810/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00098)	Tok/s 62539 (60255)	Loss/tok 3.5600 (3.2969)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [1][1820/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00093)	Tok/s 71326 (59429)	Loss/tok 3.3258 (3.2979)	Learning Rate [7.8125e-05]
0: TRAIN [1][1820/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00096)	Tok/s 71320 (59002)	Loss/tok 3.5386 (3.2959)	Learning Rate [7.8125e-05]
2: TRAIN [1][1820/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 72136 (59788)	Loss/tok 3.3072 (3.2992)	Learning Rate [7.8125e-05]
3: TRAIN [1][1820/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00098)	Tok/s 72232 (60243)	Loss/tok 3.4853 (3.2970)	Learning Rate [7.8125e-05]
1: TRAIN [1][1830/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00093)	Tok/s 72964 (59420)	Loss/tok 3.3546 (3.2977)	Learning Rate [7.8125e-05]
0: TRAIN [1][1830/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 72236 (58993)	Loss/tok 3.4320 (3.2959)	Learning Rate [7.8125e-05]
2: TRAIN [1][1830/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00093)	Tok/s 73213 (59778)	Loss/tok 3.4132 (3.2992)	Learning Rate [7.8125e-05]
3: TRAIN [1][1830/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00098)	Tok/s 73204 (60233)	Loss/tok 3.3718 (3.2970)	Learning Rate [7.8125e-05]
2: TRAIN [1][1840/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 76981 (59808)	Loss/tok 3.4421 (3.2993)	Learning Rate [7.8125e-05]
1: TRAIN [1][1840/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00093)	Tok/s 76762 (59451)	Loss/tok 3.3310 (3.2980)	Learning Rate [7.8125e-05]
0: TRAIN [1][1840/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00096)	Tok/s 76562 (59025)	Loss/tok 3.3068 (3.2961)	Learning Rate [7.8125e-05]
3: TRAIN [1][1840/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00098)	Tok/s 77887 (60262)	Loss/tok 3.3194 (3.2973)	Learning Rate [7.8125e-05]
1: TRAIN [1][1850/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00093)	Tok/s 80025 (59450)	Loss/tok 3.2314 (3.2976)	Learning Rate [7.8125e-05]
0: TRAIN [1][1850/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00096)	Tok/s 79524 (59023)	Loss/tok 3.2582 (3.2959)	Learning Rate [7.8125e-05]
2: TRAIN [1][1850/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00093)	Tok/s 80250 (59806)	Loss/tok 3.3813 (3.2995)	Learning Rate [7.8125e-05]
3: TRAIN [1][1850/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00098)	Tok/s 80898 (60262)	Loss/tok 3.2704 (3.2974)	Learning Rate [7.8125e-05]
2: TRAIN [1][1860/6832]	Time 0.092 (0.106)	Data 0.00098 (0.00093)	Tok/s 52765 (59848)	Loss/tok 3.4138 (3.3000)	Learning Rate [7.8125e-05]
1: TRAIN [1][1860/6832]	Time 0.092 (0.106)	Data 0.00092 (0.00093)	Tok/s 52791 (59492)	Loss/tok 3.2791 (3.2979)	Learning Rate [7.8125e-05]
0: TRAIN [1][1860/6832]	Time 0.092 (0.106)	Data 0.00095 (0.00096)	Tok/s 52049 (59066)	Loss/tok 3.1078 (3.2963)	Learning Rate [7.8125e-05]
3: TRAIN [1][1860/6832]	Time 0.092 (0.106)	Data 0.00107 (0.00098)	Tok/s 52785 (60303)	Loss/tok 3.2040 (3.2976)	Learning Rate [7.8125e-05]
2: TRAIN [1][1870/6832]	Time 0.101 (0.106)	Data 0.00085 (0.00093)	Tok/s 52046 (59861)	Loss/tok 3.1108 (3.2998)	Learning Rate [7.8125e-05]
1: TRAIN [1][1870/6832]	Time 0.101 (0.106)	Data 0.00091 (0.00093)	Tok/s 52045 (59506)	Loss/tok 3.3419 (3.2978)	Learning Rate [7.8125e-05]
0: TRAIN [1][1870/6832]	Time 0.101 (0.106)	Data 0.00087 (0.00096)	Tok/s 52019 (59080)	Loss/tok 3.2907 (3.2965)	Learning Rate [7.8125e-05]
3: TRAIN [1][1870/6832]	Time 0.101 (0.106)	Data 0.00092 (0.00098)	Tok/s 52065 (60316)	Loss/tok 3.2803 (3.2977)	Learning Rate [7.8125e-05]
1: TRAIN [1][1880/6832]	Time 0.080 (0.106)	Data 0.00088 (0.00093)	Tok/s 52715 (59486)	Loss/tok 3.1558 (3.2975)	Learning Rate [7.8125e-05]
2: TRAIN [1][1880/6832]	Time 0.080 (0.106)	Data 0.00085 (0.00093)	Tok/s 52815 (59843)	Loss/tok 3.0042 (3.2997)	Learning Rate [7.8125e-05]
0: TRAIN [1][1880/6832]	Time 0.080 (0.106)	Data 0.00089 (0.00096)	Tok/s 52697 (59061)	Loss/tok 3.1196 (3.2965)	Learning Rate [7.8125e-05]
3: TRAIN [1][1880/6832]	Time 0.080 (0.106)	Data 0.00089 (0.00098)	Tok/s 54303 (60300)	Loss/tok 3.1640 (3.2977)	Learning Rate [7.8125e-05]
2: TRAIN [1][1890/6832]	Time 0.080 (0.105)	Data 0.00084 (0.00093)	Tok/s 52966 (59815)	Loss/tok 3.0692 (3.2999)	Learning Rate [7.8125e-05]
1: TRAIN [1][1890/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00093)	Tok/s 51372 (59455)	Loss/tok 3.0486 (3.2972)	Learning Rate [7.8125e-05]
0: TRAIN [1][1890/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00096)	Tok/s 51332 (59026)	Loss/tok 3.0507 (3.2960)	Learning Rate [7.8125e-05]
3: TRAIN [1][1890/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00098)	Tok/s 52974 (60274)	Loss/tok 3.1115 (3.2975)	Learning Rate [7.8125e-05]
2: TRAIN [1][1900/6832]	Time 0.117 (0.105)	Data 0.00083 (0.00093)	Tok/s 55939 (59806)	Loss/tok 3.3672 (3.3000)	Learning Rate [7.8125e-05]
1: TRAIN [1][1900/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00093)	Tok/s 55489 (59448)	Loss/tok 3.1761 (3.2974)	Learning Rate [7.8125e-05]
3: TRAIN [1][1900/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00098)	Tok/s 55933 (60263)	Loss/tok 3.3366 (3.2976)	Learning Rate [7.8125e-05]
0: TRAIN [1][1900/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00096)	Tok/s 54888 (59020)	Loss/tok 3.4110 (3.2961)	Learning Rate [7.8125e-05]
2: TRAIN [1][1910/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00093)	Tok/s 52999 (59805)	Loss/tok 3.1405 (3.2998)	Learning Rate [7.8125e-05]
1: TRAIN [1][1910/6832]	Time 0.082 (0.105)	Data 0.00095 (0.00093)	Tok/s 52179 (59448)	Loss/tok 3.0281 (3.2973)	Learning Rate [7.8125e-05]
0: TRAIN [1][1910/6832]	Time 0.082 (0.105)	Data 0.00092 (0.00096)	Tok/s 51421 (59019)	Loss/tok 3.0101 (3.2961)	Learning Rate [7.8125e-05]
3: TRAIN [1][1910/6832]	Time 0.082 (0.105)	Data 0.00099 (0.00098)	Tok/s 53008 (60261)	Loss/tok 3.1520 (3.2974)	Learning Rate [7.8125e-05]
1: TRAIN [1][1920/6832]	Time 0.055 (0.105)	Data 0.00091 (0.00093)	Tok/s 50989 (59437)	Loss/tok 2.8711 (3.2967)	Learning Rate [7.8125e-05]
2: TRAIN [1][1920/6832]	Time 0.055 (0.105)	Data 0.00086 (0.00093)	Tok/s 50953 (59795)	Loss/tok 2.8452 (3.2993)	Learning Rate [7.8125e-05]
0: TRAIN [1][1920/6832]	Time 0.055 (0.105)	Data 0.00087 (0.00096)	Tok/s 49883 (59007)	Loss/tok 2.6454 (3.2958)	Learning Rate [7.8125e-05]
3: TRAIN [1][1920/6832]	Time 0.055 (0.105)	Data 0.00099 (0.00098)	Tok/s 51727 (60250)	Loss/tok 2.9344 (3.2971)	Learning Rate [7.8125e-05]
2: TRAIN [1][1930/6832]	Time 0.080 (0.105)	Data 0.00086 (0.00093)	Tok/s 54483 (59788)	Loss/tok 3.0769 (3.2990)	Learning Rate [7.8125e-05]
1: TRAIN [1][1930/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00093)	Tok/s 53151 (59430)	Loss/tok 3.0862 (3.2969)	Learning Rate [7.8125e-05]
0: TRAIN [1][1930/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00096)	Tok/s 53130 (59000)	Loss/tok 3.1374 (3.2956)	Learning Rate [7.8125e-05]
3: TRAIN [1][1930/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00098)	Tok/s 54736 (60242)	Loss/tok 2.8887 (3.2969)	Learning Rate [7.8125e-05]
2: TRAIN [1][1940/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00093)	Tok/s 54168 (59768)	Loss/tok 3.3177 (3.2991)	Learning Rate [7.8125e-05]
1: TRAIN [1][1940/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00093)	Tok/s 53301 (59410)	Loss/tok 3.3784 (3.2968)	Learning Rate [7.8125e-05]
0: TRAIN [1][1940/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00096)	Tok/s 53051 (58981)	Loss/tok 3.3673 (3.2955)	Learning Rate [7.8125e-05]
3: TRAIN [1][1940/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00098)	Tok/s 54166 (60222)	Loss/tok 3.3146 (3.2971)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][1950/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00093)	Tok/s 56027 (59760)	Loss/tok 3.1928 (3.2992)	Learning Rate [7.8125e-05]
1: TRAIN [1][1950/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00093)	Tok/s 56012 (59402)	Loss/tok 3.5673 (3.2968)	Learning Rate [7.8125e-05]
0: TRAIN [1][1950/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00096)	Tok/s 55975 (58975)	Loss/tok 3.2910 (3.2953)	Learning Rate [7.8125e-05]
3: TRAIN [1][1950/6832]	Time 0.101 (0.105)	Data 0.00097 (0.00098)	Tok/s 56640 (60215)	Loss/tok 3.2905 (3.2970)	Learning Rate [7.8125e-05]
2: TRAIN [1][1960/6832]	Time 0.042 (0.105)	Data 0.00084 (0.00093)	Tok/s 39573 (59767)	Loss/tok 2.0416 (3.2991)	Learning Rate [7.8125e-05]
1: TRAIN [1][1960/6832]	Time 0.042 (0.105)	Data 0.00088 (0.00093)	Tok/s 33704 (59407)	Loss/tok 2.0719 (3.2968)	Learning Rate [7.8125e-05]
0: TRAIN [1][1960/6832]	Time 0.042 (0.105)	Data 0.00088 (0.00096)	Tok/s 22009 (58974)	Loss/tok 1.7944 (3.2953)	Learning Rate [7.8125e-05]
3: TRAIN [1][1960/6832]	Time 0.042 (0.105)	Data 0.00092 (0.00098)	Tok/s 43553 (60224)	Loss/tok 2.3585 (3.2969)	Learning Rate [7.8125e-05]
2: TRAIN [1][1970/6832]	Time 0.057 (0.105)	Data 0.00084 (0.00093)	Tok/s 52563 (59755)	Loss/tok 3.0772 (3.2989)	Learning Rate [7.8125e-05]
1: TRAIN [1][1970/6832]	Time 0.057 (0.105)	Data 0.00090 (0.00093)	Tok/s 51916 (59395)	Loss/tok 2.8531 (3.2965)	Learning Rate [7.8125e-05]
0: TRAIN [1][1970/6832]	Time 0.057 (0.105)	Data 0.00088 (0.00096)	Tok/s 51909 (58964)	Loss/tok 2.9539 (3.2954)	Learning Rate [7.8125e-05]
3: TRAIN [1][1970/6832]	Time 0.057 (0.105)	Data 0.00090 (0.00098)	Tok/s 54183 (60212)	Loss/tok 3.0228 (3.2970)	Learning Rate [7.8125e-05]
2: TRAIN [1][1980/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 63589 (59757)	Loss/tok 3.3761 (3.2987)	Learning Rate [7.8125e-05]
1: TRAIN [1][1980/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 63499 (59398)	Loss/tok 3.4255 (3.2964)	Learning Rate [7.8125e-05]
0: TRAIN [1][1980/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00096)	Tok/s 63485 (58967)	Loss/tok 3.3202 (3.2952)	Learning Rate [7.8125e-05]
3: TRAIN [1][1980/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00098)	Tok/s 64340 (60214)	Loss/tok 3.5206 (3.2972)	Learning Rate [7.8125e-05]
2: TRAIN [1][1990/6832]	Time 0.079 (0.105)	Data 0.00083 (0.00093)	Tok/s 53370 (59771)	Loss/tok 3.1437 (3.2988)	Learning Rate [7.8125e-05]
1: TRAIN [1][1990/6832]	Time 0.079 (0.105)	Data 0.00089 (0.00093)	Tok/s 52640 (59412)	Loss/tok 3.0486 (3.2965)	Learning Rate [7.8125e-05]
0: TRAIN [1][1990/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00096)	Tok/s 51703 (58982)	Loss/tok 3.1011 (3.2953)	Learning Rate [7.8125e-05]
3: TRAIN [1][1990/6832]	Time 0.079 (0.105)	Data 0.00091 (0.00098)	Tok/s 53374 (60228)	Loss/tok 3.0869 (3.2971)	Learning Rate [7.8125e-05]
1: TRAIN [1][2000/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00093)	Tok/s 54645 (59393)	Loss/tok 3.3358 (3.2967)	Learning Rate [7.8125e-05]
2: TRAIN [1][2000/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00093)	Tok/s 54697 (59751)	Loss/tok 3.4791 (3.2987)	Learning Rate [7.8125e-05]
0: TRAIN [1][2000/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00096)	Tok/s 54654 (58964)	Loss/tok 3.2209 (3.2951)	Learning Rate [7.8125e-05]
3: TRAIN [1][2000/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00098)	Tok/s 54716 (60208)	Loss/tok 3.2336 (3.2969)	Learning Rate [7.8125e-05]
2: TRAIN [1][2010/6832]	Time 0.071 (0.105)	Data 0.00085 (0.00093)	Tok/s 48434 (59780)	Loss/tok 3.0214 (3.2983)	Learning Rate [7.8125e-05]
1: TRAIN [1][2010/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00093)	Tok/s 48411 (59422)	Loss/tok 2.9802 (3.2963)	Learning Rate [7.8125e-05]
0: TRAIN [1][2010/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00096)	Tok/s 48408 (58993)	Loss/tok 3.0656 (3.2946)	Learning Rate [7.8125e-05]
3: TRAIN [1][2010/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00098)	Tok/s 49233 (60237)	Loss/tok 2.9935 (3.2962)	Learning Rate [7.8125e-05]
2: TRAIN [1][2020/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00093)	Tok/s 57232 (59765)	Loss/tok 3.1417 (3.2980)	Learning Rate [7.8125e-05]
3: TRAIN [1][2020/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00098)	Tok/s 58204 (60222)	Loss/tok 3.2581 (3.2961)	Learning Rate [7.8125e-05]
1: TRAIN [1][2020/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00093)	Tok/s 57062 (59406)	Loss/tok 3.1640 (3.2960)	Learning Rate [7.8125e-05]
0: TRAIN [1][2020/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00096)	Tok/s 57044 (58977)	Loss/tok 3.3455 (3.2944)	Learning Rate [7.8125e-05]
2: TRAIN [1][2030/6832]	Time 0.047 (0.105)	Data 0.00090 (0.00093)	Tok/s 46160 (59761)	Loss/tok 2.2765 (3.2982)	Learning Rate [7.8125e-05]
1: TRAIN [1][2030/6832]	Time 0.047 (0.105)	Data 0.00092 (0.00093)	Tok/s 44292 (59401)	Loss/tok 2.5035 (3.2959)	Learning Rate [7.8125e-05]
0: TRAIN [1][2030/6832]	Time 0.047 (0.105)	Data 0.00089 (0.00096)	Tok/s 42110 (58972)	Loss/tok 2.4155 (3.2942)	Learning Rate [7.8125e-05]
3: TRAIN [1][2030/6832]	Time 0.047 (0.105)	Data 0.00092 (0.00098)	Tok/s 47537 (60218)	Loss/tok 2.3375 (3.2960)	Learning Rate [7.8125e-05]
1: TRAIN [1][2040/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00093)	Tok/s 65290 (59380)	Loss/tok 3.4924 (3.2958)	Learning Rate [7.8125e-05]
0: TRAIN [1][2040/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00096)	Tok/s 65304 (58947)	Loss/tok 3.2934 (3.2938)	Learning Rate [7.8125e-05]
3: TRAIN [1][2040/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00098)	Tok/s 65308 (60199)	Loss/tok 3.4329 (3.2958)	Learning Rate [7.8125e-05]
2: TRAIN [1][2040/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00093)	Tok/s 65223 (59740)	Loss/tok 3.3024 (3.2979)	Learning Rate [7.8125e-05]
2: TRAIN [1][2050/6832]	Time 0.112 (0.105)	Data 0.00096 (0.00093)	Tok/s 51324 (59730)	Loss/tok 3.2478 (3.2978)	Learning Rate [7.8125e-05]
1: TRAIN [1][2050/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00093)	Tok/s 51141 (59369)	Loss/tok 3.2073 (3.2958)	Learning Rate [7.8125e-05]
0: TRAIN [1][2050/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00096)	Tok/s 51169 (58937)	Loss/tok 3.2337 (3.2939)	Learning Rate [7.8125e-05]
3: TRAIN [1][2050/6832]	Time 0.112 (0.105)	Data 0.00096 (0.00098)	Tok/s 51330 (60187)	Loss/tok 3.2526 (3.2957)	Learning Rate [7.8125e-05]
2: TRAIN [1][2060/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00093)	Tok/s 61130 (59735)	Loss/tok 3.3550 (3.2979)	Learning Rate [7.8125e-05]
1: TRAIN [1][2060/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00093)	Tok/s 60888 (59375)	Loss/tok 3.3584 (3.2960)	Learning Rate [7.8125e-05]
3: TRAIN [1][2060/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00098)	Tok/s 62019 (60192)	Loss/tok 3.4461 (3.2962)	Learning Rate [7.8125e-05]
0: TRAIN [1][2060/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00096)	Tok/s 60890 (58944)	Loss/tok 3.3989 (3.2940)	Learning Rate [7.8125e-05]
1: TRAIN [1][2070/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00093)	Tok/s 58030 (59345)	Loss/tok 3.2443 (3.2955)	Learning Rate [7.8125e-05]
0: TRAIN [1][2070/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00096)	Tok/s 58032 (58910)	Loss/tok 3.3782 (3.2936)	Learning Rate [7.8125e-05]
2: TRAIN [1][2070/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00093)	Tok/s 57949 (59706)	Loss/tok 3.3846 (3.2973)	Learning Rate [7.8125e-05]
3: TRAIN [1][2070/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00098)	Tok/s 58727 (60166)	Loss/tok 3.2883 (3.2956)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [1][2080/6832]	Time 0.053 (0.105)	Data 0.00091 (0.00093)	Tok/s 44912 (59316)	Loss/tok 2.5917 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2080/6832]	Time 0.053 (0.105)	Data 0.00089 (0.00096)	Tok/s 43632 (58875)	Loss/tok 2.5386 (3.2934)	Learning Rate [7.8125e-05]
2: TRAIN [1][2080/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00093)	Tok/s 46040 (59679)	Loss/tok 2.6619 (3.2971)	Learning Rate [7.8125e-05]
3: TRAIN [1][2080/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00098)	Tok/s 47738 (60140)	Loss/tok 2.6142 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2090/6832]	Time 0.093 (0.105)	Data 0.00116 (0.00093)	Tok/s 53746 (59683)	Loss/tok 3.1563 (3.2970)	Learning Rate [7.8125e-05]
1: TRAIN [1][2090/6832]	Time 0.093 (0.105)	Data 0.00089 (0.00093)	Tok/s 53456 (59321)	Loss/tok 3.3554 (3.2952)	Learning Rate [7.8125e-05]
0: TRAIN [1][2090/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00096)	Tok/s 53441 (58880)	Loss/tok 3.2301 (3.2936)	Learning Rate [7.8125e-05]
3: TRAIN [1][2090/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00098)	Tok/s 53464 (60144)	Loss/tok 3.2471 (3.2950)	Learning Rate [7.8125e-05]
1: TRAIN [1][2100/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00093)	Tok/s 53268 (59314)	Loss/tok 3.5156 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2100/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00093)	Tok/s 53325 (59675)	Loss/tok 3.0767 (3.2967)	Learning Rate [7.8125e-05]
0: TRAIN [1][2100/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00096)	Tok/s 53282 (58873)	Loss/tok 3.0818 (3.2934)	Learning Rate [7.8125e-05]
3: TRAIN [1][2100/6832]	Time 0.091 (0.105)	Data 0.00091 (0.00098)	Tok/s 53322 (60136)	Loss/tok 3.1238 (3.2947)	Learning Rate [7.8125e-05]
1: TRAIN [1][2110/6832]	Time 0.083 (0.105)	Data 0.00101 (0.00093)	Tok/s 50944 (59325)	Loss/tok 3.0460 (3.2951)	Learning Rate [7.8125e-05]
0: TRAIN [1][2110/6832]	Time 0.083 (0.105)	Data 0.00100 (0.00096)	Tok/s 50942 (58886)	Loss/tok 2.8312 (3.2935)	Learning Rate [7.8125e-05]
2: TRAIN [1][2110/6832]	Time 0.083 (0.105)	Data 0.00095 (0.00093)	Tok/s 51571 (59687)	Loss/tok 3.0428 (3.2967)	Learning Rate [7.8125e-05]
3: TRAIN [1][2110/6832]	Time 0.083 (0.105)	Data 0.00098 (0.00098)	Tok/s 52552 (60147)	Loss/tok 3.1701 (3.2949)	Learning Rate [7.8125e-05]
1: TRAIN [1][2120/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00093)	Tok/s 53256 (59319)	Loss/tok 3.1983 (3.2954)	Learning Rate [7.8125e-05]
2: TRAIN [1][2120/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00093)	Tok/s 53222 (59681)	Loss/tok 3.3153 (3.2970)	Learning Rate [7.8125e-05]
0: TRAIN [1][2120/6832]	Time 0.091 (0.105)	Data 0.00089 (0.00096)	Tok/s 53218 (58881)	Loss/tok 3.1616 (3.2936)	Learning Rate [7.8125e-05]
3: TRAIN [1][2120/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00098)	Tok/s 54250 (60140)	Loss/tok 3.3230 (3.2952)	Learning Rate [7.8125e-05]
1: Gradient norm: inf
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][2130/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00093)	Tok/s 92213 (59342)	Loss/tok 3.2330 (3.2954)	Learning Rate [7.8125e-05]
0: TRAIN [1][2130/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 91105 (58905)	Loss/tok 3.1420 (3.2932)	Learning Rate [7.8125e-05]
3: TRAIN [1][2130/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00098)	Tok/s 95173 (60165)	Loss/tok 3.2256 (3.2953)	Learning Rate [7.8125e-05]
2: TRAIN [1][2130/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 93274 (59705)	Loss/tok 3.0088 (3.2967)	Learning Rate [7.8125e-05]
2: TRAIN [1][2140/6832]	Time 0.074 (0.105)	Data 0.00095 (0.00093)	Tok/s 53907 (59692)	Loss/tok 2.9489 (3.2966)	Learning Rate [7.8125e-05]
1: TRAIN [1][2140/6832]	Time 0.074 (0.105)	Data 0.00089 (0.00093)	Tok/s 53862 (59329)	Loss/tok 3.0362 (3.2954)	Learning Rate [7.8125e-05]
3: TRAIN [1][2140/6832]	Time 0.074 (0.105)	Data 0.00098 (0.00098)	Tok/s 55103 (60151)	Loss/tok 3.1625 (3.2955)	Learning Rate [7.8125e-05]
0: TRAIN [1][2140/6832]	Time 0.074 (0.105)	Data 0.00091 (0.00095)	Tok/s 53876 (58893)	Loss/tok 3.1279 (3.2931)	Learning Rate [7.8125e-05]
1: TRAIN [1][2150/6832]	Time 0.054 (0.105)	Data 0.00088 (0.00093)	Tok/s 45049 (59307)	Loss/tok 2.6121 (3.2953)	Learning Rate [7.8125e-05]
2: TRAIN [1][2150/6832]	Time 0.054 (0.105)	Data 0.00091 (0.00093)	Tok/s 45217 (59671)	Loss/tok 2.6426 (3.2963)	Learning Rate [7.8125e-05]
3: TRAIN [1][2150/6832]	Time 0.054 (0.105)	Data 0.00088 (0.00098)	Tok/s 47401 (60131)	Loss/tok 2.7249 (3.2954)	Learning Rate [7.8125e-05]
0: TRAIN [1][2150/6832]	Time 0.054 (0.105)	Data 0.00095 (0.00095)	Tok/s 42952 (58870)	Loss/tok 2.5098 (3.2929)	Learning Rate [7.8125e-05]
2: TRAIN [1][2160/6832]	Time 0.099 (0.105)	Data 0.00091 (0.00093)	Tok/s 54484 (59664)	Loss/tok 3.2404 (3.2964)	Learning Rate [7.8125e-05]
1: TRAIN [1][2160/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00093)	Tok/s 54467 (59300)	Loss/tok 3.2514 (3.2953)	Learning Rate [7.8125e-05]
3: TRAIN [1][2160/6832]	Time 0.099 (0.105)	Data 0.00098 (0.00098)	Tok/s 54947 (60124)	Loss/tok 3.3066 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2160/6832]	Time 0.099 (0.105)	Data 0.00101 (0.00096)	Tok/s 54467 (58864)	Loss/tok 3.2339 (3.2928)	Learning Rate [7.8125e-05]
2: TRAIN [1][2170/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00093)	Tok/s 53334 (59657)	Loss/tok 3.1961 (3.2962)	Learning Rate [7.8125e-05]
1: TRAIN [1][2170/6832]	Time 0.081 (0.105)	Data 0.00091 (0.00093)	Tok/s 51882 (59293)	Loss/tok 3.0565 (3.2948)	Learning Rate [7.8125e-05]
3: TRAIN [1][2170/6832]	Time 0.081 (0.105)	Data 0.00094 (0.00098)	Tok/s 53581 (60117)	Loss/tok 3.1018 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2170/6832]	Time 0.081 (0.105)	Data 0.00093 (0.00096)	Tok/s 51864 (58856)	Loss/tok 2.9912 (3.2925)	Learning Rate [7.8125e-05]
1: TRAIN [1][2180/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 80300 (59288)	Loss/tok 3.2711 (3.2949)	Learning Rate [7.8125e-05]
2: TRAIN [1][2180/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00093)	Tok/s 80766 (59655)	Loss/tok 3.3430 (3.2964)	Learning Rate [7.8125e-05]
3: TRAIN [1][2180/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00098)	Tok/s 81198 (60117)	Loss/tok 3.2849 (3.2955)	Learning Rate [7.8125e-05]
0: TRAIN [1][2180/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00096)	Tok/s 80019 (58847)	Loss/tok 3.3136 (3.2925)	Learning Rate [7.8125e-05]
1: TRAIN [1][2190/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00093)	Tok/s 63912 (59297)	Loss/tok 3.4202 (3.2953)	Learning Rate [7.8125e-05]
2: TRAIN [1][2190/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00093)	Tok/s 63867 (59666)	Loss/tok 3.3578 (3.2965)	Learning Rate [7.8125e-05]
0: TRAIN [1][2190/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00096)	Tok/s 63847 (58852)	Loss/tok 3.4276 (3.2927)	Learning Rate [7.8125e-05]
3: TRAIN [1][2190/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00098)	Tok/s 64611 (60128)	Loss/tok 3.3648 (3.2956)	Learning Rate [7.8125e-05]
2: TRAIN [1][2200/6832]	Time 0.074 (0.105)	Data 0.00085 (0.00093)	Tok/s 51653 (59675)	Loss/tok 3.0702 (3.2963)	Learning Rate [7.8125e-05]
1: TRAIN [1][2200/6832]	Time 0.074 (0.105)	Data 0.00085 (0.00093)	Tok/s 51657 (59307)	Loss/tok 3.0967 (3.2955)	Learning Rate [7.8125e-05]
3: TRAIN [1][2200/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00098)	Tok/s 51645 (60137)	Loss/tok 3.1151 (3.2956)	Learning Rate [7.8125e-05]
0: TRAIN [1][2200/6832]	Time 0.074 (0.105)	Data 0.00100 (0.00096)	Tok/s 50164 (58861)	Loss/tok 3.1549 (3.2927)	Learning Rate [7.8125e-05]
2: TRAIN [1][2210/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00093)	Tok/s 73659 (59681)	Loss/tok 3.2907 (3.2964)	Learning Rate [7.8125e-05]
1: TRAIN [1][2210/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00093)	Tok/s 73649 (59314)	Loss/tok 3.2406 (3.2953)	Learning Rate [7.8125e-05]
3: TRAIN [1][2210/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00098)	Tok/s 73841 (60142)	Loss/tok 3.4281 (3.2957)	Learning Rate [7.8125e-05]
0: TRAIN [1][2210/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00096)	Tok/s 72825 (58869)	Loss/tok 3.4576 (3.2929)	Learning Rate [7.8125e-05]
2: TRAIN [1][2220/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00093)	Tok/s 52647 (59688)	Loss/tok 3.0749 (3.2964)	Learning Rate [7.8125e-05]
1: TRAIN [1][2220/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00093)	Tok/s 52649 (59321)	Loss/tok 3.0332 (3.2955)	Learning Rate [7.8125e-05]
3: TRAIN [1][2220/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00098)	Tok/s 52654 (60149)	Loss/tok 3.3427 (3.2959)	Learning Rate [7.8125e-05]
0: TRAIN [1][2220/6832]	Time 0.088 (0.105)	Data 0.00094 (0.00096)	Tok/s 52645 (58877)	Loss/tok 3.2426 (3.2930)	Learning Rate [7.8125e-05]
2: TRAIN [1][2230/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00093)	Tok/s 53047 (59679)	Loss/tok 2.9343 (3.2965)	Learning Rate [7.8125e-05]
1: TRAIN [1][2230/6832]	Time 0.070 (0.105)	Data 0.00086 (0.00093)	Tok/s 52783 (59313)	Loss/tok 3.0690 (3.2954)	Learning Rate [7.8125e-05]
3: TRAIN [1][2230/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00098)	Tok/s 53061 (60139)	Loss/tok 2.9972 (3.2958)	Learning Rate [7.8125e-05]
0: TRAIN [1][2230/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00096)	Tok/s 51158 (58870)	Loss/tok 2.9170 (3.2926)	Learning Rate [7.8125e-05]
1: TRAIN [1][2240/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00093)	Tok/s 52435 (59294)	Loss/tok 3.3526 (3.2956)	Learning Rate [7.8125e-05]
3: TRAIN [1][2240/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00098)	Tok/s 52351 (60118)	Loss/tok 3.5974 (3.2960)	Learning Rate [7.8125e-05]
2: TRAIN [1][2240/6832]	Time 0.095 (0.105)	Data 0.00083 (0.00093)	Tok/s 52350 (59659)	Loss/tok 3.2129 (3.2963)	Learning Rate [7.8125e-05]
0: TRAIN [1][2240/6832]	Time 0.095 (0.105)	Data 0.00099 (0.00096)	Tok/s 52412 (58852)	Loss/tok 3.1973 (3.2927)	Learning Rate [7.8125e-05]
2: TRAIN [1][2250/6832]	Time 0.096 (0.105)	Data 0.00087 (0.00093)	Tok/s 53304 (59643)	Loss/tok 3.1304 (3.2962)	Learning Rate [7.8125e-05]
1: TRAIN [1][2250/6832]	Time 0.096 (0.105)	Data 0.00090 (0.00093)	Tok/s 53262 (59278)	Loss/tok 3.2308 (3.2957)	Learning Rate [7.8125e-05]
3: TRAIN [1][2250/6832]	Time 0.096 (0.105)	Data 0.00085 (0.00098)	Tok/s 53294 (60101)	Loss/tok 3.1340 (3.2961)	Learning Rate [7.8125e-05]
0: TRAIN [1][2250/6832]	Time 0.096 (0.105)	Data 0.00101 (0.00096)	Tok/s 52150 (58836)	Loss/tok 3.2219 (3.2927)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][2260/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00093)	Tok/s 51245 (59647)	Loss/tok 3.3348 (3.2963)	Learning Rate [7.8125e-05]
1: TRAIN [1][2260/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00093)	Tok/s 50879 (59283)	Loss/tok 3.4279 (3.2962)	Learning Rate [7.8125e-05]
3: TRAIN [1][2260/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00098)	Tok/s 52059 (60105)	Loss/tok 3.5397 (3.2965)	Learning Rate [7.8125e-05]
0: TRAIN [1][2260/6832]	Time 0.111 (0.105)	Data 0.00099 (0.00096)	Tok/s 50889 (58843)	Loss/tok 3.1608 (3.2929)	Learning Rate [7.8125e-05]
1: TRAIN [1][2270/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 83947 (59282)	Loss/tok 3.2719 (3.2959)	Learning Rate [7.8125e-05]
2: TRAIN [1][2270/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00093)	Tok/s 84383 (59647)	Loss/tok 3.4374 (3.2963)	Learning Rate [7.8125e-05]
3: TRAIN [1][2270/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00098)	Tok/s 84907 (60105)	Loss/tok 3.3357 (3.2963)	Learning Rate [7.8125e-05]
0: TRAIN [1][2270/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00096)	Tok/s 83199 (58842)	Loss/tok 3.3252 (3.2927)	Learning Rate [7.8125e-05]
1: TRAIN [1][2280/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00093)	Tok/s 50150 (59267)	Loss/tok 2.9036 (3.2956)	Learning Rate [7.8125e-05]
2: TRAIN [1][2280/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00093)	Tok/s 50113 (59634)	Loss/tok 2.8643 (3.2959)	Learning Rate [7.8125e-05]
3: TRAIN [1][2280/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00098)	Tok/s 50131 (60092)	Loss/tok 2.8582 (3.2961)	Learning Rate [7.8125e-05]
0: TRAIN [1][2280/6832]	Time 0.071 (0.105)	Data 0.00102 (0.00096)	Tok/s 50141 (58822)	Loss/tok 3.2418 (3.2924)	Learning Rate [7.8125e-05]
2: TRAIN [1][2290/6832]	Time 0.111 (0.105)	Data 0.00096 (0.00093)	Tok/s 52987 (59619)	Loss/tok 3.5149 (3.2963)	Learning Rate [7.8125e-05]
1: TRAIN [1][2290/6832]	Time 0.111 (0.105)	Data 0.00105 (0.00093)	Tok/s 52992 (59253)	Loss/tok 3.2312 (3.2957)	Learning Rate [7.8125e-05]
3: TRAIN [1][2290/6832]	Time 0.111 (0.105)	Data 0.00099 (0.00098)	Tok/s 53011 (60078)	Loss/tok 3.5467 (3.2962)	Learning Rate [7.8125e-05]
0: TRAIN [1][2290/6832]	Time 0.111 (0.105)	Data 0.00098 (0.00096)	Tok/s 52983 (58810)	Loss/tok 3.1466 (3.2924)	Learning Rate [7.8125e-05]
1: TRAIN [1][2300/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00093)	Tok/s 52494 (59237)	Loss/tok 3.2952 (3.2956)	Learning Rate [7.8125e-05]
2: TRAIN [1][2300/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00093)	Tok/s 53038 (59604)	Loss/tok 3.1566 (3.2962)	Learning Rate [7.8125e-05]
3: TRAIN [1][2300/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00098)	Tok/s 53388 (60063)	Loss/tok 3.0718 (3.2961)	Learning Rate [7.8125e-05]
0: TRAIN [1][2300/6832]	Time 0.115 (0.105)	Data 0.00098 (0.00096)	Tok/s 52440 (58796)	Loss/tok 3.2922 (3.2924)	Learning Rate [7.8125e-05]
1: TRAIN [1][2310/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00093)	Tok/s 60345 (59243)	Loss/tok 3.2607 (3.2954)	Learning Rate [7.8125e-05]
2: TRAIN [1][2310/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00093)	Tok/s 61021 (59612)	Loss/tok 3.6268 (3.2964)	Learning Rate [7.8125e-05]
3: TRAIN [1][2310/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00098)	Tok/s 60993 (60072)	Loss/tok 3.3214 (3.2960)	Learning Rate [7.8125e-05]
0: TRAIN [1][2310/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00096)	Tok/s 60037 (58797)	Loss/tok 3.3503 (3.2921)	Learning Rate [7.8125e-05]
1: TRAIN [1][2320/6832]	Time 0.052 (0.105)	Data 0.00091 (0.00093)	Tok/s 45040 (59254)	Loss/tok 2.5726 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2320/6832]	Time 0.052 (0.105)	Data 0.00090 (0.00093)	Tok/s 46427 (59623)	Loss/tok 2.7473 (3.2965)	Learning Rate [7.8125e-05]
3: TRAIN [1][2320/6832]	Time 0.051 (0.105)	Data 0.00096 (0.00098)	Tok/s 48153 (60083)	Loss/tok 2.6888 (3.2961)	Learning Rate [7.8125e-05]
0: TRAIN [1][2320/6832]	Time 0.052 (0.105)	Data 0.00097 (0.00096)	Tok/s 44113 (58807)	Loss/tok 2.5537 (3.2921)	Learning Rate [7.8125e-05]
2: TRAIN [1][2330/6832]	Time 0.101 (0.105)	Data 0.00084 (0.00093)	Tok/s 53266 (59620)	Loss/tok 3.0549 (3.2962)	Learning Rate [7.8125e-05]
1: TRAIN [1][2330/6832]	Time 0.101 (0.105)	Data 0.00088 (0.00093)	Tok/s 53253 (59252)	Loss/tok 3.2993 (3.2948)	Learning Rate [7.8125e-05]
3: TRAIN [1][2330/6832]	Time 0.101 (0.105)	Data 0.00088 (0.00098)	Tok/s 53580 (60080)	Loss/tok 3.2463 (3.2957)	Learning Rate [7.8125e-05]
0: TRAIN [1][2330/6832]	Time 0.101 (0.105)	Data 0.00099 (0.00096)	Tok/s 53281 (58805)	Loss/tok 3.1345 (3.2918)	Learning Rate [7.8125e-05]
1: TRAIN [1][2340/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 83360 (59251)	Loss/tok 3.4247 (3.2950)	Learning Rate [7.8125e-05]
2: TRAIN [1][2340/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00093)	Tok/s 83483 (59620)	Loss/tok 3.2379 (3.2960)	Learning Rate [7.8125e-05]
3: TRAIN [1][2340/6832]	Time 0.132 (0.105)	Data 0.00106 (0.00098)	Tok/s 84333 (60083)	Loss/tok 3.3621 (3.2957)	Learning Rate [7.8125e-05]
0: TRAIN [1][2340/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00096)	Tok/s 82591 (58799)	Loss/tok 3.4342 (3.2917)	Learning Rate [7.8125e-05]
2: TRAIN [1][2350/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00093)	Tok/s 54039 (59614)	Loss/tok 3.3755 (3.2958)	Learning Rate [7.8125e-05]
1: TRAIN [1][2350/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00093)	Tok/s 53644 (59243)	Loss/tok 3.3737 (3.2950)	Learning Rate [7.8125e-05]
3: TRAIN [1][2350/6832]	Time 0.119 (0.105)	Data 0.00103 (0.00098)	Tok/s 54794 (60078)	Loss/tok 3.2795 (3.2954)	Learning Rate [7.8125e-05]
0: TRAIN [1][2350/6832]	Time 0.119 (0.105)	Data 0.00105 (0.00096)	Tok/s 53635 (58788)	Loss/tok 3.5539 (3.2915)	Learning Rate [7.8125e-05]
2: TRAIN [1][2360/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00093)	Tok/s 64594 (59618)	Loss/tok 3.4060 (3.2960)	Learning Rate [7.8125e-05]
1: TRAIN [1][2360/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00093)	Tok/s 64545 (59247)	Loss/tok 3.5341 (3.2952)	Learning Rate [7.8125e-05]
3: TRAIN [1][2360/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00098)	Tok/s 64736 (60081)	Loss/tok 3.3508 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2360/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00096)	Tok/s 64516 (58793)	Loss/tok 3.5391 (3.2915)	Learning Rate [7.8125e-05]
2: TRAIN [1][2370/6832]	Time 0.130 (0.105)	Data 0.00083 (0.00093)	Tok/s 77524 (59607)	Loss/tok 3.3109 (3.2959)	Learning Rate [7.8125e-05]
1: TRAIN [1][2370/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 77501 (59237)	Loss/tok 3.2643 (3.2951)	Learning Rate [7.8125e-05]
0: TRAIN [1][2370/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00096)	Tok/s 77088 (58782)	Loss/tok 3.3449 (3.2914)	Learning Rate [7.8125e-05]
3: TRAIN [1][2370/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00098)	Tok/s 78494 (60069)	Loss/tok 3.4469 (3.2953)	Learning Rate [7.8125e-05]
1: TRAIN [1][2380/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 75630 (59247)	Loss/tok 3.3048 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2380/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00096)	Tok/s 75668 (58793)	Loss/tok 3.2878 (3.2914)	Learning Rate [7.8125e-05]
2: TRAIN [1][2380/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00093)	Tok/s 76146 (59616)	Loss/tok 3.4934 (3.2958)	Learning Rate [7.8125e-05]
3: TRAIN [1][2380/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00098)	Tok/s 76526 (60077)	Loss/tok 3.4510 (3.2952)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [1][2390/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 64511 (59240)	Loss/tok 3.4714 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2390/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00093)	Tok/s 64484 (59611)	Loss/tok 3.5870 (3.2959)	Learning Rate [7.8125e-05]
0: TRAIN [1][2390/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 64324 (58787)	Loss/tok 3.2867 (3.2914)	Learning Rate [7.8125e-05]
3: TRAIN [1][2390/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00098)	Tok/s 64499 (60071)	Loss/tok 3.4496 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2400/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00093)	Tok/s 58199 (59595)	Loss/tok 3.2017 (3.2958)	Learning Rate [7.8125e-05]
1: TRAIN [1][2400/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00093)	Tok/s 58200 (59225)	Loss/tok 3.5531 (3.2951)	Learning Rate [7.8125e-05]
0: TRAIN [1][2400/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00096)	Tok/s 58195 (58770)	Loss/tok 3.3413 (3.2915)	Learning Rate [7.8125e-05]
3: TRAIN [1][2400/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00098)	Tok/s 58643 (60055)	Loss/tok 3.5582 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2410/6832]	Time 0.113 (0.105)	Data 0.00083 (0.00093)	Tok/s 51121 (59578)	Loss/tok 3.2082 (3.2956)	Learning Rate [7.8125e-05]
1: TRAIN [1][2410/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00093)	Tok/s 51193 (59206)	Loss/tok 3.2235 (3.2949)	Learning Rate [7.8125e-05]
0: TRAIN [1][2410/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00096)	Tok/s 51185 (58749)	Loss/tok 3.2211 (3.2914)	Learning Rate [7.8125e-05]
3: TRAIN [1][2410/6832]	Time 0.113 (0.105)	Data 0.00084 (0.00098)	Tok/s 51116 (60039)	Loss/tok 3.2653 (3.2951)	Learning Rate [7.8125e-05]
2: TRAIN [1][2420/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00093)	Tok/s 86415 (59583)	Loss/tok 3.0936 (3.2955)	Learning Rate [7.8125e-05]
1: TRAIN [1][2420/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 85486 (59210)	Loss/tok 3.2265 (3.2948)	Learning Rate [7.8125e-05]
0: TRAIN [1][2420/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00096)	Tok/s 85213 (58754)	Loss/tok 3.1937 (3.2914)	Learning Rate [7.8125e-05]
3: TRAIN [1][2420/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00098)	Tok/s 86898 (60043)	Loss/tok 3.1632 (3.2951)	Learning Rate [7.8125e-05]
1: TRAIN [1][2430/6832]	Time 0.062 (0.105)	Data 0.00090 (0.00093)	Tok/s 49416 (59215)	Loss/tok 2.8032 (3.2951)	Learning Rate [7.8125e-05]
2: TRAIN [1][2430/6832]	Time 0.062 (0.105)	Data 0.00084 (0.00093)	Tok/s 50538 (59587)	Loss/tok 2.9599 (3.2954)	Learning Rate [7.8125e-05]
0: TRAIN [1][2430/6832]	Time 0.062 (0.105)	Data 0.00089 (0.00096)	Tok/s 49463 (58759)	Loss/tok 2.7659 (3.2915)	Learning Rate [7.8125e-05]
3: TRAIN [1][2430/6832]	Time 0.062 (0.105)	Data 0.00087 (0.00098)	Tok/s 51460 (60046)	Loss/tok 2.8843 (3.2954)	Learning Rate [7.8125e-05]
1: TRAIN [1][2440/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00093)	Tok/s 81490 (59205)	Loss/tok 3.4229 (3.2951)	Learning Rate [7.8125e-05]
0: TRAIN [1][2440/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 80813 (58751)	Loss/tok 3.2994 (3.2913)	Learning Rate [7.8125e-05]
2: TRAIN [1][2440/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00093)	Tok/s 81951 (59575)	Loss/tok 3.3823 (3.2953)	Learning Rate [7.8125e-05]
3: TRAIN [1][2440/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00098)	Tok/s 82470 (60034)	Loss/tok 3.2733 (3.2953)	Learning Rate [7.8125e-05]
2: TRAIN [1][2450/6832]	Time 0.114 (0.105)	Data 0.00085 (0.00093)	Tok/s 60708 (59559)	Loss/tok 3.2684 (3.2948)	Learning Rate [7.8125e-05]
1: TRAIN [1][2450/6832]	Time 0.114 (0.105)	Data 0.00096 (0.00093)	Tok/s 60694 (59184)	Loss/tok 3.4433 (3.2948)	Learning Rate [7.8125e-05]
0: TRAIN [1][2450/6832]	Time 0.114 (0.105)	Data 0.00095 (0.00096)	Tok/s 60683 (58725)	Loss/tok 3.2680 (3.2909)	Learning Rate [7.8125e-05]
3: TRAIN [1][2450/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00098)	Tok/s 60710 (60020)	Loss/tok 3.5206 (3.2951)	Learning Rate [7.8125e-05]
1: TRAIN [1][2460/6832]	Time 0.114 (0.105)	Data 0.00091 (0.00093)	Tok/s 55010 (59180)	Loss/tok 3.1810 (3.2949)	Learning Rate [7.8125e-05]
0: TRAIN [1][2460/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00096)	Tok/s 55004 (58721)	Loss/tok 3.1592 (3.2908)	Learning Rate [7.8125e-05]
2: TRAIN [1][2460/6832]	Time 0.114 (0.105)	Data 0.00085 (0.00093)	Tok/s 54968 (59555)	Loss/tok 3.4234 (3.2950)	Learning Rate [7.8125e-05]
3: TRAIN [1][2460/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00098)	Tok/s 55418 (60015)	Loss/tok 3.2818 (3.2950)	Learning Rate [7.8125e-05]
1: TRAIN [1][2470/6832]	Time 0.099 (0.105)	Data 0.00089 (0.00093)	Tok/s 53921 (59201)	Loss/tok 3.2881 (3.2951)	Learning Rate [7.8125e-05]
2: TRAIN [1][2470/6832]	Time 0.099 (0.105)	Data 0.00084 (0.00093)	Tok/s 54435 (59576)	Loss/tok 3.2589 (3.2950)	Learning Rate [7.8125e-05]
0: TRAIN [1][2470/6832]	Time 0.099 (0.105)	Data 0.00088 (0.00096)	Tok/s 53091 (58743)	Loss/tok 3.1868 (3.2908)	Learning Rate [7.8125e-05]
3: TRAIN [1][2470/6832]	Time 0.099 (0.105)	Data 0.00091 (0.00098)	Tok/s 54420 (60035)	Loss/tok 3.1793 (3.2952)	Learning Rate [7.8125e-05]
1: TRAIN [1][2480/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00093)	Tok/s 64574 (59217)	Loss/tok 3.4482 (3.2955)	Learning Rate [7.8125e-05]
2: TRAIN [1][2480/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 64519 (59592)	Loss/tok 3.3426 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2480/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00096)	Tok/s 64365 (58760)	Loss/tok 3.6534 (3.2913)	Learning Rate [7.8125e-05]
3: TRAIN [1][2480/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00098)	Tok/s 64470 (60050)	Loss/tok 3.4546 (3.2956)	Learning Rate [7.8125e-05]
2: TRAIN [1][2490/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00093)	Tok/s 52378 (59595)	Loss/tok 3.3165 (3.2955)	Learning Rate [7.8125e-05]
1: TRAIN [1][2490/6832]	Time 0.115 (0.105)	Data 0.00097 (0.00093)	Tok/s 52351 (59220)	Loss/tok 3.3199 (3.2954)	Learning Rate [7.8125e-05]
0: TRAIN [1][2490/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00096)	Tok/s 52361 (58763)	Loss/tok 3.3614 (3.2912)	Learning Rate [7.8125e-05]
3: TRAIN [1][2490/6832]	Time 0.115 (0.105)	Data 0.00096 (0.00098)	Tok/s 52382 (60053)	Loss/tok 3.4197 (3.2956)	Learning Rate [7.8125e-05]
2: TRAIN [1][2500/6832]	Time 0.088 (0.105)	Data 0.00091 (0.00093)	Tok/s 53734 (59605)	Loss/tok 3.2175 (3.2953)	Learning Rate [7.8125e-05]
1: TRAIN [1][2500/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00093)	Tok/s 53705 (59230)	Loss/tok 3.1518 (3.2951)	Learning Rate [7.8125e-05]
0: TRAIN [1][2500/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00096)	Tok/s 53741 (58774)	Loss/tok 3.0123 (3.2911)	Learning Rate [7.8125e-05]
3: TRAIN [1][2500/6832]	Time 0.088 (0.105)	Data 0.00092 (0.00098)	Tok/s 53740 (60064)	Loss/tok 3.1447 (3.2954)	Learning Rate [7.8125e-05]
2: TRAIN [1][2510/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 71489 (59622)	Loss/tok 3.4916 (3.2956)	Learning Rate [7.8125e-05]
1: TRAIN [1][2510/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00093)	Tok/s 70901 (59248)	Loss/tok 3.4988 (3.2950)	Learning Rate [7.8125e-05]
0: TRAIN [1][2510/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00096)	Tok/s 70559 (58792)	Loss/tok 3.2633 (3.2912)	Learning Rate [7.8125e-05]
3: TRAIN [1][2510/6832]	Time 0.133 (0.105)	Data 0.00105 (0.00098)	Tok/s 71476 (60081)	Loss/tok 3.4398 (3.2954)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][2520/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00093)	Tok/s 63719 (59605)	Loss/tok 3.4218 (3.2954)	Learning Rate [7.8125e-05]
1: TRAIN [1][2520/6832]	Time 0.127 (0.105)	Data 0.00098 (0.00093)	Tok/s 63697 (59231)	Loss/tok 3.2433 (3.2948)	Learning Rate [7.8125e-05]
0: TRAIN [1][2520/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00096)	Tok/s 63724 (58775)	Loss/tok 3.4805 (3.2910)	Learning Rate [7.8125e-05]
3: TRAIN [1][2520/6832]	Time 0.127 (0.105)	Data 0.00102 (0.00098)	Tok/s 64538 (60063)	Loss/tok 3.3005 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2530/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 77446 (59604)	Loss/tok 3.2101 (3.2954)	Learning Rate [7.8125e-05]
1: TRAIN [1][2530/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00092)	Tok/s 77369 (59230)	Loss/tok 3.2240 (3.2948)	Learning Rate [7.8125e-05]
0: TRAIN [1][2530/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00096)	Tok/s 76464 (58773)	Loss/tok 3.3946 (3.2909)	Learning Rate [7.8125e-05]
3: TRAIN [1][2530/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00098)	Tok/s 77785 (60062)	Loss/tok 3.3257 (3.2951)	Learning Rate [7.8125e-05]
1: TRAIN [1][2540/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00092)	Tok/s 52213 (59223)	Loss/tok 3.3579 (3.2950)	Learning Rate [7.8125e-05]
2: TRAIN [1][2540/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00093)	Tok/s 52507 (59597)	Loss/tok 3.3876 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2540/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00096)	Tok/s 52227 (58768)	Loss/tok 3.3192 (3.2909)	Learning Rate [7.8125e-05]
3: TRAIN [1][2540/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00098)	Tok/s 53297 (60055)	Loss/tok 3.3465 (3.2950)	Learning Rate [7.8125e-05]
1: TRAIN [1][2550/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00092)	Tok/s 59932 (59243)	Loss/tok 3.4433 (3.2951)	Learning Rate [7.8125e-05]
2: TRAIN [1][2550/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00093)	Tok/s 59920 (59617)	Loss/tok 3.3273 (3.2954)	Learning Rate [7.8125e-05]
3: TRAIN [1][2550/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00098)	Tok/s 59955 (60074)	Loss/tok 3.3860 (3.2953)	Learning Rate [7.8125e-05]
0: TRAIN [1][2550/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00096)	Tok/s 59558 (58789)	Loss/tok 3.3077 (3.2911)	Learning Rate [7.8125e-05]
1: TRAIN [1][2560/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00092)	Tok/s 88035 (59259)	Loss/tok 3.0439 (3.2948)	Learning Rate [7.8125e-05]
2: TRAIN [1][2560/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00093)	Tok/s 88779 (59633)	Loss/tok 3.0869 (3.2955)	Learning Rate [7.8125e-05]
0: TRAIN [1][2560/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00096)	Tok/s 87267 (58806)	Loss/tok 3.3288 (3.2913)	Learning Rate [7.8125e-05]
3: TRAIN [1][2560/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00098)	Tok/s 89494 (60090)	Loss/tok 3.2387 (3.2956)	Learning Rate [7.8125e-05]
1: TRAIN [1][2570/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00092)	Tok/s 82941 (59262)	Loss/tok 3.2127 (3.2945)	Learning Rate [7.8125e-05]
0: TRAIN [1][2570/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00096)	Tok/s 82653 (58809)	Loss/tok 3.3188 (3.2913)	Learning Rate [7.8125e-05]
2: TRAIN [1][2570/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00093)	Tok/s 83628 (59636)	Loss/tok 3.3281 (3.2955)	Learning Rate [7.8125e-05]
3: TRAIN [1][2570/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00098)	Tok/s 84099 (60092)	Loss/tok 3.2802 (3.2954)	Learning Rate [7.8125e-05]
2: TRAIN [1][2580/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 65705 (59639)	Loss/tok 3.4711 (3.2957)	Learning Rate [7.8125e-05]
1: TRAIN [1][2580/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00092)	Tok/s 65676 (59266)	Loss/tok 3.4331 (3.2947)	Learning Rate [7.8125e-05]
0: TRAIN [1][2580/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00096)	Tok/s 65719 (58814)	Loss/tok 3.4039 (3.2916)	Learning Rate [7.8125e-05]
3: TRAIN [1][2580/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00098)	Tok/s 66588 (60096)	Loss/tok 3.2456 (3.2955)	Learning Rate [7.8125e-05]
2: TRAIN [1][2590/6832]	Time 0.064 (0.105)	Data 0.00085 (0.00093)	Tok/s 49880 (59611)	Loss/tok 3.0143 (3.2954)	Learning Rate [7.8125e-05]
3: TRAIN [1][2590/6832]	Time 0.064 (0.105)	Data 0.00089 (0.00098)	Tok/s 51569 (60068)	Loss/tok 2.8436 (3.2953)	Learning Rate [7.8125e-05]
1: TRAIN [1][2590/6832]	Time 0.064 (0.105)	Data 0.00093 (0.00092)	Tok/s 49846 (59238)	Loss/tok 2.9696 (3.2943)	Learning Rate [7.8125e-05]
0: TRAIN [1][2590/6832]	Time 0.064 (0.105)	Data 0.00096 (0.00096)	Tok/s 49903 (58787)	Loss/tok 2.9820 (3.2912)	Learning Rate [7.8125e-05]
2: TRAIN [1][2600/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00093)	Tok/s 61994 (59633)	Loss/tok 3.5262 (3.2955)	Learning Rate [7.8125e-05]
1: TRAIN [1][2600/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00092)	Tok/s 61460 (59261)	Loss/tok 3.3917 (3.2943)	Learning Rate [7.8125e-05]
0: TRAIN [1][2600/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00096)	Tok/s 61486 (58810)	Loss/tok 3.4917 (3.2913)	Learning Rate [7.8125e-05]
3: TRAIN [1][2600/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00098)	Tok/s 62491 (60090)	Loss/tok 3.3679 (3.2956)	Learning Rate [7.8125e-05]
2: TRAIN [1][2610/6832]	Time 0.072 (0.105)	Data 0.00084 (0.00093)	Tok/s 53584 (59631)	Loss/tok 3.1192 (3.2950)	Learning Rate [7.8125e-05]
0: TRAIN [1][2610/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00096)	Tok/s 52054 (58808)	Loss/tok 2.9498 (3.2910)	Learning Rate [7.8125e-05]
1: TRAIN [1][2610/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00092)	Tok/s 53577 (59259)	Loss/tok 3.1600 (3.2942)	Learning Rate [7.8125e-05]
3: TRAIN [1][2610/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00098)	Tok/s 53574 (60089)	Loss/tok 3.0496 (3.2956)	Learning Rate [7.8125e-05]
2: TRAIN [1][2620/6832]	Time 0.094 (0.105)	Data 0.00089 (0.00093)	Tok/s 53099 (59630)	Loss/tok 3.1408 (3.2950)	Learning Rate [7.8125e-05]
1: TRAIN [1][2620/6832]	Time 0.094 (0.105)	Data 0.00091 (0.00092)	Tok/s 53062 (59258)	Loss/tok 3.2861 (3.2942)	Learning Rate [7.8125e-05]
0: TRAIN [1][2620/6832]	Time 0.094 (0.105)	Data 0.00089 (0.00096)	Tok/s 52678 (58807)	Loss/tok 3.1860 (3.2910)	Learning Rate [7.8125e-05]
3: TRAIN [1][2620/6832]	Time 0.094 (0.105)	Data 0.00094 (0.00098)	Tok/s 53137 (60086)	Loss/tok 3.1302 (3.2955)	Learning Rate [7.8125e-05]
1: TRAIN [1][2630/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00092)	Tok/s 66003 (59260)	Loss/tok 3.4809 (3.2943)	Learning Rate [7.8125e-05]
2: TRAIN [1][2630/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00093)	Tok/s 66141 (59632)	Loss/tok 3.5171 (3.2948)	Learning Rate [7.8125e-05]
0: TRAIN [1][2630/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00096)	Tok/s 66023 (58810)	Loss/tok 3.3222 (3.2910)	Learning Rate [7.8125e-05]
3: TRAIN [1][2630/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00098)	Tok/s 66895 (60089)	Loss/tok 3.3879 (3.2955)	Learning Rate [7.8125e-05]
0: TRAIN [1][2640/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 81114 (58809)	Loss/tok 3.1419 (3.2906)	Learning Rate [7.8125e-05]
1: TRAIN [1][2640/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00092)	Tok/s 81404 (59258)	Loss/tok 3.3317 (3.2941)	Learning Rate [7.8125e-05]
2: TRAIN [1][2640/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00093)	Tok/s 81784 (59630)	Loss/tok 3.2576 (3.2945)	Learning Rate [7.8125e-05]
3: TRAIN [1][2640/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00098)	Tok/s 82324 (60088)	Loss/tok 3.3131 (3.2952)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][2650/6832]	Time 0.124 (0.105)	Data 0.00084 (0.00093)	Tok/s 59770 (59606)	Loss/tok 3.3869 (3.2943)	Learning Rate [7.8125e-05]
1: TRAIN [1][2650/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00092)	Tok/s 59746 (59235)	Loss/tok 3.3334 (3.2937)	Learning Rate [7.8125e-05]
0: TRAIN [1][2650/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00096)	Tok/s 59783 (58780)	Loss/tok 3.2630 (3.2903)	Learning Rate [7.8125e-05]
3: TRAIN [1][2650/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00098)	Tok/s 60091 (60065)	Loss/tok 3.3970 (3.2948)	Learning Rate [7.8125e-05]
1: TRAIN [1][2660/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00092)	Tok/s 65267 (59244)	Loss/tok 3.3284 (3.2937)	Learning Rate [7.8125e-05]
2: TRAIN [1][2660/6832]	Time 0.125 (0.105)	Data 0.00103 (0.00093)	Tok/s 65841 (59615)	Loss/tok 3.3389 (3.2943)	Learning Rate [7.8125e-05]
0: TRAIN [1][2660/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00096)	Tok/s 65273 (58791)	Loss/tok 3.3445 (3.2902)	Learning Rate [7.8125e-05]
3: TRAIN [1][2660/6832]	Time 0.125 (0.105)	Data 0.00098 (0.00098)	Tok/s 66336 (60074)	Loss/tok 3.4545 (3.2949)	Learning Rate [7.8125e-05]
2: TRAIN [1][2670/6832]	Time 0.121 (0.105)	Data 0.00084 (0.00093)	Tok/s 60135 (59627)	Loss/tok 3.3652 (3.2944)	Learning Rate [7.8125e-05]
1: TRAIN [1][2670/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00092)	Tok/s 59323 (59256)	Loss/tok 3.1916 (3.2939)	Learning Rate [7.8125e-05]
3: TRAIN [1][2670/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00098)	Tok/s 60457 (60085)	Loss/tok 3.3970 (3.2951)	Learning Rate [7.8125e-05]
0: TRAIN [1][2670/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00096)	Tok/s 59341 (58803)	Loss/tok 3.2409 (3.2905)	Learning Rate [7.8125e-05]
1: TRAIN [1][2680/6832]	Time 0.083 (0.105)	Data 0.00085 (0.00092)	Tok/s 52276 (59249)	Loss/tok 2.9013 (3.2935)	Learning Rate [7.8125e-05]
0: TRAIN [1][2680/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00096)	Tok/s 52294 (58796)	Loss/tok 3.0459 (3.2902)	Learning Rate [7.8125e-05]
2: TRAIN [1][2680/6832]	Time 0.083 (0.105)	Data 0.00094 (0.00093)	Tok/s 52258 (59620)	Loss/tok 3.1691 (3.2943)	Learning Rate [7.8125e-05]
3: TRAIN [1][2680/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00098)	Tok/s 53354 (60079)	Loss/tok 3.2538 (3.2952)	Learning Rate [7.8125e-05]
2: TRAIN [1][2690/6832]	Time 0.097 (0.105)	Data 0.00084 (0.00093)	Tok/s 51517 (59609)	Loss/tok 3.1520 (3.2939)	Learning Rate [7.8125e-05]
3: TRAIN [1][2690/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00098)	Tok/s 51547 (60069)	Loss/tok 3.0935 (3.2950)	Learning Rate [7.8125e-05]
0: TRAIN [1][2690/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00096)	Tok/s 51500 (58787)	Loss/tok 3.3732 (3.2902)	Learning Rate [7.8125e-05]
1: TRAIN [1][2690/6832]	Time 0.097 (0.105)	Data 0.00119 (0.00092)	Tok/s 51555 (59239)	Loss/tok 3.1765 (3.2934)	Learning Rate [7.8125e-05]
1: TRAIN [1][2700/6832]	Time 0.102 (0.105)	Data 0.00089 (0.00092)	Tok/s 54671 (59220)	Loss/tok 3.4439 (3.2933)	Learning Rate [7.8125e-05]
2: TRAIN [1][2700/6832]	Time 0.102 (0.105)	Data 0.00084 (0.00093)	Tok/s 55164 (59591)	Loss/tok 3.3613 (3.2937)	Learning Rate [7.8125e-05]
0: TRAIN [1][2700/6832]	Time 0.102 (0.105)	Data 0.00092 (0.00096)	Tok/s 53879 (58769)	Loss/tok 3.2841 (3.2902)	Learning Rate [7.8125e-05]
3: TRAIN [1][2700/6832]	Time 0.102 (0.105)	Data 0.00088 (0.00098)	Tok/s 55168 (60050)	Loss/tok 3.1584 (3.2949)	Learning Rate [7.8125e-05]
2: TRAIN [1][2710/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00093)	Tok/s 54305 (59594)	Loss/tok 3.2115 (3.2937)	Learning Rate [7.8125e-05]
1: TRAIN [1][2710/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00092)	Tok/s 54299 (59225)	Loss/tok 3.1723 (3.2931)	Learning Rate [7.8125e-05]
0: TRAIN [1][2710/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00096)	Tok/s 53503 (58774)	Loss/tok 3.3767 (3.2904)	Learning Rate [7.8125e-05]
3: TRAIN [1][2710/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00098)	Tok/s 54352 (60054)	Loss/tok 3.3077 (3.2951)	Learning Rate [7.8125e-05]
2: TRAIN [1][2720/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00093)	Tok/s 76348 (59584)	Loss/tok 3.2825 (3.2933)	Learning Rate [7.8125e-05]
1: TRAIN [1][2720/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00092)	Tok/s 75705 (59216)	Loss/tok 3.2300 (3.2929)	Learning Rate [7.8125e-05]
0: TRAIN [1][2720/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00096)	Tok/s 75430 (58765)	Loss/tok 3.4927 (3.2904)	Learning Rate [7.8125e-05]
3: TRAIN [1][2720/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00098)	Tok/s 76129 (60043)	Loss/tok 3.1662 (3.2949)	Learning Rate [7.8125e-05]
1: TRAIN [1][2730/6832]	Time 0.127 (0.105)	Data 0.00100 (0.00092)	Tok/s 70356 (59205)	Loss/tok 3.3774 (3.2928)	Learning Rate [7.8125e-05]
0: TRAIN [1][2730/6832]	Time 0.127 (0.105)	Data 0.00105 (0.00096)	Tok/s 70145 (58755)	Loss/tok 3.4302 (3.2904)	Learning Rate [7.8125e-05]
2: TRAIN [1][2730/6832]	Time 0.128 (0.105)	Data 0.00106 (0.00093)	Tok/s 70103 (59573)	Loss/tok 3.4552 (3.2931)	Learning Rate [7.8125e-05]
3: TRAIN [1][2730/6832]	Time 0.128 (0.105)	Data 0.00105 (0.00098)	Tok/s 70116 (60031)	Loss/tok 3.4353 (3.2949)	Learning Rate [7.8125e-05]
1: TRAIN [1][2740/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00092)	Tok/s 59394 (59207)	Loss/tok 3.3858 (3.2927)	Learning Rate [7.8125e-05]
2: TRAIN [1][2740/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00093)	Tok/s 59397 (59575)	Loss/tok 3.3307 (3.2929)	Learning Rate [7.8125e-05]
3: TRAIN [1][2740/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00098)	Tok/s 59399 (60033)	Loss/tok 3.3429 (3.2945)	Learning Rate [7.8125e-05]
0: TRAIN [1][2740/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00096)	Tok/s 58759 (58757)	Loss/tok 3.5060 (3.2903)	Learning Rate [7.8125e-05]
2: TRAIN [1][2750/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00093)	Tok/s 52590 (59573)	Loss/tok 3.1442 (3.2929)	Learning Rate [7.8125e-05]
3: TRAIN [1][2750/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00098)	Tok/s 52601 (60031)	Loss/tok 3.3524 (3.2945)	Learning Rate [7.8125e-05]
1: TRAIN [1][2750/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00092)	Tok/s 52598 (59205)	Loss/tok 3.1260 (3.2929)	Learning Rate [7.8125e-05]
0: TRAIN [1][2750/6832]	Time 0.088 (0.105)	Data 0.00093 (0.00096)	Tok/s 52527 (58757)	Loss/tok 3.2875 (3.2905)	Learning Rate [7.8125e-05]
2: TRAIN [1][2760/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00093)	Tok/s 63246 (59584)	Loss/tok 3.5286 (3.2932)	Learning Rate [7.8125e-05]
3: TRAIN [1][2760/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00098)	Tok/s 63539 (60041)	Loss/tok 3.2971 (3.2949)	Learning Rate [7.8125e-05]
1: TRAIN [1][2760/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00092)	Tok/s 62481 (59215)	Loss/tok 3.3155 (3.2931)	Learning Rate [7.8125e-05]
0: TRAIN [1][2760/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00096)	Tok/s 62467 (58768)	Loss/tok 3.3130 (3.2905)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][2770/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00093)	Tok/s 76680 (59610)	Loss/tok 3.3869 (3.2932)	Learning Rate [7.8125e-05]
3: TRAIN [1][2770/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00098)	Tok/s 76662 (60067)	Loss/tok 3.3261 (3.2948)	Learning Rate [7.8125e-05]
0: TRAIN [1][2770/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00096)	Tok/s 75701 (58796)	Loss/tok 3.3554 (3.2903)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
1: TRAIN [1][2770/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00092)	Tok/s 76018 (59242)	Loss/tok 3.3331 (3.2933)	Learning Rate [7.8125e-05]
2: TRAIN [1][2780/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00093)	Tok/s 86457 (59616)	Loss/tok 3.2455 (3.2931)	Learning Rate [7.8125e-05]
3: TRAIN [1][2780/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00098)	Tok/s 86934 (60073)	Loss/tok 3.2230 (3.2945)	Learning Rate [7.8125e-05]
0: TRAIN [1][2780/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00096)	Tok/s 85383 (58801)	Loss/tok 3.2130 (3.2903)	Learning Rate [7.8125e-05]
1: TRAIN [1][2780/6832]	Time 0.131 (0.105)	Data 0.00109 (0.00092)	Tok/s 86042 (59248)	Loss/tok 3.2352 (3.2932)	Learning Rate [7.8125e-05]
2: TRAIN [1][2790/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00093)	Tok/s 53320 (59609)	Loss/tok 3.2259 (3.2930)	Learning Rate [7.8125e-05]
3: TRAIN [1][2790/6832]	Time 0.084 (0.105)	Data 0.00084 (0.00098)	Tok/s 53308 (60066)	Loss/tok 3.1189 (3.2942)	Learning Rate [7.8125e-05]
0: TRAIN [1][2790/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00096)	Tok/s 51793 (58788)	Loss/tok 3.2495 (3.2904)	Learning Rate [7.8125e-05]
1: TRAIN [1][2790/6832]	Time 0.084 (0.105)	Data 0.00101 (0.00092)	Tok/s 53190 (59238)	Loss/tok 3.1255 (3.2930)	Learning Rate [7.8125e-05]
2: TRAIN [1][2800/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00093)	Tok/s 51161 (59606)	Loss/tok 2.9006 (3.2932)	Learning Rate [7.8125e-05]
3: TRAIN [1][2800/6832]	Time 0.070 (0.105)	Data 0.00097 (0.00098)	Tok/s 51661 (60063)	Loss/tok 3.0160 (3.2939)	Learning Rate [7.8125e-05]
0: TRAIN [1][2800/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00096)	Tok/s 51148 (58787)	Loss/tok 3.1307 (3.2904)	Learning Rate [7.8125e-05]
1: TRAIN [1][2800/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00092)	Tok/s 51233 (59236)	Loss/tok 2.9349 (3.2930)	Learning Rate [7.8125e-05]
2: TRAIN [1][2810/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00093)	Tok/s 74979 (59625)	Loss/tok 3.4619 (3.2935)	Learning Rate [7.8125e-05]
3: TRAIN [1][2810/6832]	Time 0.131 (0.105)	Data 0.00083 (0.00098)	Tok/s 75400 (60083)	Loss/tok 3.3860 (3.2940)	Learning Rate [7.8125e-05]
0: TRAIN [1][2810/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00096)	Tok/s 74438 (58801)	Loss/tok 3.1137 (3.2907)	Learning Rate [7.8125e-05]
1: TRAIN [1][2810/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00092)	Tok/s 74367 (59254)	Loss/tok 3.3141 (3.2933)	Learning Rate [7.8125e-05]
2: TRAIN [1][2820/6832]	Time 0.110 (0.105)	Data 0.00084 (0.00093)	Tok/s 54706 (59619)	Loss/tok 3.2513 (3.2935)	Learning Rate [7.8125e-05]
3: TRAIN [1][2820/6832]	Time 0.110 (0.105)	Data 0.00083 (0.00098)	Tok/s 54911 (60076)	Loss/tok 3.2600 (3.2940)	Learning Rate [7.8125e-05]
0: TRAIN [1][2820/6832]	Time 0.110 (0.105)	Data 0.00088 (0.00096)	Tok/s 53604 (58796)	Loss/tok 3.2576 (3.2907)	Learning Rate [7.8125e-05]
1: TRAIN [1][2820/6832]	Time 0.110 (0.105)	Data 0.00101 (0.00093)	Tok/s 53598 (59247)	Loss/tok 3.2770 (3.2933)	Learning Rate [7.8125e-05]
3: TRAIN [1][2830/6832]	Time 0.108 (0.105)	Data 0.00083 (0.00098)	Tok/s 52261 (60068)	Loss/tok 3.0829 (3.2940)	Learning Rate [7.8125e-05]
2: TRAIN [1][2830/6832]	Time 0.108 (0.105)	Data 0.00084 (0.00093)	Tok/s 51593 (59610)	Loss/tok 3.1786 (3.2932)	Learning Rate [7.8125e-05]
0: TRAIN [1][2830/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00096)	Tok/s 51057 (58789)	Loss/tok 3.2015 (3.2906)	Learning Rate [7.8125e-05]
1: TRAIN [1][2830/6832]	Time 0.108 (0.105)	Data 0.00101 (0.00093)	Tok/s 51063 (59239)	Loss/tok 3.2117 (3.2933)	Learning Rate [7.8125e-05]
2: TRAIN [1][2840/6832]	Time 0.051 (0.105)	Data 0.00095 (0.00093)	Tok/s 47349 (59618)	Loss/tok 2.5478 (3.2930)	Learning Rate [7.8125e-05]
3: TRAIN [1][2840/6832]	Time 0.051 (0.105)	Data 0.00090 (0.00098)	Tok/s 48449 (60077)	Loss/tok 2.6776 (3.2936)	Learning Rate [7.8125e-05]
0: TRAIN [1][2840/6832]	Time 0.051 (0.105)	Data 0.00087 (0.00096)	Tok/s 44786 (58797)	Loss/tok 2.4337 (3.2904)	Learning Rate [7.8125e-05]
1: TRAIN [1][2840/6832]	Time 0.052 (0.105)	Data 0.00095 (0.00093)	Tok/s 45967 (59247)	Loss/tok 2.5029 (3.2932)	Learning Rate [7.8125e-05]
2: TRAIN [1][2850/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00093)	Tok/s 53605 (59619)	Loss/tok 3.3377 (3.2929)	Learning Rate [7.8125e-05]
3: TRAIN [1][2850/6832]	Time 0.103 (0.105)	Data 0.00083 (0.00098)	Tok/s 53619 (60076)	Loss/tok 3.3417 (3.2935)	Learning Rate [7.8125e-05]
0: TRAIN [1][2850/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00096)	Tok/s 53618 (58798)	Loss/tok 3.2338 (3.2903)	Learning Rate [7.8125e-05]
1: TRAIN [1][2850/6832]	Time 0.103 (0.105)	Data 0.00096 (0.00093)	Tok/s 53628 (59248)	Loss/tok 3.1460 (3.2930)	Learning Rate [7.8125e-05]
2: TRAIN [1][2860/6832]	Time 0.108 (0.105)	Data 0.00086 (0.00093)	Tok/s 53362 (59611)	Loss/tok 3.1951 (3.2928)	Learning Rate [7.8125e-05]
3: TRAIN [1][2860/6832]	Time 0.108 (0.105)	Data 0.00084 (0.00098)	Tok/s 53368 (60068)	Loss/tok 3.4638 (3.2936)	Learning Rate [7.8125e-05]
0: TRAIN [1][2860/6832]	Time 0.108 (0.105)	Data 0.00094 (0.00096)	Tok/s 52155 (58790)	Loss/tok 3.1080 (3.2903)	Learning Rate [7.8125e-05]
1: TRAIN [1][2860/6832]	Time 0.108 (0.105)	Data 0.00097 (0.00093)	Tok/s 52274 (59239)	Loss/tok 3.2848 (3.2929)	Learning Rate [7.8125e-05]
2: TRAIN [1][2870/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00093)	Tok/s 77568 (59637)	Loss/tok 3.3834 (3.2927)	Learning Rate [7.8125e-05]
3: TRAIN [1][2870/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00098)	Tok/s 78298 (60095)	Loss/tok 3.3042 (3.2934)	Learning Rate [7.8125e-05]
0: TRAIN [1][2870/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00096)	Tok/s 76935 (58817)	Loss/tok 3.5608 (3.2902)	Learning Rate [7.8125e-05]
1: TRAIN [1][2870/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00093)	Tok/s 77498 (59266)	Loss/tok 3.4030 (3.2928)	Learning Rate [7.8125e-05]
2: TRAIN [1][2880/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00093)	Tok/s 50494 (59635)	Loss/tok 2.6398 (3.2927)	Learning Rate [7.8125e-05]
3: TRAIN [1][2880/6832]	Time 0.053 (0.105)	Data 0.00086 (0.00098)	Tok/s 50535 (60091)	Loss/tok 2.7245 (3.2933)	Learning Rate [7.8125e-05]
0: TRAIN [1][2880/6832]	Time 0.053 (0.105)	Data 0.00089 (0.00096)	Tok/s 48202 (58815)	Loss/tok 2.7440 (3.2901)	Learning Rate [7.8125e-05]
1: TRAIN [1][2880/6832]	Time 0.053 (0.105)	Data 0.00097 (0.00093)	Tok/s 50378 (59264)	Loss/tok 2.6942 (3.2929)	Learning Rate [7.8125e-05]
3: TRAIN [1][2890/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00098)	Tok/s 53963 (60109)	Loss/tok 2.9194 (3.2931)	Learning Rate [7.8125e-05]
2: TRAIN [1][2890/6832]	Time 0.071 (0.105)	Data 0.00107 (0.00093)	Tok/s 54006 (59651)	Loss/tok 3.0036 (3.2925)	Learning Rate [7.8125e-05]
0: TRAIN [1][2890/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00096)	Tok/s 52320 (58830)	Loss/tok 2.9483 (3.2899)	Learning Rate [7.8125e-05]
1: TRAIN [1][2890/6832]	Time 0.071 (0.105)	Data 0.00095 (0.00093)	Tok/s 53995 (59280)	Loss/tok 3.0262 (3.2927)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [1][2900/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00093)	Tok/s 62608 (59666)	Loss/tok 3.3537 (3.2923)	Learning Rate [7.8125e-05]
3: TRAIN [1][2900/6832]	Time 0.128 (0.105)	Data 0.00083 (0.00098)	Tok/s 63145 (60124)	Loss/tok 3.4524 (3.2929)	Learning Rate [7.8125e-05]
0: TRAIN [1][2900/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00096)	Tok/s 62166 (58845)	Loss/tok 3.4722 (3.2897)	Learning Rate [7.8125e-05]
1: TRAIN [1][2900/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00093)	Tok/s 62174 (59294)	Loss/tok 3.4168 (3.2925)	Learning Rate [7.8125e-05]
2: TRAIN [1][2910/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00093)	Tok/s 83804 (59681)	Loss/tok 3.3657 (3.2923)	Learning Rate [7.8125e-05]
3: TRAIN [1][2910/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00098)	Tok/s 84087 (60139)	Loss/tok 3.2811 (3.2932)	Learning Rate [7.8125e-05]
0: TRAIN [1][2910/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00096)	Tok/s 82710 (58860)	Loss/tok 3.2572 (3.2900)	Learning Rate [7.8125e-05]
1: TRAIN [1][2910/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00093)	Tok/s 83147 (59310)	Loss/tok 3.3019 (3.2926)	Learning Rate [7.8125e-05]
2: TRAIN [1][2920/6832]	Time 0.061 (0.105)	Data 0.00098 (0.00093)	Tok/s 50993 (59661)	Loss/tok 2.9993 (3.2918)	Learning Rate [7.8125e-05]
3: TRAIN [1][2920/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00098)	Tok/s 52790 (60121)	Loss/tok 2.9127 (3.2929)	Learning Rate [7.8125e-05]
0: TRAIN [1][2920/6832]	Time 0.060 (0.105)	Data 0.00094 (0.00096)	Tok/s 50832 (58837)	Loss/tok 2.8929 (3.2896)	Learning Rate [7.8125e-05]
1: TRAIN [1][2920/6832]	Time 0.060 (0.105)	Data 0.00093 (0.00093)	Tok/s 50864 (59289)	Loss/tok 2.8586 (3.2923)	Learning Rate [7.8125e-05]
2: TRAIN [1][2930/6832]	Time 0.117 (0.105)	Data 0.00084 (0.00093)	Tok/s 59956 (59650)	Loss/tok 3.5301 (3.2917)	Learning Rate [7.8125e-05]
3: TRAIN [1][2930/6832]	Time 0.117 (0.105)	Data 0.00083 (0.00098)	Tok/s 59959 (60109)	Loss/tok 3.3718 (3.2926)	Learning Rate [7.8125e-05]
0: TRAIN [1][2930/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00096)	Tok/s 59932 (58826)	Loss/tok 3.3011 (3.2893)	Learning Rate [7.8125e-05]
1: TRAIN [1][2930/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00093)	Tok/s 59944 (59278)	Loss/tok 3.1761 (3.2920)	Learning Rate [7.8125e-05]
2: TRAIN [1][2940/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00093)	Tok/s 61670 (59655)	Loss/tok 3.4346 (3.2916)	Learning Rate [7.8125e-05]
3: TRAIN [1][2940/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00098)	Tok/s 61678 (60114)	Loss/tok 3.4571 (3.2926)	Learning Rate [7.8125e-05]
0: TRAIN [1][2940/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00096)	Tok/s 60672 (58830)	Loss/tok 3.4248 (3.2894)	Learning Rate [7.8125e-05]
1: TRAIN [1][2940/6832]	Time 0.127 (0.105)	Data 0.00099 (0.00093)	Tok/s 61621 (59283)	Loss/tok 3.5946 (3.2922)	Learning Rate [7.8125e-05]
2: TRAIN [1][2950/6832]	Time 0.088 (0.105)	Data 0.00094 (0.00093)	Tok/s 52592 (59654)	Loss/tok 3.2339 (3.2917)	Learning Rate [7.8125e-05]
3: TRAIN [1][2950/6832]	Time 0.088 (0.105)	Data 0.00092 (0.00098)	Tok/s 52586 (60114)	Loss/tok 3.2322 (3.2924)	Learning Rate [7.8125e-05]
0: TRAIN [1][2950/6832]	Time 0.088 (0.105)	Data 0.00096 (0.00096)	Tok/s 52047 (58830)	Loss/tok 2.8898 (3.2891)	Learning Rate [7.8125e-05]
1: TRAIN [1][2950/6832]	Time 0.088 (0.105)	Data 0.00095 (0.00093)	Tok/s 52622 (59282)	Loss/tok 3.1030 (3.2921)	Learning Rate [7.8125e-05]
3: TRAIN [1][2960/6832]	Time 0.100 (0.105)	Data 0.00084 (0.00098)	Tok/s 52707 (60107)	Loss/tok 3.2477 (3.2924)	Learning Rate [7.8125e-05]
2: TRAIN [1][2960/6832]	Time 0.100 (0.105)	Data 0.00088 (0.00093)	Tok/s 52678 (59647)	Loss/tok 3.2037 (3.2915)	Learning Rate [7.8125e-05]
0: TRAIN [1][2960/6832]	Time 0.100 (0.105)	Data 0.00092 (0.00096)	Tok/s 52651 (58825)	Loss/tok 3.1667 (3.2888)	Learning Rate [7.8125e-05]
1: TRAIN [1][2960/6832]	Time 0.100 (0.105)	Data 0.00098 (0.00093)	Tok/s 52687 (59276)	Loss/tok 3.1208 (3.2919)	Learning Rate [7.8125e-05]
2: TRAIN [1][2970/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00093)	Tok/s 50981 (59663)	Loss/tok 3.3448 (3.2915)	Learning Rate [7.8125e-05]
3: TRAIN [1][2970/6832]	Time 0.117 (0.105)	Data 0.00083 (0.00098)	Tok/s 51582 (60122)	Loss/tok 3.2915 (3.2924)	Learning Rate [7.8125e-05]
0: TRAIN [1][2970/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00096)	Tok/s 50441 (58840)	Loss/tok 3.3281 (3.2889)	Learning Rate [7.8125e-05]
1: TRAIN [1][2970/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00093)	Tok/s 50455 (59291)	Loss/tok 3.4169 (3.2918)	Learning Rate [7.8125e-05]
2: TRAIN [1][2980/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00093)	Tok/s 54944 (59664)	Loss/tok 3.4574 (3.2916)	Learning Rate [7.8125e-05]
3: TRAIN [1][2980/6832]	Time 0.114 (0.105)	Data 0.00086 (0.00098)	Tok/s 54939 (60123)	Loss/tok 3.3905 (3.2927)	Learning Rate [7.8125e-05]
0: TRAIN [1][2980/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00096)	Tok/s 54456 (58843)	Loss/tok 3.2271 (3.2892)	Learning Rate [7.8125e-05]
1: TRAIN [1][2980/6832]	Time 0.114 (0.105)	Data 0.00096 (0.00093)	Tok/s 54907 (59293)	Loss/tok 3.2624 (3.2919)	Learning Rate [7.8125e-05]
2: TRAIN [1][2990/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00093)	Tok/s 91851 (59658)	Loss/tok 3.1802 (3.2914)	Learning Rate [7.8125e-05]
3: TRAIN [1][2990/6832]	Time 0.133 (0.105)	Data 0.00086 (0.00098)	Tok/s 93650 (60117)	Loss/tok 3.0906 (3.2923)	Learning Rate [7.8125e-05]
0: TRAIN [1][2990/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00096)	Tok/s 89753 (58838)	Loss/tok 3.2151 (3.2891)	Learning Rate [7.8125e-05]
1: TRAIN [1][2990/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00093)	Tok/s 90710 (59287)	Loss/tok 3.3692 (3.2919)	Learning Rate [7.8125e-05]
2: TRAIN [1][3000/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00093)	Tok/s 59651 (59664)	Loss/tok 3.3467 (3.2913)	Learning Rate [7.8125e-05]
3: TRAIN [1][3000/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00098)	Tok/s 60613 (60124)	Loss/tok 3.2861 (3.2924)	Learning Rate [7.8125e-05]
0: TRAIN [1][3000/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00096)	Tok/s 59679 (58845)	Loss/tok 3.4144 (3.2892)	Learning Rate [7.8125e-05]
1: TRAIN [1][3000/6832]	Time 0.116 (0.105)	Data 0.00107 (0.00093)	Tok/s 59709 (59294)	Loss/tok 3.3297 (3.2919)	Learning Rate [7.8125e-05]
2: TRAIN [1][3010/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 77055 (59670)	Loss/tok 3.3751 (3.2912)	Learning Rate [7.8125e-05]
3: TRAIN [1][3010/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00098)	Tok/s 77037 (60129)	Loss/tok 3.3003 (3.2923)	Learning Rate [7.8125e-05]
0: TRAIN [1][3010/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 76097 (58851)	Loss/tok 3.2412 (3.2889)	Learning Rate [7.8125e-05]
1: TRAIN [1][3010/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00093)	Tok/s 76115 (59300)	Loss/tok 3.3520 (3.2916)	Learning Rate [7.8125e-05]
2: TRAIN [1][3020/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 70202 (59663)	Loss/tok 3.3670 (3.2911)	Learning Rate [7.8125e-05]
0: TRAIN [1][3020/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 70185 (58844)	Loss/tok 3.4309 (3.2889)	Learning Rate [7.8125e-05]
3: TRAIN [1][3020/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00097)	Tok/s 70588 (60122)	Loss/tok 3.4056 (3.2922)	Learning Rate [7.8125e-05]
1: TRAIN [1][3020/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00093)	Tok/s 70184 (59292)	Loss/tok 3.4234 (3.2915)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [1][3030/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00093)	Tok/s 58953 (59666)	Loss/tok 3.3428 (3.2910)	Learning Rate [7.8125e-05]
3: TRAIN [1][3030/6832]	Time 0.116 (0.105)	Data 0.00082 (0.00097)	Tok/s 59439 (60126)	Loss/tok 3.3606 (3.2921)	Learning Rate [7.8125e-05]
0: TRAIN [1][3030/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00095)	Tok/s 58362 (58848)	Loss/tok 3.3308 (3.2888)	Learning Rate [7.8125e-05]
1: TRAIN [1][3030/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00093)	Tok/s 58342 (59296)	Loss/tok 3.3552 (3.2914)	Learning Rate [7.8125e-05]
2: TRAIN [1][3040/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00093)	Tok/s 65034 (59659)	Loss/tok 3.2538 (3.2906)	Learning Rate [7.8125e-05]
3: TRAIN [1][3040/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00097)	Tok/s 65027 (60119)	Loss/tok 3.4067 (3.2920)	Learning Rate [7.8125e-05]
0: TRAIN [1][3040/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00095)	Tok/s 64852 (58836)	Loss/tok 3.3447 (3.2886)	Learning Rate [7.8125e-05]
1: TRAIN [1][3040/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00093)	Tok/s 65050 (59287)	Loss/tok 3.3432 (3.2912)	Learning Rate [7.8125e-05]
2: TRAIN [1][3050/6832]	Time 0.056 (0.105)	Data 0.00087 (0.00093)	Tok/s 48113 (59642)	Loss/tok 2.6910 (3.2905)	Learning Rate [7.8125e-05]
3: TRAIN [1][3050/6832]	Time 0.056 (0.105)	Data 0.00086 (0.00097)	Tok/s 48099 (60102)	Loss/tok 2.6681 (3.2917)	Learning Rate [7.8125e-05]
0: TRAIN [1][3050/6832]	Time 0.056 (0.105)	Data 0.00086 (0.00095)	Tok/s 45795 (58819)	Loss/tok 2.6677 (3.2885)	Learning Rate [7.8125e-05]
1: TRAIN [1][3050/6832]	Time 0.056 (0.105)	Data 0.00096 (0.00093)	Tok/s 46956 (59270)	Loss/tok 2.7007 (3.2911)	Learning Rate [7.8125e-05]
2: TRAIN [1][3060/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00093)	Tok/s 53492 (59639)	Loss/tok 3.3806 (3.2907)	Learning Rate [7.8125e-05]
3: TRAIN [1][3060/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00097)	Tok/s 54092 (60098)	Loss/tok 3.1543 (3.2919)	Learning Rate [7.8125e-05]
0: TRAIN [1][3060/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00095)	Tok/s 53481 (58818)	Loss/tok 3.2462 (3.2885)	Learning Rate [7.8125e-05]
1: TRAIN [1][3060/6832]	Time 0.110 (0.105)	Data 0.00095 (0.00093)	Tok/s 53498 (59267)	Loss/tok 3.1587 (3.2912)	Learning Rate [7.8125e-05]
2: TRAIN [1][3070/6832]	Time 0.096 (0.105)	Data 0.00084 (0.00093)	Tok/s 54423 (59655)	Loss/tok 3.1702 (3.2908)	Learning Rate [7.8125e-05]
3: TRAIN [1][3070/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00097)	Tok/s 54444 (60115)	Loss/tok 3.0833 (3.2918)	Learning Rate [7.8125e-05]
0: TRAIN [1][3070/6832]	Time 0.096 (0.105)	Data 0.00089 (0.00095)	Tok/s 54446 (58835)	Loss/tok 3.1906 (3.2886)	Learning Rate [7.8125e-05]
1: TRAIN [1][3070/6832]	Time 0.096 (0.105)	Data 0.00102 (0.00093)	Tok/s 54434 (59284)	Loss/tok 3.3536 (3.2912)	Learning Rate [7.8125e-05]
2: TRAIN [1][3080/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00093)	Tok/s 50840 (59644)	Loss/tok 3.2492 (3.2905)	Learning Rate [7.8125e-05]
3: TRAIN [1][3080/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00097)	Tok/s 50826 (60103)	Loss/tok 3.1713 (3.2914)	Learning Rate [7.8125e-05]
0: TRAIN [1][3080/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00095)	Tok/s 49738 (58825)	Loss/tok 3.3215 (3.2882)	Learning Rate [7.8125e-05]
1: TRAIN [1][3080/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00093)	Tok/s 50470 (59273)	Loss/tok 3.2307 (3.2910)	Learning Rate [7.8125e-05]
2: TRAIN [1][3090/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00093)	Tok/s 50166 (59657)	Loss/tok 3.1931 (3.2906)	Learning Rate [7.8125e-05]
3: TRAIN [1][3090/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00097)	Tok/s 50174 (60116)	Loss/tok 3.2293 (3.2915)	Learning Rate [7.8125e-05]
0: TRAIN [1][3090/6832]	Time 0.105 (0.105)	Data 0.00109 (0.00095)	Tok/s 50147 (58839)	Loss/tok 3.1110 (3.2881)	Learning Rate [7.8125e-05]
1: TRAIN [1][3090/6832]	Time 0.105 (0.105)	Data 0.00101 (0.00093)	Tok/s 50109 (59287)	Loss/tok 3.1143 (3.2911)	Learning Rate [7.8125e-05]
2: TRAIN [1][3100/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00093)	Tok/s 52666 (59646)	Loss/tok 3.2145 (3.2905)	Learning Rate [7.8125e-05]
3: TRAIN [1][3100/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00097)	Tok/s 52649 (60105)	Loss/tok 3.1918 (3.2914)	Learning Rate [7.8125e-05]
0: TRAIN [1][3100/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00095)	Tok/s 51482 (58829)	Loss/tok 3.2247 (3.2879)	Learning Rate [7.8125e-05]
1: TRAIN [1][3100/6832]	Time 0.112 (0.105)	Data 0.00096 (0.00093)	Tok/s 52679 (59276)	Loss/tok 3.2065 (3.2910)	Learning Rate [7.8125e-05]
2: TRAIN [1][3110/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 73666 (59641)	Loss/tok 3.2919 (3.2905)	Learning Rate [7.8125e-05]
3: TRAIN [1][3110/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00097)	Tok/s 73816 (60099)	Loss/tok 3.4515 (3.2914)	Learning Rate [7.8125e-05]
0: TRAIN [1][3110/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00095)	Tok/s 72821 (58824)	Loss/tok 3.4348 (3.2879)	Learning Rate [7.8125e-05]
1: TRAIN [1][3110/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00093)	Tok/s 73633 (59271)	Loss/tok 3.4657 (3.2911)	Learning Rate [7.8125e-05]
2: TRAIN [1][3120/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00093)	Tok/s 52562 (59629)	Loss/tok 3.3364 (3.2905)	Learning Rate [7.8125e-05]
3: TRAIN [1][3120/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00097)	Tok/s 53647 (60088)	Loss/tok 3.0466 (3.2913)	Learning Rate [7.8125e-05]
1: TRAIN [1][3120/6832]	Time 0.087 (0.105)	Data 0.00106 (0.00093)	Tok/s 52692 (59260)	Loss/tok 3.1204 (3.2910)	Learning Rate [7.8125e-05]
0: TRAIN [1][3120/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00095)	Tok/s 52577 (58815)	Loss/tok 3.1788 (3.2879)	Learning Rate [7.8125e-05]
2: TRAIN [1][3130/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00093)	Tok/s 38498 (59606)	Loss/tok 1.7924 (3.2903)	Learning Rate [7.8125e-05]
3: TRAIN [1][3130/6832]	Time 0.043 (0.105)	Data 0.00087 (0.00097)	Tok/s 42182 (60066)	Loss/tok 2.3343 (3.2912)	Learning Rate [7.8125e-05]
0: TRAIN [1][3130/6832]	Time 0.043 (0.105)	Data 0.00098 (0.00095)	Tok/s 21929 (58787)	Loss/tok 1.7112 (3.2877)	Learning Rate [7.8125e-05]
1: TRAIN [1][3130/6832]	Time 0.043 (0.105)	Data 0.00098 (0.00093)	Tok/s 34162 (59236)	Loss/tok 1.9721 (3.2907)	Learning Rate [7.8125e-05]
2: TRAIN [1][3140/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00093)	Tok/s 55800 (59610)	Loss/tok 2.9871 (3.2901)	Learning Rate [7.8125e-05]
3: TRAIN [1][3140/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00097)	Tok/s 56565 (60071)	Loss/tok 3.2669 (3.2911)	Learning Rate [7.8125e-05]
0: TRAIN [1][3140/6832]	Time 0.092 (0.105)	Data 0.00088 (0.00095)	Tok/s 55786 (58792)	Loss/tok 3.0825 (3.2876)	Learning Rate [7.8125e-05]
1: TRAIN [1][3140/6832]	Time 0.092 (0.105)	Data 0.00099 (0.00093)	Tok/s 55769 (59240)	Loss/tok 3.2077 (3.2907)	Learning Rate [7.8125e-05]
2: TRAIN [1][3150/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00093)	Tok/s 62484 (59603)	Loss/tok 3.4894 (3.2904)	Learning Rate [7.8125e-05]
3: TRAIN [1][3150/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00097)	Tok/s 63319 (60064)	Loss/tok 3.4494 (3.2912)	Learning Rate [7.8125e-05]
0: TRAIN [1][3150/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00095)	Tok/s 62544 (58787)	Loss/tok 3.3926 (3.2878)	Learning Rate [7.8125e-05]
1: TRAIN [1][3150/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00093)	Tok/s 62500 (59234)	Loss/tok 3.4702 (3.2908)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [1][3160/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00093)	Tok/s 67906 (59597)	Loss/tok 3.4830 (3.2903)	Learning Rate [7.8125e-05]
3: TRAIN [1][3160/6832]	Time 0.130 (0.105)	Data 0.00082 (0.00097)	Tok/s 68756 (60058)	Loss/tok 3.4973 (3.2912)	Learning Rate [7.8125e-05]
0: TRAIN [1][3160/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00095)	Tok/s 67851 (58782)	Loss/tok 3.3930 (3.2878)	Learning Rate [7.8125e-05]
1: TRAIN [1][3160/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00093)	Tok/s 67867 (59228)	Loss/tok 3.4969 (3.2908)	Learning Rate [7.8125e-05]
2: TRAIN [1][3170/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00093)	Tok/s 64621 (59589)	Loss/tok 3.2853 (3.2900)	Learning Rate [7.8125e-05]
3: TRAIN [1][3170/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00097)	Tok/s 64640 (60049)	Loss/tok 3.4365 (3.2912)	Learning Rate [7.8125e-05]
0: TRAIN [1][3170/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00095)	Tok/s 63617 (58770)	Loss/tok 3.4087 (3.2877)	Learning Rate [7.8125e-05]
1: TRAIN [1][3170/6832]	Time 0.123 (0.105)	Data 0.00098 (0.00093)	Tok/s 63831 (59219)	Loss/tok 3.4775 (3.2907)	Learning Rate [7.8125e-05]
2: TRAIN [1][3180/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00093)	Tok/s 61701 (59576)	Loss/tok 3.3429 (3.2899)	Learning Rate [7.8125e-05]
3: TRAIN [1][3180/6832]	Time 0.127 (0.105)	Data 0.00084 (0.00097)	Tok/s 61708 (60037)	Loss/tok 3.2162 (3.2910)	Learning Rate [7.8125e-05]
0: TRAIN [1][3180/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00095)	Tok/s 60698 (58758)	Loss/tok 3.5406 (3.2877)	Learning Rate [7.8125e-05]
1: TRAIN [1][3180/6832]	Time 0.127 (0.105)	Data 0.00099 (0.00093)	Tok/s 61333 (59207)	Loss/tok 3.2223 (3.2904)	Learning Rate [7.8125e-05]
2: TRAIN [1][3190/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00093)	Tok/s 65683 (59560)	Loss/tok 3.5353 (3.2898)	Learning Rate [7.8125e-05]
0: TRAIN [1][3190/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 65715 (58738)	Loss/tok 3.4419 (3.2876)	Learning Rate [7.8125e-05]
3: TRAIN [1][3190/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00097)	Tok/s 65945 (60022)	Loss/tok 3.3681 (3.2908)	Learning Rate [7.8125e-05]
1: TRAIN [1][3190/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00093)	Tok/s 65662 (59189)	Loss/tok 3.3030 (3.2902)	Learning Rate [7.8125e-05]
2: TRAIN [1][3200/6832]	Time 0.076 (0.105)	Data 0.00095 (0.00093)	Tok/s 52404 (59558)	Loss/tok 3.0871 (3.2900)	Learning Rate [7.8125e-05]
3: TRAIN [1][3200/6832]	Time 0.076 (0.105)	Data 0.00094 (0.00097)	Tok/s 52413 (60019)	Loss/tok 3.0136 (3.2910)	Learning Rate [7.8125e-05]
0: TRAIN [1][3200/6832]	Time 0.076 (0.105)	Data 0.00085 (0.00095)	Tok/s 50683 (58737)	Loss/tok 3.0081 (3.2876)	Learning Rate [7.8125e-05]
1: TRAIN [1][3200/6832]	Time 0.076 (0.105)	Data 0.00108 (0.00093)	Tok/s 51546 (59188)	Loss/tok 3.0033 (3.2902)	Learning Rate [7.8125e-05]
2: TRAIN [1][3210/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00093)	Tok/s 81779 (59571)	Loss/tok 3.2304 (3.2899)	Learning Rate [7.8125e-05]
0: TRAIN [1][3210/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 80787 (58750)	Loss/tok 3.1346 (3.2877)	Learning Rate [7.8125e-05]
3: TRAIN [1][3210/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00097)	Tok/s 82419 (60031)	Loss/tok 3.2923 (3.2909)	Learning Rate [7.8125e-05]
1: TRAIN [1][3210/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00093)	Tok/s 81465 (59201)	Loss/tok 3.3537 (3.2904)	Learning Rate [7.8125e-05]
2: TRAIN [1][3220/6832]	Time 0.121 (0.105)	Data 0.00103 (0.00093)	Tok/s 59879 (59566)	Loss/tok 3.5215 (3.2901)	Learning Rate [7.8125e-05]
0: TRAIN [1][3220/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00095)	Tok/s 59084 (58744)	Loss/tok 3.3710 (3.2878)	Learning Rate [7.8125e-05]
3: TRAIN [1][3220/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00097)	Tok/s 60129 (60026)	Loss/tok 3.3286 (3.2909)	Learning Rate [7.8125e-05]
1: TRAIN [1][3220/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00093)	Tok/s 59063 (59195)	Loss/tok 3.3067 (3.2904)	Learning Rate [7.8125e-05]
2: TRAIN [1][3230/6832]	Time 0.055 (0.105)	Data 0.00097 (0.00093)	Tok/s 51069 (59559)	Loss/tok 2.7229 (3.2899)	Learning Rate [7.8125e-05]
0: TRAIN [1][3230/6832]	Time 0.055 (0.105)	Data 0.00086 (0.00095)	Tok/s 49704 (58737)	Loss/tok 2.7823 (3.2880)	Learning Rate [7.8125e-05]
3: TRAIN [1][3230/6832]	Time 0.055 (0.105)	Data 0.00097 (0.00097)	Tok/s 52119 (60018)	Loss/tok 2.8961 (3.2908)	Learning Rate [7.8125e-05]
1: TRAIN [1][3230/6832]	Time 0.055 (0.105)	Data 0.00103 (0.00093)	Tok/s 51070 (59188)	Loss/tok 2.6918 (3.2903)	Learning Rate [7.8125e-05]
2: TRAIN [1][3240/6832]	Time 0.084 (0.105)	Data 0.00097 (0.00093)	Tok/s 51907 (59566)	Loss/tok 3.1007 (3.2899)	Learning Rate [7.8125e-05]
0: TRAIN [1][3240/6832]	Time 0.084 (0.105)	Data 0.00093 (0.00095)	Tok/s 51878 (58746)	Loss/tok 3.0313 (3.2881)	Learning Rate [7.8125e-05]
3: TRAIN [1][3240/6832]	Time 0.084 (0.105)	Data 0.00094 (0.00097)	Tok/s 51768 (60025)	Loss/tok 3.1138 (3.2910)	Learning Rate [7.8125e-05]
1: TRAIN [1][3240/6832]	Time 0.084 (0.105)	Data 0.00100 (0.00093)	Tok/s 51854 (59196)	Loss/tok 3.0894 (3.2903)	Learning Rate [7.8125e-05]
3: TRAIN [1][3250/6832]	Time 0.076 (0.105)	Data 0.00099 (0.00097)	Tok/s 53954 (60042)	Loss/tok 3.0489 (3.2908)	Learning Rate [7.8125e-05]
0: TRAIN [1][3250/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00095)	Tok/s 53879 (58763)	Loss/tok 3.0785 (3.2879)	Learning Rate [7.8125e-05]
2: TRAIN [1][3250/6832]	Time 0.076 (0.105)	Data 0.00100 (0.00093)	Tok/s 53898 (59582)	Loss/tok 3.0239 (3.2898)	Learning Rate [7.8125e-05]
1: TRAIN [1][3250/6832]	Time 0.076 (0.105)	Data 0.00097 (0.00093)	Tok/s 53861 (59213)	Loss/tok 3.0153 (3.2902)	Learning Rate [7.8125e-05]
2: TRAIN [1][3260/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00093)	Tok/s 61428 (59600)	Loss/tok 3.4127 (3.2896)	Learning Rate [7.8125e-05]
3: TRAIN [1][3260/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00097)	Tok/s 62382 (60059)	Loss/tok 3.4364 (3.2908)	Learning Rate [7.8125e-05]
0: TRAIN [1][3260/6832]	Time 0.127 (0.105)	Data 0.00108 (0.00095)	Tok/s 61460 (58781)	Loss/tok 3.4186 (3.2879)	Learning Rate [7.8125e-05]
1: TRAIN [1][3260/6832]	Time 0.127 (0.105)	Data 0.00115 (0.00093)	Tok/s 61454 (59231)	Loss/tok 3.4956 (3.2901)	Learning Rate [7.8125e-05]
2: TRAIN [1][3270/6832]	Time 0.122 (0.105)	Data 0.00096 (0.00093)	Tok/s 58675 (59607)	Loss/tok 3.5169 (3.2897)	Learning Rate [7.8125e-05]
3: TRAIN [1][3270/6832]	Time 0.122 (0.105)	Data 0.00099 (0.00097)	Tok/s 58684 (60066)	Loss/tok 3.3380 (3.2908)	Learning Rate [7.8125e-05]
0: TRAIN [1][3270/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00095)	Tok/s 58003 (58789)	Loss/tok 3.4107 (3.2879)	Learning Rate [7.8125e-05]
1: TRAIN [1][3270/6832]	Time 0.122 (0.105)	Data 0.00098 (0.00093)	Tok/s 58653 (59238)	Loss/tok 3.4274 (3.2902)	Learning Rate [7.8125e-05]
2: TRAIN [1][3280/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00093)	Tok/s 72747 (59607)	Loss/tok 3.3434 (3.2895)	Learning Rate [7.8125e-05]
3: TRAIN [1][3280/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00097)	Tok/s 72757 (60065)	Loss/tok 3.4418 (3.2909)	Learning Rate [7.8125e-05]
0: TRAIN [1][3280/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 71810 (58790)	Loss/tok 3.3311 (3.2877)	Learning Rate [7.8125e-05]
1: TRAIN [1][3280/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00093)	Tok/s 72253 (59239)	Loss/tok 3.4194 (3.2902)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][3290/6832]	Time 0.129 (0.105)	Data 0.00104 (0.00093)	Tok/s 69478 (59616)	Loss/tok 3.2644 (3.2892)	Learning Rate [7.8125e-05]
0: TRAIN [1][3290/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 69438 (58799)	Loss/tok 3.4918 (3.2875)	Learning Rate [7.8125e-05]
3: TRAIN [1][3290/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00097)	Tok/s 70093 (60075)	Loss/tok 3.3150 (3.2907)	Learning Rate [7.8125e-05]
1: TRAIN [1][3290/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00094)	Tok/s 69446 (59248)	Loss/tok 3.4796 (3.2901)	Learning Rate [7.8125e-05]
2: TRAIN [1][3300/6832]	Time 0.100 (0.105)	Data 0.00096 (0.00093)	Tok/s 52651 (59608)	Loss/tok 3.2739 (3.2890)	Learning Rate [7.8125e-05]
0: TRAIN [1][3300/6832]	Time 0.100 (0.105)	Data 0.00088 (0.00095)	Tok/s 52639 (58792)	Loss/tok 3.1800 (3.2873)	Learning Rate [7.8125e-05]
3: TRAIN [1][3300/6832]	Time 0.100 (0.105)	Data 0.00096 (0.00097)	Tok/s 52625 (60067)	Loss/tok 3.1234 (3.2905)	Learning Rate [7.8125e-05]
1: TRAIN [1][3300/6832]	Time 0.100 (0.105)	Data 0.00106 (0.00094)	Tok/s 52661 (59241)	Loss/tok 2.8820 (3.2899)	Learning Rate [7.8125e-05]
2: TRAIN [1][3310/6832]	Time 0.066 (0.105)	Data 0.00108 (0.00093)	Tok/s 52305 (59619)	Loss/tok 2.9347 (3.2888)	Learning Rate [7.8125e-05]
0: TRAIN [1][3310/6832]	Time 0.066 (0.105)	Data 0.00094 (0.00095)	Tok/s 52356 (58803)	Loss/tok 2.9687 (3.2872)	Learning Rate [7.8125e-05]
3: TRAIN [1][3310/6832]	Time 0.066 (0.105)	Data 0.00106 (0.00097)	Tok/s 52387 (60077)	Loss/tok 2.9412 (3.2904)	Learning Rate [7.8125e-05]
1: TRAIN [1][3310/6832]	Time 0.066 (0.105)	Data 0.00103 (0.00094)	Tok/s 52396 (59252)	Loss/tok 2.9403 (3.2897)	Learning Rate [7.8125e-05]
2: TRAIN [1][3320/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00093)	Tok/s 72469 (59635)	Loss/tok 3.2664 (3.2889)	Learning Rate [7.8125e-05]
0: TRAIN [1][3320/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 71455 (58819)	Loss/tok 3.3738 (3.2872)	Learning Rate [7.8125e-05]
3: TRAIN [1][3320/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00097)	Tok/s 72476 (60092)	Loss/tok 3.4733 (3.2906)	Learning Rate [7.8125e-05]
1: TRAIN [1][3320/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00094)	Tok/s 71941 (59268)	Loss/tok 3.5239 (3.2899)	Learning Rate [7.8125e-05]
2: TRAIN [1][3330/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00093)	Tok/s 62608 (59633)	Loss/tok 3.3106 (3.2889)	Learning Rate [7.8125e-05]
0: TRAIN [1][3330/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00095)	Tok/s 61683 (58818)	Loss/tok 3.3515 (3.2872)	Learning Rate [7.8125e-05]
3: TRAIN [1][3330/6832]	Time 0.123 (0.105)	Data 0.00100 (0.00097)	Tok/s 62650 (60091)	Loss/tok 3.3458 (3.2905)	Learning Rate [7.8125e-05]
1: TRAIN [1][3330/6832]	Time 0.122 (0.105)	Data 0.00100 (0.00094)	Tok/s 61659 (59266)	Loss/tok 3.2377 (3.2899)	Learning Rate [7.8125e-05]
2: TRAIN [1][3340/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00093)	Tok/s 56838 (59633)	Loss/tok 3.4380 (3.2888)	Learning Rate [7.8125e-05]
1: TRAIN [1][3340/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00094)	Tok/s 56805 (59266)	Loss/tok 3.4123 (3.2897)	Learning Rate [7.8125e-05]
0: TRAIN [1][3340/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00095)	Tok/s 56831 (58818)	Loss/tok 3.2795 (3.2871)	Learning Rate [7.8125e-05]
3: TRAIN [1][3340/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00097)	Tok/s 56831 (60092)	Loss/tok 3.3053 (3.2904)	Learning Rate [7.8125e-05]
2: TRAIN [1][3350/6832]	Time 0.046 (0.105)	Data 0.00089 (0.00093)	Tok/s 36034 (59625)	Loss/tok 1.9256 (3.2883)	Learning Rate [7.8125e-05]
0: TRAIN [1][3350/6832]	Time 0.046 (0.105)	Data 0.00089 (0.00095)	Tok/s 19351 (58804)	Loss/tok 1.6701 (3.2867)	Learning Rate [7.8125e-05]
3: TRAIN [1][3350/6832]	Time 0.046 (0.105)	Data 0.00091 (0.00097)	Tok/s 39650 (60085)	Loss/tok 2.3475 (3.2902)	Learning Rate [7.8125e-05]
1: TRAIN [1][3350/6832]	Time 0.046 (0.105)	Data 0.00099 (0.00094)	Tok/s 31087 (59257)	Loss/tok 2.1549 (3.2893)	Learning Rate [7.8125e-05]
2: TRAIN [1][3360/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00093)	Tok/s 69644 (59625)	Loss/tok 3.4706 (3.2882)	Learning Rate [7.8125e-05]
3: TRAIN [1][3360/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00097)	Tok/s 69613 (60085)	Loss/tok 3.3334 (3.2900)	Learning Rate [7.8125e-05]
0: TRAIN [1][3360/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00095)	Tok/s 69030 (58804)	Loss/tok 3.3104 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][3360/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 69633 (59257)	Loss/tok 3.2610 (3.2891)	Learning Rate [7.8125e-05]
0: TRAIN [1][3370/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 82491 (58810)	Loss/tok 3.3293 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][3370/6832]	Time 0.133 (0.105)	Data 0.00100 (0.00093)	Tok/s 83415 (59631)	Loss/tok 3.1578 (3.2881)	Learning Rate [7.8125e-05]
3: TRAIN [1][3370/6832]	Time 0.133 (0.105)	Data 0.00095 (0.00097)	Tok/s 84021 (60090)	Loss/tok 3.2905 (3.2898)	Learning Rate [7.8125e-05]
1: TRAIN [1][3370/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00094)	Tok/s 83095 (59263)	Loss/tok 3.2553 (3.2890)	Learning Rate [7.8125e-05]
0: TRAIN [1][3380/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00095)	Tok/s 52148 (58800)	Loss/tok 3.3386 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][3380/6832]	Time 0.120 (0.105)	Data 0.00083 (0.00093)	Tok/s 52103 (59621)	Loss/tok 3.3863 (3.2878)	Learning Rate [7.8125e-05]
3: TRAIN [1][3380/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00097)	Tok/s 52134 (60080)	Loss/tok 3.2938 (3.2896)	Learning Rate [7.8125e-05]
1: TRAIN [1][3380/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00094)	Tok/s 52142 (59252)	Loss/tok 3.2126 (3.2889)	Learning Rate [7.8125e-05]
2: TRAIN [1][3390/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 76819 (59621)	Loss/tok 3.3479 (3.2879)	Learning Rate [7.8125e-05]
0: TRAIN [1][3390/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 75851 (58801)	Loss/tok 3.4389 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3390/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00097)	Tok/s 76836 (60080)	Loss/tok 3.4726 (3.2896)	Learning Rate [7.8125e-05]
1: TRAIN [1][3390/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00094)	Tok/s 76277 (59253)	Loss/tok 3.3318 (3.2890)	Learning Rate [7.8125e-05]
2: TRAIN [1][3400/6832]	Time 0.074 (0.105)	Data 0.00083 (0.00093)	Tok/s 52845 (59604)	Loss/tok 3.2327 (3.2876)	Learning Rate [7.8125e-05]
0: TRAIN [1][3400/6832]	Time 0.074 (0.105)	Data 0.00085 (0.00095)	Tok/s 51690 (58779)	Loss/tok 2.9476 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][3400/6832]	Time 0.074 (0.105)	Data 0.00086 (0.00097)	Tok/s 53475 (60064)	Loss/tok 3.0431 (3.2894)	Learning Rate [7.8125e-05]
1: TRAIN [1][3400/6832]	Time 0.074 (0.105)	Data 0.00096 (0.00094)	Tok/s 51697 (59234)	Loss/tok 2.9437 (3.2887)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][3410/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00093)	Tok/s 52125 (59610)	Loss/tok 3.0871 (3.2877)	Learning Rate [7.8125e-05]
0: TRAIN [1][3410/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00095)	Tok/s 52162 (58785)	Loss/tok 3.2062 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3410/6832]	Time 0.088 (0.105)	Data 0.00093 (0.00097)	Tok/s 52076 (60069)	Loss/tok 3.2236 (3.2896)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
1: TRAIN [1][3410/6832]	Time 0.088 (0.105)	Data 0.00099 (0.00094)	Tok/s 52144 (59240)	Loss/tok 3.1735 (3.2890)	Learning Rate [7.8125e-05]
2: TRAIN [1][3420/6832]	Time 0.101 (0.105)	Data 0.00096 (0.00093)	Tok/s 53450 (59606)	Loss/tok 3.3165 (3.2879)	Learning Rate [7.8125e-05]
0: TRAIN [1][3420/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00095)	Tok/s 52187 (58781)	Loss/tok 3.1313 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][3420/6832]	Time 0.101 (0.105)	Data 0.00101 (0.00097)	Tok/s 53458 (60065)	Loss/tok 3.1484 (3.2899)	Learning Rate [7.8125e-05]
1: TRAIN [1][3420/6832]	Time 0.101 (0.105)	Data 0.00102 (0.00094)	Tok/s 53455 (59236)	Loss/tok 3.3018 (3.2891)	Learning Rate [7.8125e-05]
0: TRAIN [1][3430/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00095)	Tok/s 51825 (58787)	Loss/tok 3.2646 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][3430/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00097)	Tok/s 51881 (60070)	Loss/tok 3.2388 (3.2897)	Learning Rate [7.8125e-05]
2: TRAIN [1][3430/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00093)	Tok/s 51833 (59611)	Loss/tok 2.9926 (3.2876)	Learning Rate [7.8125e-05]
1: TRAIN [1][3430/6832]	Time 0.074 (0.105)	Data 0.00105 (0.00094)	Tok/s 51846 (59242)	Loss/tok 3.0812 (3.2889)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [1][3440/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00093)	Tok/s 51980 (59615)	Loss/tok 3.2750 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][3440/6832]	Time 0.111 (0.105)	Data 0.00089 (0.00095)	Tok/s 51792 (58790)	Loss/tok 3.3633 (3.2861)	Learning Rate [7.8125e-05]
3: TRAIN [1][3440/6832]	Time 0.111 (0.105)	Data 0.00095 (0.00097)	Tok/s 53038 (60074)	Loss/tok 3.3100 (3.2895)	Learning Rate [7.8125e-05]
1: TRAIN [1][3440/6832]	Time 0.111 (0.105)	Data 0.00099 (0.00094)	Tok/s 51809 (59245)	Loss/tok 3.4101 (3.2887)	Learning Rate [7.8125e-05]
2: TRAIN [1][3450/6832]	Time 0.052 (0.105)	Data 0.00086 (0.00093)	Tok/s 47335 (59601)	Loss/tok 2.5995 (3.2874)	Learning Rate [7.8125e-05]
0: TRAIN [1][3450/6832]	Time 0.052 (0.105)	Data 0.00091 (0.00095)	Tok/s 45214 (58777)	Loss/tok 2.4983 (3.2859)	Learning Rate [7.8125e-05]
3: TRAIN [1][3450/6832]	Time 0.052 (0.105)	Data 0.00091 (0.00097)	Tok/s 49457 (60061)	Loss/tok 2.7834 (3.2894)	Learning Rate [7.8125e-05]
1: TRAIN [1][3450/6832]	Time 0.052 (0.105)	Data 0.00100 (0.00094)	Tok/s 47003 (59232)	Loss/tok 2.4892 (3.2886)	Learning Rate [7.8125e-05]
2: TRAIN [1][3460/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00093)	Tok/s 59682 (59592)	Loss/tok 3.3863 (3.2873)	Learning Rate [7.8125e-05]
3: TRAIN [1][3460/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00097)	Tok/s 59695 (60051)	Loss/tok 3.2905 (3.2894)	Learning Rate [7.8125e-05]
0: TRAIN [1][3460/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00095)	Tok/s 58665 (58764)	Loss/tok 3.3868 (3.2859)	Learning Rate [7.8125e-05]
1: TRAIN [1][3460/6832]	Time 0.129 (0.105)	Data 0.00104 (0.00094)	Tok/s 58935 (59221)	Loss/tok 3.4294 (3.2887)	Learning Rate [7.8125e-05]
2: TRAIN [1][3470/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00093)	Tok/s 88466 (59593)	Loss/tok 3.1521 (3.2873)	Learning Rate [7.8125e-05]
3: TRAIN [1][3470/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00097)	Tok/s 89385 (60053)	Loss/tok 3.1341 (3.2894)	Learning Rate [7.8125e-05]
0: TRAIN [1][3470/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 87060 (58766)	Loss/tok 3.2203 (3.2859)	Learning Rate [7.8125e-05]
1: TRAIN [1][3470/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00094)	Tok/s 87911 (59223)	Loss/tok 3.2974 (3.2887)	Learning Rate [7.8125e-05]
2: TRAIN [1][3480/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00093)	Tok/s 76278 (59604)	Loss/tok 3.3386 (3.2873)	Learning Rate [7.8125e-05]
0: TRAIN [1][3480/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 75679 (58777)	Loss/tok 3.3001 (3.2860)	Learning Rate [7.8125e-05]
3: TRAIN [1][3480/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00097)	Tok/s 76609 (60063)	Loss/tok 3.3714 (3.2894)	Learning Rate [7.8125e-05]
1: TRAIN [1][3480/6832]	Time 0.130 (0.105)	Data 0.00108 (0.00094)	Tok/s 75628 (59233)	Loss/tok 3.3917 (3.2886)	Learning Rate [7.8125e-05]
0: TRAIN [1][3490/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00095)	Tok/s 76305 (58779)	Loss/tok 3.3396 (3.2859)	Learning Rate [7.8125e-05]
2: TRAIN [1][3490/6832]	Time 0.132 (0.105)	Data 0.00083 (0.00093)	Tok/s 76617 (59606)	Loss/tok 3.4333 (3.2873)	Learning Rate [7.8125e-05]
3: TRAIN [1][3490/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00097)	Tok/s 77407 (60065)	Loss/tok 3.3879 (3.2893)	Learning Rate [7.8125e-05]
1: TRAIN [1][3490/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00094)	Tok/s 76653 (59235)	Loss/tok 3.5013 (3.2885)	Learning Rate [7.8125e-05]
2: TRAIN [1][3500/6832]	Time 0.076 (0.105)	Data 0.00084 (0.00093)	Tok/s 52512 (59611)	Loss/tok 3.0808 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][3500/6832]	Time 0.076 (0.105)	Data 0.00088 (0.00095)	Tok/s 52515 (58785)	Loss/tok 2.9763 (3.2861)	Learning Rate [7.8125e-05]
3: TRAIN [1][3500/6832]	Time 0.076 (0.105)	Data 0.00088 (0.00097)	Tok/s 54142 (60070)	Loss/tok 2.9760 (3.2893)	Learning Rate [7.8125e-05]
1: TRAIN [1][3500/6832]	Time 0.076 (0.105)	Data 0.00106 (0.00094)	Tok/s 52531 (59241)	Loss/tok 2.9640 (3.2886)	Learning Rate [7.8125e-05]
2: TRAIN [1][3510/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 81873 (59622)	Loss/tok 3.2168 (3.2874)	Learning Rate [7.8125e-05]
0: TRAIN [1][3510/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 81112 (58798)	Loss/tok 3.1515 (3.2861)	Learning Rate [7.8125e-05]
3: TRAIN [1][3510/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00097)	Tok/s 82719 (60081)	Loss/tok 3.2313 (3.2892)	Learning Rate [7.8125e-05]
1: TRAIN [1][3510/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00094)	Tok/s 81839 (59252)	Loss/tok 3.2444 (3.2886)	Learning Rate [7.8125e-05]
2: TRAIN [1][3520/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 70556 (59634)	Loss/tok 3.2427 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][3520/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 70354 (58810)	Loss/tok 3.2969 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3520/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00097)	Tok/s 70972 (60092)	Loss/tok 3.3375 (3.2893)	Learning Rate [7.8125e-05]
1: TRAIN [1][3520/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00094)	Tok/s 70507 (59264)	Loss/tok 3.5230 (3.2890)	Learning Rate [7.8125e-05]
2: TRAIN [1][3530/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00093)	Tok/s 64119 (59646)	Loss/tok 3.3411 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][3530/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00095)	Tok/s 63905 (58823)	Loss/tok 3.2202 (3.2866)	Learning Rate [7.8125e-05]
3: TRAIN [1][3530/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00097)	Tok/s 64994 (60105)	Loss/tok 3.3621 (3.2892)	Learning Rate [7.8125e-05]
1: TRAIN [1][3530/6832]	Time 0.126 (0.105)	Data 0.00104 (0.00094)	Tok/s 63978 (59277)	Loss/tok 3.5803 (3.2890)	Learning Rate [7.8125e-05]
2: TRAIN [1][3540/6832]	Time 0.051 (0.105)	Data 0.00084 (0.00093)	Tok/s 47957 (59645)	Loss/tok 2.6359 (3.2873)	Learning Rate [7.8125e-05]
0: TRAIN [1][3540/6832]	Time 0.051 (0.105)	Data 0.00089 (0.00095)	Tok/s 45327 (58823)	Loss/tok 2.6037 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3540/6832]	Time 0.051 (0.105)	Data 0.00089 (0.00097)	Tok/s 50377 (60104)	Loss/tok 2.8059 (3.2891)	Learning Rate [7.8125e-05]
1: TRAIN [1][3540/6832]	Time 0.051 (0.105)	Data 0.00099 (0.00094)	Tok/s 47821 (59277)	Loss/tok 2.6666 (3.2889)	Learning Rate [7.8125e-05]
2: TRAIN [1][3550/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00093)	Tok/s 60340 (59649)	Loss/tok 3.3529 (3.2874)	Learning Rate [7.8125e-05]
3: TRAIN [1][3550/6832]	Time 0.119 (0.105)	Data 0.00103 (0.00097)	Tok/s 60355 (60108)	Loss/tok 3.1319 (3.2891)	Learning Rate [7.8125e-05]
0: TRAIN [1][3550/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00095)	Tok/s 59540 (58828)	Loss/tok 3.2284 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][3550/6832]	Time 0.119 (0.105)	Data 0.00108 (0.00094)	Tok/s 60366 (59281)	Loss/tok 3.2436 (3.2890)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [1][3560/6832]	Time 0.076 (0.105)	Data 0.00127 (0.00093)	Tok/s 51119 (59659)	Loss/tok 3.1224 (3.2876)	Learning Rate [7.8125e-05]
0: TRAIN [1][3560/6832]	Time 0.076 (0.105)	Data 0.00094 (0.00095)	Tok/s 50328 (58839)	Loss/tok 3.0083 (3.2867)	Learning Rate [7.8125e-05]
3: TRAIN [1][3560/6832]	Time 0.076 (0.105)	Data 0.00123 (0.00097)	Tok/s 52009 (60118)	Loss/tok 3.1424 (3.2892)	Learning Rate [7.8125e-05]
1: TRAIN [1][3560/6832]	Time 0.076 (0.105)	Data 0.00108 (0.00094)	Tok/s 50381 (59292)	Loss/tok 3.1991 (3.2892)	Learning Rate [7.8125e-05]
2: TRAIN [1][3570/6832]	Time 0.121 (0.105)	Data 0.00101 (0.00093)	Tok/s 58045 (59651)	Loss/tok 3.3408 (3.2878)	Learning Rate [7.8125e-05]
3: TRAIN [1][3570/6832]	Time 0.121 (0.105)	Data 0.00099 (0.00097)	Tok/s 58086 (60109)	Loss/tok 3.2379 (3.2892)	Learning Rate [7.8125e-05]
0: TRAIN [1][3570/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00095)	Tok/s 57853 (58832)	Loss/tok 3.3427 (3.2866)	Learning Rate [7.8125e-05]
1: TRAIN [1][3570/6832]	Time 0.121 (0.105)	Data 0.00100 (0.00094)	Tok/s 57978 (59284)	Loss/tok 3.2716 (3.2893)	Learning Rate [7.8125e-05]
2: TRAIN [1][3580/6832]	Time 0.071 (0.105)	Data 0.00094 (0.00093)	Tok/s 48545 (59648)	Loss/tok 2.8591 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][3580/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00095)	Tok/s 48541 (58830)	Loss/tok 2.8940 (3.2867)	Learning Rate [7.8125e-05]
3: TRAIN [1][3580/6832]	Time 0.071 (0.105)	Data 0.00103 (0.00097)	Tok/s 49113 (60106)	Loss/tok 2.7680 (3.2895)	Learning Rate [7.8125e-05]
1: TRAIN [1][3580/6832]	Time 0.071 (0.105)	Data 0.00105 (0.00094)	Tok/s 48556 (59281)	Loss/tok 3.2697 (3.2893)	Learning Rate [7.8125e-05]
2: TRAIN [1][3590/6832]	Time 0.091 (0.105)	Data 0.00100 (0.00093)	Tok/s 51761 (59641)	Loss/tok 3.2237 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][3590/6832]	Time 0.092 (0.105)	Data 0.00093 (0.00095)	Tok/s 51717 (58825)	Loss/tok 3.1633 (3.2867)	Learning Rate [7.8125e-05]
3: TRAIN [1][3590/6832]	Time 0.092 (0.105)	Data 0.00094 (0.00097)	Tok/s 51742 (60099)	Loss/tok 3.1503 (3.2893)	Learning Rate [7.8125e-05]
1: TRAIN [1][3590/6832]	Time 0.092 (0.105)	Data 0.00101 (0.00094)	Tok/s 51675 (59275)	Loss/tok 3.1405 (3.2893)	Learning Rate [7.8125e-05]
2: TRAIN [1][3600/6832]	Time 0.132 (0.105)	Data 0.00107 (0.00093)	Tok/s 79658 (59656)	Loss/tok 3.2010 (3.2881)	Learning Rate [7.8125e-05]
0: TRAIN [1][3600/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 78817 (58839)	Loss/tok 3.3707 (3.2869)	Learning Rate [7.8125e-05]
3: TRAIN [1][3600/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00097)	Tok/s 80235 (60113)	Loss/tok 3.3292 (3.2895)	Learning Rate [7.8125e-05]
1: TRAIN [1][3600/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00094)	Tok/s 79316 (59290)	Loss/tok 3.2313 (3.2895)	Learning Rate [7.8125e-05]
2: TRAIN [1][3610/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00093)	Tok/s 56892 (59652)	Loss/tok 3.4868 (3.2881)	Learning Rate [7.8125e-05]
0: TRAIN [1][3610/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00095)	Tok/s 55890 (58836)	Loss/tok 3.2336 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][3610/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00097)	Tok/s 56896 (60109)	Loss/tok 3.1012 (3.2893)	Learning Rate [7.8125e-05]
1: TRAIN [1][3610/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00094)	Tok/s 56831 (59286)	Loss/tok 3.3249 (3.2894)	Learning Rate [7.8125e-05]
2: TRAIN [1][3620/6832]	Time 0.069 (0.105)	Data 0.00098 (0.00093)	Tok/s 51999 (59656)	Loss/tok 2.7560 (3.2879)	Learning Rate [7.8125e-05]
0: TRAIN [1][3620/6832]	Time 0.069 (0.105)	Data 0.00098 (0.00095)	Tok/s 51971 (58840)	Loss/tok 3.1074 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][3620/6832]	Time 0.069 (0.105)	Data 0.00094 (0.00097)	Tok/s 51981 (60113)	Loss/tok 2.8537 (3.2891)	Learning Rate [7.8125e-05]
1: TRAIN [1][3620/6832]	Time 0.069 (0.105)	Data 0.00102 (0.00094)	Tok/s 52022 (59291)	Loss/tok 3.0331 (3.2893)	Learning Rate [7.8125e-05]
2: TRAIN [1][3630/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00093)	Tok/s 53342 (59659)	Loss/tok 3.1378 (3.2877)	Learning Rate [7.8125e-05]
0: TRAIN [1][3630/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00095)	Tok/s 53330 (58844)	Loss/tok 3.0458 (3.2866)	Learning Rate [7.8125e-05]
3: TRAIN [1][3630/6832]	Time 0.070 (0.105)	Data 0.00094 (0.00097)	Tok/s 53348 (60116)	Loss/tok 3.1481 (3.2891)	Learning Rate [7.8125e-05]
1: TRAIN [1][3630/6832]	Time 0.070 (0.105)	Data 0.00100 (0.00094)	Tok/s 53348 (59294)	Loss/tok 2.9045 (3.2893)	Learning Rate [7.8125e-05]
2: TRAIN [1][3640/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00093)	Tok/s 56324 (59651)	Loss/tok 3.3707 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][3640/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00095)	Tok/s 55546 (58833)	Loss/tok 3.3289 (3.2864)	Learning Rate [7.8125e-05]
1: TRAIN [1][3640/6832]	Time 0.120 (0.105)	Data 0.00107 (0.00094)	Tok/s 56357 (59285)	Loss/tok 3.5046 (3.2892)	Learning Rate [7.8125e-05]
3: TRAIN [1][3640/6832]	Time 0.120 (0.105)	Data 0.00097 (0.00098)	Tok/s 56341 (60108)	Loss/tok 3.2616 (3.2889)	Learning Rate [7.8125e-05]
2: TRAIN [1][3650/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00093)	Tok/s 69295 (59645)	Loss/tok 3.4261 (3.2876)	Learning Rate [7.8125e-05]
3: TRAIN [1][3650/6832]	Time 0.129 (0.105)	Data 0.00204 (0.00098)	Tok/s 69605 (60102)	Loss/tok 3.4553 (3.2889)	Learning Rate [7.8125e-05]
0: TRAIN [1][3650/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 69008 (58829)	Loss/tok 3.5694 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][3650/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00094)	Tok/s 69283 (59279)	Loss/tok 3.4756 (3.2892)	Learning Rate [7.8125e-05]
2: TRAIN [1][3660/6832]	Time 0.094 (0.105)	Data 0.00109 (0.00093)	Tok/s 51829 (59638)	Loss/tok 3.1715 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][3660/6832]	Time 0.094 (0.105)	Data 0.00090 (0.00095)	Tok/s 51857 (58823)	Loss/tok 3.2126 (3.2865)	Learning Rate [7.8125e-05]
3: TRAIN [1][3660/6832]	Time 0.094 (0.105)	Data 0.00109 (0.00098)	Tok/s 52562 (60096)	Loss/tok 3.0829 (3.2888)	Learning Rate [7.8125e-05]
1: TRAIN [1][3660/6832]	Time 0.094 (0.105)	Data 0.00101 (0.00094)	Tok/s 51864 (59273)	Loss/tok 3.0491 (3.2891)	Learning Rate [7.8125e-05]
2: TRAIN [1][3670/6832]	Time 0.055 (0.105)	Data 0.00098 (0.00093)	Tok/s 51290 (59648)	Loss/tok 2.6805 (3.2873)	Learning Rate [7.8125e-05]
0: TRAIN [1][3670/6832]	Time 0.055 (0.105)	Data 0.00087 (0.00095)	Tok/s 49527 (58832)	Loss/tok 2.7687 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3670/6832]	Time 0.055 (0.105)	Data 0.00096 (0.00098)	Tok/s 51509 (60106)	Loss/tok 2.7773 (3.2888)	Learning Rate [7.8125e-05]
1: TRAIN [1][3670/6832]	Time 0.055 (0.105)	Data 0.00107 (0.00094)	Tok/s 51201 (59282)	Loss/tok 2.7873 (3.2889)	Learning Rate [7.8125e-05]
2: TRAIN [1][3680/6832]	Time 0.102 (0.105)	Data 0.00102 (0.00093)	Tok/s 53745 (59660)	Loss/tok 3.0586 (3.2870)	Learning Rate [7.8125e-05]
3: TRAIN [1][3680/6832]	Time 0.102 (0.105)	Data 0.00100 (0.00098)	Tok/s 53777 (60117)	Loss/tok 3.1389 (3.2884)	Learning Rate [7.8125e-05]
0: TRAIN [1][3680/6832]	Time 0.102 (0.105)	Data 0.00087 (0.00095)	Tok/s 53721 (58844)	Loss/tok 3.1819 (3.2862)	Learning Rate [7.8125e-05]
1: TRAIN [1][3680/6832]	Time 0.102 (0.105)	Data 0.00099 (0.00094)	Tok/s 53706 (59294)	Loss/tok 3.4047 (3.2887)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][3690/6832]	Time 0.116 (0.105)	Data 0.00101 (0.00093)	Tok/s 52994 (59669)	Loss/tok 3.3787 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][3690/6832]	Time 0.116 (0.105)	Data 0.00084 (0.00095)	Tok/s 52949 (58854)	Loss/tok 3.2524 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][3690/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00098)	Tok/s 53671 (60126)	Loss/tok 3.3398 (3.2884)	Learning Rate [7.8125e-05]
1: TRAIN [1][3690/6832]	Time 0.116 (0.105)	Data 0.00103 (0.00094)	Tok/s 52945 (59304)	Loss/tok 3.2785 (3.2888)	Learning Rate [7.8125e-05]
2: TRAIN [1][3700/6832]	Time 0.126 (0.105)	Data 0.00115 (0.00093)	Tok/s 58099 (59670)	Loss/tok 3.4400 (3.2874)	Learning Rate [7.8125e-05]
0: TRAIN [1][3700/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00095)	Tok/s 58070 (58855)	Loss/tok 3.3544 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][3700/6832]	Time 0.126 (0.105)	Data 0.00108 (0.00098)	Tok/s 58344 (60127)	Loss/tok 3.4297 (3.2885)	Learning Rate [7.8125e-05]
1: TRAIN [1][3700/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00094)	Tok/s 58034 (59305)	Loss/tok 3.4269 (3.2889)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [1][3710/6832]	Time 0.123 (0.105)	Data 0.00092 (0.00093)	Tok/s 56252 (59684)	Loss/tok 3.2324 (3.2874)	Learning Rate [7.8125e-05]
0: TRAIN [1][3710/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00095)	Tok/s 55217 (58871)	Loss/tok 3.4341 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][3710/6832]	Time 0.123 (0.105)	Data 0.00098 (0.00098)	Tok/s 56238 (60142)	Loss/tok 3.3912 (3.2883)	Learning Rate [7.8125e-05]
1: TRAIN [1][3710/6832]	Time 0.123 (0.105)	Data 0.00099 (0.00094)	Tok/s 55400 (59319)	Loss/tok 3.2991 (3.2888)	Learning Rate [7.8125e-05]
2: TRAIN [1][3720/6832]	Time 0.113 (0.105)	Data 0.00097 (0.00093)	Tok/s 53169 (59673)	Loss/tok 3.4461 (3.2874)	Learning Rate [7.8125e-05]
3: TRAIN [1][3720/6832]	Time 0.113 (0.105)	Data 0.00093 (0.00098)	Tok/s 53172 (60130)	Loss/tok 3.2959 (3.2882)	Learning Rate [7.8125e-05]
0: TRAIN [1][3720/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00095)	Tok/s 53128 (58859)	Loss/tok 3.4628 (3.2863)	Learning Rate [7.8125e-05]
1: TRAIN [1][3720/6832]	Time 0.113 (0.105)	Data 0.00096 (0.00094)	Tok/s 53119 (59308)	Loss/tok 3.2910 (3.2886)	Learning Rate [7.8125e-05]
2: TRAIN [1][3730/6832]	Time 0.103 (0.105)	Data 0.00107 (0.00094)	Tok/s 50233 (59675)	Loss/tok 3.1962 (3.2874)	Learning Rate [7.8125e-05]
3: TRAIN [1][3730/6832]	Time 0.103 (0.105)	Data 0.00108 (0.00098)	Tok/s 51179 (60133)	Loss/tok 2.9873 (3.2881)	Learning Rate [7.8125e-05]
0: TRAIN [1][3730/6832]	Time 0.103 (0.105)	Data 0.00097 (0.00095)	Tok/s 49845 (58863)	Loss/tok 3.1024 (3.2864)	Learning Rate [7.8125e-05]
1: TRAIN [1][3730/6832]	Time 0.103 (0.105)	Data 0.00097 (0.00094)	Tok/s 49919 (59311)	Loss/tok 3.1252 (3.2887)	Learning Rate [7.8125e-05]
2: TRAIN [1][3740/6832]	Time 0.055 (0.105)	Data 0.00103 (0.00094)	Tok/s 48548 (59680)	Loss/tok 2.6424 (3.2873)	Learning Rate [7.8125e-05]
0: TRAIN [1][3740/6832]	Time 0.055 (0.105)	Data 0.00090 (0.00095)	Tok/s 46242 (58868)	Loss/tok 2.7383 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][3740/6832]	Time 0.055 (0.105)	Data 0.00104 (0.00098)	Tok/s 48557 (60136)	Loss/tok 2.7161 (3.2882)	Learning Rate [7.8125e-05]
1: TRAIN [1][3740/6832]	Time 0.055 (0.105)	Data 0.00103 (0.00094)	Tok/s 47776 (59315)	Loss/tok 2.5832 (3.2885)	Learning Rate [7.8125e-05]
0: TRAIN [1][3750/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00095)	Tok/s 54516 (58869)	Loss/tok 3.2881 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][3750/6832]	Time 0.113 (0.105)	Data 0.00101 (0.00094)	Tok/s 55496 (59681)	Loss/tok 3.1960 (3.2874)	Learning Rate [7.8125e-05]
3: TRAIN [1][3750/6832]	Time 0.113 (0.105)	Data 0.00119 (0.00098)	Tok/s 55464 (60138)	Loss/tok 3.1629 (3.2880)	Learning Rate [7.8125e-05]
1: TRAIN [1][3750/6832]	Time 0.113 (0.105)	Data 0.00099 (0.00094)	Tok/s 54737 (59317)	Loss/tok 3.3716 (3.2884)	Learning Rate [7.8125e-05]
0: TRAIN [1][3760/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00095)	Tok/s 72988 (58869)	Loss/tok 3.4785 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][3760/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00094)	Tok/s 73913 (59680)	Loss/tok 3.3090 (3.2873)	Learning Rate [7.8125e-05]
3: TRAIN [1][3760/6832]	Time 0.130 (0.105)	Data 0.00106 (0.00098)	Tok/s 73895 (60137)	Loss/tok 3.4435 (3.2881)	Learning Rate [7.8125e-05]
1: TRAIN [1][3760/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 73622 (59316)	Loss/tok 3.2035 (3.2882)	Learning Rate [7.8125e-05]
2: TRAIN [1][3770/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00094)	Tok/s 54837 (59679)	Loss/tok 3.1614 (3.2874)	Learning Rate [7.8125e-05]
3: TRAIN [1][3770/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00098)	Tok/s 54857 (60136)	Loss/tok 3.2937 (3.2879)	Learning Rate [7.8125e-05]
0: TRAIN [1][3770/6832]	Time 0.119 (0.105)	Data 0.00084 (0.00095)	Tok/s 53692 (58868)	Loss/tok 3.3447 (3.2863)	Learning Rate [7.8125e-05]
1: TRAIN [1][3770/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00095)	Tok/s 54535 (59314)	Loss/tok 3.4010 (3.2883)	Learning Rate [7.8125e-05]
2: TRAIN [1][3780/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00094)	Tok/s 84145 (59696)	Loss/tok 3.3574 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][3780/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00095)	Tok/s 83145 (58886)	Loss/tok 3.1859 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3780/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00098)	Tok/s 84589 (60153)	Loss/tok 3.2356 (3.2879)	Learning Rate [7.8125e-05]
1: TRAIN [1][3780/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00095)	Tok/s 83504 (59332)	Loss/tok 3.1485 (3.2882)	Learning Rate [7.8125e-05]
2: TRAIN [1][3790/6832]	Time 0.061 (0.105)	Data 0.00096 (0.00094)	Tok/s 50275 (59686)	Loss/tok 2.7712 (3.2872)	Learning Rate [7.8125e-05]
0: TRAIN [1][3790/6832]	Time 0.061 (0.105)	Data 0.00084 (0.00095)	Tok/s 50243 (58876)	Loss/tok 2.8966 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][3790/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00098)	Tok/s 52077 (60142)	Loss/tok 2.8641 (3.2877)	Learning Rate [7.8125e-05]
1: TRAIN [1][3790/6832]	Time 0.061 (0.105)	Data 0.00098 (0.00095)	Tok/s 50242 (59321)	Loss/tok 2.7076 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][3800/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00095)	Tok/s 81026 (58881)	Loss/tok 3.2172 (3.2863)	Learning Rate [7.8125e-05]
2: TRAIN [1][3800/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00094)	Tok/s 81871 (59690)	Loss/tok 3.2519 (3.2871)	Learning Rate [7.8125e-05]
3: TRAIN [1][3800/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00098)	Tok/s 82596 (60146)	Loss/tok 3.3373 (3.2877)	Learning Rate [7.8125e-05]
1: TRAIN [1][3800/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00095)	Tok/s 81535 (59326)	Loss/tok 3.2948 (3.2881)	Learning Rate [7.8125e-05]
2: TRAIN [1][3810/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 80054 (59713)	Loss/tok 3.3069 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][3810/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00098)	Tok/s 80294 (60170)	Loss/tok 3.3539 (3.2876)	Learning Rate [7.8125e-05]
0: TRAIN [1][3810/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00095)	Tok/s 79166 (58900)	Loss/tok 3.2918 (3.2862)	Learning Rate [7.8125e-05]
1: TRAIN [1][3810/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00095)	Tok/s 79257 (59348)	Loss/tok 3.4212 (3.2880)	Learning Rate [7.8125e-05]
2: TRAIN [1][3820/6832]	Time 0.103 (0.105)	Data 0.00101 (0.00094)	Tok/s 52080 (59730)	Loss/tok 3.0878 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][3820/6832]	Time 0.103 (0.105)	Data 0.00084 (0.00095)	Tok/s 50887 (58917)	Loss/tok 3.2263 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][3820/6832]	Time 0.103 (0.105)	Data 0.00097 (0.00098)	Tok/s 52178 (60187)	Loss/tok 3.3391 (3.2877)	Learning Rate [7.8125e-05]
1: TRAIN [1][3820/6832]	Time 0.103 (0.105)	Data 0.00100 (0.00095)	Tok/s 50899 (59365)	Loss/tok 3.0096 (3.2880)	Learning Rate [7.8125e-05]
2: TRAIN [1][3830/6832]	Time 0.119 (0.105)	Data 0.00118 (0.00094)	Tok/s 57908 (59738)	Loss/tok 3.4109 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][3830/6832]	Time 0.119 (0.105)	Data 0.00112 (0.00098)	Tok/s 57928 (60194)	Loss/tok 3.5209 (3.2878)	Learning Rate [7.8125e-05]
0: TRAIN [1][3830/6832]	Time 0.119 (0.105)	Data 0.00111 (0.00095)	Tok/s 56830 (58925)	Loss/tok 3.1026 (3.2863)	Learning Rate [7.8125e-05]
1: TRAIN [1][3830/6832]	Time 0.119 (0.105)	Data 0.00105 (0.00095)	Tok/s 57221 (59373)	Loss/tok 3.4453 (3.2881)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [1][3840/6832]	Time 0.083 (0.105)	Data 0.00094 (0.00094)	Tok/s 52208 (59737)	Loss/tok 3.1934 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][3840/6832]	Time 0.083 (0.105)	Data 0.00085 (0.00095)	Tok/s 50987 (58925)	Loss/tok 2.9151 (3.2861)	Learning Rate [7.8125e-05]
3: TRAIN [1][3840/6832]	Time 0.083 (0.105)	Data 0.00095 (0.00098)	Tok/s 52482 (60194)	Loss/tok 3.2208 (3.2878)	Learning Rate [7.8125e-05]
1: TRAIN [1][3840/6832]	Time 0.083 (0.105)	Data 0.00098 (0.00095)	Tok/s 50968 (59372)	Loss/tok 3.1169 (3.2881)	Learning Rate [7.8125e-05]
1: TRAIN [1][3850/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 79916 (59388)	Loss/tok 3.2825 (3.2882)	Learning Rate [7.8125e-05]
0: TRAIN [1][3850/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 79806 (58940)	Loss/tok 3.2358 (3.2861)	Learning Rate [7.8125e-05]
2: TRAIN [1][3850/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00094)	Tok/s 80357 (59752)	Loss/tok 3.3845 (3.2869)	Learning Rate [7.8125e-05]
3: TRAIN [1][3850/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00098)	Tok/s 80834 (60208)	Loss/tok 3.2955 (3.2881)	Learning Rate [7.8125e-05]
2: TRAIN [1][3860/6832]	Time 0.092 (0.105)	Data 0.00110 (0.00094)	Tok/s 56759 (59737)	Loss/tok 3.1813 (3.2868)	Learning Rate [7.8125e-05]
1: TRAIN [1][3860/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00095)	Tok/s 56748 (59373)	Loss/tok 3.1316 (3.2880)	Learning Rate [7.8125e-05]
3: TRAIN [1][3860/6832]	Time 0.092 (0.105)	Data 0.00102 (0.00098)	Tok/s 56778 (60193)	Loss/tok 3.2095 (3.2879)	Learning Rate [7.8125e-05]
0: TRAIN [1][3860/6832]	Time 0.092 (0.105)	Data 0.00093 (0.00095)	Tok/s 56781 (58926)	Loss/tok 3.2556 (3.2859)	Learning Rate [7.8125e-05]
2: TRAIN [1][3870/6832]	Time 0.060 (0.105)	Data 0.00097 (0.00094)	Tok/s 51709 (59735)	Loss/tok 2.8659 (3.2870)	Learning Rate [7.8125e-05]
1: TRAIN [1][3870/6832]	Time 0.060 (0.105)	Data 0.00088 (0.00095)	Tok/s 50786 (59371)	Loss/tok 2.8536 (3.2881)	Learning Rate [7.8125e-05]
3: TRAIN [1][3870/6832]	Time 0.060 (0.105)	Data 0.00096 (0.00098)	Tok/s 52935 (60191)	Loss/tok 2.8719 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][3870/6832]	Time 0.060 (0.105)	Data 0.00090 (0.00095)	Tok/s 50819 (58925)	Loss/tok 2.8390 (3.2861)	Learning Rate [7.8125e-05]
2: TRAIN [1][3880/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00094)	Tok/s 58367 (59731)	Loss/tok 3.2402 (3.2868)	Learning Rate [7.8125e-05]
1: TRAIN [1][3880/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00095)	Tok/s 58338 (59366)	Loss/tok 3.4131 (3.2879)	Learning Rate [7.8125e-05]
0: TRAIN [1][3880/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00095)	Tok/s 58354 (58921)	Loss/tok 3.1056 (3.2859)	Learning Rate [7.8125e-05]
3: TRAIN [1][3880/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00098)	Tok/s 58368 (60187)	Loss/tok 3.4187 (3.2879)	Learning Rate [7.8125e-05]
2: TRAIN [1][3890/6832]	Time 0.066 (0.105)	Data 0.00102 (0.00094)	Tok/s 52157 (59733)	Loss/tok 2.8448 (3.2869)	Learning Rate [7.8125e-05]
1: TRAIN [1][3890/6832]	Time 0.066 (0.105)	Data 0.00094 (0.00095)	Tok/s 52125 (59368)	Loss/tok 2.9785 (3.2881)	Learning Rate [7.8125e-05]
3: TRAIN [1][3890/6832]	Time 0.066 (0.105)	Data 0.00100 (0.00098)	Tok/s 53052 (60188)	Loss/tok 2.8308 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][3890/6832]	Time 0.066 (0.105)	Data 0.00090 (0.00094)	Tok/s 52085 (58923)	Loss/tok 3.0241 (3.2861)	Learning Rate [7.8125e-05]
2: TRAIN [1][3900/6832]	Time 0.120 (0.105)	Data 0.00097 (0.00094)	Tok/s 58537 (59730)	Loss/tok 3.4113 (3.2871)	Learning Rate [7.8125e-05]
1: TRAIN [1][3900/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00095)	Tok/s 58496 (59366)	Loss/tok 3.3709 (3.2882)	Learning Rate [7.8125e-05]
0: TRAIN [1][3900/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00094)	Tok/s 58507 (58922)	Loss/tok 3.7295 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3900/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00098)	Tok/s 58518 (60184)	Loss/tok 3.4317 (3.2881)	Learning Rate [7.8125e-05]
2: TRAIN [1][3910/6832]	Time 0.080 (0.105)	Data 0.00098 (0.00094)	Tok/s 53062 (59735)	Loss/tok 3.1487 (3.2871)	Learning Rate [7.8125e-05]
1: TRAIN [1][3910/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00095)	Tok/s 52606 (59370)	Loss/tok 3.0650 (3.2883)	Learning Rate [7.8125e-05]
3: TRAIN [1][3910/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00098)	Tok/s 53081 (60188)	Loss/tok 2.9814 (3.2881)	Learning Rate [7.8125e-05]
0: TRAIN [1][3910/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00094)	Tok/s 51421 (58927)	Loss/tok 2.9721 (3.2864)	Learning Rate [7.8125e-05]
1: TRAIN [1][3920/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 59956 (59373)	Loss/tok 3.3674 (3.2883)	Learning Rate [7.8125e-05]
2: TRAIN [1][3920/6832]	Time 0.128 (0.105)	Data 0.00111 (0.00094)	Tok/s 59930 (59736)	Loss/tok 3.5663 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][3920/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 59378 (58929)	Loss/tok 3.0938 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3920/6832]	Time 0.128 (0.105)	Data 0.00102 (0.00098)	Tok/s 59968 (60190)	Loss/tok 3.2950 (3.2880)	Learning Rate [7.8125e-05]
1: TRAIN [1][3930/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00095)	Tok/s 52894 (59366)	Loss/tok 3.0374 (3.2882)	Learning Rate [7.8125e-05]
0: TRAIN [1][3930/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00094)	Tok/s 52413 (58922)	Loss/tok 3.1250 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][3930/6832]	Time 0.085 (0.105)	Data 0.00101 (0.00098)	Tok/s 52885 (60183)	Loss/tok 3.1763 (3.2881)	Learning Rate [7.8125e-05]
2: TRAIN [1][3930/6832]	Time 0.084 (0.105)	Data 0.00120 (0.00094)	Tok/s 53020 (59730)	Loss/tok 3.1366 (3.2871)	Learning Rate [7.8125e-05]
1: TRAIN [1][3940/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00095)	Tok/s 91177 (59389)	Loss/tok 3.1866 (3.2882)	Learning Rate [7.8125e-05]
2: TRAIN [1][3940/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00094)	Tok/s 92330 (59753)	Loss/tok 3.1884 (3.2868)	Learning Rate [7.8125e-05]
0: TRAIN [1][3940/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 90426 (58945)	Loss/tok 3.1750 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][3940/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00098)	Tok/s 94014 (60207)	Loss/tok 3.1057 (3.2879)	Learning Rate [7.8125e-05]
1: TRAIN [1][3950/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 62131 (59383)	Loss/tok 3.4258 (3.2881)	Learning Rate [7.8125e-05]
0: TRAIN [1][3950/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 62130 (58941)	Loss/tok 3.3433 (3.2863)	Learning Rate [7.8125e-05]
2: TRAIN [1][3950/6832]	Time 0.128 (0.105)	Data 0.00102 (0.00094)	Tok/s 62113 (59748)	Loss/tok 3.3875 (3.2869)	Learning Rate [7.8125e-05]
3: TRAIN [1][3950/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00098)	Tok/s 62116 (60201)	Loss/tok 3.4506 (3.2880)	Learning Rate [7.8125e-05]
2: TRAIN [1][3960/6832]	Time 0.096 (0.105)	Data 0.00098 (0.00094)	Tok/s 51963 (59740)	Loss/tok 3.1104 (3.2868)	Learning Rate [7.8125e-05]
1: TRAIN [1][3960/6832]	Time 0.096 (0.105)	Data 0.00089 (0.00095)	Tok/s 51958 (59375)	Loss/tok 3.1762 (3.2879)	Learning Rate [7.8125e-05]
3: TRAIN [1][3960/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00098)	Tok/s 52097 (60192)	Loss/tok 3.3299 (3.2879)	Learning Rate [7.8125e-05]
0: TRAIN [1][3960/6832]	Time 0.096 (0.105)	Data 0.00090 (0.00094)	Tok/s 51949 (58933)	Loss/tok 3.1700 (3.2862)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][3970/6832]	Time 0.109 (0.105)	Data 0.00100 (0.00094)	Tok/s 54052 (59742)	Loss/tok 3.3699 (3.2868)	Learning Rate [7.8125e-05]
1: TRAIN [1][3970/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00095)	Tok/s 54040 (59378)	Loss/tok 3.4395 (3.2878)	Learning Rate [7.8125e-05]
0: TRAIN [1][3970/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00094)	Tok/s 53052 (58936)	Loss/tok 3.0425 (3.2861)	Learning Rate [7.8125e-05]
3: TRAIN [1][3970/6832]	Time 0.109 (0.105)	Data 0.00097 (0.00098)	Tok/s 54044 (60194)	Loss/tok 3.1965 (3.2877)	Learning Rate [7.8125e-05]
2: TRAIN [1][3980/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 68915 (59748)	Loss/tok 3.5288 (3.2869)	Learning Rate [7.8125e-05]
0: TRAIN [1][3980/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 68946 (58944)	Loss/tok 3.3894 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][3980/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00098)	Tok/s 69239 (60201)	Loss/tok 3.3226 (3.2876)	Learning Rate [7.8125e-05]
1: TRAIN [1][3980/6832]	Time 0.130 (0.105)	Data 0.00121 (0.00095)	Tok/s 68962 (59385)	Loss/tok 3.3665 (3.2881)	Learning Rate [7.8125e-05]
2: TRAIN [1][3990/6832]	Time 0.079 (0.105)	Data 0.00118 (0.00094)	Tok/s 54996 (59746)	Loss/tok 3.0453 (3.2868)	Learning Rate [7.8125e-05]
1: TRAIN [1][3990/6832]	Time 0.079 (0.105)	Data 0.00099 (0.00095)	Tok/s 53463 (59383)	Loss/tok 3.0427 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][3990/6832]	Time 0.079 (0.105)	Data 0.00096 (0.00094)	Tok/s 53395 (58943)	Loss/tok 3.0750 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][3990/6832]	Time 0.079 (0.105)	Data 0.00113 (0.00098)	Tok/s 55041 (60198)	Loss/tok 3.2789 (3.2876)	Learning Rate [7.8125e-05]
1: TRAIN [1][4000/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 88134 (59387)	Loss/tok 3.1288 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][4000/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 87386 (58944)	Loss/tok 3.3193 (3.2865)	Learning Rate [7.8125e-05]
2: TRAIN [1][4000/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 88884 (59751)	Loss/tok 3.0466 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][4000/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00098)	Tok/s 89486 (60204)	Loss/tok 3.3096 (3.2876)	Learning Rate [7.8125e-05]
2: TRAIN [1][4010/6832]	Time 0.073 (0.105)	Data 0.00102 (0.00094)	Tok/s 54371 (59747)	Loss/tok 2.9788 (3.2867)	Learning Rate [7.8125e-05]
3: TRAIN [1][4010/6832]	Time 0.073 (0.105)	Data 0.00100 (0.00098)	Tok/s 54350 (60200)	Loss/tok 3.0492 (3.2875)	Learning Rate [7.8125e-05]
1: TRAIN [1][4010/6832]	Time 0.073 (0.105)	Data 0.00095 (0.00094)	Tok/s 52774 (59383)	Loss/tok 2.8824 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][4010/6832]	Time 0.073 (0.105)	Data 0.00098 (0.00094)	Tok/s 52592 (58941)	Loss/tok 3.1831 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][4020/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00094)	Tok/s 58476 (59751)	Loss/tok 3.2898 (3.2867)	Learning Rate [7.8125e-05]
1: TRAIN [1][4020/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 58454 (59388)	Loss/tok 3.1952 (3.2880)	Learning Rate [7.8125e-05]
3: TRAIN [1][4020/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00098)	Tok/s 58485 (60203)	Loss/tok 3.3773 (3.2876)	Learning Rate [7.8125e-05]
0: TRAIN [1][4020/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 58447 (58946)	Loss/tok 3.2608 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4030/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00094)	Tok/s 60207 (59391)	Loss/tok 3.4777 (3.2879)	Learning Rate [7.8125e-05]
2: TRAIN [1][4030/6832]	Time 0.117 (0.105)	Data 0.00101 (0.00094)	Tok/s 60191 (59754)	Loss/tok 3.2604 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][4030/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00098)	Tok/s 60202 (60206)	Loss/tok 3.2461 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][4030/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 59251 (58950)	Loss/tok 3.3980 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][4040/6832]	Time 0.074 (0.105)	Data 0.00110 (0.00094)	Tok/s 51904 (59744)	Loss/tok 3.0017 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4040/6832]	Time 0.074 (0.105)	Data 0.00089 (0.00094)	Tok/s 51613 (59381)	Loss/tok 2.9675 (3.2878)	Learning Rate [7.8125e-05]
0: TRAIN [1][4040/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00094)	Tok/s 51641 (58940)	Loss/tok 2.9149 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][4040/6832]	Time 0.074 (0.105)	Data 0.00108 (0.00098)	Tok/s 53354 (60196)	Loss/tok 3.2313 (3.2873)	Learning Rate [7.8125e-05]
1: TRAIN [1][4050/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 62852 (59373)	Loss/tok 3.3578 (3.2878)	Learning Rate [7.8125e-05]
0: TRAIN [1][4050/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00094)	Tok/s 62853 (58932)	Loss/tok 3.5257 (3.2861)	Learning Rate [7.8125e-05]
2: TRAIN [1][4050/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00094)	Tok/s 63379 (59735)	Loss/tok 3.5006 (3.2867)	Learning Rate [7.8125e-05]
3: TRAIN [1][4050/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00098)	Tok/s 63850 (60187)	Loss/tok 3.3323 (3.2873)	Learning Rate [7.8125e-05]
2: TRAIN [1][4060/6832]	Time 0.110 (0.105)	Data 0.00115 (0.00094)	Tok/s 52535 (59749)	Loss/tok 3.3214 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4060/6832]	Time 0.110 (0.105)	Data 0.00096 (0.00094)	Tok/s 52553 (59386)	Loss/tok 3.2961 (3.2876)	Learning Rate [7.8125e-05]
0: TRAIN [1][4060/6832]	Time 0.110 (0.105)	Data 0.00097 (0.00094)	Tok/s 52563 (58945)	Loss/tok 3.1930 (3.2859)	Learning Rate [7.8125e-05]
3: TRAIN [1][4060/6832]	Time 0.110 (0.105)	Data 0.00109 (0.00098)	Tok/s 52729 (60201)	Loss/tok 3.4017 (3.2872)	Learning Rate [7.8125e-05]
2: TRAIN [1][4070/6832]	Time 0.103 (0.105)	Data 0.00096 (0.00094)	Tok/s 52668 (59749)	Loss/tok 3.1060 (3.2864)	Learning Rate [7.8125e-05]
1: TRAIN [1][4070/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00094)	Tok/s 52378 (59386)	Loss/tok 3.1066 (3.2875)	Learning Rate [7.8125e-05]
0: TRAIN [1][4070/6832]	Time 0.103 (0.105)	Data 0.00087 (0.00094)	Tok/s 52382 (58945)	Loss/tok 3.0806 (3.2859)	Learning Rate [7.8125e-05]
3: TRAIN [1][4070/6832]	Time 0.103 (0.105)	Data 0.00094 (0.00098)	Tok/s 53655 (60200)	Loss/tok 3.0521 (3.2872)	Learning Rate [7.8125e-05]
1: TRAIN [1][4080/6832]	Time 0.090 (0.105)	Data 0.00088 (0.00094)	Tok/s 55304 (59398)	Loss/tok 3.2476 (3.2874)	Learning Rate [7.8125e-05]
0: TRAIN [1][4080/6832]	Time 0.090 (0.105)	Data 0.00088 (0.00094)	Tok/s 55311 (58956)	Loss/tok 3.2952 (3.2860)	Learning Rate [7.8125e-05]
2: TRAIN [1][4080/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00094)	Tok/s 56292 (59761)	Loss/tok 3.2022 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][4080/6832]	Time 0.090 (0.105)	Data 0.00096 (0.00098)	Tok/s 56704 (60213)	Loss/tok 3.2902 (3.2871)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [1][4090/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00094)	Tok/s 56361 (59406)	Loss/tok 3.2606 (3.2873)	Learning Rate [7.8125e-05]
0: TRAIN [1][4090/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 56330 (58965)	Loss/tok 3.3747 (3.2860)	Learning Rate [7.8125e-05]
2: TRAIN [1][4090/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00094)	Tok/s 57197 (59769)	Loss/tok 3.2766 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][4090/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00098)	Tok/s 57366 (60220)	Loss/tok 3.3359 (3.2872)	Learning Rate [7.8125e-05]
2: TRAIN [1][4100/6832]	Time 0.043 (0.105)	Data 0.00097 (0.00094)	Tok/s 38709 (59756)	Loss/tok 2.2586 (3.2863)	Learning Rate [7.8125e-05]
1: TRAIN [1][4100/6832]	Time 0.043 (0.105)	Data 0.00088 (0.00094)	Tok/s 34763 (59392)	Loss/tok 2.1563 (3.2872)	Learning Rate [7.8125e-05]
3: TRAIN [1][4100/6832]	Time 0.043 (0.105)	Data 0.00092 (0.00098)	Tok/s 42583 (60209)	Loss/tok 2.3370 (3.2872)	Learning Rate [7.8125e-05]
0: TRAIN [1][4100/6832]	Time 0.043 (0.105)	Data 0.00087 (0.00094)	Tok/s 22143 (58948)	Loss/tok 1.6438 (3.2860)	Learning Rate [7.8125e-05]
2: TRAIN [1][4110/6832]	Time 0.088 (0.105)	Data 0.00096 (0.00094)	Tok/s 53652 (59751)	Loss/tok 3.3124 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][4110/6832]	Time 0.088 (0.105)	Data 0.00093 (0.00098)	Tok/s 53608 (60204)	Loss/tok 3.1199 (3.2871)	Learning Rate [7.8125e-05]
1: TRAIN [1][4110/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00094)	Tok/s 53548 (59388)	Loss/tok 3.3257 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][4110/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00094)	Tok/s 53512 (58944)	Loss/tok 3.0623 (3.2859)	Learning Rate [7.8125e-05]
2: TRAIN [1][4120/6832]	Time 0.112 (0.105)	Data 0.00102 (0.00094)	Tok/s 51022 (59749)	Loss/tok 3.3286 (3.2862)	Learning Rate [7.8125e-05]
1: TRAIN [1][4120/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00094)	Tok/s 50046 (59386)	Loss/tok 3.2854 (3.2870)	Learning Rate [7.8125e-05]
3: TRAIN [1][4120/6832]	Time 0.112 (0.105)	Data 0.00097 (0.00098)	Tok/s 51225 (60202)	Loss/tok 3.2928 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][4120/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 50043 (58943)	Loss/tok 3.2441 (3.2858)	Learning Rate [7.8125e-05]
1: TRAIN [1][4130/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 70613 (59388)	Loss/tok 3.4899 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][4130/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00094)	Tok/s 70049 (58945)	Loss/tok 3.4443 (3.2858)	Learning Rate [7.8125e-05]
3: TRAIN [1][4130/6832]	Time 0.129 (0.105)	Data 0.00107 (0.00098)	Tok/s 70719 (60203)	Loss/tok 3.4989 (3.2872)	Learning Rate [7.8125e-05]
2: TRAIN [1][4130/6832]	Time 0.129 (0.105)	Data 0.00110 (0.00094)	Tok/s 70503 (59751)	Loss/tok 3.5511 (3.2862)	Learning Rate [7.8125e-05]
1: TRAIN [1][4140/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00094)	Tok/s 51322 (59384)	Loss/tok 3.2865 (3.2870)	Learning Rate [7.8125e-05]
2: TRAIN [1][4140/6832]	Time 0.112 (0.105)	Data 0.00089 (0.00094)	Tok/s 51316 (59748)	Loss/tok 3.2455 (3.2860)	Learning Rate [7.8125e-05]
3: TRAIN [1][4140/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00098)	Tok/s 51313 (60200)	Loss/tok 3.2809 (3.2872)	Learning Rate [7.8125e-05]
0: TRAIN [1][4140/6832]	Time 0.112 (0.105)	Data 0.00089 (0.00094)	Tok/s 51279 (58941)	Loss/tok 3.3018 (3.2856)	Learning Rate [7.8125e-05]
1: TRAIN [1][4150/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00094)	Tok/s 50304 (59393)	Loss/tok 2.6816 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][4150/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00094)	Tok/s 50074 (58950)	Loss/tok 2.8097 (3.2857)	Learning Rate [7.8125e-05]
3: TRAIN [1][4150/6832]	Time 0.059 (0.105)	Data 0.00085 (0.00098)	Tok/s 51367 (60207)	Loss/tok 2.8584 (3.2873)	Learning Rate [7.8125e-05]
2: TRAIN [1][4150/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00094)	Tok/s 50131 (59756)	Loss/tok 2.7492 (3.2862)	Learning Rate [7.8125e-05]
1: TRAIN [1][4160/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 53400 (59382)	Loss/tok 3.3098 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][4160/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 53228 (58938)	Loss/tok 3.2211 (3.2857)	Learning Rate [7.8125e-05]
3: TRAIN [1][4160/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00098)	Tok/s 54340 (60198)	Loss/tok 3.3017 (3.2871)	Learning Rate [7.8125e-05]
2: TRAIN [1][4160/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00094)	Tok/s 54241 (59747)	Loss/tok 3.2684 (3.2861)	Learning Rate [7.8125e-05]
1: TRAIN [1][4170/6832]	Time 0.067 (0.105)	Data 0.00090 (0.00094)	Tok/s 51269 (59371)	Loss/tok 3.0103 (3.2869)	Learning Rate [7.8125e-05]
2: TRAIN [1][4170/6832]	Time 0.067 (0.105)	Data 0.00090 (0.00094)	Tok/s 52198 (59736)	Loss/tok 2.8267 (3.2859)	Learning Rate [7.8125e-05]
0: TRAIN [1][4170/6832]	Time 0.067 (0.105)	Data 0.00091 (0.00094)	Tok/s 51313 (58927)	Loss/tok 2.9318 (3.2855)	Learning Rate [7.8125e-05]
3: TRAIN [1][4170/6832]	Time 0.067 (0.105)	Data 0.00086 (0.00098)	Tok/s 53189 (60187)	Loss/tok 2.8755 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][4180/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 79394 (58934)	Loss/tok 3.3617 (3.2853)	Learning Rate [7.8125e-05]
1: TRAIN [1][4180/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 79611 (59377)	Loss/tok 3.3655 (3.2869)	Learning Rate [7.8125e-05]
2: TRAIN [1][4180/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 79989 (59741)	Loss/tok 3.2096 (3.2858)	Learning Rate [7.8125e-05]
3: TRAIN [1][4180/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00098)	Tok/s 80350 (60193)	Loss/tok 3.2838 (3.2871)	Learning Rate [7.8125e-05]
1: TRAIN [1][4190/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00094)	Tok/s 55993 (59367)	Loss/tok 3.5065 (3.2869)	Learning Rate [7.8125e-05]
2: TRAIN [1][4190/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00094)	Tok/s 56001 (59731)	Loss/tok 3.2905 (3.2858)	Learning Rate [7.8125e-05]
3: TRAIN [1][4190/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00098)	Tok/s 55986 (60182)	Loss/tok 3.3851 (3.2871)	Learning Rate [7.8125e-05]
0: TRAIN [1][4190/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 55000 (58924)	Loss/tok 3.5096 (3.2852)	Learning Rate [7.8125e-05]
2: TRAIN [1][4200/6832]	Time 0.065 (0.105)	Data 0.00088 (0.00094)	Tok/s 51707 (59718)	Loss/tok 3.0578 (3.2858)	Learning Rate [7.8125e-05]
1: TRAIN [1][4200/6832]	Time 0.065 (0.105)	Data 0.00090 (0.00094)	Tok/s 51236 (59354)	Loss/tok 2.9516 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][4200/6832]	Time 0.065 (0.105)	Data 0.00086 (0.00098)	Tok/s 53214 (60169)	Loss/tok 3.0138 (3.2870)	Learning Rate [7.8125e-05]
0: TRAIN [1][4200/6832]	Time 0.065 (0.105)	Data 0.00091 (0.00094)	Tok/s 51206 (58912)	Loss/tok 2.9854 (3.2851)	Learning Rate [7.8125e-05]
1: TRAIN [1][4210/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00094)	Tok/s 87596 (59368)	Loss/tok 3.2548 (3.2866)	Learning Rate [7.8125e-05]
0: TRAIN [1][4210/6832]	Time 0.133 (0.105)	Data 0.00092 (0.00094)	Tok/s 86677 (58926)	Loss/tok 3.1283 (3.2849)	Learning Rate [7.8125e-05]
2: TRAIN [1][4210/6832]	Time 0.133 (0.105)	Data 0.00092 (0.00094)	Tok/s 88205 (59731)	Loss/tok 3.2167 (3.2856)	Learning Rate [7.8125e-05]
3: TRAIN [1][4210/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00098)	Tok/s 88968 (60182)	Loss/tok 3.1673 (3.2870)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [1][4220/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 74950 (59367)	Loss/tok 3.3750 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][4220/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 75013 (58923)	Loss/tok 3.3062 (3.2849)	Learning Rate [7.8125e-05]
2: TRAIN [1][4220/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 75912 (59731)	Loss/tok 3.4103 (3.2856)	Learning Rate [7.8125e-05]
3: TRAIN [1][4220/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00098)	Tok/s 75937 (60183)	Loss/tok 3.3495 (3.2870)	Learning Rate [7.8125e-05]
2: TRAIN [1][4230/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00094)	Tok/s 60977 (59722)	Loss/tok 3.3454 (3.2855)	Learning Rate [7.8125e-05]
1: TRAIN [1][4230/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00094)	Tok/s 60939 (59357)	Loss/tok 3.2804 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][4230/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00094)	Tok/s 60364 (58910)	Loss/tok 3.3203 (3.2848)	Learning Rate [7.8125e-05]
3: TRAIN [1][4230/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00098)	Tok/s 60957 (60173)	Loss/tok 3.2653 (3.2869)	Learning Rate [7.8125e-05]
1: TRAIN [1][4240/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00094)	Tok/s 51936 (59366)	Loss/tok 3.1871 (3.2867)	Learning Rate [7.8125e-05]
2: TRAIN [1][4240/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00094)	Tok/s 51977 (59731)	Loss/tok 3.0924 (3.2855)	Learning Rate [7.8125e-05]
3: TRAIN [1][4240/6832]	Time 0.089 (0.105)	Data 0.00085 (0.00098)	Tok/s 51958 (60182)	Loss/tok 3.0056 (3.2868)	Learning Rate [7.8125e-05]
0: TRAIN [1][4240/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00094)	Tok/s 51945 (58920)	Loss/tok 3.1291 (3.2850)	Learning Rate [7.8125e-05]
1: TRAIN [1][4250/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00094)	Tok/s 57558 (59376)	Loss/tok 3.3314 (3.2868)	Learning Rate [7.8125e-05]
0: TRAIN [1][4250/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00094)	Tok/s 57578 (58930)	Loss/tok 3.2637 (3.2849)	Learning Rate [7.8125e-05]
2: TRAIN [1][4250/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00094)	Tok/s 57602 (59741)	Loss/tok 3.3785 (3.2855)	Learning Rate [7.8125e-05]
3: TRAIN [1][4250/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00098)	Tok/s 58304 (60192)	Loss/tok 3.4256 (3.2868)	Learning Rate [7.8125e-05]
1: TRAIN [1][4260/6832]	Time 0.067 (0.105)	Data 0.00095 (0.00094)	Tok/s 49502 (59372)	Loss/tok 3.0327 (3.2867)	Learning Rate [7.8125e-05]
2: TRAIN [1][4260/6832]	Time 0.067 (0.105)	Data 0.00103 (0.00094)	Tok/s 50027 (59738)	Loss/tok 2.9592 (3.2856)	Learning Rate [7.8125e-05]
3: TRAIN [1][4260/6832]	Time 0.067 (0.105)	Data 0.00096 (0.00098)	Tok/s 51504 (60190)	Loss/tok 3.0454 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][4260/6832]	Time 0.067 (0.105)	Data 0.00098 (0.00094)	Tok/s 49533 (58924)	Loss/tok 3.1267 (3.2849)	Learning Rate [7.8125e-05]
1: TRAIN [1][4270/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 64311 (59373)	Loss/tok 3.3217 (3.2867)	Learning Rate [7.8125e-05]
2: TRAIN [1][4270/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 64311 (59738)	Loss/tok 3.5205 (3.2857)	Learning Rate [7.8125e-05]
3: TRAIN [1][4270/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00098)	Tok/s 64579 (60190)	Loss/tok 3.4529 (3.2869)	Learning Rate [7.8125e-05]
0: TRAIN [1][4270/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 64308 (58926)	Loss/tok 3.4914 (3.2850)	Learning Rate [7.8125e-05]
1: TRAIN [1][4280/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 81908 (59370)	Loss/tok 3.3208 (3.2866)	Learning Rate [7.8125e-05]
3: TRAIN [1][4280/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00098)	Tok/s 82805 (60187)	Loss/tok 3.3199 (3.2869)	Learning Rate [7.8125e-05]
2: TRAIN [1][4280/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 82003 (59736)	Loss/tok 3.3390 (3.2857)	Learning Rate [7.8125e-05]
0: TRAIN [1][4280/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 81037 (58923)	Loss/tok 3.3238 (3.2849)	Learning Rate [7.8125e-05]
1: TRAIN [1][4290/6832]	Time 0.116 (0.105)	Data 0.00110 (0.00094)	Tok/s 53065 (59363)	Loss/tok 3.3680 (3.2866)	Learning Rate [7.8125e-05]
2: TRAIN [1][4290/6832]	Time 0.116 (0.105)	Data 0.00100 (0.00094)	Tok/s 53079 (59728)	Loss/tok 3.2442 (3.2856)	Learning Rate [7.8125e-05]
0: TRAIN [1][4290/6832]	Time 0.116 (0.105)	Data 0.00112 (0.00094)	Tok/s 53075 (58916)	Loss/tok 3.1894 (3.2848)	Learning Rate [7.8125e-05]
3: TRAIN [1][4290/6832]	Time 0.116 (0.105)	Data 0.00098 (0.00098)	Tok/s 54039 (60179)	Loss/tok 3.3538 (3.2869)	Learning Rate [7.8125e-05]
2: TRAIN [1][4300/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00094)	Tok/s 91577 (59734)	Loss/tok 3.1689 (3.2857)	Learning Rate [7.8125e-05]
3: TRAIN [1][4300/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00098)	Tok/s 93446 (60186)	Loss/tok 3.1111 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][4300/6832]	Time 0.133 (0.105)	Data 0.00107 (0.00094)	Tok/s 89159 (58923)	Loss/tok 3.0684 (3.2847)	Learning Rate [7.8125e-05]
1: TRAIN [1][4300/6832]	Time 0.133 (0.105)	Data 0.00105 (0.00094)	Tok/s 90107 (59369)	Loss/tok 3.1755 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4310/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00094)	Tok/s 52267 (59362)	Loss/tok 3.4198 (3.2866)	Learning Rate [7.8125e-05]
3: TRAIN [1][4310/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00098)	Tok/s 52254 (60178)	Loss/tok 3.2827 (3.2866)	Learning Rate [7.8125e-05]
0: TRAIN [1][4310/6832]	Time 0.118 (0.105)	Data 0.00097 (0.00094)	Tok/s 52253 (58916)	Loss/tok 3.2475 (3.2848)	Learning Rate [7.8125e-05]
2: TRAIN [1][4310/6832]	Time 0.118 (0.105)	Data 0.00097 (0.00094)	Tok/s 52251 (59727)	Loss/tok 3.3638 (3.2858)	Learning Rate [7.8125e-05]
1: TRAIN [1][4320/6832]	Time 0.079 (0.105)	Data 0.00099 (0.00094)	Tok/s 52715 (59359)	Loss/tok 3.0471 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][4320/6832]	Time 0.079 (0.105)	Data 0.00102 (0.00094)	Tok/s 53541 (59724)	Loss/tok 2.9188 (3.2856)	Learning Rate [7.8125e-05]
0: TRAIN [1][4320/6832]	Time 0.079 (0.105)	Data 0.00104 (0.00094)	Tok/s 51901 (58913)	Loss/tok 3.0960 (3.2848)	Learning Rate [7.8125e-05]
3: TRAIN [1][4320/6832]	Time 0.079 (0.105)	Data 0.00099 (0.00098)	Tok/s 53533 (60175)	Loss/tok 3.0387 (3.2866)	Learning Rate [7.8125e-05]
1: TRAIN [1][4330/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 69501 (59356)	Loss/tok 3.3743 (3.2863)	Learning Rate [7.8125e-05]
0: TRAIN [1][4330/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 69528 (58911)	Loss/tok 3.3408 (3.2847)	Learning Rate [7.8125e-05]
2: TRAIN [1][4330/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 69902 (59721)	Loss/tok 3.4370 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4330/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00098)	Tok/s 70517 (60172)	Loss/tok 3.3958 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4340/6832]	Time 0.072 (0.105)	Data 0.00103 (0.00094)	Tok/s 53650 (59351)	Loss/tok 3.1508 (3.2863)	Learning Rate [7.8125e-05]
2: TRAIN [1][4340/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00094)	Tok/s 53677 (59714)	Loss/tok 2.9839 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4340/6832]	Time 0.072 (0.105)	Data 0.00087 (0.00098)	Tok/s 53668 (60165)	Loss/tok 3.0611 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][4340/6832]	Time 0.072 (0.105)	Data 0.00104 (0.00094)	Tok/s 51898 (58905)	Loss/tok 2.8246 (3.2846)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [1][4350/6832]	Time 0.076 (0.105)	Data 0.00096 (0.00094)	Tok/s 54206 (59346)	Loss/tok 3.0428 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][4350/6832]	Time 0.076 (0.105)	Data 0.00106 (0.00094)	Tok/s 54225 (59710)	Loss/tok 3.0459 (3.2855)	Learning Rate [7.8125e-05]
3: TRAIN [1][4350/6832]	Time 0.076 (0.105)	Data 0.00101 (0.00098)	Tok/s 54210 (60160)	Loss/tok 3.1350 (3.2865)	Learning Rate [7.8125e-05]
0: TRAIN [1][4350/6832]	Time 0.076 (0.105)	Data 0.00102 (0.00094)	Tok/s 54192 (58901)	Loss/tok 2.8831 (3.2845)	Learning Rate [7.8125e-05]
2: TRAIN [1][4360/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00094)	Tok/s 54094 (59708)	Loss/tok 3.2446 (3.2854)	Learning Rate [7.8125e-05]
1: TRAIN [1][4360/6832]	Time 0.085 (0.105)	Data 0.00095 (0.00094)	Tok/s 52943 (59344)	Loss/tok 3.0930 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][4360/6832]	Time 0.085 (0.105)	Data 0.00087 (0.00098)	Tok/s 54076 (60159)	Loss/tok 3.2018 (3.2865)	Learning Rate [7.8125e-05]
0: TRAIN [1][4360/6832]	Time 0.085 (0.105)	Data 0.00097 (0.00094)	Tok/s 52564 (58900)	Loss/tok 3.1841 (3.2845)	Learning Rate [7.8125e-05]
2: TRAIN [1][4370/6832]	Time 0.104 (0.105)	Data 0.00085 (0.00094)	Tok/s 55202 (59709)	Loss/tok 3.2255 (3.2855)	Learning Rate [7.8125e-05]
1: TRAIN [1][4370/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00094)	Tok/s 55183 (59345)	Loss/tok 3.4291 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][4370/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00097)	Tok/s 55199 (60159)	Loss/tok 3.2812 (3.2866)	Learning Rate [7.8125e-05]
0: TRAIN [1][4370/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00094)	Tok/s 55220 (58902)	Loss/tok 3.1983 (3.2845)	Learning Rate [7.8125e-05]
1: TRAIN [1][4380/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 69792 (59345)	Loss/tok 3.5239 (3.2862)	Learning Rate [7.8125e-05]
0: TRAIN [1][4380/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 69778 (58898)	Loss/tok 3.5746 (3.2844)	Learning Rate [7.8125e-05]
2: TRAIN [1][4380/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 70049 (59710)	Loss/tok 3.3727 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4380/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00097)	Tok/s 70739 (60162)	Loss/tok 3.3305 (3.2863)	Learning Rate [7.8125e-05]
2: TRAIN [1][4390/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 59903 (59707)	Loss/tok 3.0789 (3.2853)	Learning Rate [7.8125e-05]
3: TRAIN [1][4390/6832]	Time 0.113 (0.105)	Data 0.00093 (0.00097)	Tok/s 59920 (60159)	Loss/tok 3.3141 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4390/6832]	Time 0.113 (0.105)	Data 0.00102 (0.00094)	Tok/s 58801 (59342)	Loss/tok 3.3643 (3.2863)	Learning Rate [7.8125e-05]
0: TRAIN [1][4390/6832]	Time 0.113 (0.105)	Data 0.00106 (0.00094)	Tok/s 58755 (58895)	Loss/tok 3.3479 (3.2844)	Learning Rate [7.8125e-05]
1: TRAIN [1][4400/6832]	Time 0.103 (0.105)	Data 0.00094 (0.00094)	Tok/s 54679 (59347)	Loss/tok 3.0703 (3.2863)	Learning Rate [7.8125e-05]
2: TRAIN [1][4400/6832]	Time 0.103 (0.105)	Data 0.00094 (0.00094)	Tok/s 54720 (59713)	Loss/tok 3.0889 (3.2855)	Learning Rate [7.8125e-05]
3: TRAIN [1][4400/6832]	Time 0.103 (0.105)	Data 0.00092 (0.00097)	Tok/s 54752 (60163)	Loss/tok 3.1797 (3.2866)	Learning Rate [7.8125e-05]
0: TRAIN [1][4400/6832]	Time 0.103 (0.105)	Data 0.00100 (0.00094)	Tok/s 53828 (58901)	Loss/tok 3.2858 (3.2845)	Learning Rate [7.8125e-05]
1: TRAIN [1][4410/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00094)	Tok/s 52241 (59345)	Loss/tok 3.3846 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][4410/6832]	Time 0.098 (0.105)	Data 0.00089 (0.00094)	Tok/s 52238 (59711)	Loss/tok 3.5118 (3.2855)	Learning Rate [7.8125e-05]
3: TRAIN [1][4410/6832]	Time 0.098 (0.105)	Data 0.00090 (0.00097)	Tok/s 52551 (60161)	Loss/tok 3.0412 (3.2866)	Learning Rate [7.8125e-05]
0: TRAIN [1][4410/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00094)	Tok/s 52200 (58899)	Loss/tok 3.2633 (3.2845)	Learning Rate [7.8125e-05]
1: TRAIN [1][4420/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00094)	Tok/s 54430 (59352)	Loss/tok 3.1341 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][4420/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00094)	Tok/s 54882 (59718)	Loss/tok 2.9759 (3.2854)	Learning Rate [7.8125e-05]
0: TRAIN [1][4420/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00094)	Tok/s 54401 (58906)	Loss/tok 2.9431 (3.2844)	Learning Rate [7.8125e-05]
3: TRAIN [1][4420/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00097)	Tok/s 56049 (60168)	Loss/tok 3.0295 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4430/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 62211 (59354)	Loss/tok 3.3446 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][4430/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00094)	Tok/s 63013 (59720)	Loss/tok 3.5885 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4430/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00097)	Tok/s 63012 (60170)	Loss/tok 3.2298 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][4430/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00094)	Tok/s 61947 (58910)	Loss/tok 3.2910 (3.2842)	Learning Rate [7.8125e-05]
1: TRAIN [1][4440/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00094)	Tok/s 52671 (59348)	Loss/tok 3.3375 (3.2863)	Learning Rate [7.8125e-05]
2: TRAIN [1][4440/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00094)	Tok/s 52671 (59713)	Loss/tok 3.3622 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4440/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00097)	Tok/s 53629 (60163)	Loss/tok 3.2299 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][4440/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00094)	Tok/s 52683 (58903)	Loss/tok 3.3119 (3.2843)	Learning Rate [7.8125e-05]
1: TRAIN [1][4450/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 66756 (59350)	Loss/tok 3.6095 (3.2865)	Learning Rate [7.8125e-05]
0: TRAIN [1][4450/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 66718 (58904)	Loss/tok 3.3174 (3.2843)	Learning Rate [7.8125e-05]
2: TRAIN [1][4450/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 66631 (59717)	Loss/tok 3.3203 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4450/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00097)	Tok/s 66883 (60167)	Loss/tok 3.4350 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4460/6832]	Time 0.114 (0.105)	Data 0.00098 (0.00094)	Tok/s 57107 (59349)	Loss/tok 3.3252 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][4460/6832]	Time 0.114 (0.105)	Data 0.00098 (0.00097)	Tok/s 57864 (60166)	Loss/tok 3.3706 (3.2863)	Learning Rate [7.8125e-05]
2: TRAIN [1][4460/6832]	Time 0.114 (0.105)	Data 0.00102 (0.00094)	Tok/s 57098 (59715)	Loss/tok 3.2336 (3.2852)	Learning Rate [7.8125e-05]
0: TRAIN [1][4460/6832]	Time 0.114 (0.105)	Data 0.00098 (0.00094)	Tok/s 57114 (58903)	Loss/tok 3.4669 (3.2843)	Learning Rate [7.8125e-05]
1: TRAIN [1][4470/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 71485 (59346)	Loss/tok 3.5638 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][4470/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00094)	Tok/s 72156 (59712)	Loss/tok 3.1705 (3.2851)	Learning Rate [7.8125e-05]
3: TRAIN [1][4470/6832]	Time 0.129 (0.105)	Data 0.00103 (0.00097)	Tok/s 72485 (60163)	Loss/tok 3.4545 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][4470/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00094)	Tok/s 71514 (58900)	Loss/tok 3.3670 (3.2844)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][4480/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 78614 (59717)	Loss/tok 3.5682 (3.2852)	Learning Rate [7.8125e-05]
1: TRAIN [1][4480/6832]	Time 0.132 (0.105)	Data 0.00110 (0.00094)	Tok/s 77917 (59351)	Loss/tok 3.2983 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][4480/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00097)	Tok/s 78605 (60168)	Loss/tok 3.3074 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][4480/6832]	Time 0.132 (0.105)	Data 0.00106 (0.00094)	Tok/s 77745 (58906)	Loss/tok 3.3232 (3.2845)	Learning Rate [7.8125e-05]
1: TRAIN [1][4490/6832]	Time 0.083 (0.105)	Data 0.00088 (0.00094)	Tok/s 54216 (59347)	Loss/tok 3.2865 (3.2864)	Learning Rate [7.8125e-05]
2: TRAIN [1][4490/6832]	Time 0.082 (0.105)	Data 0.00087 (0.00094)	Tok/s 54315 (59712)	Loss/tok 3.2060 (3.2853)	Learning Rate [7.8125e-05]
3: TRAIN [1][4490/6832]	Time 0.082 (0.105)	Data 0.00085 (0.00097)	Tok/s 54312 (60162)	Loss/tok 3.1897 (3.2865)	Learning Rate [7.8125e-05]
0: TRAIN [1][4490/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00094)	Tok/s 53165 (58902)	Loss/tok 3.0579 (3.2845)	Learning Rate [7.8125e-05]
1: TRAIN [1][4500/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00094)	Tok/s 52773 (59348)	Loss/tok 3.2005 (3.2865)	Learning Rate [7.8125e-05]
3: TRAIN [1][4500/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00097)	Tok/s 52768 (60163)	Loss/tok 3.2697 (3.2866)	Learning Rate [7.8125e-05]
2: TRAIN [1][4500/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00094)	Tok/s 52753 (59713)	Loss/tok 3.2742 (3.2851)	Learning Rate [7.8125e-05]
0: TRAIN [1][4500/6832]	Time 0.104 (0.105)	Data 0.00095 (0.00094)	Tok/s 52780 (58904)	Loss/tok 3.1866 (3.2844)	Learning Rate [7.8125e-05]
1: TRAIN [1][4510/6832]	Time 0.047 (0.105)	Data 0.00098 (0.00094)	Tok/s 43089 (59343)	Loss/tok 2.6042 (3.2865)	Learning Rate [7.8125e-05]
2: TRAIN [1][4510/6832]	Time 0.047 (0.105)	Data 0.00097 (0.00094)	Tok/s 45810 (59709)	Loss/tok 2.4545 (3.2849)	Learning Rate [7.8125e-05]
3: TRAIN [1][4510/6832]	Time 0.047 (0.105)	Data 0.00094 (0.00097)	Tok/s 46782 (60159)	Loss/tok 2.5321 (3.2866)	Learning Rate [7.8125e-05]
0: TRAIN [1][4510/6832]	Time 0.047 (0.105)	Data 0.00097 (0.00094)	Tok/s 40531 (58899)	Loss/tok 2.2942 (3.2843)	Learning Rate [7.8125e-05]
1: TRAIN [1][4520/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00094)	Tok/s 60105 (59351)	Loss/tok 3.3786 (3.2868)	Learning Rate [7.8125e-05]
3: TRAIN [1][4520/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00097)	Tok/s 60667 (60166)	Loss/tok 3.3244 (3.2868)	Learning Rate [7.8125e-05]
2: TRAIN [1][4520/6832]	Time 0.123 (0.105)	Data 0.00093 (0.00094)	Tok/s 60122 (59717)	Loss/tok 3.3016 (3.2850)	Learning Rate [7.8125e-05]
0: TRAIN [1][4520/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00094)	Tok/s 60107 (58907)	Loss/tok 3.4358 (3.2845)	Learning Rate [7.8125e-05]
1: TRAIN [1][4530/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00094)	Tok/s 54412 (59342)	Loss/tok 3.3861 (3.2866)	Learning Rate [7.8125e-05]
2: TRAIN [1][4530/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00094)	Tok/s 54427 (59708)	Loss/tok 3.1877 (3.2848)	Learning Rate [7.8125e-05]
0: TRAIN [1][4530/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00094)	Tok/s 54422 (58895)	Loss/tok 3.3166 (3.2843)	Learning Rate [7.8125e-05]
3: TRAIN [1][4530/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00097)	Tok/s 54397 (60158)	Loss/tok 3.4057 (3.2865)	Learning Rate [7.8125e-05]
1: TRAIN [1][4540/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 67523 (59342)	Loss/tok 3.4103 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][4540/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 66724 (58895)	Loss/tok 3.2167 (3.2844)	Learning Rate [7.8125e-05]
2: TRAIN [1][4540/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 67624 (59707)	Loss/tok 3.3861 (3.2847)	Learning Rate [7.8125e-05]
3: TRAIN [1][4540/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00097)	Tok/s 67615 (60157)	Loss/tok 3.3013 (3.2864)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [1][4550/6832]	Time 0.113 (0.105)	Data 0.00099 (0.00094)	Tok/s 61234 (59704)	Loss/tok 3.2876 (3.2845)	Learning Rate [7.8125e-05]
1: TRAIN [1][4550/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00094)	Tok/s 60211 (59338)	Loss/tok 3.2604 (3.2864)	Learning Rate [7.8125e-05]
3: TRAIN [1][4550/6832]	Time 0.113 (0.105)	Data 0.00097 (0.00097)	Tok/s 61246 (60155)	Loss/tok 3.2709 (3.2862)	Learning Rate [7.8125e-05]
0: TRAIN [1][4550/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 59972 (58891)	Loss/tok 3.3578 (3.2842)	Learning Rate [7.8125e-05]
1: TRAIN [1][4560/6832]	Time 0.058 (0.105)	Data 0.00094 (0.00094)	Tok/s 50778 (59326)	Loss/tok 2.9591 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][4560/6832]	Time 0.058 (0.105)	Data 0.00097 (0.00094)	Tok/s 50800 (59692)	Loss/tok 2.8698 (3.2843)	Learning Rate [7.8125e-05]
3: TRAIN [1][4560/6832]	Time 0.058 (0.105)	Data 0.00094 (0.00097)	Tok/s 52474 (60143)	Loss/tok 2.8168 (3.2861)	Learning Rate [7.8125e-05]
0: TRAIN [1][4560/6832]	Time 0.058 (0.105)	Data 0.00094 (0.00094)	Tok/s 50854 (58879)	Loss/tok 2.8458 (3.2840)	Learning Rate [7.8125e-05]
1: TRAIN [1][4570/6832]	Time 0.101 (0.105)	Data 0.00090 (0.00094)	Tok/s 54621 (59340)	Loss/tok 3.1538 (3.2861)	Learning Rate [7.8125e-05]
0: TRAIN [1][4570/6832]	Time 0.101 (0.105)	Data 0.00095 (0.00094)	Tok/s 54578 (58893)	Loss/tok 3.1029 (3.2839)	Learning Rate [7.8125e-05]
3: TRAIN [1][4570/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00097)	Tok/s 55821 (60157)	Loss/tok 3.3191 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][4570/6832]	Time 0.101 (0.105)	Data 0.00095 (0.00094)	Tok/s 55848 (59706)	Loss/tok 3.2470 (3.2844)	Learning Rate [7.8125e-05]
3: TRAIN [1][4580/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00097)	Tok/s 59217 (60153)	Loss/tok 3.3531 (3.2861)	Learning Rate [7.8125e-05]
1: TRAIN [1][4580/6832]	Time 0.114 (0.105)	Data 0.00091 (0.00094)	Tok/s 58492 (59337)	Loss/tok 3.3101 (3.2861)	Learning Rate [7.8125e-05]
0: TRAIN [1][4580/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00094)	Tok/s 58503 (58890)	Loss/tok 3.1569 (3.2840)	Learning Rate [7.8125e-05]
2: TRAIN [1][4580/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00094)	Tok/s 58493 (59703)	Loss/tok 3.3736 (3.2842)	Learning Rate [7.8125e-05]
1: TRAIN [1][4590/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00094)	Tok/s 49614 (59324)	Loss/tok 3.0302 (3.2858)	Learning Rate [7.8125e-05]
3: TRAIN [1][4590/6832]	Time 0.070 (0.105)	Data 0.00085 (0.00097)	Tok/s 51446 (60140)	Loss/tok 3.0238 (3.2859)	Learning Rate [7.8125e-05]
2: TRAIN [1][4590/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00094)	Tok/s 49667 (59690)	Loss/tok 3.0922 (3.2841)	Learning Rate [7.8125e-05]
0: TRAIN [1][4590/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00094)	Tok/s 49664 (58877)	Loss/tok 2.9600 (3.2838)	Learning Rate [7.8125e-05]
3: TRAIN [1][4600/6832]	Time 0.091 (0.105)	Data 0.00091 (0.00097)	Tok/s 54716 (60134)	Loss/tok 3.1052 (3.2859)	Learning Rate [7.8125e-05]
2: TRAIN [1][4600/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00094)	Tok/s 54708 (59684)	Loss/tok 3.1378 (3.2839)	Learning Rate [7.8125e-05]
1: TRAIN [1][4600/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00094)	Tok/s 54669 (59319)	Loss/tok 3.2199 (3.2856)	Learning Rate [7.8125e-05]
0: TRAIN [1][4600/6832]	Time 0.091 (0.105)	Data 0.00093 (0.00094)	Tok/s 54690 (58872)	Loss/tok 3.1099 (3.2837)	Learning Rate [7.8125e-05]
1: TRAIN [1][4610/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 67914 (59318)	Loss/tok 3.3182 (3.2858)	Learning Rate [7.8125e-05]
2: TRAIN [1][4610/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00094)	Tok/s 67929 (59684)	Loss/tok 3.3625 (3.2841)	Learning Rate [7.8125e-05]
3: TRAIN [1][4610/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00097)	Tok/s 67923 (60135)	Loss/tok 3.2727 (3.2859)	Learning Rate [7.8125e-05]
0: TRAIN [1][4610/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00094)	Tok/s 67559 (58870)	Loss/tok 3.5516 (3.2839)	Learning Rate [7.8125e-05]
1: TRAIN [1][4620/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00094)	Tok/s 58399 (59313)	Loss/tok 3.1220 (3.2857)	Learning Rate [7.8125e-05]
3: TRAIN [1][4620/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00097)	Tok/s 59331 (60131)	Loss/tok 3.3014 (3.2860)	Learning Rate [7.8125e-05]
0: TRAIN [1][4620/6832]	Time 0.125 (0.105)	Data 0.00092 (0.00094)	Tok/s 58433 (58862)	Loss/tok 3.3461 (3.2841)	Learning Rate [7.8125e-05]
2: TRAIN [1][4620/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00094)	Tok/s 58369 (59679)	Loss/tok 3.3839 (3.2843)	Learning Rate [7.8125e-05]
1: TRAIN [1][4630/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 51473 (59309)	Loss/tok 3.3902 (3.2858)	Learning Rate [7.8125e-05]
3: TRAIN [1][4630/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00097)	Tok/s 51462 (60126)	Loss/tok 3.1990 (3.2859)	Learning Rate [7.8125e-05]
2: TRAIN [1][4630/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 51471 (59675)	Loss/tok 3.2488 (3.2843)	Learning Rate [7.8125e-05]
0: TRAIN [1][4630/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00094)	Tok/s 51477 (58859)	Loss/tok 3.2642 (3.2841)	Learning Rate [7.8125e-05]
1: TRAIN [1][4640/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 60394 (59325)	Loss/tok 3.3228 (3.2859)	Learning Rate [7.8125e-05]
0: TRAIN [1][4640/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 59871 (58876)	Loss/tok 3.1916 (3.2841)	Learning Rate [7.8125e-05]
2: TRAIN [1][4640/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 60751 (59691)	Loss/tok 3.1694 (3.2842)	Learning Rate [7.8125e-05]
3: TRAIN [1][4640/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00097)	Tok/s 60743 (60141)	Loss/tok 3.3819 (3.2860)	Learning Rate [7.8125e-05]
1: TRAIN [1][4650/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 58114 (59327)	Loss/tok 3.3564 (3.2861)	Learning Rate [7.8125e-05]
3: TRAIN [1][4650/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00097)	Tok/s 58370 (60142)	Loss/tok 3.3431 (3.2858)	Learning Rate [7.8125e-05]
2: TRAIN [1][4650/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 58049 (59692)	Loss/tok 3.3797 (3.2843)	Learning Rate [7.8125e-05]
0: TRAIN [1][4650/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 58122 (58878)	Loss/tok 3.3689 (3.2841)	Learning Rate [7.8125e-05]
1: TRAIN [1][4660/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 53715 (59320)	Loss/tok 3.3297 (3.2862)	Learning Rate [7.8125e-05]
0: TRAIN [1][4660/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00094)	Tok/s 53723 (58871)	Loss/tok 3.3988 (3.2841)	Learning Rate [7.8125e-05]
3: TRAIN [1][4660/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00097)	Tok/s 53565 (60134)	Loss/tok 3.1939 (3.2858)	Learning Rate [7.8125e-05]
2: TRAIN [1][4660/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00094)	Tok/s 53549 (59684)	Loss/tok 3.3191 (3.2842)	Learning Rate [7.8125e-05]
2: TRAIN [1][4670/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00094)	Tok/s 50818 (59681)	Loss/tok 3.2192 (3.2842)	Learning Rate [7.8125e-05]
3: TRAIN [1][4670/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00097)	Tok/s 51580 (60130)	Loss/tok 3.2614 (3.2857)	Learning Rate [7.8125e-05]
0: TRAIN [1][4670/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00094)	Tok/s 50530 (58868)	Loss/tok 3.1692 (3.2841)	Learning Rate [7.8125e-05]
1: TRAIN [1][4670/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00094)	Tok/s 50448 (59316)	Loss/tok 3.3138 (3.2862)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [1][4680/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00094)	Tok/s 52111 (59316)	Loss/tok 3.3484 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][4680/6832]	Time 0.106 (0.105)	Data 0.00087 (0.00097)	Tok/s 52068 (60131)	Loss/tok 3.4147 (3.2857)	Learning Rate [7.8125e-05]
2: TRAIN [1][4680/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00094)	Tok/s 52071 (59681)	Loss/tok 3.2217 (3.2840)	Learning Rate [7.8125e-05]
0: TRAIN [1][4680/6832]	Time 0.106 (0.105)	Data 0.00092 (0.00094)	Tok/s 52112 (58868)	Loss/tok 3.1451 (3.2840)	Learning Rate [7.8125e-05]
1: TRAIN [1][4690/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00094)	Tok/s 47478 (59308)	Loss/tok 2.7646 (3.2860)	Learning Rate [7.8125e-05]
2: TRAIN [1][4690/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00094)	Tok/s 47525 (59673)	Loss/tok 2.6498 (3.2838)	Learning Rate [7.8125e-05]
3: TRAIN [1][4690/6832]	Time 0.059 (0.105)	Data 0.00090 (0.00097)	Tok/s 48371 (60123)	Loss/tok 2.9480 (3.2857)	Learning Rate [7.8125e-05]
0: TRAIN [1][4690/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00094)	Tok/s 46727 (58860)	Loss/tok 2.8892 (3.2839)	Learning Rate [7.8125e-05]
1: TRAIN [1][4700/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 53746 (59314)	Loss/tok 3.1642 (3.2860)	Learning Rate [7.8125e-05]
3: TRAIN [1][4700/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00097)	Tok/s 53690 (60128)	Loss/tok 3.2103 (3.2856)	Learning Rate [7.8125e-05]
2: TRAIN [1][4700/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00094)	Tok/s 53692 (59679)	Loss/tok 3.3339 (3.2839)	Learning Rate [7.8125e-05]
0: TRAIN [1][4700/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00094)	Tok/s 53727 (58867)	Loss/tok 3.3596 (3.2838)	Learning Rate [7.8125e-05]
1: TRAIN [1][4710/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00094)	Tok/s 62399 (59317)	Loss/tok 3.4250 (3.2862)	Learning Rate [7.8125e-05]
3: TRAIN [1][4710/6832]	Time 0.123 (0.105)	Data 0.00095 (0.00097)	Tok/s 63471 (60131)	Loss/tok 3.3770 (3.2856)	Learning Rate [7.8125e-05]
0: TRAIN [1][4710/6832]	Time 0.123 (0.105)	Data 0.00095 (0.00094)	Tok/s 62392 (58870)	Loss/tok 3.4902 (3.2839)	Learning Rate [7.8125e-05]
2: TRAIN [1][4710/6832]	Time 0.123 (0.105)	Data 0.00096 (0.00094)	Tok/s 63293 (59682)	Loss/tok 3.3003 (3.2840)	Learning Rate [7.8125e-05]
1: TRAIN [1][4720/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 80428 (59327)	Loss/tok 3.4906 (3.2863)	Learning Rate [7.8125e-05]
3: TRAIN [1][4720/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00097)	Tok/s 81438 (60141)	Loss/tok 3.2651 (3.2854)	Learning Rate [7.8125e-05]
2: TRAIN [1][4720/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 80661 (59691)	Loss/tok 3.2479 (3.2840)	Learning Rate [7.8125e-05]
0: TRAIN [1][4720/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00094)	Tok/s 79865 (58880)	Loss/tok 3.3898 (3.2838)	Learning Rate [7.8125e-05]
1: TRAIN [1][4730/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 61197 (59322)	Loss/tok 3.5327 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][4730/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 61187 (58876)	Loss/tok 3.2645 (3.2839)	Learning Rate [7.8125e-05]
3: TRAIN [1][4730/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00097)	Tok/s 62173 (60136)	Loss/tok 3.3784 (3.2855)	Learning Rate [7.8125e-05]
2: TRAIN [1][4730/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 61696 (59687)	Loss/tok 3.2472 (3.2840)	Learning Rate [7.8125e-05]
1: TRAIN [1][4740/6832]	Time 0.132 (0.106)	Data 0.00090 (0.00094)	Tok/s 77864 (59324)	Loss/tok 3.3372 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][4740/6832]	Time 0.132 (0.106)	Data 0.00090 (0.00094)	Tok/s 77843 (58878)	Loss/tok 3.3822 (3.2840)	Learning Rate [7.8125e-05]
3: TRAIN [1][4740/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00097)	Tok/s 78741 (60137)	Loss/tok 3.3321 (3.2854)	Learning Rate [7.8125e-05]
2: TRAIN [1][4740/6832]	Time 0.132 (0.106)	Data 0.00089 (0.00094)	Tok/s 78334 (59688)	Loss/tok 3.3114 (3.2842)	Learning Rate [7.8125e-05]
1: TRAIN [1][4750/6832]	Time 0.130 (0.106)	Data 0.00093 (0.00094)	Tok/s 67002 (59328)	Loss/tok 3.5314 (3.2865)	Learning Rate [7.8125e-05]
2: TRAIN [1][4750/6832]	Time 0.130 (0.106)	Data 0.00101 (0.00094)	Tok/s 67089 (59692)	Loss/tok 3.2890 (3.2842)	Learning Rate [7.8125e-05]
0: TRAIN [1][4750/6832]	Time 0.130 (0.106)	Data 0.00093 (0.00094)	Tok/s 66630 (58882)	Loss/tok 3.2079 (3.2840)	Learning Rate [7.8125e-05]
3: TRAIN [1][4750/6832]	Time 0.130 (0.106)	Data 0.00099 (0.00097)	Tok/s 67095 (60140)	Loss/tok 3.2806 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4760/6832]	Time 0.130 (0.106)	Data 0.00088 (0.00097)	Tok/s 73088 (60153)	Loss/tok 3.4757 (3.2854)	Learning Rate [7.8125e-05]
2: TRAIN [1][4760/6832]	Time 0.130 (0.106)	Data 0.00089 (0.00094)	Tok/s 73074 (59705)	Loss/tok 3.3759 (3.2841)	Learning Rate [7.8125e-05]
1: TRAIN [1][4760/6832]	Time 0.130 (0.106)	Data 0.00104 (0.00094)	Tok/s 72723 (59341)	Loss/tok 3.3813 (3.2863)	Learning Rate [7.8125e-05]
0: TRAIN [1][4760/6832]	Time 0.130 (0.106)	Data 0.00104 (0.00094)	Tok/s 72128 (58896)	Loss/tok 3.5152 (3.2839)	Learning Rate [7.8125e-05]
2: TRAIN [1][4770/6832]	Time 0.130 (0.106)	Data 0.00089 (0.00094)	Tok/s 77954 (59703)	Loss/tok 3.3253 (3.2839)	Learning Rate [7.8125e-05]
3: TRAIN [1][4770/6832]	Time 0.130 (0.106)	Data 0.00087 (0.00097)	Tok/s 78552 (60151)	Loss/tok 3.2519 (3.2852)	Learning Rate [7.8125e-05]
1: TRAIN [1][4770/6832]	Time 0.130 (0.106)	Data 0.00089 (0.00094)	Tok/s 77945 (59339)	Loss/tok 3.4211 (3.2863)	Learning Rate [7.8125e-05]
0: TRAIN [1][4770/6832]	Time 0.130 (0.106)	Data 0.00090 (0.00094)	Tok/s 77295 (58894)	Loss/tok 3.3618 (3.2838)	Learning Rate [7.8125e-05]
1: TRAIN [1][4780/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 69330 (59331)	Loss/tok 3.3549 (3.2862)	Learning Rate [7.8125e-05]
2: TRAIN [1][4780/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 69333 (59695)	Loss/tok 3.3473 (3.2838)	Learning Rate [7.8125e-05]
3: TRAIN [1][4780/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00097)	Tok/s 69746 (60142)	Loss/tok 3.4264 (3.2851)	Learning Rate [7.8125e-05]
0: TRAIN [1][4780/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 69309 (58887)	Loss/tok 3.2123 (3.2837)	Learning Rate [7.8125e-05]
2: TRAIN [1][4790/6832]	Time 0.085 (0.105)	Data 0.00101 (0.00094)	Tok/s 54373 (59706)	Loss/tok 3.2048 (3.2837)	Learning Rate [7.8125e-05]
1: TRAIN [1][4790/6832]	Time 0.085 (0.105)	Data 0.00097 (0.00094)	Tok/s 53470 (59341)	Loss/tok 3.1171 (3.2859)	Learning Rate [7.8125e-05]
3: TRAIN [1][4790/6832]	Time 0.085 (0.105)	Data 0.00099 (0.00097)	Tok/s 54364 (60155)	Loss/tok 3.1285 (3.2849)	Learning Rate [7.8125e-05]
0: TRAIN [1][4790/6832]	Time 0.085 (0.105)	Data 0.00099 (0.00094)	Tok/s 52869 (58896)	Loss/tok 3.1549 (3.2835)	Learning Rate [7.8125e-05]
1: TRAIN [1][4800/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00094)	Tok/s 51966 (59341)	Loss/tok 3.0843 (3.2859)	Learning Rate [7.8125e-05]
0: TRAIN [1][4800/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00094)	Tok/s 51245 (58896)	Loss/tok 2.9476 (3.2835)	Learning Rate [7.8125e-05]
3: TRAIN [1][4800/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00097)	Tok/s 51945 (60154)	Loss/tok 3.0272 (3.2849)	Learning Rate [7.8125e-05]
2: TRAIN [1][4800/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00094)	Tok/s 51932 (59706)	Loss/tok 3.0502 (3.2837)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [1][4810/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00094)	Tok/s 71674 (59343)	Loss/tok 3.3480 (3.2859)	Learning Rate [7.8125e-05]
0: TRAIN [1][4810/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 71694 (58899)	Loss/tok 3.4309 (3.2835)	Learning Rate [7.8125e-05]
3: TRAIN [1][4810/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00097)	Tok/s 72602 (60155)	Loss/tok 3.3259 (3.2848)	Learning Rate [7.8125e-05]
2: TRAIN [1][4810/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 72489 (59707)	Loss/tok 3.4213 (3.2836)	Learning Rate [7.8125e-05]
1: TRAIN [1][4820/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00094)	Tok/s 52670 (59339)	Loss/tok 3.2447 (3.2859)	Learning Rate [7.8125e-05]
3: TRAIN [1][4820/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00097)	Tok/s 53768 (60151)	Loss/tok 3.4462 (3.2848)	Learning Rate [7.8125e-05]
2: TRAIN [1][4820/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00094)	Tok/s 52967 (59703)	Loss/tok 3.4165 (3.2836)	Learning Rate [7.8125e-05]
0: TRAIN [1][4820/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 52671 (58895)	Loss/tok 3.3034 (3.2836)	Learning Rate [7.8125e-05]
3: TRAIN [1][4830/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00097)	Tok/s 75872 (60156)	Loss/tok 3.2856 (3.2848)	Learning Rate [7.8125e-05]
1: TRAIN [1][4830/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00094)	Tok/s 74915 (59344)	Loss/tok 3.2247 (3.2859)	Learning Rate [7.8125e-05]
2: TRAIN [1][4830/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00094)	Tok/s 74940 (59708)	Loss/tok 3.4352 (3.2836)	Learning Rate [7.8125e-05]
0: TRAIN [1][4830/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 74789 (58901)	Loss/tok 3.5298 (3.2836)	Learning Rate [7.8125e-05]
1: TRAIN [1][4840/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00094)	Tok/s 53477 (59339)	Loss/tok 3.2379 (3.2858)	Learning Rate [7.8125e-05]
0: TRAIN [1][4840/6832]	Time 0.079 (0.105)	Data 0.00090 (0.00094)	Tok/s 53444 (58895)	Loss/tok 3.1295 (3.2835)	Learning Rate [7.8125e-05]
2: TRAIN [1][4840/6832]	Time 0.079 (0.105)	Data 0.00094 (0.00094)	Tok/s 53541 (59702)	Loss/tok 3.1460 (3.2835)	Learning Rate [7.8125e-05]
3: TRAIN [1][4840/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00097)	Tok/s 55024 (60150)	Loss/tok 3.2022 (3.2847)	Learning Rate [7.8125e-05]
1: TRAIN [1][4850/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00094)	Tok/s 57974 (59336)	Loss/tok 3.3947 (3.2858)	Learning Rate [7.8125e-05]
0: TRAIN [1][4850/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 57898 (58893)	Loss/tok 3.3170 (3.2834)	Learning Rate [7.8125e-05]
2: TRAIN [1][4850/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 58956 (59699)	Loss/tok 3.1404 (3.2834)	Learning Rate [7.8125e-05]
3: TRAIN [1][4850/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00097)	Tok/s 58959 (60146)	Loss/tok 3.2477 (3.2846)	Learning Rate [7.8125e-05]
2: TRAIN [1][4860/6832]	Time 0.048 (0.105)	Data 0.00094 (0.00094)	Tok/s 45665 (59696)	Loss/tok 2.4157 (3.2834)	Learning Rate [7.8125e-05]
3: TRAIN [1][4860/6832]	Time 0.048 (0.105)	Data 0.00099 (0.00097)	Tok/s 47063 (60144)	Loss/tok 2.5806 (3.2846)	Learning Rate [7.8125e-05]
1: TRAIN [1][4860/6832]	Time 0.048 (0.105)	Data 0.00096 (0.00094)	Tok/s 42551 (59333)	Loss/tok 2.4010 (3.2857)	Learning Rate [7.8125e-05]
0: TRAIN [1][4860/6832]	Time 0.048 (0.105)	Data 0.00101 (0.00094)	Tok/s 40017 (58890)	Loss/tok 2.3716 (3.2834)	Learning Rate [7.8125e-05]
1: TRAIN [1][4870/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00094)	Tok/s 75555 (59338)	Loss/tok 3.3095 (3.2856)	Learning Rate [7.8125e-05]
0: TRAIN [1][4870/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00094)	Tok/s 75397 (58895)	Loss/tok 3.4626 (3.2833)	Learning Rate [7.8125e-05]
3: TRAIN [1][4870/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00097)	Tok/s 76428 (60149)	Loss/tok 3.4611 (3.2843)	Learning Rate [7.8125e-05]
2: TRAIN [1][4870/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 76377 (59702)	Loss/tok 3.4209 (3.2832)	Learning Rate [7.8125e-05]
1: TRAIN [1][4880/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00094)	Tok/s 52381 (59344)	Loss/tok 3.3012 (3.2855)	Learning Rate [7.8125e-05]
3: TRAIN [1][4880/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00097)	Tok/s 52358 (60155)	Loss/tok 3.3346 (3.2843)	Learning Rate [7.8125e-05]
0: TRAIN [1][4880/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 52050 (58902)	Loss/tok 3.3620 (3.2832)	Learning Rate [7.8125e-05]
2: TRAIN [1][4880/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00094)	Tok/s 52357 (59708)	Loss/tok 3.1997 (3.2832)	Learning Rate [7.8125e-05]
3: TRAIN [1][4890/6832]	Time 0.130 (0.105)	Data 0.00102 (0.00097)	Tok/s 73080 (60153)	Loss/tok 3.4030 (3.2843)	Learning Rate [7.8125e-05]
1: TRAIN [1][4890/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 72529 (59342)	Loss/tok 3.1251 (3.2854)	Learning Rate [7.8125e-05]
2: TRAIN [1][4890/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 73077 (59706)	Loss/tok 3.3776 (3.2831)	Learning Rate [7.8125e-05]
0: TRAIN [1][4890/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00094)	Tok/s 72030 (58901)	Loss/tok 3.5504 (3.2832)	Learning Rate [7.8125e-05]
1: TRAIN [1][4900/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 69208 (59350)	Loss/tok 3.3216 (3.2853)	Learning Rate [7.8125e-05]
0: TRAIN [1][4900/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 69208 (58908)	Loss/tok 3.4087 (3.2834)	Learning Rate [7.8125e-05]
2: TRAIN [1][4900/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 69090 (59713)	Loss/tok 3.3108 (3.2831)	Learning Rate [7.8125e-05]
3: TRAIN [1][4900/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00097)	Tok/s 69498 (60161)	Loss/tok 3.5115 (3.2845)	Learning Rate [7.8125e-05]
2: TRAIN [1][4910/6832]	Time 0.114 (0.106)	Data 0.00093 (0.00094)	Tok/s 60407 (59715)	Loss/tok 3.4686 (3.2833)	Learning Rate [7.8125e-05]
1: TRAIN [1][4910/6832]	Time 0.114 (0.106)	Data 0.00090 (0.00094)	Tok/s 60374 (59352)	Loss/tok 3.5438 (3.2854)	Learning Rate [7.8125e-05]
3: TRAIN [1][4910/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00097)	Tok/s 60494 (60162)	Loss/tok 3.4689 (3.2846)	Learning Rate [7.8125e-05]
0: TRAIN [1][4910/6832]	Time 0.115 (0.106)	Data 0.00096 (0.00094)	Tok/s 60358 (58911)	Loss/tok 3.2795 (3.2834)	Learning Rate [7.8125e-05]
2: TRAIN [1][4920/6832]	Time 0.107 (0.105)	Data 0.00085 (0.00094)	Tok/s 51261 (59697)	Loss/tok 3.1610 (3.2831)	Learning Rate [7.8125e-05]
3: TRAIN [1][4920/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00097)	Tok/s 51271 (60145)	Loss/tok 3.3011 (3.2844)	Learning Rate [7.8125e-05]
1: TRAIN [1][4920/6832]	Time 0.107 (0.105)	Data 0.00091 (0.00094)	Tok/s 51244 (59333)	Loss/tok 3.1110 (3.2852)	Learning Rate [7.8125e-05]
0: TRAIN [1][4920/6832]	Time 0.107 (0.105)	Data 0.00093 (0.00094)	Tok/s 51276 (58890)	Loss/tok 3.2964 (3.2832)	Learning Rate [7.8125e-05]
2: TRAIN [1][4930/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 74332 (59693)	Loss/tok 3.3573 (3.2830)	Learning Rate [7.8125e-05]
1: TRAIN [1][4930/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 73871 (59330)	Loss/tok 3.3658 (3.2851)	Learning Rate [7.8125e-05]
0: TRAIN [1][4930/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 73853 (58887)	Loss/tok 3.3271 (3.2832)	Learning Rate [7.8125e-05]
3: TRAIN [1][4930/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00097)	Tok/s 74827 (60141)	Loss/tok 3.3596 (3.2845)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][4940/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 75935 (59698)	Loss/tok 3.4250 (3.2830)	Learning Rate [7.8125e-05]
1: TRAIN [1][4940/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 75321 (59334)	Loss/tok 3.4124 (3.2852)	Learning Rate [7.8125e-05]
0: TRAIN [1][4940/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00094)	Tok/s 75292 (58892)	Loss/tok 3.3438 (3.2834)	Learning Rate [7.8125e-05]
3: TRAIN [1][4940/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00097)	Tok/s 76276 (60146)	Loss/tok 3.2416 (3.2844)	Learning Rate [7.8125e-05]
1: TRAIN [1][4950/6832]	Time 0.042 (0.105)	Data 0.00097 (0.00094)	Tok/s 33303 (59322)	Loss/tok 2.2503 (3.2851)	Learning Rate [7.8125e-05]
0: TRAIN [1][4950/6832]	Time 0.042 (0.105)	Data 0.00095 (0.00094)	Tok/s 21344 (58877)	Loss/tok 1.6751 (3.2832)	Learning Rate [7.8125e-05]
2: TRAIN [1][4950/6832]	Time 0.042 (0.105)	Data 0.00091 (0.00094)	Tok/s 39719 (59688)	Loss/tok 1.8821 (3.2828)	Learning Rate [7.8125e-05]
3: TRAIN [1][4950/6832]	Time 0.042 (0.105)	Data 0.00098 (0.00097)	Tok/s 43944 (60136)	Loss/tok 2.2085 (3.2842)	Learning Rate [7.8125e-05]
2: TRAIN [1][4960/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00094)	Tok/s 52138 (59678)	Loss/tok 2.9535 (3.2826)	Learning Rate [7.8125e-05]
3: TRAIN [1][4960/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00097)	Tok/s 52205 (60128)	Loss/tok 3.0525 (3.2840)	Learning Rate [7.8125e-05]
1: TRAIN [1][4960/6832]	Time 0.064 (0.105)	Data 0.00092 (0.00094)	Tok/s 50190 (59310)	Loss/tok 2.9066 (3.2848)	Learning Rate [7.8125e-05]
0: TRAIN [1][4960/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00094)	Tok/s 50214 (58861)	Loss/tok 2.8372 (3.2830)	Learning Rate [7.8125e-05]
2: TRAIN [1][4970/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 65212 (59678)	Loss/tok 3.3679 (3.2826)	Learning Rate [7.8125e-05]
3: TRAIN [1][4970/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00097)	Tok/s 65232 (60127)	Loss/tok 3.2121 (3.2840)	Learning Rate [7.8125e-05]
0: TRAIN [1][4970/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 64731 (58861)	Loss/tok 3.4335 (3.2830)	Learning Rate [7.8125e-05]
1: TRAIN [1][4970/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 65189 (59309)	Loss/tok 3.3736 (3.2847)	Learning Rate [7.8125e-05]
2: TRAIN [1][4980/6832]	Time 0.076 (0.105)	Data 0.00095 (0.00094)	Tok/s 52188 (59674)	Loss/tok 3.0722 (3.2826)	Learning Rate [7.8125e-05]
0: TRAIN [1][4980/6832]	Time 0.076 (0.105)	Data 0.00091 (0.00094)	Tok/s 52192 (58858)	Loss/tok 3.1225 (3.2830)	Learning Rate [7.8125e-05]
1: TRAIN [1][4980/6832]	Time 0.076 (0.105)	Data 0.00095 (0.00094)	Tok/s 52169 (59305)	Loss/tok 3.0333 (3.2847)	Learning Rate [7.8125e-05]
3: TRAIN [1][4980/6832]	Time 0.076 (0.105)	Data 0.00096 (0.00097)	Tok/s 52479 (60122)	Loss/tok 3.0210 (3.2839)	Learning Rate [7.8125e-05]
1: TRAIN [1][4990/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00094)	Tok/s 52804 (59303)	Loss/tok 3.1496 (3.2846)	Learning Rate [7.8125e-05]
2: TRAIN [1][4990/6832]	Time 0.096 (0.105)	Data 0.00086 (0.00094)	Tok/s 53282 (59671)	Loss/tok 3.0306 (3.2825)	Learning Rate [7.8125e-05]
0: TRAIN [1][4990/6832]	Time 0.096 (0.105)	Data 0.00090 (0.00094)	Tok/s 51936 (58855)	Loss/tok 3.1071 (3.2829)	Learning Rate [7.8125e-05]
3: TRAIN [1][4990/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00097)	Tok/s 53290 (60119)	Loss/tok 3.0999 (3.2839)	Learning Rate [7.8125e-05]
2: TRAIN [1][5000/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00094)	Tok/s 52703 (59678)	Loss/tok 3.0856 (3.2825)	Learning Rate [7.8125e-05]
1: TRAIN [1][5000/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00094)	Tok/s 52597 (59311)	Loss/tok 3.2089 (3.2845)	Learning Rate [7.8125e-05]
0: TRAIN [1][5000/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00094)	Tok/s 52624 (58864)	Loss/tok 3.0174 (3.2829)	Learning Rate [7.8125e-05]
3: TRAIN [1][5000/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00097)	Tok/s 54268 (60127)	Loss/tok 3.0642 (3.2838)	Learning Rate [7.8125e-05]
1: TRAIN [1][5010/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00094)	Tok/s 53727 (59302)	Loss/tok 3.2443 (3.2845)	Learning Rate [7.8125e-05]
2: TRAIN [1][5010/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00094)	Tok/s 53631 (59670)	Loss/tok 3.0905 (3.2824)	Learning Rate [7.8125e-05]
0: TRAIN [1][5010/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00094)	Tok/s 53706 (58856)	Loss/tok 3.0741 (3.2829)	Learning Rate [7.8125e-05]
3: TRAIN [1][5010/6832]	Time 0.091 (0.105)	Data 0.00091 (0.00097)	Tok/s 54452 (60118)	Loss/tok 3.2366 (3.2836)	Learning Rate [7.8125e-05]
1: TRAIN [1][5020/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00094)	Tok/s 51994 (59304)	Loss/tok 3.0637 (3.2845)	Learning Rate [7.8125e-05]
0: TRAIN [1][5020/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00094)	Tok/s 51247 (58855)	Loss/tok 3.0733 (3.2827)	Learning Rate [7.8125e-05]
2: TRAIN [1][5020/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00094)	Tok/s 52842 (59672)	Loss/tok 3.2084 (3.2822)	Learning Rate [7.8125e-05]
3: TRAIN [1][5020/6832]	Time 0.080 (0.105)	Data 0.00099 (0.00097)	Tok/s 52871 (60121)	Loss/tok 3.1487 (3.2836)	Learning Rate [7.8125e-05]
2: TRAIN [1][5030/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00094)	Tok/s 53011 (59675)	Loss/tok 3.2100 (3.2823)	Learning Rate [7.8125e-05]
1: TRAIN [1][5030/6832]	Time 0.077 (0.105)	Data 0.00093 (0.00094)	Tok/s 53019 (59307)	Loss/tok 3.1141 (3.2844)	Learning Rate [7.8125e-05]
0: TRAIN [1][5030/6832]	Time 0.077 (0.105)	Data 0.00092 (0.00094)	Tok/s 52987 (58858)	Loss/tok 3.2745 (3.2827)	Learning Rate [7.8125e-05]
3: TRAIN [1][5030/6832]	Time 0.077 (0.105)	Data 0.00096 (0.00097)	Tok/s 53019 (60123)	Loss/tok 3.1604 (3.2836)	Learning Rate [7.8125e-05]
1: TRAIN [1][5040/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 61316 (59300)	Loss/tok 3.4388 (3.2842)	Learning Rate [7.8125e-05]
2: TRAIN [1][5040/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 61746 (59668)	Loss/tok 3.2483 (3.2822)	Learning Rate [7.8125e-05]
0: TRAIN [1][5040/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00094)	Tok/s 61299 (58852)	Loss/tok 3.4348 (3.2826)	Learning Rate [7.8125e-05]
3: TRAIN [1][5040/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00097)	Tok/s 62298 (60116)	Loss/tok 3.3243 (3.2835)	Learning Rate [7.8125e-05]
1: TRAIN [1][5050/6832]	Time 0.127 (0.105)	Data 0.00103 (0.00094)	Tok/s 69421 (59294)	Loss/tok 3.4832 (3.2842)	Learning Rate [7.8125e-05]
2: TRAIN [1][5050/6832]	Time 0.127 (0.105)	Data 0.00096 (0.00094)	Tok/s 69419 (59662)	Loss/tok 3.4905 (3.2821)	Learning Rate [7.8125e-05]
0: TRAIN [1][5050/6832]	Time 0.127 (0.105)	Data 0.00108 (0.00094)	Tok/s 69409 (58846)	Loss/tok 3.2576 (3.2825)	Learning Rate [7.8125e-05]
3: TRAIN [1][5050/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00097)	Tok/s 69394 (60109)	Loss/tok 3.2759 (3.2835)	Learning Rate [7.8125e-05]
2: TRAIN [1][5060/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00094)	Tok/s 51958 (59658)	Loss/tok 3.3626 (3.2819)	Learning Rate [7.8125e-05]
1: TRAIN [1][5060/6832]	Time 0.104 (0.105)	Data 0.00089 (0.00094)	Tok/s 50799 (59290)	Loss/tok 3.1535 (3.2839)	Learning Rate [7.8125e-05]
0: TRAIN [1][5060/6832]	Time 0.104 (0.105)	Data 0.00095 (0.00094)	Tok/s 50696 (58842)	Loss/tok 3.3213 (3.2825)	Learning Rate [7.8125e-05]
3: TRAIN [1][5060/6832]	Time 0.103 (0.105)	Data 0.00106 (0.00097)	Tok/s 52203 (60105)	Loss/tok 3.0280 (3.2833)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [1][5070/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00094)	Tok/s 55166 (59295)	Loss/tok 3.3010 (3.2838)	Learning Rate [7.8125e-05]
2: TRAIN [1][5070/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00094)	Tok/s 55151 (59663)	Loss/tok 3.3442 (3.2818)	Learning Rate [7.8125e-05]
0: TRAIN [1][5070/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00094)	Tok/s 55136 (58849)	Loss/tok 3.2881 (3.2824)	Learning Rate [7.8125e-05]
3: TRAIN [1][5070/6832]	Time 0.121 (0.105)	Data 0.00094 (0.00097)	Tok/s 55133 (60111)	Loss/tok 3.3004 (3.2832)	Learning Rate [7.8125e-05]
1: TRAIN [1][5080/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00094)	Tok/s 58996 (59296)	Loss/tok 3.4589 (3.2838)	Learning Rate [7.8125e-05]
0: TRAIN [1][5080/6832]	Time 0.122 (0.105)	Data 0.00096 (0.00094)	Tok/s 58047 (58849)	Loss/tok 3.2716 (3.2823)	Learning Rate [7.8125e-05]
2: TRAIN [1][5080/6832]	Time 0.122 (0.105)	Data 0.00105 (0.00094)	Tok/s 58988 (59663)	Loss/tok 3.4279 (3.2819)	Learning Rate [7.8125e-05]
3: TRAIN [1][5080/6832]	Time 0.122 (0.105)	Data 0.00098 (0.00097)	Tok/s 58982 (60111)	Loss/tok 3.3585 (3.2831)	Learning Rate [7.8125e-05]
1: TRAIN [1][5090/6832]	Time 0.126 (0.105)	Data 0.00113 (0.00094)	Tok/s 62790 (59304)	Loss/tok 3.2222 (3.2838)	Learning Rate [7.8125e-05]
0: TRAIN [1][5090/6832]	Time 0.126 (0.105)	Data 0.00111 (0.00094)	Tok/s 62804 (58858)	Loss/tok 3.3274 (3.2824)	Learning Rate [7.8125e-05]
2: TRAIN [1][5090/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00094)	Tok/s 62754 (59672)	Loss/tok 3.4277 (3.2820)	Learning Rate [7.8125e-05]
3: TRAIN [1][5090/6832]	Time 0.126 (0.105)	Data 0.00127 (0.00097)	Tok/s 62793 (60119)	Loss/tok 3.2368 (3.2831)	Learning Rate [7.8125e-05]
2: TRAIN [1][5100/6832]	Time 0.075 (0.105)	Data 0.00093 (0.00094)	Tok/s 52922 (59684)	Loss/tok 3.0621 (3.2821)	Learning Rate [7.8125e-05]
1: TRAIN [1][5100/6832]	Time 0.075 (0.105)	Data 0.00091 (0.00094)	Tok/s 52788 (59316)	Loss/tok 3.1266 (3.2837)	Learning Rate [7.8125e-05]
0: TRAIN [1][5100/6832]	Time 0.075 (0.105)	Data 0.00093 (0.00094)	Tok/s 52785 (58871)	Loss/tok 2.9802 (3.2825)	Learning Rate [7.8125e-05]
3: TRAIN [1][5100/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00097)	Tok/s 53753 (60131)	Loss/tok 2.9999 (3.2831)	Learning Rate [7.8125e-05]
1: TRAIN [1][5110/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 59215 (59308)	Loss/tok 3.3799 (3.2838)	Learning Rate [7.8125e-05]
0: TRAIN [1][5110/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00094)	Tok/s 59039 (58863)	Loss/tok 3.3636 (3.2825)	Learning Rate [7.8125e-05]
2: TRAIN [1][5110/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00094)	Tok/s 59205 (59676)	Loss/tok 3.3304 (3.2820)	Learning Rate [7.8125e-05]
3: TRAIN [1][5110/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00097)	Tok/s 58919 (60123)	Loss/tok 3.4734 (3.2830)	Learning Rate [7.8125e-05]
1: TRAIN [1][5120/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00094)	Tok/s 51167 (59295)	Loss/tok 2.9844 (3.2837)	Learning Rate [7.8125e-05]
2: TRAIN [1][5120/6832]	Time 0.070 (0.105)	Data 0.00085 (0.00094)	Tok/s 51148 (59664)	Loss/tok 2.8908 (3.2817)	Learning Rate [7.8125e-05]
0: TRAIN [1][5120/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00094)	Tok/s 51035 (58849)	Loss/tok 3.1442 (3.2824)	Learning Rate [7.8125e-05]
3: TRAIN [1][5120/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00097)	Tok/s 51167 (60111)	Loss/tok 3.1516 (3.2829)	Learning Rate [7.8125e-05]
1: TRAIN [1][5130/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 77794 (59297)	Loss/tok 3.3364 (3.2836)	Learning Rate [7.8125e-05]
2: TRAIN [1][5130/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 78564 (59666)	Loss/tok 3.2994 (3.2816)	Learning Rate [7.8125e-05]
0: TRAIN [1][5130/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 77754 (58851)	Loss/tok 3.3500 (3.2823)	Learning Rate [7.8125e-05]
3: TRAIN [1][5130/6832]	Time 0.132 (0.105)	Data 0.00127 (0.00097)	Tok/s 78788 (60114)	Loss/tok 3.4091 (3.2828)	Learning Rate [7.8125e-05]
2: TRAIN [1][5140/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 62536 (59666)	Loss/tok 3.4819 (3.2816)	Learning Rate [7.8125e-05]
1: TRAIN [1][5140/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00094)	Tok/s 62492 (59297)	Loss/tok 3.3376 (3.2835)	Learning Rate [7.8125e-05]
3: TRAIN [1][5140/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00097)	Tok/s 62596 (60114)	Loss/tok 3.3895 (3.2828)	Learning Rate [7.8125e-05]
0: TRAIN [1][5140/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00094)	Tok/s 62489 (58852)	Loss/tok 3.3626 (3.2822)	Learning Rate [7.8125e-05]
2: TRAIN [1][5150/6832]	Time 0.093 (0.105)	Data 0.00086 (0.00094)	Tok/s 52565 (59672)	Loss/tok 3.0382 (3.2815)	Learning Rate [7.8125e-05]
3: TRAIN [1][5150/6832]	Time 0.093 (0.105)	Data 0.00096 (0.00097)	Tok/s 52565 (60120)	Loss/tok 3.1617 (3.2828)	Learning Rate [7.8125e-05]
1: TRAIN [1][5150/6832]	Time 0.092 (0.105)	Data 0.00099 (0.00094)	Tok/s 52144 (59304)	Loss/tok 3.2795 (3.2836)	Learning Rate [7.8125e-05]
0: TRAIN [1][5150/6832]	Time 0.093 (0.105)	Data 0.00097 (0.00094)	Tok/s 51173 (58858)	Loss/tok 3.0899 (3.2821)	Learning Rate [7.8125e-05]
0: TRAIN [1][5160/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00094)	Tok/s 72355 (58865)	Loss/tok 3.2234 (3.2821)	Learning Rate [7.8125e-05]
1: TRAIN [1][5160/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00094)	Tok/s 72905 (59311)	Loss/tok 3.4382 (3.2838)	Learning Rate [7.8125e-05]
2: TRAIN [1][5160/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 72846 (59679)	Loss/tok 3.3456 (3.2815)	Learning Rate [7.8125e-05]
3: TRAIN [1][5160/6832]	Time 0.132 (0.105)	Data 0.00110 (0.00097)	Tok/s 73275 (60127)	Loss/tok 3.3926 (3.2828)	Learning Rate [7.8125e-05]
2: TRAIN [1][5170/6832]	Time 0.104 (0.105)	Data 0.00087 (0.00094)	Tok/s 52607 (59672)	Loss/tok 3.2309 (3.2815)	Learning Rate [7.8125e-05]
1: TRAIN [1][5170/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00094)	Tok/s 51742 (59304)	Loss/tok 3.1055 (3.2837)	Learning Rate [7.8125e-05]
0: TRAIN [1][5170/6832]	Time 0.104 (0.105)	Data 0.00096 (0.00094)	Tok/s 51742 (58859)	Loss/tok 3.1644 (3.2821)	Learning Rate [7.8125e-05]
3: TRAIN [1][5170/6832]	Time 0.104 (0.105)	Data 0.00089 (0.00097)	Tok/s 52979 (60120)	Loss/tok 3.2274 (3.2827)	Learning Rate [7.8125e-05]
0: TRAIN [1][5180/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00094)	Tok/s 59412 (58860)	Loss/tok 3.3336 (3.2821)	Learning Rate [7.8125e-05]
1: TRAIN [1][5180/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00094)	Tok/s 59576 (59305)	Loss/tok 3.3368 (3.2837)	Learning Rate [7.8125e-05]
2: TRAIN [1][5180/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00094)	Tok/s 60436 (59673)	Loss/tok 3.3428 (3.2814)	Learning Rate [7.8125e-05]
3: TRAIN [1][5180/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00097)	Tok/s 60456 (60120)	Loss/tok 3.5883 (3.2827)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][5190/6832]	Time 0.080 (0.105)	Data 0.00113 (0.00094)	Tok/s 53114 (59667)	Loss/tok 3.0217 (3.2814)	Learning Rate [7.8125e-05]
0: TRAIN [1][5190/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00094)	Tok/s 52786 (58855)	Loss/tok 2.9066 (3.2820)	Learning Rate [7.8125e-05]
1: TRAIN [1][5190/6832]	Time 0.080 (0.105)	Data 0.00096 (0.00094)	Tok/s 52742 (59299)	Loss/tok 2.9917 (3.2837)	Learning Rate [7.8125e-05]
3: TRAIN [1][5190/6832]	Time 0.080 (0.105)	Data 0.00106 (0.00097)	Tok/s 54466 (60114)	Loss/tok 3.1071 (3.2827)	Learning Rate [7.8125e-05]
2: TRAIN [1][5200/6832]	Time 0.115 (0.105)	Data 0.00098 (0.00094)	Tok/s 52409 (59670)	Loss/tok 3.1932 (3.2814)	Learning Rate [7.8125e-05]
1: TRAIN [1][5200/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00094)	Tok/s 52398 (59302)	Loss/tok 3.1498 (3.2837)	Learning Rate [7.8125e-05]
3: TRAIN [1][5200/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00097)	Tok/s 52421 (60118)	Loss/tok 3.2716 (3.2828)	Learning Rate [7.8125e-05]
0: TRAIN [1][5200/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00094)	Tok/s 52401 (58859)	Loss/tok 3.3275 (3.2821)	Learning Rate [7.8125e-05]
1: TRAIN [1][5210/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 83669 (59316)	Loss/tok 3.0598 (3.2838)	Learning Rate [7.8125e-05]
0: TRAIN [1][5210/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 83434 (58872)	Loss/tok 3.4406 (3.2823)	Learning Rate [7.8125e-05]
2: TRAIN [1][5210/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 84257 (59683)	Loss/tok 3.3898 (3.2817)	Learning Rate [7.8125e-05]
3: TRAIN [1][5210/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00097)	Tok/s 84625 (60130)	Loss/tok 3.4677 (3.2830)	Learning Rate [7.8125e-05]
0: TRAIN [1][5220/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00094)	Tok/s 65429 (58875)	Loss/tok 3.4173 (3.2823)	Learning Rate [7.8125e-05]
2: TRAIN [1][5220/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 65954 (59687)	Loss/tok 3.5318 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5220/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 65970 (59320)	Loss/tok 3.1698 (3.2838)	Learning Rate [7.8125e-05]
3: TRAIN [1][5220/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00097)	Tok/s 65955 (60134)	Loss/tok 3.4092 (3.2829)	Learning Rate [7.8125e-05]
0: TRAIN [1][5230/6832]	Time 0.046 (0.105)	Data 0.00091 (0.00094)	Tok/s 42112 (58873)	Loss/tok 2.2705 (3.2822)	Learning Rate [7.8125e-05]
1: TRAIN [1][5230/6832]	Time 0.046 (0.105)	Data 0.00093 (0.00094)	Tok/s 44927 (59318)	Loss/tok 2.5811 (3.2838)	Learning Rate [7.8125e-05]
3: TRAIN [1][5230/6832]	Time 0.046 (0.105)	Data 0.00094 (0.00097)	Tok/s 48234 (60132)	Loss/tok 2.4074 (3.2828)	Learning Rate [7.8125e-05]
2: TRAIN [1][5230/6832]	Time 0.046 (0.105)	Data 0.00085 (0.00094)	Tok/s 47096 (59685)	Loss/tok 2.4953 (3.2816)	Learning Rate [7.8125e-05]
2: TRAIN [1][5240/6832]	Time 0.042 (0.105)	Data 0.00086 (0.00094)	Tok/s 39253 (59682)	Loss/tok 2.0715 (3.2815)	Learning Rate [7.8125e-05]
1: TRAIN [1][5240/6832]	Time 0.042 (0.105)	Data 0.00095 (0.00094)	Tok/s 33300 (59314)	Loss/tok 2.0380 (3.2836)	Learning Rate [7.8125e-05]
3: TRAIN [1][5240/6832]	Time 0.042 (0.105)	Data 0.00090 (0.00097)	Tok/s 43116 (60130)	Loss/tok 2.3045 (3.2826)	Learning Rate [7.8125e-05]
0: TRAIN [1][5240/6832]	Time 0.042 (0.105)	Data 0.00092 (0.00094)	Tok/s 21158 (58867)	Loss/tok 1.6945 (3.2821)	Learning Rate [7.8125e-05]
2: TRAIN [1][5250/6832]	Time 0.053 (0.105)	Data 0.00091 (0.00094)	Tok/s 45837 (59676)	Loss/tok 2.6909 (3.2814)	Learning Rate [7.8125e-05]
0: TRAIN [1][5250/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00094)	Tok/s 43435 (58862)	Loss/tok 2.4295 (3.2821)	Learning Rate [7.8125e-05]
1: TRAIN [1][5250/6832]	Time 0.053 (0.105)	Data 0.00094 (0.00094)	Tok/s 44485 (59308)	Loss/tok 2.5888 (3.2835)	Learning Rate [7.8125e-05]
3: TRAIN [1][5250/6832]	Time 0.053 (0.105)	Data 0.00124 (0.00097)	Tok/s 47480 (60124)	Loss/tok 2.4862 (3.2826)	Learning Rate [7.8125e-05]
3: TRAIN [1][5260/6832]	Time 0.089 (0.105)	Data 0.00099 (0.00097)	Tok/s 54788 (60125)	Loss/tok 3.0880 (3.2826)	Learning Rate [7.8125e-05]
1: TRAIN [1][5260/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00094)	Tok/s 53762 (59309)	Loss/tok 3.2286 (3.2835)	Learning Rate [7.8125e-05]
0: TRAIN [1][5260/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00094)	Tok/s 53324 (58864)	Loss/tok 3.1519 (3.2822)	Learning Rate [7.8125e-05]
2: TRAIN [1][5260/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00094)	Tok/s 54699 (59678)	Loss/tok 3.2554 (3.2814)	Learning Rate [7.8125e-05]
1: TRAIN [1][5270/6832]	Time 0.121 (0.105)	Data 0.00094 (0.00094)	Tok/s 58325 (59304)	Loss/tok 3.3609 (3.2836)	Learning Rate [7.8125e-05]
0: TRAIN [1][5270/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00094)	Tok/s 58344 (58858)	Loss/tok 3.3016 (3.2822)	Learning Rate [7.8125e-05]
2: TRAIN [1][5270/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00094)	Tok/s 58271 (59673)	Loss/tok 3.4608 (3.2813)	Learning Rate [7.8125e-05]
3: TRAIN [1][5270/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00097)	Tok/s 58274 (60120)	Loss/tok 3.2067 (3.2825)	Learning Rate [7.8125e-05]
0: TRAIN [1][5280/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 54666 (58849)	Loss/tok 3.3615 (3.2822)	Learning Rate [7.8125e-05]
1: TRAIN [1][5280/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 54758 (59294)	Loss/tok 3.2761 (3.2835)	Learning Rate [7.8125e-05]
2: TRAIN [1][5280/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00094)	Tok/s 55725 (59663)	Loss/tok 3.2604 (3.2811)	Learning Rate [7.8125e-05]
3: TRAIN [1][5280/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00097)	Tok/s 55747 (60110)	Loss/tok 3.1874 (3.2824)	Learning Rate [7.8125e-05]
2: TRAIN [1][5290/6832]	Time 0.121 (0.105)	Data 0.00101 (0.00094)	Tok/s 52679 (59661)	Loss/tok 3.2195 (3.2810)	Learning Rate [7.8125e-05]
1: TRAIN [1][5290/6832]	Time 0.122 (0.105)	Data 0.00102 (0.00094)	Tok/s 52636 (59292)	Loss/tok 3.4146 (3.2836)	Learning Rate [7.8125e-05]
0: TRAIN [1][5290/6832]	Time 0.122 (0.105)	Data 0.00102 (0.00094)	Tok/s 52645 (58848)	Loss/tok 3.5397 (3.2823)	Learning Rate [7.8125e-05]
3: TRAIN [1][5290/6832]	Time 0.122 (0.105)	Data 0.00103 (0.00097)	Tok/s 52649 (60108)	Loss/tok 3.1330 (3.2824)	Learning Rate [7.8125e-05]
0: TRAIN [1][5300/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00094)	Tok/s 57098 (58828)	Loss/tok 3.4597 (3.2822)	Learning Rate [7.8125e-05]
1: TRAIN [1][5300/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00094)	Tok/s 57078 (59277)	Loss/tok 3.3055 (3.2834)	Learning Rate [7.8125e-05]
2: TRAIN [1][5300/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00094)	Tok/s 57567 (59648)	Loss/tok 3.2505 (3.2809)	Learning Rate [7.8125e-05]
3: TRAIN [1][5300/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00097)	Tok/s 58066 (60097)	Loss/tok 3.2648 (3.2822)	Learning Rate [7.8125e-05]
2: TRAIN [1][5310/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00094)	Tok/s 52753 (59653)	Loss/tok 3.2364 (3.2810)	Learning Rate [7.8125e-05]
1: TRAIN [1][5310/6832]	Time 0.087 (0.105)	Data 0.00093 (0.00094)	Tok/s 52771 (59283)	Loss/tok 3.3000 (3.2836)	Learning Rate [7.8125e-05]
0: TRAIN [1][5310/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00094)	Tok/s 52753 (58834)	Loss/tok 3.2989 (3.2823)	Learning Rate [7.8125e-05]
3: TRAIN [1][5310/6832]	Time 0.087 (0.105)	Data 0.00092 (0.00097)	Tok/s 52750 (60102)	Loss/tok 3.2201 (3.2824)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][5320/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00094)	Tok/s 53594 (59652)	Loss/tok 3.2106 (3.2810)	Learning Rate [7.8125e-05]
0: TRAIN [1][5320/6832]	Time 0.100 (0.105)	Data 0.00087 (0.00094)	Tok/s 52679 (58834)	Loss/tok 3.1014 (3.2822)	Learning Rate [7.8125e-05]
1: TRAIN [1][5320/6832]	Time 0.100 (0.105)	Data 0.00094 (0.00094)	Tok/s 52662 (59282)	Loss/tok 3.2694 (3.2835)	Learning Rate [7.8125e-05]
3: TRAIN [1][5320/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00097)	Tok/s 53946 (60101)	Loss/tok 3.1644 (3.2823)	Learning Rate [7.8125e-05]
1: TRAIN [1][5330/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00094)	Tok/s 56974 (59280)	Loss/tok 3.3396 (3.2835)	Learning Rate [7.8125e-05]
0: TRAIN [1][5330/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00094)	Tok/s 56253 (58832)	Loss/tok 3.2037 (3.2822)	Learning Rate [7.8125e-05]
2: TRAIN [1][5330/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00094)	Tok/s 57252 (59650)	Loss/tok 3.3609 (3.2810)	Learning Rate [7.8125e-05]
3: TRAIN [1][5330/6832]	Time 0.118 (0.105)	Data 0.00100 (0.00097)	Tok/s 57266 (60099)	Loss/tok 3.3029 (3.2822)	Learning Rate [7.8125e-05]
2: TRAIN [1][5340/6832]	Time 0.104 (0.105)	Data 0.00087 (0.00094)	Tok/s 51477 (59645)	Loss/tok 3.2779 (3.2809)	Learning Rate [7.8125e-05]
3: TRAIN [1][5340/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00097)	Tok/s 51474 (60093)	Loss/tok 3.2149 (3.2822)	Learning Rate [7.8125e-05]
1: TRAIN [1][5340/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00094)	Tok/s 51457 (59275)	Loss/tok 3.3277 (3.2834)	Learning Rate [7.8125e-05]
0: TRAIN [1][5340/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00094)	Tok/s 50635 (58827)	Loss/tok 3.0659 (3.2822)	Learning Rate [7.8125e-05]
2: TRAIN [1][5350/6832]	Time 0.056 (0.105)	Data 0.00086 (0.00094)	Tok/s 50603 (59644)	Loss/tok 2.5775 (3.2810)	Learning Rate [7.8125e-05]
1: TRAIN [1][5350/6832]	Time 0.056 (0.105)	Data 0.00090 (0.00094)	Tok/s 50587 (59274)	Loss/tok 2.7148 (3.2833)	Learning Rate [7.8125e-05]
0: TRAIN [1][5350/6832]	Time 0.056 (0.105)	Data 0.00090 (0.00094)	Tok/s 49386 (58827)	Loss/tok 2.8185 (3.2821)	Learning Rate [7.8125e-05]
3: TRAIN [1][5350/6832]	Time 0.056 (0.105)	Data 0.00093 (0.00097)	Tok/s 50859 (60092)	Loss/tok 2.9000 (3.2821)	Learning Rate [7.8125e-05]
2: TRAIN [1][5360/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00094)	Tok/s 52519 (59643)	Loss/tok 3.1882 (3.2811)	Learning Rate [7.8125e-05]
1: TRAIN [1][5360/6832]	Time 0.093 (0.105)	Data 0.00092 (0.00094)	Tok/s 52500 (59273)	Loss/tok 3.0795 (3.2832)	Learning Rate [7.8125e-05]
3: TRAIN [1][5360/6832]	Time 0.093 (0.105)	Data 0.00092 (0.00097)	Tok/s 52937 (60090)	Loss/tok 3.2203 (3.2821)	Learning Rate [7.8125e-05]
0: TRAIN [1][5360/6832]	Time 0.093 (0.105)	Data 0.00092 (0.00094)	Tok/s 52495 (58825)	Loss/tok 3.3113 (3.2820)	Learning Rate [7.8125e-05]
2: TRAIN [1][5370/6832]	Time 0.065 (0.105)	Data 0.00086 (0.00094)	Tok/s 51570 (59643)	Loss/tok 2.9931 (3.2811)	Learning Rate [7.8125e-05]
1: TRAIN [1][5370/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00094)	Tok/s 51552 (59273)	Loss/tok 3.0240 (3.2832)	Learning Rate [7.8125e-05]
3: TRAIN [1][5370/6832]	Time 0.065 (0.105)	Data 0.00091 (0.00097)	Tok/s 52693 (60090)	Loss/tok 2.9195 (3.2820)	Learning Rate [7.8125e-05]
0: TRAIN [1][5370/6832]	Time 0.065 (0.105)	Data 0.00089 (0.00094)	Tok/s 51516 (58826)	Loss/tok 3.0519 (3.2820)	Learning Rate [7.8125e-05]
2: TRAIN [1][5380/6832]	Time 0.049 (0.105)	Data 0.00087 (0.00094)	Tok/s 43804 (59641)	Loss/tok 2.3644 (3.2809)	Learning Rate [7.8125e-05]
3: TRAIN [1][5380/6832]	Time 0.049 (0.105)	Data 0.00093 (0.00097)	Tok/s 45354 (60090)	Loss/tok 2.5493 (3.2820)	Learning Rate [7.8125e-05]
0: TRAIN [1][5380/6832]	Time 0.049 (0.105)	Data 0.00090 (0.00094)	Tok/s 38948 (58824)	Loss/tok 2.3016 (3.2820)	Learning Rate [7.8125e-05]
1: TRAIN [1][5380/6832]	Time 0.049 (0.105)	Data 0.00091 (0.00094)	Tok/s 41244 (59272)	Loss/tok 2.4248 (3.2832)	Learning Rate [7.8125e-05]
1: TRAIN [1][5390/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00094)	Tok/s 66102 (59267)	Loss/tok 3.3525 (3.2831)	Learning Rate [7.8125e-05]
0: TRAIN [1][5390/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 65212 (58820)	Loss/tok 3.1732 (3.2819)	Learning Rate [7.8125e-05]
2: TRAIN [1][5390/6832]	Time 0.126 (0.105)	Data 0.00104 (0.00094)	Tok/s 66245 (59636)	Loss/tok 3.4641 (3.2810)	Learning Rate [7.8125e-05]
3: TRAIN [1][5390/6832]	Time 0.126 (0.105)	Data 0.00103 (0.00097)	Tok/s 66246 (60084)	Loss/tok 3.3169 (3.2819)	Learning Rate [7.8125e-05]
2: TRAIN [1][5400/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00094)	Tok/s 64685 (59626)	Loss/tok 3.2161 (3.2808)	Learning Rate [7.8125e-05]
0: TRAIN [1][5400/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 64089 (58808)	Loss/tok 3.3603 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5400/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 64078 (59256)	Loss/tok 3.4508 (3.2830)	Learning Rate [7.8125e-05]
3: TRAIN [1][5400/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00097)	Tok/s 65076 (60073)	Loss/tok 3.4670 (3.2818)	Learning Rate [7.8125e-05]
2: TRAIN [1][5410/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 80262 (59628)	Loss/tok 3.2134 (3.2807)	Learning Rate [7.8125e-05]
0: TRAIN [1][5410/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 79601 (58811)	Loss/tok 3.3237 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5410/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 79719 (59258)	Loss/tok 3.2344 (3.2831)	Learning Rate [7.8125e-05]
3: TRAIN [1][5410/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00097)	Tok/s 80753 (60075)	Loss/tok 3.3053 (3.2818)	Learning Rate [7.8125e-05]
2: TRAIN [1][5420/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00094)	Tok/s 51787 (59627)	Loss/tok 3.1648 (3.2806)	Learning Rate [7.8125e-05]
1: TRAIN [1][5420/6832]	Time 0.089 (0.105)	Data 0.00091 (0.00094)	Tok/s 51738 (59258)	Loss/tok 3.0502 (3.2830)	Learning Rate [7.8125e-05]
0: TRAIN [1][5420/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00094)	Tok/s 51754 (58811)	Loss/tok 3.1675 (3.2817)	Learning Rate [7.8125e-05]
3: TRAIN [1][5420/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00097)	Tok/s 51786 (60075)	Loss/tok 3.0893 (3.2818)	Learning Rate [7.8125e-05]
2: TRAIN [1][5430/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 63925 (59627)	Loss/tok 3.3761 (3.2806)	Learning Rate [7.8125e-05]
1: TRAIN [1][5430/6832]	Time 0.130 (0.105)	Data 0.00112 (0.00094)	Tok/s 63918 (59258)	Loss/tok 3.3512 (3.2829)	Learning Rate [7.8125e-05]
0: TRAIN [1][5430/6832]	Time 0.130 (0.105)	Data 0.00108 (0.00094)	Tok/s 63360 (58811)	Loss/tok 3.3079 (3.2815)	Learning Rate [7.8125e-05]
3: TRAIN [1][5430/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00097)	Tok/s 63697 (60075)	Loss/tok 3.3706 (3.2817)	Learning Rate [7.8125e-05]
2: TRAIN [1][5440/6832]	Time 0.103 (0.105)	Data 0.00093 (0.00094)	Tok/s 52425 (59628)	Loss/tok 3.1460 (3.2805)	Learning Rate [7.8125e-05]
1: TRAIN [1][5440/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00094)	Tok/s 52359 (59258)	Loss/tok 3.3051 (3.2830)	Learning Rate [7.8125e-05]
3: TRAIN [1][5440/6832]	Time 0.103 (0.105)	Data 0.00096 (0.00097)	Tok/s 53074 (60075)	Loss/tok 3.1931 (3.2817)	Learning Rate [7.8125e-05]
0: TRAIN [1][5440/6832]	Time 0.103 (0.105)	Data 0.00092 (0.00094)	Tok/s 52349 (58812)	Loss/tok 3.1454 (3.2816)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [1][5450/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 65231 (59620)	Loss/tok 3.2402 (3.2805)	Learning Rate [7.8125e-05]
3: TRAIN [1][5450/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00097)	Tok/s 65909 (60067)	Loss/tok 3.3795 (3.2816)	Learning Rate [7.8125e-05]
1: TRAIN [1][5450/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00094)	Tok/s 65228 (59251)	Loss/tok 3.4890 (3.2830)	Learning Rate [7.8125e-05]
0: TRAIN [1][5450/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00094)	Tok/s 65235 (58805)	Loss/tok 3.3746 (3.2816)	Learning Rate [7.8125e-05]
0: TRAIN [1][5460/6832]	Time 0.079 (0.105)	Data 0.00089 (0.00094)	Tok/s 51981 (58803)	Loss/tok 2.9362 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5460/6832]	Time 0.079 (0.105)	Data 0.00092 (0.00094)	Tok/s 51955 (59248)	Loss/tok 2.9651 (3.2830)	Learning Rate [7.8125e-05]
2: TRAIN [1][5460/6832]	Time 0.079 (0.105)	Data 0.00098 (0.00094)	Tok/s 51970 (59617)	Loss/tok 3.1372 (3.2805)	Learning Rate [7.8125e-05]
3: TRAIN [1][5460/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00097)	Tok/s 51845 (60063)	Loss/tok 3.0545 (3.2818)	Learning Rate [7.8125e-05]
2: TRAIN [1][5470/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00094)	Tok/s 68346 (59616)	Loss/tok 3.3683 (3.2805)	Learning Rate [7.8125e-05]
3: TRAIN [1][5470/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00097)	Tok/s 68366 (60062)	Loss/tok 3.4402 (3.2820)	Learning Rate [7.8125e-05]
1: TRAIN [1][5470/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 68363 (59247)	Loss/tok 3.3558 (3.2829)	Learning Rate [7.8125e-05]
0: TRAIN [1][5470/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00094)	Tok/s 67989 (58803)	Loss/tok 3.3747 (3.2817)	Learning Rate [7.8125e-05]
0: TRAIN [1][5480/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00094)	Tok/s 58258 (58801)	Loss/tok 3.4012 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5480/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00094)	Tok/s 58235 (59245)	Loss/tok 3.4494 (3.2830)	Learning Rate [7.8125e-05]
2: TRAIN [1][5480/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 58203 (59613)	Loss/tok 3.3253 (3.2804)	Learning Rate [7.8125e-05]
3: TRAIN [1][5480/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00097)	Tok/s 59039 (60060)	Loss/tok 3.5035 (3.2820)	Learning Rate [7.8125e-05]
2: TRAIN [1][5490/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00094)	Tok/s 52248 (59614)	Loss/tok 3.3018 (3.2804)	Learning Rate [7.8125e-05]
1: TRAIN [1][5490/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00094)	Tok/s 52256 (59246)	Loss/tok 3.1456 (3.2829)	Learning Rate [7.8125e-05]
3: TRAIN [1][5490/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00097)	Tok/s 52243 (60061)	Loss/tok 3.2003 (3.2819)	Learning Rate [7.8125e-05]
0: TRAIN [1][5490/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00094)	Tok/s 51309 (58802)	Loss/tok 3.1767 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5500/6832]	Time 0.068 (0.105)	Data 0.00091 (0.00094)	Tok/s 52494 (59243)	Loss/tok 3.1939 (3.2829)	Learning Rate [7.8125e-05]
0: TRAIN [1][5500/6832]	Time 0.068 (0.105)	Data 0.00088 (0.00094)	Tok/s 52497 (58800)	Loss/tok 2.9815 (3.2817)	Learning Rate [7.8125e-05]
2: TRAIN [1][5500/6832]	Time 0.068 (0.105)	Data 0.00086 (0.00094)	Tok/s 52439 (59611)	Loss/tok 3.1243 (3.2804)	Learning Rate [7.8125e-05]
3: TRAIN [1][5500/6832]	Time 0.068 (0.105)	Data 0.00092 (0.00097)	Tok/s 52550 (60058)	Loss/tok 2.8840 (3.2820)	Learning Rate [7.8125e-05]
0: TRAIN [1][5510/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 84581 (58809)	Loss/tok 3.2401 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5510/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 85297 (59252)	Loss/tok 3.2081 (3.2828)	Learning Rate [7.8125e-05]
2: TRAIN [1][5510/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 85976 (59620)	Loss/tok 3.2057 (3.2803)	Learning Rate [7.8125e-05]
3: TRAIN [1][5510/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00097)	Tok/s 86415 (60066)	Loss/tok 3.2269 (3.2818)	Learning Rate [7.8125e-05]
2: TRAIN [1][5520/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 64231 (59625)	Loss/tok 3.2118 (3.2803)	Learning Rate [7.8125e-05]
3: TRAIN [1][5520/6832]	Time 0.119 (0.105)	Data 0.00083 (0.00097)	Tok/s 63677 (60072)	Loss/tok 3.4586 (3.2818)	Learning Rate [7.8125e-05]
0: TRAIN [1][5520/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00094)	Tok/s 62560 (58814)	Loss/tok 3.2868 (3.2818)	Learning Rate [7.8125e-05]
1: TRAIN [1][5520/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00094)	Tok/s 63604 (59257)	Loss/tok 3.3096 (3.2829)	Learning Rate [7.8125e-05]
2: TRAIN [1][5530/6832]	Time 0.116 (0.105)	Data 0.00093 (0.00094)	Tok/s 59732 (59632)	Loss/tok 3.3533 (3.2803)	Learning Rate [7.8125e-05]
3: TRAIN [1][5530/6832]	Time 0.116 (0.105)	Data 0.00100 (0.00097)	Tok/s 60483 (60079)	Loss/tok 3.1439 (3.2818)	Learning Rate [7.8125e-05]
1: TRAIN [1][5530/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00094)	Tok/s 59711 (59265)	Loss/tok 3.3383 (3.2830)	Learning Rate [7.8125e-05]
0: TRAIN [1][5530/6832]	Time 0.116 (0.105)	Data 0.00117 (0.00094)	Tok/s 59738 (58822)	Loss/tok 3.2712 (3.2817)	Learning Rate [7.8125e-05]
1: TRAIN [1][5540/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00094)	Tok/s 55703 (59263)	Loss/tok 3.3250 (3.2829)	Learning Rate [7.8125e-05]
2: TRAIN [1][5540/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00094)	Tok/s 56609 (59632)	Loss/tok 3.4178 (3.2802)	Learning Rate [7.8125e-05]
0: TRAIN [1][5540/6832]	Time 0.122 (0.105)	Data 0.00108 (0.00094)	Tok/s 55511 (58819)	Loss/tok 3.3365 (3.2816)	Learning Rate [7.8125e-05]
3: TRAIN [1][5540/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00097)	Tok/s 56617 (60079)	Loss/tok 3.3776 (3.2816)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
0: Gradient norm: inf
1: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][5550/6832]	Time 0.048 (0.105)	Data 0.00093 (0.00094)	Tok/s 42829 (59260)	Loss/tok 2.4507 (3.2828)	Learning Rate [7.8125e-05]
3: TRAIN [1][5550/6832]	Time 0.048 (0.105)	Data 0.00099 (0.00097)	Tok/s 46993 (60077)	Loss/tok 2.4896 (3.2816)	Learning Rate [7.8125e-05]
0: TRAIN [1][5550/6832]	Time 0.048 (0.105)	Data 0.00110 (0.00094)	Tok/s 40325 (58816)	Loss/tok 2.2743 (3.2814)	Learning Rate [7.8125e-05]
2: TRAIN [1][5550/6832]	Time 0.048 (0.105)	Data 0.00097 (0.00094)	Tok/s 45367 (59629)	Loss/tok 2.3697 (3.2799)	Learning Rate [7.8125e-05]
2: TRAIN [1][5560/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00094)	Tok/s 53382 (59622)	Loss/tok 3.3018 (3.2799)	Learning Rate [7.8125e-05]
0: TRAIN [1][5560/6832]	Time 0.077 (0.105)	Data 0.00100 (0.00094)	Tok/s 53392 (58809)	Loss/tok 3.1250 (3.2813)	Learning Rate [7.8125e-05]
3: TRAIN [1][5560/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00097)	Tok/s 53391 (60070)	Loss/tok 3.3001 (3.2815)	Learning Rate [7.8125e-05]
1: TRAIN [1][5560/6832]	Time 0.077 (0.105)	Data 0.00090 (0.00094)	Tok/s 53340 (59253)	Loss/tok 3.1682 (3.2827)	Learning Rate [7.8125e-05]
1: TRAIN [1][5570/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00094)	Tok/s 81849 (59255)	Loss/tok 3.3612 (3.2825)	Learning Rate [7.8125e-05]
2: TRAIN [1][5570/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00094)	Tok/s 82041 (59625)	Loss/tok 3.0897 (3.2797)	Learning Rate [7.8125e-05]
3: TRAIN [1][5570/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00097)	Tok/s 82810 (60073)	Loss/tok 3.2403 (3.2813)	Learning Rate [7.8125e-05]
0: TRAIN [1][5570/6832]	Time 0.131 (0.105)	Data 0.00108 (0.00094)	Tok/s 81026 (58812)	Loss/tok 3.2558 (3.2811)	Learning Rate [7.8125e-05]
2: TRAIN [1][5580/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 81063 (59620)	Loss/tok 3.4756 (3.2797)	Learning Rate [7.8125e-05]
1: TRAIN [1][5580/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 80138 (59250)	Loss/tok 3.1311 (3.2823)	Learning Rate [7.8125e-05]
3: TRAIN [1][5580/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00097)	Tok/s 81127 (60069)	Loss/tok 3.1337 (3.2812)	Learning Rate [7.8125e-05]
0: TRAIN [1][5580/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00094)	Tok/s 80162 (58805)	Loss/tok 3.2999 (3.2811)	Learning Rate [7.8125e-05]
2: TRAIN [1][5590/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 61741 (59618)	Loss/tok 3.2217 (3.2795)	Learning Rate [7.8125e-05]
1: TRAIN [1][5590/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 61693 (59248)	Loss/tok 3.4418 (3.2823)	Learning Rate [7.8125e-05]
3: TRAIN [1][5590/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00097)	Tok/s 62291 (60067)	Loss/tok 3.4389 (3.2811)	Learning Rate [7.8125e-05]
0: TRAIN [1][5590/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00094)	Tok/s 61709 (58804)	Loss/tok 3.4558 (3.2811)	Learning Rate [7.8125e-05]
2: TRAIN [1][5600/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00094)	Tok/s 49867 (59613)	Loss/tok 3.2039 (3.2795)	Learning Rate [7.8125e-05]
1: TRAIN [1][5600/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00094)	Tok/s 49872 (59243)	Loss/tok 3.3515 (3.2822)	Learning Rate [7.8125e-05]
3: TRAIN [1][5600/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00097)	Tok/s 49886 (60061)	Loss/tok 3.3376 (3.2810)	Learning Rate [7.8125e-05]
0: TRAIN [1][5600/6832]	Time 0.116 (0.105)	Data 0.00098 (0.00094)	Tok/s 49851 (58799)	Loss/tok 3.3118 (3.2811)	Learning Rate [7.8125e-05]
2: TRAIN [1][5610/6832]	Time 0.083 (0.105)	Data 0.00086 (0.00094)	Tok/s 53683 (59606)	Loss/tok 3.2109 (3.2794)	Learning Rate [7.8125e-05]
1: TRAIN [1][5610/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00094)	Tok/s 53674 (59236)	Loss/tok 3.2742 (3.2822)	Learning Rate [7.8125e-05]
0: TRAIN [1][5610/6832]	Time 0.083 (0.105)	Data 0.00097 (0.00094)	Tok/s 52547 (58792)	Loss/tok 3.0224 (3.2810)	Learning Rate [7.8125e-05]
3: TRAIN [1][5610/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00097)	Tok/s 53666 (60054)	Loss/tok 2.9439 (3.2809)	Learning Rate [7.8125e-05]
2: TRAIN [1][5620/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00094)	Tok/s 51787 (59604)	Loss/tok 2.9352 (3.2793)	Learning Rate [7.8125e-05]
1: TRAIN [1][5620/6832]	Time 0.072 (0.105)	Data 0.00086 (0.00094)	Tok/s 51762 (59234)	Loss/tok 2.9442 (3.2820)	Learning Rate [7.8125e-05]
3: TRAIN [1][5620/6832]	Time 0.072 (0.105)	Data 0.00086 (0.00097)	Tok/s 51784 (60053)	Loss/tok 3.1031 (3.2808)	Learning Rate [7.8125e-05]
0: TRAIN [1][5620/6832]	Time 0.072 (0.105)	Data 0.00097 (0.00094)	Tok/s 50562 (58790)	Loss/tok 2.8962 (3.2809)	Learning Rate [7.8125e-05]
2: TRAIN [1][5630/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 81693 (59607)	Loss/tok 3.2094 (3.2792)	Learning Rate [7.8125e-05]
3: TRAIN [1][5630/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00097)	Tok/s 82573 (60056)	Loss/tok 3.2916 (3.2809)	Learning Rate [7.8125e-05]
1: TRAIN [1][5630/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 81595 (59238)	Loss/tok 3.2871 (3.2821)	Learning Rate [7.8125e-05]
0: TRAIN [1][5630/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 80756 (58794)	Loss/tok 3.2563 (3.2809)	Learning Rate [7.8125e-05]
2: TRAIN [1][5640/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00094)	Tok/s 57121 (59600)	Loss/tok 3.3688 (3.2792)	Learning Rate [7.8125e-05]
1: TRAIN [1][5640/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00094)	Tok/s 56612 (59231)	Loss/tok 3.4280 (3.2820)	Learning Rate [7.8125e-05]
3: TRAIN [1][5640/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00097)	Tok/s 57711 (60048)	Loss/tok 3.4257 (3.2809)	Learning Rate [7.8125e-05]
0: TRAIN [1][5640/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00094)	Tok/s 56615 (58787)	Loss/tok 3.3396 (3.2808)	Learning Rate [7.8125e-05]
1: TRAIN [1][5650/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 62048 (59237)	Loss/tok 3.4354 (3.2821)	Learning Rate [7.8125e-05]
0: TRAIN [1][5650/6832]	Time 0.126 (0.105)	Data 0.00097 (0.00094)	Tok/s 62038 (58793)	Loss/tok 3.4784 (3.2810)	Learning Rate [7.8125e-05]
2: TRAIN [1][5650/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00094)	Tok/s 62836 (59606)	Loss/tok 3.2643 (3.2793)	Learning Rate [7.8125e-05]
3: TRAIN [1][5650/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00097)	Tok/s 62999 (60053)	Loss/tok 3.1852 (3.2810)	Learning Rate [7.8125e-05]
2: TRAIN [1][5660/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 83503 (59610)	Loss/tok 3.2245 (3.2793)	Learning Rate [7.8125e-05]
3: TRAIN [1][5660/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00097)	Tok/s 84994 (60058)	Loss/tok 3.2808 (3.2809)	Learning Rate [7.8125e-05]
1: TRAIN [1][5660/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 82191 (59241)	Loss/tok 3.4207 (3.2822)	Learning Rate [7.8125e-05]
0: TRAIN [1][5660/6832]	Time 0.131 (0.105)	Data 0.00115 (0.00094)	Tok/s 81263 (58798)	Loss/tok 3.1830 (3.2809)	Learning Rate [7.8125e-05]
1: TRAIN [1][5670/6832]	Time 0.057 (0.105)	Data 0.00091 (0.00094)	Tok/s 51281 (59235)	Loss/tok 2.7637 (3.2820)	Learning Rate [7.8125e-05]
2: TRAIN [1][5670/6832]	Time 0.057 (0.105)	Data 0.00094 (0.00094)	Tok/s 51751 (59605)	Loss/tok 2.9463 (3.2791)	Learning Rate [7.8125e-05]
0: TRAIN [1][5670/6832]	Time 0.057 (0.105)	Data 0.00091 (0.00094)	Tok/s 51316 (58792)	Loss/tok 2.6455 (3.2807)	Learning Rate [7.8125e-05]
3: TRAIN [1][5670/6832]	Time 0.057 (0.105)	Data 0.00092 (0.00097)	Tok/s 53537 (60053)	Loss/tok 2.9268 (3.2807)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [1][5680/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00094)	Tok/s 52750 (59230)	Loss/tok 3.1723 (3.2818)	Learning Rate [7.8125e-05]
2: TRAIN [1][5680/6832]	Time 0.095 (0.105)	Data 0.00092 (0.00094)	Tok/s 52819 (59599)	Loss/tok 3.1958 (3.2790)	Learning Rate [7.8125e-05]
3: TRAIN [1][5680/6832]	Time 0.095 (0.105)	Data 0.00089 (0.00097)	Tok/s 52802 (60048)	Loss/tok 3.1836 (3.2806)	Learning Rate [7.8125e-05]
0: TRAIN [1][5680/6832]	Time 0.095 (0.105)	Data 0.00097 (0.00094)	Tok/s 52725 (58786)	Loss/tok 3.1476 (3.2806)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
2: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][5690/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00094)	Tok/s 61330 (59228)	Loss/tok 3.4340 (3.2817)	Learning Rate [7.8125e-05]
0: TRAIN [1][5690/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00094)	Tok/s 61365 (58784)	Loss/tok 3.3473 (3.2805)	Learning Rate [7.8125e-05]
3: TRAIN [1][5690/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00097)	Tok/s 62403 (60047)	Loss/tok 3.3852 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][5690/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 61576 (59598)	Loss/tok 3.1682 (3.2788)	Learning Rate [7.8125e-05]
1: TRAIN [1][5700/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 72667 (59238)	Loss/tok 3.4245 (3.2817)	Learning Rate [7.8125e-05]
2: TRAIN [1][5700/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 73060 (59608)	Loss/tok 3.2831 (3.2787)	Learning Rate [7.8125e-05]
3: TRAIN [1][5700/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00097)	Tok/s 73064 (60057)	Loss/tok 3.4016 (3.2806)	Learning Rate [7.8125e-05]
0: TRAIN [1][5700/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 72033 (58794)	Loss/tok 3.2812 (3.2805)	Learning Rate [7.8125e-05]
1: TRAIN [1][5710/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 57317 (59234)	Loss/tok 3.2636 (3.2816)	Learning Rate [7.8125e-05]
0: TRAIN [1][5710/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00094)	Tok/s 57348 (58790)	Loss/tok 3.2410 (3.2804)	Learning Rate [7.8125e-05]
2: TRAIN [1][5710/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00094)	Tok/s 57532 (59603)	Loss/tok 3.3893 (3.2787)	Learning Rate [7.8125e-05]
3: TRAIN [1][5710/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00097)	Tok/s 58395 (60053)	Loss/tok 3.3636 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][5720/6832]	Time 0.073 (0.105)	Data 0.00104 (0.00094)	Tok/s 54037 (59595)	Loss/tok 3.0150 (3.2785)	Learning Rate [7.8125e-05]
1: TRAIN [1][5720/6832]	Time 0.073 (0.105)	Data 0.00090 (0.00094)	Tok/s 52788 (59226)	Loss/tok 2.9178 (3.2815)	Learning Rate [7.8125e-05]
3: TRAIN [1][5720/6832]	Time 0.073 (0.105)	Data 0.00100 (0.00097)	Tok/s 54036 (60045)	Loss/tok 3.1162 (3.2805)	Learning Rate [7.8125e-05]
0: TRAIN [1][5720/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00094)	Tok/s 52337 (58782)	Loss/tok 2.9716 (3.2802)	Learning Rate [7.8125e-05]
2: TRAIN [1][5730/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00094)	Tok/s 51302 (59588)	Loss/tok 3.3282 (3.2785)	Learning Rate [7.8125e-05]
1: TRAIN [1][5730/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00094)	Tok/s 51275 (59218)	Loss/tok 3.2385 (3.2815)	Learning Rate [7.8125e-05]
3: TRAIN [1][5730/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00097)	Tok/s 52129 (60038)	Loss/tok 3.1270 (3.2804)	Learning Rate [7.8125e-05]
0: TRAIN [1][5730/6832]	Time 0.100 (0.105)	Data 0.00098 (0.00094)	Tok/s 51304 (58775)	Loss/tok 3.1365 (3.2801)	Learning Rate [7.8125e-05]
1: TRAIN [1][5740/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00094)	Tok/s 60590 (59208)	Loss/tok 3.3422 (3.2814)	Learning Rate [7.8125e-05]
0: TRAIN [1][5740/6832]	Time 0.120 (0.105)	Data 0.00096 (0.00094)	Tok/s 59968 (58763)	Loss/tok 3.4312 (3.2801)	Learning Rate [7.8125e-05]
2: TRAIN [1][5740/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00094)	Tok/s 61035 (59579)	Loss/tok 3.2661 (3.2784)	Learning Rate [7.8125e-05]
3: TRAIN [1][5740/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00097)	Tok/s 60974 (60029)	Loss/tok 3.3515 (3.2802)	Learning Rate [7.8125e-05]
1: TRAIN [1][5750/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 61386 (59218)	Loss/tok 3.4651 (3.2813)	Learning Rate [7.8125e-05]
2: TRAIN [1][5750/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00094)	Tok/s 61646 (59590)	Loss/tok 3.3205 (3.2783)	Learning Rate [7.8125e-05]
3: TRAIN [1][5750/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00097)	Tok/s 62400 (60041)	Loss/tok 3.3963 (3.2802)	Learning Rate [7.8125e-05]
0: TRAIN [1][5750/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 61393 (58771)	Loss/tok 3.5437 (3.2801)	Learning Rate [7.8125e-05]
1: TRAIN [1][5760/6832]	Time 0.044 (0.105)	Data 0.00090 (0.00094)	Tok/s 33297 (59222)	Loss/tok 2.0051 (3.2813)	Learning Rate [7.8125e-05]
2: TRAIN [1][5760/6832]	Time 0.044 (0.105)	Data 0.00093 (0.00094)	Tok/s 37605 (59595)	Loss/tok 2.0348 (3.2784)	Learning Rate [7.8125e-05]
0: TRAIN [1][5760/6832]	Time 0.044 (0.105)	Data 0.00095 (0.00094)	Tok/s 21996 (58772)	Loss/tok 1.7860 (3.2800)	Learning Rate [7.8125e-05]
3: TRAIN [1][5760/6832]	Time 0.044 (0.105)	Data 0.00089 (0.00097)	Tok/s 41277 (60048)	Loss/tok 2.3112 (3.2802)	Learning Rate [7.8125e-05]
1: TRAIN [1][5770/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00094)	Tok/s 52128 (59216)	Loss/tok 3.2733 (3.2812)	Learning Rate [7.8125e-05]
2: TRAIN [1][5770/6832]	Time 0.103 (0.105)	Data 0.00098 (0.00094)	Tok/s 52155 (59589)	Loss/tok 3.2150 (3.2784)	Learning Rate [7.8125e-05]
3: TRAIN [1][5770/6832]	Time 0.103 (0.105)	Data 0.00095 (0.00097)	Tok/s 52162 (60041)	Loss/tok 3.2872 (3.2801)	Learning Rate [7.8125e-05]
0: TRAIN [1][5770/6832]	Time 0.103 (0.105)	Data 0.00099 (0.00094)	Tok/s 51322 (58766)	Loss/tok 3.0623 (3.2800)	Learning Rate [7.8125e-05]
2: TRAIN [1][5780/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00094)	Tok/s 52324 (59579)	Loss/tok 3.1674 (3.2783)	Learning Rate [7.8125e-05]
1: TRAIN [1][5780/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00094)	Tok/s 52351 (59205)	Loss/tok 3.2250 (3.2811)	Learning Rate [7.8125e-05]
0: TRAIN [1][5780/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00094)	Tok/s 52349 (58753)	Loss/tok 3.3096 (3.2798)	Learning Rate [7.8125e-05]
3: TRAIN [1][5780/6832]	Time 0.105 (0.105)	Data 0.00133 (0.00097)	Tok/s 52460 (60031)	Loss/tok 3.1687 (3.2800)	Learning Rate [7.8125e-05]
2: TRAIN [1][5790/6832]	Time 0.099 (0.105)	Data 0.00101 (0.00094)	Tok/s 54048 (59580)	Loss/tok 3.1180 (3.2783)	Learning Rate [7.8125e-05]
1: TRAIN [1][5790/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00094)	Tok/s 53963 (59206)	Loss/tok 3.3680 (3.2810)	Learning Rate [7.8125e-05]
3: TRAIN [1][5790/6832]	Time 0.099 (0.105)	Data 0.00098 (0.00097)	Tok/s 54049 (60032)	Loss/tok 3.0816 (3.2799)	Learning Rate [7.8125e-05]
0: TRAIN [1][5790/6832]	Time 0.100 (0.105)	Data 0.00096 (0.00094)	Tok/s 53944 (58754)	Loss/tok 3.3948 (3.2798)	Learning Rate [7.8125e-05]
1: TRAIN [1][5800/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00094)	Tok/s 72297 (59209)	Loss/tok 3.2990 (3.2810)	Learning Rate [7.8125e-05]
2: TRAIN [1][5800/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 73245 (59583)	Loss/tok 3.3665 (3.2783)	Learning Rate [7.8125e-05]
3: TRAIN [1][5800/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00097)	Tok/s 73247 (60034)	Loss/tok 3.3056 (3.2799)	Learning Rate [7.8125e-05]
0: TRAIN [1][5800/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00094)	Tok/s 72243 (58757)	Loss/tok 3.2577 (3.2797)	Learning Rate [7.8125e-05]
1: TRAIN [1][5810/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 69408 (59203)	Loss/tok 3.3589 (3.2809)	Learning Rate [7.8125e-05]
0: TRAIN [1][5810/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 69460 (58751)	Loss/tok 3.4127 (3.2796)	Learning Rate [7.8125e-05]
2: TRAIN [1][5810/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 70230 (59577)	Loss/tok 3.4195 (3.2782)	Learning Rate [7.8125e-05]
3: TRAIN [1][5810/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00097)	Tok/s 70324 (60028)	Loss/tok 3.3230 (3.2797)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][5820/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00094)	Tok/s 68924 (59576)	Loss/tok 3.5125 (3.2782)	Learning Rate [7.8125e-05]
1: TRAIN [1][5820/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 68907 (59203)	Loss/tok 3.4011 (3.2809)	Learning Rate [7.8125e-05]
3: TRAIN [1][5820/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00097)	Tok/s 69836 (60028)	Loss/tok 3.3676 (3.2797)	Learning Rate [7.8125e-05]
0: TRAIN [1][5820/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00094)	Tok/s 68928 (58752)	Loss/tok 3.5084 (3.2797)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
3: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
1: TRAIN [1][5830/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00094)	Tok/s 60255 (59212)	Loss/tok 3.2481 (3.2809)	Learning Rate [7.8125e-05]
2: TRAIN [1][5830/6832]	Time 0.115 (0.105)	Data 0.00098 (0.00094)	Tok/s 60243 (59585)	Loss/tok 3.4275 (3.2783)	Learning Rate [7.8125e-05]
3: TRAIN [1][5830/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00097)	Tok/s 61314 (60037)	Loss/tok 3.3334 (3.2797)	Learning Rate [7.8125e-05]
0: TRAIN [1][5830/6832]	Time 0.115 (0.105)	Data 0.00139 (0.00094)	Tok/s 59972 (58761)	Loss/tok 3.1550 (3.2797)	Learning Rate [7.8125e-05]
1: TRAIN [1][5840/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00094)	Tok/s 51335 (59216)	Loss/tok 3.0568 (3.2809)	Learning Rate [7.8125e-05]
2: TRAIN [1][5840/6832]	Time 0.075 (0.105)	Data 0.00093 (0.00094)	Tok/s 51220 (59589)	Loss/tok 3.1705 (3.2783)	Learning Rate [7.8125e-05]
3: TRAIN [1][5840/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00097)	Tok/s 51234 (60041)	Loss/tok 3.1645 (3.2797)	Learning Rate [7.8125e-05]
0: TRAIN [1][5840/6832]	Time 0.075 (0.105)	Data 0.00102 (0.00094)	Tok/s 51299 (58765)	Loss/tok 3.2084 (3.2797)	Learning Rate [7.8125e-05]
2: TRAIN [1][5850/6832]	Time 0.120 (0.105)	Data 0.00096 (0.00094)	Tok/s 51360 (59579)	Loss/tok 3.3640 (3.2781)	Learning Rate [7.8125e-05]
1: TRAIN [1][5850/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00094)	Tok/s 50928 (59205)	Loss/tok 3.2101 (3.2807)	Learning Rate [7.8125e-05]
3: TRAIN [1][5850/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00097)	Tok/s 51055 (60032)	Loss/tok 3.2598 (3.2795)	Learning Rate [7.8125e-05]
0: TRAIN [1][5850/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00094)	Tok/s 50004 (58753)	Loss/tok 3.2362 (3.2796)	Learning Rate [7.8125e-05]
2: TRAIN [1][5860/6832]	Time 0.058 (0.105)	Data 0.00090 (0.00094)	Tok/s 50510 (59570)	Loss/tok 2.7584 (3.2781)	Learning Rate [7.8125e-05]
3: TRAIN [1][5860/6832]	Time 0.058 (0.105)	Data 0.00085 (0.00097)	Tok/s 50482 (60023)	Loss/tok 2.7549 (3.2794)	Learning Rate [7.8125e-05]
1: TRAIN [1][5860/6832]	Time 0.058 (0.105)	Data 0.00087 (0.00094)	Tok/s 50498 (59196)	Loss/tok 2.8087 (3.2807)	Learning Rate [7.8125e-05]
0: TRAIN [1][5860/6832]	Time 0.058 (0.105)	Data 0.00119 (0.00094)	Tok/s 49315 (58741)	Loss/tok 2.8299 (3.2795)	Learning Rate [7.8125e-05]
2: TRAIN [1][5870/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 75145 (59572)	Loss/tok 3.2537 (3.2780)	Learning Rate [7.8125e-05]
1: TRAIN [1][5870/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 74979 (59199)	Loss/tok 3.3320 (3.2807)	Learning Rate [7.8125e-05]
3: TRAIN [1][5870/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00097)	Tok/s 75389 (60026)	Loss/tok 3.2616 (3.2794)	Learning Rate [7.8125e-05]
0: TRAIN [1][5870/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00094)	Tok/s 74099 (58744)	Loss/tok 3.5039 (3.2796)	Learning Rate [7.8125e-05]
1: TRAIN [1][5880/6832]	Time 0.113 (0.105)	Data 0.00093 (0.00094)	Tok/s 53025 (59192)	Loss/tok 3.3431 (3.2807)	Learning Rate [7.8125e-05]
2: TRAIN [1][5880/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 53019 (59566)	Loss/tok 3.1557 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][5880/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00097)	Tok/s 53154 (60019)	Loss/tok 3.3163 (3.2794)	Learning Rate [7.8125e-05]
0: TRAIN [1][5880/6832]	Time 0.113 (0.105)	Data 0.00099 (0.00094)	Tok/s 53017 (58738)	Loss/tok 3.4148 (3.2795)	Learning Rate [7.8125e-05]
1: TRAIN [1][5890/6832]	Time 0.129 (0.105)	Data 0.00107 (0.00094)	Tok/s 75192 (59189)	Loss/tok 3.3962 (3.2806)	Learning Rate [7.8125e-05]
3: TRAIN [1][5890/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00097)	Tok/s 76021 (60016)	Loss/tok 3.3052 (3.2793)	Learning Rate [7.8125e-05]
0: TRAIN [1][5890/6832]	Time 0.130 (0.105)	Data 0.00121 (0.00094)	Tok/s 75107 (58735)	Loss/tok 3.3550 (3.2794)	Learning Rate [7.8125e-05]
2: TRAIN [1][5890/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00094)	Tok/s 75469 (59562)	Loss/tok 3.4711 (3.2778)	Learning Rate [7.8125e-05]
1: TRAIN [1][5900/6832]	Time 0.070 (0.105)	Data 0.00094 (0.00094)	Tok/s 52700 (59189)	Loss/tok 3.2234 (3.2807)	Learning Rate [7.8125e-05]
3: TRAIN [1][5900/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00097)	Tok/s 52679 (60016)	Loss/tok 3.0778 (3.2794)	Learning Rate [7.8125e-05]
2: TRAIN [1][5900/6832]	Time 0.070 (0.105)	Data 0.00095 (0.00094)	Tok/s 52683 (59562)	Loss/tok 3.0522 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [1][5900/6832]	Time 0.070 (0.105)	Data 0.00101 (0.00094)	Tok/s 52404 (58735)	Loss/tok 2.9326 (3.2794)	Learning Rate [7.8125e-05]
1: TRAIN [1][5910/6832]	Time 0.102 (0.105)	Data 0.00089 (0.00094)	Tok/s 54740 (59188)	Loss/tok 3.2909 (3.2808)	Learning Rate [7.8125e-05]
2: TRAIN [1][5910/6832]	Time 0.102 (0.105)	Data 0.00090 (0.00094)	Tok/s 55110 (59562)	Loss/tok 3.0777 (3.2780)	Learning Rate [7.8125e-05]
3: TRAIN [1][5910/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00097)	Tok/s 55093 (60014)	Loss/tok 3.0660 (3.2795)	Learning Rate [7.8125e-05]
0: TRAIN [1][5910/6832]	Time 0.102 (0.105)	Data 0.00106 (0.00094)	Tok/s 53844 (58735)	Loss/tok 3.3885 (3.2794)	Learning Rate [7.8125e-05]
1: TRAIN [1][5920/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 83686 (59185)	Loss/tok 3.3138 (3.2807)	Learning Rate [7.8125e-05]
3: TRAIN [1][5920/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00097)	Tok/s 84610 (60010)	Loss/tok 3.1066 (3.2793)	Learning Rate [7.8125e-05]
2: TRAIN [1][5920/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00094)	Tok/s 84112 (59558)	Loss/tok 3.2304 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [1][5920/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00094)	Tok/s 83167 (58732)	Loss/tok 3.3242 (3.2793)	Learning Rate [7.8125e-05]
1: TRAIN [1][5930/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 80618 (59189)	Loss/tok 3.2103 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][5930/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00094)	Tok/s 81141 (59562)	Loss/tok 3.2244 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][5930/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00097)	Tok/s 81657 (60014)	Loss/tok 3.3030 (3.2792)	Learning Rate [7.8125e-05]
0: TRAIN [1][5930/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00094)	Tok/s 80173 (58736)	Loss/tok 3.1024 (3.2793)	Learning Rate [7.8125e-05]
1: TRAIN [1][5940/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 62110 (59196)	Loss/tok 3.4524 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][5940/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 62257 (59569)	Loss/tok 3.5177 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][5940/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00097)	Tok/s 62992 (60021)	Loss/tok 3.3256 (3.2792)	Learning Rate [7.8125e-05]
0: TRAIN [1][5940/6832]	Time 0.128 (0.105)	Data 0.00100 (0.00094)	Tok/s 62032 (58743)	Loss/tok 3.2808 (3.2792)	Learning Rate [7.8125e-05]
1: TRAIN [1][5950/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 70296 (59200)	Loss/tok 3.5405 (3.2807)	Learning Rate [7.8125e-05]
2: TRAIN [1][5950/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 70262 (59573)	Loss/tok 3.3853 (3.2780)	Learning Rate [7.8125e-05]
3: TRAIN [1][5950/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00097)	Tok/s 71008 (60025)	Loss/tok 3.3403 (3.2792)	Learning Rate [7.8125e-05]
0: TRAIN [1][5950/6832]	Time 0.127 (0.105)	Data 0.00099 (0.00094)	Tok/s 70298 (58747)	Loss/tok 3.6459 (3.2793)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [1][5960/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 58617 (59202)	Loss/tok 3.2429 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][5960/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00094)	Tok/s 58638 (59575)	Loss/tok 3.5105 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][5960/6832]	Time 0.118 (0.105)	Data 0.00084 (0.00097)	Tok/s 59122 (60027)	Loss/tok 3.4495 (3.2792)	Learning Rate [7.8125e-05]
0: TRAIN [1][5960/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00094)	Tok/s 59274 (58750)	Loss/tok 3.3750 (3.2793)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][5970/6832]	Time 0.068 (0.105)	Data 0.00092 (0.00094)	Tok/s 52418 (59203)	Loss/tok 2.9690 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][5970/6832]	Time 0.068 (0.105)	Data 0.00089 (0.00094)	Tok/s 52427 (59577)	Loss/tok 2.8715 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][5970/6832]	Time 0.068 (0.105)	Data 0.00086 (0.00097)	Tok/s 53356 (60029)	Loss/tok 3.0147 (3.2791)	Learning Rate [7.8125e-05]
0: TRAIN [1][5970/6832]	Time 0.068 (0.105)	Data 0.00115 (0.00094)	Tok/s 52463 (58749)	Loss/tok 3.1072 (3.2792)	Learning Rate [7.8125e-05]
1: TRAIN [1][5980/6832]	Time 0.118 (0.105)	Data 0.00102 (0.00094)	Tok/s 53249 (59214)	Loss/tok 3.1714 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][5980/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00094)	Tok/s 53254 (59588)	Loss/tok 3.3658 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][5980/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00097)	Tok/s 53227 (60040)	Loss/tok 3.2468 (3.2792)	Learning Rate [7.8125e-05]
0: TRAIN [1][5980/6832]	Time 0.118 (0.105)	Data 0.00103 (0.00094)	Tok/s 53269 (58760)	Loss/tok 3.2290 (3.2792)	Learning Rate [7.8125e-05]
1: TRAIN [1][5990/6832]	Time 0.130 (0.105)	Data 0.00112 (0.00094)	Tok/s 67154 (59221)	Loss/tok 3.3664 (3.2807)	Learning Rate [7.8125e-05]
2: TRAIN [1][5990/6832]	Time 0.130 (0.105)	Data 0.00102 (0.00094)	Tok/s 67499 (59594)	Loss/tok 3.3234 (3.2780)	Learning Rate [7.8125e-05]
3: TRAIN [1][5990/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00097)	Tok/s 68090 (60045)	Loss/tok 3.3104 (3.2793)	Learning Rate [7.8125e-05]
0: TRAIN [1][5990/6832]	Time 0.130 (0.105)	Data 0.00111 (0.00094)	Tok/s 67182 (58767)	Loss/tok 3.2777 (3.2793)	Learning Rate [7.8125e-05]
1: TRAIN [1][6000/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00094)	Tok/s 47640 (59211)	Loss/tok 2.8631 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][6000/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00094)	Tok/s 47619 (59585)	Loss/tok 3.0785 (3.2778)	Learning Rate [7.8125e-05]
3: TRAIN [1][6000/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00097)	Tok/s 47602 (60036)	Loss/tok 2.9911 (3.2792)	Learning Rate [7.8125e-05]
0: TRAIN [1][6000/6832]	Time 0.075 (0.105)	Data 0.00098 (0.00094)	Tok/s 47613 (58757)	Loss/tok 2.9214 (3.2792)	Learning Rate [7.8125e-05]
2: TRAIN [1][6010/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00094)	Tok/s 78466 (59595)	Loss/tok 3.2793 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][6010/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00097)	Tok/s 78957 (60046)	Loss/tok 3.2844 (3.2792)	Learning Rate [7.8125e-05]
1: TRAIN [1][6010/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 78397 (59222)	Loss/tok 3.3400 (3.2807)	Learning Rate [7.8125e-05]
0: TRAIN [1][6010/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00094)	Tok/s 77423 (58768)	Loss/tok 3.2809 (3.2792)	Learning Rate [7.8125e-05]
1: TRAIN [1][6020/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00094)	Tok/s 57957 (59216)	Loss/tok 3.2713 (3.2806)	Learning Rate [7.8125e-05]
2: TRAIN [1][6020/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00094)	Tok/s 58887 (59589)	Loss/tok 3.2913 (3.2777)	Learning Rate [7.8125e-05]
3: TRAIN [1][6020/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00097)	Tok/s 58995 (60040)	Loss/tok 3.2753 (3.2790)	Learning Rate [7.8125e-05]
0: TRAIN [1][6020/6832]	Time 0.124 (0.105)	Data 0.00097 (0.00095)	Tok/s 57977 (58761)	Loss/tok 3.3657 (3.2790)	Learning Rate [7.8125e-05]
2: TRAIN [1][6030/6832]	Time 0.100 (0.105)	Data 0.00097 (0.00094)	Tok/s 53991 (59593)	Loss/tok 3.1193 (3.2778)	Learning Rate [7.8125e-05]
1: TRAIN [1][6030/6832]	Time 0.100 (0.105)	Data 0.00096 (0.00094)	Tok/s 53192 (59220)	Loss/tok 3.2517 (3.2806)	Learning Rate [7.8125e-05]
3: TRAIN [1][6030/6832]	Time 0.100 (0.105)	Data 0.00092 (0.00097)	Tok/s 54028 (60044)	Loss/tok 3.2135 (3.2791)	Learning Rate [7.8125e-05]
0: TRAIN [1][6030/6832]	Time 0.100 (0.105)	Data 0.00098 (0.00095)	Tok/s 52740 (58766)	Loss/tok 3.0352 (3.2791)	Learning Rate [7.8125e-05]
1: TRAIN [1][6040/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 61076 (59221)	Loss/tok 3.4355 (3.2804)	Learning Rate [7.8125e-05]
2: TRAIN [1][6040/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 61726 (59594)	Loss/tok 3.4604 (3.2776)	Learning Rate [7.8125e-05]
3: TRAIN [1][6040/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00097)	Tok/s 61731 (60045)	Loss/tok 3.4119 (3.2790)	Learning Rate [7.8125e-05]
0: TRAIN [1][6040/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00095)	Tok/s 60734 (58767)	Loss/tok 3.3412 (3.2790)	Learning Rate [7.8125e-05]
2: TRAIN [1][6050/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00094)	Tok/s 54669 (59587)	Loss/tok 3.3177 (3.2776)	Learning Rate [7.8125e-05]
3: TRAIN [1][6050/6832]	Time 0.103 (0.105)	Data 0.00087 (0.00097)	Tok/s 55196 (60038)	Loss/tok 3.3720 (3.2790)	Learning Rate [7.8125e-05]
1: TRAIN [1][6050/6832]	Time 0.103 (0.105)	Data 0.00087 (0.00094)	Tok/s 54616 (59214)	Loss/tok 3.2372 (3.2805)	Learning Rate [7.8125e-05]
0: TRAIN [1][6050/6832]	Time 0.105 (0.105)	Data 0.00097 (0.00095)	Tok/s 53492 (58760)	Loss/tok 3.2687 (3.2789)	Learning Rate [7.8125e-05]
1: TRAIN [1][6060/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00093)	Tok/s 59542 (59218)	Loss/tok 3.3831 (3.2805)	Learning Rate [7.8125e-05]
2: TRAIN [1][6060/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 59773 (59590)	Loss/tok 3.3199 (3.2776)	Learning Rate [7.8125e-05]
3: TRAIN [1][6060/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00097)	Tok/s 59794 (60041)	Loss/tok 3.2926 (3.2790)	Learning Rate [7.8125e-05]
0: TRAIN [1][6060/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00095)	Tok/s 58724 (58764)	Loss/tok 3.3842 (3.2789)	Learning Rate [7.8125e-05]
2: TRAIN [1][6070/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00094)	Tok/s 53452 (59583)	Loss/tok 3.2265 (3.2773)	Learning Rate [7.8125e-05]
1: TRAIN [1][6070/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00093)	Tok/s 53370 (59210)	Loss/tok 3.3139 (3.2804)	Learning Rate [7.8125e-05]
3: TRAIN [1][6070/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00097)	Tok/s 53739 (60033)	Loss/tok 3.2286 (3.2789)	Learning Rate [7.8125e-05]
0: TRAIN [1][6070/6832]	Time 0.101 (0.105)	Data 0.00100 (0.00095)	Tok/s 53379 (58755)	Loss/tok 3.3819 (3.2788)	Learning Rate [7.8125e-05]
1: TRAIN [1][6080/6832]	Time 0.054 (0.105)	Data 0.00095 (0.00093)	Tok/s 52117 (59203)	Loss/tok 2.6296 (3.2802)	Learning Rate [7.8125e-05]
2: TRAIN [1][6080/6832]	Time 0.054 (0.105)	Data 0.00092 (0.00094)	Tok/s 52042 (59575)	Loss/tok 2.6113 (3.2773)	Learning Rate [7.8125e-05]
3: TRAIN [1][6080/6832]	Time 0.054 (0.105)	Data 0.00095 (0.00097)	Tok/s 52089 (60026)	Loss/tok 2.7449 (3.2787)	Learning Rate [7.8125e-05]
0: TRAIN [1][6080/6832]	Time 0.054 (0.105)	Data 0.00100 (0.00095)	Tok/s 49747 (58748)	Loss/tok 2.8309 (3.2787)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][6090/6832]	Time 0.084 (0.105)	Data 0.00139 (0.00094)	Tok/s 53336 (59572)	Loss/tok 3.1027 (3.2773)	Learning Rate [7.8125e-05]
1: TRAIN [1][6090/6832]	Time 0.084 (0.105)	Data 0.00095 (0.00093)	Tok/s 53275 (59201)	Loss/tok 3.1028 (3.2802)	Learning Rate [7.8125e-05]
3: TRAIN [1][6090/6832]	Time 0.084 (0.105)	Data 0.00129 (0.00097)	Tok/s 53385 (60023)	Loss/tok 3.1371 (3.2787)	Learning Rate [7.8125e-05]
0: TRAIN [1][6090/6832]	Time 0.084 (0.105)	Data 0.00116 (0.00095)	Tok/s 53282 (58746)	Loss/tok 3.2203 (3.2787)	Learning Rate [7.8125e-05]
1: TRAIN [1][6100/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00093)	Tok/s 53980 (59198)	Loss/tok 3.2872 (3.2802)	Learning Rate [7.8125e-05]
2: TRAIN [1][6100/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00094)	Tok/s 53955 (59571)	Loss/tok 3.3169 (3.2772)	Learning Rate [7.8125e-05]
3: TRAIN [1][6100/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00097)	Tok/s 53945 (60022)	Loss/tok 3.3361 (3.2787)	Learning Rate [7.8125e-05]
0: TRAIN [1][6100/6832]	Time 0.119 (0.105)	Data 0.00103 (0.00095)	Tok/s 53600 (58742)	Loss/tok 3.2429 (3.2786)	Learning Rate [7.8125e-05]
1: TRAIN [1][6110/6832]	Time 0.099 (0.105)	Data 0.00093 (0.00093)	Tok/s 54210 (59197)	Loss/tok 3.1853 (3.2801)	Learning Rate [7.8125e-05]
2: TRAIN [1][6110/6832]	Time 0.099 (0.105)	Data 0.00116 (0.00094)	Tok/s 54214 (59569)	Loss/tok 3.2043 (3.2771)	Learning Rate [7.8125e-05]
3: TRAIN [1][6110/6832]	Time 0.099 (0.105)	Data 0.00107 (0.00097)	Tok/s 54232 (60020)	Loss/tok 3.2673 (3.2786)	Learning Rate [7.8125e-05]
0: TRAIN [1][6110/6832]	Time 0.099 (0.105)	Data 0.00098 (0.00095)	Tok/s 53410 (58741)	Loss/tok 3.1750 (3.2784)	Learning Rate [7.8125e-05]
1: TRAIN [1][6120/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00093)	Tok/s 60411 (59202)	Loss/tok 3.3724 (3.2802)	Learning Rate [7.8125e-05]
3: TRAIN [1][6120/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00097)	Tok/s 61515 (60025)	Loss/tok 3.4982 (3.2785)	Learning Rate [7.8125e-05]
0: TRAIN [1][6120/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00095)	Tok/s 60413 (58746)	Loss/tok 3.4734 (3.2784)	Learning Rate [7.8125e-05]
2: TRAIN [1][6120/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00094)	Tok/s 60926 (59574)	Loss/tok 3.2081 (3.2771)	Learning Rate [7.8125e-05]
1: TRAIN [1][6130/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 60437 (59195)	Loss/tok 3.4723 (3.2802)	Learning Rate [7.8125e-05]
2: TRAIN [1][6130/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00094)	Tok/s 61350 (59568)	Loss/tok 3.3600 (3.2770)	Learning Rate [7.8125e-05]
3: TRAIN [1][6130/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00097)	Tok/s 61397 (60019)	Loss/tok 3.4165 (3.2785)	Learning Rate [7.8125e-05]
0: TRAIN [1][6130/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00095)	Tok/s 60468 (58740)	Loss/tok 3.4513 (3.2784)	Learning Rate [7.8125e-05]
1: TRAIN [1][6140/6832]	Time 0.100 (0.105)	Data 0.00099 (0.00093)	Tok/s 53605 (59189)	Loss/tok 3.1686 (3.2800)	Learning Rate [7.8125e-05]
3: TRAIN [1][6140/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00097)	Tok/s 53930 (60013)	Loss/tok 3.1876 (3.2784)	Learning Rate [7.8125e-05]
2: TRAIN [1][6140/6832]	Time 0.100 (0.105)	Data 0.00097 (0.00094)	Tok/s 53602 (59562)	Loss/tok 3.1316 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [1][6140/6832]	Time 0.100 (0.105)	Data 0.00102 (0.00095)	Tok/s 53620 (58734)	Loss/tok 3.2629 (3.2784)	Learning Rate [7.8125e-05]
1: TRAIN [1][6150/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00093)	Tok/s 69903 (59189)	Loss/tok 3.3054 (3.2800)	Learning Rate [7.8125e-05]
0: TRAIN [1][6150/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00095)	Tok/s 69881 (58734)	Loss/tok 3.3751 (3.2783)	Learning Rate [7.8125e-05]
2: TRAIN [1][6150/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00094)	Tok/s 69833 (59561)	Loss/tok 3.3054 (3.2769)	Learning Rate [7.8125e-05]
3: TRAIN [1][6150/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00097)	Tok/s 70420 (60012)	Loss/tok 3.4783 (3.2785)	Learning Rate [7.8125e-05]
1: TRAIN [1][6160/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00093)	Tok/s 52361 (59178)	Loss/tok 3.1377 (3.2798)	Learning Rate [7.8125e-05]
2: TRAIN [1][6160/6832]	Time 0.090 (0.105)	Data 0.00088 (0.00094)	Tok/s 52352 (59550)	Loss/tok 3.2125 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [1][6160/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00095)	Tok/s 52341 (58723)	Loss/tok 3.2586 (3.2781)	Learning Rate [7.8125e-05]
3: TRAIN [1][6160/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00097)	Tok/s 52323 (60002)	Loss/tok 3.1451 (3.2783)	Learning Rate [7.8125e-05]
1: TRAIN [1][6170/6832]	Time 0.056 (0.105)	Data 0.00094 (0.00093)	Tok/s 50373 (59178)	Loss/tok 2.7288 (3.2798)	Learning Rate [7.8125e-05]
0: TRAIN [1][6170/6832]	Time 0.056 (0.105)	Data 0.00094 (0.00095)	Tok/s 50444 (58723)	Loss/tok 2.7084 (3.2781)	Learning Rate [7.8125e-05]
2: TRAIN [1][6170/6832]	Time 0.056 (0.105)	Data 0.00092 (0.00094)	Tok/s 50651 (59550)	Loss/tok 2.8012 (3.2767)	Learning Rate [7.8125e-05]
3: TRAIN [1][6170/6832]	Time 0.056 (0.105)	Data 0.00089 (0.00097)	Tok/s 52685 (60001)	Loss/tok 2.7615 (3.2783)	Learning Rate [7.8125e-05]
1: TRAIN [1][6180/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00093)	Tok/s 57241 (59166)	Loss/tok 3.2255 (3.2796)	Learning Rate [7.8125e-05]
0: TRAIN [1][6180/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00095)	Tok/s 56298 (58709)	Loss/tok 3.2435 (3.2779)	Learning Rate [7.8125e-05]
2: TRAIN [1][6180/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00094)	Tok/s 57246 (59539)	Loss/tok 3.2693 (3.2765)	Learning Rate [7.8125e-05]
3: TRAIN [1][6180/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00097)	Tok/s 57241 (59991)	Loss/tok 3.3347 (3.2782)	Learning Rate [7.8125e-05]
1: TRAIN [1][6190/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00093)	Tok/s 59706 (59167)	Loss/tok 3.5041 (3.2796)	Learning Rate [7.8125e-05]
2: TRAIN [1][6190/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 59655 (59539)	Loss/tok 3.2842 (3.2764)	Learning Rate [7.8125e-05]
3: TRAIN [1][6190/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00097)	Tok/s 59659 (59991)	Loss/tok 3.3811 (3.2782)	Learning Rate [7.8125e-05]
0: TRAIN [1][6190/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00095)	Tok/s 59693 (58710)	Loss/tok 3.4062 (3.2778)	Learning Rate [7.8125e-05]
2: TRAIN [1][6200/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00094)	Tok/s 61829 (59547)	Loss/tok 3.2965 (3.2764)	Learning Rate [7.8125e-05]
1: TRAIN [1][6200/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00093)	Tok/s 61767 (59174)	Loss/tok 3.2844 (3.2795)	Learning Rate [7.8125e-05]
3: TRAIN [1][6200/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00097)	Tok/s 61823 (59999)	Loss/tok 3.2166 (3.2781)	Learning Rate [7.8125e-05]
0: TRAIN [1][6200/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00095)	Tok/s 60762 (58717)	Loss/tok 3.1815 (3.2776)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [1][6210/6832]	Time 0.070 (0.105)	Data 0.00104 (0.00094)	Tok/s 52805 (59554)	Loss/tok 2.9533 (3.2763)	Learning Rate [7.8125e-05]
1: TRAIN [1][6210/6832]	Time 0.070 (0.105)	Data 0.00098 (0.00093)	Tok/s 52738 (59181)	Loss/tok 2.9915 (3.2793)	Learning Rate [7.8125e-05]
3: TRAIN [1][6210/6832]	Time 0.070 (0.105)	Data 0.00108 (0.00097)	Tok/s 53000 (60005)	Loss/tok 3.0098 (3.2780)	Learning Rate [7.8125e-05]
0: TRAIN [1][6210/6832]	Time 0.070 (0.105)	Data 0.00104 (0.00095)	Tok/s 52765 (58724)	Loss/tok 3.1232 (3.2776)	Learning Rate [7.8125e-05]
1: TRAIN [1][6220/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 73356 (59182)	Loss/tok 3.2695 (3.2792)	Learning Rate [7.8125e-05]
0: TRAIN [1][6220/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00095)	Tok/s 73078 (58723)	Loss/tok 3.3183 (3.2775)	Learning Rate [7.8125e-05]
3: TRAIN [1][6220/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00097)	Tok/s 74092 (60007)	Loss/tok 3.3365 (3.2778)	Learning Rate [7.8125e-05]
2: TRAIN [1][6220/6832]	Time 0.132 (0.105)	Data 0.00104 (0.00094)	Tok/s 72745 (59555)	Loss/tok 3.5300 (3.2763)	Learning Rate [7.8125e-05]
2: TRAIN [1][6230/6832]	Time 0.077 (0.105)	Data 0.00090 (0.00094)	Tok/s 52860 (59551)	Loss/tok 2.9435 (3.2762)	Learning Rate [7.8125e-05]
1: TRAIN [1][6230/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00093)	Tok/s 52833 (59178)	Loss/tok 3.0766 (3.2792)	Learning Rate [7.8125e-05]
3: TRAIN [1][6230/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00097)	Tok/s 52856 (60003)	Loss/tok 3.0775 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [1][6230/6832]	Time 0.077 (0.105)	Data 0.00095 (0.00095)	Tok/s 52891 (58720)	Loss/tok 3.1469 (3.2775)	Learning Rate [7.8125e-05]
1: TRAIN [1][6240/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00093)	Tok/s 58686 (59176)	Loss/tok 3.2856 (3.2792)	Learning Rate [7.8125e-05]
2: TRAIN [1][6240/6832]	Time 0.113 (0.105)	Data 0.00098 (0.00094)	Tok/s 58721 (59549)	Loss/tok 3.2157 (3.2762)	Learning Rate [7.8125e-05]
3: TRAIN [1][6240/6832]	Time 0.113 (0.105)	Data 0.00100 (0.00097)	Tok/s 58726 (60001)	Loss/tok 3.4945 (3.2778)	Learning Rate [7.8125e-05]
0: TRAIN [1][6240/6832]	Time 0.113 (0.105)	Data 0.00096 (0.00095)	Tok/s 58657 (58718)	Loss/tok 3.3294 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6250/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00094)	Tok/s 51879 (59558)	Loss/tok 3.2057 (3.2761)	Learning Rate [7.8125e-05]
1: TRAIN [1][6250/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00093)	Tok/s 51306 (59185)	Loss/tok 3.0753 (3.2791)	Learning Rate [7.8125e-05]
3: TRAIN [1][6250/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00097)	Tok/s 52181 (60010)	Loss/tok 3.1341 (3.2778)	Learning Rate [7.8125e-05]
0: TRAIN [1][6250/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00095)	Tok/s 50439 (58727)	Loss/tok 3.0488 (3.2774)	Learning Rate [7.8125e-05]
1: TRAIN [1][6260/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00093)	Tok/s 68027 (59191)	Loss/tok 3.3865 (3.2791)	Learning Rate [7.8125e-05]
2: TRAIN [1][6260/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00094)	Tok/s 68028 (59563)	Loss/tok 3.2982 (3.2761)	Learning Rate [7.8125e-05]
3: TRAIN [1][6260/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00097)	Tok/s 68032 (60015)	Loss/tok 3.3596 (3.2778)	Learning Rate [7.8125e-05]
0: TRAIN [1][6260/6832]	Time 0.130 (0.105)	Data 0.00102 (0.00095)	Tok/s 67586 (58733)	Loss/tok 3.3479 (3.2774)	Learning Rate [7.8125e-05]
1: TRAIN [1][6270/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00093)	Tok/s 51827 (59190)	Loss/tok 3.3690 (3.2791)	Learning Rate [7.8125e-05]
2: TRAIN [1][6270/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00094)	Tok/s 53120 (59562)	Loss/tok 3.1729 (3.2761)	Learning Rate [7.8125e-05]
0: TRAIN [1][6270/6832]	Time 0.092 (0.105)	Data 0.00094 (0.00095)	Tok/s 51755 (58732)	Loss/tok 3.1633 (3.2774)	Learning Rate [7.8125e-05]
3: TRAIN [1][6270/6832]	Time 0.092 (0.105)	Data 0.00089 (0.00096)	Tok/s 53101 (60014)	Loss/tok 3.0485 (3.2778)	Learning Rate [7.8125e-05]
1: TRAIN [1][6280/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 77237 (59196)	Loss/tok 3.4082 (3.2790)	Learning Rate [7.8125e-05]
2: TRAIN [1][6280/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 77502 (59568)	Loss/tok 3.3737 (3.2760)	Learning Rate [7.8125e-05]
3: TRAIN [1][6280/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00096)	Tok/s 78205 (60020)	Loss/tok 3.2108 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [1][6280/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 77001 (58738)	Loss/tok 3.2312 (3.2772)	Learning Rate [7.8125e-05]
2: TRAIN [1][6290/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00094)	Tok/s 52631 (59565)	Loss/tok 2.9704 (3.2760)	Learning Rate [7.8125e-05]
1: TRAIN [1][6290/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00093)	Tok/s 51357 (59193)	Loss/tok 3.1978 (3.2790)	Learning Rate [7.8125e-05]
3: TRAIN [1][6290/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00096)	Tok/s 52629 (60017)	Loss/tok 3.0635 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [1][6290/6832]	Time 0.075 (0.105)	Data 0.00096 (0.00095)	Tok/s 50947 (58736)	Loss/tok 3.0906 (3.2772)	Learning Rate [7.8125e-05]
2: TRAIN [1][6300/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00094)	Tok/s 56582 (59556)	Loss/tok 3.4096 (3.2760)	Learning Rate [7.8125e-05]
1: TRAIN [1][6300/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00093)	Tok/s 56578 (59184)	Loss/tok 3.3409 (3.2789)	Learning Rate [7.8125e-05]
3: TRAIN [1][6300/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00096)	Tok/s 56590 (60007)	Loss/tok 3.2773 (3.2776)	Learning Rate [7.8125e-05]
0: TRAIN [1][6300/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00095)	Tok/s 56613 (58726)	Loss/tok 3.1138 (3.2771)	Learning Rate [7.8125e-05]
2: TRAIN [1][6310/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00094)	Tok/s 56131 (59550)	Loss/tok 3.3360 (3.2759)	Learning Rate [7.8125e-05]
3: TRAIN [1][6310/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00096)	Tok/s 56135 (60003)	Loss/tok 3.3756 (3.2776)	Learning Rate [7.8125e-05]
1: TRAIN [1][6310/6832]	Time 0.123 (0.105)	Data 0.00096 (0.00093)	Tok/s 56124 (59177)	Loss/tok 3.3136 (3.2788)	Learning Rate [7.8125e-05]
0: TRAIN [1][6310/6832]	Time 0.123 (0.105)	Data 0.00103 (0.00095)	Tok/s 56121 (58719)	Loss/tok 3.1412 (3.2770)	Learning Rate [7.8125e-05]
1: TRAIN [1][6320/6832]	Time 0.119 (0.105)	Data 0.00109 (0.00093)	Tok/s 56001 (59183)	Loss/tok 3.2986 (3.2788)	Learning Rate [7.8125e-05]
2: TRAIN [1][6320/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00094)	Tok/s 55982 (59557)	Loss/tok 3.3158 (3.2759)	Learning Rate [7.8125e-05]
3: TRAIN [1][6320/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00096)	Tok/s 55980 (60010)	Loss/tok 3.4280 (3.2776)	Learning Rate [7.8125e-05]
0: TRAIN [1][6320/6832]	Time 0.119 (0.105)	Data 0.00111 (0.00095)	Tok/s 55957 (58723)	Loss/tok 3.3414 (3.2771)	Learning Rate [7.8125e-05]
1: TRAIN [1][6330/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00093)	Tok/s 54086 (59180)	Loss/tok 3.2287 (3.2788)	Learning Rate [7.8125e-05]
0: TRAIN [1][6330/6832]	Time 0.103 (0.105)	Data 0.00091 (0.00095)	Tok/s 53434 (58720)	Loss/tok 3.1280 (3.2771)	Learning Rate [7.8125e-05]
2: TRAIN [1][6330/6832]	Time 0.103 (0.105)	Data 0.00091 (0.00094)	Tok/s 54648 (59554)	Loss/tok 3.1774 (3.2758)	Learning Rate [7.8125e-05]
3: TRAIN [1][6330/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00096)	Tok/s 54659 (60006)	Loss/tok 3.1601 (3.2775)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][6340/6832]	Time 0.078 (0.105)	Data 0.00089 (0.00094)	Tok/s 53925 (59555)	Loss/tok 3.0900 (3.2759)	Learning Rate [7.8125e-05]
1: TRAIN [1][6340/6832]	Time 0.078 (0.105)	Data 0.00085 (0.00093)	Tok/s 52978 (59182)	Loss/tok 3.1410 (3.2788)	Learning Rate [7.8125e-05]
3: TRAIN [1][6340/6832]	Time 0.078 (0.105)	Data 0.00086 (0.00096)	Tok/s 53921 (60007)	Loss/tok 3.0023 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6340/6832]	Time 0.078 (0.105)	Data 0.00095 (0.00095)	Tok/s 52247 (58722)	Loss/tok 3.0158 (3.2771)	Learning Rate [7.8125e-05]
1: TRAIN [1][6350/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00093)	Tok/s 59987 (59181)	Loss/tok 3.4172 (3.2787)	Learning Rate [7.8125e-05]
0: TRAIN [1][6350/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00095)	Tok/s 59964 (58722)	Loss/tok 3.4978 (3.2771)	Learning Rate [7.8125e-05]
2: TRAIN [1][6350/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00094)	Tok/s 59920 (59555)	Loss/tok 3.3412 (3.2758)	Learning Rate [7.8125e-05]
3: TRAIN [1][6350/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00096)	Tok/s 60879 (60007)	Loss/tok 3.4588 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6360/6832]	Time 0.103 (0.105)	Data 0.00103 (0.00094)	Tok/s 54460 (59548)	Loss/tok 3.3332 (3.2757)	Learning Rate [7.8125e-05]
3: TRAIN [1][6360/6832]	Time 0.103 (0.105)	Data 0.00099 (0.00096)	Tok/s 54458 (60000)	Loss/tok 2.9949 (3.2773)	Learning Rate [7.8125e-05]
1: TRAIN [1][6360/6832]	Time 0.104 (0.105)	Data 0.00100 (0.00093)	Tok/s 54393 (59174)	Loss/tok 3.3703 (3.2786)	Learning Rate [7.8125e-05]
0: TRAIN [1][6360/6832]	Time 0.104 (0.105)	Data 0.00104 (0.00095)	Tok/s 54190 (58715)	Loss/tok 3.2039 (3.2770)	Learning Rate [7.8125e-05]
1: TRAIN [1][6370/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00093)	Tok/s 63023 (59183)	Loss/tok 3.2122 (3.2784)	Learning Rate [7.8125e-05]
2: TRAIN [1][6370/6832]	Time 0.126 (0.105)	Data 0.00102 (0.00094)	Tok/s 63176 (59557)	Loss/tok 3.3382 (3.2757)	Learning Rate [7.8125e-05]
0: TRAIN [1][6370/6832]	Time 0.126 (0.105)	Data 0.00100 (0.00095)	Tok/s 63040 (58724)	Loss/tok 3.4227 (3.2770)	Learning Rate [7.8125e-05]
3: TRAIN [1][6370/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00096)	Tok/s 64006 (60009)	Loss/tok 3.4472 (3.2774)	Learning Rate [7.8125e-05]
1: TRAIN [1][6380/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00093)	Tok/s 57836 (59184)	Loss/tok 3.2200 (3.2785)	Learning Rate [7.8125e-05]
0: TRAIN [1][6380/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00095)	Tok/s 56884 (58725)	Loss/tok 3.2561 (3.2770)	Learning Rate [7.8125e-05]
3: TRAIN [1][6380/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00096)	Tok/s 57882 (60009)	Loss/tok 3.2934 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6380/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 57849 (59558)	Loss/tok 3.1604 (3.2757)	Learning Rate [7.8125e-05]
1: TRAIN [1][6390/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00093)	Tok/s 86234 (59182)	Loss/tok 3.1971 (3.2784)	Learning Rate [7.8125e-05]
0: TRAIN [1][6390/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 85400 (58723)	Loss/tok 3.2290 (3.2769)	Learning Rate [7.8125e-05]
2: TRAIN [1][6390/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 86513 (59556)	Loss/tok 3.2071 (3.2757)	Learning Rate [7.8125e-05]
3: TRAIN [1][6390/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 87117 (60007)	Loss/tok 3.1804 (3.2774)	Learning Rate [7.8125e-05]
1: TRAIN [1][6400/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00093)	Tok/s 54140 (59189)	Loss/tok 3.0971 (3.2785)	Learning Rate [7.8125e-05]
2: TRAIN [1][6400/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00094)	Tok/s 54152 (59562)	Loss/tok 3.2108 (3.2757)	Learning Rate [7.8125e-05]
3: TRAIN [1][6400/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00096)	Tok/s 54156 (60013)	Loss/tok 3.0035 (3.2776)	Learning Rate [7.8125e-05]
0: TRAIN [1][6400/6832]	Time 0.080 (0.105)	Data 0.00095 (0.00095)	Tok/s 54111 (58730)	Loss/tok 3.1896 (3.2770)	Learning Rate [7.8125e-05]
2: TRAIN [1][6410/6832]	Time 0.098 (0.105)	Data 0.00090 (0.00094)	Tok/s 52963 (59558)	Loss/tok 3.1814 (3.2756)	Learning Rate [7.8125e-05]
1: TRAIN [1][6410/6832]	Time 0.098 (0.105)	Data 0.00086 (0.00093)	Tok/s 52106 (59186)	Loss/tok 3.1499 (3.2785)	Learning Rate [7.8125e-05]
0: TRAIN [1][6410/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00095)	Tok/s 52138 (58727)	Loss/tok 3.1454 (3.2769)	Learning Rate [7.8125e-05]
3: TRAIN [1][6410/6832]	Time 0.098 (0.105)	Data 0.00086 (0.00096)	Tok/s 53430 (60009)	Loss/tok 3.1264 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6420/6832]	Time 0.069 (0.105)	Data 0.00095 (0.00094)	Tok/s 51657 (59563)	Loss/tok 2.9826 (3.2756)	Learning Rate [7.8125e-05]
1: TRAIN [1][6420/6832]	Time 0.069 (0.105)	Data 0.00088 (0.00093)	Tok/s 51638 (59190)	Loss/tok 2.9762 (3.2784)	Learning Rate [7.8125e-05]
3: TRAIN [1][6420/6832]	Time 0.069 (0.105)	Data 0.00093 (0.00096)	Tok/s 51660 (60014)	Loss/tok 2.9697 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6420/6832]	Time 0.069 (0.105)	Data 0.00094 (0.00095)	Tok/s 51631 (58733)	Loss/tok 2.9453 (3.2769)	Learning Rate [7.8125e-05]
1: TRAIN [1][6430/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00093)	Tok/s 53518 (59191)	Loss/tok 3.1415 (3.2784)	Learning Rate [7.8125e-05]
0: TRAIN [1][6430/6832]	Time 0.105 (0.105)	Data 0.00096 (0.00095)	Tok/s 53462 (58733)	Loss/tok 3.1015 (3.2769)	Learning Rate [7.8125e-05]
2: TRAIN [1][6430/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00094)	Tok/s 53441 (59563)	Loss/tok 3.1614 (3.2756)	Learning Rate [7.8125e-05]
3: TRAIN [1][6430/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00096)	Tok/s 53428 (60013)	Loss/tok 3.3489 (3.2775)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [1][6440/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 73970 (59570)	Loss/tok 3.4135 (3.2754)	Learning Rate [7.8125e-05]
1: TRAIN [1][6440/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00093)	Tok/s 73867 (59198)	Loss/tok 3.2973 (3.2783)	Learning Rate [7.8125e-05]
0: TRAIN [1][6440/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 73912 (58741)	Loss/tok 3.1434 (3.2767)	Learning Rate [7.8125e-05]
3: TRAIN [1][6440/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 74877 (60022)	Loss/tok 3.4167 (3.2774)	Learning Rate [7.8125e-05]
1: TRAIN [1][6450/6832]	Time 0.065 (0.105)	Data 0.00088 (0.00093)	Tok/s 50860 (59196)	Loss/tok 3.0615 (3.2782)	Learning Rate [7.8125e-05]
2: TRAIN [1][6450/6832]	Time 0.065 (0.105)	Data 0.00090 (0.00094)	Tok/s 51078 (59569)	Loss/tok 3.1470 (3.2752)	Learning Rate [7.8125e-05]
3: TRAIN [1][6450/6832]	Time 0.065 (0.105)	Data 0.00086 (0.00096)	Tok/s 52806 (60021)	Loss/tok 3.1497 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [1][6450/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00095)	Tok/s 50845 (58739)	Loss/tok 3.1052 (3.2766)	Learning Rate [7.8125e-05]
2: TRAIN [1][6460/6832]	Time 0.097 (0.105)	Data 0.00091 (0.00094)	Tok/s 54016 (59563)	Loss/tok 3.1220 (3.2751)	Learning Rate [7.8125e-05]
1: TRAIN [1][6460/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00093)	Tok/s 53998 (59190)	Loss/tok 3.1386 (3.2780)	Learning Rate [7.8125e-05]
0: TRAIN [1][6460/6832]	Time 0.097 (0.105)	Data 0.00097 (0.00095)	Tok/s 54031 (58732)	Loss/tok 3.3024 (3.2764)	Learning Rate [7.8125e-05]
3: TRAIN [1][6460/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00096)	Tok/s 54018 (60016)	Loss/tok 3.3226 (3.2771)	Learning Rate [7.8125e-05]
2: TRAIN [1][6470/6832]	Time 0.100 (0.105)	Data 0.00108 (0.00094)	Tok/s 51438 (59562)	Loss/tok 3.2652 (3.2750)	Learning Rate [7.8125e-05]
1: TRAIN [1][6470/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00093)	Tok/s 51399 (59188)	Loss/tok 3.1825 (3.2780)	Learning Rate [7.8125e-05]
3: TRAIN [1][6470/6832]	Time 0.100 (0.105)	Data 0.00105 (0.00096)	Tok/s 51432 (60014)	Loss/tok 3.1829 (3.2770)	Learning Rate [7.8125e-05]
0: TRAIN [1][6470/6832]	Time 0.100 (0.105)	Data 0.00109 (0.00095)	Tok/s 50388 (58730)	Loss/tok 3.1108 (3.2764)	Learning Rate [7.8125e-05]
2: TRAIN [1][6480/6832]	Time 0.088 (0.105)	Data 0.00095 (0.00094)	Tok/s 55320 (59556)	Loss/tok 2.9512 (3.2750)	Learning Rate [7.8125e-05]
1: TRAIN [1][6480/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00093)	Tok/s 55227 (59183)	Loss/tok 3.0254 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][6480/6832]	Time 0.088 (0.105)	Data 0.00099 (0.00096)	Tok/s 55656 (60008)	Loss/tok 3.0874 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [1][6480/6832]	Time 0.088 (0.105)	Data 0.00098 (0.00095)	Tok/s 55279 (58724)	Loss/tok 3.0347 (3.2763)	Learning Rate [7.8125e-05]
2: TRAIN [1][6490/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00094)	Tok/s 61779 (59566)	Loss/tok 3.2950 (3.2750)	Learning Rate [7.8125e-05]
1: TRAIN [1][6490/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00093)	Tok/s 60981 (59193)	Loss/tok 3.3129 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][6490/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00096)	Tok/s 62041 (60018)	Loss/tok 3.3848 (3.2770)	Learning Rate [7.8125e-05]
0: TRAIN [1][6490/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00095)	Tok/s 60930 (58735)	Loss/tok 3.3615 (3.2763)	Learning Rate [7.8125e-05]
2: TRAIN [1][6500/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 65342 (59566)	Loss/tok 3.4597 (3.2751)	Learning Rate [7.8125e-05]
1: TRAIN [1][6500/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 65390 (59192)	Loss/tok 3.3167 (3.2779)	Learning Rate [7.8125e-05]
3: TRAIN [1][6500/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00096)	Tok/s 65353 (60017)	Loss/tok 3.4601 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [1][6500/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00095)	Tok/s 64868 (58735)	Loss/tok 3.2773 (3.2764)	Learning Rate [7.8125e-05]
1: TRAIN [1][6510/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00093)	Tok/s 63791 (59197)	Loss/tok 3.2811 (3.2779)	Learning Rate [7.8125e-05]
2: TRAIN [1][6510/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 64142 (59570)	Loss/tok 3.3125 (3.2752)	Learning Rate [7.8125e-05]
3: TRAIN [1][6510/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 64766 (60022)	Loss/tok 3.4607 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [1][6510/6832]	Time 0.128 (0.105)	Data 0.00100 (0.00095)	Tok/s 63777 (58740)	Loss/tok 3.3519 (3.2764)	Learning Rate [7.8125e-05]
2: TRAIN [1][6520/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00094)	Tok/s 60321 (59564)	Loss/tok 3.2709 (3.2752)	Learning Rate [7.8125e-05]
1: TRAIN [1][6520/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00093)	Tok/s 60296 (59191)	Loss/tok 3.3110 (3.2778)	Learning Rate [7.8125e-05]
3: TRAIN [1][6520/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00096)	Tok/s 61192 (60015)	Loss/tok 3.3468 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [1][6520/6832]	Time 0.121 (0.105)	Data 0.00103 (0.00095)	Tok/s 60338 (58734)	Loss/tok 3.3966 (3.2764)	Learning Rate [7.8125e-05]
2: TRAIN [1][6530/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 79069 (59572)	Loss/tok 3.2452 (3.2752)	Learning Rate [7.8125e-05]
3: TRAIN [1][6530/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 79107 (60023)	Loss/tok 3.4807 (3.2773)	Learning Rate [7.8125e-05]
1: TRAIN [1][6530/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00093)	Tok/s 78033 (59198)	Loss/tok 3.2565 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [1][6530/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 77947 (58740)	Loss/tok 3.4537 (3.2764)	Learning Rate [7.8125e-05]
1: TRAIN [1][6540/6832]	Time 0.108 (0.105)	Data 0.00095 (0.00093)	Tok/s 51966 (59211)	Loss/tok 3.1618 (3.2779)	Learning Rate [7.8125e-05]
2: TRAIN [1][6540/6832]	Time 0.108 (0.105)	Data 0.00088 (0.00094)	Tok/s 51979 (59585)	Loss/tok 3.1031 (3.2751)	Learning Rate [7.8125e-05]
3: TRAIN [1][6540/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00096)	Tok/s 51975 (60037)	Loss/tok 3.1830 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [1][6540/6832]	Time 0.108 (0.105)	Data 0.00100 (0.00095)	Tok/s 51994 (58753)	Loss/tok 3.2630 (3.2764)	Learning Rate [7.8125e-05]
1: TRAIN [1][6550/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00093)	Tok/s 51455 (59209)	Loss/tok 3.1793 (3.2779)	Learning Rate [7.8125e-05]
2: TRAIN [1][6550/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 51502 (59583)	Loss/tok 3.3233 (3.2751)	Learning Rate [7.8125e-05]
0: TRAIN [1][6550/6832]	Time 0.119 (0.105)	Data 0.00101 (0.00095)	Tok/s 51061 (58751)	Loss/tok 3.2782 (3.2764)	Learning Rate [7.8125e-05]
3: TRAIN [1][6550/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00096)	Tok/s 51485 (60035)	Loss/tok 3.4042 (3.2773)	Learning Rate [7.8125e-05]
1: TRAIN [1][6560/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00093)	Tok/s 57869 (59206)	Loss/tok 3.4686 (3.2779)	Learning Rate [7.8125e-05]
2: TRAIN [1][6560/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 57863 (59580)	Loss/tok 3.4907 (3.2751)	Learning Rate [7.8125e-05]
3: TRAIN [1][6560/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 57875 (60032)	Loss/tok 3.2079 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [1][6560/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00095)	Tok/s 57879 (58747)	Loss/tok 3.3090 (3.2764)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][6570/6832]	Time 0.080 (0.105)	Data 0.00094 (0.00094)	Tok/s 54170 (59588)	Loss/tok 3.0889 (3.2750)	Learning Rate [7.8125e-05]
1: TRAIN [1][6570/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00093)	Tok/s 54092 (59214)	Loss/tok 3.0434 (3.2778)	Learning Rate [7.8125e-05]
3: TRAIN [1][6570/6832]	Time 0.080 (0.105)	Data 0.00097 (0.00096)	Tok/s 55155 (60040)	Loss/tok 3.1975 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [1][6570/6832]	Time 0.080 (0.105)	Data 0.00098 (0.00095)	Tok/s 54111 (58756)	Loss/tok 3.2592 (3.2763)	Learning Rate [7.8125e-05]
2: TRAIN [1][6580/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 92931 (59592)	Loss/tok 3.2396 (3.2750)	Learning Rate [7.8125e-05]
1: TRAIN [1][6580/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00093)	Tok/s 91760 (59218)	Loss/tok 3.1528 (3.2777)	Learning Rate [7.8125e-05]
3: TRAIN [1][6580/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00096)	Tok/s 94888 (60043)	Loss/tok 3.1469 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [1][6580/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00095)	Tok/s 90703 (58759)	Loss/tok 3.2476 (3.2763)	Learning Rate [7.8125e-05]
1: TRAIN [1][6590/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00093)	Tok/s 53018 (59209)	Loss/tok 3.1316 (3.2776)	Learning Rate [7.8125e-05]
2: TRAIN [1][6590/6832]	Time 0.097 (0.105)	Data 0.00093 (0.00094)	Tok/s 53009 (59583)	Loss/tok 3.1420 (3.2750)	Learning Rate [7.8125e-05]
0: TRAIN [1][6590/6832]	Time 0.097 (0.105)	Data 0.00099 (0.00095)	Tok/s 53013 (58751)	Loss/tok 3.3174 (3.2763)	Learning Rate [7.8125e-05]
3: TRAIN [1][6590/6832]	Time 0.097 (0.105)	Data 0.00098 (0.00096)	Tok/s 53642 (60035)	Loss/tok 3.3027 (3.2771)	Learning Rate [7.8125e-05]
1: TRAIN [1][6600/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 83429 (59205)	Loss/tok 3.1734 (3.2776)	Learning Rate [7.8125e-05]
2: TRAIN [1][6600/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 83695 (59580)	Loss/tok 3.1041 (3.2748)	Learning Rate [7.8125e-05]
0: TRAIN [1][6600/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00095)	Tok/s 82669 (58745)	Loss/tok 3.1313 (3.2762)	Learning Rate [7.8125e-05]
3: TRAIN [1][6600/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00096)	Tok/s 84365 (60032)	Loss/tok 3.3521 (3.2770)	Learning Rate [7.8125e-05]
2: TRAIN [1][6610/6832]	Time 0.089 (0.105)	Data 0.00085 (0.00094)	Tok/s 51876 (59577)	Loss/tok 3.0707 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [1][6610/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00095)	Tok/s 51898 (58743)	Loss/tok 3.2009 (3.2760)	Learning Rate [7.8125e-05]
1: TRAIN [1][6610/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00093)	Tok/s 51890 (59202)	Loss/tok 3.1127 (3.2775)	Learning Rate [7.8125e-05]
3: TRAIN [1][6610/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00096)	Tok/s 52023 (60029)	Loss/tok 3.1459 (3.2769)	Learning Rate [7.8125e-05]
1: TRAIN [1][6620/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00093)	Tok/s 68001 (59204)	Loss/tok 3.3985 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6620/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00095)	Tok/s 67995 (58745)	Loss/tok 3.3995 (3.2761)	Learning Rate [7.8125e-05]
2: TRAIN [1][6620/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 67996 (59578)	Loss/tok 3.4529 (3.2747)	Learning Rate [7.8125e-05]
3: TRAIN [1][6620/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 68357 (60030)	Loss/tok 3.3716 (3.2770)	Learning Rate [7.8125e-05]
1: TRAIN [1][6630/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00093)	Tok/s 79811 (59211)	Loss/tok 3.1807 (3.2777)	Learning Rate [7.8125e-05]
2: TRAIN [1][6630/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 80536 (59586)	Loss/tok 3.4438 (3.2747)	Learning Rate [7.8125e-05]
3: TRAIN [1][6630/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 80532 (60037)	Loss/tok 3.1175 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [1][6630/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 79572 (58752)	Loss/tok 3.3736 (3.2761)	Learning Rate [7.8125e-05]
1: TRAIN [1][6640/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00093)	Tok/s 52570 (59213)	Loss/tok 3.1776 (3.2777)	Learning Rate [7.8125e-05]
2: TRAIN [1][6640/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00094)	Tok/s 52574 (59588)	Loss/tok 3.2041 (3.2746)	Learning Rate [7.8125e-05]
3: TRAIN [1][6640/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00096)	Tok/s 52559 (60038)	Loss/tok 3.2963 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [1][6640/6832]	Time 0.107 (0.105)	Data 0.00098 (0.00095)	Tok/s 51669 (58754)	Loss/tok 3.1704 (3.2761)	Learning Rate [7.8125e-05]
1: TRAIN [1][6650/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00093)	Tok/s 53609 (59213)	Loss/tok 3.2213 (3.2775)	Learning Rate [7.8125e-05]
2: TRAIN [1][6650/6832]	Time 0.076 (0.105)	Data 0.00091 (0.00094)	Tok/s 53660 (59588)	Loss/tok 3.0273 (3.2745)	Learning Rate [7.8125e-05]
3: TRAIN [1][6650/6832]	Time 0.076 (0.105)	Data 0.00090 (0.00096)	Tok/s 53694 (60039)	Loss/tok 3.0075 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [1][6650/6832]	Time 0.076 (0.105)	Data 0.00096 (0.00095)	Tok/s 53644 (58755)	Loss/tok 3.1299 (3.2759)	Learning Rate [7.8125e-05]
1: TRAIN [1][6660/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 76785 (59217)	Loss/tok 3.2601 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6660/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00095)	Tok/s 76787 (58758)	Loss/tok 3.2053 (3.2758)	Learning Rate [7.8125e-05]
3: TRAIN [1][6660/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00096)	Tok/s 77802 (60043)	Loss/tok 3.3373 (3.2767)	Learning Rate [7.8125e-05]
2: TRAIN [1][6660/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 77631 (59592)	Loss/tok 3.5396 (3.2744)	Learning Rate [7.8125e-05]
1: TRAIN [1][6670/6832]	Time 0.089 (0.105)	Data 0.00096 (0.00093)	Tok/s 51638 (59206)	Loss/tok 3.3577 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [1][6670/6832]	Time 0.089 (0.105)	Data 0.00096 (0.00095)	Tok/s 51660 (58745)	Loss/tok 3.1876 (3.2757)	Learning Rate [7.8125e-05]
2: TRAIN [1][6670/6832]	Time 0.089 (0.105)	Data 0.00098 (0.00094)	Tok/s 51595 (59581)	Loss/tok 3.3488 (3.2742)	Learning Rate [7.8125e-05]
3: TRAIN [1][6670/6832]	Time 0.089 (0.105)	Data 0.00099 (0.00096)	Tok/s 51605 (60033)	Loss/tok 3.0907 (3.2765)	Learning Rate [7.8125e-05]
1: TRAIN [1][6680/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 79113 (59215)	Loss/tok 3.2370 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [1][6680/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 78175 (58755)	Loss/tok 3.4872 (3.2758)	Learning Rate [7.8125e-05]
2: TRAIN [1][6680/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 79089 (59591)	Loss/tok 3.3342 (3.2743)	Learning Rate [7.8125e-05]
3: TRAIN [1][6680/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 79436 (60043)	Loss/tok 3.2444 (3.2766)	Learning Rate [7.8125e-05]
2: TRAIN [1][6690/6832]	Time 0.074 (0.105)	Data 0.00089 (0.00094)	Tok/s 50257 (59590)	Loss/tok 3.0768 (3.2743)	Learning Rate [7.8125e-05]
1: TRAIN [1][6690/6832]	Time 0.074 (0.105)	Data 0.00088 (0.00093)	Tok/s 50260 (59215)	Loss/tok 3.0915 (3.2774)	Learning Rate [7.8125e-05]
3: TRAIN [1][6690/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00096)	Tok/s 50254 (60042)	Loss/tok 2.9518 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [1][6690/6832]	Time 0.074 (0.105)	Data 0.00092 (0.00095)	Tok/s 50134 (58756)	Loss/tok 2.9948 (3.2758)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [1][6700/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00094)	Tok/s 51398 (59589)	Loss/tok 3.2081 (3.2743)	Learning Rate [7.8125e-05]
1: TRAIN [1][6700/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00093)	Tok/s 51388 (59214)	Loss/tok 3.0137 (3.2774)	Learning Rate [7.8125e-05]
0: TRAIN [1][6700/6832]	Time 0.095 (0.105)	Data 0.00091 (0.00095)	Tok/s 51383 (58755)	Loss/tok 3.1829 (3.2757)	Learning Rate [7.8125e-05]
3: TRAIN [1][6700/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00096)	Tok/s 52371 (60041)	Loss/tok 3.2983 (3.2767)	Learning Rate [7.8125e-05]
1: TRAIN [1][6710/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00093)	Tok/s 58192 (59219)	Loss/tok 3.3779 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6710/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00094)	Tok/s 58210 (59594)	Loss/tok 3.2511 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [1][6710/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00095)	Tok/s 57138 (58760)	Loss/tok 3.4462 (3.2759)	Learning Rate [7.8125e-05]
3: TRAIN [1][6710/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00096)	Tok/s 58209 (60045)	Loss/tok 3.1551 (3.2767)	Learning Rate [7.8125e-05]
1: TRAIN [1][6720/6832]	Time 0.105 (0.105)	Data 0.00085 (0.00093)	Tok/s 51200 (59223)	Loss/tok 3.1602 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6720/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00094)	Tok/s 52273 (59597)	Loss/tok 3.3236 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [1][6720/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00095)	Tok/s 51218 (58764)	Loss/tok 3.0835 (3.2759)	Learning Rate [7.8125e-05]
3: TRAIN [1][6720/6832]	Time 0.105 (0.105)	Data 0.00093 (0.00096)	Tok/s 52512 (60049)	Loss/tok 3.0904 (3.2767)	Learning Rate [7.8125e-05]
1: TRAIN [1][6730/6832]	Time 0.130 (0.105)	Data 0.00107 (0.00093)	Tok/s 68694 (59222)	Loss/tok 3.5020 (3.2774)	Learning Rate [7.8125e-05]
0: TRAIN [1][6730/6832]	Time 0.130 (0.105)	Data 0.00107 (0.00095)	Tok/s 68003 (58764)	Loss/tok 3.3146 (3.2759)	Learning Rate [7.8125e-05]
2: TRAIN [1][6730/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00094)	Tok/s 68661 (59596)	Loss/tok 3.2875 (3.2743)	Learning Rate [7.8125e-05]
3: TRAIN [1][6730/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00096)	Tok/s 68610 (60048)	Loss/tok 3.2937 (3.2768)	Learning Rate [7.8125e-05]
1: TRAIN [1][6740/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00093)	Tok/s 71389 (59229)	Loss/tok 3.4704 (3.2775)	Learning Rate [7.8125e-05]
2: TRAIN [1][6740/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 72082 (59602)	Loss/tok 3.4708 (3.2742)	Learning Rate [7.8125e-05]
0: TRAIN [1][6740/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 71398 (58770)	Loss/tok 3.5190 (3.2759)	Learning Rate [7.8125e-05]
3: TRAIN [1][6740/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00096)	Tok/s 72410 (60054)	Loss/tok 3.3587 (3.2768)	Learning Rate [7.8125e-05]
1: TRAIN [1][6750/6832]	Time 0.060 (0.105)	Data 0.00099 (0.00093)	Tok/s 51420 (59232)	Loss/tok 2.8479 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6750/6832]	Time 0.060 (0.105)	Data 0.00103 (0.00095)	Tok/s 51451 (58774)	Loss/tok 2.7932 (3.2759)	Learning Rate [7.8125e-05]
2: TRAIN [1][6750/6832]	Time 0.060 (0.105)	Data 0.00094 (0.00094)	Tok/s 51318 (59606)	Loss/tok 2.7939 (3.2742)	Learning Rate [7.8125e-05]
3: TRAIN [1][6750/6832]	Time 0.060 (0.105)	Data 0.00106 (0.00096)	Tok/s 52883 (60057)	Loss/tok 2.9465 (3.2768)	Learning Rate [7.8125e-05]
1: TRAIN [1][6760/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 70774 (59234)	Loss/tok 3.5753 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6760/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 70758 (58776)	Loss/tok 3.4013 (3.2758)	Learning Rate [7.8125e-05]
2: TRAIN [1][6760/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 71743 (59607)	Loss/tok 3.6018 (3.2743)	Learning Rate [7.8125e-05]
3: TRAIN [1][6760/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00096)	Tok/s 71741 (60058)	Loss/tok 3.4221 (3.2768)	Learning Rate [7.8125e-05]
1: TRAIN [1][6770/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00093)	Tok/s 72143 (59235)	Loss/tok 3.3975 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6770/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00095)	Tok/s 71796 (58778)	Loss/tok 3.4513 (3.2759)	Learning Rate [7.8125e-05]
2: TRAIN [1][6770/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 72676 (59609)	Loss/tok 3.4984 (3.2743)	Learning Rate [7.8125e-05]
3: TRAIN [1][6770/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00096)	Tok/s 72685 (60059)	Loss/tok 3.3236 (3.2768)	Learning Rate [7.8125e-05]
2: TRAIN [1][6780/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00094)	Tok/s 51446 (59604)	Loss/tok 3.3916 (3.2742)	Learning Rate [7.8125e-05]
1: TRAIN [1][6780/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00093)	Tok/s 51418 (59230)	Loss/tok 3.3204 (3.2774)	Learning Rate [7.8125e-05]
3: TRAIN [1][6780/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00096)	Tok/s 51458 (60055)	Loss/tok 3.4021 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [1][6780/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00095)	Tok/s 51429 (58773)	Loss/tok 3.3965 (3.2758)	Learning Rate [7.8125e-05]
1: Gradient norm: inf
2: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [1][6790/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00093)	Tok/s 57243 (59231)	Loss/tok 3.3972 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6790/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00094)	Tok/s 57239 (59605)	Loss/tok 3.5577 (3.2742)	Learning Rate [7.8125e-05]
0: TRAIN [1][6790/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00095)	Tok/s 57215 (58772)	Loss/tok 3.3184 (3.2757)	Learning Rate [7.8125e-05]
3: TRAIN [1][6790/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00096)	Tok/s 57248 (60056)	Loss/tok 3.5176 (3.2768)	Learning Rate [7.8125e-05]
1: TRAIN [1][6800/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00093)	Tok/s 52044 (59240)	Loss/tok 3.4693 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6800/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 52248 (59615)	Loss/tok 3.2792 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [1][6800/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00095)	Tok/s 52015 (58782)	Loss/tok 3.4124 (3.2758)	Learning Rate [7.8125e-05]
3: TRAIN [1][6800/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00096)	Tok/s 53117 (60066)	Loss/tok 3.2226 (3.2768)	Learning Rate [7.8125e-05]
1: TRAIN [1][6810/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00093)	Tok/s 55630 (59237)	Loss/tok 3.3572 (3.2774)	Learning Rate [7.8125e-05]
2: TRAIN [1][6810/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00094)	Tok/s 56669 (59612)	Loss/tok 3.3870 (3.2744)	Learning Rate [7.8125e-05]
0: TRAIN [1][6810/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00095)	Tok/s 55639 (58779)	Loss/tok 3.3370 (3.2758)	Learning Rate [7.8125e-05]
3: TRAIN [1][6810/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00096)	Tok/s 56689 (60063)	Loss/tok 3.4777 (3.2769)	Learning Rate [7.8125e-05]
1: TRAIN [1][6820/6832]	Time 0.052 (0.105)	Data 0.00088 (0.00093)	Tok/s 47055 (59237)	Loss/tok 2.6714 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6820/6832]	Time 0.052 (0.105)	Data 0.00089 (0.00095)	Tok/s 45174 (58779)	Loss/tok 2.5700 (3.2758)	Learning Rate [7.8125e-05]
2: TRAIN [1][6820/6832]	Time 0.052 (0.105)	Data 0.00094 (0.00094)	Tok/s 47949 (59611)	Loss/tok 2.6699 (3.2744)	Learning Rate [7.8125e-05]
3: TRAIN [1][6820/6832]	Time 0.052 (0.105)	Data 0.00098 (0.00096)	Tok/s 49664 (60063)	Loss/tok 2.7373 (3.2769)	Learning Rate [7.8125e-05]
1: TRAIN [1][6830/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 64915 (59234)	Loss/tok 3.2826 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [1][6830/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 64910 (58777)	Loss/tok 3.6194 (3.2759)	Learning Rate [7.8125e-05]
2: TRAIN [1][6830/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 65498 (59609)	Loss/tok 3.3831 (3.2744)	Learning Rate [7.8125e-05]
3: TRAIN [1][6830/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00097)	Tok/s 65899 (60060)	Loss/tok 3.4127 (3.2769)	Learning Rate [7.8125e-05]
2: Running validation on dev set
3: Running validation on dev set
1: Running validation on dev set
0: Running validation on dev set
2: VALIDATION [1][0/20]	Time 0.037 (0.000)	Data 0.00219 (0.00000)	Tok/s 206328 (0)	Loss/tok 3.3271 (0.0000)	Learning Rate [7.8125e-05]
3: VALIDATION [1][0/20]	Time 0.036 (0.000)	Data 0.00230 (0.00000)	Tok/s 203492 (0)	Loss/tok 3.2319 (0.0000)	Learning Rate [7.8125e-05]
1: VALIDATION [1][0/20]	Time 0.040 (0.000)	Data 0.00206 (0.00000)	Tok/s 208382 (0)	Loss/tok 3.3298 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [1][0/20]	Time 0.066 (0.000)	Data 0.00213 (0.00000)	Tok/s 154998 (0)	Loss/tok 3.4275 (0.0000)	Learning Rate [7.8125e-05]
3: VALIDATION [1][10/20]	Time 0.015 (0.021)	Data 0.00175 (0.00193)	Tok/s 196180 (204475)	Loss/tok 3.1072 (3.2090)	Learning Rate [7.8125e-05]
2: VALIDATION [1][10/20]	Time 0.015 (0.021)	Data 0.00172 (0.00187)	Tok/s 200694 (206769)	Loss/tok 3.0199 (3.1671)	Learning Rate [7.8125e-05]
1: VALIDATION [1][10/20]	Time 0.016 (0.022)	Data 0.00185 (0.00183)	Tok/s 199463 (207910)	Loss/tok 3.0971 (3.2193)	Learning Rate [7.8125e-05]
0: VALIDATION [1][10/20]	Time 0.015 (0.022)	Data 0.00168 (0.00178)	Tok/s 203988 (209749)	Loss/tok 3.1603 (3.1775)	Learning Rate [7.8125e-05]
2: Running evaluation on test set
3: Running evaluation on test set
1: Running evaluation on test set
:::MLPv0.5.0 gnmt 1560383787.125044584 (train.py:459) eval_start: 1
0: Running evaluation on test set
3: TEST [1][0/6]	Time 1.175 (1.175)	Decoder iters 99.0 (99.0)	Tok/s 6520 (6520)
1: TEST [1][0/6]	Time 1.176 (1.176)	Decoder iters 149.0 (149.0)	Tok/s 6489 (6489)
0: TEST [1][0/6]	Time 1.176 (1.176)	Decoder iters 66.0 (66.0)	Tok/s 5997 (5997)
2: TEST [1][0/6]	Time 1.177 (1.177)	Decoder iters 149.0 (149.0)	Tok/s 6327 (6327)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
2: Finished evaluation on test set
1: Finished evaluation on test set
3: Finished evaluation on test set
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560383797.248834610 (train.py:464) eval_accuracy: {"epoch": 1, "value": 20.899999618530273}
:::MLPv0.5.0 gnmt 1560383797.249540329 (train.py:466) eval_target: 21.8
2: Summary: Epoch: 1	Training Loss 3.2761
3: Summary: Epoch: 1	Training Loss 3.2761
2: Performance: Epoch: 1	Training: 237678 Tok/s
3: Performance: Epoch: 1	Training: 237678 Tok/s
1: Summary: Epoch: 1	Training Loss 3.2761
2: Finished epoch 1
3: Finished epoch 1
2: Starting epoch 2
3: Starting epoch 2
1: Performance: Epoch: 1	Training: 237678 Tok/s
1: Finished epoch 1
1: Starting epoch 2
:::MLPv0.5.0 gnmt 1560383797.250129938 (train.py:467) eval_stop
0: Summary: Epoch: 1	Training Loss: 3.2761	Validation Loss: 3.1603	Test BLEU: 20.90
0: Performance: Epoch: 1	Training: 237678 Tok/s	Validation: 708000 Tok/s
0: Finished epoch 1
0: Starting epoch 2
:::MLPv0.5.0 gnmt 1560383797.250918388 (train.py:443) train_epoch: 2
2: Sampler for epoch 2 uses seed 3796669421
1: Sampler for epoch 2 uses seed 3796669421
:::MLPv0.5.0 gnmt 1560383797.518384457 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 2 uses seed 3796669421
3: Sampler for epoch 2 uses seed 3796669421
:::MLPv0.5.0 gnmt 1560383797.612773895 (seq2seq/data/sampler.py:66) input_shard: 40960
3: TRAIN [2][0/6832]	Time 1.590 (0.000)	Data 1.29098 (0.00000)	Tok/s 2818 (0)	Loss/tok 3.2143 (0.0000)	Learning Rate [7.8125e-05]
2: TRAIN [2][0/6832]	Time 1.590 (0.000)	Data 1.26570 (0.00000)	Tok/s 2818 (0)	Loss/tok 2.9257 (0.0000)	Learning Rate [7.8125e-05]
1: TRAIN [2][0/6832]	Time 1.590 (0.000)	Data 1.09245 (0.00000)	Tok/s 2817 (0)	Loss/tok 2.9684 (0.0000)	Learning Rate [7.8125e-05]
0: TRAIN [2][0/6832]	Time 1.591 (0.000)	Data 1.50989 (0.00000)	Tok/s 2816 (0)	Loss/tok 3.0848 (0.0000)	Learning Rate [7.8125e-05]
2: TRAIN [2][10/6832]	Time 0.058 (0.088)	Data 0.00094 (0.00101)	Tok/s 48827 (55861)	Loss/tok 2.6632 (3.0983)	Learning Rate [7.8125e-05]
3: TRAIN [2][10/6832]	Time 0.058 (0.088)	Data 0.00090 (0.00099)	Tok/s 49032 (56257)	Loss/tok 2.7263 (3.1176)	Learning Rate [7.8125e-05]
1: TRAIN [2][10/6832]	Time 0.057 (0.088)	Data 0.00089 (0.00098)	Tok/s 48975 (55605)	Loss/tok 2.7426 (3.1497)	Learning Rate [7.8125e-05]
0: TRAIN [2][10/6832]	Time 0.058 (0.088)	Data 0.00106 (0.00090)	Tok/s 47654 (55169)	Loss/tok 2.5760 (3.1367)	Learning Rate [7.8125e-05]
2: TRAIN [2][20/6832]	Time 0.073 (0.102)	Data 0.00093 (0.00099)	Tok/s 52958 (60212)	Loss/tok 2.9015 (3.2281)	Learning Rate [7.8125e-05]
3: TRAIN [2][20/6832]	Time 0.072 (0.102)	Data 0.00086 (0.00095)	Tok/s 52968 (60544)	Loss/tok 2.9689 (3.2046)	Learning Rate [7.8125e-05]
1: TRAIN [2][20/6832]	Time 0.073 (0.102)	Data 0.00088 (0.00096)	Tok/s 52525 (60037)	Loss/tok 3.2626 (3.2287)	Learning Rate [7.8125e-05]
0: TRAIN [2][20/6832]	Time 0.073 (0.102)	Data 0.00106 (0.00100)	Tok/s 50980 (59600)	Loss/tok 2.9829 (3.2293)	Learning Rate [7.8125e-05]
1: TRAIN [2][30/6832]	Time 0.131 (0.103)	Data 0.00095 (0.00094)	Tok/s 70869 (61279)	Loss/tok 3.1380 (3.2209)	Learning Rate [7.8125e-05]
2: TRAIN [2][30/6832]	Time 0.130 (0.103)	Data 0.00110 (0.00097)	Tok/s 71677 (61549)	Loss/tok 3.3859 (3.2312)	Learning Rate [7.8125e-05]
3: TRAIN [2][30/6832]	Time 0.131 (0.103)	Data 0.00104 (0.00094)	Tok/s 71347 (61934)	Loss/tok 3.3569 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][30/6832]	Time 0.131 (0.103)	Data 0.00110 (0.00103)	Tok/s 70261 (60825)	Loss/tok 3.3995 (3.2258)	Learning Rate [7.8125e-05]
1: TRAIN [2][40/6832]	Time 0.069 (0.104)	Data 0.00109 (0.00094)	Tok/s 51973 (61515)	Loss/tok 3.0216 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][40/6832]	Time 0.069 (0.104)	Data 0.00096 (0.00093)	Tok/s 52023 (62285)	Loss/tok 2.9898 (3.1926)	Learning Rate [7.8125e-05]
2: TRAIN [2][40/6832]	Time 0.069 (0.104)	Data 0.00101 (0.00096)	Tok/s 52007 (61874)	Loss/tok 2.9178 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [2][40/6832]	Time 0.069 (0.104)	Data 0.00108 (0.00105)	Tok/s 51879 (61054)	Loss/tok 2.8818 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][50/6832]	Time 0.073 (0.101)	Data 0.00096 (0.00092)	Tok/s 54298 (62316)	Loss/tok 3.0098 (3.1785)	Learning Rate [7.8125e-05]
1: TRAIN [2][50/6832]	Time 0.073 (0.101)	Data 0.00089 (0.00094)	Tok/s 52761 (61470)	Loss/tok 2.9736 (3.2015)	Learning Rate [7.8125e-05]
2: TRAIN [2][50/6832]	Time 0.073 (0.101)	Data 0.00119 (0.00096)	Tok/s 54458 (61923)	Loss/tok 3.2086 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][50/6832]	Time 0.073 (0.101)	Data 0.00103 (0.00105)	Tok/s 52355 (61019)	Loss/tok 2.9460 (3.1970)	Learning Rate [7.8125e-05]
1: TRAIN [2][60/6832]	Time 0.128 (0.103)	Data 0.00094 (0.00093)	Tok/s 62109 (61009)	Loss/tok 3.3239 (3.2087)	Learning Rate [7.8125e-05]
2: TRAIN [2][60/6832]	Time 0.128 (0.103)	Data 0.00091 (0.00096)	Tok/s 62057 (61435)	Loss/tok 3.3976 (3.2149)	Learning Rate [7.8125e-05]
3: TRAIN [2][60/6832]	Time 0.128 (0.103)	Data 0.00087 (0.00092)	Tok/s 62221 (61789)	Loss/tok 3.3636 (3.1933)	Learning Rate [7.8125e-05]
0: TRAIN [2][60/6832]	Time 0.128 (0.103)	Data 0.00108 (0.00107)	Tok/s 61962 (60587)	Loss/tok 3.4299 (3.2044)	Learning Rate [7.8125e-05]
1: TRAIN [2][70/6832]	Time 0.082 (0.101)	Data 0.00095 (0.00093)	Tok/s 53204 (59895)	Loss/tok 3.1951 (3.1998)	Learning Rate [7.8125e-05]
3: TRAIN [2][70/6832]	Time 0.082 (0.101)	Data 0.00091 (0.00091)	Tok/s 53281 (60657)	Loss/tok 3.1496 (3.1912)	Learning Rate [7.8125e-05]
2: TRAIN [2][70/6832]	Time 0.082 (0.101)	Data 0.00096 (0.00095)	Tok/s 53088 (60327)	Loss/tok 3.1475 (3.2060)	Learning Rate [7.8125e-05]
0: TRAIN [2][70/6832]	Time 0.082 (0.101)	Data 0.00118 (0.00107)	Tok/s 53017 (59500)	Loss/tok 3.1300 (3.1972)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][80/6832]	Time 0.058 (0.102)	Data 0.00104 (0.00095)	Tok/s 51126 (60089)	Loss/tok 2.7865 (3.2013)	Learning Rate [7.8125e-05]
3: TRAIN [2][80/6832]	Time 0.058 (0.102)	Data 0.00098 (0.00091)	Tok/s 53033 (60439)	Loss/tok 2.8409 (3.1891)	Learning Rate [7.8125e-05]
1: TRAIN [2][80/6832]	Time 0.058 (0.102)	Data 0.00099 (0.00093)	Tok/s 50781 (59678)	Loss/tok 2.6383 (3.2074)	Learning Rate [7.8125e-05]
0: TRAIN [2][80/6832]	Time 0.058 (0.102)	Data 0.00107 (0.00107)	Tok/s 50578 (59314)	Loss/tok 2.6749 (3.1964)	Learning Rate [7.8125e-05]
2: TRAIN [2][90/6832]	Time 0.117 (0.100)	Data 0.00091 (0.00095)	Tok/s 52519 (59350)	Loss/tok 3.2070 (3.1970)	Learning Rate [7.8125e-05]
3: TRAIN [2][90/6832]	Time 0.117 (0.100)	Data 0.00084 (0.00090)	Tok/s 52512 (59722)	Loss/tok 3.1386 (3.1825)	Learning Rate [7.8125e-05]
1: TRAIN [2][90/6832]	Time 0.117 (0.100)	Data 0.00087 (0.00093)	Tok/s 51796 (58890)	Loss/tok 3.1519 (3.2033)	Learning Rate [7.8125e-05]
0: TRAIN [2][90/6832]	Time 0.117 (0.100)	Data 0.00106 (0.00107)	Tok/s 51273 (58388)	Loss/tok 3.1804 (3.1899)	Learning Rate [7.8125e-05]
2: TRAIN [2][100/6832]	Time 0.055 (0.099)	Data 0.00092 (0.00094)	Tok/s 50788 (58952)	Loss/tok 2.8877 (3.1872)	Learning Rate [7.8125e-05]
3: TRAIN [2][100/6832]	Time 0.055 (0.099)	Data 0.00086 (0.00090)	Tok/s 51461 (59312)	Loss/tok 2.8022 (3.1756)	Learning Rate [7.8125e-05]
1: TRAIN [2][100/6832]	Time 0.055 (0.099)	Data 0.00088 (0.00093)	Tok/s 50801 (58528)	Loss/tok 2.8239 (3.1919)	Learning Rate [7.8125e-05]
0: TRAIN [2][100/6832]	Time 0.056 (0.099)	Data 0.00117 (0.00107)	Tok/s 49473 (58035)	Loss/tok 2.5663 (3.1822)	Learning Rate [7.8125e-05]
2: TRAIN [2][110/6832]	Time 0.119 (0.099)	Data 0.00102 (0.00094)	Tok/s 51529 (59001)	Loss/tok 3.2313 (3.1927)	Learning Rate [7.8125e-05]
1: TRAIN [2][110/6832]	Time 0.119 (0.099)	Data 0.00092 (0.00092)	Tok/s 51489 (58595)	Loss/tok 3.2704 (3.1897)	Learning Rate [7.8125e-05]
3: TRAIN [2][110/6832]	Time 0.119 (0.099)	Data 0.00101 (0.00090)	Tok/s 51523 (59359)	Loss/tok 3.2189 (3.1768)	Learning Rate [7.8125e-05]
0: TRAIN [2][110/6832]	Time 0.119 (0.099)	Data 0.00106 (0.00107)	Tok/s 50391 (58124)	Loss/tok 3.2598 (3.1864)	Learning Rate [7.8125e-05]
2: TRAIN [2][120/6832]	Time 0.118 (0.099)	Data 0.00091 (0.00094)	Tok/s 55306 (58900)	Loss/tok 3.2185 (3.1931)	Learning Rate [7.8125e-05]
3: TRAIN [2][120/6832]	Time 0.118 (0.099)	Data 0.00086 (0.00090)	Tok/s 55298 (59285)	Loss/tok 3.0916 (3.1758)	Learning Rate [7.8125e-05]
1: TRAIN [2][120/6832]	Time 0.118 (0.099)	Data 0.00087 (0.00093)	Tok/s 55263 (58496)	Loss/tok 3.1225 (3.1889)	Learning Rate [7.8125e-05]
0: TRAIN [2][120/6832]	Time 0.118 (0.099)	Data 0.00113 (0.00107)	Tok/s 55122 (58029)	Loss/tok 3.1150 (3.1829)	Learning Rate [7.8125e-05]
1: TRAIN [2][130/6832]	Time 0.120 (0.100)	Data 0.00086 (0.00092)	Tok/s 54220 (58690)	Loss/tok 3.2865 (3.1911)	Learning Rate [7.8125e-05]
3: TRAIN [2][130/6832]	Time 0.120 (0.100)	Data 0.00085 (0.00090)	Tok/s 54732 (59479)	Loss/tok 3.2700 (3.1797)	Learning Rate [7.8125e-05]
2: TRAIN [2][130/6832]	Time 0.120 (0.100)	Data 0.00090 (0.00094)	Tok/s 54219 (59071)	Loss/tok 3.2746 (3.1968)	Learning Rate [7.8125e-05]
0: TRAIN [2][130/6832]	Time 0.120 (0.099)	Data 0.00093 (0.00106)	Tok/s 54238 (58251)	Loss/tok 3.2896 (3.1875)	Learning Rate [7.8125e-05]
1: TRAIN [2][140/6832]	Time 0.097 (0.099)	Data 0.00094 (0.00092)	Tok/s 52776 (58531)	Loss/tok 3.1290 (3.1931)	Learning Rate [7.8125e-05]
0: TRAIN [2][140/6832]	Time 0.097 (0.099)	Data 0.00102 (0.00107)	Tok/s 52830 (58094)	Loss/tok 3.1197 (3.1844)	Learning Rate [7.8125e-05]
3: TRAIN [2][140/6832]	Time 0.097 (0.099)	Data 0.00096 (0.00090)	Tok/s 54067 (59334)	Loss/tok 3.0542 (3.1774)	Learning Rate [7.8125e-05]
2: TRAIN [2][140/6832]	Time 0.097 (0.099)	Data 0.00100 (0.00094)	Tok/s 53350 (58918)	Loss/tok 3.0878 (3.1973)	Learning Rate [7.8125e-05]
3: TRAIN [2][150/6832]	Time 0.103 (0.100)	Data 0.00084 (0.00090)	Tok/s 53300 (59505)	Loss/tok 3.3201 (3.1826)	Learning Rate [7.8125e-05]
2: TRAIN [2][150/6832]	Time 0.103 (0.100)	Data 0.00091 (0.00094)	Tok/s 53299 (59088)	Loss/tok 3.1401 (3.1982)	Learning Rate [7.8125e-05]
1: TRAIN [2][150/6832]	Time 0.103 (0.100)	Data 0.00088 (0.00092)	Tok/s 53243 (58700)	Loss/tok 2.9935 (3.1952)	Learning Rate [7.8125e-05]
0: TRAIN [2][150/6832]	Time 0.103 (0.100)	Data 0.00092 (0.00106)	Tok/s 53225 (58274)	Loss/tok 3.1654 (3.1895)	Learning Rate [7.8125e-05]
1: TRAIN [2][160/6832]	Time 0.068 (0.101)	Data 0.00091 (0.00092)	Tok/s 48917 (59012)	Loss/tok 2.9584 (3.1965)	Learning Rate [7.8125e-05]
2: TRAIN [2][160/6832]	Time 0.068 (0.101)	Data 0.00093 (0.00094)	Tok/s 48872 (59393)	Loss/tok 2.8779 (3.1992)	Learning Rate [7.8125e-05]
3: TRAIN [2][160/6832]	Time 0.068 (0.101)	Data 0.00090 (0.00090)	Tok/s 49208 (59822)	Loss/tok 3.1486 (3.1873)	Learning Rate [7.8125e-05]
0: TRAIN [2][160/6832]	Time 0.068 (0.101)	Data 0.00095 (0.00106)	Tok/s 48903 (58606)	Loss/tok 2.7371 (3.1930)	Learning Rate [7.8125e-05]
1: TRAIN [2][170/6832]	Time 0.066 (0.102)	Data 0.00089 (0.00092)	Tok/s 50110 (59257)	Loss/tok 2.9541 (3.1962)	Learning Rate [7.8125e-05]
2: TRAIN [2][170/6832]	Time 0.066 (0.102)	Data 0.00091 (0.00094)	Tok/s 50096 (59645)	Loss/tok 2.7994 (3.1992)	Learning Rate [7.8125e-05]
3: TRAIN [2][170/6832]	Time 0.067 (0.102)	Data 0.00086 (0.00090)	Tok/s 50636 (60078)	Loss/tok 2.9993 (3.1870)	Learning Rate [7.8125e-05]
0: TRAIN [2][170/6832]	Time 0.066 (0.102)	Data 0.00099 (0.00105)	Tok/s 50135 (58850)	Loss/tok 3.0490 (3.1961)	Learning Rate [7.8125e-05]
1: TRAIN [2][180/6832]	Time 0.067 (0.101)	Data 0.00090 (0.00092)	Tok/s 51522 (59275)	Loss/tok 3.0624 (3.1967)	Learning Rate [7.8125e-05]
2: TRAIN [2][180/6832]	Time 0.067 (0.101)	Data 0.00091 (0.00094)	Tok/s 51507 (59660)	Loss/tok 2.8826 (3.1967)	Learning Rate [7.8125e-05]
3: TRAIN [2][180/6832]	Time 0.067 (0.101)	Data 0.00087 (0.00090)	Tok/s 52270 (60097)	Loss/tok 2.9850 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [2][180/6832]	Time 0.067 (0.101)	Data 0.00097 (0.00105)	Tok/s 51517 (58872)	Loss/tok 2.8648 (3.1916)	Learning Rate [7.8125e-05]
1: TRAIN [2][190/6832]	Time 0.132 (0.101)	Data 0.00091 (0.00092)	Tok/s 85407 (59271)	Loss/tok 3.2022 (3.1946)	Learning Rate [7.8125e-05]
2: TRAIN [2][190/6832]	Time 0.132 (0.101)	Data 0.00091 (0.00094)	Tok/s 86169 (59656)	Loss/tok 3.1655 (3.1962)	Learning Rate [7.8125e-05]
3: TRAIN [2][190/6832]	Time 0.132 (0.101)	Data 0.00087 (0.00090)	Tok/s 86475 (60091)	Loss/tok 3.2183 (3.1859)	Learning Rate [7.8125e-05]
0: TRAIN [2][190/6832]	Time 0.132 (0.101)	Data 0.00094 (0.00105)	Tok/s 84864 (58879)	Loss/tok 2.9939 (3.1904)	Learning Rate [7.8125e-05]
1: TRAIN [2][200/6832]	Time 0.126 (0.102)	Data 0.00089 (0.00092)	Tok/s 58851 (59352)	Loss/tok 3.4231 (3.1997)	Learning Rate [7.8125e-05]
3: TRAIN [2][200/6832]	Time 0.126 (0.102)	Data 0.00089 (0.00090)	Tok/s 58801 (60167)	Loss/tok 3.3860 (3.1918)	Learning Rate [7.8125e-05]
2: TRAIN [2][200/6832]	Time 0.126 (0.102)	Data 0.00093 (0.00094)	Tok/s 58799 (59731)	Loss/tok 3.0670 (3.1969)	Learning Rate [7.8125e-05]
0: TRAIN [2][200/6832]	Time 0.126 (0.102)	Data 0.00095 (0.00104)	Tok/s 58818 (58969)	Loss/tok 3.4281 (3.1903)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [2][210/6832]	Time 0.120 (0.102)	Data 0.00090 (0.00092)	Tok/s 60253 (59236)	Loss/tok 3.1534 (3.1974)	Learning Rate [7.8125e-05]
3: TRAIN [2][210/6832]	Time 0.120 (0.102)	Data 0.00088 (0.00090)	Tok/s 60713 (60045)	Loss/tok 3.3958 (3.1930)	Learning Rate [7.8125e-05]
2: TRAIN [2][210/6832]	Time 0.120 (0.102)	Data 0.00091 (0.00094)	Tok/s 60712 (59605)	Loss/tok 3.2557 (3.1943)	Learning Rate [7.8125e-05]
0: TRAIN [2][210/6832]	Time 0.120 (0.102)	Data 0.00101 (0.00104)	Tok/s 59643 (58855)	Loss/tok 3.2731 (3.1931)	Learning Rate [7.8125e-05]
1: TRAIN [2][220/6832]	Time 0.121 (0.103)	Data 0.00087 (0.00092)	Tok/s 53742 (59316)	Loss/tok 3.4298 (3.2038)	Learning Rate [7.8125e-05]
2: TRAIN [2][220/6832]	Time 0.121 (0.103)	Data 0.00088 (0.00094)	Tok/s 53741 (59674)	Loss/tok 3.1553 (3.1962)	Learning Rate [7.8125e-05]
3: TRAIN [2][220/6832]	Time 0.121 (0.103)	Data 0.00085 (0.00090)	Tok/s 53741 (60107)	Loss/tok 3.3730 (3.1975)	Learning Rate [7.8125e-05]
0: TRAIN [2][220/6832]	Time 0.121 (0.103)	Data 0.00091 (0.00104)	Tok/s 53772 (58938)	Loss/tok 3.2238 (3.1990)	Learning Rate [7.8125e-05]
1: TRAIN [2][230/6832]	Time 0.048 (0.102)	Data 0.00087 (0.00092)	Tok/s 43301 (59151)	Loss/tok 2.5273 (3.2026)	Learning Rate [7.8125e-05]
2: TRAIN [2][230/6832]	Time 0.048 (0.102)	Data 0.00099 (0.00094)	Tok/s 45150 (59507)	Loss/tok 2.3822 (3.1945)	Learning Rate [7.8125e-05]
3: TRAIN [2][230/6832]	Time 0.048 (0.102)	Data 0.00092 (0.00090)	Tok/s 47391 (59954)	Loss/tok 2.6030 (3.1981)	Learning Rate [7.8125e-05]
0: TRAIN [2][230/6832]	Time 0.048 (0.102)	Data 0.00094 (0.00104)	Tok/s 40646 (58774)	Loss/tok 2.1724 (3.1982)	Learning Rate [7.8125e-05]
2: TRAIN [2][240/6832]	Time 0.090 (0.103)	Data 0.00085 (0.00094)	Tok/s 53842 (59712)	Loss/tok 2.9802 (3.1960)	Learning Rate [7.8125e-05]
3: TRAIN [2][240/6832]	Time 0.090 (0.103)	Data 0.00084 (0.00090)	Tok/s 53820 (60148)	Loss/tok 3.1309 (3.1987)	Learning Rate [7.8125e-05]
1: TRAIN [2][240/6832]	Time 0.090 (0.103)	Data 0.00084 (0.00092)	Tok/s 53235 (59356)	Loss/tok 3.0329 (3.2054)	Learning Rate [7.8125e-05]
0: TRAIN [2][240/6832]	Time 0.090 (0.103)	Data 0.00095 (0.00104)	Tok/s 52395 (58986)	Loss/tok 3.2173 (3.2004)	Learning Rate [7.8125e-05]
1: TRAIN [2][250/6832]	Time 0.130 (0.103)	Data 0.00094 (0.00092)	Tok/s 67975 (59601)	Loss/tok 3.2769 (3.2084)	Learning Rate [7.8125e-05]
3: TRAIN [2][250/6832]	Time 0.130 (0.103)	Data 0.00090 (0.00090)	Tok/s 68060 (60394)	Loss/tok 3.2660 (3.1995)	Learning Rate [7.8125e-05]
2: TRAIN [2][250/6832]	Time 0.130 (0.103)	Data 0.00093 (0.00094)	Tok/s 67953 (59950)	Loss/tok 3.3229 (3.1999)	Learning Rate [7.8125e-05]
0: TRAIN [2][250/6832]	Time 0.130 (0.103)	Data 0.00095 (0.00104)	Tok/s 67822 (59234)	Loss/tok 3.2756 (3.1993)	Learning Rate [7.8125e-05]
1: TRAIN [2][260/6832]	Time 0.073 (0.103)	Data 0.00092 (0.00092)	Tok/s 52272 (59377)	Loss/tok 3.1035 (3.2090)	Learning Rate [7.8125e-05]
3: TRAIN [2][260/6832]	Time 0.073 (0.103)	Data 0.00093 (0.00090)	Tok/s 52836 (60198)	Loss/tok 3.1218 (3.1996)	Learning Rate [7.8125e-05]
2: TRAIN [2][260/6832]	Time 0.073 (0.103)	Data 0.00094 (0.00094)	Tok/s 52842 (59747)	Loss/tok 3.0200 (3.1997)	Learning Rate [7.8125e-05]
0: TRAIN [2][260/6832]	Time 0.073 (0.103)	Data 0.00103 (0.00103)	Tok/s 51029 (58969)	Loss/tok 2.9852 (3.1989)	Learning Rate [7.8125e-05]
2: TRAIN [2][270/6832]	Time 0.129 (0.103)	Data 0.00098 (0.00094)	Tok/s 68728 (59834)	Loss/tok 3.2985 (3.2007)	Learning Rate [7.8125e-05]
3: TRAIN [2][270/6832]	Time 0.129 (0.103)	Data 0.00095 (0.00091)	Tok/s 69438 (60287)	Loss/tok 3.2888 (3.2027)	Learning Rate [7.8125e-05]
1: TRAIN [2][270/6832]	Time 0.129 (0.103)	Data 0.00092 (0.00092)	Tok/s 68405 (59466)	Loss/tok 3.3830 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][270/6832]	Time 0.129 (0.103)	Data 0.00115 (0.00104)	Tok/s 68449 (59072)	Loss/tok 3.4252 (3.2041)	Learning Rate [7.8125e-05]
1: TRAIN [2][280/6832]	Time 0.060 (0.104)	Data 0.00082 (0.00092)	Tok/s 46807 (59445)	Loss/tok 2.7566 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][280/6832]	Time 0.060 (0.104)	Data 0.00088 (0.00095)	Tok/s 46858 (59807)	Loss/tok 2.7385 (3.2003)	Learning Rate [7.8125e-05]
3: TRAIN [2][280/6832]	Time 0.060 (0.104)	Data 0.00085 (0.00091)	Tok/s 48892 (60256)	Loss/tok 2.7736 (3.2039)	Learning Rate [7.8125e-05]
0: TRAIN [2][280/6832]	Time 0.060 (0.104)	Data 0.00102 (0.00104)	Tok/s 46801 (59061)	Loss/tok 2.7217 (3.2044)	Learning Rate [7.8125e-05]
1: TRAIN [2][290/6832]	Time 0.070 (0.104)	Data 0.00082 (0.00091)	Tok/s 51190 (59414)	Loss/tok 2.9445 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][290/6832]	Time 0.070 (0.104)	Data 0.00089 (0.00095)	Tok/s 51167 (59780)	Loss/tok 2.9704 (3.2023)	Learning Rate [7.8125e-05]
3: TRAIN [2][290/6832]	Time 0.070 (0.104)	Data 0.00086 (0.00091)	Tok/s 51186 (60224)	Loss/tok 2.7805 (3.2045)	Learning Rate [7.8125e-05]
0: TRAIN [2][290/6832]	Time 0.070 (0.104)	Data 0.00108 (0.00104)	Tok/s 51196 (59029)	Loss/tok 2.8804 (3.2053)	Learning Rate [7.8125e-05]
1: TRAIN [2][300/6832]	Time 0.118 (0.104)	Data 0.00082 (0.00091)	Tok/s 50948 (59457)	Loss/tok 3.1922 (3.2101)	Learning Rate [7.8125e-05]
3: TRAIN [2][300/6832]	Time 0.118 (0.104)	Data 0.00087 (0.00091)	Tok/s 50947 (60272)	Loss/tok 3.3464 (3.2046)	Learning Rate [7.8125e-05]
2: TRAIN [2][300/6832]	Time 0.118 (0.104)	Data 0.00088 (0.00095)	Tok/s 50916 (59827)	Loss/tok 3.2482 (3.2005)	Learning Rate [7.8125e-05]
0: TRAIN [2][300/6832]	Time 0.118 (0.104)	Data 0.00106 (0.00104)	Tok/s 50945 (59077)	Loss/tok 3.2130 (3.2036)	Learning Rate [7.8125e-05]
1: TRAIN [2][310/6832]	Time 0.085 (0.104)	Data 0.00085 (0.00091)	Tok/s 50916 (59666)	Loss/tok 3.1527 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][310/6832]	Time 0.085 (0.104)	Data 0.00092 (0.00091)	Tok/s 50914 (60506)	Loss/tok 3.1141 (3.2060)	Learning Rate [7.8125e-05]
0: TRAIN [2][310/6832]	Time 0.086 (0.104)	Data 0.00104 (0.00104)	Tok/s 50854 (59248)	Loss/tok 3.0033 (3.2029)	Learning Rate [7.8125e-05]
2: TRAIN [2][310/6832]	Time 0.087 (0.104)	Data 0.00096 (0.00095)	Tok/s 50250 (60046)	Loss/tok 3.2814 (3.2021)	Learning Rate [7.8125e-05]
2: TRAIN [2][320/6832]	Time 0.129 (0.103)	Data 0.00089 (0.00095)	Tok/s 69590 (59865)	Loss/tok 3.2990 (3.2005)	Learning Rate [7.8125e-05]
3: TRAIN [2][320/6832]	Time 0.129 (0.103)	Data 0.00086 (0.00091)	Tok/s 70267 (60343)	Loss/tok 3.4670 (3.2038)	Learning Rate [7.8125e-05]
1: TRAIN [2][320/6832]	Time 0.129 (0.103)	Data 0.00084 (0.00091)	Tok/s 69520 (59463)	Loss/tok 3.4794 (3.2090)	Learning Rate [7.8125e-05]
0: TRAIN [2][320/6832]	Time 0.129 (0.103)	Data 0.00101 (0.00104)	Tok/s 69515 (59006)	Loss/tok 3.1842 (3.1993)	Learning Rate [7.8125e-05]
1: TRAIN [2][330/6832]	Time 0.118 (0.103)	Data 0.00086 (0.00091)	Tok/s 56438 (59386)	Loss/tok 3.3203 (3.2095)	Learning Rate [7.8125e-05]
2: TRAIN [2][330/6832]	Time 0.118 (0.103)	Data 0.00094 (0.00095)	Tok/s 56343 (59789)	Loss/tok 3.3850 (3.2012)	Learning Rate [7.8125e-05]
3: TRAIN [2][330/6832]	Time 0.118 (0.103)	Data 0.00086 (0.00092)	Tok/s 56317 (60268)	Loss/tok 3.2372 (3.2042)	Learning Rate [7.8125e-05]
0: TRAIN [2][330/6832]	Time 0.118 (0.103)	Data 0.00105 (0.00104)	Tok/s 56357 (58932)	Loss/tok 3.3400 (3.2002)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][340/6832]	Time 0.103 (0.103)	Data 0.00091 (0.00095)	Tok/s 53496 (59681)	Loss/tok 3.0806 (3.1988)	Learning Rate [7.8125e-05]
1: TRAIN [2][340/6832]	Time 0.103 (0.103)	Data 0.00083 (0.00091)	Tok/s 53467 (59265)	Loss/tok 3.3160 (3.2092)	Learning Rate [7.8125e-05]
3: TRAIN [2][340/6832]	Time 0.102 (0.103)	Data 0.00093 (0.00092)	Tok/s 55113 (60167)	Loss/tok 3.2222 (3.2045)	Learning Rate [7.8125e-05]
0: TRAIN [2][340/6832]	Time 0.103 (0.103)	Data 0.00101 (0.00104)	Tok/s 53451 (58785)	Loss/tok 3.0687 (3.2000)	Learning Rate [7.8125e-05]
1: TRAIN [2][350/6832]	Time 0.066 (0.103)	Data 0.00090 (0.00091)	Tok/s 46610 (59287)	Loss/tok 2.9058 (3.2074)	Learning Rate [7.8125e-05]
2: TRAIN [2][350/6832]	Time 0.066 (0.103)	Data 0.00094 (0.00095)	Tok/s 46852 (59696)	Loss/tok 2.7922 (3.1981)	Learning Rate [7.8125e-05]
3: TRAIN [2][350/6832]	Time 0.066 (0.103)	Data 0.00089 (0.00092)	Tok/s 48532 (60193)	Loss/tok 2.9658 (3.2039)	Learning Rate [7.8125e-05]
0: TRAIN [2][350/6832]	Time 0.066 (0.103)	Data 0.00478 (0.00106)	Tok/s 46620 (58817)	Loss/tok 2.9498 (3.2007)	Learning Rate [7.8125e-05]
2: TRAIN [2][360/6832]	Time 0.082 (0.103)	Data 0.00092 (0.00095)	Tok/s 54657 (59568)	Loss/tok 3.1135 (3.1987)	Learning Rate [7.8125e-05]
1: TRAIN [2][360/6832]	Time 0.082 (0.103)	Data 0.00090 (0.00091)	Tok/s 54604 (59155)	Loss/tok 3.1225 (3.2074)	Learning Rate [7.8125e-05]
3: TRAIN [2][360/6832]	Time 0.082 (0.103)	Data 0.00091 (0.00092)	Tok/s 54645 (60057)	Loss/tok 2.9975 (3.2030)	Learning Rate [7.8125e-05]
0: TRAIN [2][360/6832]	Time 0.082 (0.103)	Data 0.00106 (0.00106)	Tok/s 54205 (58687)	Loss/tok 3.2235 (3.2010)	Learning Rate [7.8125e-05]
1: TRAIN [2][370/6832]	Time 0.124 (0.103)	Data 0.00087 (0.00091)	Tok/s 57598 (59187)	Loss/tok 3.3534 (3.2088)	Learning Rate [7.8125e-05]
2: TRAIN [2][370/6832]	Time 0.124 (0.103)	Data 0.00095 (0.00095)	Tok/s 57592 (59592)	Loss/tok 3.3089 (3.2028)	Learning Rate [7.8125e-05]
3: TRAIN [2][370/6832]	Time 0.125 (0.103)	Data 0.00088 (0.00092)	Tok/s 57572 (60077)	Loss/tok 3.3142 (3.2078)	Learning Rate [7.8125e-05]
0: TRAIN [2][370/6832]	Time 0.124 (0.103)	Data 0.00104 (0.00106)	Tok/s 56614 (58722)	Loss/tok 3.3183 (3.2045)	Learning Rate [7.8125e-05]
1: TRAIN [2][380/6832]	Time 0.125 (0.103)	Data 0.00086 (0.00091)	Tok/s 62495 (59122)	Loss/tok 3.2747 (3.2096)	Learning Rate [7.8125e-05]
2: TRAIN [2][380/6832]	Time 0.125 (0.103)	Data 0.00090 (0.00095)	Tok/s 63465 (59524)	Loss/tok 3.3356 (3.2022)	Learning Rate [7.8125e-05]
3: TRAIN [2][380/6832]	Time 0.125 (0.103)	Data 0.00092 (0.00092)	Tok/s 63478 (60000)	Loss/tok 3.3949 (3.2067)	Learning Rate [7.8125e-05]
0: TRAIN [2][380/6832]	Time 0.125 (0.103)	Data 0.00104 (0.00106)	Tok/s 62399 (58666)	Loss/tok 3.3836 (3.2043)	Learning Rate [7.8125e-05]
1: TRAIN [2][390/6832]	Time 0.130 (0.103)	Data 0.00092 (0.00091)	Tok/s 67127 (59263)	Loss/tok 3.2858 (3.2101)	Learning Rate [7.8125e-05]
3: TRAIN [2][390/6832]	Time 0.130 (0.103)	Data 0.00090 (0.00093)	Tok/s 67847 (60144)	Loss/tok 3.3928 (3.2079)	Learning Rate [7.8125e-05]
0: TRAIN [2][390/6832]	Time 0.130 (0.103)	Data 0.00105 (0.00106)	Tok/s 67159 (58808)	Loss/tok 3.1773 (3.2048)	Learning Rate [7.8125e-05]
2: TRAIN [2][390/6832]	Time 0.130 (0.103)	Data 0.00095 (0.00096)	Tok/s 66760 (59665)	Loss/tok 3.3121 (3.2029)	Learning Rate [7.8125e-05]
2: TRAIN [2][400/6832]	Time 0.090 (0.103)	Data 0.00122 (0.00096)	Tok/s 50945 (59738)	Loss/tok 3.1151 (3.2018)	Learning Rate [7.8125e-05]
3: TRAIN [2][400/6832]	Time 0.090 (0.103)	Data 0.00122 (0.00093)	Tok/s 52253 (60216)	Loss/tok 3.2269 (3.2073)	Learning Rate [7.8125e-05]
1: TRAIN [2][400/6832]	Time 0.091 (0.103)	Data 0.00101 (0.00091)	Tok/s 50851 (59335)	Loss/tok 3.0979 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][400/6832]	Time 0.091 (0.103)	Data 0.00113 (0.00106)	Tok/s 50909 (58879)	Loss/tok 3.0156 (3.2024)	Learning Rate [7.8125e-05]
1: TRAIN [2][410/6832]	Time 0.131 (0.104)	Data 0.00095 (0.00091)	Tok/s 85666 (59388)	Loss/tok 3.1678 (3.2094)	Learning Rate [7.8125e-05]
3: TRAIN [2][410/6832]	Time 0.132 (0.104)	Data 0.00166 (0.00093)	Tok/s 87136 (60263)	Loss/tok 3.0544 (3.2065)	Learning Rate [7.8125e-05]
2: TRAIN [2][410/6832]	Time 0.132 (0.104)	Data 0.00097 (0.00096)	Tok/s 86228 (59786)	Loss/tok 3.0608 (3.2000)	Learning Rate [7.8125e-05]
0: TRAIN [2][410/6832]	Time 0.131 (0.104)	Data 0.00105 (0.00106)	Tok/s 85382 (58934)	Loss/tok 3.3267 (3.2022)	Learning Rate [7.8125e-05]
2: TRAIN [2][420/6832]	Time 0.115 (0.103)	Data 0.00093 (0.00096)	Tok/s 63443 (59700)	Loss/tok 3.4057 (3.1999)	Learning Rate [7.8125e-05]
1: TRAIN [2][420/6832]	Time 0.115 (0.103)	Data 0.00087 (0.00091)	Tok/s 63433 (59305)	Loss/tok 3.2412 (3.2085)	Learning Rate [7.8125e-05]
3: TRAIN [2][420/6832]	Time 0.115 (0.103)	Data 0.00085 (0.00093)	Tok/s 63663 (60176)	Loss/tok 3.1680 (3.2054)	Learning Rate [7.8125e-05]
0: TRAIN [2][420/6832]	Time 0.115 (0.103)	Data 0.00102 (0.00106)	Tok/s 63378 (58848)	Loss/tok 3.2655 (3.2014)	Learning Rate [7.8125e-05]
1: TRAIN [2][430/6832]	Time 0.054 (0.103)	Data 0.00087 (0.00091)	Tok/s 48637 (59297)	Loss/tok 2.6999 (3.2085)	Learning Rate [7.8125e-05]
3: TRAIN [2][430/6832]	Time 0.054 (0.103)	Data 0.00085 (0.00093)	Tok/s 50098 (60187)	Loss/tok 2.7357 (3.2050)	Learning Rate [7.8125e-05]
2: TRAIN [2][430/6832]	Time 0.054 (0.103)	Data 0.00093 (0.00096)	Tok/s 50097 (59710)	Loss/tok 2.7654 (3.2004)	Learning Rate [7.8125e-05]
0: TRAIN [2][430/6832]	Time 0.054 (0.103)	Data 0.00108 (0.00106)	Tok/s 47679 (58812)	Loss/tok 2.6399 (3.2005)	Learning Rate [7.8125e-05]
1: TRAIN [2][440/6832]	Time 0.117 (0.103)	Data 0.00085 (0.00091)	Tok/s 59269 (59306)	Loss/tok 3.4820 (3.2089)	Learning Rate [7.8125e-05]
2: TRAIN [2][440/6832]	Time 0.117 (0.103)	Data 0.00091 (0.00096)	Tok/s 59253 (59718)	Loss/tok 3.2307 (3.1997)	Learning Rate [7.8125e-05]
3: TRAIN [2][440/6832]	Time 0.117 (0.103)	Data 0.00087 (0.00093)	Tok/s 59262 (60192)	Loss/tok 3.0455 (3.2041)	Learning Rate [7.8125e-05]
0: TRAIN [2][440/6832]	Time 0.117 (0.103)	Data 0.00112 (0.00106)	Tok/s 59231 (58822)	Loss/tok 3.1642 (3.2005)	Learning Rate [7.8125e-05]
1: TRAIN [2][450/6832]	Time 0.131 (0.103)	Data 0.00090 (0.00091)	Tok/s 66386 (59287)	Loss/tok 3.2933 (3.2089)	Learning Rate [7.8125e-05]
2: TRAIN [2][450/6832]	Time 0.131 (0.103)	Data 0.00098 (0.00096)	Tok/s 66213 (59701)	Loss/tok 3.2468 (3.1982)	Learning Rate [7.8125e-05]
3: TRAIN [2][450/6832]	Time 0.131 (0.103)	Data 0.00093 (0.00093)	Tok/s 66791 (60172)	Loss/tok 3.5146 (3.2047)	Learning Rate [7.8125e-05]
0: TRAIN [2][450/6832]	Time 0.131 (0.103)	Data 0.00105 (0.00106)	Tok/s 66364 (58808)	Loss/tok 3.3372 (3.2005)	Learning Rate [7.8125e-05]
1: TRAIN [2][460/6832]	Time 0.056 (0.103)	Data 0.00086 (0.00091)	Tok/s 50693 (59347)	Loss/tok 2.5694 (3.2071)	Learning Rate [7.8125e-05]
2: TRAIN [2][460/6832]	Time 0.056 (0.103)	Data 0.00094 (0.00096)	Tok/s 50679 (59764)	Loss/tok 2.7726 (3.1966)	Learning Rate [7.8125e-05]
3: TRAIN [2][460/6832]	Time 0.056 (0.103)	Data 0.00089 (0.00093)	Tok/s 50666 (60232)	Loss/tok 2.7815 (3.2036)	Learning Rate [7.8125e-05]
0: TRAIN [2][460/6832]	Time 0.056 (0.103)	Data 0.00112 (0.00106)	Tok/s 49422 (58865)	Loss/tok 2.7142 (3.1997)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [2][470/6832]	Time 0.132 (0.103)	Data 0.00089 (0.00091)	Tok/s 91405 (59350)	Loss/tok 3.0808 (3.2052)	Learning Rate [7.8125e-05]
3: TRAIN [2][470/6832]	Time 0.132 (0.103)	Data 0.00087 (0.00093)	Tok/s 94480 (60243)	Loss/tok 3.1741 (3.2025)	Learning Rate [7.8125e-05]
2: TRAIN [2][470/6832]	Time 0.132 (0.103)	Data 0.00090 (0.00096)	Tok/s 92565 (59764)	Loss/tok 3.0580 (3.1949)	Learning Rate [7.8125e-05]
0: TRAIN [2][470/6832]	Time 0.132 (0.103)	Data 0.00108 (0.00106)	Tok/s 90276 (58871)	Loss/tok 3.1187 (3.1991)	Learning Rate [7.8125e-05]
1: TRAIN [2][480/6832]	Time 0.117 (0.103)	Data 0.00086 (0.00091)	Tok/s 61186 (59258)	Loss/tok 3.2007 (3.2053)	Learning Rate [7.8125e-05]
3: TRAIN [2][480/6832]	Time 0.117 (0.103)	Data 0.00094 (0.00093)	Tok/s 61232 (60142)	Loss/tok 3.1597 (3.2031)	Learning Rate [7.8125e-05]
2: TRAIN [2][480/6832]	Time 0.117 (0.103)	Data 0.00096 (0.00096)	Tok/s 61222 (59669)	Loss/tok 3.2944 (3.1953)	Learning Rate [7.8125e-05]
0: TRAIN [2][480/6832]	Time 0.117 (0.103)	Data 0.00103 (0.00107)	Tok/s 60116 (58781)	Loss/tok 3.2183 (3.1991)	Learning Rate [7.8125e-05]
1: TRAIN [2][490/6832]	Time 0.077 (0.103)	Data 0.00090 (0.00091)	Tok/s 52881 (59195)	Loss/tok 2.9489 (3.2045)	Learning Rate [7.8125e-05]
2: TRAIN [2][490/6832]	Time 0.077 (0.103)	Data 0.00093 (0.00096)	Tok/s 52873 (59603)	Loss/tok 3.0096 (3.1933)	Learning Rate [7.8125e-05]
3: TRAIN [2][490/6832]	Time 0.077 (0.103)	Data 0.00091 (0.00093)	Tok/s 52874 (60074)	Loss/tok 3.1391 (3.2029)	Learning Rate [7.8125e-05]
0: TRAIN [2][490/6832]	Time 0.079 (0.103)	Data 0.00108 (0.00107)	Tok/s 52158 (58720)	Loss/tok 2.8962 (3.1982)	Learning Rate [7.8125e-05]
2: TRAIN [2][500/6832]	Time 0.131 (0.103)	Data 0.00089 (0.00096)	Tok/s 82495 (59647)	Loss/tok 3.2669 (3.1953)	Learning Rate [7.8125e-05]
1: TRAIN [2][500/6832]	Time 0.131 (0.103)	Data 0.00098 (0.00091)	Tok/s 82300 (59245)	Loss/tok 3.2208 (3.2051)	Learning Rate [7.8125e-05]
3: TRAIN [2][500/6832]	Time 0.131 (0.103)	Data 0.00085 (0.00093)	Tok/s 83196 (60115)	Loss/tok 3.2226 (3.2051)	Learning Rate [7.8125e-05]
0: TRAIN [2][500/6832]	Time 0.131 (0.103)	Data 0.00103 (0.00107)	Tok/s 81558 (58772)	Loss/tok 3.3293 (3.1998)	Learning Rate [7.8125e-05]
1: TRAIN [2][510/6832]	Time 0.099 (0.103)	Data 0.00086 (0.00091)	Tok/s 53727 (59286)	Loss/tok 3.1340 (3.2058)	Learning Rate [7.8125e-05]
0: TRAIN [2][510/6832]	Time 0.099 (0.103)	Data 0.00106 (0.00106)	Tok/s 52949 (58809)	Loss/tok 3.0701 (3.2006)	Learning Rate [7.8125e-05]
2: TRAIN [2][510/6832]	Time 0.099 (0.103)	Data 0.00103 (0.00096)	Tok/s 54248 (59684)	Loss/tok 3.2267 (3.1957)	Learning Rate [7.8125e-05]
3: TRAIN [2][510/6832]	Time 0.099 (0.103)	Data 0.00099 (0.00093)	Tok/s 54224 (60149)	Loss/tok 3.1483 (3.2048)	Learning Rate [7.8125e-05]
1: TRAIN [2][520/6832]	Time 0.120 (0.103)	Data 0.00091 (0.00091)	Tok/s 55456 (59367)	Loss/tok 3.2589 (3.2054)	Learning Rate [7.8125e-05]
0: TRAIN [2][520/6832]	Time 0.120 (0.103)	Data 0.00098 (0.00106)	Tok/s 55467 (58890)	Loss/tok 3.3366 (3.2000)	Learning Rate [7.8125e-05]
2: TRAIN [2][520/6832]	Time 0.120 (0.103)	Data 0.00095 (0.00096)	Tok/s 55433 (59766)	Loss/tok 3.2353 (3.1960)	Learning Rate [7.8125e-05]
3: TRAIN [2][520/6832]	Time 0.120 (0.103)	Data 0.00091 (0.00093)	Tok/s 55442 (60233)	Loss/tok 3.2406 (3.2058)	Learning Rate [7.8125e-05]
1: TRAIN [2][530/6832]	Time 0.118 (0.103)	Data 0.00088 (0.00091)	Tok/s 55321 (59515)	Loss/tok 3.1681 (3.2057)	Learning Rate [7.8125e-05]
2: TRAIN [2][530/6832]	Time 0.118 (0.103)	Data 0.00089 (0.00096)	Tok/s 55298 (59912)	Loss/tok 3.3713 (3.1957)	Learning Rate [7.8125e-05]
3: TRAIN [2][530/6832]	Time 0.118 (0.103)	Data 0.00086 (0.00093)	Tok/s 55301 (60381)	Loss/tok 3.2235 (3.2059)	Learning Rate [7.8125e-05]
0: TRAIN [2][530/6832]	Time 0.118 (0.103)	Data 0.00097 (0.00106)	Tok/s 55314 (59040)	Loss/tok 3.4140 (3.2011)	Learning Rate [7.8125e-05]
1: TRAIN [2][540/6832]	Time 0.131 (0.103)	Data 0.00090 (0.00091)	Tok/s 76931 (59606)	Loss/tok 3.2694 (3.2063)	Learning Rate [7.8125e-05]
0: TRAIN [2][540/6832]	Time 0.131 (0.103)	Data 0.00102 (0.00106)	Tok/s 76283 (59113)	Loss/tok 3.1105 (3.2003)	Learning Rate [7.8125e-05]
2: TRAIN [2][540/6832]	Time 0.132 (0.103)	Data 0.00090 (0.00096)	Tok/s 76867 (60005)	Loss/tok 3.1988 (3.1969)	Learning Rate [7.8125e-05]
3: TRAIN [2][540/6832]	Time 0.132 (0.103)	Data 0.00088 (0.00093)	Tok/s 77632 (60479)	Loss/tok 3.3167 (3.2067)	Learning Rate [7.8125e-05]
1: TRAIN [2][550/6832]	Time 0.059 (0.103)	Data 0.00090 (0.00091)	Tok/s 51973 (59618)	Loss/tok 2.7974 (3.2069)	Learning Rate [7.8125e-05]
2: TRAIN [2][550/6832]	Time 0.059 (0.103)	Data 0.00088 (0.00096)	Tok/s 51981 (60012)	Loss/tok 2.7347 (3.1966)	Learning Rate [7.8125e-05]
3: TRAIN [2][550/6832]	Time 0.059 (0.103)	Data 0.00088 (0.00093)	Tok/s 54034 (60489)	Loss/tok 2.9305 (3.2082)	Learning Rate [7.8125e-05]
0: TRAIN [2][550/6832]	Time 0.060 (0.103)	Data 0.00103 (0.00106)	Tok/s 51353 (59129)	Loss/tok 2.7111 (3.2007)	Learning Rate [7.8125e-05]
2: TRAIN [2][560/6832]	Time 0.104 (0.103)	Data 0.00095 (0.00096)	Tok/s 54002 (60033)	Loss/tok 2.8603 (3.1962)	Learning Rate [7.8125e-05]
1: TRAIN [2][560/6832]	Time 0.104 (0.103)	Data 0.00110 (0.00091)	Tok/s 54077 (59644)	Loss/tok 3.2591 (3.2078)	Learning Rate [7.8125e-05]
0: TRAIN [2][560/6832]	Time 0.104 (0.103)	Data 0.00097 (0.00106)	Tok/s 54036 (59156)	Loss/tok 3.0284 (3.2006)	Learning Rate [7.8125e-05]
3: TRAIN [2][560/6832]	Time 0.104 (0.103)	Data 0.00097 (0.00094)	Tok/s 54176 (60509)	Loss/tok 2.9553 (3.2073)	Learning Rate [7.8125e-05]
1: TRAIN [2][570/6832]	Time 0.085 (0.104)	Data 0.00088 (0.00091)	Tok/s 52245 (59694)	Loss/tok 3.1149 (3.2078)	Learning Rate [7.8125e-05]
2: TRAIN [2][570/6832]	Time 0.085 (0.104)	Data 0.00094 (0.00096)	Tok/s 52748 (60084)	Loss/tok 2.9565 (3.1960)	Learning Rate [7.8125e-05]
0: TRAIN [2][570/6832]	Time 0.085 (0.104)	Data 0.00090 (0.00106)	Tok/s 51207 (59208)	Loss/tok 3.1526 (3.2008)	Learning Rate [7.8125e-05]
3: TRAIN [2][570/6832]	Time 0.084 (0.104)	Data 0.00108 (0.00094)	Tok/s 53133 (60555)	Loss/tok 3.1563 (3.2077)	Learning Rate [7.8125e-05]
2: TRAIN [2][580/6832]	Time 0.132 (0.104)	Data 0.00089 (0.00096)	Tok/s 88253 (60128)	Loss/tok 3.1290 (3.1960)	Learning Rate [7.8125e-05]
0: TRAIN [2][580/6832]	Time 0.132 (0.104)	Data 0.00103 (0.00105)	Tok/s 87073 (59258)	Loss/tok 3.1388 (3.2009)	Learning Rate [7.8125e-05]
1: TRAIN [2][580/6832]	Time 0.132 (0.104)	Data 0.00099 (0.00091)	Tok/s 87774 (59741)	Loss/tok 3.0769 (3.2072)	Learning Rate [7.8125e-05]
3: TRAIN [2][580/6832]	Time 0.132 (0.104)	Data 0.00104 (0.00094)	Tok/s 89093 (60601)	Loss/tok 3.1521 (3.2066)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][590/6832]	Time 0.129 (0.104)	Data 0.00133 (0.00096)	Tok/s 68413 (60229)	Loss/tok 3.3517 (3.1980)	Learning Rate [7.8125e-05]
1: TRAIN [2][590/6832]	Time 0.128 (0.104)	Data 0.00118 (0.00091)	Tok/s 68757 (59844)	Loss/tok 3.3659 (3.2083)	Learning Rate [7.8125e-05]
0: TRAIN [2][590/6832]	Time 0.129 (0.104)	Data 0.00125 (0.00105)	Tok/s 68674 (59368)	Loss/tok 3.4024 (3.2039)	Learning Rate [7.8125e-05]
3: TRAIN [2][590/6832]	Time 0.129 (0.104)	Data 0.00127 (0.00094)	Tok/s 69041 (60698)	Loss/tok 3.4821 (3.2087)	Learning Rate [7.8125e-05]
1: Gradient norm: inf
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [2][600/6832]	Time 0.069 (0.104)	Data 0.00095 (0.00091)	Tok/s 53974 (59861)	Loss/tok 3.2567 (3.2072)	Learning Rate [7.8125e-05]
0: TRAIN [2][600/6832]	Time 0.069 (0.104)	Data 0.00099 (0.00105)	Tok/s 53812 (59384)	Loss/tok 3.0030 (3.2039)	Learning Rate [7.8125e-05]
2: TRAIN [2][600/6832]	Time 0.069 (0.104)	Data 0.00113 (0.00096)	Tok/s 54754 (60245)	Loss/tok 2.8466 (3.1972)	Learning Rate [7.8125e-05]
3: TRAIN [2][600/6832]	Time 0.069 (0.104)	Data 0.00114 (0.00094)	Tok/s 55621 (60719)	Loss/tok 3.0282 (3.2082)	Learning Rate [7.8125e-05]
1: TRAIN [2][610/6832]	Time 0.127 (0.104)	Data 0.00088 (0.00091)	Tok/s 61493 (59803)	Loss/tok 3.5033 (3.2070)	Learning Rate [7.8125e-05]
2: TRAIN [2][610/6832]	Time 0.127 (0.104)	Data 0.00089 (0.00096)	Tok/s 61715 (60183)	Loss/tok 3.2841 (3.1960)	Learning Rate [7.8125e-05]
3: TRAIN [2][610/6832]	Time 0.127 (0.104)	Data 0.00089 (0.00094)	Tok/s 62525 (60656)	Loss/tok 3.5069 (3.2080)	Learning Rate [7.8125e-05]
0: TRAIN [2][610/6832]	Time 0.127 (0.104)	Data 0.00099 (0.00105)	Tok/s 61500 (59328)	Loss/tok 3.2608 (3.2031)	Learning Rate [7.8125e-05]
1: TRAIN [2][620/6832]	Time 0.127 (0.104)	Data 0.00094 (0.00091)	Tok/s 60403 (59889)	Loss/tok 3.1392 (3.2074)	Learning Rate [7.8125e-05]
2: TRAIN [2][620/6832]	Time 0.127 (0.104)	Data 0.00091 (0.00096)	Tok/s 61278 (60273)	Loss/tok 3.5466 (3.1976)	Learning Rate [7.8125e-05]
3: TRAIN [2][620/6832]	Time 0.127 (0.104)	Data 0.00091 (0.00094)	Tok/s 61493 (60742)	Loss/tok 3.3522 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][620/6832]	Time 0.127 (0.104)	Data 0.00113 (0.00105)	Tok/s 60411 (59419)	Loss/tok 3.3598 (3.2039)	Learning Rate [7.8125e-05]
2: TRAIN [2][630/6832]	Time 0.121 (0.104)	Data 0.00089 (0.00096)	Tok/s 54582 (60335)	Loss/tok 3.2446 (3.1996)	Learning Rate [7.8125e-05]
1: TRAIN [2][630/6832]	Time 0.121 (0.104)	Data 0.00096 (0.00091)	Tok/s 54047 (59953)	Loss/tok 3.3705 (3.2095)	Learning Rate [7.8125e-05]
3: TRAIN [2][630/6832]	Time 0.121 (0.104)	Data 0.00092 (0.00094)	Tok/s 55148 (60802)	Loss/tok 3.0964 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][630/6832]	Time 0.121 (0.104)	Data 0.00107 (0.00105)	Tok/s 54055 (59484)	Loss/tok 3.0630 (3.2053)	Learning Rate [7.8125e-05]
1: TRAIN [2][640/6832]	Time 0.060 (0.104)	Data 0.00091 (0.00091)	Tok/s 49134 (59979)	Loss/tok 2.7734 (3.2100)	Learning Rate [7.8125e-05]
0: TRAIN [2][640/6832]	Time 0.060 (0.104)	Data 0.00102 (0.00105)	Tok/s 49196 (59515)	Loss/tok 2.7940 (3.2049)	Learning Rate [7.8125e-05]
2: TRAIN [2][640/6832]	Time 0.060 (0.104)	Data 0.00091 (0.00096)	Tok/s 49056 (60357)	Loss/tok 2.8804 (3.2005)	Learning Rate [7.8125e-05]
3: TRAIN [2][640/6832]	Time 0.060 (0.104)	Data 0.00087 (0.00094)	Tok/s 50470 (60823)	Loss/tok 2.8562 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][650/6832]	Time 0.132 (0.104)	Data 0.00091 (0.00091)	Tok/s 83406 (60020)	Loss/tok 3.2480 (3.2099)	Learning Rate [7.8125e-05]
2: TRAIN [2][650/6832]	Time 0.132 (0.104)	Data 0.00092 (0.00096)	Tok/s 83793 (60398)	Loss/tok 3.0887 (3.2001)	Learning Rate [7.8125e-05]
0: TRAIN [2][650/6832]	Time 0.132 (0.104)	Data 0.00099 (0.00105)	Tok/s 82743 (59559)	Loss/tok 3.1482 (3.2054)	Learning Rate [7.8125e-05]
3: TRAIN [2][650/6832]	Time 0.133 (0.104)	Data 0.00089 (0.00094)	Tok/s 83706 (60860)	Loss/tok 3.4334 (3.2136)	Learning Rate [7.8125e-05]
1: TRAIN [2][660/6832]	Time 0.073 (0.104)	Data 0.00093 (0.00091)	Tok/s 51653 (60037)	Loss/tok 2.9478 (3.2100)	Learning Rate [7.8125e-05]
0: TRAIN [2][660/6832]	Time 0.073 (0.104)	Data 0.00107 (0.00105)	Tok/s 51128 (59580)	Loss/tok 2.9523 (3.2071)	Learning Rate [7.8125e-05]
2: TRAIN [2][660/6832]	Time 0.073 (0.104)	Data 0.00088 (0.00096)	Tok/s 52736 (60416)	Loss/tok 3.0328 (3.2004)	Learning Rate [7.8125e-05]
3: TRAIN [2][660/6832]	Time 0.073 (0.104)	Data 0.00093 (0.00094)	Tok/s 52745 (60876)	Loss/tok 2.9225 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][670/6832]	Time 0.131 (0.104)	Data 0.00086 (0.00096)	Tok/s 78854 (60399)	Loss/tok 3.2272 (3.1993)	Learning Rate [7.8125e-05]
1: TRAIN [2][670/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00091)	Tok/s 77903 (60017)	Loss/tok 3.3115 (3.2085)	Learning Rate [7.8125e-05]
3: TRAIN [2][670/6832]	Time 0.131 (0.104)	Data 0.00090 (0.00094)	Tok/s 78873 (60860)	Loss/tok 3.2001 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][670/6832]	Time 0.132 (0.104)	Data 0.00104 (0.00105)	Tok/s 77861 (59554)	Loss/tok 3.3183 (3.2065)	Learning Rate [7.8125e-05]
1: TRAIN [2][680/6832]	Time 0.125 (0.104)	Data 0.00092 (0.00091)	Tok/s 60260 (60037)	Loss/tok 3.1665 (3.2069)	Learning Rate [7.8125e-05]
2: TRAIN [2][680/6832]	Time 0.125 (0.104)	Data 0.00100 (0.00096)	Tok/s 61137 (60421)	Loss/tok 3.2372 (3.1989)	Learning Rate [7.8125e-05]
0: TRAIN [2][680/6832]	Time 0.125 (0.104)	Data 0.00096 (0.00105)	Tok/s 60293 (59574)	Loss/tok 3.4086 (3.2060)	Learning Rate [7.8125e-05]
3: TRAIN [2][680/6832]	Time 0.125 (0.104)	Data 0.00098 (0.00094)	Tok/s 61311 (60884)	Loss/tok 3.3155 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][690/6832]	Time 0.105 (0.104)	Data 0.00086 (0.00096)	Tok/s 53486 (60476)	Loss/tok 3.1095 (3.1989)	Learning Rate [7.8125e-05]
3: TRAIN [2][690/6832]	Time 0.105 (0.104)	Data 0.00090 (0.00094)	Tok/s 53486 (60938)	Loss/tok 3.1956 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][690/6832]	Time 0.105 (0.104)	Data 0.00101 (0.00105)	Tok/s 52271 (59630)	Loss/tok 3.1986 (3.2056)	Learning Rate [7.8125e-05]
1: TRAIN [2][690/6832]	Time 0.105 (0.104)	Data 0.00087 (0.00091)	Tok/s 53096 (60094)	Loss/tok 3.0070 (3.2071)	Learning Rate [7.8125e-05]
1: TRAIN [2][700/6832]	Time 0.132 (0.104)	Data 0.00092 (0.00091)	Tok/s 75960 (60092)	Loss/tok 3.3354 (3.2091)	Learning Rate [7.8125e-05]
2: TRAIN [2][700/6832]	Time 0.132 (0.104)	Data 0.00098 (0.00096)	Tok/s 76321 (60470)	Loss/tok 3.3448 (3.2006)	Learning Rate [7.8125e-05]
0: TRAIN [2][700/6832]	Time 0.132 (0.104)	Data 0.00099 (0.00105)	Tok/s 75377 (59634)	Loss/tok 3.1466 (3.2059)	Learning Rate [7.8125e-05]
3: TRAIN [2][700/6832]	Time 0.133 (0.104)	Data 0.00107 (0.00094)	Tok/s 76246 (60932)	Loss/tok 3.4413 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][710/6832]	Time 0.075 (0.104)	Data 0.00088 (0.00096)	Tok/s 52575 (60515)	Loss/tok 2.9539 (3.2003)	Learning Rate [7.8125e-05]
1: TRAIN [2][710/6832]	Time 0.075 (0.104)	Data 0.00089 (0.00091)	Tok/s 52581 (60142)	Loss/tok 3.0221 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][710/6832]	Time 0.075 (0.104)	Data 0.00103 (0.00104)	Tok/s 52578 (59688)	Loss/tok 3.0234 (3.2063)	Learning Rate [7.8125e-05]
3: TRAIN [2][710/6832]	Time 0.075 (0.104)	Data 0.00094 (0.00094)	Tok/s 53672 (60978)	Loss/tok 3.0214 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][720/6832]	Time 0.121 (0.104)	Data 0.00096 (0.00091)	Tok/s 54314 (60133)	Loss/tok 3.2728 (3.2099)	Learning Rate [7.8125e-05]
2: TRAIN [2][720/6832]	Time 0.121 (0.104)	Data 0.00105 (0.00096)	Tok/s 55191 (60509)	Loss/tok 3.1128 (3.2001)	Learning Rate [7.8125e-05]
0: TRAIN [2][720/6832]	Time 0.121 (0.104)	Data 0.00099 (0.00104)	Tok/s 54109 (59677)	Loss/tok 3.5159 (3.2070)	Learning Rate [7.8125e-05]
3: TRAIN [2][720/6832]	Time 0.121 (0.104)	Data 0.00107 (0.00094)	Tok/s 55185 (60973)	Loss/tok 3.1662 (3.2123)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][730/6832]	Time 0.113 (0.104)	Data 0.00092 (0.00096)	Tok/s 50753 (60424)	Loss/tok 3.3183 (3.2005)	Learning Rate [7.8125e-05]
1: TRAIN [2][730/6832]	Time 0.113 (0.104)	Data 0.00088 (0.00091)	Tok/s 50751 (60047)	Loss/tok 3.2391 (3.2095)	Learning Rate [7.8125e-05]
3: TRAIN [2][730/6832]	Time 0.113 (0.104)	Data 0.00097 (0.00094)	Tok/s 50773 (60890)	Loss/tok 3.2374 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][730/6832]	Time 0.113 (0.104)	Data 0.00135 (0.00104)	Tok/s 50799 (59590)	Loss/tok 3.1603 (3.2071)	Learning Rate [7.8125e-05]
1: TRAIN [2][740/6832]	Time 0.117 (0.104)	Data 0.00087 (0.00091)	Tok/s 54667 (59999)	Loss/tok 3.2813 (3.2098)	Learning Rate [7.8125e-05]
2: TRAIN [2][740/6832]	Time 0.117 (0.104)	Data 0.00087 (0.00096)	Tok/s 54609 (60375)	Loss/tok 3.2743 (3.2006)	Learning Rate [7.8125e-05]
0: TRAIN [2][740/6832]	Time 0.117 (0.104)	Data 0.00091 (0.00104)	Tok/s 54637 (59541)	Loss/tok 3.2696 (3.2066)	Learning Rate [7.8125e-05]
3: TRAIN [2][740/6832]	Time 0.117 (0.104)	Data 0.00088 (0.00094)	Tok/s 54617 (60838)	Loss/tok 3.3888 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][750/6832]	Time 0.047 (0.104)	Data 0.00088 (0.00091)	Tok/s 43291 (59974)	Loss/tok 2.4211 (3.2090)	Learning Rate [7.8125e-05]
0: TRAIN [2][750/6832]	Time 0.047 (0.104)	Data 0.00094 (0.00104)	Tok/s 40754 (59516)	Loss/tok 2.3118 (3.2064)	Learning Rate [7.8125e-05]
2: TRAIN [2][750/6832]	Time 0.047 (0.104)	Data 0.00093 (0.00096)	Tok/s 45752 (60351)	Loss/tok 2.3610 (3.2004)	Learning Rate [7.8125e-05]
3: TRAIN [2][750/6832]	Time 0.047 (0.104)	Data 0.00095 (0.00094)	Tok/s 47529 (60818)	Loss/tok 2.3037 (3.2111)	Learning Rate [7.8125e-05]
2: TRAIN [2][760/6832]	Time 0.132 (0.104)	Data 0.00092 (0.00096)	Tok/s 88853 (60375)	Loss/tok 3.1282 (3.2006)	Learning Rate [7.8125e-05]
1: TRAIN [2][760/6832]	Time 0.132 (0.104)	Data 0.00089 (0.00091)	Tok/s 88087 (59996)	Loss/tok 3.1652 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][760/6832]	Time 0.132 (0.104)	Data 0.00102 (0.00094)	Tok/s 89636 (60839)	Loss/tok 3.1275 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][760/6832]	Time 0.132 (0.104)	Data 0.00093 (0.00104)	Tok/s 87274 (59542)	Loss/tok 3.2073 (3.2072)	Learning Rate [7.8125e-05]
2: TRAIN [2][770/6832]	Time 0.131 (0.104)	Data 0.00086 (0.00096)	Tok/s 74625 (60374)	Loss/tok 3.5057 (3.2028)	Learning Rate [7.8125e-05]
1: TRAIN [2][770/6832]	Time 0.131 (0.104)	Data 0.00092 (0.00091)	Tok/s 74393 (59997)	Loss/tok 3.1197 (3.2104)	Learning Rate [7.8125e-05]
3: TRAIN [2][770/6832]	Time 0.131 (0.104)	Data 0.00092 (0.00094)	Tok/s 75410 (60837)	Loss/tok 3.4866 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][770/6832]	Time 0.131 (0.104)	Data 0.00090 (0.00104)	Tok/s 74436 (59541)	Loss/tok 3.1078 (3.2071)	Learning Rate [7.8125e-05]
1: TRAIN [2][780/6832]	Time 0.128 (0.104)	Data 0.00099 (0.00091)	Tok/s 63837 (59950)	Loss/tok 3.2689 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][780/6832]	Time 0.128 (0.104)	Data 0.00103 (0.00104)	Tok/s 63833 (59496)	Loss/tok 3.2012 (3.2057)	Learning Rate [7.8125e-05]
3: TRAIN [2][780/6832]	Time 0.128 (0.104)	Data 0.00093 (0.00094)	Tok/s 64330 (60794)	Loss/tok 3.3991 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][780/6832]	Time 0.128 (0.104)	Data 0.00092 (0.00096)	Tok/s 63803 (60328)	Loss/tok 3.2654 (3.2023)	Learning Rate [7.8125e-05]
1: TRAIN [2][790/6832]	Time 0.070 (0.104)	Data 0.00093 (0.00091)	Tok/s 51249 (59848)	Loss/tok 2.9503 (3.2089)	Learning Rate [7.8125e-05]
0: TRAIN [2][790/6832]	Time 0.070 (0.104)	Data 0.00091 (0.00103)	Tok/s 51268 (59390)	Loss/tok 2.8846 (3.2044)	Learning Rate [7.8125e-05]
3: TRAIN [2][790/6832]	Time 0.070 (0.104)	Data 0.00105 (0.00094)	Tok/s 51574 (60695)	Loss/tok 2.9078 (3.2115)	Learning Rate [7.8125e-05]
2: TRAIN [2][790/6832]	Time 0.070 (0.104)	Data 0.00112 (0.00096)	Tok/s 51309 (60228)	Loss/tok 2.8168 (3.2017)	Learning Rate [7.8125e-05]
2: TRAIN [2][800/6832]	Time 0.127 (0.104)	Data 0.00092 (0.00096)	Tok/s 63726 (60227)	Loss/tok 3.2790 (3.2012)	Learning Rate [7.8125e-05]
1: TRAIN [2][800/6832]	Time 0.127 (0.104)	Data 0.00102 (0.00091)	Tok/s 63684 (59844)	Loss/tok 3.3366 (3.2089)	Learning Rate [7.8125e-05]
3: TRAIN [2][800/6832]	Time 0.127 (0.104)	Data 0.00096 (0.00094)	Tok/s 63724 (60698)	Loss/tok 3.2496 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][800/6832]	Time 0.127 (0.104)	Data 0.00103 (0.00103)	Tok/s 63695 (59373)	Loss/tok 3.5137 (3.2046)	Learning Rate [7.8125e-05]
2: TRAIN [2][810/6832]	Time 0.130 (0.104)	Data 0.00085 (0.00096)	Tok/s 72954 (60218)	Loss/tok 3.2948 (3.2010)	Learning Rate [7.8125e-05]
1: TRAIN [2][810/6832]	Time 0.130 (0.104)	Data 0.00092 (0.00091)	Tok/s 72608 (59836)	Loss/tok 3.4690 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][810/6832]	Time 0.130 (0.104)	Data 0.00095 (0.00103)	Tok/s 71972 (59369)	Loss/tok 3.1514 (3.2045)	Learning Rate [7.8125e-05]
3: TRAIN [2][810/6832]	Time 0.130 (0.104)	Data 0.00086 (0.00094)	Tok/s 72936 (60687)	Loss/tok 3.3048 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][820/6832]	Time 0.133 (0.104)	Data 0.00095 (0.00091)	Tok/s 84788 (59878)	Loss/tok 3.2451 (3.2097)	Learning Rate [7.8125e-05]
2: TRAIN [2][820/6832]	Time 0.133 (0.104)	Data 0.00092 (0.00096)	Tok/s 85655 (60259)	Loss/tok 3.1071 (3.2017)	Learning Rate [7.8125e-05]
3: TRAIN [2][820/6832]	Time 0.133 (0.104)	Data 0.00092 (0.00094)	Tok/s 85905 (60725)	Loss/tok 3.1358 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][820/6832]	Time 0.133 (0.104)	Data 0.00092 (0.00103)	Tok/s 84372 (59415)	Loss/tok 3.2163 (3.2058)	Learning Rate [7.8125e-05]
2: TRAIN [2][830/6832]	Time 0.112 (0.104)	Data 0.00086 (0.00096)	Tok/s 51557 (60188)	Loss/tok 3.1516 (3.2015)	Learning Rate [7.8125e-05]
3: TRAIN [2][830/6832]	Time 0.112 (0.104)	Data 0.00087 (0.00094)	Tok/s 51558 (60651)	Loss/tok 3.1270 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][830/6832]	Time 0.112 (0.104)	Data 0.00092 (0.00091)	Tok/s 51547 (59806)	Loss/tok 3.2074 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][830/6832]	Time 0.112 (0.104)	Data 0.00095 (0.00103)	Tok/s 51542 (59346)	Loss/tok 3.2904 (3.2052)	Learning Rate [7.8125e-05]
1: TRAIN [2][840/6832]	Time 0.119 (0.104)	Data 0.00089 (0.00091)	Tok/s 60192 (59790)	Loss/tok 3.2013 (3.2102)	Learning Rate [7.8125e-05]
2: TRAIN [2][840/6832]	Time 0.119 (0.104)	Data 0.00087 (0.00096)	Tok/s 61244 (60173)	Loss/tok 3.3023 (3.2017)	Learning Rate [7.8125e-05]
3: TRAIN [2][840/6832]	Time 0.118 (0.104)	Data 0.00115 (0.00094)	Tok/s 61570 (60635)	Loss/tok 3.2359 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][840/6832]	Time 0.119 (0.104)	Data 0.00091 (0.00103)	Tok/s 60151 (59331)	Loss/tok 3.4322 (3.2056)	Learning Rate [7.8125e-05]
2: TRAIN [2][850/6832]	Time 0.130 (0.104)	Data 0.00094 (0.00096)	Tok/s 74989 (60204)	Loss/tok 3.2938 (3.2016)	Learning Rate [7.8125e-05]
3: TRAIN [2][850/6832]	Time 0.130 (0.104)	Data 0.00089 (0.00094)	Tok/s 75627 (60666)	Loss/tok 3.4795 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][850/6832]	Time 0.130 (0.104)	Data 0.00092 (0.00091)	Tok/s 74579 (59821)	Loss/tok 3.2634 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][850/6832]	Time 0.130 (0.104)	Data 0.00090 (0.00103)	Tok/s 74560 (59362)	Loss/tok 3.3155 (3.2055)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
3: TRAIN [2][860/6832]	Time 0.125 (0.104)	Data 0.00089 (0.00094)	Tok/s 59451 (60682)	Loss/tok 3.3110 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][860/6832]	Time 0.125 (0.104)	Data 0.00087 (0.00096)	Tok/s 59428 (60221)	Loss/tok 3.3538 (3.2024)	Learning Rate [7.8125e-05]
1: TRAIN [2][860/6832]	Time 0.125 (0.104)	Data 0.00099 (0.00091)	Tok/s 58997 (59839)	Loss/tok 3.3804 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][860/6832]	Time 0.125 (0.104)	Data 0.00089 (0.00103)	Tok/s 58375 (59382)	Loss/tok 2.9467 (3.2044)	Learning Rate [7.8125e-05]
2: TRAIN [2][870/6832]	Time 0.116 (0.104)	Data 0.00094 (0.00096)	Tok/s 59698 (60162)	Loss/tok 3.2245 (3.2027)	Learning Rate [7.8125e-05]
1: TRAIN [2][870/6832]	Time 0.116 (0.104)	Data 0.00102 (0.00091)	Tok/s 58814 (59779)	Loss/tok 3.1860 (3.2095)	Learning Rate [7.8125e-05]
3: TRAIN [2][870/6832]	Time 0.116 (0.104)	Data 0.00095 (0.00094)	Tok/s 59676 (60623)	Loss/tok 3.3268 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][870/6832]	Time 0.116 (0.104)	Data 0.00098 (0.00103)	Tok/s 58570 (59320)	Loss/tok 3.2936 (3.2043)	Learning Rate [7.8125e-05]
3: TRAIN [2][880/6832]	Time 0.090 (0.104)	Data 0.00087 (0.00094)	Tok/s 52758 (60533)	Loss/tok 3.2389 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][880/6832]	Time 0.090 (0.104)	Data 0.00091 (0.00102)	Tok/s 51298 (59212)	Loss/tok 3.1411 (3.2035)	Learning Rate [7.8125e-05]
1: TRAIN [2][880/6832]	Time 0.090 (0.104)	Data 0.00096 (0.00091)	Tok/s 51278 (59681)	Loss/tok 3.1649 (3.2088)	Learning Rate [7.8125e-05]
2: TRAIN [2][880/6832]	Time 0.090 (0.104)	Data 0.00088 (0.00096)	Tok/s 51429 (60068)	Loss/tok 2.9949 (3.2017)	Learning Rate [7.8125e-05]
2: TRAIN [2][890/6832]	Time 0.130 (0.104)	Data 0.00097 (0.00096)	Tok/s 71318 (60111)	Loss/tok 3.4012 (3.2022)	Learning Rate [7.8125e-05]
3: TRAIN [2][890/6832]	Time 0.130 (0.104)	Data 0.00111 (0.00094)	Tok/s 72137 (60576)	Loss/tok 3.3151 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][890/6832]	Time 0.130 (0.104)	Data 0.00098 (0.00091)	Tok/s 70933 (59718)	Loss/tok 3.4561 (3.2092)	Learning Rate [7.8125e-05]
0: TRAIN [2][890/6832]	Time 0.130 (0.104)	Data 0.00093 (0.00102)	Tok/s 70965 (59235)	Loss/tok 3.2238 (3.2035)	Learning Rate [7.8125e-05]
2: TRAIN [2][900/6832]	Time 0.075 (0.104)	Data 0.00087 (0.00096)	Tok/s 53169 (60122)	Loss/tok 3.0066 (3.2025)	Learning Rate [7.8125e-05]
3: TRAIN [2][900/6832]	Time 0.075 (0.104)	Data 0.00087 (0.00094)	Tok/s 53184 (60585)	Loss/tok 3.1143 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][900/6832]	Time 0.075 (0.104)	Data 0.00093 (0.00102)	Tok/s 51419 (59248)	Loss/tok 3.0637 (3.2047)	Learning Rate [7.8125e-05]
1: TRAIN [2][900/6832]	Time 0.075 (0.104)	Data 0.00097 (0.00091)	Tok/s 51951 (59729)	Loss/tok 3.0181 (3.2098)	Learning Rate [7.8125e-05]
2: TRAIN [2][910/6832]	Time 0.130 (0.104)	Data 0.00086 (0.00096)	Tok/s 77074 (60105)	Loss/tok 3.1413 (3.2033)	Learning Rate [7.8125e-05]
1: TRAIN [2][910/6832]	Time 0.130 (0.104)	Data 0.00093 (0.00091)	Tok/s 76773 (59714)	Loss/tok 3.2201 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][910/6832]	Time 0.130 (0.104)	Data 0.00088 (0.00094)	Tok/s 77066 (60567)	Loss/tok 3.2538 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][910/6832]	Time 0.130 (0.104)	Data 0.00097 (0.00102)	Tok/s 76065 (59236)	Loss/tok 3.2114 (3.2047)	Learning Rate [7.8125e-05]
1: TRAIN [2][920/6832]	Time 0.094 (0.104)	Data 0.00090 (0.00091)	Tok/s 54485 (59726)	Loss/tok 3.1554 (3.2103)	Learning Rate [7.8125e-05]
2: TRAIN [2][920/6832]	Time 0.094 (0.104)	Data 0.00100 (0.00096)	Tok/s 54578 (60115)	Loss/tok 3.1941 (3.2031)	Learning Rate [7.8125e-05]
3: TRAIN [2][920/6832]	Time 0.094 (0.104)	Data 0.00099 (0.00094)	Tok/s 54588 (60580)	Loss/tok 3.1929 (3.2104)	Learning Rate [7.8125e-05]
0: TRAIN [2][920/6832]	Time 0.094 (0.104)	Data 0.00091 (0.00102)	Tok/s 53212 (59243)	Loss/tok 3.1169 (3.2043)	Learning Rate [7.8125e-05]
1: TRAIN [2][930/6832]	Time 0.113 (0.104)	Data 0.00096 (0.00091)	Tok/s 54517 (59726)	Loss/tok 3.2469 (3.2100)	Learning Rate [7.8125e-05]
0: TRAIN [2][930/6832]	Time 0.113 (0.104)	Data 0.00102 (0.00102)	Tok/s 54499 (59245)	Loss/tok 3.2072 (3.2042)	Learning Rate [7.8125e-05]
2: TRAIN [2][930/6832]	Time 0.113 (0.104)	Data 0.00099 (0.00096)	Tok/s 55011 (60114)	Loss/tok 3.2422 (3.2033)	Learning Rate [7.8125e-05]
3: TRAIN [2][930/6832]	Time 0.113 (0.104)	Data 0.00101 (0.00094)	Tok/s 55603 (60580)	Loss/tok 3.3717 (3.2096)	Learning Rate [7.8125e-05]
2: TRAIN [2][940/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00096)	Tok/s 88307 (60193)	Loss/tok 3.0649 (3.2030)	Learning Rate [7.8125e-05]
1: TRAIN [2][940/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00091)	Tok/s 87837 (59806)	Loss/tok 3.2148 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][940/6832]	Time 0.132 (0.104)	Data 0.00091 (0.00102)	Tok/s 87058 (59327)	Loss/tok 3.1265 (3.2035)	Learning Rate [7.8125e-05]
3: TRAIN [2][940/6832]	Time 0.132 (0.104)	Data 0.00087 (0.00094)	Tok/s 89249 (60659)	Loss/tok 3.1141 (3.2094)	Learning Rate [7.8125e-05]
2: TRAIN [2][950/6832]	Time 0.127 (0.104)	Data 0.00086 (0.00096)	Tok/s 60010 (60132)	Loss/tok 3.4119 (3.2032)	Learning Rate [7.8125e-05]
1: TRAIN [2][950/6832]	Time 0.128 (0.104)	Data 0.00096 (0.00091)	Tok/s 59226 (59744)	Loss/tok 3.3997 (3.2092)	Learning Rate [7.8125e-05]
0: TRAIN [2][950/6832]	Time 0.128 (0.104)	Data 0.00096 (0.00102)	Tok/s 59198 (59266)	Loss/tok 3.3068 (3.2029)	Learning Rate [7.8125e-05]
3: TRAIN [2][950/6832]	Time 0.127 (0.104)	Data 0.00089 (0.00094)	Tok/s 60250 (60598)	Loss/tok 3.4098 (3.2097)	Learning Rate [7.8125e-05]
1: TRAIN [2][960/6832]	Time 0.131 (0.104)	Data 0.00095 (0.00091)	Tok/s 73023 (59813)	Loss/tok 3.1531 (3.2091)	Learning Rate [7.8125e-05]
2: TRAIN [2][960/6832]	Time 0.132 (0.104)	Data 0.00091 (0.00096)	Tok/s 73000 (60199)	Loss/tok 3.3471 (3.2037)	Learning Rate [7.8125e-05]
0: TRAIN [2][960/6832]	Time 0.131 (0.104)	Data 0.00098 (0.00102)	Tok/s 72693 (59339)	Loss/tok 3.5311 (3.2037)	Learning Rate [7.8125e-05]
3: TRAIN [2][960/6832]	Time 0.131 (0.104)	Data 0.00091 (0.00094)	Tok/s 73421 (60665)	Loss/tok 3.3655 (3.2106)	Learning Rate [7.8125e-05]
2: TRAIN [2][970/6832]	Time 0.109 (0.104)	Data 0.00091 (0.00096)	Tok/s 54073 (60142)	Loss/tok 3.2163 (3.2032)	Learning Rate [7.8125e-05]
3: TRAIN [2][970/6832]	Time 0.109 (0.104)	Data 0.00093 (0.00094)	Tok/s 54100 (60608)	Loss/tok 3.2249 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][970/6832]	Time 0.109 (0.104)	Data 0.00089 (0.00091)	Tok/s 53649 (59757)	Loss/tok 3.2318 (3.2088)	Learning Rate [7.8125e-05]
0: TRAIN [2][970/6832]	Time 0.109 (0.104)	Data 0.00091 (0.00101)	Tok/s 52763 (59283)	Loss/tok 3.0444 (3.2029)	Learning Rate [7.8125e-05]
1: TRAIN [2][980/6832]	Time 0.092 (0.104)	Data 0.00087 (0.00091)	Tok/s 53004 (59828)	Loss/tok 3.2022 (3.2091)	Learning Rate [7.8125e-05]
2: TRAIN [2][980/6832]	Time 0.092 (0.104)	Data 0.00084 (0.00096)	Tok/s 52944 (60214)	Loss/tok 3.1319 (3.2032)	Learning Rate [7.8125e-05]
0: TRAIN [2][980/6832]	Time 0.092 (0.104)	Data 0.00089 (0.00101)	Tok/s 53003 (59354)	Loss/tok 2.9271 (3.2031)	Learning Rate [7.8125e-05]
3: TRAIN [2][980/6832]	Time 0.092 (0.104)	Data 0.00090 (0.00094)	Tok/s 52981 (60682)	Loss/tok 3.1493 (3.2105)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][990/6832]	Time 0.091 (0.104)	Data 0.00090 (0.00091)	Tok/s 52111 (59852)	Loss/tok 3.1214 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][990/6832]	Time 0.091 (0.104)	Data 0.00093 (0.00101)	Tok/s 52003 (59379)	Loss/tok 3.1805 (3.2031)	Learning Rate [7.8125e-05]
2: TRAIN [2][990/6832]	Time 0.091 (0.104)	Data 0.00097 (0.00096)	Tok/s 52096 (60237)	Loss/tok 3.1437 (3.2033)	Learning Rate [7.8125e-05]
3: TRAIN [2][990/6832]	Time 0.091 (0.104)	Data 0.00104 (0.00094)	Tok/s 52134 (60702)	Loss/tok 3.1229 (3.2107)	Learning Rate [7.8125e-05]
2: TRAIN [2][1000/6832]	Time 0.066 (0.104)	Data 0.00090 (0.00095)	Tok/s 50531 (60262)	Loss/tok 2.9454 (3.2044)	Learning Rate [7.8125e-05]
1: TRAIN [2][1000/6832]	Time 0.066 (0.104)	Data 0.00092 (0.00091)	Tok/s 50479 (59881)	Loss/tok 2.9047 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][1000/6832]	Time 0.066 (0.104)	Data 0.00095 (0.00094)	Tok/s 52203 (60727)	Loss/tok 2.6973 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][1000/6832]	Time 0.066 (0.104)	Data 0.00098 (0.00101)	Tok/s 50544 (59410)	Loss/tok 2.9570 (3.2041)	Learning Rate [7.8125e-05]
2: TRAIN [2][1010/6832]	Time 0.088 (0.104)	Data 0.00085 (0.00095)	Tok/s 52281 (60259)	Loss/tok 3.0427 (3.2052)	Learning Rate [7.8125e-05]
1: TRAIN [2][1010/6832]	Time 0.088 (0.104)	Data 0.00093 (0.00091)	Tok/s 52275 (59879)	Loss/tok 3.1276 (3.2101)	Learning Rate [7.8125e-05]
3: TRAIN [2][1010/6832]	Time 0.088 (0.104)	Data 0.00092 (0.00094)	Tok/s 52291 (60727)	Loss/tok 3.1030 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][1010/6832]	Time 0.088 (0.104)	Data 0.00102 (0.00101)	Tok/s 50834 (59409)	Loss/tok 3.0796 (3.2039)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
1: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [2][1020/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00091)	Tok/s 54418 (59916)	Loss/tok 3.1448 (3.2106)	Learning Rate [7.8125e-05]
2: TRAIN [2][1020/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00095)	Tok/s 54419 (60294)	Loss/tok 3.0524 (3.2061)	Learning Rate [7.8125e-05]
0: TRAIN [2][1020/6832]	Time 0.089 (0.105)	Data 0.00099 (0.00101)	Tok/s 54434 (59448)	Loss/tok 3.1011 (3.2047)	Learning Rate [7.8125e-05]
3: TRAIN [2][1020/6832]	Time 0.089 (0.105)	Data 0.00091 (0.00094)	Tok/s 55473 (60765)	Loss/tok 3.0405 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][1030/6832]	Time 0.115 (0.104)	Data 0.00088 (0.00091)	Tok/s 51137 (59868)	Loss/tok 3.1384 (3.2108)	Learning Rate [7.8125e-05]
2: TRAIN [2][1030/6832]	Time 0.115 (0.104)	Data 0.00088 (0.00095)	Tok/s 51116 (60254)	Loss/tok 3.3260 (3.2057)	Learning Rate [7.8125e-05]
0: TRAIN [2][1030/6832]	Time 0.115 (0.104)	Data 0.00100 (0.00101)	Tok/s 51158 (59380)	Loss/tok 3.1375 (3.2044)	Learning Rate [7.8125e-05]
3: TRAIN [2][1030/6832]	Time 0.115 (0.104)	Data 0.00090 (0.00094)	Tok/s 51899 (60730)	Loss/tok 3.1501 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][1040/6832]	Time 0.129 (0.104)	Data 0.00092 (0.00091)	Tok/s 66547 (59877)	Loss/tok 3.4635 (3.2107)	Learning Rate [7.8125e-05]
2: TRAIN [2][1040/6832]	Time 0.129 (0.104)	Data 0.00095 (0.00095)	Tok/s 66519 (60262)	Loss/tok 3.2438 (3.2059)	Learning Rate [7.8125e-05]
0: TRAIN [2][1040/6832]	Time 0.129 (0.104)	Data 0.00100 (0.00101)	Tok/s 66547 (59391)	Loss/tok 3.4748 (3.2045)	Learning Rate [7.8125e-05]
3: TRAIN [2][1040/6832]	Time 0.129 (0.104)	Data 0.00096 (0.00094)	Tok/s 66977 (60737)	Loss/tok 3.3720 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][1050/6832]	Time 0.129 (0.104)	Data 0.00086 (0.00095)	Tok/s 66671 (60248)	Loss/tok 3.3267 (3.2059)	Learning Rate [7.8125e-05]
1: TRAIN [2][1050/6832]	Time 0.129 (0.104)	Data 0.00090 (0.00091)	Tok/s 66668 (59864)	Loss/tok 3.3748 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][1050/6832]	Time 0.129 (0.104)	Data 0.00104 (0.00101)	Tok/s 66015 (59379)	Loss/tok 3.3731 (3.2049)	Learning Rate [7.8125e-05]
3: TRAIN [2][1050/6832]	Time 0.129 (0.104)	Data 0.00093 (0.00094)	Tok/s 66673 (60725)	Loss/tok 3.3584 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][1060/6832]	Time 0.128 (0.104)	Data 0.00089 (0.00095)	Tok/s 67809 (60215)	Loss/tok 3.3798 (3.2062)	Learning Rate [7.8125e-05]
1: TRAIN [2][1060/6832]	Time 0.128 (0.104)	Data 0.00088 (0.00091)	Tok/s 67778 (59827)	Loss/tok 3.3324 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][1060/6832]	Time 0.128 (0.104)	Data 0.00100 (0.00101)	Tok/s 67701 (59334)	Loss/tok 3.2814 (3.2051)	Learning Rate [7.8125e-05]
3: TRAIN [2][1060/6832]	Time 0.128 (0.104)	Data 0.00094 (0.00094)	Tok/s 68157 (60693)	Loss/tok 3.3881 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][1070/6832]	Time 0.131 (0.104)	Data 0.00089 (0.00095)	Tok/s 72535 (60188)	Loss/tok 3.2051 (3.2052)	Learning Rate [7.8125e-05]
1: TRAIN [2][1070/6832]	Time 0.130 (0.104)	Data 0.00095 (0.00091)	Tok/s 72104 (59800)	Loss/tok 3.3302 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][1070/6832]	Time 0.130 (0.104)	Data 0.00106 (0.00101)	Tok/s 71658 (59305)	Loss/tok 3.1531 (3.2047)	Learning Rate [7.8125e-05]
3: TRAIN [2][1070/6832]	Time 0.131 (0.104)	Data 0.00087 (0.00094)	Tok/s 72540 (60669)	Loss/tok 3.3715 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][1080/6832]	Time 0.094 (0.104)	Data 0.00090 (0.00095)	Tok/s 50556 (60212)	Loss/tok 3.4843 (3.2052)	Learning Rate [7.8125e-05]
1: TRAIN [2][1080/6832]	Time 0.094 (0.104)	Data 0.00098 (0.00091)	Tok/s 50579 (59821)	Loss/tok 3.2014 (3.2105)	Learning Rate [7.8125e-05]
3: TRAIN [2][1080/6832]	Time 0.094 (0.104)	Data 0.00086 (0.00094)	Tok/s 50549 (60699)	Loss/tok 3.0189 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][1080/6832]	Time 0.094 (0.104)	Data 0.00106 (0.00101)	Tok/s 50587 (59319)	Loss/tok 3.3451 (3.2052)	Learning Rate [7.8125e-05]
2: TRAIN [2][1090/6832]	Time 0.080 (0.104)	Data 0.00088 (0.00095)	Tok/s 52949 (60214)	Loss/tok 3.0390 (3.2054)	Learning Rate [7.8125e-05]
1: TRAIN [2][1090/6832]	Time 0.080 (0.104)	Data 0.00089 (0.00091)	Tok/s 52958 (59824)	Loss/tok 3.0465 (3.2102)	Learning Rate [7.8125e-05]
3: TRAIN [2][1090/6832]	Time 0.080 (0.104)	Data 0.00090 (0.00094)	Tok/s 52980 (60698)	Loss/tok 3.1722 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][1090/6832]	Time 0.080 (0.104)	Data 0.00103 (0.00101)	Tok/s 51848 (59322)	Loss/tok 2.9855 (3.2061)	Learning Rate [7.8125e-05]
1: TRAIN [2][1100/6832]	Time 0.113 (0.104)	Data 0.00087 (0.00091)	Tok/s 55438 (59859)	Loss/tok 3.2139 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][1100/6832]	Time 0.113 (0.104)	Data 0.00101 (0.00101)	Tok/s 55430 (59359)	Loss/tok 3.3542 (3.2066)	Learning Rate [7.8125e-05]
2: TRAIN [2][1100/6832]	Time 0.113 (0.104)	Data 0.00093 (0.00095)	Tok/s 55442 (60247)	Loss/tok 3.3664 (3.2060)	Learning Rate [7.8125e-05]
3: TRAIN [2][1100/6832]	Time 0.113 (0.104)	Data 0.00093 (0.00094)	Tok/s 55406 (60731)	Loss/tok 3.2823 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][1110/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00095)	Tok/s 92734 (60269)	Loss/tok 3.1491 (3.2063)	Learning Rate [7.8125e-05]
1: TRAIN [2][1110/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00091)	Tok/s 91421 (59881)	Loss/tok 3.1406 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][1110/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 94545 (60754)	Loss/tok 3.1511 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][1110/6832]	Time 0.132 (0.105)	Data 0.00107 (0.00101)	Tok/s 90641 (59383)	Loss/tok 3.1739 (3.2068)	Learning Rate [7.8125e-05]
1: TRAIN [2][1120/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00091)	Tok/s 72837 (59935)	Loss/tok 3.2724 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][1120/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 72784 (60321)	Loss/tok 3.4389 (3.2069)	Learning Rate [7.8125e-05]
0: TRAIN [2][1120/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00101)	Tok/s 72314 (59440)	Loss/tok 3.3217 (3.2068)	Learning Rate [7.8125e-05]
3: TRAIN [2][1120/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 72913 (60804)	Loss/tok 3.3298 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][1130/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00095)	Tok/s 58071 (60299)	Loss/tok 3.3418 (3.2063)	Learning Rate [7.8125e-05]
3: TRAIN [2][1130/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00094)	Tok/s 58276 (60786)	Loss/tok 3.1347 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][1130/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00091)	Tok/s 58046 (59912)	Loss/tok 3.5694 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][1130/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00101)	Tok/s 58077 (59417)	Loss/tok 3.3482 (3.2063)	Learning Rate [7.8125e-05]
1: TRAIN [2][1140/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00091)	Tok/s 62321 (59876)	Loss/tok 3.3026 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][1140/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00095)	Tok/s 62293 (60264)	Loss/tok 3.2453 (3.2057)	Learning Rate [7.8125e-05]
0: TRAIN [2][1140/6832]	Time 0.123 (0.105)	Data 0.00104 (0.00101)	Tok/s 62317 (59384)	Loss/tok 3.3166 (3.2062)	Learning Rate [7.8125e-05]
3: TRAIN [2][1140/6832]	Time 0.123 (0.105)	Data 0.00096 (0.00094)	Tok/s 62305 (60747)	Loss/tok 3.3549 (3.2116)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][1150/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00095)	Tok/s 52748 (60285)	Loss/tok 3.0014 (3.2057)	Learning Rate [7.8125e-05]
3: TRAIN [2][1150/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00094)	Tok/s 54136 (60768)	Loss/tok 3.2051 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][1150/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00091)	Tok/s 52617 (59899)	Loss/tok 3.1600 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][1150/6832]	Time 0.088 (0.105)	Data 0.00096 (0.00101)	Tok/s 52600 (59407)	Loss/tok 3.0962 (3.2055)	Learning Rate [7.8125e-05]
2: TRAIN [2][1160/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00095)	Tok/s 51746 (60270)	Loss/tok 3.4164 (3.2057)	Learning Rate [7.8125e-05]
1: TRAIN [2][1160/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00091)	Tok/s 50727 (59884)	Loss/tok 3.1691 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][1160/6832]	Time 0.116 (0.105)	Data 0.00107 (0.00101)	Tok/s 50761 (59394)	Loss/tok 3.2779 (3.2053)	Learning Rate [7.8125e-05]
3: TRAIN [2][1160/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00094)	Tok/s 51808 (60751)	Loss/tok 3.2947 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][1170/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00095)	Tok/s 55806 (60310)	Loss/tok 3.1457 (3.2057)	Learning Rate [7.8125e-05]
1: TRAIN [2][1170/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00091)	Tok/s 54663 (59924)	Loss/tok 3.0267 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][1170/6832]	Time 0.087 (0.105)	Data 0.00097 (0.00094)	Tok/s 56135 (60790)	Loss/tok 3.1504 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][1170/6832]	Time 0.087 (0.105)	Data 0.00103 (0.00101)	Tok/s 54666 (59434)	Loss/tok 3.0396 (3.2058)	Learning Rate [7.8125e-05]
2: TRAIN [2][1180/6832]	Time 0.087 (0.105)	Data 0.00097 (0.00095)	Tok/s 53237 (60281)	Loss/tok 2.9666 (3.2058)	Learning Rate [7.8125e-05]
1: TRAIN [2][1180/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00091)	Tok/s 53212 (59896)	Loss/tok 3.0797 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][1180/6832]	Time 0.087 (0.105)	Data 0.00097 (0.00094)	Tok/s 53259 (60760)	Loss/tok 3.1828 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][1180/6832]	Time 0.087 (0.105)	Data 0.00101 (0.00101)	Tok/s 53268 (59408)	Loss/tok 2.9032 (3.2056)	Learning Rate [7.8125e-05]
2: TRAIN [2][1190/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00095)	Tok/s 51952 (60244)	Loss/tok 2.9303 (3.2056)	Learning Rate [7.8125e-05]
1: TRAIN [2][1190/6832]	Time 0.059 (0.105)	Data 0.00099 (0.00091)	Tok/s 51815 (59858)	Loss/tok 2.7796 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][1190/6832]	Time 0.059 (0.105)	Data 0.00101 (0.00101)	Tok/s 51887 (59361)	Loss/tok 2.8655 (3.2060)	Learning Rate [7.8125e-05]
3: TRAIN [2][1190/6832]	Time 0.059 (0.105)	Data 0.00098 (0.00094)	Tok/s 53906 (60725)	Loss/tok 2.8024 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][1200/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00095)	Tok/s 47679 (60242)	Loss/tok 2.7617 (3.2052)	Learning Rate [7.8125e-05]
1: TRAIN [2][1200/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00091)	Tok/s 47658 (59856)	Loss/tok 3.0634 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][1200/6832]	Time 0.070 (0.105)	Data 0.00107 (0.00101)	Tok/s 47710 (59361)	Loss/tok 2.9719 (3.2060)	Learning Rate [7.8125e-05]
3: TRAIN [2][1200/6832]	Time 0.070 (0.105)	Data 0.00098 (0.00094)	Tok/s 49315 (60724)	Loss/tok 2.9339 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][1210/6832]	Time 0.056 (0.105)	Data 0.00087 (0.00091)	Tok/s 52481 (59903)	Loss/tok 2.5645 (3.2105)	Learning Rate [7.8125e-05]
2: TRAIN [2][1210/6832]	Time 0.056 (0.105)	Data 0.00087 (0.00095)	Tok/s 52422 (60289)	Loss/tok 2.8810 (3.2046)	Learning Rate [7.8125e-05]
0: TRAIN [2][1210/6832]	Time 0.056 (0.105)	Data 0.00095 (0.00101)	Tok/s 50995 (59408)	Loss/tok 2.7068 (3.2055)	Learning Rate [7.8125e-05]
3: TRAIN [2][1210/6832]	Time 0.056 (0.105)	Data 0.00089 (0.00094)	Tok/s 52472 (60772)	Loss/tok 2.8451 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][1220/6832]	Time 0.070 (0.104)	Data 0.00087 (0.00091)	Tok/s 51277 (59871)	Loss/tok 2.9325 (3.2103)	Learning Rate [7.8125e-05]
2: TRAIN [2][1220/6832]	Time 0.070 (0.104)	Data 0.00087 (0.00095)	Tok/s 51187 (60256)	Loss/tok 2.8918 (3.2045)	Learning Rate [7.8125e-05]
0: TRAIN [2][1220/6832]	Time 0.070 (0.104)	Data 0.00096 (0.00101)	Tok/s 51233 (59378)	Loss/tok 2.9446 (3.2054)	Learning Rate [7.8125e-05]
3: TRAIN [2][1220/6832]	Time 0.070 (0.104)	Data 0.00100 (0.00094)	Tok/s 51374 (60740)	Loss/tok 3.0671 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][1230/6832]	Time 0.132 (0.104)	Data 0.00086 (0.00091)	Tok/s 88432 (59857)	Loss/tok 3.2575 (3.2105)	Learning Rate [7.8125e-05]
2: TRAIN [2][1230/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00095)	Tok/s 88898 (60243)	Loss/tok 3.1003 (3.2043)	Learning Rate [7.8125e-05]
0: TRAIN [2][1230/6832]	Time 0.132 (0.104)	Data 0.00093 (0.00101)	Tok/s 87547 (59364)	Loss/tok 3.1907 (3.2050)	Learning Rate [7.8125e-05]
3: TRAIN [2][1230/6832]	Time 0.132 (0.104)	Data 0.00090 (0.00094)	Tok/s 89661 (60727)	Loss/tok 3.2004 (3.2109)	Learning Rate [7.8125e-05]
2: TRAIN [2][1240/6832]	Time 0.075 (0.104)	Data 0.00091 (0.00095)	Tok/s 52585 (60245)	Loss/tok 2.9415 (3.2045)	Learning Rate [7.8125e-05]
1: TRAIN [2][1240/6832]	Time 0.075 (0.104)	Data 0.00084 (0.00091)	Tok/s 51514 (59860)	Loss/tok 2.9202 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][1240/6832]	Time 0.075 (0.104)	Data 0.00090 (0.00094)	Tok/s 53242 (60727)	Loss/tok 3.0455 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][1240/6832]	Time 0.075 (0.104)	Data 0.00091 (0.00101)	Tok/s 51503 (59370)	Loss/tok 3.0155 (3.2054)	Learning Rate [7.8125e-05]
1: TRAIN [2][1250/6832]	Time 0.106 (0.105)	Data 0.00085 (0.00091)	Tok/s 51854 (59839)	Loss/tok 3.0222 (3.2115)	Learning Rate [7.8125e-05]
2: TRAIN [2][1250/6832]	Time 0.106 (0.105)	Data 0.00085 (0.00095)	Tok/s 51846 (60222)	Loss/tok 3.2391 (3.2053)	Learning Rate [7.8125e-05]
3: TRAIN [2][1250/6832]	Time 0.106 (0.104)	Data 0.00086 (0.00094)	Tok/s 51855 (60705)	Loss/tok 3.0834 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][1250/6832]	Time 0.106 (0.104)	Data 0.00095 (0.00101)	Tok/s 51839 (59352)	Loss/tok 3.2699 (3.2056)	Learning Rate [7.8125e-05]
2: TRAIN [2][1260/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00095)	Tok/s 88793 (60242)	Loss/tok 3.0964 (3.2054)	Learning Rate [7.8125e-05]
1: TRAIN [2][1260/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00091)	Tok/s 88118 (59858)	Loss/tok 3.2268 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][1260/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 89634 (60725)	Loss/tok 3.2089 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][1260/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00101)	Tok/s 87603 (59371)	Loss/tok 3.0957 (3.2056)	Learning Rate [7.8125e-05]
2: TRAIN [2][1270/6832]	Time 0.066 (0.105)	Data 0.00099 (0.00095)	Tok/s 52207 (60258)	Loss/tok 3.0372 (3.2057)	Learning Rate [7.8125e-05]
1: TRAIN [2][1270/6832]	Time 0.066 (0.105)	Data 0.00089 (0.00091)	Tok/s 52193 (59874)	Loss/tok 2.9819 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][1270/6832]	Time 0.066 (0.105)	Data 0.00106 (0.00101)	Tok/s 52206 (59389)	Loss/tok 2.8437 (3.2064)	Learning Rate [7.8125e-05]
3: TRAIN [2][1270/6832]	Time 0.066 (0.105)	Data 0.00099 (0.00094)	Tok/s 52195 (60739)	Loss/tok 3.0912 (3.2111)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][1280/6832]	Time 0.132 (0.104)	Data 0.00087 (0.00095)	Tok/s 82524 (60228)	Loss/tok 3.2328 (3.2055)	Learning Rate [7.8125e-05]
1: TRAIN [2][1280/6832]	Time 0.132 (0.104)	Data 0.00086 (0.00091)	Tok/s 81689 (59846)	Loss/tok 3.1542 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][1280/6832]	Time 0.132 (0.104)	Data 0.00098 (0.00101)	Tok/s 81746 (59362)	Loss/tok 3.1599 (3.2057)	Learning Rate [7.8125e-05]
3: TRAIN [2][1280/6832]	Time 0.132 (0.104)	Data 0.00092 (0.00094)	Tok/s 82687 (60707)	Loss/tok 3.1423 (3.2109)	Learning Rate [7.8125e-05]
2: TRAIN [2][1290/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00095)	Tok/s 53839 (60205)	Loss/tok 3.0463 (3.2059)	Learning Rate [7.8125e-05]
1: TRAIN [2][1290/6832]	Time 0.100 (0.105)	Data 0.00088 (0.00091)	Tok/s 53223 (59823)	Loss/tok 3.1195 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][1290/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00094)	Tok/s 53853 (60680)	Loss/tok 3.1106 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][1290/6832]	Time 0.100 (0.105)	Data 0.00096 (0.00101)	Tok/s 52537 (59341)	Loss/tok 3.2130 (3.2060)	Learning Rate [7.8125e-05]
1: TRAIN [2][1300/6832]	Time 0.078 (0.104)	Data 0.00084 (0.00091)	Tok/s 54271 (59777)	Loss/tok 3.0743 (3.2106)	Learning Rate [7.8125e-05]
2: TRAIN [2][1300/6832]	Time 0.078 (0.104)	Data 0.00086 (0.00095)	Tok/s 54270 (60157)	Loss/tok 2.9663 (3.2059)	Learning Rate [7.8125e-05]
0: TRAIN [2][1300/6832]	Time 0.078 (0.104)	Data 0.00095 (0.00101)	Tok/s 54273 (59298)	Loss/tok 3.0374 (3.2057)	Learning Rate [7.8125e-05]
3: TRAIN [2][1300/6832]	Time 0.078 (0.104)	Data 0.00085 (0.00094)	Tok/s 55539 (60633)	Loss/tok 3.1364 (3.2109)	Learning Rate [7.8125e-05]
2: TRAIN [2][1310/6832]	Time 0.064 (0.104)	Data 0.00087 (0.00095)	Tok/s 51629 (60196)	Loss/tok 2.8708 (3.2056)	Learning Rate [7.8125e-05]
1: TRAIN [2][1310/6832]	Time 0.064 (0.104)	Data 0.00087 (0.00091)	Tok/s 50189 (59814)	Loss/tok 2.8009 (3.2101)	Learning Rate [7.8125e-05]
0: TRAIN [2][1310/6832]	Time 0.064 (0.104)	Data 0.00097 (0.00101)	Tok/s 49687 (59335)	Loss/tok 2.8024 (3.2057)	Learning Rate [7.8125e-05]
3: TRAIN [2][1310/6832]	Time 0.064 (0.104)	Data 0.00090 (0.00094)	Tok/s 51642 (60671)	Loss/tok 2.9290 (3.2105)	Learning Rate [7.8125e-05]
1: TRAIN [2][1320/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00091)	Tok/s 68840 (59820)	Loss/tok 3.3785 (3.2110)	Learning Rate [7.8125e-05]
2: TRAIN [2][1320/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 68982 (60201)	Loss/tok 3.4094 (3.2060)	Learning Rate [7.8125e-05]
0: TRAIN [2][1320/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00101)	Tok/s 68831 (59343)	Loss/tok 3.4389 (3.2061)	Learning Rate [7.8125e-05]
3: TRAIN [2][1320/6832]	Time 0.128 (0.105)	Data 0.00101 (0.00094)	Tok/s 69804 (60676)	Loss/tok 3.2684 (3.2109)	Learning Rate [7.8125e-05]
2: TRAIN [2][1330/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00095)	Tok/s 54365 (60216)	Loss/tok 3.0317 (3.2054)	Learning Rate [7.8125e-05]
1: TRAIN [2][1330/6832]	Time 0.090 (0.105)	Data 0.00085 (0.00091)	Tok/s 53541 (59833)	Loss/tok 3.2252 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][1330/6832]	Time 0.089 (0.105)	Data 0.00100 (0.00094)	Tok/s 54366 (60690)	Loss/tok 3.1165 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][1330/6832]	Time 0.090 (0.105)	Data 0.00097 (0.00101)	Tok/s 52906 (59354)	Loss/tok 3.1647 (3.2063)	Learning Rate [7.8125e-05]
1: TRAIN [2][1340/6832]	Time 0.129 (0.104)	Data 0.00091 (0.00090)	Tok/s 64466 (59806)	Loss/tok 3.4248 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][1340/6832]	Time 0.129 (0.104)	Data 0.00101 (0.00101)	Tok/s 64535 (59327)	Loss/tok 3.3619 (3.2059)	Learning Rate [7.8125e-05]
2: TRAIN [2][1340/6832]	Time 0.129 (0.104)	Data 0.00113 (0.00095)	Tok/s 64430 (60190)	Loss/tok 3.4977 (3.2052)	Learning Rate [7.8125e-05]
3: TRAIN [2][1340/6832]	Time 0.129 (0.104)	Data 0.00110 (0.00094)	Tok/s 64938 (60665)	Loss/tok 3.3088 (3.2104)	Learning Rate [7.8125e-05]
2: TRAIN [2][1350/6832]	Time 0.131 (0.104)	Data 0.00087 (0.00095)	Tok/s 81151 (60195)	Loss/tok 3.2421 (3.2058)	Learning Rate [7.8125e-05]
3: TRAIN [2][1350/6832]	Time 0.131 (0.104)	Data 0.00092 (0.00094)	Tok/s 81266 (60667)	Loss/tok 3.2313 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][1350/6832]	Time 0.131 (0.104)	Data 0.00086 (0.00090)	Tok/s 80227 (59812)	Loss/tok 3.2630 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][1350/6832]	Time 0.131 (0.104)	Data 0.00095 (0.00101)	Tok/s 80246 (59336)	Loss/tok 3.3307 (3.2060)	Learning Rate [7.8125e-05]
1: TRAIN [2][1360/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00090)	Tok/s 54354 (59817)	Loss/tok 3.1252 (3.2108)	Learning Rate [7.8125e-05]
2: TRAIN [2][1360/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00095)	Tok/s 54279 (60199)	Loss/tok 3.2108 (3.2059)	Learning Rate [7.8125e-05]
0: TRAIN [2][1360/6832]	Time 0.104 (0.105)	Data 0.00096 (0.00101)	Tok/s 54354 (59343)	Loss/tok 3.3416 (3.2065)	Learning Rate [7.8125e-05]
3: TRAIN [2][1360/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00094)	Tok/s 54794 (60672)	Loss/tok 3.1741 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][1370/6832]	Time 0.045 (0.105)	Data 0.00087 (0.00090)	Tok/s 32095 (59823)	Loss/tok 2.0143 (3.2112)	Learning Rate [7.8125e-05]
2: TRAIN [2][1370/6832]	Time 0.045 (0.105)	Data 0.00087 (0.00095)	Tok/s 37053 (60208)	Loss/tok 1.9702 (3.2059)	Learning Rate [7.8125e-05]
3: TRAIN [2][1370/6832]	Time 0.045 (0.105)	Data 0.00091 (0.00094)	Tok/s 41064 (60683)	Loss/tok 2.2956 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][1370/6832]	Time 0.045 (0.105)	Data 0.00100 (0.00101)	Tok/s 19432 (59342)	Loss/tok 1.7735 (3.2068)	Learning Rate [7.8125e-05]
2: TRAIN [2][1380/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00095)	Tok/s 60311 (60189)	Loss/tok 3.2036 (3.2058)	Learning Rate [7.8125e-05]
1: TRAIN [2][1380/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00090)	Tok/s 60207 (59804)	Loss/tok 3.3566 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][1380/6832]	Time 0.117 (0.105)	Data 0.00100 (0.00101)	Tok/s 60243 (59317)	Loss/tok 3.2029 (3.2069)	Learning Rate [7.8125e-05]
3: TRAIN [2][1380/6832]	Time 0.117 (0.105)	Data 0.00102 (0.00094)	Tok/s 60300 (60666)	Loss/tok 3.1700 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][1390/6832]	Time 0.055 (0.105)	Data 0.00089 (0.00090)	Tok/s 46851 (59833)	Loss/tok 2.6298 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][1390/6832]	Time 0.055 (0.105)	Data 0.00094 (0.00095)	Tok/s 48791 (60221)	Loss/tok 2.7130 (3.2066)	Learning Rate [7.8125e-05]
0: TRAIN [2][1390/6832]	Time 0.055 (0.105)	Data 0.00098 (0.00101)	Tok/s 46578 (59349)	Loss/tok 2.6857 (3.2074)	Learning Rate [7.8125e-05]
3: TRAIN [2][1390/6832]	Time 0.055 (0.105)	Data 0.00093 (0.00094)	Tok/s 48822 (60697)	Loss/tok 2.6549 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][1400/6832]	Time 0.065 (0.105)	Data 0.00087 (0.00095)	Tok/s 52238 (60212)	Loss/tok 2.7990 (3.2067)	Learning Rate [7.8125e-05]
1: TRAIN [2][1400/6832]	Time 0.065 (0.105)	Data 0.00084 (0.00090)	Tok/s 51503 (59826)	Loss/tok 2.8558 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][1400/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00094)	Tok/s 53586 (60689)	Loss/tok 2.8070 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][1400/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00101)	Tok/s 51436 (59344)	Loss/tok 3.0110 (3.2077)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][1410/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 79559 (60227)	Loss/tok 3.2990 (3.2074)	Learning Rate [7.8125e-05]
1: TRAIN [2][1410/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00090)	Tok/s 79288 (59842)	Loss/tok 3.1898 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][1410/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 80263 (60703)	Loss/tok 3.1973 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][1410/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00101)	Tok/s 78913 (59363)	Loss/tok 3.2059 (3.2081)	Learning Rate [7.8125e-05]
2: TRAIN [2][1420/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00095)	Tok/s 51014 (60215)	Loss/tok 3.2900 (3.2074)	Learning Rate [7.8125e-05]
1: TRAIN [2][1420/6832]	Time 0.105 (0.105)	Data 0.00086 (0.00090)	Tok/s 50964 (59831)	Loss/tok 3.2318 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][1420/6832]	Time 0.105 (0.105)	Data 0.00095 (0.00101)	Tok/s 50968 (59354)	Loss/tok 3.0920 (3.2079)	Learning Rate [7.8125e-05]
3: TRAIN [2][1420/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00094)	Tok/s 52216 (60690)	Loss/tok 3.1814 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][1430/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00095)	Tok/s 53431 (60214)	Loss/tok 3.1624 (3.2072)	Learning Rate [7.8125e-05]
1: TRAIN [2][1430/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00090)	Tok/s 53355 (59832)	Loss/tok 3.2198 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][1430/6832]	Time 0.122 (0.105)	Data 0.00100 (0.00094)	Tok/s 53432 (60688)	Loss/tok 3.3128 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][1430/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00101)	Tok/s 52691 (59357)	Loss/tok 3.1877 (3.2079)	Learning Rate [7.8125e-05]
1: TRAIN [2][1440/6832]	Time 0.081 (0.105)	Data 0.00084 (0.00090)	Tok/s 50328 (59793)	Loss/tok 2.9733 (3.2109)	Learning Rate [7.8125e-05]
2: TRAIN [2][1440/6832]	Time 0.081 (0.105)	Data 0.00091 (0.00095)	Tok/s 51845 (60176)	Loss/tok 3.1638 (3.2071)	Learning Rate [7.8125e-05]
0: TRAIN [2][1440/6832]	Time 0.081 (0.105)	Data 0.00094 (0.00101)	Tok/s 50321 (59316)	Loss/tok 3.0369 (3.2073)	Learning Rate [7.8125e-05]
3: TRAIN [2][1440/6832]	Time 0.081 (0.105)	Data 0.00095 (0.00094)	Tok/s 51877 (60650)	Loss/tok 2.9031 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][1450/6832]	Time 0.097 (0.105)	Data 0.00082 (0.00090)	Tok/s 54321 (59769)	Loss/tok 3.1063 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][1450/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00094)	Tok/s 54392 (60622)	Loss/tok 3.2470 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][1450/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00095)	Tok/s 54376 (60150)	Loss/tok 3.1136 (3.2069)	Learning Rate [7.8125e-05]
0: TRAIN [2][1450/6832]	Time 0.097 (0.105)	Data 0.00094 (0.00101)	Tok/s 53480 (59293)	Loss/tok 3.1983 (3.2073)	Learning Rate [7.8125e-05]
2: TRAIN [2][1460/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00095)	Tok/s 50610 (60168)	Loss/tok 2.7559 (3.2071)	Learning Rate [7.8125e-05]
1: TRAIN [2][1460/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00090)	Tok/s 50303 (59787)	Loss/tok 2.9144 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][1460/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00101)	Tok/s 50290 (59313)	Loss/tok 2.8597 (3.2077)	Learning Rate [7.8125e-05]
3: TRAIN [2][1460/6832]	Time 0.061 (0.105)	Data 0.00090 (0.00094)	Tok/s 52449 (60640)	Loss/tok 2.8402 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][1470/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00090)	Tok/s 76781 (59793)	Loss/tok 3.2333 (3.2112)	Learning Rate [7.8125e-05]
2: TRAIN [2][1470/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00095)	Tok/s 77255 (60172)	Loss/tok 3.2983 (3.2076)	Learning Rate [7.8125e-05]
0: TRAIN [2][1470/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00101)	Tok/s 76777 (59321)	Loss/tok 3.2714 (3.2083)	Learning Rate [7.8125e-05]
3: TRAIN [2][1470/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 77559 (60645)	Loss/tok 3.4600 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][1480/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00095)	Tok/s 53524 (60147)	Loss/tok 3.1694 (3.2078)	Learning Rate [7.8125e-05]
1: TRAIN [2][1480/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00090)	Tok/s 53482 (59767)	Loss/tok 3.2014 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][1480/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00101)	Tok/s 53139 (59296)	Loss/tok 3.0138 (3.2080)	Learning Rate [7.8125e-05]
3: TRAIN [2][1480/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00094)	Tok/s 53487 (60619)	Loss/tok 3.0930 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][1490/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 77079 (60146)	Loss/tok 3.1235 (3.2079)	Learning Rate [7.8125e-05]
1: TRAIN [2][1490/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00090)	Tok/s 76655 (59763)	Loss/tok 3.3304 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][1490/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00101)	Tok/s 76086 (59286)	Loss/tok 3.4016 (3.2085)	Learning Rate [7.8125e-05]
3: TRAIN [2][1490/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 77115 (60619)	Loss/tok 3.3364 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][1500/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00095)	Tok/s 53984 (60121)	Loss/tok 3.1289 (3.2080)	Learning Rate [7.8125e-05]
1: TRAIN [2][1500/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00090)	Tok/s 53964 (59738)	Loss/tok 3.4133 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][1500/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00101)	Tok/s 52880 (59261)	Loss/tok 3.2168 (3.2089)	Learning Rate [7.8125e-05]
3: TRAIN [2][1500/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00094)	Tok/s 53978 (60593)	Loss/tok 3.2908 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][1510/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00095)	Tok/s 57716 (60122)	Loss/tok 3.2304 (3.2076)	Learning Rate [7.8125e-05]
1: TRAIN [2][1510/6832]	Time 0.111 (0.105)	Data 0.00085 (0.00090)	Tok/s 57680 (59736)	Loss/tok 3.1787 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][1510/6832]	Time 0.111 (0.105)	Data 0.00093 (0.00094)	Tok/s 57753 (60596)	Loss/tok 3.1605 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][1510/6832]	Time 0.111 (0.105)	Data 0.00092 (0.00101)	Tok/s 57701 (59252)	Loss/tok 3.2390 (3.2086)	Learning Rate [7.8125e-05]
1: TRAIN [2][1520/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00090)	Tok/s 55357 (59730)	Loss/tok 3.2300 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][1520/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00095)	Tok/s 55848 (60117)	Loss/tok 3.2203 (3.2081)	Learning Rate [7.8125e-05]
3: TRAIN [2][1520/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00094)	Tok/s 56450 (60590)	Loss/tok 3.1594 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][1520/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00101)	Tok/s 55311 (59247)	Loss/tok 3.2502 (3.2090)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [2][1530/6832]	Time 0.134 (0.105)	Data 0.00090 (0.00090)	Tok/s 90177 (59726)	Loss/tok 2.9710 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][1530/6832]	Time 0.134 (0.105)	Data 0.00093 (0.00100)	Tok/s 89290 (59243)	Loss/tok 3.1372 (3.2087)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
2: TRAIN [2][1530/6832]	Time 0.134 (0.105)	Data 0.00092 (0.00095)	Tok/s 91364 (60114)	Loss/tok 3.1080 (3.2077)	Learning Rate [7.8125e-05]
3: TRAIN [2][1530/6832]	Time 0.134 (0.105)	Data 0.00097 (0.00094)	Tok/s 93271 (60588)	Loss/tok 2.9968 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][1540/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00095)	Tok/s 68113 (60088)	Loss/tok 3.3976 (3.2080)	Learning Rate [7.8125e-05]
1: TRAIN [2][1540/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00090)	Tok/s 68113 (59702)	Loss/tok 3.1689 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][1540/6832]	Time 0.126 (0.105)	Data 0.00102 (0.00094)	Tok/s 68147 (60560)	Loss/tok 3.3266 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][1540/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00100)	Tok/s 67359 (59220)	Loss/tok 3.2021 (3.2085)	Learning Rate [7.8125e-05]
1: TRAIN [2][1550/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00090)	Tok/s 88042 (59734)	Loss/tok 3.1353 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][1550/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00100)	Tok/s 87466 (59252)	Loss/tok 3.1175 (3.2086)	Learning Rate [7.8125e-05]
2: TRAIN [2][1550/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00095)	Tok/s 88684 (60119)	Loss/tok 3.0386 (3.2079)	Learning Rate [7.8125e-05]
3: TRAIN [2][1550/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00094)	Tok/s 89494 (60590)	Loss/tok 3.0957 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][1560/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00090)	Tok/s 66974 (59772)	Loss/tok 3.3705 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][1560/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00095)	Tok/s 67269 (60156)	Loss/tok 3.4853 (3.2086)	Learning Rate [7.8125e-05]
0: TRAIN [2][1560/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00100)	Tok/s 67003 (59291)	Loss/tok 3.4466 (3.2092)	Learning Rate [7.8125e-05]
3: TRAIN [2][1560/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00094)	Tok/s 67935 (60628)	Loss/tok 3.1934 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][1570/6832]	Time 0.105 (0.105)	Data 0.00084 (0.00095)	Tok/s 54933 (60144)	Loss/tok 3.3568 (3.2088)	Learning Rate [7.8125e-05]
1: TRAIN [2][1570/6832]	Time 0.105 (0.105)	Data 0.00084 (0.00090)	Tok/s 54927 (59761)	Loss/tok 3.1437 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][1570/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00100)	Tok/s 54938 (59282)	Loss/tok 3.3663 (3.2092)	Learning Rate [7.8125e-05]
3: TRAIN [2][1570/6832]	Time 0.105 (0.105)	Data 0.00088 (0.00094)	Tok/s 54953 (60616)	Loss/tok 3.0474 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][1580/6832]	Time 0.044 (0.105)	Data 0.00085 (0.00095)	Tok/s 38149 (60106)	Loss/tok 1.9325 (3.2086)	Learning Rate [7.8125e-05]
1: TRAIN [2][1580/6832]	Time 0.044 (0.105)	Data 0.00086 (0.00090)	Tok/s 33543 (59720)	Loss/tok 2.0596 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][1580/6832]	Time 0.044 (0.105)	Data 0.00274 (0.00100)	Tok/s 21640 (59237)	Loss/tok 1.7945 (3.2091)	Learning Rate [7.8125e-05]
3: TRAIN [2][1580/6832]	Time 0.044 (0.105)	Data 0.00096 (0.00094)	Tok/s 42323 (60579)	Loss/tok 2.2685 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][1590/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00090)	Tok/s 56468 (59732)	Loss/tok 3.4643 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][1590/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 56616 (60118)	Loss/tok 3.3776 (3.2089)	Learning Rate [7.8125e-05]
0: TRAIN [2][1590/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00100)	Tok/s 56491 (59249)	Loss/tok 3.1866 (3.2092)	Learning Rate [7.8125e-05]
3: TRAIN [2][1590/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 57457 (60593)	Loss/tok 3.3020 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][1600/6832]	Time 0.102 (0.105)	Data 0.00092 (0.00095)	Tok/s 54954 (60104)	Loss/tok 3.0555 (3.2087)	Learning Rate [7.8125e-05]
1: TRAIN [2][1600/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00090)	Tok/s 54938 (59718)	Loss/tok 3.0212 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][1600/6832]	Time 0.102 (0.105)	Data 0.00098 (0.00100)	Tok/s 54963 (59233)	Loss/tok 3.1844 (3.2088)	Learning Rate [7.8125e-05]
3: TRAIN [2][1600/6832]	Time 0.102 (0.105)	Data 0.00095 (0.00094)	Tok/s 55241 (60578)	Loss/tok 3.2518 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][1610/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00090)	Tok/s 64285 (59708)	Loss/tok 3.4784 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][1610/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00100)	Tok/s 64224 (59225)	Loss/tok 3.3372 (3.2089)	Learning Rate [7.8125e-05]
2: TRAIN [2][1610/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 64235 (60094)	Loss/tok 3.3971 (3.2090)	Learning Rate [7.8125e-05]
3: TRAIN [2][1610/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 64202 (60567)	Loss/tok 3.1897 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][1620/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00090)	Tok/s 88017 (59754)	Loss/tok 3.0463 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][1620/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00100)	Tok/s 87260 (59262)	Loss/tok 3.3771 (3.2092)	Learning Rate [7.8125e-05]
2: TRAIN [2][1620/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 88724 (60142)	Loss/tok 3.1410 (3.2084)	Learning Rate [7.8125e-05]
3: TRAIN [2][1620/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00094)	Tok/s 89477 (60618)	Loss/tok 3.2047 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][1630/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00095)	Tok/s 79347 (60160)	Loss/tok 3.2061 (3.2084)	Learning Rate [7.8125e-05]
1: TRAIN [2][1630/6832]	Time 0.131 (0.105)	Data 0.00116 (0.00090)	Tok/s 78673 (59769)	Loss/tok 3.1789 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][1630/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00094)	Tok/s 79324 (60637)	Loss/tok 3.3930 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][1630/6832]	Time 0.131 (0.105)	Data 0.00114 (0.00100)	Tok/s 78369 (59273)	Loss/tok 3.2883 (3.2096)	Learning Rate [7.8125e-05]
2: TRAIN [2][1640/6832]	Time 0.075 (0.105)	Data 0.00094 (0.00095)	Tok/s 52821 (60138)	Loss/tok 3.0477 (3.2085)	Learning Rate [7.8125e-05]
1: TRAIN [2][1640/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00090)	Tok/s 52805 (59748)	Loss/tok 2.9093 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][1640/6832]	Time 0.075 (0.105)	Data 0.00099 (0.00100)	Tok/s 51155 (59253)	Loss/tok 2.9911 (3.2096)	Learning Rate [7.8125e-05]
3: TRAIN [2][1640/6832]	Time 0.075 (0.105)	Data 0.00101 (0.00094)	Tok/s 52852 (60613)	Loss/tok 3.1137 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][1650/6832]	Time 0.047 (0.105)	Data 0.00089 (0.00095)	Tok/s 46359 (60114)	Loss/tok 2.4154 (3.2088)	Learning Rate [7.8125e-05]
1: TRAIN [2][1650/6832]	Time 0.047 (0.105)	Data 0.00086 (0.00090)	Tok/s 44021 (59724)	Loss/tok 2.3755 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][1650/6832]	Time 0.047 (0.105)	Data 0.00094 (0.00100)	Tok/s 41592 (59231)	Loss/tok 2.4606 (3.2093)	Learning Rate [7.8125e-05]
3: TRAIN [2][1650/6832]	Time 0.047 (0.105)	Data 0.00095 (0.00094)	Tok/s 48486 (60590)	Loss/tok 2.4745 (3.2132)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][1660/6832]	Time 0.093 (0.105)	Data 0.00101 (0.00095)	Tok/s 52049 (60136)	Loss/tok 3.1670 (3.2090)	Learning Rate [7.8125e-05]
1: TRAIN [2][1660/6832]	Time 0.093 (0.105)	Data 0.00093 (0.00090)	Tok/s 52034 (59747)	Loss/tok 3.0488 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][1660/6832]	Time 0.094 (0.105)	Data 0.00098 (0.00100)	Tok/s 52014 (59255)	Loss/tok 3.0681 (3.2096)	Learning Rate [7.8125e-05]
3: TRAIN [2][1660/6832]	Time 0.093 (0.105)	Data 0.00110 (0.00094)	Tok/s 52671 (60611)	Loss/tok 3.3024 (3.2139)	Learning Rate [7.8125e-05]
1: TRAIN [2][1670/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00090)	Tok/s 59420 (59798)	Loss/tok 3.3020 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][1670/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00100)	Tok/s 59407 (59306)	Loss/tok 3.2359 (3.2098)	Learning Rate [7.8125e-05]
2: TRAIN [2][1670/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00095)	Tok/s 59447 (60185)	Loss/tok 3.3773 (3.2089)	Learning Rate [7.8125e-05]
3: TRAIN [2][1670/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00094)	Tok/s 59470 (60661)	Loss/tok 3.1892 (3.2137)	Learning Rate [7.8125e-05]
1: TRAIN [2][1680/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00090)	Tok/s 58782 (59774)	Loss/tok 3.2265 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][1680/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00100)	Tok/s 57946 (59283)	Loss/tok 3.3333 (3.2099)	Learning Rate [7.8125e-05]
2: TRAIN [2][1680/6832]	Time 0.122 (0.105)	Data 0.00096 (0.00095)	Tok/s 58922 (60160)	Loss/tok 3.4040 (3.2088)	Learning Rate [7.8125e-05]
3: TRAIN [2][1680/6832]	Time 0.122 (0.105)	Data 0.00101 (0.00094)	Tok/s 58879 (60635)	Loss/tok 3.1667 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][1690/6832]	Time 0.082 (0.105)	Data 0.00086 (0.00095)	Tok/s 53399 (60144)	Loss/tok 2.8011 (3.2084)	Learning Rate [7.8125e-05]
1: TRAIN [2][1690/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00090)	Tok/s 53404 (59757)	Loss/tok 3.1419 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][1690/6832]	Time 0.082 (0.105)	Data 0.00096 (0.00100)	Tok/s 53399 (59267)	Loss/tok 3.0997 (3.2094)	Learning Rate [7.8125e-05]
3: TRAIN [2][1690/6832]	Time 0.081 (0.105)	Data 0.00091 (0.00094)	Tok/s 53423 (60617)	Loss/tok 3.2286 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][1700/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00095)	Tok/s 62716 (60124)	Loss/tok 3.4078 (3.2089)	Learning Rate [7.8125e-05]
1: TRAIN [2][1700/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00090)	Tok/s 62443 (59734)	Loss/tok 3.3837 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][1700/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00095)	Tok/s 63475 (60598)	Loss/tok 3.3369 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][1700/6832]	Time 0.127 (0.105)	Data 0.00105 (0.00100)	Tok/s 62484 (59239)	Loss/tok 3.3411 (3.2095)	Learning Rate [7.8125e-05]
2: TRAIN [2][1710/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00095)	Tok/s 59148 (60093)	Loss/tok 3.5183 (3.2087)	Learning Rate [7.8125e-05]
1: TRAIN [2][1710/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00090)	Tok/s 59201 (59701)	Loss/tok 3.3050 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][1710/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00100)	Tok/s 59197 (59201)	Loss/tok 3.3687 (3.2093)	Learning Rate [7.8125e-05]
3: TRAIN [2][1710/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00095)	Tok/s 59197 (60570)	Loss/tok 3.2263 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][1720/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 78686 (60077)	Loss/tok 3.1201 (3.2082)	Learning Rate [7.8125e-05]
1: TRAIN [2][1720/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00090)	Tok/s 77998 (59684)	Loss/tok 3.1903 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][1720/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00100)	Tok/s 77669 (59183)	Loss/tok 3.4115 (3.2094)	Learning Rate [7.8125e-05]
3: TRAIN [2][1720/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 78692 (60553)	Loss/tok 3.2017 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][1730/6832]	Time 0.071 (0.105)	Data 0.00103 (0.00095)	Tok/s 53966 (60057)	Loss/tok 3.0505 (3.2084)	Learning Rate [7.8125e-05]
1: TRAIN [2][1730/6832]	Time 0.071 (0.105)	Data 0.00094 (0.00090)	Tok/s 52508 (59663)	Loss/tok 3.0557 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][1730/6832]	Time 0.071 (0.105)	Data 0.00101 (0.00100)	Tok/s 52066 (59164)	Loss/tok 2.9164 (3.2092)	Learning Rate [7.8125e-05]
3: TRAIN [2][1730/6832]	Time 0.071 (0.105)	Data 0.00104 (0.00095)	Tok/s 53960 (60532)	Loss/tok 3.3969 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][1740/6832]	Time 0.093 (0.105)	Data 0.00093 (0.00095)	Tok/s 52361 (60063)	Loss/tok 3.1768 (3.2091)	Learning Rate [7.8125e-05]
1: TRAIN [2][1740/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00090)	Tok/s 52106 (59671)	Loss/tok 3.0265 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][1740/6832]	Time 0.093 (0.105)	Data 0.00106 (0.00100)	Tok/s 52101 (59173)	Loss/tok 3.0797 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][1740/6832]	Time 0.093 (0.105)	Data 0.00098 (0.00095)	Tok/s 53485 (60539)	Loss/tok 3.0521 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][1750/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 74513 (60070)	Loss/tok 3.1664 (3.2094)	Learning Rate [7.8125e-05]
1: TRAIN [2][1750/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00090)	Tok/s 74445 (59678)	Loss/tok 3.2931 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][1750/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 75498 (60546)	Loss/tok 3.2977 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][1750/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00100)	Tok/s 74471 (59180)	Loss/tok 3.3080 (3.2099)	Learning Rate [7.8125e-05]
1: TRAIN [2][1760/6832]	Time 0.125 (0.105)	Data 0.00100 (0.00090)	Tok/s 62597 (59659)	Loss/tok 3.3449 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][1760/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00095)	Tok/s 62802 (60051)	Loss/tok 3.2140 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][1760/6832]	Time 0.125 (0.105)	Data 0.00105 (0.00100)	Tok/s 62595 (59164)	Loss/tok 3.2667 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][1760/6832]	Time 0.125 (0.105)	Data 0.00108 (0.00095)	Tok/s 63554 (60527)	Loss/tok 3.3521 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][1770/6832]	Time 0.114 (0.105)	Data 0.00088 (0.00090)	Tok/s 57138 (59655)	Loss/tok 3.3478 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][1770/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00095)	Tok/s 57126 (60047)	Loss/tok 3.2873 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [2][1770/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00100)	Tok/s 57110 (59162)	Loss/tok 3.2744 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][1770/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00095)	Tok/s 58072 (60523)	Loss/tok 3.2327 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][1780/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00090)	Tok/s 52292 (59609)	Loss/tok 3.0261 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][1780/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00095)	Tok/s 52264 (60007)	Loss/tok 3.0046 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][1780/6832]	Time 0.071 (0.105)	Data 0.00098 (0.00100)	Tok/s 52296 (59105)	Loss/tok 2.8716 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][1780/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00095)	Tok/s 52272 (60485)	Loss/tok 2.8761 (3.2128)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][1790/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00090)	Tok/s 73787 (59607)	Loss/tok 3.2605 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][1790/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00100)	Tok/s 73426 (59105)	Loss/tok 3.2931 (3.2095)	Learning Rate [7.8125e-05]
2: TRAIN [2][1790/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 73717 (60003)	Loss/tok 3.3119 (3.2095)	Learning Rate [7.8125e-05]
3: TRAIN [2][1790/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 74318 (60482)	Loss/tok 3.3481 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][1800/6832]	Time 0.095 (0.105)	Data 0.00084 (0.00090)	Tok/s 54085 (59596)	Loss/tok 3.1818 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][1800/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00094)	Tok/s 55167 (59992)	Loss/tok 3.0836 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][1800/6832]	Time 0.093 (0.105)	Data 0.00099 (0.00100)	Tok/s 54821 (59096)	Loss/tok 3.0875 (3.2095)	Learning Rate [7.8125e-05]
3: TRAIN [2][1800/6832]	Time 0.095 (0.105)	Data 0.00095 (0.00095)	Tok/s 55457 (60471)	Loss/tok 3.2910 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][1810/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00094)	Tok/s 57412 (59999)	Loss/tok 3.1602 (3.2094)	Learning Rate [7.8125e-05]
1: TRAIN [2][1810/6832]	Time 0.114 (0.105)	Data 0.00091 (0.00090)	Tok/s 57187 (59604)	Loss/tok 3.3694 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][1810/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00100)	Tok/s 57182 (59105)	Loss/tok 3.1829 (3.2094)	Learning Rate [7.8125e-05]
3: TRAIN [2][1810/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00095)	Tok/s 58323 (60479)	Loss/tok 3.2693 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][1820/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00094)	Tok/s 92297 (60029)	Loss/tok 2.9816 (3.2093)	Learning Rate [7.8125e-05]
1: TRAIN [2][1820/6832]	Time 0.133 (0.105)	Data 0.00086 (0.00090)	Tok/s 91043 (59634)	Loss/tok 3.1146 (3.2132)	Learning Rate [7.8125e-05]
3: TRAIN [2][1820/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 94270 (60508)	Loss/tok 3.1833 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][1820/6832]	Time 0.133 (0.105)	Data 0.00092 (0.00100)	Tok/s 89943 (59137)	Loss/tok 3.1175 (3.2096)	Learning Rate [7.8125e-05]
2: TRAIN [2][1830/6832]	Time 0.096 (0.105)	Data 0.00098 (0.00094)	Tok/s 53545 (60030)	Loss/tok 3.0223 (3.2089)	Learning Rate [7.8125e-05]
1: TRAIN [2][1830/6832]	Time 0.096 (0.105)	Data 0.00095 (0.00090)	Tok/s 53459 (59636)	Loss/tok 3.2587 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][1830/6832]	Time 0.096 (0.105)	Data 0.00097 (0.00100)	Tok/s 52499 (59138)	Loss/tok 3.4364 (3.2094)	Learning Rate [7.8125e-05]
3: TRAIN [2][1830/6832]	Time 0.096 (0.105)	Data 0.00101 (0.00095)	Tok/s 53525 (60509)	Loss/tok 3.2170 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][1840/6832]	Time 0.045 (0.105)	Data 0.00087 (0.00090)	Tok/s 32188 (59606)	Loss/tok 2.1562 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][1840/6832]	Time 0.045 (0.105)	Data 0.00095 (0.00100)	Tok/s 20630 (59103)	Loss/tok 1.6254 (3.2097)	Learning Rate [7.8125e-05]
2: TRAIN [2][1840/6832]	Time 0.045 (0.105)	Data 0.00087 (0.00094)	Tok/s 37160 (60001)	Loss/tok 1.8691 (3.2090)	Learning Rate [7.8125e-05]
3: TRAIN [2][1840/6832]	Time 0.045 (0.105)	Data 0.00094 (0.00095)	Tok/s 40463 (60481)	Loss/tok 2.4101 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][1850/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00090)	Tok/s 56343 (59624)	Loss/tok 3.3153 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][1850/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00100)	Tok/s 56346 (59122)	Loss/tok 3.2609 (3.2097)	Learning Rate [7.8125e-05]
2: TRAIN [2][1850/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00094)	Tok/s 57048 (60019)	Loss/tok 3.2461 (3.2089)	Learning Rate [7.8125e-05]
3: TRAIN [2][1850/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00095)	Tok/s 57288 (60499)	Loss/tok 3.2548 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][1860/6832]	Time 0.064 (0.105)	Data 0.00095 (0.00094)	Tok/s 51673 (59990)	Loss/tok 3.0086 (3.2086)	Learning Rate [7.8125e-05]
1: TRAIN [2][1860/6832]	Time 0.064 (0.105)	Data 0.00086 (0.00090)	Tok/s 51644 (59593)	Loss/tok 2.9662 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][1860/6832]	Time 0.064 (0.105)	Data 0.00094 (0.00095)	Tok/s 52773 (60471)	Loss/tok 2.9570 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][1860/6832]	Time 0.064 (0.105)	Data 0.00092 (0.00100)	Tok/s 51659 (59086)	Loss/tok 2.8882 (3.2092)	Learning Rate [7.8125e-05]
1: TRAIN [2][1870/6832]	Time 0.072 (0.105)	Data 0.00093 (0.00090)	Tok/s 51798 (59577)	Loss/tok 2.8551 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][1870/6832]	Time 0.072 (0.105)	Data 0.00093 (0.00094)	Tok/s 51697 (59975)	Loss/tok 3.0131 (3.2089)	Learning Rate [7.8125e-05]
0: TRAIN [2][1870/6832]	Time 0.072 (0.105)	Data 0.00095 (0.00100)	Tok/s 51792 (59070)	Loss/tok 3.0532 (3.2092)	Learning Rate [7.8125e-05]
3: TRAIN [2][1870/6832]	Time 0.072 (0.105)	Data 0.00097 (0.00095)	Tok/s 51707 (60456)	Loss/tok 3.2398 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][1880/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00090)	Tok/s 75675 (59593)	Loss/tok 3.3025 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][1880/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00100)	Tok/s 75515 (59087)	Loss/tok 3.1943 (3.2092)	Learning Rate [7.8125e-05]
2: TRAIN [2][1880/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 76338 (59990)	Loss/tok 3.3108 (3.2091)	Learning Rate [7.8125e-05]
3: TRAIN [2][1880/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 76354 (60470)	Loss/tok 3.4197 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][1890/6832]	Time 0.090 (0.105)	Data 0.00086 (0.00094)	Tok/s 52442 (59980)	Loss/tok 3.1844 (3.2089)	Learning Rate [7.8125e-05]
1: TRAIN [2][1890/6832]	Time 0.090 (0.105)	Data 0.00092 (0.00090)	Tok/s 52397 (59580)	Loss/tok 3.0937 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][1890/6832]	Time 0.090 (0.105)	Data 0.00096 (0.00100)	Tok/s 52412 (59070)	Loss/tok 3.2999 (3.2094)	Learning Rate [7.8125e-05]
3: TRAIN [2][1890/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00095)	Tok/s 52433 (60462)	Loss/tok 2.9768 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][1900/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00090)	Tok/s 65606 (59603)	Loss/tok 3.3109 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][1900/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 65628 (60003)	Loss/tok 3.3984 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][1900/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00100)	Tok/s 65566 (59095)	Loss/tok 3.3774 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][1900/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 65629 (60484)	Loss/tok 3.3735 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][1910/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00090)	Tok/s 53895 (59596)	Loss/tok 3.1194 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][1910/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00094)	Tok/s 54689 (59994)	Loss/tok 3.3656 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][1910/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00095)	Tok/s 54704 (60474)	Loss/tok 3.0516 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][1910/6832]	Time 0.119 (0.105)	Data 0.00109 (0.00100)	Tok/s 53613 (59088)	Loss/tok 3.4948 (3.2104)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
1: TRAIN [2][1920/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00090)	Tok/s 61815 (59582)	Loss/tok 3.2905 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][1920/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00094)	Tok/s 62396 (59979)	Loss/tok 3.1571 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [2][1920/6832]	Time 0.131 (0.105)	Data 0.00108 (0.00100)	Tok/s 61787 (59075)	Loss/tok 3.3240 (3.2104)	Learning Rate [7.8125e-05]
3: TRAIN [2][1920/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00095)	Tok/s 62740 (60458)	Loss/tok 3.4100 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][1930/6832]	Time 0.117 (0.105)	Data 0.00112 (0.00095)	Tok/s 57889 (60455)	Loss/tok 3.0515 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][1930/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00090)	Tok/s 57858 (59580)	Loss/tok 3.1385 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][1930/6832]	Time 0.117 (0.105)	Data 0.00104 (0.00100)	Tok/s 57887 (59075)	Loss/tok 3.2668 (3.2106)	Learning Rate [7.8125e-05]
2: TRAIN [2][1930/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00094)	Tok/s 57888 (59978)	Loss/tok 3.3540 (3.2099)	Learning Rate [7.8125e-05]
1: TRAIN [2][1940/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00090)	Tok/s 58764 (59556)	Loss/tok 3.3351 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][1940/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00094)	Tok/s 58748 (59955)	Loss/tok 3.5046 (3.2101)	Learning Rate [7.8125e-05]
0: TRAIN [2][1940/6832]	Time 0.124 (0.105)	Data 0.00103 (0.00100)	Tok/s 58778 (59046)	Loss/tok 3.5104 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][1940/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00095)	Tok/s 58726 (60433)	Loss/tok 3.2917 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][1950/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00094)	Tok/s 65532 (59961)	Loss/tok 3.3463 (3.2101)	Learning Rate [7.8125e-05]
1: TRAIN [2][1950/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00090)	Tok/s 65518 (59562)	Loss/tok 3.3665 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][1950/6832]	Time 0.125 (0.105)	Data 0.00085 (0.00095)	Tok/s 65538 (60439)	Loss/tok 3.2382 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][1950/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00100)	Tok/s 65558 (59053)	Loss/tok 3.1117 (3.2104)	Learning Rate [7.8125e-05]
2: TRAIN [2][1960/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00094)	Tok/s 54912 (59916)	Loss/tok 2.9106 (3.2095)	Learning Rate [7.8125e-05]
1: TRAIN [2][1960/6832]	Time 0.077 (0.105)	Data 0.00088 (0.00090)	Tok/s 54959 (59513)	Loss/tok 2.7832 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][1960/6832]	Time 0.077 (0.105)	Data 0.00084 (0.00094)	Tok/s 54936 (60395)	Loss/tok 2.9699 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][1960/6832]	Time 0.077 (0.105)	Data 0.00095 (0.00100)	Tok/s 54882 (59000)	Loss/tok 3.0461 (3.2097)	Learning Rate [7.8125e-05]
1: TRAIN [2][1970/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00090)	Tok/s 52633 (59529)	Loss/tok 3.2350 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][1970/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00094)	Tok/s 52610 (59931)	Loss/tok 3.3249 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][1970/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00100)	Tok/s 52617 (59015)	Loss/tok 3.0828 (3.2096)	Learning Rate [7.8125e-05]
3: TRAIN [2][1970/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00094)	Tok/s 52739 (60410)	Loss/tok 3.3492 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][1980/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00094)	Tok/s 52537 (59950)	Loss/tok 3.0058 (3.2097)	Learning Rate [7.8125e-05]
1: TRAIN [2][1980/6832]	Time 0.080 (0.105)	Data 0.00086 (0.00090)	Tok/s 51738 (59547)	Loss/tok 3.1543 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][1980/6832]	Time 0.080 (0.105)	Data 0.00098 (0.00100)	Tok/s 50990 (59034)	Loss/tok 3.0553 (3.2097)	Learning Rate [7.8125e-05]
3: TRAIN [2][1980/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00094)	Tok/s 52574 (60427)	Loss/tok 3.1330 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][1990/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00090)	Tok/s 57142 (59535)	Loss/tok 3.3901 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][1990/6832]	Time 0.125 (0.105)	Data 0.00098 (0.00094)	Tok/s 57562 (59937)	Loss/tok 3.1690 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][1990/6832]	Time 0.125 (0.105)	Data 0.00086 (0.00094)	Tok/s 57543 (60415)	Loss/tok 3.2636 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][1990/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00100)	Tok/s 56532 (59023)	Loss/tok 3.1902 (3.2099)	Learning Rate [7.8125e-05]
1: TRAIN [2][2000/6832]	Time 0.061 (0.105)	Data 0.00090 (0.00090)	Tok/s 48543 (59534)	Loss/tok 2.7702 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][2000/6832]	Time 0.061 (0.105)	Data 0.00096 (0.00094)	Tok/s 48453 (59935)	Loss/tok 2.8715 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][2000/6832]	Time 0.061 (0.105)	Data 0.00091 (0.00100)	Tok/s 48524 (59023)	Loss/tok 2.7933 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][2000/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00094)	Tok/s 50428 (60413)	Loss/tok 2.8404 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][2010/6832]	Time 0.092 (0.105)	Data 0.00084 (0.00090)	Tok/s 52854 (59523)	Loss/tok 3.1928 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2010/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00100)	Tok/s 52843 (59014)	Loss/tok 3.2377 (3.2097)	Learning Rate [7.8125e-05]
2: TRAIN [2][2010/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00094)	Tok/s 53030 (59923)	Loss/tok 3.1678 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][2010/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00094)	Tok/s 54228 (60401)	Loss/tok 3.1572 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][2020/6832]	Time 0.080 (0.105)	Data 0.00095 (0.00094)	Tok/s 54565 (59907)	Loss/tok 2.9360 (3.2100)	Learning Rate [7.8125e-05]
1: TRAIN [2][2020/6832]	Time 0.080 (0.105)	Data 0.00101 (0.00090)	Tok/s 54545 (59507)	Loss/tok 3.0441 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][2020/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00094)	Tok/s 54642 (60383)	Loss/tok 2.9032 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2020/6832]	Time 0.080 (0.105)	Data 0.00097 (0.00100)	Tok/s 54605 (58999)	Loss/tok 3.0522 (3.2096)	Learning Rate [7.8125e-05]
1: TRAIN [2][2030/6832]	Time 0.100 (0.105)	Data 0.00086 (0.00090)	Tok/s 53498 (59490)	Loss/tok 3.2205 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][2030/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00094)	Tok/s 53760 (59892)	Loss/tok 3.2507 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][2030/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00100)	Tok/s 53535 (58977)	Loss/tok 3.0419 (3.2095)	Learning Rate [7.8125e-05]
3: TRAIN [2][2030/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00094)	Tok/s 54739 (60369)	Loss/tok 3.1688 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][2040/6832]	Time 0.087 (0.105)	Data 0.00088 (0.00094)	Tok/s 52663 (59889)	Loss/tok 3.1475 (3.2099)	Learning Rate [7.8125e-05]
1: TRAIN [2][2040/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00090)	Tok/s 51328 (59488)	Loss/tok 3.0709 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][2040/6832]	Time 0.087 (0.105)	Data 0.00092 (0.00094)	Tok/s 52677 (60366)	Loss/tok 3.1705 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2040/6832]	Time 0.088 (0.105)	Data 0.00093 (0.00100)	Tok/s 51191 (58976)	Loss/tok 3.0995 (3.2095)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][2050/6832]	Time 0.111 (0.105)	Data 0.00085 (0.00090)	Tok/s 52099 (59508)	Loss/tok 3.1680 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2050/6832]	Time 0.111 (0.105)	Data 0.00094 (0.00100)	Tok/s 51909 (58996)	Loss/tok 3.1807 (3.2095)	Learning Rate [7.8125e-05]
2: TRAIN [2][2050/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00094)	Tok/s 52000 (59908)	Loss/tok 3.1464 (3.2097)	Learning Rate [7.8125e-05]
3: TRAIN [2][2050/6832]	Time 0.111 (0.105)	Data 0.00086 (0.00094)	Tok/s 51971 (60384)	Loss/tok 3.2883 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][2060/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00090)	Tok/s 54305 (59494)	Loss/tok 3.3124 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2060/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00100)	Tok/s 54315 (58984)	Loss/tok 3.2451 (3.2096)	Learning Rate [7.8125e-05]
2: TRAIN [2][2060/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00094)	Tok/s 54266 (59894)	Loss/tok 3.1871 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][2060/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00094)	Tok/s 54288 (60370)	Loss/tok 3.1844 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][2070/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00090)	Tok/s 51644 (59511)	Loss/tok 3.1448 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2070/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00100)	Tok/s 51617 (59002)	Loss/tok 3.1375 (3.2099)	Learning Rate [7.8125e-05]
2: TRAIN [2][2070/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 52614 (59910)	Loss/tok 3.1844 (3.2097)	Learning Rate [7.8125e-05]
3: TRAIN [2][2070/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00094)	Tok/s 52650 (60386)	Loss/tok 3.1501 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][2080/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00090)	Tok/s 63460 (59505)	Loss/tok 3.2557 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][2080/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00094)	Tok/s 63451 (59903)	Loss/tok 3.4153 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [2][2080/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00100)	Tok/s 63482 (58998)	Loss/tok 3.4033 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][2080/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00094)	Tok/s 63693 (60379)	Loss/tok 3.1291 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][2090/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00094)	Tok/s 51064 (59900)	Loss/tok 3.0758 (3.2099)	Learning Rate [7.8125e-05]
3: TRAIN [2][2090/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00094)	Tok/s 51098 (60374)	Loss/tok 2.8601 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2090/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00100)	Tok/s 50793 (58996)	Loss/tok 2.7494 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][2090/6832]	Time 0.070 (0.105)	Data 0.00121 (0.00090)	Tok/s 51093 (59503)	Loss/tok 2.8253 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][2100/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00094)	Tok/s 52202 (59892)	Loss/tok 3.2278 (3.2101)	Learning Rate [7.8125e-05]
1: TRAIN [2][2100/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00090)	Tok/s 52226 (59496)	Loss/tok 3.0460 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][2100/6832]	Time 0.103 (0.105)	Data 0.00084 (0.00094)	Tok/s 52201 (60365)	Loss/tok 3.1377 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][2100/6832]	Time 0.103 (0.105)	Data 0.00094 (0.00100)	Tok/s 52185 (58992)	Loss/tok 3.1631 (3.2102)	Learning Rate [7.8125e-05]
2: TRAIN [2][2110/6832]	Time 0.088 (0.105)	Data 0.00092 (0.00094)	Tok/s 53607 (59899)	Loss/tok 3.0791 (3.2102)	Learning Rate [7.8125e-05]
1: TRAIN [2][2110/6832]	Time 0.088 (0.105)	Data 0.00084 (0.00090)	Tok/s 53579 (59504)	Loss/tok 3.1406 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][2110/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00094)	Tok/s 53579 (60372)	Loss/tok 3.1426 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][2110/6832]	Time 0.088 (0.105)	Data 0.00091 (0.00100)	Tok/s 53564 (59001)	Loss/tok 3.0743 (3.2104)	Learning Rate [7.8125e-05]
2: TRAIN [2][2120/6832]	Time 0.063 (0.105)	Data 0.00090 (0.00094)	Tok/s 51328 (59887)	Loss/tok 2.7761 (3.2102)	Learning Rate [7.8125e-05]
3: TRAIN [2][2120/6832]	Time 0.063 (0.105)	Data 0.00086 (0.00094)	Tok/s 53112 (60359)	Loss/tok 2.9322 (3.2131)	Learning Rate [7.8125e-05]
1: TRAIN [2][2120/6832]	Time 0.063 (0.105)	Data 0.00083 (0.00090)	Tok/s 51013 (59493)	Loss/tok 3.0050 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][2120/6832]	Time 0.063 (0.105)	Data 0.00091 (0.00100)	Tok/s 51062 (58992)	Loss/tok 2.6915 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][2130/6832]	Time 0.110 (0.105)	Data 0.00092 (0.00090)	Tok/s 54706 (59479)	Loss/tok 3.2618 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][2130/6832]	Time 0.110 (0.105)	Data 0.00090 (0.00094)	Tok/s 54661 (59872)	Loss/tok 3.1737 (3.2102)	Learning Rate [7.8125e-05]
0: TRAIN [2][2130/6832]	Time 0.110 (0.105)	Data 0.00098 (0.00099)	Tok/s 54050 (58979)	Loss/tok 3.1146 (3.2102)	Learning Rate [7.8125e-05]
3: TRAIN [2][2130/6832]	Time 0.110 (0.105)	Data 0.00088 (0.00094)	Tok/s 54654 (60343)	Loss/tok 3.3621 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][2140/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00094)	Tok/s 55056 (59882)	Loss/tok 3.0323 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][2140/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00094)	Tok/s 55066 (60352)	Loss/tok 3.1750 (3.2131)	Learning Rate [7.8125e-05]
1: TRAIN [2][2140/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00090)	Tok/s 55054 (59489)	Loss/tok 2.8794 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2140/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00099)	Tok/s 53907 (58989)	Loss/tok 3.1773 (3.2100)	Learning Rate [7.8125e-05]
2: TRAIN [2][2150/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00094)	Tok/s 53943 (59883)	Loss/tok 3.2454 (3.2099)	Learning Rate [7.8125e-05]
3: TRAIN [2][2150/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00094)	Tok/s 53944 (60352)	Loss/tok 3.2142 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][2150/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00090)	Tok/s 53253 (59491)	Loss/tok 3.1619 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][2150/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00099)	Tok/s 52863 (58992)	Loss/tok 3.1977 (3.2102)	Learning Rate [7.8125e-05]
1: TRAIN [2][2160/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00090)	Tok/s 82177 (59516)	Loss/tok 3.0505 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][2160/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00099)	Tok/s 81363 (59017)	Loss/tok 3.2638 (3.2101)	Learning Rate [7.8125e-05]
2: TRAIN [2][2160/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 82293 (59908)	Loss/tok 3.2109 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][2160/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 83135 (60377)	Loss/tok 3.2301 (3.2135)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][2170/6832]	Time 0.076 (0.105)	Data 0.00089 (0.00090)	Tok/s 52338 (59527)	Loss/tok 3.0561 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][2170/6832]	Time 0.076 (0.105)	Data 0.00097 (0.00099)	Tok/s 52351 (59029)	Loss/tok 3.1322 (3.2104)	Learning Rate [7.8125e-05]
2: TRAIN [2][2170/6832]	Time 0.076 (0.105)	Data 0.00098 (0.00094)	Tok/s 52701 (59918)	Loss/tok 3.0214 (3.2103)	Learning Rate [7.8125e-05]
3: TRAIN [2][2170/6832]	Time 0.076 (0.105)	Data 0.00097 (0.00094)	Tok/s 54019 (60387)	Loss/tok 3.0345 (3.2136)	Learning Rate [7.8125e-05]
1: TRAIN [2][2180/6832]	Time 0.108 (0.105)	Data 0.00083 (0.00090)	Tok/s 54603 (59516)	Loss/tok 3.0478 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][2180/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00094)	Tok/s 55564 (59908)	Loss/tok 3.0158 (3.2098)	Learning Rate [7.8125e-05]
3: TRAIN [2][2180/6832]	Time 0.108 (0.105)	Data 0.00091 (0.00094)	Tok/s 55559 (60378)	Loss/tok 3.2620 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][2180/6832]	Time 0.108 (0.105)	Data 0.00089 (0.00099)	Tok/s 54389 (59020)	Loss/tok 3.1434 (3.2100)	Learning Rate [7.8125e-05]
2: TRAIN [2][2190/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00094)	Tok/s 53280 (59897)	Loss/tok 2.9884 (3.2098)	Learning Rate [7.8125e-05]
1: TRAIN [2][2190/6832]	Time 0.110 (0.105)	Data 0.00099 (0.00090)	Tok/s 53294 (59504)	Loss/tok 3.2071 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2190/6832]	Time 0.111 (0.105)	Data 0.00103 (0.00099)	Tok/s 52696 (59009)	Loss/tok 3.3042 (3.2101)	Learning Rate [7.8125e-05]
3: TRAIN [2][2190/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00094)	Tok/s 53274 (60365)	Loss/tok 3.2267 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2200/6832]	Time 0.097 (0.105)	Data 0.00096 (0.00094)	Tok/s 53041 (59902)	Loss/tok 3.0691 (3.2098)	Learning Rate [7.8125e-05]
1: TRAIN [2][2200/6832]	Time 0.096 (0.105)	Data 0.00106 (0.00090)	Tok/s 52352 (59510)	Loss/tok 2.9800 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][2200/6832]	Time 0.096 (0.105)	Data 0.00090 (0.00094)	Tok/s 53060 (60370)	Loss/tok 3.0739 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [2][2200/6832]	Time 0.096 (0.105)	Data 0.00107 (0.00099)	Tok/s 51759 (59016)	Loss/tok 3.2470 (3.2103)	Learning Rate [7.8125e-05]
2: TRAIN [2][2210/6832]	Time 0.073 (0.105)	Data 0.00097 (0.00094)	Tok/s 52318 (59888)	Loss/tok 2.9260 (3.2099)	Learning Rate [7.8125e-05]
1: TRAIN [2][2210/6832]	Time 0.073 (0.105)	Data 0.00097 (0.00090)	Tok/s 52306 (59497)	Loss/tok 3.0279 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2210/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00099)	Tok/s 51382 (59004)	Loss/tok 3.0740 (3.2104)	Learning Rate [7.8125e-05]
3: TRAIN [2][2210/6832]	Time 0.073 (0.105)	Data 0.00098 (0.00094)	Tok/s 52350 (60355)	Loss/tok 2.9465 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][2220/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00094)	Tok/s 52767 (59861)	Loss/tok 3.1710 (3.2097)	Learning Rate [7.8125e-05]
1: TRAIN [2][2220/6832]	Time 0.078 (0.105)	Data 0.00082 (0.00090)	Tok/s 52736 (59469)	Loss/tok 3.1319 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2220/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00099)	Tok/s 52710 (58972)	Loss/tok 2.9966 (3.2100)	Learning Rate [7.8125e-05]
3: TRAIN [2][2220/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00094)	Tok/s 52778 (60329)	Loss/tok 2.9420 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][2230/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 76739 (59852)	Loss/tok 3.3174 (3.2098)	Learning Rate [7.8125e-05]
1: TRAIN [2][2230/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00090)	Tok/s 76625 (59462)	Loss/tok 3.2338 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][2230/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00099)	Tok/s 75941 (58967)	Loss/tok 3.3735 (3.2101)	Learning Rate [7.8125e-05]
3: TRAIN [2][2230/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 77421 (60322)	Loss/tok 3.1634 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][2240/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00094)	Tok/s 52550 (59839)	Loss/tok 3.1065 (3.2099)	Learning Rate [7.8125e-05]
1: TRAIN [2][2240/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00090)	Tok/s 52539 (59450)	Loss/tok 3.0496 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][2240/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00094)	Tok/s 52551 (60308)	Loss/tok 3.0032 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][2240/6832]	Time 0.078 (0.105)	Data 0.00089 (0.00099)	Tok/s 52497 (58957)	Loss/tok 2.9672 (3.2105)	Learning Rate [7.8125e-05]
2: TRAIN [2][2250/6832]	Time 0.086 (0.105)	Data 0.00098 (0.00094)	Tok/s 50335 (59828)	Loss/tok 3.2851 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][2250/6832]	Time 0.087 (0.105)	Data 0.00098 (0.00090)	Tok/s 50292 (59441)	Loss/tok 3.0682 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][2250/6832]	Time 0.086 (0.105)	Data 0.00112 (0.00094)	Tok/s 51556 (60297)	Loss/tok 3.0632 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][2250/6832]	Time 0.087 (0.105)	Data 0.00105 (0.00099)	Tok/s 50290 (58949)	Loss/tok 3.4246 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][2260/6832]	Time 0.064 (0.105)	Data 0.00086 (0.00090)	Tok/s 50040 (59424)	Loss/tok 2.8808 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][2260/6832]	Time 0.064 (0.105)	Data 0.00086 (0.00094)	Tok/s 50802 (59814)	Loss/tok 2.7568 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][2260/6832]	Time 0.064 (0.105)	Data 0.00094 (0.00099)	Tok/s 50018 (58927)	Loss/tok 2.9654 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][2260/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00094)	Tok/s 51921 (60283)	Loss/tok 3.0741 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2270/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 65566 (59801)	Loss/tok 3.3557 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][2270/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00090)	Tok/s 65212 (59412)	Loss/tok 3.2999 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2270/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00099)	Tok/s 65259 (58917)	Loss/tok 3.3050 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][2270/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 66212 (60269)	Loss/tok 3.4380 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][2280/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00094)	Tok/s 54347 (59795)	Loss/tok 3.1749 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][2280/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00090)	Tok/s 54332 (59406)	Loss/tok 3.0688 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2280/6832]	Time 0.097 (0.105)	Data 0.00104 (0.00099)	Tok/s 54365 (58913)	Loss/tok 3.1615 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][2280/6832]	Time 0.097 (0.105)	Data 0.00094 (0.00094)	Tok/s 54357 (60263)	Loss/tok 3.1458 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][2290/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00094)	Tok/s 61025 (59765)	Loss/tok 3.2978 (3.2103)	Learning Rate [7.8125e-05]
1: TRAIN [2][2290/6832]	Time 0.125 (0.105)	Data 0.00085 (0.00090)	Tok/s 60363 (59374)	Loss/tok 3.2841 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2290/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00099)	Tok/s 60313 (58876)	Loss/tok 3.2719 (3.2105)	Learning Rate [7.8125e-05]
3: TRAIN [2][2290/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00094)	Tok/s 61435 (60234)	Loss/tok 3.3118 (3.2135)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][2300/6832]	Time 0.057 (0.105)	Data 0.00086 (0.00094)	Tok/s 49717 (59767)	Loss/tok 2.7491 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][2300/6832]	Time 0.057 (0.105)	Data 0.00083 (0.00090)	Tok/s 49279 (59377)	Loss/tok 2.6739 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][2300/6832]	Time 0.057 (0.105)	Data 0.00092 (0.00099)	Tok/s 47332 (58880)	Loss/tok 2.7078 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][2300/6832]	Time 0.056 (0.105)	Data 0.00091 (0.00094)	Tok/s 50531 (60235)	Loss/tok 2.7473 (3.2135)	Learning Rate [7.8125e-05]
1: TRAIN [2][2310/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00090)	Tok/s 50164 (59377)	Loss/tok 2.7579 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][2310/6832]	Time 0.061 (0.105)	Data 0.00096 (0.00094)	Tok/s 50150 (59767)	Loss/tok 2.9080 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][2310/6832]	Time 0.061 (0.105)	Data 0.00103 (0.00099)	Tok/s 50181 (58881)	Loss/tok 2.8865 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][2310/6832]	Time 0.061 (0.105)	Data 0.00094 (0.00094)	Tok/s 51714 (60235)	Loss/tok 2.7287 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][2320/6832]	Time 0.107 (0.105)	Data 0.00087 (0.00094)	Tok/s 53745 (59760)	Loss/tok 3.0905 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][2320/6832]	Time 0.107 (0.105)	Data 0.00085 (0.00090)	Tok/s 53764 (59372)	Loss/tok 3.2100 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2320/6832]	Time 0.107 (0.105)	Data 0.00096 (0.00099)	Tok/s 53789 (58877)	Loss/tok 3.3503 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][2320/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00094)	Tok/s 53768 (60229)	Loss/tok 3.1178 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][2330/6832]	Time 0.075 (0.105)	Data 0.00097 (0.00094)	Tok/s 52640 (59750)	Loss/tok 3.0158 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][2330/6832]	Time 0.075 (0.105)	Data 0.00100 (0.00090)	Tok/s 52650 (59363)	Loss/tok 3.0205 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][2330/6832]	Time 0.075 (0.105)	Data 0.00097 (0.00094)	Tok/s 52636 (60219)	Loss/tok 3.1168 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][2330/6832]	Time 0.075 (0.105)	Data 0.00104 (0.00099)	Tok/s 52671 (58870)	Loss/tok 3.0945 (3.2112)	Learning Rate [7.8125e-05]
2: TRAIN [2][2340/6832]	Time 0.103 (0.105)	Data 0.00097 (0.00094)	Tok/s 54893 (59739)	Loss/tok 3.1603 (3.2105)	Learning Rate [7.8125e-05]
1: TRAIN [2][2340/6832]	Time 0.103 (0.105)	Data 0.00095 (0.00090)	Tok/s 54814 (59352)	Loss/tok 3.2218 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][2340/6832]	Time 0.103 (0.105)	Data 0.00100 (0.00099)	Tok/s 53669 (58860)	Loss/tok 3.2110 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][2340/6832]	Time 0.102 (0.105)	Data 0.00095 (0.00094)	Tok/s 54949 (60208)	Loss/tok 3.1064 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2350/6832]	Time 0.056 (0.105)	Data 0.00097 (0.00094)	Tok/s 48061 (59723)	Loss/tok 2.5711 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][2350/6832]	Time 0.056 (0.105)	Data 0.00092 (0.00090)	Tok/s 46676 (59337)	Loss/tok 2.5834 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][2350/6832]	Time 0.056 (0.105)	Data 0.00097 (0.00099)	Tok/s 45653 (58845)	Loss/tok 2.7694 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][2350/6832]	Time 0.056 (0.105)	Data 0.00096 (0.00094)	Tok/s 48054 (60193)	Loss/tok 2.6237 (3.2135)	Learning Rate [7.8125e-05]
1: TRAIN [2][2360/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00090)	Tok/s 58145 (59336)	Loss/tok 3.2549 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][2360/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00099)	Tok/s 58122 (58845)	Loss/tok 3.3164 (3.2107)	Learning Rate [7.8125e-05]
2: TRAIN [2][2360/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00094)	Tok/s 58506 (59722)	Loss/tok 3.2979 (3.2102)	Learning Rate [7.8125e-05]
3: TRAIN [2][2360/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00094)	Tok/s 59501 (60192)	Loss/tok 3.2382 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2370/6832]	Time 0.079 (0.105)	Data 0.00105 (0.00094)	Tok/s 53625 (59721)	Loss/tok 3.2031 (3.2102)	Learning Rate [7.8125e-05]
1: TRAIN [2][2370/6832]	Time 0.079 (0.105)	Data 0.00097 (0.00090)	Tok/s 52591 (59336)	Loss/tok 3.2770 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][2370/6832]	Time 0.079 (0.105)	Data 0.00102 (0.00099)	Tok/s 52004 (58846)	Loss/tok 2.9801 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][2370/6832]	Time 0.079 (0.105)	Data 0.00100 (0.00094)	Tok/s 53627 (60189)	Loss/tok 3.1993 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2380/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 70312 (59731)	Loss/tok 3.1433 (3.2103)	Learning Rate [7.8125e-05]
1: TRAIN [2][2380/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00090)	Tok/s 70077 (59345)	Loss/tok 3.3536 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][2380/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00099)	Tok/s 70117 (58855)	Loss/tok 3.3523 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][2380/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 71120 (60198)	Loss/tok 3.2572 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][2390/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 53311 (59725)	Loss/tok 3.1927 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][2390/6832]	Time 0.113 (0.105)	Data 0.00084 (0.00090)	Tok/s 53310 (59339)	Loss/tok 3.2696 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][2390/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00099)	Tok/s 53288 (58850)	Loss/tok 3.0701 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][2390/6832]	Time 0.113 (0.105)	Data 0.00098 (0.00094)	Tok/s 53348 (60191)	Loss/tok 3.1552 (3.2139)	Learning Rate [7.8125e-05]
2: TRAIN [2][2400/6832]	Time 0.093 (0.105)	Data 0.00085 (0.00094)	Tok/s 53589 (59710)	Loss/tok 3.1012 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][2400/6832]	Time 0.093 (0.105)	Data 0.00089 (0.00094)	Tok/s 53613 (60175)	Loss/tok 3.1621 (3.2137)	Learning Rate [7.8125e-05]
1: TRAIN [2][2400/6832]	Time 0.093 (0.105)	Data 0.00086 (0.00090)	Tok/s 53581 (59326)	Loss/tok 3.1763 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][2400/6832]	Time 0.093 (0.105)	Data 0.00088 (0.00099)	Tok/s 53579 (58838)	Loss/tok 3.0726 (3.2112)	Learning Rate [7.8125e-05]
2: TRAIN [2][2410/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00094)	Tok/s 53811 (59705)	Loss/tok 3.1923 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][2410/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00090)	Tok/s 53810 (59322)	Loss/tok 3.0546 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][2410/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00094)	Tok/s 53851 (60168)	Loss/tok 3.3193 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [2][2410/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00099)	Tok/s 53766 (58835)	Loss/tok 2.9211 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][2420/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00090)	Tok/s 63811 (59322)	Loss/tok 3.3221 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][2420/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00099)	Tok/s 63833 (58832)	Loss/tok 3.3510 (3.2112)	Learning Rate [7.8125e-05]
2: TRAIN [2][2420/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00094)	Tok/s 63752 (59706)	Loss/tok 3.5370 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][2420/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 63734 (60170)	Loss/tok 3.3463 (3.2139)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][2430/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 75861 (59701)	Loss/tok 3.1944 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][2430/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00090)	Tok/s 74941 (59315)	Loss/tok 3.2208 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][2430/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00099)	Tok/s 74934 (58820)	Loss/tok 3.3080 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][2430/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 75860 (60166)	Loss/tok 3.2900 (3.2138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2440/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 92363 (59714)	Loss/tok 3.0551 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][2440/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00090)	Tok/s 91084 (59328)	Loss/tok 3.0360 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][2440/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00099)	Tok/s 90043 (58835)	Loss/tok 3.0820 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][2440/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 94172 (60179)	Loss/tok 3.0615 (3.2140)	Learning Rate [7.8125e-05]
2: TRAIN [2][2450/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00094)	Tok/s 73151 (59715)	Loss/tok 3.4163 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][2450/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00090)	Tok/s 72578 (59330)	Loss/tok 3.3270 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][2450/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 73154 (60180)	Loss/tok 3.1637 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][2450/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00099)	Tok/s 72152 (58837)	Loss/tok 3.2663 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][2460/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00090)	Tok/s 53256 (59333)	Loss/tok 3.2372 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2460/6832]	Time 0.110 (0.105)	Data 0.00090 (0.00099)	Tok/s 52435 (58837)	Loss/tok 3.2496 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][2460/6832]	Time 0.110 (0.105)	Data 0.00101 (0.00094)	Tok/s 53587 (59720)	Loss/tok 3.1259 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][2460/6832]	Time 0.110 (0.105)	Data 0.00100 (0.00094)	Tok/s 53557 (60185)	Loss/tok 3.1870 (3.2140)	Learning Rate [7.8125e-05]
2: TRAIN [2][2470/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 64140 (59715)	Loss/tok 3.3978 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][2470/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00090)	Tok/s 64095 (59329)	Loss/tok 3.3961 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][2470/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 64691 (60181)	Loss/tok 3.3691 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][2470/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00099)	Tok/s 64093 (58834)	Loss/tok 3.5335 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][2480/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00090)	Tok/s 52963 (59334)	Loss/tok 3.1504 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][2480/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00094)	Tok/s 52923 (59720)	Loss/tok 3.1708 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][2480/6832]	Time 0.075 (0.105)	Data 0.00091 (0.00098)	Tok/s 52952 (58840)	Loss/tok 3.0427 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][2480/6832]	Time 0.075 (0.105)	Data 0.00086 (0.00094)	Tok/s 52919 (60185)	Loss/tok 3.0295 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][2490/6832]	Time 0.100 (0.105)	Data 0.00087 (0.00094)	Tok/s 53604 (59718)	Loss/tok 3.1460 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][2490/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00094)	Tok/s 53600 (60183)	Loss/tok 3.1557 (3.2142)	Learning Rate [7.8125e-05]
1: TRAIN [2][2490/6832]	Time 0.100 (0.105)	Data 0.00097 (0.00090)	Tok/s 53602 (59333)	Loss/tok 3.1368 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2490/6832]	Time 0.100 (0.105)	Data 0.00099 (0.00098)	Tok/s 53613 (58840)	Loss/tok 3.1749 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][2500/6832]	Time 0.089 (0.105)	Data 0.00085 (0.00094)	Tok/s 51787 (59704)	Loss/tok 2.9973 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][2500/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00090)	Tok/s 51683 (59319)	Loss/tok 3.0215 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][2500/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00094)	Tok/s 51800 (60168)	Loss/tok 3.1246 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2500/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00098)	Tok/s 50342 (58826)	Loss/tok 3.4128 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2510/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00090)	Tok/s 70375 (59299)	Loss/tok 3.2795 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][2510/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00094)	Tok/s 70360 (59686)	Loss/tok 3.4370 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][2510/6832]	Time 0.125 (0.105)	Data 0.00085 (0.00094)	Tok/s 70401 (60150)	Loss/tok 3.4116 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [2][2510/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00098)	Tok/s 70251 (58803)	Loss/tok 3.2744 (3.2116)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [2][2520/6832]	Time 0.096 (0.105)	Data 0.00097 (0.00094)	Tok/s 53164 (59692)	Loss/tok 3.1450 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][2520/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00090)	Tok/s 53252 (59306)	Loss/tok 3.0448 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][2520/6832]	Time 0.096 (0.105)	Data 0.00100 (0.00094)	Tok/s 54109 (60156)	Loss/tok 3.0593 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][2520/6832]	Time 0.096 (0.105)	Data 0.00095 (0.00098)	Tok/s 53231 (58812)	Loss/tok 3.1426 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][2530/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00094)	Tok/s 52598 (59664)	Loss/tok 3.1708 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][2530/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00094)	Tok/s 52935 (60128)	Loss/tok 3.2328 (3.2142)	Learning Rate [7.8125e-05]
1: TRAIN [2][2530/6832]	Time 0.097 (0.105)	Data 0.00085 (0.00090)	Tok/s 52550 (59279)	Loss/tok 3.1545 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2530/6832]	Time 0.097 (0.105)	Data 0.00098 (0.00098)	Tok/s 52585 (58785)	Loss/tok 3.0661 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2540/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00090)	Tok/s 91496 (59294)	Loss/tok 3.0589 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][2540/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 92762 (59679)	Loss/tok 3.0991 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][2540/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 94703 (60142)	Loss/tok 3.0827 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][2540/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00098)	Tok/s 90439 (58800)	Loss/tok 3.2318 (3.2115)	Learning Rate [7.8125e-05]
2: TRAIN [2][2550/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00094)	Tok/s 57344 (59676)	Loss/tok 3.3918 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][2550/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00090)	Tok/s 56634 (59291)	Loss/tok 3.2380 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][2550/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00094)	Tok/s 57736 (60138)	Loss/tok 3.2393 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [2][2550/6832]	Time 0.113 (0.105)	Data 0.00104 (0.00098)	Tok/s 56612 (58799)	Loss/tok 3.3585 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][2560/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 50344 (59680)	Loss/tok 3.2824 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][2560/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 50576 (60142)	Loss/tok 3.2593 (3.2142)	Learning Rate [7.8125e-05]
1: TRAIN [2][2560/6832]	Time 0.120 (0.105)	Data 0.00082 (0.00090)	Tok/s 50300 (59295)	Loss/tok 3.3708 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][2560/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00098)	Tok/s 50301 (58804)	Loss/tok 3.2582 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][2570/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 56343 (59673)	Loss/tok 3.2364 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][2570/6832]	Time 0.127 (0.105)	Data 0.00083 (0.00090)	Tok/s 56323 (59287)	Loss/tok 3.2515 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][2570/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 56326 (60134)	Loss/tok 3.1744 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2570/6832]	Time 0.127 (0.105)	Data 0.00098 (0.00098)	Tok/s 55359 (58797)	Loss/tok 3.1015 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][2580/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00094)	Tok/s 52417 (59665)	Loss/tok 3.1908 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][2580/6832]	Time 0.110 (0.105)	Data 0.00090 (0.00094)	Tok/s 52395 (60126)	Loss/tok 3.2258 (3.2145)	Learning Rate [7.8125e-05]
1: TRAIN [2][2580/6832]	Time 0.110 (0.105)	Data 0.00085 (0.00090)	Tok/s 52345 (59281)	Loss/tok 3.2866 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][2580/6832]	Time 0.110 (0.105)	Data 0.00100 (0.00098)	Tok/s 52367 (58792)	Loss/tok 3.0841 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][2590/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00094)	Tok/s 52041 (59655)	Loss/tok 3.1900 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][2590/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00094)	Tok/s 52056 (60115)	Loss/tok 3.0372 (3.2144)	Learning Rate [7.8125e-05]
1: TRAIN [2][2590/6832]	Time 0.103 (0.105)	Data 0.00083 (0.00090)	Tok/s 50818 (59270)	Loss/tok 3.3271 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][2590/6832]	Time 0.103 (0.105)	Data 0.00102 (0.00098)	Tok/s 50806 (58782)	Loss/tok 3.0810 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2600/6832]	Time 0.084 (0.105)	Data 0.00084 (0.00090)	Tok/s 51889 (59269)	Loss/tok 3.1469 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][2600/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00094)	Tok/s 51876 (59653)	Loss/tok 3.0948 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][2600/6832]	Time 0.084 (0.105)	Data 0.00091 (0.00094)	Tok/s 51885 (60113)	Loss/tok 3.0681 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2600/6832]	Time 0.084 (0.105)	Data 0.00098 (0.00098)	Tok/s 51925 (58781)	Loss/tok 3.2472 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][2610/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00090)	Tok/s 52870 (59243)	Loss/tok 3.1214 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][2610/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00094)	Tok/s 53408 (59628)	Loss/tok 3.2297 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][2610/6832]	Time 0.122 (0.105)	Data 0.00094 (0.00094)	Tok/s 53462 (60088)	Loss/tok 3.1974 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][2610/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00098)	Tok/s 52421 (58756)	Loss/tok 3.2665 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][2620/6832]	Time 0.107 (0.105)	Data 0.00087 (0.00090)	Tok/s 53667 (59225)	Loss/tok 3.1487 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][2620/6832]	Time 0.107 (0.105)	Data 0.00084 (0.00094)	Tok/s 53698 (59609)	Loss/tok 3.0895 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][2620/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00094)	Tok/s 53704 (60068)	Loss/tok 3.2633 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [2][2620/6832]	Time 0.107 (0.105)	Data 0.00096 (0.00098)	Tok/s 53732 (58739)	Loss/tok 3.1778 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][2630/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00090)	Tok/s 69382 (59218)	Loss/tok 3.3229 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][2630/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 69568 (59601)	Loss/tok 3.2212 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][2630/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 70442 (60059)	Loss/tok 3.5156 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [2][2630/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00098)	Tok/s 69407 (58734)	Loss/tok 3.2750 (3.2118)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [2][2640/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00090)	Tok/s 52989 (59206)	Loss/tok 2.8806 (3.2122)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
2: TRAIN [2][2640/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00094)	Tok/s 52915 (59588)	Loss/tok 3.0244 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][2640/6832]	Time 0.080 (0.105)	Data 0.00097 (0.00094)	Tok/s 52880 (60046)	Loss/tok 3.0300 (3.2144)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2640/6832]	Time 0.080 (0.105)	Data 0.00094 (0.00098)	Tok/s 51483 (58723)	Loss/tok 3.0516 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2650/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00090)	Tok/s 51665 (59205)	Loss/tok 3.4485 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][2650/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00094)	Tok/s 51595 (59588)	Loss/tok 3.1518 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][2650/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00094)	Tok/s 51545 (60046)	Loss/tok 3.2167 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2650/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00098)	Tok/s 50757 (58718)	Loss/tok 3.0680 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][2660/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00090)	Tok/s 67112 (59200)	Loss/tok 3.2071 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][2660/6832]	Time 0.130 (0.105)	Data 0.00083 (0.00094)	Tok/s 67110 (59582)	Loss/tok 3.4924 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][2660/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 67612 (60040)	Loss/tok 3.3413 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][2660/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00098)	Tok/s 67100 (58712)	Loss/tok 3.2606 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][2670/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00090)	Tok/s 61482 (59228)	Loss/tok 3.5005 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][2670/6832]	Time 0.127 (0.105)	Data 0.00083 (0.00094)	Tok/s 61473 (59610)	Loss/tok 3.4394 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][2670/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00098)	Tok/s 61488 (58742)	Loss/tok 3.3247 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][2670/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 61464 (60067)	Loss/tok 3.4664 (3.2147)	Learning Rate [7.8125e-05]
1: TRAIN [2][2680/6832]	Time 0.047 (0.105)	Data 0.00090 (0.00090)	Tok/s 44192 (59215)	Loss/tok 2.4193 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][2680/6832]	Time 0.046 (0.105)	Data 0.00106 (0.00094)	Tok/s 46850 (59598)	Loss/tok 2.3704 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][2680/6832]	Time 0.047 (0.105)	Data 0.00090 (0.00098)	Tok/s 41246 (58729)	Loss/tok 2.3038 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][2680/6832]	Time 0.047 (0.105)	Data 0.00107 (0.00094)	Tok/s 47261 (60055)	Loss/tok 2.4727 (3.2149)	Learning Rate [7.8125e-05]
1: TRAIN [2][2690/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00090)	Tok/s 72979 (59237)	Loss/tok 3.3233 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][2690/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00098)	Tok/s 72178 (58752)	Loss/tok 3.4940 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][2690/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 73099 (59619)	Loss/tok 3.3054 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][2690/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 73091 (60076)	Loss/tok 3.1914 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][2700/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00090)	Tok/s 83740 (59256)	Loss/tok 3.3217 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][2700/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00098)	Tok/s 82924 (58772)	Loss/tok 3.2203 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][2700/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 83688 (59638)	Loss/tok 3.1978 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][2700/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 84578 (60095)	Loss/tok 3.1215 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][2710/6832]	Time 0.097 (0.105)	Data 0.00086 (0.00090)	Tok/s 52991 (59243)	Loss/tok 3.1808 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][2710/6832]	Time 0.097 (0.105)	Data 0.00085 (0.00094)	Tok/s 52977 (59625)	Loss/tok 3.1420 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][2710/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00094)	Tok/s 54053 (60083)	Loss/tok 3.3339 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][2710/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00098)	Tok/s 52956 (58759)	Loss/tok 3.1369 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][2720/6832]	Time 0.127 (0.105)	Data 0.00101 (0.00090)	Tok/s 67348 (59252)	Loss/tok 3.3129 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][2720/6832]	Time 0.127 (0.105)	Data 0.00107 (0.00098)	Tok/s 67317 (58769)	Loss/tok 3.3041 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][2720/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 67320 (59634)	Loss/tok 3.4016 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][2720/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00094)	Tok/s 68096 (60093)	Loss/tok 3.3493 (3.2149)	Learning Rate [7.8125e-05]
1: TRAIN [2][2730/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00090)	Tok/s 67141 (59244)	Loss/tok 3.4830 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][2730/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00098)	Tok/s 67069 (58763)	Loss/tok 3.3795 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][2730/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 67057 (59625)	Loss/tok 3.1457 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][2730/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00094)	Tok/s 67028 (60085)	Loss/tok 3.3315 (3.2148)	Learning Rate [7.8125e-05]
2: TRAIN [2][2740/6832]	Time 0.113 (0.105)	Data 0.00083 (0.00094)	Tok/s 55645 (59616)	Loss/tok 3.3527 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][2740/6832]	Time 0.113 (0.105)	Data 0.00084 (0.00090)	Tok/s 54808 (59235)	Loss/tok 3.2896 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][2740/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00094)	Tok/s 55634 (60075)	Loss/tok 3.0367 (3.2147)	Learning Rate [7.8125e-05]
0: TRAIN [2][2740/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00098)	Tok/s 54500 (58755)	Loss/tok 3.3790 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][2750/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00090)	Tok/s 61731 (59240)	Loss/tok 3.3154 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][2750/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 62173 (59621)	Loss/tok 3.4585 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][2750/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00094)	Tok/s 62672 (60079)	Loss/tok 3.1185 (3.2147)	Learning Rate [7.8125e-05]
0: TRAIN [2][2750/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00098)	Tok/s 61699 (58760)	Loss/tok 3.3245 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][2760/6832]	Time 0.119 (0.105)	Data 0.00084 (0.00090)	Tok/s 54629 (59236)	Loss/tok 3.3143 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][2760/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00094)	Tok/s 54594 (59616)	Loss/tok 3.4119 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][2760/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00094)	Tok/s 54924 (60074)	Loss/tok 3.3029 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][2760/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00098)	Tok/s 54612 (58757)	Loss/tok 3.3189 (3.2125)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][2770/6832]	Time 0.116 (0.105)	Data 0.00100 (0.00094)	Tok/s 53147 (59608)	Loss/tok 3.2472 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][2770/6832]	Time 0.116 (0.105)	Data 0.00101 (0.00090)	Tok/s 53162 (59227)	Loss/tok 3.3463 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][2770/6832]	Time 0.116 (0.105)	Data 0.00107 (0.00098)	Tok/s 52370 (58745)	Loss/tok 3.1510 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][2770/6832]	Time 0.116 (0.105)	Data 0.00106 (0.00094)	Tok/s 53172 (60066)	Loss/tok 3.4324 (3.2148)	Learning Rate [7.8125e-05]
2: TRAIN [2][2780/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00094)	Tok/s 49036 (59600)	Loss/tok 2.9186 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2780/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00090)	Tok/s 48907 (59218)	Loss/tok 2.9768 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][2780/6832]	Time 0.071 (0.105)	Data 0.00097 (0.00098)	Tok/s 48948 (58737)	Loss/tok 2.7821 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][2780/6832]	Time 0.071 (0.105)	Data 0.00099 (0.00094)	Tok/s 50767 (60058)	Loss/tok 3.0512 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][2790/6832]	Time 0.133 (0.105)	Data 0.00082 (0.00094)	Tok/s 87751 (59608)	Loss/tok 3.1758 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][2790/6832]	Time 0.133 (0.105)	Data 0.00083 (0.00090)	Tok/s 87206 (59225)	Loss/tok 3.0042 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][2790/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00098)	Tok/s 86457 (58741)	Loss/tok 3.2039 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][2790/6832]	Time 0.133 (0.105)	Data 0.00085 (0.00094)	Tok/s 88640 (60068)	Loss/tok 3.1386 (3.2149)	Learning Rate [7.8125e-05]
1: TRAIN [2][2800/6832]	Time 0.044 (0.105)	Data 0.00085 (0.00090)	Tok/s 33041 (59226)	Loss/tok 2.0707 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][2800/6832]	Time 0.044 (0.105)	Data 0.00083 (0.00094)	Tok/s 37696 (59611)	Loss/tok 1.8934 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2800/6832]	Time 0.044 (0.105)	Data 0.00091 (0.00098)	Tok/s 22316 (58739)	Loss/tok 1.6987 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][2800/6832]	Time 0.044 (0.105)	Data 0.00088 (0.00094)	Tok/s 40300 (60071)	Loss/tok 2.3980 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][2810/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00090)	Tok/s 70311 (59229)	Loss/tok 3.1939 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][2810/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 70286 (59613)	Loss/tok 3.6389 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][2810/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 71271 (60073)	Loss/tok 3.4569 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][2810/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00098)	Tok/s 70299 (58743)	Loss/tok 3.4209 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][2820/6832]	Time 0.118 (0.105)	Data 0.00084 (0.00090)	Tok/s 54322 (59243)	Loss/tok 3.1817 (3.2138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2820/6832]	Time 0.118 (0.105)	Data 0.00083 (0.00094)	Tok/s 55155 (59627)	Loss/tok 3.3287 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][2820/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00094)	Tok/s 55389 (60086)	Loss/tok 3.2480 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][2820/6832]	Time 0.118 (0.105)	Data 0.00100 (0.00098)	Tok/s 54311 (58758)	Loss/tok 3.1390 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][2830/6832]	Time 0.110 (0.105)	Data 0.00083 (0.00090)	Tok/s 59350 (59243)	Loss/tok 3.0512 (3.2137)	Learning Rate [7.8125e-05]
2: TRAIN [2][2830/6832]	Time 0.110 (0.105)	Data 0.00085 (0.00094)	Tok/s 60065 (59626)	Loss/tok 3.2430 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][2830/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00098)	Tok/s 59351 (58759)	Loss/tok 3.2789 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][2830/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00094)	Tok/s 60483 (60087)	Loss/tok 3.2867 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][2840/6832]	Time 0.084 (0.105)	Data 0.00085 (0.00090)	Tok/s 55163 (59272)	Loss/tok 3.2067 (3.2138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2840/6832]	Time 0.084 (0.105)	Data 0.00084 (0.00094)	Tok/s 55127 (59655)	Loss/tok 3.1700 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][2840/6832]	Time 0.083 (0.105)	Data 0.00093 (0.00098)	Tok/s 55201 (58789)	Loss/tok 3.1664 (3.2128)	Learning Rate [7.8125e-05]
3: TRAIN [2][2840/6832]	Time 0.084 (0.105)	Data 0.00095 (0.00094)	Tok/s 55362 (60114)	Loss/tok 3.0919 (3.2153)	Learning Rate [7.8125e-05]
1: TRAIN [2][2850/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00090)	Tok/s 68027 (59258)	Loss/tok 3.4415 (3.2138)	Learning Rate [7.8125e-05]
2: TRAIN [2][2850/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00094)	Tok/s 67946 (59641)	Loss/tok 3.4340 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][2850/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00098)	Tok/s 67977 (58774)	Loss/tok 3.3973 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][2850/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 68923 (60100)	Loss/tok 3.3242 (3.2152)	Learning Rate [7.8125e-05]
1: TRAIN [2][2860/6832]	Time 0.105 (0.105)	Data 0.00085 (0.00090)	Tok/s 54861 (59253)	Loss/tok 3.2083 (3.2141)	Learning Rate [7.8125e-05]
3: TRAIN [2][2860/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00094)	Tok/s 54875 (60093)	Loss/tok 3.2748 (3.2154)	Learning Rate [7.8125e-05]
2: TRAIN [2][2860/6832]	Time 0.105 (0.105)	Data 0.00084 (0.00094)	Tok/s 54870 (59634)	Loss/tok 3.1746 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][2860/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00098)	Tok/s 54851 (58769)	Loss/tok 3.3356 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][2870/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00090)	Tok/s 61326 (59264)	Loss/tok 3.3533 (3.2141)	Learning Rate [7.8125e-05]
2: TRAIN [2][2870/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00094)	Tok/s 61364 (59646)	Loss/tok 3.3266 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][2870/6832]	Time 0.121 (0.105)	Data 0.00105 (0.00094)	Tok/s 61369 (60104)	Loss/tok 3.2490 (3.2156)	Learning Rate [7.8125e-05]
0: TRAIN [2][2870/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00098)	Tok/s 61199 (58782)	Loss/tok 3.2568 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][2880/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00090)	Tok/s 68600 (59253)	Loss/tok 3.4125 (3.2140)	Learning Rate [7.8125e-05]
2: TRAIN [2][2880/6832]	Time 0.131 (0.105)	Data 0.00083 (0.00094)	Tok/s 68533 (59634)	Loss/tok 3.4149 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][2880/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00098)	Tok/s 68629 (58772)	Loss/tok 3.2672 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][2880/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 69017 (60092)	Loss/tok 3.3537 (3.2156)	Learning Rate [7.8125e-05]
2: TRAIN [2][2890/6832]	Time 0.115 (0.105)	Data 0.00083 (0.00094)	Tok/s 53237 (59626)	Loss/tok 3.1597 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][2890/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00090)	Tok/s 53226 (59245)	Loss/tok 3.2614 (3.2142)	Learning Rate [7.8125e-05]
3: TRAIN [2][2890/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00094)	Tok/s 54032 (60083)	Loss/tok 3.2016 (3.2156)	Learning Rate [7.8125e-05]
0: TRAIN [2][2890/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00098)	Tok/s 53199 (58765)	Loss/tok 3.1711 (3.2130)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][2900/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00094)	Tok/s 49913 (59608)	Loss/tok 3.2423 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][2900/6832]	Time 0.113 (0.105)	Data 0.00084 (0.00090)	Tok/s 49925 (59228)	Loss/tok 3.0979 (3.2140)	Learning Rate [7.8125e-05]
3: TRAIN [2][2900/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00094)	Tok/s 49926 (60065)	Loss/tok 3.1974 (3.2156)	Learning Rate [7.8125e-05]
0: TRAIN [2][2900/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00098)	Tok/s 48857 (58748)	Loss/tok 3.1841 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][2910/6832]	Time 0.103 (0.105)	Data 0.00083 (0.00094)	Tok/s 53526 (59595)	Loss/tok 3.2317 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][2910/6832]	Time 0.103 (0.105)	Data 0.00084 (0.00090)	Tok/s 53532 (59215)	Loss/tok 3.0900 (3.2138)	Learning Rate [7.8125e-05]
0: TRAIN [2][2910/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00098)	Tok/s 53500 (58737)	Loss/tok 3.1580 (3.2128)	Learning Rate [7.8125e-05]
3: TRAIN [2][2910/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00094)	Tok/s 53499 (60051)	Loss/tok 3.2696 (3.2157)	Learning Rate [7.8125e-05]
1: TRAIN [2][2920/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00090)	Tok/s 51593 (59217)	Loss/tok 3.0587 (3.2137)	Learning Rate [7.8125e-05]
2: TRAIN [2][2920/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00094)	Tok/s 51807 (59597)	Loss/tok 3.1203 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][2920/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00098)	Tok/s 50711 (58739)	Loss/tok 3.0299 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][2920/6832]	Time 0.086 (0.105)	Data 0.00101 (0.00094)	Tok/s 51821 (60053)	Loss/tok 3.0749 (3.2157)	Learning Rate [7.8125e-05]
2: TRAIN [2][2930/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00094)	Tok/s 55443 (59621)	Loss/tok 3.2482 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][2930/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00090)	Tok/s 55455 (59241)	Loss/tok 3.1841 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][2930/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00094)	Tok/s 55456 (60077)	Loss/tok 3.3048 (3.2158)	Learning Rate [7.8125e-05]
0: TRAIN [2][2930/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00098)	Tok/s 55452 (58764)	Loss/tok 3.3269 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][2940/6832]	Time 0.094 (0.105)	Data 0.00085 (0.00094)	Tok/s 53180 (59610)	Loss/tok 2.9974 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2940/6832]	Time 0.094 (0.105)	Data 0.00088 (0.00090)	Tok/s 51859 (59230)	Loss/tok 3.1025 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][2940/6832]	Time 0.094 (0.105)	Data 0.00093 (0.00098)	Tok/s 51869 (58753)	Loss/tok 2.9944 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][2940/6832]	Time 0.094 (0.105)	Data 0.00094 (0.00094)	Tok/s 53260 (60065)	Loss/tok 3.1032 (3.2156)	Learning Rate [7.8125e-05]
2: TRAIN [2][2950/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00094)	Tok/s 53813 (59598)	Loss/tok 3.1561 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][2950/6832]	Time 0.095 (0.105)	Data 0.00086 (0.00090)	Tok/s 53754 (59218)	Loss/tok 3.0857 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][2950/6832]	Time 0.095 (0.105)	Data 0.00091 (0.00098)	Tok/s 53788 (58742)	Loss/tok 3.0694 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][2950/6832]	Time 0.095 (0.105)	Data 0.00093 (0.00094)	Tok/s 55055 (60052)	Loss/tok 3.0655 (3.2156)	Learning Rate [7.8125e-05]
2: TRAIN [2][2960/6832]	Time 0.133 (0.105)	Data 0.00084 (0.00094)	Tok/s 88017 (59620)	Loss/tok 3.0455 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][2960/6832]	Time 0.133 (0.105)	Data 0.00086 (0.00090)	Tok/s 87331 (59240)	Loss/tok 3.0910 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][2960/6832]	Time 0.133 (0.105)	Data 0.00093 (0.00098)	Tok/s 86713 (58764)	Loss/tok 3.1101 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][2960/6832]	Time 0.133 (0.105)	Data 0.00095 (0.00094)	Tok/s 88707 (60074)	Loss/tok 3.1789 (3.2155)	Learning Rate [7.8125e-05]
1: TRAIN [2][2970/6832]	Time 0.118 (0.105)	Data 0.00084 (0.00090)	Tok/s 57477 (59231)	Loss/tok 3.3887 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][2970/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00094)	Tok/s 57511 (59611)	Loss/tok 3.2520 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][2970/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00098)	Tok/s 56862 (58755)	Loss/tok 3.2428 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][2970/6832]	Time 0.118 (0.105)	Data 0.00104 (0.00094)	Tok/s 57512 (60064)	Loss/tok 3.2883 (3.2154)	Learning Rate [7.8125e-05]
1: TRAIN [2][2980/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00090)	Tok/s 54613 (59231)	Loss/tok 3.2047 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][2980/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00098)	Tok/s 53683 (58755)	Loss/tok 3.2742 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][2980/6832]	Time 0.124 (0.105)	Data 0.00086 (0.00094)	Tok/s 54608 (59610)	Loss/tok 3.1597 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][2980/6832]	Time 0.124 (0.105)	Data 0.00101 (0.00094)	Tok/s 54609 (60064)	Loss/tok 3.1810 (3.2152)	Learning Rate [7.8125e-05]
1: TRAIN [2][2990/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00090)	Tok/s 52497 (59264)	Loss/tok 3.1047 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][2990/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00094)	Tok/s 52524 (59644)	Loss/tok 3.2167 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][2990/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00098)	Tok/s 51669 (58789)	Loss/tok 3.1970 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][2990/6832]	Time 0.105 (0.105)	Data 0.00093 (0.00094)	Tok/s 53237 (60098)	Loss/tok 2.9950 (3.2151)	Learning Rate [7.8125e-05]
2: TRAIN [2][3000/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00094)	Tok/s 64683 (59676)	Loss/tok 3.1710 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][3000/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00090)	Tok/s 64170 (59296)	Loss/tok 3.4844 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][3000/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00098)	Tok/s 64173 (58821)	Loss/tok 3.2472 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3000/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 65167 (60130)	Loss/tok 3.3425 (3.2150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3010/6832]	Time 0.120 (0.105)	Data 0.00083 (0.00090)	Tok/s 53382 (59290)	Loss/tok 3.2759 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][3010/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00094)	Tok/s 53845 (59670)	Loss/tok 3.3505 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][3010/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00097)	Tok/s 53419 (58815)	Loss/tok 3.2375 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][3010/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00094)	Tok/s 54459 (60123)	Loss/tok 3.4259 (3.2149)	Learning Rate [7.8125e-05]
1: TRAIN [2][3020/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00090)	Tok/s 49883 (59289)	Loss/tok 3.0728 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][3020/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00094)	Tok/s 49878 (59669)	Loss/tok 3.2314 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][3020/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00094)	Tok/s 50962 (60123)	Loss/tok 3.1831 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][3020/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00097)	Tok/s 49877 (58815)	Loss/tok 3.2627 (3.2127)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][3030/6832]	Time 0.127 (0.105)	Data 0.00084 (0.00090)	Tok/s 60091 (59277)	Loss/tok 3.4308 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][3030/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00097)	Tok/s 59300 (58803)	Loss/tok 3.3259 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][3030/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 60258 (59657)	Loss/tok 3.4600 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][3030/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 60185 (60111)	Loss/tok 3.3483 (3.2152)	Learning Rate [7.8125e-05]
1: TRAIN [2][3040/6832]	Time 0.133 (0.105)	Data 0.00085 (0.00090)	Tok/s 90542 (59279)	Loss/tok 3.1078 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][3040/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00094)	Tok/s 91974 (59659)	Loss/tok 3.2338 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][3040/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00097)	Tok/s 89699 (58805)	Loss/tok 3.1693 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3040/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00094)	Tok/s 94013 (60114)	Loss/tok 3.0667 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3050/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00094)	Tok/s 53048 (59649)	Loss/tok 3.2311 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][3050/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00090)	Tok/s 52941 (59270)	Loss/tok 3.3135 (3.2132)	Learning Rate [7.8125e-05]
3: TRAIN [2][3050/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 53047 (60103)	Loss/tok 3.0874 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3050/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00097)	Tok/s 52919 (58796)	Loss/tok 3.3282 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][3060/6832]	Time 0.103 (0.105)	Data 0.00093 (0.00094)	Tok/s 52665 (59627)	Loss/tok 3.1082 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][3060/6832]	Time 0.103 (0.105)	Data 0.00098 (0.00090)	Tok/s 52291 (59245)	Loss/tok 3.1980 (3.2131)	Learning Rate [7.8125e-05]
3: TRAIN [2][3060/6832]	Time 0.103 (0.105)	Data 0.00108 (0.00094)	Tok/s 53508 (60084)	Loss/tok 3.2394 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][3060/6832]	Time 0.103 (0.105)	Data 0.00103 (0.00097)	Tok/s 52314 (58764)	Loss/tok 3.1403 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][3070/6832]	Time 0.092 (0.105)	Data 0.00088 (0.00090)	Tok/s 54223 (59233)	Loss/tok 3.0996 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][3070/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00094)	Tok/s 54218 (59615)	Loss/tok 3.2191 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][3070/6832]	Time 0.092 (0.105)	Data 0.00097 (0.00094)	Tok/s 54218 (60072)	Loss/tok 3.1417 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][3070/6832]	Time 0.092 (0.105)	Data 0.00089 (0.00097)	Tok/s 54226 (58753)	Loss/tok 3.2119 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][3080/6832]	Time 0.076 (0.105)	Data 0.00085 (0.00094)	Tok/s 52049 (59615)	Loss/tok 2.8681 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][3080/6832]	Time 0.076 (0.105)	Data 0.00085 (0.00090)	Tok/s 52054 (59233)	Loss/tok 2.8795 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][3080/6832]	Time 0.076 (0.105)	Data 0.00091 (0.00097)	Tok/s 52076 (58754)	Loss/tok 3.2006 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][3080/6832]	Time 0.076 (0.105)	Data 0.00094 (0.00094)	Tok/s 52197 (60071)	Loss/tok 3.0023 (3.2149)	Learning Rate [7.8125e-05]
1: TRAIN [2][3090/6832]	Time 0.121 (0.105)	Data 0.00084 (0.00090)	Tok/s 63714 (59239)	Loss/tok 3.3532 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][3090/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00097)	Tok/s 63714 (58761)	Loss/tok 3.2268 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][3090/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00094)	Tok/s 64701 (59620)	Loss/tok 3.2145 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][3090/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00094)	Tok/s 64692 (60076)	Loss/tok 3.4597 (3.2149)	Learning Rate [7.8125e-05]
1: TRAIN [2][3100/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00090)	Tok/s 64065 (59240)	Loss/tok 3.2568 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][3100/6832]	Time 0.124 (0.105)	Data 0.00083 (0.00094)	Tok/s 64039 (59621)	Loss/tok 3.2055 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][3100/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00097)	Tok/s 64057 (58762)	Loss/tok 3.3024 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3100/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00095)	Tok/s 64081 (60077)	Loss/tok 3.3572 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][3110/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00090)	Tok/s 83652 (59259)	Loss/tok 3.2824 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][3110/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00097)	Tok/s 83221 (58781)	Loss/tok 3.1313 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][3110/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00094)	Tok/s 84201 (59639)	Loss/tok 3.2203 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][3110/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00095)	Tok/s 84593 (60096)	Loss/tok 3.0436 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3120/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00094)	Tok/s 57589 (59642)	Loss/tok 3.2844 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][3120/6832]	Time 0.125 (0.105)	Data 0.00084 (0.00090)	Tok/s 57551 (59262)	Loss/tok 3.4331 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][3120/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00097)	Tok/s 57303 (58786)	Loss/tok 3.4053 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][3120/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00095)	Tok/s 57609 (60098)	Loss/tok 3.1046 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][3130/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00090)	Tok/s 56884 (59261)	Loss/tok 3.2784 (3.2138)	Learning Rate [7.8125e-05]
2: TRAIN [2][3130/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00094)	Tok/s 56852 (59642)	Loss/tok 3.1538 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][3130/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00097)	Tok/s 56855 (58781)	Loss/tok 3.3091 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3130/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00095)	Tok/s 56858 (60099)	Loss/tok 3.3461 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][3140/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00090)	Tok/s 61327 (59265)	Loss/tok 3.4341 (3.2139)	Learning Rate [7.8125e-05]
2: TRAIN [2][3140/6832]	Time 0.125 (0.105)	Data 0.00086 (0.00094)	Tok/s 61683 (59645)	Loss/tok 3.4988 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][3140/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00097)	Tok/s 60646 (58785)	Loss/tok 3.3621 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][3140/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00095)	Tok/s 61690 (60102)	Loss/tok 3.3107 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][3150/6832]	Time 0.094 (0.105)	Data 0.00092 (0.00090)	Tok/s 53043 (59246)	Loss/tok 3.0181 (3.2138)	Learning Rate [7.8125e-05]
2: TRAIN [2][3150/6832]	Time 0.094 (0.105)	Data 0.00093 (0.00094)	Tok/s 54107 (59629)	Loss/tok 3.1420 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][3150/6832]	Time 0.094 (0.105)	Data 0.00094 (0.00095)	Tok/s 54405 (60087)	Loss/tok 3.4258 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][3150/6832]	Time 0.094 (0.105)	Data 0.00090 (0.00097)	Tok/s 53059 (58764)	Loss/tok 3.1392 (3.2126)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [2][3160/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00090)	Tok/s 53579 (59245)	Loss/tok 3.2453 (3.2139)	Learning Rate [7.8125e-05]
2: TRAIN [2][3160/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00094)	Tok/s 53576 (59627)	Loss/tok 3.2287 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][3160/6832]	Time 0.110 (0.105)	Data 0.00093 (0.00095)	Tok/s 53578 (60085)	Loss/tok 3.1700 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][3160/6832]	Time 0.110 (0.105)	Data 0.00093 (0.00097)	Tok/s 52994 (58763)	Loss/tok 3.2337 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][3170/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00094)	Tok/s 69978 (59628)	Loss/tok 3.3566 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][3170/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00090)	Tok/s 69853 (59246)	Loss/tok 3.4251 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [2][3170/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00097)	Tok/s 69844 (58764)	Loss/tok 3.3370 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][3170/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 70855 (60086)	Loss/tok 3.3952 (3.2148)	Learning Rate [7.8125e-05]
2: TRAIN [2][3180/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00094)	Tok/s 52374 (59621)	Loss/tok 3.1634 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][3180/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00090)	Tok/s 52349 (59240)	Loss/tok 3.2030 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3180/6832]	Time 0.105 (0.105)	Data 0.00097 (0.00095)	Tok/s 52385 (60078)	Loss/tok 3.1922 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][3180/6832]	Time 0.105 (0.105)	Data 0.00096 (0.00097)	Tok/s 52123 (58759)	Loss/tok 3.1590 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][3190/6832]	Time 0.059 (0.105)	Data 0.00085 (0.00090)	Tok/s 49783 (59238)	Loss/tok 2.6635 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][3190/6832]	Time 0.059 (0.105)	Data 0.00085 (0.00094)	Tok/s 49792 (59618)	Loss/tok 2.7667 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][3190/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00095)	Tok/s 51769 (60076)	Loss/tok 2.7807 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][3190/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00097)	Tok/s 49820 (58758)	Loss/tok 2.8435 (3.2126)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
1: Skipped batch, new scale: 4096.0
0: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [2][3200/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00090)	Tok/s 55285 (59260)	Loss/tok 3.3501 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][3200/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00094)	Tok/s 55257 (59640)	Loss/tok 3.2018 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][3200/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00097)	Tok/s 55286 (58780)	Loss/tok 3.2809 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3200/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00095)	Tok/s 55258 (60097)	Loss/tok 3.4367 (3.2150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3210/6832]	Time 0.057 (0.105)	Data 0.00084 (0.00090)	Tok/s 51678 (59261)	Loss/tok 2.7960 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][3210/6832]	Time 0.057 (0.105)	Data 0.00088 (0.00097)	Tok/s 51685 (58782)	Loss/tok 2.7641 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][3210/6832]	Time 0.057 (0.105)	Data 0.00087 (0.00094)	Tok/s 51472 (59640)	Loss/tok 2.7845 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][3210/6832]	Time 0.057 (0.105)	Data 0.00092 (0.00095)	Tok/s 52775 (60098)	Loss/tok 2.8030 (3.2147)	Learning Rate [7.8125e-05]
1: TRAIN [2][3220/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00090)	Tok/s 55399 (59248)	Loss/tok 3.2776 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][3220/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 55362 (59627)	Loss/tok 3.2911 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][3220/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00097)	Tok/s 54506 (58769)	Loss/tok 3.1883 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3220/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00095)	Tok/s 55365 (60084)	Loss/tok 3.1678 (3.2147)	Learning Rate [7.8125e-05]
1: TRAIN [2][3230/6832]	Time 0.108 (0.105)	Data 0.00093 (0.00090)	Tok/s 53406 (59241)	Loss/tok 3.2706 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][3230/6832]	Time 0.108 (0.105)	Data 0.00098 (0.00094)	Tok/s 53376 (59620)	Loss/tok 3.2559 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][3230/6832]	Time 0.108 (0.105)	Data 0.00117 (0.00097)	Tok/s 53463 (58762)	Loss/tok 3.2121 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][3230/6832]	Time 0.108 (0.105)	Data 0.00097 (0.00095)	Tok/s 53437 (60076)	Loss/tok 3.4255 (3.2149)	Learning Rate [7.8125e-05]
2: TRAIN [2][3240/6832]	Time 0.090 (0.105)	Data 0.00084 (0.00094)	Tok/s 52336 (59619)	Loss/tok 3.2988 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][3240/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00090)	Tok/s 52313 (59242)	Loss/tok 3.1403 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][3240/6832]	Time 0.091 (0.105)	Data 0.00092 (0.00097)	Tok/s 52318 (58764)	Loss/tok 3.1021 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][3240/6832]	Time 0.090 (0.105)	Data 0.00095 (0.00095)	Tok/s 52627 (60076)	Loss/tok 3.2277 (3.2148)	Learning Rate [7.8125e-05]
2: TRAIN [2][3250/6832]	Time 0.106 (0.105)	Data 0.00086 (0.00094)	Tok/s 52128 (59619)	Loss/tok 3.1771 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][3250/6832]	Time 0.106 (0.105)	Data 0.00084 (0.00090)	Tok/s 52090 (59240)	Loss/tok 3.4236 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][3250/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00097)	Tok/s 52103 (58760)	Loss/tok 3.0367 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3250/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00095)	Tok/s 52111 (60077)	Loss/tok 3.1424 (3.2146)	Learning Rate [7.8125e-05]
1: TRAIN [2][3260/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00090)	Tok/s 52236 (59234)	Loss/tok 2.9467 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][3260/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00097)	Tok/s 52259 (58756)	Loss/tok 2.8333 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][3260/6832]	Time 0.061 (0.105)	Data 0.00086 (0.00094)	Tok/s 52054 (59613)	Loss/tok 2.8070 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][3260/6832]	Time 0.062 (0.105)	Data 0.00092 (0.00095)	Tok/s 53732 (60070)	Loss/tok 3.0808 (3.2146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3270/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00094)	Tok/s 68971 (59613)	Loss/tok 3.3353 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][3270/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00090)	Tok/s 68883 (59234)	Loss/tok 3.3622 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3270/6832]	Time 0.126 (0.105)	Data 0.00100 (0.00095)	Tok/s 69551 (60070)	Loss/tok 3.2122 (3.2146)	Learning Rate [7.8125e-05]
0: TRAIN [2][3270/6832]	Time 0.126 (0.105)	Data 0.00097 (0.00097)	Tok/s 68899 (58755)	Loss/tok 3.2694 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][3280/6832]	Time 0.069 (0.105)	Data 0.00091 (0.00094)	Tok/s 52084 (59617)	Loss/tok 3.0178 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][3280/6832]	Time 0.069 (0.105)	Data 0.00088 (0.00090)	Tok/s 52072 (59239)	Loss/tok 2.8306 (3.2132)	Learning Rate [7.8125e-05]
3: TRAIN [2][3280/6832]	Time 0.069 (0.105)	Data 0.00093 (0.00095)	Tok/s 53196 (60076)	Loss/tok 3.3111 (3.2147)	Learning Rate [7.8125e-05]
0: TRAIN [2][3280/6832]	Time 0.069 (0.105)	Data 0.00093 (0.00097)	Tok/s 52039 (58759)	Loss/tok 2.9365 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][3290/6832]	Time 0.114 (0.105)	Data 0.00083 (0.00090)	Tok/s 56873 (59246)	Loss/tok 3.3151 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][3290/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00094)	Tok/s 57028 (59624)	Loss/tok 3.0904 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][3290/6832]	Time 0.114 (0.105)	Data 0.00085 (0.00097)	Tok/s 55902 (58766)	Loss/tok 3.0657 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][3290/6832]	Time 0.114 (0.105)	Data 0.00091 (0.00095)	Tok/s 57039 (60082)	Loss/tok 3.0866 (3.2146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3300/6832]	Time 0.101 (0.105)	Data 0.00090 (0.00093)	Tok/s 52121 (59621)	Loss/tok 3.1870 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][3300/6832]	Time 0.101 (0.105)	Data 0.00090 (0.00090)	Tok/s 52085 (59244)	Loss/tok 3.3300 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][3300/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00097)	Tok/s 52110 (58764)	Loss/tok 3.2499 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][3300/6832]	Time 0.101 (0.105)	Data 0.00091 (0.00095)	Tok/s 52136 (60078)	Loss/tok 2.9931 (3.2146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3310/6832]	Time 0.065 (0.105)	Data 0.00110 (0.00094)	Tok/s 50035 (59619)	Loss/tok 2.8789 (3.2111)	Learning Rate [7.8125e-05]
1: TRAIN [2][3310/6832]	Time 0.065 (0.105)	Data 0.00097 (0.00090)	Tok/s 48969 (59242)	Loss/tok 2.7594 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][3310/6832]	Time 0.065 (0.105)	Data 0.00098 (0.00097)	Tok/s 49032 (58763)	Loss/tok 2.9625 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3310/6832]	Time 0.064 (0.105)	Data 0.00108 (0.00095)	Tok/s 51640 (60076)	Loss/tok 2.7868 (3.2143)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][3320/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00090)	Tok/s 59697 (59253)	Loss/tok 3.1353 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][3320/6832]	Time 0.118 (0.105)	Data 0.00112 (0.00093)	Tok/s 59706 (59629)	Loss/tok 3.3531 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][3320/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00097)	Tok/s 59734 (58775)	Loss/tok 3.1088 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3320/6832]	Time 0.118 (0.105)	Data 0.00104 (0.00095)	Tok/s 59772 (60086)	Loss/tok 3.1625 (3.2144)	Learning Rate [7.8125e-05]
2: TRAIN [2][3330/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00093)	Tok/s 56136 (59625)	Loss/tok 3.2872 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][3330/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00090)	Tok/s 56144 (59248)	Loss/tok 3.3291 (3.2135)	Learning Rate [7.8125e-05]
0: TRAIN [2][3330/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00097)	Tok/s 56120 (58771)	Loss/tok 3.4392 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3330/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00095)	Tok/s 56912 (60082)	Loss/tok 3.0619 (3.2143)	Learning Rate [7.8125e-05]
2: TRAIN [2][3340/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00093)	Tok/s 52783 (59635)	Loss/tok 2.9789 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][3340/6832]	Time 0.073 (0.105)	Data 0.00097 (0.00095)	Tok/s 52786 (60092)	Loss/tok 2.9797 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][3340/6832]	Time 0.073 (0.105)	Data 0.00095 (0.00097)	Tok/s 51081 (58781)	Loss/tok 3.0164 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][3340/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00090)	Tok/s 51896 (59258)	Loss/tok 3.0889 (3.2137)	Learning Rate [7.8125e-05]
1: TRAIN [2][3350/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00090)	Tok/s 57290 (59258)	Loss/tok 3.2269 (3.2137)	Learning Rate [7.8125e-05]
2: TRAIN [2][3350/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00093)	Tok/s 57244 (59636)	Loss/tok 3.4223 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][3350/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00097)	Tok/s 57267 (58778)	Loss/tok 3.3456 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3350/6832]	Time 0.123 (0.105)	Data 0.00094 (0.00095)	Tok/s 57250 (60094)	Loss/tok 3.2561 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][3360/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00093)	Tok/s 64755 (59634)	Loss/tok 3.3319 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][3360/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00095)	Tok/s 65305 (60092)	Loss/tok 3.3062 (3.2141)	Learning Rate [7.8125e-05]
1: TRAIN [2][3360/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00090)	Tok/s 64730 (59256)	Loss/tok 3.4252 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][3360/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00097)	Tok/s 64756 (58776)	Loss/tok 3.3481 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][3370/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00093)	Tok/s 53972 (59631)	Loss/tok 3.2109 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][3370/6832]	Time 0.114 (0.105)	Data 0.00100 (0.00090)	Tok/s 54009 (59251)	Loss/tok 3.2877 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3370/6832]	Time 0.114 (0.105)	Data 0.00099 (0.00095)	Tok/s 54923 (60089)	Loss/tok 3.3109 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][3370/6832]	Time 0.114 (0.105)	Data 0.00096 (0.00097)	Tok/s 54005 (58769)	Loss/tok 3.2770 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][3380/6832]	Time 0.051 (0.105)	Data 0.00088 (0.00093)	Tok/s 47617 (59618)	Loss/tok 2.6817 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][3380/6832]	Time 0.051 (0.105)	Data 0.00089 (0.00095)	Tok/s 49086 (60078)	Loss/tok 2.6347 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][3380/6832]	Time 0.051 (0.105)	Data 0.00089 (0.00097)	Tok/s 45145 (58752)	Loss/tok 2.4541 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][3380/6832]	Time 0.051 (0.105)	Data 0.00092 (0.00090)	Tok/s 46565 (59236)	Loss/tok 2.5047 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][3390/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 62486 (59636)	Loss/tok 3.3114 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][3390/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 62991 (60096)	Loss/tok 3.1542 (3.2143)	Learning Rate [7.8125e-05]
1: TRAIN [2][3390/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00090)	Tok/s 62446 (59254)	Loss/tok 3.2750 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][3390/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00097)	Tok/s 62429 (58770)	Loss/tok 3.2563 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][3400/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 81629 (59653)	Loss/tok 3.1276 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][3400/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00090)	Tok/s 81449 (59272)	Loss/tok 3.1574 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3400/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00095)	Tok/s 82316 (60114)	Loss/tok 3.2056 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [2][3400/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00097)	Tok/s 80665 (58788)	Loss/tok 3.2453 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][3410/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 82011 (59658)	Loss/tok 3.0292 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][3410/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00090)	Tok/s 81909 (59277)	Loss/tok 3.4346 (3.2138)	Learning Rate [7.8125e-05]
0: TRAIN [2][3410/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00097)	Tok/s 81066 (58794)	Loss/tok 3.1546 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3410/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 82722 (60118)	Loss/tok 3.1225 (3.2143)	Learning Rate [7.8125e-05]
2: TRAIN [2][3420/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00093)	Tok/s 72612 (59661)	Loss/tok 3.2630 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][3420/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00090)	Tok/s 71592 (59279)	Loss/tok 3.4096 (3.2141)	Learning Rate [7.8125e-05]
3: TRAIN [2][3420/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 72644 (60119)	Loss/tok 3.3579 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][3420/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00097)	Tok/s 71623 (58797)	Loss/tok 3.2401 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][3430/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00093)	Tok/s 54754 (59647)	Loss/tok 2.8976 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][3430/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00095)	Tok/s 55019 (60105)	Loss/tok 3.1046 (3.2146)	Learning Rate [7.8125e-05]
0: TRAIN [2][3430/6832]	Time 0.103 (0.105)	Data 0.00099 (0.00097)	Tok/s 54794 (58785)	Loss/tok 3.1674 (3.2135)	Learning Rate [7.8125e-05]
1: TRAIN [2][3430/6832]	Time 0.103 (0.105)	Data 0.00103 (0.00090)	Tok/s 54785 (59266)	Loss/tok 3.1467 (3.2141)	Learning Rate [7.8125e-05]
2: TRAIN [2][3440/6832]	Time 0.087 (0.105)	Data 0.00085 (0.00093)	Tok/s 51707 (59637)	Loss/tok 3.1800 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][3440/6832]	Time 0.087 (0.105)	Data 0.00088 (0.00090)	Tok/s 51732 (59257)	Loss/tok 3.1880 (3.2142)	Learning Rate [7.8125e-05]
3: TRAIN [2][3440/6832]	Time 0.087 (0.105)	Data 0.00088 (0.00095)	Tok/s 51718 (60095)	Loss/tok 3.1313 (3.2147)	Learning Rate [7.8125e-05]
0: TRAIN [2][3440/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00097)	Tok/s 51741 (58775)	Loss/tok 2.9974 (3.2135)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][3450/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00090)	Tok/s 52459 (59253)	Loss/tok 2.9699 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [2][3450/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00097)	Tok/s 52416 (58772)	Loss/tok 3.0550 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][3450/6832]	Time 0.073 (0.105)	Data 0.00095 (0.00093)	Tok/s 52345 (59633)	Loss/tok 3.0846 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][3450/6832]	Time 0.073 (0.105)	Data 0.00093 (0.00095)	Tok/s 52805 (60090)	Loss/tok 2.8995 (3.2146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3460/6832]	Time 0.058 (0.105)	Data 0.00087 (0.00093)	Tok/s 48333 (59654)	Loss/tok 2.8618 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][3460/6832]	Time 0.058 (0.105)	Data 0.00090 (0.00090)	Tok/s 48349 (59275)	Loss/tok 2.7054 (3.2141)	Learning Rate [7.8125e-05]
3: TRAIN [2][3460/6832]	Time 0.058 (0.105)	Data 0.00087 (0.00095)	Tok/s 48321 (60112)	Loss/tok 2.5950 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][3460/6832]	Time 0.058 (0.105)	Data 0.00090 (0.00097)	Tok/s 46406 (58794)	Loss/tok 2.6739 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][3470/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 59721 (59655)	Loss/tok 3.3349 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][3470/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00090)	Tok/s 59631 (59276)	Loss/tok 3.2379 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][3470/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00097)	Tok/s 58748 (58796)	Loss/tok 3.3154 (3.2135)	Learning Rate [7.8125e-05]
3: TRAIN [2][3470/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00095)	Tok/s 59730 (60112)	Loss/tok 3.5218 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3480/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00093)	Tok/s 76148 (59657)	Loss/tok 3.2715 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][3480/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00095)	Tok/s 76179 (60113)	Loss/tok 3.2272 (3.2147)	Learning Rate [7.8125e-05]
1: TRAIN [2][3480/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00090)	Tok/s 76142 (59278)	Loss/tok 3.1609 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][3480/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00097)	Tok/s 75168 (58798)	Loss/tok 3.2894 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][3490/6832]	Time 0.074 (0.105)	Data 0.00086 (0.00093)	Tok/s 53121 (59642)	Loss/tok 3.2633 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][3490/6832]	Time 0.074 (0.105)	Data 0.00084 (0.00095)	Tok/s 53651 (60099)	Loss/tok 3.0367 (3.2145)	Learning Rate [7.8125e-05]
1: TRAIN [2][3490/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00090)	Tok/s 51911 (59262)	Loss/tok 3.0399 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [2][3490/6832]	Time 0.074 (0.105)	Data 0.00094 (0.00097)	Tok/s 51925 (58779)	Loss/tok 3.1382 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3500/6832]	Time 0.112 (0.105)	Data 0.00089 (0.00090)	Tok/s 52500 (59258)	Loss/tok 3.0868 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [2][3500/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00097)	Tok/s 51512 (58776)	Loss/tok 3.3169 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][3500/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00093)	Tok/s 52435 (59637)	Loss/tok 3.1352 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][3500/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00095)	Tok/s 51924 (60093)	Loss/tok 3.1997 (3.2145)	Learning Rate [7.8125e-05]
2: TRAIN [2][3510/6832]	Time 0.072 (0.105)	Data 0.00095 (0.00093)	Tok/s 55009 (59639)	Loss/tok 3.0980 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][3510/6832]	Time 0.072 (0.105)	Data 0.00095 (0.00090)	Tok/s 55016 (59261)	Loss/tok 2.9831 (3.2141)	Learning Rate [7.8125e-05]
3: TRAIN [2][3510/6832]	Time 0.072 (0.105)	Data 0.00094 (0.00095)	Tok/s 55990 (60095)	Loss/tok 3.0269 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][3510/6832]	Time 0.072 (0.105)	Data 0.00096 (0.00097)	Tok/s 54968 (58778)	Loss/tok 3.0203 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][3520/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 79115 (59644)	Loss/tok 3.2444 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][3520/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 79230 (60099)	Loss/tok 3.3302 (3.2147)	Learning Rate [7.8125e-05]
1: TRAIN [2][3520/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00090)	Tok/s 78834 (59265)	Loss/tok 3.2933 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][3520/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00097)	Tok/s 78171 (58783)	Loss/tok 3.2690 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][3530/6832]	Time 0.098 (0.105)	Data 0.00089 (0.00093)	Tok/s 52415 (59627)	Loss/tok 3.0897 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][3530/6832]	Time 0.098 (0.105)	Data 0.00110 (0.00091)	Tok/s 52455 (59249)	Loss/tok 3.3667 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [2][3530/6832]	Time 0.098 (0.105)	Data 0.00116 (0.00097)	Tok/s 52475 (58768)	Loss/tok 3.1190 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3530/6832]	Time 0.098 (0.105)	Data 0.00091 (0.00095)	Tok/s 52531 (60082)	Loss/tok 3.2053 (3.2146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3540/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00093)	Tok/s 54837 (59621)	Loss/tok 3.3114 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][3540/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00095)	Tok/s 55033 (60076)	Loss/tok 3.3197 (3.2146)	Learning Rate [7.8125e-05]
1: TRAIN [2][3540/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00091)	Tok/s 54839 (59244)	Loss/tok 3.2400 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][3540/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00097)	Tok/s 54848 (58763)	Loss/tok 3.1720 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][3550/6832]	Time 0.083 (0.105)	Data 0.00089 (0.00093)	Tok/s 55426 (59620)	Loss/tok 3.1250 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][3550/6832]	Time 0.083 (0.105)	Data 0.00092 (0.00097)	Tok/s 53890 (58762)	Loss/tok 3.1448 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][3550/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00091)	Tok/s 54764 (59242)	Loss/tok 3.1115 (3.2144)	Learning Rate [7.8125e-05]
3: TRAIN [2][3550/6832]	Time 0.083 (0.105)	Data 0.00095 (0.00095)	Tok/s 55474 (60075)	Loss/tok 3.0450 (3.2145)	Learning Rate [7.8125e-05]
2: TRAIN [2][3560/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00093)	Tok/s 52538 (59623)	Loss/tok 3.2211 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][3560/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00091)	Tok/s 52185 (59246)	Loss/tok 3.2948 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][3560/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00097)	Tok/s 52229 (58766)	Loss/tok 3.3208 (3.2135)	Learning Rate [7.8125e-05]
3: TRAIN [2][3560/6832]	Time 0.118 (0.105)	Data 0.00104 (0.00095)	Tok/s 53288 (60078)	Loss/tok 3.0944 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3570/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00093)	Tok/s 53821 (59631)	Loss/tok 3.1640 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][3570/6832]	Time 0.116 (0.105)	Data 0.00103 (0.00091)	Tok/s 53773 (59255)	Loss/tok 3.2202 (3.2146)	Learning Rate [7.8125e-05]
0: TRAIN [2][3570/6832]	Time 0.117 (0.105)	Data 0.00106 (0.00097)	Tok/s 52709 (58775)	Loss/tok 3.2483 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3570/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00095)	Tok/s 53825 (60086)	Loss/tok 3.2281 (3.2147)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][3580/6832]	Time 0.115 (0.105)	Data 0.00099 (0.00093)	Tok/s 57813 (59629)	Loss/tok 3.3060 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][3580/6832]	Time 0.115 (0.105)	Data 0.00102 (0.00097)	Tok/s 57810 (58774)	Loss/tok 3.2754 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3580/6832]	Time 0.115 (0.105)	Data 0.00100 (0.00091)	Tok/s 57792 (59252)	Loss/tok 3.2117 (3.2147)	Learning Rate [7.8125e-05]
3: TRAIN [2][3580/6832]	Time 0.115 (0.105)	Data 0.00106 (0.00095)	Tok/s 57802 (60083)	Loss/tok 3.1692 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3590/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00093)	Tok/s 70499 (59641)	Loss/tok 3.1906 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][3590/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00091)	Tok/s 69976 (59263)	Loss/tok 3.1680 (3.2147)	Learning Rate [7.8125e-05]
3: TRAIN [2][3590/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 70931 (60095)	Loss/tok 3.1496 (3.2147)	Learning Rate [7.8125e-05]
0: TRAIN [2][3590/6832]	Time 0.130 (0.105)	Data 0.00122 (0.00097)	Tok/s 70150 (58785)	Loss/tok 3.3100 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][3600/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00093)	Tok/s 52661 (59633)	Loss/tok 3.2305 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][3600/6832]	Time 0.105 (0.105)	Data 0.00095 (0.00091)	Tok/s 52650 (59257)	Loss/tok 3.1047 (3.2146)	Learning Rate [7.8125e-05]
0: TRAIN [2][3600/6832]	Time 0.105 (0.105)	Data 0.00093 (0.00097)	Tok/s 52654 (58779)	Loss/tok 3.0449 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3600/6832]	Time 0.105 (0.105)	Data 0.00096 (0.00095)	Tok/s 52669 (60088)	Loss/tok 3.2010 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3610/6832]	Time 0.094 (0.105)	Data 0.00089 (0.00093)	Tok/s 54338 (59636)	Loss/tok 3.0575 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][3610/6832]	Time 0.094 (0.105)	Data 0.00093 (0.00091)	Tok/s 54294 (59260)	Loss/tok 3.2076 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][3610/6832]	Time 0.094 (0.105)	Data 0.00092 (0.00097)	Tok/s 53584 (58783)	Loss/tok 2.9613 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3610/6832]	Time 0.094 (0.105)	Data 0.00092 (0.00095)	Tok/s 54356 (60090)	Loss/tok 3.1516 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3620/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00093)	Tok/s 59026 (59630)	Loss/tok 3.2529 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][3620/6832]	Time 0.117 (0.105)	Data 0.00102 (0.00091)	Tok/s 59046 (59254)	Loss/tok 3.4578 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][3620/6832]	Time 0.117 (0.105)	Data 0.00099 (0.00097)	Tok/s 58616 (58777)	Loss/tok 3.3376 (3.2135)	Learning Rate [7.8125e-05]
3: TRAIN [2][3620/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00095)	Tok/s 58952 (60084)	Loss/tok 3.3461 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3630/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00093)	Tok/s 54941 (59619)	Loss/tok 3.1651 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][3630/6832]	Time 0.112 (0.105)	Data 0.00097 (0.00091)	Tok/s 54948 (59244)	Loss/tok 3.1723 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][3630/6832]	Time 0.112 (0.105)	Data 0.00096 (0.00097)	Tok/s 54952 (58767)	Loss/tok 3.2512 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][3630/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00095)	Tok/s 54966 (60073)	Loss/tok 3.2939 (3.2150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3640/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00091)	Tok/s 61129 (59240)	Loss/tok 3.3568 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][3640/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00097)	Tok/s 61115 (58761)	Loss/tok 3.3372 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][3640/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00093)	Tok/s 61782 (59616)	Loss/tok 3.2825 (3.2128)	Learning Rate [7.8125e-05]
3: TRAIN [2][3640/6832]	Time 0.124 (0.105)	Data 0.00101 (0.00095)	Tok/s 61998 (60070)	Loss/tok 3.2129 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3650/6832]	Time 0.065 (0.105)	Data 0.00100 (0.00097)	Tok/s 49302 (58778)	Loss/tok 2.9105 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3650/6832]	Time 0.065 (0.105)	Data 0.00089 (0.00091)	Tok/s 49263 (59257)	Loss/tok 2.8812 (3.2149)	Learning Rate [7.8125e-05]
3: TRAIN [2][3650/6832]	Time 0.065 (0.105)	Data 0.00094 (0.00095)	Tok/s 51326 (60088)	Loss/tok 2.9048 (3.2151)	Learning Rate [7.8125e-05]
2: TRAIN [2][3650/6832]	Time 0.065 (0.105)	Data 0.00089 (0.00093)	Tok/s 51299 (59634)	Loss/tok 2.8894 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][3660/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00093)	Tok/s 51646 (59632)	Loss/tok 3.1331 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][3660/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00097)	Tok/s 51550 (58778)	Loss/tok 3.0030 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][3660/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00091)	Tok/s 51533 (59255)	Loss/tok 3.0962 (3.2149)	Learning Rate [7.8125e-05]
3: TRAIN [2][3660/6832]	Time 0.089 (0.105)	Data 0.00098 (0.00095)	Tok/s 52718 (60087)	Loss/tok 3.0996 (3.2151)	Learning Rate [7.8125e-05]
2: TRAIN [2][3670/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00093)	Tok/s 67353 (59640)	Loss/tok 3.2172 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][3670/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00091)	Tok/s 67339 (59263)	Loss/tok 3.3804 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][3670/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00097)	Tok/s 66759 (58786)	Loss/tok 3.5137 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3670/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 67349 (60094)	Loss/tok 3.2910 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3680/6832]	Time 0.073 (0.105)	Data 0.00090 (0.00097)	Tok/s 49094 (58773)	Loss/tok 2.9539 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3680/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00091)	Tok/s 49051 (59257)	Loss/tok 2.8642 (3.2149)	Learning Rate [7.8125e-05]
2: TRAIN [2][3680/6832]	Time 0.073 (0.105)	Data 0.00090 (0.00093)	Tok/s 49050 (59636)	Loss/tok 3.0002 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][3680/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00095)	Tok/s 49319 (60091)	Loss/tok 3.0424 (3.2150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3690/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00091)	Tok/s 88170 (59275)	Loss/tok 3.0757 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3690/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00093)	Tok/s 88650 (59653)	Loss/tok 3.1027 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][3690/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00097)	Tok/s 87228 (58792)	Loss/tok 3.0830 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3690/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00095)	Tok/s 89416 (60109)	Loss/tok 3.1038 (3.2150)	Learning Rate [7.8125e-05]
1: TRAIN [2][3700/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00091)	Tok/s 53701 (59271)	Loss/tok 3.1351 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3700/6832]	Time 0.100 (0.105)	Data 0.00088 (0.00093)	Tok/s 53676 (59650)	Loss/tok 3.1658 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][3700/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00097)	Tok/s 53704 (58787)	Loss/tok 3.1356 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3700/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00095)	Tok/s 54649 (60106)	Loss/tok 3.2546 (3.2151)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][3710/6832]	Time 0.082 (0.105)	Data 0.00086 (0.00093)	Tok/s 56414 (59646)	Loss/tok 3.0764 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][3710/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00091)	Tok/s 55766 (59268)	Loss/tok 3.0979 (3.2148)	Learning Rate [7.8125e-05]
3: TRAIN [2][3710/6832]	Time 0.082 (0.105)	Data 0.00091 (0.00095)	Tok/s 56411 (60102)	Loss/tok 3.0379 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][3710/6832]	Time 0.082 (0.105)	Data 0.00088 (0.00097)	Tok/s 54339 (58784)	Loss/tok 3.0904 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][3720/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00093)	Tok/s 81609 (59655)	Loss/tok 3.2466 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][3720/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00097)	Tok/s 80649 (58794)	Loss/tok 3.2555 (3.2132)	Learning Rate [7.8125e-05]
1: TRAIN [2][3720/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00091)	Tok/s 81581 (59277)	Loss/tok 3.1445 (3.2148)	Learning Rate [7.8125e-05]
3: TRAIN [2][3720/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00095)	Tok/s 82477 (60110)	Loss/tok 3.1206 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3730/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00093)	Tok/s 53218 (59642)	Loss/tok 3.0571 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][3730/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00097)	Tok/s 53192 (58781)	Loss/tok 3.1498 (3.2132)	Learning Rate [7.8125e-05]
1: TRAIN [2][3730/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00091)	Tok/s 53190 (59264)	Loss/tok 3.3292 (3.2149)	Learning Rate [7.8125e-05]
3: TRAIN [2][3730/6832]	Time 0.118 (0.105)	Data 0.00099 (0.00095)	Tok/s 53222 (60097)	Loss/tok 3.1458 (3.2149)	Learning Rate [7.8125e-05]
2: TRAIN [2][3740/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00093)	Tok/s 81327 (59642)	Loss/tok 3.2453 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][3740/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00091)	Tok/s 80392 (59264)	Loss/tok 3.2500 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][3740/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00097)	Tok/s 80389 (58782)	Loss/tok 3.2509 (3.2132)	Learning Rate [7.8125e-05]
3: TRAIN [2][3740/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 81445 (60097)	Loss/tok 3.1710 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][3750/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00097)	Tok/s 69414 (58797)	Loss/tok 3.2828 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][3750/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00091)	Tok/s 69418 (59278)	Loss/tok 3.5785 (3.2154)	Learning Rate [7.8125e-05]
3: TRAIN [2][3750/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 70076 (60110)	Loss/tok 3.4192 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3750/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 69344 (59656)	Loss/tok 3.1919 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][3760/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00093)	Tok/s 66352 (59648)	Loss/tok 3.5738 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][3760/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00097)	Tok/s 66371 (58790)	Loss/tok 3.3497 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3760/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00091)	Tok/s 66349 (59271)	Loss/tok 3.4729 (3.2155)	Learning Rate [7.8125e-05]
3: TRAIN [2][3760/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00095)	Tok/s 66879 (60103)	Loss/tok 3.3899 (3.2152)	Learning Rate [7.8125e-05]
0: TRAIN [2][3770/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00097)	Tok/s 61119 (58801)	Loss/tok 3.3411 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3770/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00091)	Tok/s 61299 (59281)	Loss/tok 3.3683 (3.2157)	Learning Rate [7.8125e-05]
3: TRAIN [2][3770/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 62152 (60112)	Loss/tok 3.4258 (3.2154)	Learning Rate [7.8125e-05]
2: TRAIN [2][3770/6832]	Time 0.130 (0.105)	Data 0.00117 (0.00093)	Tok/s 62172 (59658)	Loss/tok 3.4383 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][3780/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 62338 (59659)	Loss/tok 3.1823 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][3780/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00097)	Tok/s 62370 (58804)	Loss/tok 3.2861 (3.2135)	Learning Rate [7.8125e-05]
1: TRAIN [2][3780/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00091)	Tok/s 62353 (59283)	Loss/tok 3.3634 (3.2156)	Learning Rate [7.8125e-05]
3: TRAIN [2][3780/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 62833 (60114)	Loss/tok 3.1739 (3.2154)	Learning Rate [7.8125e-05]
2: TRAIN [2][3790/6832]	Time 0.081 (0.105)	Data 0.00085 (0.00093)	Tok/s 52116 (59653)	Loss/tok 3.0847 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3790/6832]	Time 0.081 (0.105)	Data 0.00091 (0.00091)	Tok/s 50873 (59276)	Loss/tok 2.9203 (3.2154)	Learning Rate [7.8125e-05]
0: TRAIN [2][3790/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00097)	Tok/s 50505 (58797)	Loss/tok 3.0660 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3790/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00095)	Tok/s 52136 (60107)	Loss/tok 3.0958 (3.2153)	Learning Rate [7.8125e-05]
2: TRAIN [2][3800/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00093)	Tok/s 50717 (59668)	Loss/tok 2.9440 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][3800/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00097)	Tok/s 50582 (58813)	Loss/tok 3.0698 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][3800/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00091)	Tok/s 50566 (59291)	Loss/tok 3.1452 (3.2152)	Learning Rate [7.8125e-05]
3: TRAIN [2][3800/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00095)	Tok/s 52040 (60123)	Loss/tok 3.1075 (3.2151)	Learning Rate [7.8125e-05]
2: TRAIN [2][3810/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00093)	Tok/s 52452 (59675)	Loss/tok 2.7249 (3.2131)	Learning Rate [7.8125e-05]
1: TRAIN [2][3810/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00091)	Tok/s 52168 (59298)	Loss/tok 2.8398 (3.2153)	Learning Rate [7.8125e-05]
0: TRAIN [2][3810/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00097)	Tok/s 52174 (58820)	Loss/tok 2.7619 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3810/6832]	Time 0.059 (0.105)	Data 0.00100 (0.00095)	Tok/s 54354 (60130)	Loss/tok 2.9783 (3.2151)	Learning Rate [7.8125e-05]
2: TRAIN [2][3820/6832]	Time 0.070 (0.105)	Data 0.00085 (0.00093)	Tok/s 51206 (59666)	Loss/tok 3.0059 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][3820/6832]	Time 0.070 (0.105)	Data 0.00094 (0.00091)	Tok/s 51189 (59289)	Loss/tok 2.9550 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3820/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00097)	Tok/s 51151 (58812)	Loss/tok 2.9816 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3820/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00095)	Tok/s 51216 (60121)	Loss/tok 2.7943 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3830/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00093)	Tok/s 52354 (59669)	Loss/tok 3.0865 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][3830/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00091)	Tok/s 51714 (59292)	Loss/tok 3.1851 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3830/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00097)	Tok/s 51217 (58815)	Loss/tok 3.2902 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3830/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00095)	Tok/s 52378 (60123)	Loss/tok 3.2993 (3.2150)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [2][3840/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00093)	Tok/s 62426 (59659)	Loss/tok 3.1220 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][3840/6832]	Time 0.125 (0.105)	Data 0.00085 (0.00091)	Tok/s 62376 (59283)	Loss/tok 3.3145 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][3840/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00097)	Tok/s 61411 (58805)	Loss/tok 3.1717 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3840/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00095)	Tok/s 62442 (60113)	Loss/tok 3.5084 (3.2151)	Learning Rate [7.8125e-05]
1: TRAIN [2][3850/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00091)	Tok/s 54492 (59290)	Loss/tok 3.0327 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3850/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00097)	Tok/s 54490 (58813)	Loss/tok 3.0670 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][3850/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00093)	Tok/s 54477 (59666)	Loss/tok 3.0909 (3.2128)	Learning Rate [7.8125e-05]
3: TRAIN [2][3850/6832]	Time 0.087 (0.105)	Data 0.00099 (0.00095)	Tok/s 54427 (60119)	Loss/tok 3.2013 (3.2152)	Learning Rate [7.8125e-05]
2: TRAIN [2][3860/6832]	Time 0.065 (0.105)	Data 0.00088 (0.00093)	Tok/s 50826 (59652)	Loss/tok 2.9388 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][3860/6832]	Time 0.066 (0.105)	Data 0.00090 (0.00091)	Tok/s 50776 (59277)	Loss/tok 2.9377 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3860/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00097)	Tok/s 50833 (58800)	Loss/tok 2.9015 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][3860/6832]	Time 0.065 (0.105)	Data 0.00091 (0.00095)	Tok/s 51594 (60105)	Loss/tok 2.9021 (3.2151)	Learning Rate [7.8125e-05]
1: TRAIN [2][3870/6832]	Time 0.113 (0.105)	Data 0.00083 (0.00091)	Tok/s 54207 (59279)	Loss/tok 3.2752 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3870/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00093)	Tok/s 54244 (59654)	Loss/tok 3.3093 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][3870/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00096)	Tok/s 54204 (58802)	Loss/tok 3.2855 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3870/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00095)	Tok/s 54738 (60107)	Loss/tok 3.4017 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3880/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00093)	Tok/s 86566 (59683)	Loss/tok 3.1836 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][3880/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00091)	Tok/s 85658 (59307)	Loss/tok 3.0456 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [2][3880/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00096)	Tok/s 85539 (58831)	Loss/tok 3.0307 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][3880/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00095)	Tok/s 86998 (60135)	Loss/tok 3.2731 (3.2150)	Learning Rate [7.8125e-05]
2: TRAIN [2][3890/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00093)	Tok/s 53490 (59673)	Loss/tok 3.0589 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][3890/6832]	Time 0.103 (0.105)	Data 0.00085 (0.00091)	Tok/s 53505 (59298)	Loss/tok 2.9587 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][3890/6832]	Time 0.103 (0.105)	Data 0.00087 (0.00096)	Tok/s 53493 (58822)	Loss/tok 3.1962 (3.2131)	Learning Rate [7.8125e-05]
3: TRAIN [2][3890/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00095)	Tok/s 53517 (60125)	Loss/tok 3.2032 (3.2148)	Learning Rate [7.8125e-05]
2: TRAIN [2][3900/6832]	Time 0.109 (0.105)	Data 0.00095 (0.00093)	Tok/s 54561 (59667)	Loss/tok 3.2599 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][3900/6832]	Time 0.110 (0.105)	Data 0.00088 (0.00091)	Tok/s 53713 (59291)	Loss/tok 3.1302 (3.2145)	Learning Rate [7.8125e-05]
3: TRAIN [2][3900/6832]	Time 0.109 (0.105)	Data 0.00097 (0.00095)	Tok/s 54985 (60121)	Loss/tok 3.2606 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][3900/6832]	Time 0.110 (0.105)	Data 0.00091 (0.00096)	Tok/s 53695 (58813)	Loss/tok 3.2794 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][3910/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00091)	Tok/s 83922 (59294)	Loss/tok 3.1329 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][3910/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00093)	Tok/s 84069 (59670)	Loss/tok 3.0074 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][3910/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 82971 (58816)	Loss/tok 3.2587 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][3910/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 84936 (60125)	Loss/tok 3.2238 (3.2145)	Learning Rate [7.8125e-05]
2: TRAIN [2][3920/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00093)	Tok/s 61443 (59671)	Loss/tok 3.2569 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][3920/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00091)	Tok/s 60987 (59295)	Loss/tok 3.3198 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][3920/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 60971 (58817)	Loss/tok 3.3003 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][3920/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00095)	Tok/s 61999 (60125)	Loss/tok 3.3467 (3.2146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3930/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 74952 (59670)	Loss/tok 3.4644 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][3930/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00091)	Tok/s 74901 (59295)	Loss/tok 3.1116 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][3930/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 74873 (58817)	Loss/tok 3.2025 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][3930/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00095)	Tok/s 75904 (60125)	Loss/tok 3.3906 (3.2145)	Learning Rate [7.8125e-05]
1: TRAIN [2][3940/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00091)	Tok/s 52293 (59304)	Loss/tok 3.3041 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [2][3940/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00096)	Tok/s 52293 (58827)	Loss/tok 3.2129 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3940/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00095)	Tok/s 52297 (60134)	Loss/tok 3.0404 (3.2144)	Learning Rate [7.8125e-05]
2: TRAIN [2][3940/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00093)	Tok/s 52268 (59680)	Loss/tok 3.3016 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][3950/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 68303 (59676)	Loss/tok 3.2332 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][3950/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00091)	Tok/s 68283 (59301)	Loss/tok 3.2488 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [2][3950/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00096)	Tok/s 68305 (58825)	Loss/tok 3.2560 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3950/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 68540 (60130)	Loss/tok 3.2583 (3.2146)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][3960/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00093)	Tok/s 63827 (59670)	Loss/tok 3.3120 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][3960/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00091)	Tok/s 63560 (59296)	Loss/tok 3.4046 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][3960/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 63589 (58820)	Loss/tok 3.4575 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3960/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00095)	Tok/s 64611 (60125)	Loss/tok 3.5112 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][3970/6832]	Time 0.086 (0.105)	Data 0.00092 (0.00093)	Tok/s 53276 (59661)	Loss/tok 3.1315 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][3970/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00096)	Tok/s 53237 (58811)	Loss/tok 3.0332 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][3970/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00091)	Tok/s 53210 (59286)	Loss/tok 3.1114 (3.2144)	Learning Rate [7.8125e-05]
3: TRAIN [2][3970/6832]	Time 0.086 (0.105)	Data 0.00097 (0.00095)	Tok/s 53282 (60115)	Loss/tok 3.0490 (3.2147)	Learning Rate [7.8125e-05]
1: TRAIN [2][3980/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00091)	Tok/s 59641 (59286)	Loss/tok 3.2254 (3.2144)	Learning Rate [7.8125e-05]
2: TRAIN [2][3980/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00093)	Tok/s 59620 (59661)	Loss/tok 3.2125 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][3980/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00096)	Tok/s 59626 (58812)	Loss/tok 3.2868 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3980/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00095)	Tok/s 59671 (60114)	Loss/tok 3.3892 (3.2146)	Learning Rate [7.8125e-05]
2: TRAIN [2][3990/6832]	Time 0.133 (0.105)	Data 0.00086 (0.00093)	Tok/s 91836 (59668)	Loss/tok 3.1060 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][3990/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00091)	Tok/s 90753 (59293)	Loss/tok 3.1252 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][3990/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00096)	Tok/s 89672 (58819)	Loss/tok 3.1715 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][3990/6832]	Time 0.133 (0.105)	Data 0.00109 (0.00095)	Tok/s 93839 (60121)	Loss/tok 3.0051 (3.2145)	Learning Rate [7.8125e-05]
2: TRAIN [2][4000/6832]	Time 0.090 (0.105)	Data 0.00104 (0.00093)	Tok/s 56802 (59686)	Loss/tok 2.9393 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][4000/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00091)	Tok/s 55907 (59311)	Loss/tok 3.0974 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][4000/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00096)	Tok/s 55334 (58839)	Loss/tok 3.2605 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][4000/6832]	Time 0.090 (0.105)	Data 0.00105 (0.00095)	Tok/s 56831 (60140)	Loss/tok 3.1909 (3.2145)	Learning Rate [7.8125e-05]
2: TRAIN [2][4010/6832]	Time 0.079 (0.105)	Data 0.00086 (0.00093)	Tok/s 53594 (59690)	Loss/tok 3.2791 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][4010/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00091)	Tok/s 53628 (59316)	Loss/tok 3.1022 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][4010/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00096)	Tok/s 53610 (58843)	Loss/tok 3.2701 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][4010/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00095)	Tok/s 53592 (60144)	Loss/tok 2.9491 (3.2144)	Learning Rate [7.8125e-05]
2: TRAIN [2][4020/6832]	Time 0.123 (0.105)	Data 0.00097 (0.00093)	Tok/s 52001 (59691)	Loss/tok 3.1818 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][4020/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00091)	Tok/s 51988 (59316)	Loss/tok 3.5323 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][4020/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00096)	Tok/s 51960 (58843)	Loss/tok 3.2280 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][4020/6832]	Time 0.123 (0.105)	Data 0.00106 (0.00095)	Tok/s 51997 (60144)	Loss/tok 3.1871 (3.2145)	Learning Rate [7.8125e-05]
2: TRAIN [2][4030/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00093)	Tok/s 53447 (59688)	Loss/tok 3.0521 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][4030/6832]	Time 0.091 (0.105)	Data 0.00092 (0.00091)	Tok/s 53423 (59313)	Loss/tok 2.8968 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][4030/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00096)	Tok/s 53400 (58842)	Loss/tok 3.0616 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][4030/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00095)	Tok/s 53978 (60142)	Loss/tok 3.1172 (3.2145)	Learning Rate [7.8125e-05]
2: TRAIN [2][4040/6832]	Time 0.114 (0.106)	Data 0.00086 (0.00093)	Tok/s 60817 (59690)	Loss/tok 3.1824 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][4040/6832]	Time 0.114 (0.106)	Data 0.00086 (0.00091)	Tok/s 60790 (59316)	Loss/tok 3.3275 (3.2141)	Learning Rate [7.8125e-05]
3: TRAIN [2][4040/6832]	Time 0.114 (0.106)	Data 0.00091 (0.00095)	Tok/s 60839 (60144)	Loss/tok 3.3305 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][4040/6832]	Time 0.114 (0.106)	Data 0.00092 (0.00096)	Tok/s 60783 (58845)	Loss/tok 3.1142 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][4050/6832]	Time 0.109 (0.106)	Data 0.00086 (0.00091)	Tok/s 52941 (59319)	Loss/tok 3.2266 (3.2141)	Learning Rate [7.8125e-05]
2: TRAIN [2][4050/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00093)	Tok/s 52927 (59693)	Loss/tok 3.2687 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][4050/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00096)	Tok/s 52922 (58849)	Loss/tok 3.2909 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][4050/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00095)	Tok/s 52950 (60147)	Loss/tok 3.2259 (3.2144)	Learning Rate [7.8125e-05]
2: TRAIN [2][4060/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00093)	Tok/s 53024 (59680)	Loss/tok 3.2759 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][4060/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00091)	Tok/s 52781 (59307)	Loss/tok 3.1742 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][4060/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00096)	Tok/s 52792 (58837)	Loss/tok 3.2047 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][4060/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00095)	Tok/s 53893 (60134)	Loss/tok 3.3820 (3.2143)	Learning Rate [7.8125e-05]
1: TRAIN [2][4070/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00091)	Tok/s 54994 (59300)	Loss/tok 3.3770 (3.2139)	Learning Rate [7.8125e-05]
2: TRAIN [2][4070/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00093)	Tok/s 54991 (59673)	Loss/tok 3.2502 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][4070/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00096)	Tok/s 54959 (58831)	Loss/tok 2.9560 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][4070/6832]	Time 0.088 (0.105)	Data 0.00093 (0.00095)	Tok/s 55002 (60127)	Loss/tok 2.9289 (3.2144)	Learning Rate [7.8125e-05]
2: TRAIN [2][4080/6832]	Time 0.049 (0.105)	Data 0.00086 (0.00093)	Tok/s 44104 (59669)	Loss/tok 2.3788 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][4080/6832]	Time 0.049 (0.105)	Data 0.00085 (0.00091)	Tok/s 41711 (59295)	Loss/tok 2.4022 (3.2138)	Learning Rate [7.8125e-05]
0: TRAIN [2][4080/6832]	Time 0.049 (0.105)	Data 0.00088 (0.00096)	Tok/s 39288 (58825)	Loss/tok 2.2569 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][4080/6832]	Time 0.049 (0.105)	Data 0.00089 (0.00095)	Tok/s 45772 (60123)	Loss/tok 2.3718 (3.2142)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][4090/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00093)	Tok/s 63510 (59671)	Loss/tok 3.2616 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][4090/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00091)	Tok/s 63497 (59298)	Loss/tok 3.2076 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][4090/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00096)	Tok/s 62618 (58828)	Loss/tok 3.4432 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][4090/6832]	Time 0.121 (0.105)	Data 0.00107 (0.00095)	Tok/s 63432 (60125)	Loss/tok 3.2485 (3.2143)	Learning Rate [7.8125e-05]
2: TRAIN [2][4100/6832]	Time 0.114 (0.105)	Data 0.00103 (0.00093)	Tok/s 60674 (59659)	Loss/tok 3.3902 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][4100/6832]	Time 0.114 (0.105)	Data 0.00095 (0.00091)	Tok/s 59611 (59286)	Loss/tok 3.2134 (3.2138)	Learning Rate [7.8125e-05]
3: TRAIN [2][4100/6832]	Time 0.114 (0.105)	Data 0.00103 (0.00095)	Tok/s 60787 (60114)	Loss/tok 3.4853 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][4100/6832]	Time 0.114 (0.105)	Data 0.00101 (0.00096)	Tok/s 59595 (58816)	Loss/tok 3.2128 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][4110/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00093)	Tok/s 58239 (59658)	Loss/tok 3.2820 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][4110/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00091)	Tok/s 58116 (59286)	Loss/tok 3.2984 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][4110/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00096)	Tok/s 57172 (58816)	Loss/tok 3.4533 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][4110/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00095)	Tok/s 58248 (60113)	Loss/tok 3.3313 (3.2142)	Learning Rate [7.8125e-05]
1: TRAIN [2][4120/6832]	Time 0.102 (0.105)	Data 0.00088 (0.00091)	Tok/s 51554 (59279)	Loss/tok 3.1314 (3.2138)	Learning Rate [7.8125e-05]
2: TRAIN [2][4120/6832]	Time 0.102 (0.105)	Data 0.00090 (0.00093)	Tok/s 52471 (59652)	Loss/tok 3.1586 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][4120/6832]	Time 0.102 (0.105)	Data 0.00089 (0.00096)	Tok/s 51208 (58806)	Loss/tok 3.0703 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][4120/6832]	Time 0.102 (0.105)	Data 0.00093 (0.00095)	Tok/s 52467 (60107)	Loss/tok 3.0176 (3.2140)	Learning Rate [7.8125e-05]
2: TRAIN [2][4130/6832]	Time 0.062 (0.105)	Data 0.00088 (0.00093)	Tok/s 52057 (59655)	Loss/tok 2.8859 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][4130/6832]	Time 0.062 (0.105)	Data 0.00092 (0.00095)	Tok/s 53459 (60110)	Loss/tok 2.8940 (3.2141)	Learning Rate [7.8125e-05]
1: TRAIN [2][4130/6832]	Time 0.063 (0.105)	Data 0.00084 (0.00091)	Tok/s 51190 (59281)	Loss/tok 2.8157 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [2][4130/6832]	Time 0.062 (0.105)	Data 0.00091 (0.00096)	Tok/s 51244 (58808)	Loss/tok 2.8776 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4140/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00093)	Tok/s 66371 (59674)	Loss/tok 3.4080 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][4140/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00091)	Tok/s 66349 (59300)	Loss/tok 3.4788 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [2][4140/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 66097 (58828)	Loss/tok 3.3111 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][4140/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00095)	Tok/s 66397 (60129)	Loss/tok 3.3751 (3.2144)	Learning Rate [7.8125e-05]
2: TRAIN [2][4150/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00093)	Tok/s 52253 (59683)	Loss/tok 3.1959 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][4150/6832]	Time 0.113 (0.105)	Data 0.00084 (0.00091)	Tok/s 52227 (59309)	Loss/tok 3.2379 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][4150/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00096)	Tok/s 51253 (58837)	Loss/tok 3.1327 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][4150/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00095)	Tok/s 52252 (60138)	Loss/tok 3.1865 (3.2146)	Learning Rate [7.8125e-05]
1: TRAIN [2][4160/6832]	Time 0.112 (0.105)	Data 0.00085 (0.00091)	Tok/s 54984 (59301)	Loss/tok 3.1165 (3.2141)	Learning Rate [7.8125e-05]
2: TRAIN [2][4160/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00093)	Tok/s 54950 (59675)	Loss/tok 3.2239 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][4160/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00096)	Tok/s 54340 (58830)	Loss/tok 3.1857 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][4160/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00095)	Tok/s 54991 (60129)	Loss/tok 3.2398 (3.2147)	Learning Rate [7.8125e-05]
1: TRAIN [2][4170/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00091)	Tok/s 50661 (59303)	Loss/tok 3.2157 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [2][4170/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00096)	Tok/s 50696 (58833)	Loss/tok 3.0151 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][4170/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00093)	Tok/s 50599 (59676)	Loss/tok 3.1929 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][4170/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00095)	Tok/s 50609 (60130)	Loss/tok 3.1333 (3.2148)	Learning Rate [7.8125e-05]
2: TRAIN [2][4180/6832]	Time 0.104 (0.105)	Data 0.00097 (0.00093)	Tok/s 53864 (59677)	Loss/tok 3.0756 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][4180/6832]	Time 0.104 (0.105)	Data 0.00085 (0.00091)	Tok/s 53026 (59303)	Loss/tok 3.3302 (3.2145)	Learning Rate [7.8125e-05]
3: TRAIN [2][4180/6832]	Time 0.104 (0.105)	Data 0.00098 (0.00095)	Tok/s 54342 (60130)	Loss/tok 3.0742 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][4180/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00096)	Tok/s 52988 (58834)	Loss/tok 3.1158 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][4190/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00093)	Tok/s 51918 (59676)	Loss/tok 3.1303 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][4190/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00091)	Tok/s 51876 (59303)	Loss/tok 2.9933 (3.2145)	Learning Rate [7.8125e-05]
3: TRAIN [2][4190/6832]	Time 0.079 (0.105)	Data 0.00090 (0.00095)	Tok/s 52083 (60128)	Loss/tok 2.9671 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][4190/6832]	Time 0.079 (0.105)	Data 0.00090 (0.00096)	Tok/s 51869 (58834)	Loss/tok 3.1305 (3.2128)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [2][4200/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00093)	Tok/s 52719 (59679)	Loss/tok 2.8339 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][4200/6832]	Time 0.075 (0.105)	Data 0.00091 (0.00096)	Tok/s 51134 (58837)	Loss/tok 3.0796 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][4200/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00091)	Tok/s 51096 (59306)	Loss/tok 3.0450 (3.2144)	Learning Rate [7.8125e-05]
3: TRAIN [2][4200/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00095)	Tok/s 52833 (60131)	Loss/tok 2.9746 (3.2150)	Learning Rate [7.8125e-05]
1: TRAIN [2][4210/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00091)	Tok/s 50420 (59309)	Loss/tok 3.0946 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][4210/6832]	Time 0.090 (0.105)	Data 0.00087 (0.00093)	Tok/s 51468 (59682)	Loss/tok 3.1611 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][4210/6832]	Time 0.089 (0.105)	Data 0.00091 (0.00096)	Tok/s 50074 (58840)	Loss/tok 3.0911 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][4210/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00095)	Tok/s 51455 (60135)	Loss/tok 3.0673 (3.2148)	Learning Rate [7.8125e-05]
1: TRAIN [2][4220/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00091)	Tok/s 56831 (59304)	Loss/tok 3.3009 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][4220/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00093)	Tok/s 56811 (59677)	Loss/tok 3.2884 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][4220/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00096)	Tok/s 56814 (58833)	Loss/tok 3.2786 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][4220/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00095)	Tok/s 57866 (60131)	Loss/tok 3.1942 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][4230/6832]	Time 0.117 (0.106)	Data 0.00097 (0.00093)	Tok/s 57837 (59693)	Loss/tok 3.0380 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][4230/6832]	Time 0.117 (0.106)	Data 0.00095 (0.00091)	Tok/s 57812 (59320)	Loss/tok 3.4005 (3.2142)	Learning Rate [7.8125e-05]
3: TRAIN [2][4230/6832]	Time 0.117 (0.106)	Data 0.00096 (0.00095)	Tok/s 58402 (60147)	Loss/tok 3.4007 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][4230/6832]	Time 0.117 (0.106)	Data 0.00091 (0.00096)	Tok/s 57804 (58849)	Loss/tok 3.2996 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][4240/6832]	Time 0.073 (0.106)	Data 0.00090 (0.00091)	Tok/s 52945 (59312)	Loss/tok 3.0950 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][4240/6832]	Time 0.073 (0.106)	Data 0.00093 (0.00093)	Tok/s 54623 (59686)	Loss/tok 3.1190 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][4240/6832]	Time 0.073 (0.105)	Data 0.00093 (0.00096)	Tok/s 52773 (58841)	Loss/tok 3.0340 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][4240/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00095)	Tok/s 54953 (60138)	Loss/tok 2.8608 (3.2147)	Learning Rate [7.8125e-05]
2: TRAIN [2][4250/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00093)	Tok/s 61956 (59673)	Loss/tok 3.3578 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][4250/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00091)	Tok/s 61497 (59298)	Loss/tok 3.2869 (3.2142)	Learning Rate [7.8125e-05]
3: TRAIN [2][4250/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00095)	Tok/s 61942 (60126)	Loss/tok 3.1182 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][4250/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 60942 (58824)	Loss/tok 3.3503 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][4260/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00096)	Tok/s 57236 (58814)	Loss/tok 3.4380 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][4260/6832]	Time 0.114 (0.105)	Data 0.00088 (0.00093)	Tok/s 57171 (59662)	Loss/tok 3.2788 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][4260/6832]	Time 0.114 (0.105)	Data 0.00091 (0.00091)	Tok/s 57242 (59287)	Loss/tok 3.1298 (3.2139)	Learning Rate [7.8125e-05]
3: TRAIN [2][4260/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00095)	Tok/s 58202 (60116)	Loss/tok 3.2836 (3.2143)	Learning Rate [7.8125e-05]
1: TRAIN [2][4270/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00091)	Tok/s 61431 (59288)	Loss/tok 3.4391 (3.2140)	Learning Rate [7.8125e-05]
2: TRAIN [2][4270/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00093)	Tok/s 61445 (59663)	Loss/tok 3.3498 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][4270/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00096)	Tok/s 61448 (58816)	Loss/tok 3.2696 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][4270/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00095)	Tok/s 61929 (60117)	Loss/tok 3.2842 (3.2142)	Learning Rate [7.8125e-05]
2: TRAIN [2][4280/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00093)	Tok/s 63573 (59663)	Loss/tok 3.4820 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][4280/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00091)	Tok/s 63538 (59289)	Loss/tok 3.1951 (3.2140)	Learning Rate [7.8125e-05]
3: TRAIN [2][4280/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00095)	Tok/s 63666 (60117)	Loss/tok 3.4230 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][4280/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00096)	Tok/s 63490 (58816)	Loss/tok 3.4936 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][4290/6832]	Time 0.123 (0.105)	Data 0.00084 (0.00091)	Tok/s 60279 (59297)	Loss/tok 3.2022 (3.2137)	Learning Rate [7.8125e-05]
2: TRAIN [2][4290/6832]	Time 0.123 (0.105)	Data 0.00097 (0.00093)	Tok/s 60260 (59672)	Loss/tok 3.2966 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][4290/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00096)	Tok/s 60255 (58825)	Loss/tok 3.4212 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][4290/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00095)	Tok/s 60459 (60126)	Loss/tok 3.2741 (3.2140)	Learning Rate [7.8125e-05]
2: TRAIN [2][4300/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00093)	Tok/s 76771 (59678)	Loss/tok 3.3188 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][4300/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00091)	Tok/s 76067 (59301)	Loss/tok 3.4148 (3.2137)	Learning Rate [7.8125e-05]
3: TRAIN [2][4300/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 76773 (60132)	Loss/tok 3.2732 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [2][4300/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 75795 (58827)	Loss/tok 3.1865 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][4310/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00093)	Tok/s 46267 (59678)	Loss/tok 2.5493 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][4310/6832]	Time 0.053 (0.105)	Data 0.00087 (0.00095)	Tok/s 46866 (60131)	Loss/tok 2.5149 (3.2139)	Learning Rate [7.8125e-05]
1: TRAIN [2][4310/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00091)	Tok/s 45050 (59301)	Loss/tok 2.6314 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [2][4310/6832]	Time 0.053 (0.105)	Data 0.00098 (0.00096)	Tok/s 43836 (58828)	Loss/tok 2.6532 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4320/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00093)	Tok/s 51694 (59668)	Loss/tok 3.3303 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][4320/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00091)	Tok/s 50638 (59292)	Loss/tok 3.3626 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][4320/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00095)	Tok/s 51696 (60121)	Loss/tok 3.1890 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [2][4320/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00096)	Tok/s 50534 (58819)	Loss/tok 3.1286 (3.2119)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][4330/6832]	Time 0.071 (0.105)	Data 0.00095 (0.00093)	Tok/s 52550 (59668)	Loss/tok 3.0076 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][4330/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00091)	Tok/s 52472 (59292)	Loss/tok 2.9041 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][4330/6832]	Time 0.071 (0.105)	Data 0.00100 (0.00095)	Tok/s 52619 (60122)	Loss/tok 3.0786 (3.2138)	Learning Rate [7.8125e-05]
0: TRAIN [2][4330/6832]	Time 0.071 (0.105)	Data 0.00098 (0.00096)	Tok/s 51648 (58819)	Loss/tok 2.9534 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4340/6832]	Time 0.096 (0.105)	Data 0.00087 (0.00093)	Tok/s 54099 (59663)	Loss/tok 3.0168 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][4340/6832]	Time 0.096 (0.105)	Data 0.00085 (0.00091)	Tok/s 53398 (59287)	Loss/tok 3.1043 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][4340/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00095)	Tok/s 54777 (60117)	Loss/tok 3.0508 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [2][4340/6832]	Time 0.096 (0.105)	Data 0.00092 (0.00096)	Tok/s 53394 (58814)	Loss/tok 3.4310 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4350/6832]	Time 0.059 (0.105)	Data 0.00087 (0.00093)	Tok/s 52324 (59668)	Loss/tok 2.9069 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][4350/6832]	Time 0.059 (0.105)	Data 0.00084 (0.00095)	Tok/s 54245 (60122)	Loss/tok 2.7608 (3.2137)	Learning Rate [7.8125e-05]
1: TRAIN [2][4350/6832]	Time 0.059 (0.105)	Data 0.00086 (0.00091)	Tok/s 51857 (59290)	Loss/tok 3.1273 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][4350/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00096)	Tok/s 51877 (58816)	Loss/tok 2.9453 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4360/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00093)	Tok/s 60039 (59656)	Loss/tok 3.3235 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][4360/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00095)	Tok/s 60800 (60111)	Loss/tok 3.3356 (3.2136)	Learning Rate [7.8125e-05]
1: TRAIN [2][4360/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00091)	Tok/s 59717 (59280)	Loss/tok 3.3646 (3.2135)	Learning Rate [7.8125e-05]
0: TRAIN [2][4360/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00096)	Tok/s 59724 (58805)	Loss/tok 3.3830 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][4370/6832]	Time 0.069 (0.105)	Data 0.00097 (0.00091)	Tok/s 51812 (59287)	Loss/tok 2.9090 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4370/6832]	Time 0.069 (0.105)	Data 0.00097 (0.00096)	Tok/s 51859 (58813)	Loss/tok 2.8749 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][4370/6832]	Time 0.069 (0.105)	Data 0.00097 (0.00093)	Tok/s 51732 (59665)	Loss/tok 2.8749 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][4370/6832]	Time 0.069 (0.105)	Data 0.00097 (0.00095)	Tok/s 53297 (60120)	Loss/tok 3.2161 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][4380/6832]	Time 0.059 (0.105)	Data 0.00095 (0.00093)	Tok/s 47854 (59656)	Loss/tok 2.7739 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][4380/6832]	Time 0.059 (0.105)	Data 0.00105 (0.00091)	Tok/s 47850 (59279)	Loss/tok 2.6750 (3.2132)	Learning Rate [7.8125e-05]
3: TRAIN [2][4380/6832]	Time 0.059 (0.105)	Data 0.00090 (0.00095)	Tok/s 48339 (60113)	Loss/tok 2.7283 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][4380/6832]	Time 0.059 (0.105)	Data 0.00108 (0.00096)	Tok/s 46233 (58805)	Loss/tok 2.6236 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][4390/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00091)	Tok/s 74075 (59281)	Loss/tok 3.2527 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][4390/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00093)	Tok/s 74066 (59658)	Loss/tok 3.4036 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][4390/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 74096 (60115)	Loss/tok 3.4268 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][4390/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 73209 (58807)	Loss/tok 3.4968 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][4400/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00093)	Tok/s 54095 (59649)	Loss/tok 3.0565 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][4400/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00091)	Tok/s 53187 (59272)	Loss/tok 3.0202 (3.2131)	Learning Rate [7.8125e-05]
3: TRAIN [2][4400/6832]	Time 0.089 (0.105)	Data 0.00084 (0.00095)	Tok/s 54675 (60106)	Loss/tok 3.3315 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4400/6832]	Time 0.089 (0.105)	Data 0.00096 (0.00096)	Tok/s 53221 (58798)	Loss/tok 3.1298 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][4410/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00091)	Tok/s 83386 (59277)	Loss/tok 3.2359 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][4410/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 83644 (59654)	Loss/tok 3.2795 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][4410/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 82625 (58803)	Loss/tok 3.2090 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][4410/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00095)	Tok/s 84348 (60111)	Loss/tok 3.0598 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][4420/6832]	Time 0.064 (0.105)	Data 0.00085 (0.00091)	Tok/s 49788 (59270)	Loss/tok 2.9469 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][4420/6832]	Time 0.064 (0.105)	Data 0.00088 (0.00093)	Tok/s 49837 (59646)	Loss/tok 3.0195 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][4420/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00096)	Tok/s 49826 (58797)	Loss/tok 2.9082 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][4420/6832]	Time 0.064 (0.105)	Data 0.00088 (0.00095)	Tok/s 51595 (60103)	Loss/tok 2.9023 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][4430/6832]	Time 0.114 (0.105)	Data 0.00096 (0.00093)	Tok/s 58210 (59667)	Loss/tok 3.1863 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][4430/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00091)	Tok/s 58165 (59291)	Loss/tok 3.2824 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][4430/6832]	Time 0.114 (0.105)	Data 0.00095 (0.00096)	Tok/s 57793 (58817)	Loss/tok 3.2672 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][4430/6832]	Time 0.114 (0.105)	Data 0.00100 (0.00095)	Tok/s 58204 (60124)	Loss/tok 3.3639 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][4440/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00093)	Tok/s 55386 (59666)	Loss/tok 3.1568 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][4440/6832]	Time 0.086 (0.105)	Data 0.00088 (0.00091)	Tok/s 55240 (59289)	Loss/tok 3.2473 (3.2135)	Learning Rate [7.8125e-05]
3: TRAIN [2][4440/6832]	Time 0.086 (0.105)	Data 0.00092 (0.00095)	Tok/s 55377 (60124)	Loss/tok 3.0166 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][4440/6832]	Time 0.086 (0.105)	Data 0.00090 (0.00096)	Tok/s 53798 (58813)	Loss/tok 3.1313 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][4450/6832]	Time 0.082 (0.105)	Data 0.00085 (0.00093)	Tok/s 53350 (59659)	Loss/tok 3.0284 (3.2111)	Learning Rate [7.8125e-05]
1: TRAIN [2][4450/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00091)	Tok/s 53348 (59282)	Loss/tok 3.1338 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4450/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00096)	Tok/s 53379 (58806)	Loss/tok 3.3692 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][4450/6832]	Time 0.082 (0.105)	Data 0.00086 (0.00095)	Tok/s 53751 (60116)	Loss/tok 3.0811 (3.2131)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][4460/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00091)	Tok/s 51207 (59272)	Loss/tok 3.0802 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][4460/6832]	Time 0.088 (0.105)	Data 0.00096 (0.00093)	Tok/s 52120 (59649)	Loss/tok 3.2108 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][4460/6832]	Time 0.087 (0.105)	Data 0.00096 (0.00095)	Tok/s 52679 (60105)	Loss/tok 3.1411 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4460/6832]	Time 0.088 (0.105)	Data 0.00100 (0.00096)	Tok/s 51173 (58796)	Loss/tok 3.1007 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][4470/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00091)	Tok/s 55574 (59264)	Loss/tok 3.3918 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4470/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00096)	Tok/s 55558 (58789)	Loss/tok 3.1816 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][4470/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00093)	Tok/s 55507 (59641)	Loss/tok 3.3621 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4470/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00095)	Tok/s 55476 (60097)	Loss/tok 3.2867 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][4480/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00093)	Tok/s 60627 (59646)	Loss/tok 3.2358 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4480/6832]	Time 0.121 (0.105)	Data 0.00094 (0.00095)	Tok/s 61348 (60103)	Loss/tok 3.2788 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][4480/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00091)	Tok/s 60250 (59270)	Loss/tok 3.2696 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4480/6832]	Time 0.121 (0.105)	Data 0.00094 (0.00096)	Tok/s 60237 (58795)	Loss/tok 3.4477 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][4490/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00093)	Tok/s 51264 (59641)	Loss/tok 3.3584 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][4490/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00091)	Tok/s 51246 (59264)	Loss/tok 3.2945 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][4490/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00096)	Tok/s 51259 (58790)	Loss/tok 3.1084 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][4490/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00095)	Tok/s 51783 (60098)	Loss/tok 3.1962 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][4500/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 83638 (59645)	Loss/tok 3.1662 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][4500/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00091)	Tok/s 83586 (59268)	Loss/tok 3.3329 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][4500/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00096)	Tok/s 82734 (58794)	Loss/tok 3.4003 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][4500/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 84604 (60102)	Loss/tok 3.1578 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][4510/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00093)	Tok/s 77316 (59652)	Loss/tok 3.3783 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][4510/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00091)	Tok/s 76515 (59275)	Loss/tok 3.1826 (3.2135)	Learning Rate [7.8125e-05]
3: TRAIN [2][4510/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 77340 (60109)	Loss/tok 3.3353 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4510/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00096)	Tok/s 76303 (58801)	Loss/tok 3.5196 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][4520/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00091)	Tok/s 51633 (59273)	Loss/tok 3.3220 (3.2136)	Learning Rate [7.8125e-05]
2: TRAIN [2][4520/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00093)	Tok/s 51632 (59649)	Loss/tok 3.2213 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][4520/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00096)	Tok/s 51395 (58799)	Loss/tok 3.3168 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][4520/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00094)	Tok/s 51625 (60105)	Loss/tok 3.1771 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][4530/6832]	Time 0.063 (0.105)	Data 0.00097 (0.00093)	Tok/s 50624 (59649)	Loss/tok 2.9156 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][4530/6832]	Time 0.063 (0.105)	Data 0.00089 (0.00091)	Tok/s 48954 (59273)	Loss/tok 2.7544 (3.2134)	Learning Rate [7.8125e-05]
3: TRAIN [2][4530/6832]	Time 0.063 (0.105)	Data 0.00094 (0.00094)	Tok/s 51153 (60105)	Loss/tok 2.9390 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4530/6832]	Time 0.063 (0.105)	Data 0.00092 (0.00096)	Tok/s 48968 (58800)	Loss/tok 2.8744 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4540/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00093)	Tok/s 52864 (59650)	Loss/tok 3.2458 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][4540/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00091)	Tok/s 51433 (59274)	Loss/tok 3.1858 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][4540/6832]	Time 0.087 (0.105)	Data 0.00086 (0.00094)	Tok/s 52877 (60106)	Loss/tok 3.1210 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4540/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00096)	Tok/s 51396 (58801)	Loss/tok 3.0247 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][4550/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00091)	Tok/s 63326 (59270)	Loss/tok 3.2085 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][4550/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00093)	Tok/s 64058 (59645)	Loss/tok 3.4224 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][4550/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00096)	Tok/s 63078 (58798)	Loss/tok 3.3425 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][4550/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00094)	Tok/s 64056 (60102)	Loss/tok 3.2139 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][4560/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00093)	Tok/s 60757 (59644)	Loss/tok 3.4396 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][4560/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00091)	Tok/s 60047 (59268)	Loss/tok 3.5145 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][4560/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 60086 (58797)	Loss/tok 3.1786 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][4560/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 61030 (60100)	Loss/tok 3.3691 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][4570/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00091)	Tok/s 77111 (59272)	Loss/tok 3.3136 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][4570/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 76797 (58802)	Loss/tok 3.2603 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][4570/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00093)	Tok/s 77092 (59648)	Loss/tok 3.2802 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4570/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00094)	Tok/s 78022 (60105)	Loss/tok 3.3291 (3.2131)	Learning Rate [7.8125e-05]
1: TRAIN [2][4580/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00091)	Tok/s 71549 (59277)	Loss/tok 3.2449 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][4580/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 72400 (59654)	Loss/tok 3.2964 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][4580/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00096)	Tok/s 71450 (58807)	Loss/tok 3.3315 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][4580/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00094)	Tok/s 72436 (60110)	Loss/tok 3.2794 (3.2131)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][4590/6832]	Time 0.110 (0.105)	Data 0.00087 (0.00093)	Tok/s 52368 (59657)	Loss/tok 3.3297 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][4590/6832]	Time 0.110 (0.105)	Data 0.00088 (0.00091)	Tok/s 52381 (59281)	Loss/tok 3.2066 (3.2136)	Learning Rate [7.8125e-05]
3: TRAIN [2][4590/6832]	Time 0.110 (0.105)	Data 0.00084 (0.00094)	Tok/s 52380 (60114)	Loss/tok 3.2226 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4590/6832]	Time 0.110 (0.105)	Data 0.00093 (0.00096)	Tok/s 52395 (58811)	Loss/tok 3.1552 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][4600/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00091)	Tok/s 53560 (59281)	Loss/tok 3.3738 (3.2135)	Learning Rate [7.8125e-05]
0: TRAIN [2][4600/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00096)	Tok/s 53576 (58812)	Loss/tok 3.1797 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][4600/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00093)	Tok/s 54637 (59658)	Loss/tok 3.3484 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][4600/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00094)	Tok/s 54627 (60115)	Loss/tok 3.2375 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][4610/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00093)	Tok/s 60347 (59660)	Loss/tok 3.3189 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][4610/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00091)	Tok/s 59552 (59283)	Loss/tok 3.4119 (3.2135)	Learning Rate [7.8125e-05]
0: TRAIN [2][4610/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00096)	Tok/s 59278 (58814)	Loss/tok 3.2923 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][4610/6832]	Time 0.119 (0.105)	Data 0.00083 (0.00094)	Tok/s 60332 (60117)	Loss/tok 3.4317 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][4620/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00091)	Tok/s 52342 (59269)	Loss/tok 3.1197 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][4620/6832]	Time 0.072 (0.105)	Data 0.00087 (0.00093)	Tok/s 53017 (59646)	Loss/tok 2.9241 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][4620/6832]	Time 0.072 (0.105)	Data 0.00090 (0.00096)	Tok/s 51248 (58800)	Loss/tok 2.8641 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][4620/6832]	Time 0.072 (0.105)	Data 0.00083 (0.00094)	Tok/s 53019 (60103)	Loss/tok 3.0021 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][4630/6832]	Time 0.083 (0.105)	Data 0.00091 (0.00093)	Tok/s 55708 (59642)	Loss/tok 3.2004 (3.2111)	Learning Rate [7.8125e-05]
1: TRAIN [2][4630/6832]	Time 0.083 (0.105)	Data 0.00088 (0.00091)	Tok/s 55666 (59264)	Loss/tok 2.9953 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][4630/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00094)	Tok/s 55699 (60100)	Loss/tok 3.1232 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][4630/6832]	Time 0.083 (0.105)	Data 0.00094 (0.00096)	Tok/s 54796 (58792)	Loss/tok 3.0935 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][4640/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00093)	Tok/s 77317 (59649)	Loss/tok 3.2804 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][4640/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00091)	Tok/s 76851 (59271)	Loss/tok 3.2233 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][4640/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 77310 (60106)	Loss/tok 3.2403 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][4640/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00096)	Tok/s 76342 (58800)	Loss/tok 3.2087 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][4650/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 81176 (59666)	Loss/tok 3.1661 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][4650/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00091)	Tok/s 80547 (59287)	Loss/tok 3.2610 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][4650/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 81595 (60122)	Loss/tok 3.1184 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][4650/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00096)	Tok/s 80521 (58816)	Loss/tok 3.2188 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4660/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00093)	Tok/s 52596 (59672)	Loss/tok 3.2078 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][4660/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00091)	Tok/s 51498 (59293)	Loss/tok 3.3430 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][4660/6832]	Time 0.104 (0.105)	Data 0.00097 (0.00096)	Tok/s 51520 (58823)	Loss/tok 3.2229 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][4660/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00094)	Tok/s 52777 (60128)	Loss/tok 3.3681 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][4670/6832]	Time 0.108 (0.105)	Data 0.00086 (0.00093)	Tok/s 54417 (59665)	Loss/tok 3.2989 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][4670/6832]	Time 0.108 (0.105)	Data 0.00085 (0.00094)	Tok/s 54409 (60120)	Loss/tok 3.3666 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][4670/6832]	Time 0.108 (0.105)	Data 0.00089 (0.00091)	Tok/s 53747 (59286)	Loss/tok 3.2103 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][4670/6832]	Time 0.108 (0.105)	Data 0.00093 (0.00096)	Tok/s 53239 (58816)	Loss/tok 3.1835 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4680/6832]	Time 0.118 (0.105)	Data 0.00099 (0.00093)	Tok/s 55118 (59669)	Loss/tok 3.1439 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4680/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00094)	Tok/s 56082 (60124)	Loss/tok 3.3689 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][4680/6832]	Time 0.119 (0.105)	Data 0.00104 (0.00091)	Tok/s 55035 (59290)	Loss/tok 3.2627 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][4680/6832]	Time 0.119 (0.105)	Data 0.00116 (0.00096)	Tok/s 55031 (58821)	Loss/tok 3.2011 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4690/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00093)	Tok/s 51584 (59666)	Loss/tok 3.2660 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][4690/6832]	Time 0.109 (0.105)	Data 0.00101 (0.00091)	Tok/s 51621 (59287)	Loss/tok 3.2465 (3.2135)	Learning Rate [7.8125e-05]
3: TRAIN [2][4690/6832]	Time 0.109 (0.105)	Data 0.00085 (0.00094)	Tok/s 51606 (60120)	Loss/tok 3.1456 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][4690/6832]	Time 0.109 (0.105)	Data 0.00098 (0.00096)	Tok/s 50615 (58818)	Loss/tok 3.2931 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][4700/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00091)	Tok/s 77506 (59290)	Loss/tok 3.2355 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][4700/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00096)	Tok/s 77222 (58820)	Loss/tok 3.2977 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][4700/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00093)	Tok/s 77470 (59668)	Loss/tok 3.1234 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4700/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00094)	Tok/s 78308 (60122)	Loss/tok 3.3529 (3.2130)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][4710/6832]	Time 0.049 (0.105)	Data 0.00086 (0.00091)	Tok/s 42101 (59277)	Loss/tok 2.4288 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4710/6832]	Time 0.049 (0.105)	Data 0.00091 (0.00096)	Tok/s 39397 (58808)	Loss/tok 2.1850 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][4710/6832]	Time 0.049 (0.105)	Data 0.00101 (0.00093)	Tok/s 44488 (59656)	Loss/tok 2.3341 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][4710/6832]	Time 0.049 (0.105)	Data 0.00100 (0.00094)	Tok/s 46113 (60110)	Loss/tok 2.4028 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][4720/6832]	Time 0.118 (0.105)	Data 0.00103 (0.00093)	Tok/s 52222 (59651)	Loss/tok 3.1592 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][4720/6832]	Time 0.118 (0.105)	Data 0.00100 (0.00091)	Tok/s 52216 (59272)	Loss/tok 3.0771 (3.2132)	Learning Rate [7.8125e-05]
3: TRAIN [2][4720/6832]	Time 0.118 (0.105)	Data 0.00102 (0.00094)	Tok/s 52883 (60106)	Loss/tok 3.3153 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4720/6832]	Time 0.118 (0.105)	Data 0.00100 (0.00096)	Tok/s 52192 (58802)	Loss/tok 3.6639 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][4730/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00091)	Tok/s 53803 (59274)	Loss/tok 3.0394 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][4730/6832]	Time 0.074 (0.105)	Data 0.00092 (0.00096)	Tok/s 53760 (58805)	Loss/tok 2.8451 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][4730/6832]	Time 0.074 (0.105)	Data 0.00084 (0.00094)	Tok/s 54464 (60109)	Loss/tok 2.9715 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][4730/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00093)	Tok/s 53684 (59653)	Loss/tok 3.0436 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][4740/6832]	Time 0.076 (0.105)	Data 0.00097 (0.00091)	Tok/s 50488 (59270)	Loss/tok 3.1828 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4740/6832]	Time 0.076 (0.105)	Data 0.00099 (0.00096)	Tok/s 50475 (58801)	Loss/tok 3.0007 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][4740/6832]	Time 0.076 (0.105)	Data 0.00089 (0.00093)	Tok/s 50961 (59649)	Loss/tok 3.0563 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][4740/6832]	Time 0.076 (0.105)	Data 0.00089 (0.00094)	Tok/s 52090 (60104)	Loss/tok 2.9115 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][4750/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00093)	Tok/s 53081 (59654)	Loss/tok 2.9268 (3.2111)	Learning Rate [7.8125e-05]
1: TRAIN [2][4750/6832]	Time 0.061 (0.105)	Data 0.00094 (0.00091)	Tok/s 52287 (59274)	Loss/tok 2.7032 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][4750/6832]	Time 0.061 (0.105)	Data 0.00099 (0.00096)	Tok/s 52363 (58807)	Loss/tok 2.8379 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][4750/6832]	Time 0.061 (0.105)	Data 0.00091 (0.00094)	Tok/s 54351 (60109)	Loss/tok 2.8952 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][4760/6832]	Time 0.109 (0.105)	Data 0.00124 (0.00093)	Tok/s 52992 (59661)	Loss/tok 3.2145 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][4760/6832]	Time 0.109 (0.105)	Data 0.00106 (0.00091)	Tok/s 52978 (59282)	Loss/tok 3.0925 (3.2131)	Learning Rate [7.8125e-05]
3: TRAIN [2][4760/6832]	Time 0.109 (0.105)	Data 0.00123 (0.00094)	Tok/s 53383 (60116)	Loss/tok 3.0853 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4760/6832]	Time 0.109 (0.105)	Data 0.00105 (0.00096)	Tok/s 53015 (58814)	Loss/tok 3.1087 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][4770/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00093)	Tok/s 53548 (59653)	Loss/tok 2.9026 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][4770/6832]	Time 0.071 (0.105)	Data 0.00084 (0.00094)	Tok/s 54168 (60110)	Loss/tok 3.0889 (3.2131)	Learning Rate [7.8125e-05]
1: TRAIN [2][4770/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00091)	Tok/s 52314 (59273)	Loss/tok 2.8672 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4770/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00096)	Tok/s 52310 (58804)	Loss/tok 2.8576 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][4780/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00093)	Tok/s 70455 (59646)	Loss/tok 3.3664 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][4780/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00091)	Tok/s 70100 (59266)	Loss/tok 3.6685 (3.2131)	Learning Rate [7.8125e-05]
3: TRAIN [2][4780/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 71069 (60102)	Loss/tok 3.3583 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][4780/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00096)	Tok/s 70088 (58797)	Loss/tok 3.4167 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][4790/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00091)	Tok/s 62780 (59265)	Loss/tok 3.4002 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][4790/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 63745 (60101)	Loss/tok 3.5066 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][4790/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00093)	Tok/s 62820 (59645)	Loss/tok 3.3317 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][4790/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 62808 (58797)	Loss/tok 3.3011 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][4800/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00091)	Tok/s 50448 (59254)	Loss/tok 3.2501 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][4800/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00093)	Tok/s 51102 (59633)	Loss/tok 3.3820 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][4800/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00094)	Tok/s 51520 (60090)	Loss/tok 3.3581 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][4800/6832]	Time 0.119 (0.105)	Data 0.00099 (0.00096)	Tok/s 50464 (58787)	Loss/tok 3.1999 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][4810/6832]	Time 0.076 (0.105)	Data 0.00086 (0.00091)	Tok/s 54176 (59269)	Loss/tok 3.1421 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][4810/6832]	Time 0.076 (0.105)	Data 0.00093 (0.00093)	Tok/s 54173 (59648)	Loss/tok 2.9979 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][4810/6832]	Time 0.076 (0.105)	Data 0.00086 (0.00094)	Tok/s 54154 (60103)	Loss/tok 3.0114 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][4810/6832]	Time 0.076 (0.105)	Data 0.00090 (0.00096)	Tok/s 54174 (58802)	Loss/tok 3.0970 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][4820/6832]	Time 0.066 (0.105)	Data 0.00087 (0.00091)	Tok/s 52353 (59265)	Loss/tok 2.7952 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][4820/6832]	Time 0.066 (0.105)	Data 0.00093 (0.00093)	Tok/s 52325 (59643)	Loss/tok 2.9381 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][4820/6832]	Time 0.066 (0.105)	Data 0.00087 (0.00094)	Tok/s 52540 (60099)	Loss/tok 2.9774 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][4820/6832]	Time 0.066 (0.105)	Data 0.00095 (0.00096)	Tok/s 52349 (58798)	Loss/tok 2.9758 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][4830/6832]	Time 0.085 (0.105)	Data 0.00084 (0.00091)	Tok/s 52894 (59270)	Loss/tok 3.0807 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][4830/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00093)	Tok/s 52912 (59649)	Loss/tok 3.1418 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [2][4830/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00096)	Tok/s 52875 (58804)	Loss/tok 3.0187 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][4830/6832]	Time 0.085 (0.105)	Data 0.00085 (0.00094)	Tok/s 52934 (60104)	Loss/tok 3.2176 (3.2131)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][4840/6832]	Time 0.085 (0.105)	Data 0.00090 (0.00093)	Tok/s 54125 (59647)	Loss/tok 2.9791 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][4840/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00091)	Tok/s 53862 (59268)	Loss/tok 3.0936 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][4840/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00094)	Tok/s 54116 (60104)	Loss/tok 3.1950 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][4840/6832]	Time 0.085 (0.105)	Data 0.00095 (0.00096)	Tok/s 52654 (58800)	Loss/tok 3.0731 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][4850/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00091)	Tok/s 53486 (59257)	Loss/tok 3.3453 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][4850/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00093)	Tok/s 53484 (59636)	Loss/tok 3.4312 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][4850/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00096)	Tok/s 53492 (58789)	Loss/tok 3.1769 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][4850/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 53475 (60092)	Loss/tok 3.1749 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][4860/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00093)	Tok/s 54368 (59632)	Loss/tok 3.2057 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][4860/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00091)	Tok/s 54126 (59253)	Loss/tok 3.1480 (3.2133)	Learning Rate [7.8125e-05]
3: TRAIN [2][4860/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 54380 (60088)	Loss/tok 3.3057 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][4860/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00096)	Tok/s 53310 (58784)	Loss/tok 3.2290 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][4870/6832]	Time 0.117 (0.105)	Data 0.00083 (0.00091)	Tok/s 57794 (59246)	Loss/tok 3.2488 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][4870/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00093)	Tok/s 57796 (59624)	Loss/tok 3.1608 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][4870/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00096)	Tok/s 57160 (58777)	Loss/tok 3.1973 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][4870/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 57796 (60080)	Loss/tok 3.3522 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][4880/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00093)	Tok/s 50294 (59625)	Loss/tok 3.2895 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][4880/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00091)	Tok/s 50292 (59246)	Loss/tok 3.2626 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][4880/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00096)	Tok/s 50290 (58774)	Loss/tok 3.3980 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][4880/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 50298 (60082)	Loss/tok 3.1997 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][4890/6832]	Time 0.091 (0.105)	Data 0.00084 (0.00091)	Tok/s 52734 (59249)	Loss/tok 3.2317 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][4890/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00093)	Tok/s 53517 (59628)	Loss/tok 3.1574 (3.2105)	Learning Rate [7.8125e-05]
0: TRAIN [2][4890/6832]	Time 0.091 (0.105)	Data 0.00091 (0.00096)	Tok/s 52100 (58778)	Loss/tok 3.1335 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][4890/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00094)	Tok/s 53515 (60085)	Loss/tok 2.9398 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][4900/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00091)	Tok/s 60504 (59249)	Loss/tok 3.1378 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][4900/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00096)	Tok/s 60508 (58777)	Loss/tok 3.0775 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][4900/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00093)	Tok/s 60558 (59627)	Loss/tok 3.4289 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][4900/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00094)	Tok/s 60580 (60084)	Loss/tok 3.3464 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][4910/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00091)	Tok/s 61712 (59258)	Loss/tok 3.3207 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][4910/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00096)	Tok/s 61706 (58788)	Loss/tok 3.1385 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][4910/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00093)	Tok/s 61635 (59637)	Loss/tok 3.2342 (3.2105)	Learning Rate [7.8125e-05]
3: TRAIN [2][4910/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00094)	Tok/s 62644 (60093)	Loss/tok 3.1625 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][4920/6832]	Time 0.067 (0.105)	Data 0.00085 (0.00091)	Tok/s 49866 (59251)	Loss/tok 2.8855 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][4920/6832]	Time 0.067 (0.105)	Data 0.00095 (0.00093)	Tok/s 49915 (59629)	Loss/tok 2.9557 (3.2104)	Learning Rate [7.8125e-05]
0: TRAIN [2][4920/6832]	Time 0.067 (0.105)	Data 0.00096 (0.00096)	Tok/s 49917 (58780)	Loss/tok 2.9483 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4920/6832]	Time 0.067 (0.105)	Data 0.00098 (0.00094)	Tok/s 51845 (60086)	Loss/tok 2.7720 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][4930/6832]	Time 0.092 (0.105)	Data 0.00085 (0.00093)	Tok/s 57037 (59618)	Loss/tok 3.1951 (3.2103)	Learning Rate [7.8125e-05]
1: TRAIN [2][4930/6832]	Time 0.092 (0.105)	Data 0.00083 (0.00091)	Tok/s 55680 (59240)	Loss/tok 3.0378 (3.2131)	Learning Rate [7.8125e-05]
3: TRAIN [2][4930/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00094)	Tok/s 57084 (60076)	Loss/tok 3.1003 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][4930/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00096)	Tok/s 55697 (58770)	Loss/tok 3.1763 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][4940/6832]	Time 0.071 (0.105)	Data 0.00085 (0.00091)	Tok/s 52326 (59243)	Loss/tok 2.8781 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][4940/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00093)	Tok/s 52391 (59621)	Loss/tok 3.0186 (3.2101)	Learning Rate [7.8125e-05]
0: TRAIN [2][4940/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00096)	Tok/s 51410 (58773)	Loss/tok 2.9749 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][4940/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00094)	Tok/s 52394 (60078)	Loss/tok 2.9506 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][4950/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00091)	Tok/s 69058 (59239)	Loss/tok 3.2741 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][4950/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 69076 (59617)	Loss/tok 3.3524 (3.2101)	Learning Rate [7.8125e-05]
3: TRAIN [2][4950/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 69097 (60074)	Loss/tok 3.5256 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][4950/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 68732 (58770)	Loss/tok 3.1615 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][4960/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00091)	Tok/s 81557 (59246)	Loss/tok 3.3086 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][4960/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00096)	Tok/s 81021 (58777)	Loss/tok 3.2239 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][4960/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 81772 (59624)	Loss/tok 3.1649 (3.2103)	Learning Rate [7.8125e-05]
3: TRAIN [2][4960/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 82552 (60081)	Loss/tok 3.1961 (3.2127)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][4970/6832]	Time 0.111 (0.105)	Data 0.00084 (0.00091)	Tok/s 52920 (59266)	Loss/tok 3.1586 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][4970/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00093)	Tok/s 53058 (59643)	Loss/tok 3.3232 (3.2102)	Learning Rate [7.8125e-05]
0: TRAIN [2][4970/6832]	Time 0.111 (0.105)	Data 0.00094 (0.00096)	Tok/s 51898 (58797)	Loss/tok 3.1811 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4970/6832]	Time 0.111 (0.105)	Data 0.00089 (0.00094)	Tok/s 53070 (60100)	Loss/tok 3.1827 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][4980/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00093)	Tok/s 84039 (59654)	Loss/tok 3.2920 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][4980/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00091)	Tok/s 83510 (59277)	Loss/tok 3.2517 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][4980/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00096)	Tok/s 83077 (58808)	Loss/tok 3.2092 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][4980/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 84546 (60111)	Loss/tok 3.2320 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][4990/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00093)	Tok/s 52843 (59653)	Loss/tok 3.0692 (3.2105)	Learning Rate [7.8125e-05]
3: TRAIN [2][4990/6832]	Time 0.093 (0.105)	Data 0.00094 (0.00094)	Tok/s 53798 (60110)	Loss/tok 3.1662 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][4990/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00091)	Tok/s 52293 (59276)	Loss/tok 2.9601 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][4990/6832]	Time 0.093 (0.105)	Data 0.00097 (0.00096)	Tok/s 52325 (58808)	Loss/tok 3.0738 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5000/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00091)	Tok/s 62840 (59282)	Loss/tok 3.4073 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][5000/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00093)	Tok/s 62837 (59660)	Loss/tok 3.4099 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][5000/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 62836 (60117)	Loss/tok 3.2331 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5000/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00096)	Tok/s 61858 (58812)	Loss/tok 3.3783 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][5010/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00091)	Tok/s 51121 (59276)	Loss/tok 3.1727 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][5010/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00093)	Tok/s 51180 (59653)	Loss/tok 3.0707 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][5010/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00096)	Tok/s 51123 (58806)	Loss/tok 3.4796 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][5010/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00094)	Tok/s 51176 (60110)	Loss/tok 3.1868 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5020/6832]	Time 0.091 (0.105)	Data 0.00089 (0.00091)	Tok/s 54927 (59268)	Loss/tok 3.1797 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][5020/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00093)	Tok/s 54929 (59645)	Loss/tok 3.0488 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][5020/6832]	Time 0.091 (0.105)	Data 0.00096 (0.00094)	Tok/s 54949 (60102)	Loss/tok 3.1854 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5020/6832]	Time 0.091 (0.105)	Data 0.00098 (0.00096)	Tok/s 54910 (58799)	Loss/tok 3.1132 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][5030/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00090)	Tok/s 74164 (59268)	Loss/tok 3.3273 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5030/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 74134 (59645)	Loss/tok 3.3672 (3.2105)	Learning Rate [7.8125e-05]
0: TRAIN [2][5030/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 73636 (58800)	Loss/tok 3.1164 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5030/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 74346 (60102)	Loss/tok 3.4034 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5040/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00090)	Tok/s 54148 (59267)	Loss/tok 3.2562 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][5040/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00093)	Tok/s 54175 (59644)	Loss/tok 3.1343 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][5040/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00096)	Tok/s 54180 (58799)	Loss/tok 3.2349 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5040/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00094)	Tok/s 55258 (60100)	Loss/tok 3.2241 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5050/6832]	Time 0.069 (0.105)	Data 0.00099 (0.00093)	Tok/s 50388 (59647)	Loss/tok 2.9110 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][5050/6832]	Time 0.069 (0.105)	Data 0.00098 (0.00094)	Tok/s 51593 (60103)	Loss/tok 3.0934 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5050/6832]	Time 0.069 (0.105)	Data 0.00099 (0.00091)	Tok/s 50449 (59270)	Loss/tok 2.9396 (3.2135)	Learning Rate [7.8125e-05]
0: TRAIN [2][5050/6832]	Time 0.068 (0.105)	Data 0.00100 (0.00096)	Tok/s 50474 (58802)	Loss/tok 2.7967 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][5060/6832]	Time 0.061 (0.105)	Data 0.00099 (0.00091)	Tok/s 49953 (59273)	Loss/tok 2.8889 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][5060/6832]	Time 0.061 (0.105)	Data 0.00092 (0.00093)	Tok/s 50371 (59649)	Loss/tok 2.7458 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [2][5060/6832]	Time 0.062 (0.105)	Data 0.00105 (0.00096)	Tok/s 49949 (58805)	Loss/tok 2.8184 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][5060/6832]	Time 0.062 (0.105)	Data 0.00089 (0.00094)	Tok/s 52029 (60105)	Loss/tok 2.8589 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][5070/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00090)	Tok/s 67760 (59266)	Loss/tok 3.4212 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][5070/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00093)	Tok/s 68343 (59642)	Loss/tok 3.2695 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][5070/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00096)	Tok/s 67384 (58799)	Loss/tok 3.4149 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][5070/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 68347 (60098)	Loss/tok 3.2142 (3.2130)	Learning Rate [7.8125e-05]
1: TRAIN [2][5080/6832]	Time 0.083 (0.105)	Data 0.00093 (0.00090)	Tok/s 52736 (59286)	Loss/tok 3.0344 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][5080/6832]	Time 0.082 (0.105)	Data 0.00095 (0.00093)	Tok/s 52831 (59662)	Loss/tok 3.1906 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][5080/6832]	Time 0.082 (0.105)	Data 0.00093 (0.00094)	Tok/s 53369 (60117)	Loss/tok 3.1856 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][5080/6832]	Time 0.082 (0.105)	Data 0.00097 (0.00096)	Tok/s 52773 (58820)	Loss/tok 3.0588 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][5090/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00090)	Tok/s 78193 (59273)	Loss/tok 3.3366 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][5090/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 78145 (58805)	Loss/tok 3.2700 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][5090/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 79063 (59649)	Loss/tok 3.2355 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][5090/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 79056 (60106)	Loss/tok 3.0812 (3.2129)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [2][5100/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00090)	Tok/s 66706 (59266)	Loss/tok 3.3451 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][5100/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 66481 (58799)	Loss/tok 3.3801 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][5100/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 66625 (59643)	Loss/tok 3.2270 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][5100/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 66583 (60099)	Loss/tok 3.3020 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5110/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00093)	Tok/s 54127 (59644)	Loss/tok 3.0063 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][5110/6832]	Time 0.102 (0.105)	Data 0.00087 (0.00094)	Tok/s 54119 (60099)	Loss/tok 3.1986 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][5110/6832]	Time 0.102 (0.105)	Data 0.00086 (0.00090)	Tok/s 54034 (59267)	Loss/tok 3.2120 (3.2133)	Learning Rate [7.8125e-05]
0: TRAIN [2][5110/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00096)	Tok/s 54036 (58800)	Loss/tok 3.1961 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][5120/6832]	Time 0.059 (0.105)	Data 0.00085 (0.00090)	Tok/s 51760 (59260)	Loss/tok 2.8562 (3.2132)	Learning Rate [7.8125e-05]
2: TRAIN [2][5120/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00093)	Tok/s 52407 (59637)	Loss/tok 2.9363 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][5120/6832]	Time 0.059 (0.105)	Data 0.00091 (0.00096)	Tok/s 51773 (58794)	Loss/tok 2.8921 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][5120/6832]	Time 0.059 (0.105)	Data 0.00086 (0.00094)	Tok/s 53874 (60092)	Loss/tok 2.8566 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][5130/6832]	Time 0.095 (0.105)	Data 0.00083 (0.00090)	Tok/s 53801 (59255)	Loss/tok 3.0911 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][5130/6832]	Time 0.095 (0.105)	Data 0.00084 (0.00094)	Tok/s 53803 (60086)	Loss/tok 2.9109 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5130/6832]	Time 0.095 (0.105)	Data 0.00086 (0.00093)	Tok/s 53794 (59631)	Loss/tok 3.0616 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][5130/6832]	Time 0.095 (0.105)	Data 0.00090 (0.00096)	Tok/s 53461 (58789)	Loss/tok 3.3425 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][5140/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00090)	Tok/s 57222 (59246)	Loss/tok 3.1836 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5140/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00093)	Tok/s 57239 (59622)	Loss/tok 3.3820 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][5140/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00094)	Tok/s 57231 (60076)	Loss/tok 3.1130 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][5140/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00096)	Tok/s 57247 (58780)	Loss/tok 3.2560 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5150/6832]	Time 0.075 (0.105)	Data 0.00086 (0.00090)	Tok/s 49650 (59245)	Loss/tok 2.8746 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5150/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00096)	Tok/s 49172 (58779)	Loss/tok 3.0142 (3.2113)	Learning Rate [7.8125e-05]
2: TRAIN [2][5150/6832]	Time 0.075 (0.105)	Data 0.00087 (0.00093)	Tok/s 49627 (59622)	Loss/tok 2.8966 (3.2105)	Learning Rate [7.8125e-05]
3: TRAIN [2][5150/6832]	Time 0.075 (0.105)	Data 0.00097 (0.00094)	Tok/s 49628 (60076)	Loss/tok 3.0809 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][5160/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00090)	Tok/s 54650 (59255)	Loss/tok 3.2784 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5160/6832]	Time 0.091 (0.105)	Data 0.00093 (0.00093)	Tok/s 55705 (59632)	Loss/tok 3.0556 (3.2105)	Learning Rate [7.8125e-05]
3: TRAIN [2][5160/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00094)	Tok/s 56110 (60086)	Loss/tok 3.0684 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][5160/6832]	Time 0.091 (0.105)	Data 0.00093 (0.00096)	Tok/s 54652 (58789)	Loss/tok 3.1649 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5170/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00090)	Tok/s 52613 (59260)	Loss/tok 3.2029 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5170/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00093)	Tok/s 52599 (59636)	Loss/tok 3.0932 (3.2104)	Learning Rate [7.8125e-05]
3: TRAIN [2][5170/6832]	Time 0.100 (0.105)	Data 0.00086 (0.00094)	Tok/s 52599 (60090)	Loss/tok 3.1522 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][5170/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00096)	Tok/s 52594 (58794)	Loss/tok 3.2132 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5180/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00090)	Tok/s 63305 (59269)	Loss/tok 3.3633 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5180/6832]	Time 0.123 (0.105)	Data 0.00094 (0.00096)	Tok/s 62360 (58804)	Loss/tok 3.2540 (3.2115)	Learning Rate [7.8125e-05]
2: TRAIN [2][5180/6832]	Time 0.123 (0.105)	Data 0.00096 (0.00093)	Tok/s 63351 (59645)	Loss/tok 3.0814 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][5180/6832]	Time 0.123 (0.105)	Data 0.00095 (0.00094)	Tok/s 63341 (60099)	Loss/tok 3.2193 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5190/6832]	Time 0.127 (0.105)	Data 0.00084 (0.00090)	Tok/s 62508 (59265)	Loss/tok 3.4391 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5190/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00093)	Tok/s 63281 (59642)	Loss/tok 3.4094 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][5190/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00094)	Tok/s 63551 (60097)	Loss/tok 3.3276 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5190/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00096)	Tok/s 62501 (58797)	Loss/tok 3.3891 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][5200/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00090)	Tok/s 53407 (59261)	Loss/tok 3.0940 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5200/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00093)	Tok/s 53430 (59639)	Loss/tok 3.2625 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][5200/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00094)	Tok/s 53438 (60092)	Loss/tok 3.0067 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5200/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00096)	Tok/s 53429 (58794)	Loss/tok 3.1135 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][5210/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00090)	Tok/s 87812 (59276)	Loss/tok 3.2437 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5210/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 87049 (58809)	Loss/tok 3.1949 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][5210/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 89181 (60108)	Loss/tok 3.0474 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][5210/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00093)	Tok/s 88439 (59653)	Loss/tok 3.0457 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][5220/6832]	Time 0.107 (0.105)	Data 0.00084 (0.00090)	Tok/s 52708 (59270)	Loss/tok 3.1619 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5220/6832]	Time 0.107 (0.105)	Data 0.00090 (0.00096)	Tok/s 52751 (58804)	Loss/tok 3.2055 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][5220/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00093)	Tok/s 52708 (59648)	Loss/tok 3.1551 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][5220/6832]	Time 0.107 (0.105)	Data 0.00090 (0.00094)	Tok/s 52705 (60101)	Loss/tok 3.1312 (3.2126)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][5230/6832]	Time 0.126 (0.105)	Data 0.00084 (0.00090)	Tok/s 57987 (59267)	Loss/tok 3.2656 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5230/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00096)	Tok/s 58026 (58801)	Loss/tok 3.1468 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][5230/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00093)	Tok/s 58111 (59645)	Loss/tok 3.4341 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][5230/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00094)	Tok/s 59019 (60099)	Loss/tok 3.4966 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][5240/6832]	Time 0.078 (0.105)	Data 0.00093 (0.00090)	Tok/s 50603 (59264)	Loss/tok 3.0955 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5240/6832]	Time 0.078 (0.105)	Data 0.00098 (0.00096)	Tok/s 50640 (58798)	Loss/tok 2.9891 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][5240/6832]	Time 0.078 (0.105)	Data 0.00101 (0.00093)	Tok/s 50612 (59642)	Loss/tok 2.9825 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][5240/6832]	Time 0.078 (0.105)	Data 0.00097 (0.00094)	Tok/s 52205 (60095)	Loss/tok 3.3754 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][5250/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00090)	Tok/s 70104 (59269)	Loss/tok 3.2240 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5250/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00096)	Tok/s 70088 (58804)	Loss/tok 3.3345 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][5250/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00093)	Tok/s 70341 (59647)	Loss/tok 3.2738 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][5250/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 71057 (60101)	Loss/tok 3.2497 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][5260/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00090)	Tok/s 55298 (59266)	Loss/tok 3.0356 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][5260/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00094)	Tok/s 55296 (60097)	Loss/tok 3.1531 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5260/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00093)	Tok/s 55290 (59644)	Loss/tok 3.1397 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][5260/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00096)	Tok/s 54394 (58801)	Loss/tok 3.0575 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][5270/6832]	Time 0.087 (0.105)	Data 0.00085 (0.00090)	Tok/s 52849 (59260)	Loss/tok 3.0413 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5270/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00093)	Tok/s 53216 (59637)	Loss/tok 3.1569 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][5270/6832]	Time 0.087 (0.105)	Data 0.00085 (0.00094)	Tok/s 54326 (60090)	Loss/tok 2.9934 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5270/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00096)	Tok/s 52863 (58795)	Loss/tok 3.1443 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][5280/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00090)	Tok/s 65536 (59257)	Loss/tok 3.4215 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5280/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00096)	Tok/s 65535 (58793)	Loss/tok 3.3663 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][5280/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00093)	Tok/s 65520 (59634)	Loss/tok 3.4859 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][5280/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 66092 (60086)	Loss/tok 3.3114 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5290/6832]	Time 0.072 (0.105)	Data 0.00090 (0.00090)	Tok/s 51764 (59253)	Loss/tok 2.9800 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5290/6832]	Time 0.072 (0.105)	Data 0.00097 (0.00096)	Tok/s 51750 (58787)	Loss/tok 3.0303 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][5290/6832]	Time 0.072 (0.105)	Data 0.00102 (0.00093)	Tok/s 51730 (59630)	Loss/tok 3.0736 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][5290/6832]	Time 0.072 (0.105)	Data 0.00100 (0.00094)	Tok/s 51726 (60083)	Loss/tok 2.9685 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5300/6832]	Time 0.089 (0.105)	Data 0.00084 (0.00090)	Tok/s 54657 (59254)	Loss/tok 3.1251 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5300/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00093)	Tok/s 54662 (59631)	Loss/tok 3.1847 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][5300/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00094)	Tok/s 54654 (60084)	Loss/tok 3.1108 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5300/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00096)	Tok/s 53218 (58787)	Loss/tok 3.1207 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][5310/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00090)	Tok/s 56447 (59255)	Loss/tok 3.2548 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][5310/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00096)	Tok/s 56475 (58789)	Loss/tok 3.3212 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][5310/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00094)	Tok/s 56535 (60084)	Loss/tok 3.1765 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5310/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00093)	Tok/s 56434 (59632)	Loss/tok 3.3499 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][5320/6832]	Time 0.065 (0.105)	Data 0.00085 (0.00090)	Tok/s 49577 (59252)	Loss/tok 2.6854 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5320/6832]	Time 0.064 (0.105)	Data 0.00090 (0.00093)	Tok/s 51137 (59628)	Loss/tok 2.9270 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][5320/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00094)	Tok/s 51617 (60081)	Loss/tok 2.9935 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][5320/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00096)	Tok/s 49610 (58786)	Loss/tok 2.9792 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][5330/6832]	Time 0.062 (0.105)	Data 0.00097 (0.00093)	Tok/s 50625 (59625)	Loss/tok 2.8354 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5330/6832]	Time 0.062 (0.105)	Data 0.00094 (0.00094)	Tok/s 51876 (60077)	Loss/tok 2.8634 (3.2132)	Learning Rate [7.8125e-05]
1: TRAIN [2][5330/6832]	Time 0.062 (0.105)	Data 0.00096 (0.00090)	Tok/s 49745 (59248)	Loss/tok 2.7981 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][5330/6832]	Time 0.062 (0.105)	Data 0.00099 (0.00096)	Tok/s 49805 (58783)	Loss/tok 2.8109 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][5340/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00093)	Tok/s 52212 (59618)	Loss/tok 3.0487 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][5340/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00094)	Tok/s 52207 (60070)	Loss/tok 3.1713 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][5340/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00096)	Tok/s 52202 (58777)	Loss/tok 3.2252 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][5340/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00090)	Tok/s 52164 (59241)	Loss/tok 3.0174 (3.2129)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [2][5350/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00090)	Tok/s 66002 (59240)	Loss/tok 3.2590 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5350/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00096)	Tok/s 65656 (58773)	Loss/tok 3.3939 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][5350/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00093)	Tok/s 66125 (59617)	Loss/tok 3.3002 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][5350/6832]	Time 0.130 (0.105)	Data 0.00172 (0.00094)	Tok/s 66210 (60070)	Loss/tok 3.2530 (3.2132)	Learning Rate [7.8125e-05]
1: TRAIN [2][5360/6832]	Time 0.100 (0.105)	Data 0.00097 (0.00090)	Tok/s 53726 (59237)	Loss/tok 3.3019 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5360/6832]	Time 0.100 (0.105)	Data 0.00095 (0.00093)	Tok/s 53682 (59614)	Loss/tok 2.9793 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][5360/6832]	Time 0.100 (0.105)	Data 0.00095 (0.00094)	Tok/s 54913 (60067)	Loss/tok 3.1159 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][5360/6832]	Time 0.100 (0.105)	Data 0.00101 (0.00096)	Tok/s 53745 (58771)	Loss/tok 3.2741 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][5370/6832]	Time 0.078 (0.105)	Data 0.00094 (0.00090)	Tok/s 52535 (59234)	Loss/tok 3.1039 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5370/6832]	Time 0.078 (0.105)	Data 0.00096 (0.00093)	Tok/s 52559 (59611)	Loss/tok 3.0750 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][5370/6832]	Time 0.078 (0.105)	Data 0.00102 (0.00096)	Tok/s 52582 (58769)	Loss/tok 2.9252 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][5370/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00094)	Tok/s 52565 (60063)	Loss/tok 3.0391 (3.2132)	Learning Rate [7.8125e-05]
1: TRAIN [2][5380/6832]	Time 0.108 (0.105)	Data 0.00085 (0.00090)	Tok/s 51938 (59233)	Loss/tok 3.1438 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][5380/6832]	Time 0.108 (0.105)	Data 0.00093 (0.00093)	Tok/s 51961 (59609)	Loss/tok 2.9068 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][5380/6832]	Time 0.108 (0.105)	Data 0.00091 (0.00094)	Tok/s 51969 (60061)	Loss/tok 3.4190 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][5380/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00096)	Tok/s 51739 (58767)	Loss/tok 3.3157 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][5390/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00090)	Tok/s 61189 (59238)	Loss/tok 3.2464 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5390/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00096)	Tok/s 60604 (58773)	Loss/tok 3.3043 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][5390/6832]	Time 0.125 (0.105)	Data 0.00097 (0.00094)	Tok/s 61197 (60066)	Loss/tok 3.1726 (3.2133)	Learning Rate [7.8125e-05]
2: TRAIN [2][5390/6832]	Time 0.125 (0.105)	Data 0.00102 (0.00093)	Tok/s 61217 (59613)	Loss/tok 3.2195 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][5400/6832]	Time 0.076 (0.105)	Data 0.00084 (0.00090)	Tok/s 53857 (59234)	Loss/tok 2.9992 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][5400/6832]	Time 0.076 (0.105)	Data 0.00091 (0.00096)	Tok/s 53872 (58769)	Loss/tok 3.2065 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][5400/6832]	Time 0.076 (0.105)	Data 0.00092 (0.00093)	Tok/s 53860 (59609)	Loss/tok 3.0199 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][5400/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00094)	Tok/s 53882 (60060)	Loss/tok 3.0177 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][5410/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00090)	Tok/s 54807 (59235)	Loss/tok 3.3496 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5410/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00093)	Tok/s 54794 (59610)	Loss/tok 3.0765 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5410/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00094)	Tok/s 55856 (60061)	Loss/tok 3.0886 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][5410/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00096)	Tok/s 54793 (58770)	Loss/tok 3.1257 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][5420/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00090)	Tok/s 49715 (59242)	Loss/tok 2.8532 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5420/6832]	Time 0.064 (0.105)	Data 0.00092 (0.00095)	Tok/s 49756 (58778)	Loss/tok 2.8626 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][5420/6832]	Time 0.064 (0.105)	Data 0.00098 (0.00094)	Tok/s 50423 (59617)	Loss/tok 2.7446 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][5420/6832]	Time 0.064 (0.105)	Data 0.00093 (0.00094)	Tok/s 51639 (60068)	Loss/tok 3.0237 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][5430/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00090)	Tok/s 69732 (59233)	Loss/tok 3.3118 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5430/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00095)	Tok/s 69745 (58769)	Loss/tok 3.4152 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][5430/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 69886 (59608)	Loss/tok 3.1802 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][5430/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 70686 (60060)	Loss/tok 3.4058 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][5440/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00090)	Tok/s 63341 (59230)	Loss/tok 3.2793 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5440/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00095)	Tok/s 63332 (58766)	Loss/tok 3.2944 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5440/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 64275 (60056)	Loss/tok 3.5117 (3.2135)	Learning Rate [7.8125e-05]
2: TRAIN [2][5440/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 63420 (59604)	Loss/tok 3.3585 (3.2113)	Learning Rate [7.8125e-05]
2: TRAIN [2][5450/6832]	Time 0.095 (0.105)	Data 0.00097 (0.00094)	Tok/s 53991 (59616)	Loss/tok 3.0488 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][5450/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00094)	Tok/s 53971 (60067)	Loss/tok 3.1844 (3.2137)	Learning Rate [7.8125e-05]
1: TRAIN [2][5450/6832]	Time 0.095 (0.105)	Data 0.00090 (0.00090)	Tok/s 52911 (59241)	Loss/tok 3.1713 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5450/6832]	Time 0.095 (0.105)	Data 0.00097 (0.00095)	Tok/s 52639 (58778)	Loss/tok 3.1407 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][5460/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 78013 (60067)	Loss/tok 3.3472 (3.2137)	Learning Rate [7.8125e-05]
1: TRAIN [2][5460/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00090)	Tok/s 77035 (59241)	Loss/tok 3.2696 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5460/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 77193 (59615)	Loss/tok 3.3726 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][5460/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 76689 (58778)	Loss/tok 3.2615 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5470/6832]	Time 0.125 (0.105)	Data 0.00084 (0.00090)	Tok/s 60414 (59236)	Loss/tok 3.3560 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5470/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00094)	Tok/s 60368 (59610)	Loss/tok 3.2615 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][5470/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00094)	Tok/s 60378 (60061)	Loss/tok 3.3079 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [2][5470/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00095)	Tok/s 60349 (58773)	Loss/tok 3.4338 (3.2125)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [2][5480/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00090)	Tok/s 56759 (59233)	Loss/tok 3.2501 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][5480/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00095)	Tok/s 56806 (58771)	Loss/tok 3.4129 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][5480/6832]	Time 0.117 (0.105)	Data 0.00101 (0.00094)	Tok/s 56739 (59608)	Loss/tok 3.2583 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5480/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 56741 (60059)	Loss/tok 3.1180 (3.2135)	Learning Rate [7.8125e-05]
3: TRAIN [2][5490/6832]	Time 0.110 (0.105)	Data 0.00085 (0.00094)	Tok/s 54577 (60059)	Loss/tok 3.2756 (3.2134)	Learning Rate [7.8125e-05]
2: TRAIN [2][5490/6832]	Time 0.110 (0.105)	Data 0.00090 (0.00094)	Tok/s 54574 (59608)	Loss/tok 3.1739 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][5490/6832]	Time 0.110 (0.105)	Data 0.00084 (0.00090)	Tok/s 54510 (59233)	Loss/tok 3.1259 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5490/6832]	Time 0.110 (0.105)	Data 0.00088 (0.00095)	Tok/s 54558 (58772)	Loss/tok 3.0850 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][5500/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00090)	Tok/s 60051 (59239)	Loss/tok 3.3448 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5500/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 59812 (58778)	Loss/tok 3.3137 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][5500/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 60001 (59613)	Loss/tok 3.3939 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5500/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00094)	Tok/s 60005 (60064)	Loss/tok 3.3144 (3.2136)	Learning Rate [7.8125e-05]
1: TRAIN [2][5510/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00090)	Tok/s 67438 (59245)	Loss/tok 3.2874 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5510/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 67435 (59619)	Loss/tok 3.4141 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][5510/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00095)	Tok/s 67370 (58784)	Loss/tok 3.3771 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][5510/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 67624 (60070)	Loss/tok 3.2260 (3.2136)	Learning Rate [7.8125e-05]
1: TRAIN [2][5520/6832]	Time 0.105 (0.105)	Data 0.00085 (0.00090)	Tok/s 52268 (59243)	Loss/tok 3.2030 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5520/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00094)	Tok/s 52271 (59617)	Loss/tok 3.3023 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][5520/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00095)	Tok/s 52271 (58783)	Loss/tok 3.1077 (3.2128)	Learning Rate [7.8125e-05]
3: TRAIN [2][5520/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00094)	Tok/s 52273 (60068)	Loss/tok 3.0700 (3.2137)	Learning Rate [7.8125e-05]
2: TRAIN [2][5530/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 78107 (59619)	Loss/tok 3.2432 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][5530/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00090)	Tok/s 77341 (59245)	Loss/tok 3.2410 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][5530/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 77346 (58785)	Loss/tok 3.1421 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][5530/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 78302 (60070)	Loss/tok 3.2114 (3.2137)	Learning Rate [7.8125e-05]
1: TRAIN [2][5540/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00090)	Tok/s 69554 (59248)	Loss/tok 3.4370 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5540/6832]	Time 0.131 (0.105)	Data 0.00116 (0.00094)	Tok/s 69687 (59622)	Loss/tok 3.4162 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][5540/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 69563 (58789)	Loss/tok 3.2960 (3.2128)	Learning Rate [7.8125e-05]
3: TRAIN [2][5540/6832]	Time 0.131 (0.105)	Data 0.00110 (0.00094)	Tok/s 70516 (60073)	Loss/tok 3.3553 (3.2135)	Learning Rate [7.8125e-05]
1: TRAIN [2][5550/6832]	Time 0.085 (0.105)	Data 0.00085 (0.00090)	Tok/s 52499 (59260)	Loss/tok 2.9793 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5550/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00094)	Tok/s 53359 (59634)	Loss/tok 3.2662 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][5550/6832]	Time 0.085 (0.105)	Data 0.00089 (0.00095)	Tok/s 52514 (58801)	Loss/tok 3.0512 (3.2129)	Learning Rate [7.8125e-05]
3: TRAIN [2][5550/6832]	Time 0.085 (0.105)	Data 0.00089 (0.00094)	Tok/s 54010 (60085)	Loss/tok 2.9620 (3.2135)	Learning Rate [7.8125e-05]
1: TRAIN [2][5560/6832]	Time 0.117 (0.105)	Data 0.00084 (0.00090)	Tok/s 53825 (59250)	Loss/tok 3.2701 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5560/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00094)	Tok/s 53869 (59625)	Loss/tok 3.3447 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][5560/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00095)	Tok/s 53811 (58790)	Loss/tok 3.3108 (3.2130)	Learning Rate [7.8125e-05]
3: TRAIN [2][5560/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00094)	Tok/s 54225 (60077)	Loss/tok 3.2221 (3.2136)	Learning Rate [7.8125e-05]
1: TRAIN [2][5570/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00090)	Tok/s 61182 (59248)	Loss/tok 3.4948 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5570/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00095)	Tok/s 60765 (58788)	Loss/tok 3.2901 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5570/6832]	Time 0.126 (0.105)	Data 0.00108 (0.00094)	Tok/s 61150 (59622)	Loss/tok 3.3111 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][5570/6832]	Time 0.126 (0.105)	Data 0.00105 (0.00094)	Tok/s 61150 (60074)	Loss/tok 3.3600 (3.2135)	Learning Rate [7.8125e-05]
1: TRAIN [2][5580/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00090)	Tok/s 55920 (59240)	Loss/tok 3.3249 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5580/6832]	Time 0.115 (0.105)	Data 0.00096 (0.00094)	Tok/s 56662 (59614)	Loss/tok 3.2187 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][5580/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00095)	Tok/s 55447 (58779)	Loss/tok 3.1321 (3.2128)	Learning Rate [7.8125e-05]
3: TRAIN [2][5580/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00094)	Tok/s 56644 (60066)	Loss/tok 3.1417 (3.2134)	Learning Rate [7.8125e-05]
1: TRAIN [2][5590/6832]	Time 0.129 (0.105)	Data 0.00082 (0.00090)	Tok/s 63307 (59246)	Loss/tok 3.3744 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][5590/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 63290 (59621)	Loss/tok 3.2487 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][5590/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00095)	Tok/s 63284 (58785)	Loss/tok 3.2103 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][5590/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 63275 (60073)	Loss/tok 3.3836 (3.2132)	Learning Rate [7.8125e-05]
1: TRAIN [2][5600/6832]	Time 0.126 (0.105)	Data 0.00083 (0.00090)	Tok/s 58109 (59256)	Loss/tok 3.2844 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5600/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00095)	Tok/s 58091 (58796)	Loss/tok 3.2144 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5600/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00094)	Tok/s 58081 (59630)	Loss/tok 3.4345 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5600/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00094)	Tok/s 58077 (60082)	Loss/tok 3.2964 (3.2133)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][5610/6832]	Time 0.054 (0.105)	Data 0.00097 (0.00094)	Tok/s 50060 (59636)	Loss/tok 2.7201 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][5610/6832]	Time 0.054 (0.105)	Data 0.00096 (0.00094)	Tok/s 50047 (60087)	Loss/tok 2.6180 (3.2133)	Learning Rate [7.8125e-05]
1: TRAIN [2][5610/6832]	Time 0.054 (0.105)	Data 0.00095 (0.00090)	Tok/s 48097 (59261)	Loss/tok 2.5089 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][5610/6832]	Time 0.054 (0.105)	Data 0.00098 (0.00095)	Tok/s 47649 (58801)	Loss/tok 2.6813 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5620/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00094)	Tok/s 49298 (59629)	Loss/tok 2.9764 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][5620/6832]	Time 0.081 (0.105)	Data 0.00083 (0.00090)	Tok/s 49286 (59254)	Loss/tok 3.0318 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5620/6832]	Time 0.080 (0.105)	Data 0.00085 (0.00094)	Tok/s 50673 (60081)	Loss/tok 2.8344 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][5620/6832]	Time 0.081 (0.105)	Data 0.00093 (0.00095)	Tok/s 49233 (58792)	Loss/tok 3.0045 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][5630/6832]	Time 0.053 (0.105)	Data 0.00084 (0.00090)	Tok/s 49329 (59246)	Loss/tok 2.5307 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5630/6832]	Time 0.053 (0.105)	Data 0.00084 (0.00094)	Tok/s 51049 (60072)	Loss/tok 2.6533 (3.2131)	Learning Rate [7.8125e-05]
2: TRAIN [2][5630/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00094)	Tok/s 51044 (59620)	Loss/tok 2.7119 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][5630/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00095)	Tok/s 48557 (58785)	Loss/tok 2.8288 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5640/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00094)	Tok/s 54536 (59619)	Loss/tok 3.1490 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5640/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00090)	Tok/s 54736 (59245)	Loss/tok 3.0787 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][5640/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 55528 (60071)	Loss/tok 3.4054 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][5640/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00095)	Tok/s 54497 (58784)	Loss/tok 3.2211 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][5650/6832]	Time 0.105 (0.105)	Data 0.00095 (0.00094)	Tok/s 52664 (59612)	Loss/tok 3.0378 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5650/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00090)	Tok/s 52664 (59238)	Loss/tok 3.3509 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][5650/6832]	Time 0.105 (0.105)	Data 0.00090 (0.00094)	Tok/s 52642 (60063)	Loss/tok 3.2394 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][5650/6832]	Time 0.105 (0.105)	Data 0.00095 (0.00095)	Tok/s 52670 (58777)	Loss/tok 3.0727 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5660/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00090)	Tok/s 70700 (59236)	Loss/tok 3.2218 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][5660/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00095)	Tok/s 70724 (58775)	Loss/tok 3.3338 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5660/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00094)	Tok/s 71658 (60061)	Loss/tok 3.3385 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5660/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 70960 (59610)	Loss/tok 3.5512 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5670/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00090)	Tok/s 53971 (59231)	Loss/tok 3.0692 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][5670/6832]	Time 0.100 (0.105)	Data 0.00094 (0.00094)	Tok/s 54313 (59605)	Loss/tok 3.2023 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][5670/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00094)	Tok/s 55273 (60056)	Loss/tok 3.3466 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5670/6832]	Time 0.100 (0.105)	Data 0.00098 (0.00095)	Tok/s 54023 (58771)	Loss/tok 3.0538 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][5680/6832]	Time 0.075 (0.105)	Data 0.00085 (0.00090)	Tok/s 52879 (59229)	Loss/tok 3.0226 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][5680/6832]	Time 0.075 (0.105)	Data 0.00112 (0.00094)	Tok/s 53006 (59603)	Loss/tok 3.0609 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][5680/6832]	Time 0.075 (0.105)	Data 0.00108 (0.00094)	Tok/s 54295 (60054)	Loss/tok 3.0198 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5680/6832]	Time 0.075 (0.105)	Data 0.00102 (0.00095)	Tok/s 52885 (58769)	Loss/tok 2.8561 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][5690/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00090)	Tok/s 68902 (59226)	Loss/tok 3.2100 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][5690/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 68350 (58766)	Loss/tok 3.2265 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][5690/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00094)	Tok/s 68867 (60049)	Loss/tok 3.3758 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5690/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 68867 (59599)	Loss/tok 3.3099 (3.2111)	Learning Rate [7.8125e-05]
1: TRAIN [2][5700/6832]	Time 0.113 (0.105)	Data 0.00084 (0.00090)	Tok/s 52327 (59220)	Loss/tok 3.1350 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][5700/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00094)	Tok/s 52355 (59593)	Loss/tok 3.1944 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][5700/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00094)	Tok/s 52641 (60044)	Loss/tok 3.1088 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5700/6832]	Time 0.112 (0.105)	Data 0.00099 (0.00095)	Tok/s 52346 (58761)	Loss/tok 3.2778 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][5710/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00090)	Tok/s 57430 (59218)	Loss/tok 3.2810 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][5710/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00094)	Tok/s 58230 (59591)	Loss/tok 3.3083 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][5710/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00094)	Tok/s 58444 (60043)	Loss/tok 3.3494 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][5710/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00095)	Tok/s 57486 (58759)	Loss/tok 3.3051 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][5720/6832]	Time 0.080 (0.105)	Data 0.00084 (0.00094)	Tok/s 54638 (60048)	Loss/tok 3.1008 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5720/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00094)	Tok/s 54406 (59597)	Loss/tok 3.2329 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][5720/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00090)	Tok/s 54336 (59225)	Loss/tok 3.1407 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][5720/6832]	Time 0.080 (0.105)	Data 0.00096 (0.00095)	Tok/s 54377 (58766)	Loss/tok 3.0847 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][5730/6832]	Time 0.074 (0.105)	Data 0.00100 (0.00094)	Tok/s 52651 (59590)	Loss/tok 2.9640 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][5730/6832]	Time 0.074 (0.105)	Data 0.00097 (0.00094)	Tok/s 53704 (60041)	Loss/tok 2.9448 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5730/6832]	Time 0.074 (0.105)	Data 0.00093 (0.00090)	Tok/s 51968 (59218)	Loss/tok 2.8687 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][5730/6832]	Time 0.074 (0.105)	Data 0.00101 (0.00095)	Tok/s 52005 (58759)	Loss/tok 2.9192 (3.2123)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][5740/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00094)	Tok/s 54454 (59590)	Loss/tok 3.2269 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][5740/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00094)	Tok/s 54455 (60041)	Loss/tok 3.4836 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5740/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00090)	Tok/s 53904 (59218)	Loss/tok 3.2475 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][5740/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00095)	Tok/s 53323 (58760)	Loss/tok 3.1287 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][5750/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00094)	Tok/s 51404 (60038)	Loss/tok 2.8590 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][5750/6832]	Time 0.069 (0.105)	Data 0.00090 (0.00090)	Tok/s 49742 (59215)	Loss/tok 2.8164 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][5750/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00095)	Tok/s 49687 (58758)	Loss/tok 2.9335 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][5750/6832]	Time 0.070 (0.105)	Data 0.00099 (0.00094)	Tok/s 49687 (59587)	Loss/tok 2.9881 (3.2113)	Learning Rate [7.8125e-05]
2: TRAIN [2][5760/6832]	Time 0.064 (0.105)	Data 0.00093 (0.00094)	Tok/s 50041 (59587)	Loss/tok 2.9475 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][5760/6832]	Time 0.064 (0.105)	Data 0.00090 (0.00090)	Tok/s 50017 (59215)	Loss/tok 2.9602 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][5760/6832]	Time 0.064 (0.105)	Data 0.00093 (0.00095)	Tok/s 50024 (58758)	Loss/tok 2.7724 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][5760/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00094)	Tok/s 51959 (60039)	Loss/tok 2.8960 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5770/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00094)	Tok/s 75132 (59588)	Loss/tok 3.3083 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][5770/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00090)	Tok/s 74641 (59217)	Loss/tok 3.4088 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][5770/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 75574 (60040)	Loss/tok 3.2400 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5770/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00095)	Tok/s 74654 (58760)	Loss/tok 3.2912 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][5780/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00090)	Tok/s 53200 (59215)	Loss/tok 2.9355 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][5780/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00094)	Tok/s 53154 (60038)	Loss/tok 3.1006 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5780/6832]	Time 0.077 (0.105)	Data 0.00098 (0.00094)	Tok/s 53181 (59587)	Loss/tok 3.3746 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][5780/6832]	Time 0.077 (0.105)	Data 0.00099 (0.00095)	Tok/s 53153 (58758)	Loss/tok 2.9683 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][5790/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00090)	Tok/s 61811 (59223)	Loss/tok 3.2936 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][5790/6832]	Time 0.126 (0.105)	Data 0.00100 (0.00094)	Tok/s 62196 (59595)	Loss/tok 3.1922 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][5790/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00094)	Tok/s 62814 (60046)	Loss/tok 3.2784 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5790/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00095)	Tok/s 61007 (58767)	Loss/tok 3.2831 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][5800/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00090)	Tok/s 76277 (59223)	Loss/tok 3.2594 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][5800/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 76763 (60047)	Loss/tok 3.2344 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5800/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 76542 (59595)	Loss/tok 3.2359 (3.2116)	Learning Rate [7.8125e-05]
0: TRAIN [2][5800/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 75552 (58765)	Loss/tok 3.3472 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5810/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00094)	Tok/s 66832 (60037)	Loss/tok 3.4519 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5810/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 66266 (59585)	Loss/tok 3.3153 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][5810/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00090)	Tok/s 66229 (59213)	Loss/tok 3.3238 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5810/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00095)	Tok/s 66246 (58753)	Loss/tok 3.2764 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][5820/6832]	Time 0.094 (0.105)	Data 0.00091 (0.00090)	Tok/s 51671 (59209)	Loss/tok 3.1713 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][5820/6832]	Time 0.094 (0.105)	Data 0.00092 (0.00096)	Tok/s 51194 (58749)	Loss/tok 2.9784 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][5820/6832]	Time 0.094 (0.105)	Data 0.00095 (0.00094)	Tok/s 51689 (59581)	Loss/tok 3.3470 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][5820/6832]	Time 0.094 (0.105)	Data 0.00086 (0.00094)	Tok/s 51658 (60033)	Loss/tok 3.1708 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5830/6832]	Time 0.056 (0.105)	Data 0.00097 (0.00090)	Tok/s 50282 (59217)	Loss/tok 2.6637 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][5830/6832]	Time 0.056 (0.105)	Data 0.00096 (0.00096)	Tok/s 49613 (58758)	Loss/tok 2.7712 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][5830/6832]	Time 0.056 (0.105)	Data 0.00101 (0.00094)	Tok/s 50195 (59588)	Loss/tok 2.7533 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][5830/6832]	Time 0.056 (0.105)	Data 0.00097 (0.00094)	Tok/s 51627 (60040)	Loss/tok 2.8573 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5840/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00090)	Tok/s 66339 (59227)	Loss/tok 3.4475 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5840/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 66361 (60050)	Loss/tok 3.2590 (3.2127)	Learning Rate [7.8125e-05]
2: TRAIN [2][5840/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00094)	Tok/s 66362 (59599)	Loss/tok 3.1762 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][5840/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00096)	Tok/s 66208 (58769)	Loss/tok 3.3510 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][5850/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00094)	Tok/s 58882 (59595)	Loss/tok 3.1191 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5850/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00090)	Tok/s 58060 (59223)	Loss/tok 3.2887 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][5850/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00096)	Tok/s 57758 (58765)	Loss/tok 3.1642 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][5850/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00094)	Tok/s 58857 (60046)	Loss/tok 3.3542 (3.2128)	Learning Rate [7.8125e-05]
0: TRAIN [2][5860/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00096)	Tok/s 63855 (58772)	Loss/tok 3.3001 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5860/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00090)	Tok/s 63836 (59229)	Loss/tok 3.3193 (3.2127)	Learning Rate [7.8125e-05]
3: TRAIN [2][5860/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 64727 (60052)	Loss/tok 3.2464 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5860/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00094)	Tok/s 63809 (59601)	Loss/tok 3.3468 (3.2115)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: TRAIN [2][5870/6832]	Time 0.049 (0.105)	Data 0.00088 (0.00094)	Tok/s 45783 (60047)	Loss/tok 2.4949 (3.2129)	Learning Rate [7.8125e-05]
2: TRAIN [2][5870/6832]	Time 0.049 (0.105)	Data 0.00091 (0.00094)	Tok/s 44744 (59596)	Loss/tok 2.4567 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][5870/6832]	Time 0.049 (0.105)	Data 0.00094 (0.00090)	Tok/s 42127 (59224)	Loss/tok 2.6261 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5870/6832]	Time 0.049 (0.105)	Data 0.00094 (0.00096)	Tok/s 39576 (58766)	Loss/tok 2.2035 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5880/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 80459 (60052)	Loss/tok 3.1631 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5880/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00094)	Tok/s 80391 (59601)	Loss/tok 3.1697 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][5880/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00090)	Tok/s 79431 (59229)	Loss/tok 3.2936 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][5880/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00096)	Tok/s 79415 (58771)	Loss/tok 3.3475 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5890/6832]	Time 0.095 (0.105)	Data 0.00092 (0.00096)	Tok/s 52326 (58774)	Loss/tok 3.1717 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5890/6832]	Time 0.095 (0.105)	Data 0.00092 (0.00090)	Tok/s 53604 (59231)	Loss/tok 3.0831 (3.2126)	Learning Rate [7.8125e-05]
3: TRAIN [2][5890/6832]	Time 0.095 (0.105)	Data 0.00084 (0.00094)	Tok/s 53655 (60054)	Loss/tok 3.2561 (3.2130)	Learning Rate [7.8125e-05]
2: TRAIN [2][5890/6832]	Time 0.095 (0.105)	Data 0.00092 (0.00094)	Tok/s 53638 (59603)	Loss/tok 3.0469 (3.2115)	Learning Rate [7.8125e-05]
2: TRAIN [2][5900/6832]	Time 0.080 (0.105)	Data 0.00094 (0.00094)	Tok/s 54341 (59613)	Loss/tok 2.8980 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][5900/6832]	Time 0.080 (0.105)	Data 0.00084 (0.00094)	Tok/s 55015 (60065)	Loss/tok 3.1114 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5900/6832]	Time 0.080 (0.105)	Data 0.00094 (0.00090)	Tok/s 54427 (59241)	Loss/tok 3.0253 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5900/6832]	Time 0.080 (0.105)	Data 0.00096 (0.00096)	Tok/s 54441 (58785)	Loss/tok 3.0907 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][5910/6832]	Time 0.100 (0.105)	Data 0.00096 (0.00094)	Tok/s 53711 (59613)	Loss/tok 3.0956 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][5910/6832]	Time 0.100 (0.105)	Data 0.00084 (0.00094)	Tok/s 53708 (60064)	Loss/tok 3.2430 (3.2129)	Learning Rate [7.8125e-05]
1: TRAIN [2][5910/6832]	Time 0.100 (0.105)	Data 0.00092 (0.00090)	Tok/s 53234 (59241)	Loss/tok 3.1880 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5910/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00096)	Tok/s 52402 (58783)	Loss/tok 3.1736 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5920/6832]	Time 0.133 (0.105)	Data 0.00092 (0.00090)	Tok/s 87576 (59245)	Loss/tok 3.1837 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5920/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00096)	Tok/s 86830 (58787)	Loss/tok 3.3761 (3.2125)	Learning Rate [7.8125e-05]
3: TRAIN [2][5920/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00094)	Tok/s 89105 (60068)	Loss/tok 3.0756 (3.2128)	Learning Rate [7.8125e-05]
2: TRAIN [2][5920/6832]	Time 0.133 (0.105)	Data 0.00099 (0.00094)	Tok/s 88235 (59617)	Loss/tok 3.1717 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][5930/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00094)	Tok/s 59576 (59613)	Loss/tok 3.2696 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][5930/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00094)	Tok/s 59579 (60064)	Loss/tok 3.2966 (3.2128)	Learning Rate [7.8125e-05]
1: TRAIN [2][5930/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00090)	Tok/s 59580 (59242)	Loss/tok 3.3349 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5930/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00096)	Tok/s 59011 (58784)	Loss/tok 3.1332 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][5940/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00094)	Tok/s 52693 (59611)	Loss/tok 3.3023 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][5940/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00094)	Tok/s 52743 (60062)	Loss/tok 3.2320 (3.2127)	Learning Rate [7.8125e-05]
1: TRAIN [2][5940/6832]	Time 0.109 (0.105)	Data 0.00095 (0.00090)	Tok/s 52677 (59239)	Loss/tok 3.2709 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5940/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00096)	Tok/s 52681 (58782)	Loss/tok 3.1166 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][5950/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00090)	Tok/s 72278 (59248)	Loss/tok 3.3585 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5950/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00096)	Tok/s 71891 (58791)	Loss/tok 3.4078 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][5950/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 72845 (59620)	Loss/tok 3.4159 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][5950/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 72848 (60071)	Loss/tok 3.4036 (3.2126)	Learning Rate [7.8125e-05]
1: TRAIN [2][5960/6832]	Time 0.070 (0.105)	Data 0.00100 (0.00090)	Tok/s 53353 (59248)	Loss/tok 3.1065 (3.2126)	Learning Rate [7.8125e-05]
2: TRAIN [2][5960/6832]	Time 0.070 (0.105)	Data 0.00097 (0.00094)	Tok/s 53336 (59619)	Loss/tok 2.8072 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][5960/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00094)	Tok/s 53343 (60070)	Loss/tok 3.0040 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][5960/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00096)	Tok/s 52983 (58791)	Loss/tok 2.9833 (3.2125)	Learning Rate [7.8125e-05]
2: TRAIN [2][5970/6832]	Time 0.131 (0.105)	Data 0.00123 (0.00094)	Tok/s 78814 (59611)	Loss/tok 3.1908 (3.2115)	Learning Rate [7.8125e-05]
1: TRAIN [2][5970/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00090)	Tok/s 77665 (59240)	Loss/tok 3.1984 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][5970/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00095)	Tok/s 77701 (58783)	Loss/tok 3.1900 (3.2124)	Learning Rate [7.8125e-05]
3: TRAIN [2][5970/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00094)	Tok/s 78815 (60062)	Loss/tok 3.2031 (3.2125)	Learning Rate [7.8125e-05]
1: TRAIN [2][5980/6832]	Time 0.073 (0.105)	Data 0.00097 (0.00090)	Tok/s 51625 (59232)	Loss/tok 2.9347 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][5980/6832]	Time 0.073 (0.105)	Data 0.00111 (0.00094)	Tok/s 52499 (59604)	Loss/tok 2.9609 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][5980/6832]	Time 0.073 (0.105)	Data 0.00100 (0.00095)	Tok/s 50679 (58775)	Loss/tok 3.0301 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][5980/6832]	Time 0.073 (0.105)	Data 0.00099 (0.00094)	Tok/s 52390 (60054)	Loss/tok 2.8861 (3.2124)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][5990/6832]	Time 0.120 (0.105)	Data 0.00109 (0.00094)	Tok/s 58815 (59610)	Loss/tok 3.2281 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][5990/6832]	Time 0.120 (0.105)	Data 0.00104 (0.00094)	Tok/s 58818 (60060)	Loss/tok 3.1093 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][5990/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00095)	Tok/s 58693 (58781)	Loss/tok 3.2181 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][5990/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00090)	Tok/s 58712 (59237)	Loss/tok 3.1744 (3.2123)	Learning Rate [7.8125e-05]
2: TRAIN [2][6000/6832]	Time 0.123 (0.105)	Data 0.00101 (0.00094)	Tok/s 58426 (59612)	Loss/tok 3.3671 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][6000/6832]	Time 0.123 (0.105)	Data 0.00100 (0.00090)	Tok/s 58414 (59239)	Loss/tok 3.3456 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][6000/6832]	Time 0.123 (0.105)	Data 0.00097 (0.00095)	Tok/s 58398 (58783)	Loss/tok 3.4377 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][6000/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00094)	Tok/s 58241 (60062)	Loss/tok 3.3155 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][6010/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00094)	Tok/s 65274 (59607)	Loss/tok 3.3679 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][6010/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 65264 (60057)	Loss/tok 3.3249 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][6010/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00090)	Tok/s 65236 (59235)	Loss/tok 3.3146 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][6010/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 65204 (58779)	Loss/tok 3.2042 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][6020/6832]	Time 0.059 (0.105)	Data 0.00095 (0.00090)	Tok/s 50320 (59246)	Loss/tok 2.7650 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][6020/6832]	Time 0.058 (0.105)	Data 0.00094 (0.00095)	Tok/s 50334 (58791)	Loss/tok 2.6892 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][6020/6832]	Time 0.058 (0.105)	Data 0.00099 (0.00094)	Tok/s 50334 (59618)	Loss/tok 2.6489 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][6020/6832]	Time 0.059 (0.105)	Data 0.00087 (0.00094)	Tok/s 51290 (60068)	Loss/tok 2.8062 (3.2124)	Learning Rate [7.8125e-05]
1: TRAIN [2][6030/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00090)	Tok/s 52828 (59241)	Loss/tok 3.0440 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][6030/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00095)	Tok/s 52836 (58786)	Loss/tok 2.9208 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][6030/6832]	Time 0.075 (0.105)	Data 0.00095 (0.00094)	Tok/s 52895 (59613)	Loss/tok 2.9955 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][6030/6832]	Time 0.075 (0.105)	Data 0.00091 (0.00094)	Tok/s 52718 (60063)	Loss/tok 3.1228 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][6040/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00090)	Tok/s 52704 (59238)	Loss/tok 3.0489 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][6040/6832]	Time 0.092 (0.105)	Data 0.00094 (0.00094)	Tok/s 52723 (59608)	Loss/tok 3.2174 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][6040/6832]	Time 0.092 (0.105)	Data 0.00085 (0.00094)	Tok/s 52688 (60058)	Loss/tok 3.1376 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][6040/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00095)	Tok/s 52704 (58783)	Loss/tok 3.0499 (3.2122)	Learning Rate [7.8125e-05]
1: TRAIN [2][6050/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00090)	Tok/s 58858 (59235)	Loss/tok 3.3858 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [2][6050/6832]	Time 0.115 (0.105)	Data 0.00102 (0.00095)	Tok/s 58891 (58781)	Loss/tok 3.2512 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][6050/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00094)	Tok/s 59935 (60055)	Loss/tok 3.2618 (3.2124)	Learning Rate [7.8125e-05]
2: TRAIN [2][6050/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00094)	Tok/s 58848 (59605)	Loss/tok 3.2794 (3.2114)	Learning Rate [7.8125e-05]
0: TRAIN [2][6060/6832]	Time 0.076 (0.105)	Data 0.00096 (0.00095)	Tok/s 52297 (58790)	Loss/tok 3.1290 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][6060/6832]	Time 0.076 (0.105)	Data 0.00091 (0.00094)	Tok/s 52244 (59616)	Loss/tok 3.1289 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][6060/6832]	Time 0.076 (0.105)	Data 0.00085 (0.00094)	Tok/s 52543 (60065)	Loss/tok 3.0019 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][6060/6832]	Time 0.076 (0.105)	Data 0.00098 (0.00090)	Tok/s 52235 (59245)	Loss/tok 2.8909 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][6070/6832]	Time 0.100 (0.105)	Data 0.00101 (0.00090)	Tok/s 52394 (59243)	Loss/tok 3.2205 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][6070/6832]	Time 0.100 (0.105)	Data 0.00107 (0.00094)	Tok/s 52348 (59613)	Loss/tok 2.9461 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][6070/6832]	Time 0.100 (0.105)	Data 0.00101 (0.00094)	Tok/s 52366 (60063)	Loss/tok 3.0490 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][6070/6832]	Time 0.100 (0.105)	Data 0.00099 (0.00095)	Tok/s 52341 (58787)	Loss/tok 3.0141 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][6080/6832]	Time 0.127 (0.105)	Data 0.00098 (0.00094)	Tok/s 67576 (59622)	Loss/tok 3.3715 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][6080/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 67689 (60071)	Loss/tok 3.4061 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][6080/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00091)	Tok/s 67562 (59252)	Loss/tok 3.2269 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][6080/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00095)	Tok/s 67557 (58797)	Loss/tok 3.2077 (3.2122)	Learning Rate [7.8125e-05]
3: TRAIN [2][6090/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 60451 (60074)	Loss/tok 3.2741 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][6090/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 60446 (59624)	Loss/tok 3.2208 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][6090/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00091)	Tok/s 59685 (59254)	Loss/tok 3.4811 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][6090/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00095)	Tok/s 59466 (58800)	Loss/tok 3.4537 (3.2123)	Learning Rate [7.8125e-05]
1: TRAIN [2][6100/6832]	Time 0.087 (0.105)	Data 0.00096 (0.00091)	Tok/s 53248 (59260)	Loss/tok 3.1878 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][6100/6832]	Time 0.087 (0.105)	Data 0.00093 (0.00096)	Tok/s 51795 (58805)	Loss/tok 3.1661 (3.2123)	Learning Rate [7.8125e-05]
3: TRAIN [2][6100/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00094)	Tok/s 53194 (60078)	Loss/tok 2.9701 (3.2121)	Learning Rate [7.8125e-05]
2: TRAIN [2][6100/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00094)	Tok/s 53212 (59629)	Loss/tok 3.0489 (3.2113)	Learning Rate [7.8125e-05]
2: TRAIN [2][6110/6832]	Time 0.111 (0.105)	Data 0.00095 (0.00094)	Tok/s 53026 (59623)	Loss/tok 3.2548 (3.2113)	Learning Rate [7.8125e-05]
3: TRAIN [2][6110/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00094)	Tok/s 53695 (60072)	Loss/tok 3.1547 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][6110/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00091)	Tok/s 52962 (59253)	Loss/tok 3.1028 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][6110/6832]	Time 0.111 (0.105)	Data 0.00092 (0.00095)	Tok/s 52966 (58799)	Loss/tok 3.0676 (3.2122)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][6120/6832]	Time 0.060 (0.105)	Data 0.00085 (0.00094)	Tok/s 49358 (59613)	Loss/tok 2.9189 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][6120/6832]	Time 0.060 (0.105)	Data 0.00098 (0.00091)	Tok/s 49371 (59243)	Loss/tok 2.6305 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][6120/6832]	Time 0.060 (0.105)	Data 0.00095 (0.00095)	Tok/s 49374 (58788)	Loss/tok 2.9005 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][6120/6832]	Time 0.060 (0.105)	Data 0.00085 (0.00094)	Tok/s 50608 (60062)	Loss/tok 2.7761 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6130/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 67420 (59624)	Loss/tok 3.2984 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][6130/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00091)	Tok/s 67403 (59255)	Loss/tok 3.2733 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][6130/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00095)	Tok/s 67249 (58800)	Loss/tok 3.3778 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][6130/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 67415 (60074)	Loss/tok 3.3287 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6140/6832]	Time 0.094 (0.105)	Data 0.00094 (0.00094)	Tok/s 53276 (59622)	Loss/tok 3.2065 (3.2113)	Learning Rate [7.8125e-05]
1: TRAIN [2][6140/6832]	Time 0.094 (0.105)	Data 0.00096 (0.00091)	Tok/s 53295 (59253)	Loss/tok 3.0134 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][6140/6832]	Time 0.094 (0.105)	Data 0.00095 (0.00096)	Tok/s 52319 (58798)	Loss/tok 3.0930 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][6140/6832]	Time 0.094 (0.105)	Data 0.00096 (0.00094)	Tok/s 53281 (60071)	Loss/tok 3.0775 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6150/6832]	Time 0.049 (0.105)	Data 0.00087 (0.00094)	Tok/s 49377 (59618)	Loss/tok 2.5996 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][6150/6832]	Time 0.049 (0.105)	Data 0.00093 (0.00091)	Tok/s 48799 (59248)	Loss/tok 2.5303 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][6150/6832]	Time 0.049 (0.105)	Data 0.00092 (0.00095)	Tok/s 46776 (58792)	Loss/tok 2.3697 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][6150/6832]	Time 0.049 (0.105)	Data 0.00085 (0.00094)	Tok/s 51189 (60068)	Loss/tok 2.6983 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6160/6832]	Time 0.103 (0.105)	Data 0.00101 (0.00094)	Tok/s 54936 (59615)	Loss/tok 3.0799 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][6160/6832]	Time 0.103 (0.105)	Data 0.00103 (0.00094)	Tok/s 55859 (60064)	Loss/tok 3.1233 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6160/6832]	Time 0.103 (0.105)	Data 0.00098 (0.00096)	Tok/s 54917 (58789)	Loss/tok 3.1096 (3.2121)	Learning Rate [7.8125e-05]
1: TRAIN [2][6160/6832]	Time 0.103 (0.105)	Data 0.00100 (0.00091)	Tok/s 54906 (59245)	Loss/tok 3.1527 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][6170/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00094)	Tok/s 52972 (59607)	Loss/tok 3.2336 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][6170/6832]	Time 0.104 (0.105)	Data 0.00097 (0.00096)	Tok/s 52986 (58782)	Loss/tok 3.1671 (3.2121)	Learning Rate [7.8125e-05]
3: TRAIN [2][6170/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00094)	Tok/s 52975 (60056)	Loss/tok 3.3205 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][6170/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00091)	Tok/s 52965 (59237)	Loss/tok 3.1879 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][6180/6832]	Time 0.049 (0.105)	Data 0.00087 (0.00094)	Tok/s 44463 (59608)	Loss/tok 2.4346 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][6180/6832]	Time 0.049 (0.105)	Data 0.00099 (0.00096)	Tok/s 39572 (58782)	Loss/tok 2.3946 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][6180/6832]	Time 0.049 (0.105)	Data 0.00102 (0.00091)	Tok/s 42241 (59238)	Loss/tok 2.4246 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][6180/6832]	Time 0.049 (0.105)	Data 0.00116 (0.00094)	Tok/s 46527 (60057)	Loss/tok 2.4571 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][6190/6832]	Time 0.102 (0.105)	Data 0.00094 (0.00091)	Tok/s 52665 (59242)	Loss/tok 3.2263 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][6190/6832]	Time 0.102 (0.105)	Data 0.00087 (0.00094)	Tok/s 52619 (59612)	Loss/tok 3.1596 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [2][6190/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00096)	Tok/s 52630 (58786)	Loss/tok 3.2128 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][6190/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00094)	Tok/s 52820 (60061)	Loss/tok 3.1382 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6200/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 75748 (59615)	Loss/tok 3.4013 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6200/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00096)	Tok/s 74751 (58787)	Loss/tok 3.2269 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][6200/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00091)	Tok/s 75269 (59245)	Loss/tok 3.4738 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][6200/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 75760 (60065)	Loss/tok 3.4912 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][6210/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00091)	Tok/s 53447 (59249)	Loss/tok 2.9677 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][6210/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00096)	Tok/s 53444 (58792)	Loss/tok 2.9351 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][6210/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00094)	Tok/s 53376 (59619)	Loss/tok 3.0898 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][6210/6832]	Time 0.089 (0.105)	Data 0.00102 (0.00094)	Tok/s 53375 (60069)	Loss/tok 3.0165 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6220/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00096)	Tok/s 79397 (58795)	Loss/tok 3.1791 (3.2120)	Learning Rate [7.8125e-05]
1: TRAIN [2][6220/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00091)	Tok/s 79473 (59252)	Loss/tok 3.2476 (3.2122)	Learning Rate [7.8125e-05]
2: TRAIN [2][6220/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 80204 (59622)	Loss/tok 3.2661 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][6220/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 80432 (60071)	Loss/tok 3.2154 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6230/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00094)	Tok/s 56301 (59620)	Loss/tok 3.1742 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][6230/6832]	Time 0.109 (0.105)	Data 0.00099 (0.00091)	Tok/s 56151 (59250)	Loss/tok 3.3854 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][6230/6832]	Time 0.109 (0.105)	Data 0.00097 (0.00096)	Tok/s 56120 (58794)	Loss/tok 3.0182 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][6230/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00094)	Tok/s 57324 (60069)	Loss/tok 3.1257 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6240/6832]	Time 0.073 (0.105)	Data 0.00087 (0.00094)	Tok/s 52508 (59611)	Loss/tok 3.0105 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6240/6832]	Time 0.073 (0.105)	Data 0.00095 (0.00091)	Tok/s 52432 (59240)	Loss/tok 2.9382 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][6240/6832]	Time 0.073 (0.105)	Data 0.00098 (0.00096)	Tok/s 50781 (58780)	Loss/tok 3.0142 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6240/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00094)	Tok/s 52528 (60061)	Loss/tok 2.9944 (3.2118)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][6250/6832]	Time 0.078 (0.105)	Data 0.00094 (0.00094)	Tok/s 52604 (59617)	Loss/tok 3.0524 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6250/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00091)	Tok/s 52553 (59246)	Loss/tok 3.0801 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][6250/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00096)	Tok/s 52305 (58787)	Loss/tok 3.1867 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6250/6832]	Time 0.078 (0.105)	Data 0.00099 (0.00094)	Tok/s 52581 (60067)	Loss/tok 3.0949 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6260/6832]	Time 0.096 (0.105)	Data 0.00085 (0.00094)	Tok/s 53610 (59623)	Loss/tok 3.2289 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6260/6832]	Time 0.096 (0.105)	Data 0.00099 (0.00091)	Tok/s 52669 (59252)	Loss/tok 3.0598 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][6260/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00096)	Tok/s 52173 (58792)	Loss/tok 3.1058 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6260/6832]	Time 0.095 (0.105)	Data 0.00089 (0.00094)	Tok/s 53625 (60072)	Loss/tok 3.0987 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6270/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 65735 (59616)	Loss/tok 3.3708 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6270/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00091)	Tok/s 65744 (59245)	Loss/tok 3.3693 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][6270/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00096)	Tok/s 65709 (58785)	Loss/tok 3.2501 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6270/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 65880 (60065)	Loss/tok 3.3687 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][6280/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00091)	Tok/s 50722 (59240)	Loss/tok 3.0318 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][6280/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00096)	Tok/s 50035 (58781)	Loss/tok 3.2135 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6280/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00094)	Tok/s 51400 (59611)	Loss/tok 3.1603 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6280/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00094)	Tok/s 51424 (60060)	Loss/tok 3.1085 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6290/6832]	Time 0.050 (0.105)	Data 0.00090 (0.00094)	Tok/s 48456 (59612)	Loss/tok 2.5373 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][6290/6832]	Time 0.050 (0.105)	Data 0.00093 (0.00091)	Tok/s 48066 (59241)	Loss/tok 2.6061 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][6290/6832]	Time 0.050 (0.105)	Data 0.00093 (0.00096)	Tok/s 45843 (58782)	Loss/tok 2.5021 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6290/6832]	Time 0.050 (0.105)	Data 0.00090 (0.00094)	Tok/s 50199 (60061)	Loss/tok 2.7255 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][6300/6832]	Time 0.127 (0.105)	Data 0.00105 (0.00091)	Tok/s 67729 (59239)	Loss/tok 3.2065 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6300/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00094)	Tok/s 67733 (59609)	Loss/tok 3.4152 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][6300/6832]	Time 0.127 (0.105)	Data 0.00102 (0.00096)	Tok/s 67379 (58780)	Loss/tok 3.2489 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6300/6832]	Time 0.127 (0.105)	Data 0.00102 (0.00094)	Tok/s 67736 (60059)	Loss/tok 3.4293 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][6310/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00094)	Tok/s 53034 (59625)	Loss/tok 3.2593 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6310/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00091)	Tok/s 52975 (59255)	Loss/tok 2.9087 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6310/6832]	Time 0.089 (0.105)	Data 0.00096 (0.00096)	Tok/s 53004 (58796)	Loss/tok 3.2044 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6310/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00094)	Tok/s 53030 (60075)	Loss/tok 3.3011 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6320/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00094)	Tok/s 53014 (59617)	Loss/tok 2.8903 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][6320/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00091)	Tok/s 52872 (59247)	Loss/tok 2.8473 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6320/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00096)	Tok/s 52113 (58788)	Loss/tok 3.0408 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][6320/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00094)	Tok/s 52961 (60066)	Loss/tok 2.9554 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6330/6832]	Time 0.091 (0.105)	Data 0.00089 (0.00094)	Tok/s 53302 (59621)	Loss/tok 3.0624 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][6330/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00096)	Tok/s 53258 (58793)	Loss/tok 3.0158 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][6330/6832]	Time 0.091 (0.105)	Data 0.00093 (0.00091)	Tok/s 53267 (59251)	Loss/tok 3.0776 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][6330/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00094)	Tok/s 53337 (60070)	Loss/tok 3.0311 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6340/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00094)	Tok/s 62364 (59627)	Loss/tok 3.2206 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][6340/6832]	Time 0.119 (0.105)	Data 0.00104 (0.00091)	Tok/s 61440 (59257)	Loss/tok 3.1579 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][6340/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00094)	Tok/s 62506 (60076)	Loss/tok 3.2488 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6340/6832]	Time 0.119 (0.105)	Data 0.00102 (0.00096)	Tok/s 61424 (58798)	Loss/tok 3.2848 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][6350/6832]	Time 0.121 (0.105)	Data 0.00094 (0.00091)	Tok/s 50667 (59257)	Loss/tok 3.1387 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6350/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00094)	Tok/s 50649 (59626)	Loss/tok 3.2947 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][6350/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00096)	Tok/s 50451 (58798)	Loss/tok 3.3273 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6350/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00094)	Tok/s 50565 (60075)	Loss/tok 3.2638 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6360/6832]	Time 0.082 (0.105)	Data 0.00101 (0.00094)	Tok/s 54549 (59628)	Loss/tok 3.2508 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][6360/6832]	Time 0.082 (0.105)	Data 0.00104 (0.00091)	Tok/s 54504 (59259)	Loss/tok 3.1610 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6360/6832]	Time 0.082 (0.105)	Data 0.00105 (0.00096)	Tok/s 54474 (58800)	Loss/tok 3.0622 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6360/6832]	Time 0.082 (0.105)	Data 0.00105 (0.00094)	Tok/s 54507 (60076)	Loss/tok 3.0381 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][6370/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00091)	Tok/s 61841 (59268)	Loss/tok 3.2788 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6370/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00096)	Tok/s 61830 (58810)	Loss/tok 3.4649 (3.2120)	Learning Rate [7.8125e-05]
2: TRAIN [2][6370/6832]	Time 0.125 (0.105)	Data 0.00116 (0.00094)	Tok/s 62809 (59637)	Loss/tok 3.2458 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][6370/6832]	Time 0.125 (0.105)	Data 0.00116 (0.00094)	Tok/s 63384 (60085)	Loss/tok 3.4150 (3.2117)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: TRAIN [2][6380/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00096)	Tok/s 67165 (58807)	Loss/tok 3.3442 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][6380/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00091)	Tok/s 67152 (59265)	Loss/tok 3.2575 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6380/6832]	Time 0.131 (0.105)	Data 0.00116 (0.00094)	Tok/s 67167 (59634)	Loss/tok 3.2728 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][6380/6832]	Time 0.132 (0.105)	Data 0.00114 (0.00094)	Tok/s 68134 (60082)	Loss/tok 3.3795 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][6390/6832]	Time 0.095 (0.105)	Data 0.00096 (0.00091)	Tok/s 52420 (59267)	Loss/tok 3.4668 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6390/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00094)	Tok/s 52427 (59635)	Loss/tok 3.1188 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][6390/6832]	Time 0.095 (0.105)	Data 0.00096 (0.00096)	Tok/s 52402 (58808)	Loss/tok 3.0441 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][6390/6832]	Time 0.095 (0.105)	Data 0.00093 (0.00094)	Tok/s 52434 (60083)	Loss/tok 3.0878 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][6400/6832]	Time 0.113 (0.105)	Data 0.00095 (0.00091)	Tok/s 53287 (59270)	Loss/tok 3.2250 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6400/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00094)	Tok/s 53284 (59638)	Loss/tok 3.2668 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][6400/6832]	Time 0.113 (0.105)	Data 0.00094 (0.00096)	Tok/s 53274 (58812)	Loss/tok 3.3110 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][6400/6832]	Time 0.113 (0.105)	Data 0.00095 (0.00094)	Tok/s 53276 (60085)	Loss/tok 3.2975 (3.2118)	Learning Rate [7.8125e-05]
1: TRAIN [2][6410/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00091)	Tok/s 59207 (59274)	Loss/tok 3.2179 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6410/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00094)	Tok/s 59745 (59642)	Loss/tok 3.3130 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][6410/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00096)	Tok/s 58690 (58816)	Loss/tok 3.4022 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][6410/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00094)	Tok/s 59764 (60090)	Loss/tok 3.2508 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6420/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 70512 (59651)	Loss/tok 3.3229 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [2][6420/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00096)	Tok/s 70517 (58826)	Loss/tok 3.1810 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][6420/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 71252 (60099)	Loss/tok 3.2079 (3.2117)	Learning Rate [7.8125e-05]
1: TRAIN [2][6420/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00091)	Tok/s 70499 (59283)	Loss/tok 3.4282 (3.2119)	Learning Rate [7.8125e-05]
1: TRAIN [2][6430/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00091)	Tok/s 85232 (59292)	Loss/tok 3.0762 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][6430/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00096)	Tok/s 85020 (58834)	Loss/tok 3.1143 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6430/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 86005 (59660)	Loss/tok 2.9962 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6430/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00094)	Tok/s 86549 (60107)	Loss/tok 3.2658 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6440/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 88847 (59672)	Loss/tok 3.1921 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6440/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00091)	Tok/s 88186 (59304)	Loss/tok 3.1980 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [2][6440/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00096)	Tok/s 87393 (58847)	Loss/tok 3.1609 (3.2120)	Learning Rate [7.8125e-05]
3: TRAIN [2][6440/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 89743 (60119)	Loss/tok 3.1156 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6450/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00094)	Tok/s 54109 (59665)	Loss/tok 3.1388 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][6450/6832]	Time 0.083 (0.105)	Data 0.00098 (0.00091)	Tok/s 54091 (59298)	Loss/tok 2.9240 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6450/6832]	Time 0.083 (0.105)	Data 0.00100 (0.00096)	Tok/s 54093 (58841)	Loss/tok 3.0743 (3.2119)	Learning Rate [7.8125e-05]
3: TRAIN [2][6450/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00094)	Tok/s 54087 (60113)	Loss/tok 2.9705 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][6460/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00091)	Tok/s 52950 (59294)	Loss/tok 3.1827 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6460/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00096)	Tok/s 52955 (58837)	Loss/tok 3.2425 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6460/6832]	Time 0.106 (0.105)	Data 0.00101 (0.00094)	Tok/s 52983 (59662)	Loss/tok 3.2031 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6460/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00094)	Tok/s 54129 (60109)	Loss/tok 3.1944 (3.2116)	Learning Rate [7.8125e-05]
1: TRAIN [2][6470/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00091)	Tok/s 83242 (59302)	Loss/tok 3.1785 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6470/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00096)	Tok/s 82728 (58843)	Loss/tok 3.1631 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6470/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 83544 (59670)	Loss/tok 3.1535 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6470/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 84089 (60117)	Loss/tok 3.1260 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][6480/6832]	Time 0.130 (0.105)	Data 0.00112 (0.00091)	Tok/s 73960 (59311)	Loss/tok 3.3391 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][6480/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00096)	Tok/s 73570 (58853)	Loss/tok 3.2189 (3.2119)	Learning Rate [7.8125e-05]
2: TRAIN [2][6480/6832]	Time 0.130 (0.105)	Data 0.00102 (0.00094)	Tok/s 73867 (59679)	Loss/tok 3.4544 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][6480/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 74344 (60126)	Loss/tok 3.3004 (3.2115)	Learning Rate [7.8125e-05]
2: TRAIN [2][6490/6832]	Time 0.107 (0.105)	Data 0.00098 (0.00094)	Tok/s 50385 (59681)	Loss/tok 3.1450 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6490/6832]	Time 0.107 (0.105)	Data 0.00094 (0.00091)	Tok/s 50180 (59312)	Loss/tok 2.9383 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6490/6832]	Time 0.107 (0.105)	Data 0.00093 (0.00096)	Tok/s 50171 (58854)	Loss/tok 3.2615 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6490/6832]	Time 0.107 (0.105)	Data 0.00096 (0.00094)	Tok/s 51423 (60128)	Loss/tok 3.3170 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][6500/6832]	Time 0.099 (0.105)	Data 0.00096 (0.00091)	Tok/s 53595 (59308)	Loss/tok 3.2622 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6500/6832]	Time 0.099 (0.105)	Data 0.00102 (0.00094)	Tok/s 54479 (59676)	Loss/tok 3.0598 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][6500/6832]	Time 0.099 (0.105)	Data 0.00095 (0.00096)	Tok/s 53136 (58850)	Loss/tok 3.0867 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6500/6832]	Time 0.099 (0.105)	Data 0.00102 (0.00094)	Tok/s 54487 (60122)	Loss/tok 3.1227 (3.2114)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][6510/6832]	Time 0.082 (0.105)	Data 0.00097 (0.00094)	Tok/s 54812 (59673)	Loss/tok 2.9886 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][6510/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00091)	Tok/s 54812 (59305)	Loss/tok 2.9941 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6510/6832]	Time 0.082 (0.105)	Data 0.00095 (0.00096)	Tok/s 54829 (58847)	Loss/tok 3.1137 (3.2117)	Learning Rate [7.8125e-05]
3: TRAIN [2][6510/6832]	Time 0.082 (0.105)	Data 0.00100 (0.00094)	Tok/s 54825 (60119)	Loss/tok 2.8828 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][6520/6832]	Time 0.080 (0.105)	Data 0.00101 (0.00091)	Tok/s 52831 (59307)	Loss/tok 3.1050 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6520/6832]	Time 0.080 (0.105)	Data 0.00099 (0.00094)	Tok/s 52824 (59674)	Loss/tok 3.0761 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][6520/6832]	Time 0.080 (0.105)	Data 0.00100 (0.00096)	Tok/s 51268 (58849)	Loss/tok 3.0839 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6520/6832]	Time 0.080 (0.105)	Data 0.00104 (0.00094)	Tok/s 52821 (60121)	Loss/tok 3.0834 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][6530/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00091)	Tok/s 51950 (59310)	Loss/tok 3.0937 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6530/6832]	Time 0.084 (0.105)	Data 0.00095 (0.00096)	Tok/s 51939 (58853)	Loss/tok 3.1324 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6530/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00094)	Tok/s 51928 (59678)	Loss/tok 3.1522 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][6530/6832]	Time 0.084 (0.105)	Data 0.00094 (0.00094)	Tok/s 52262 (60124)	Loss/tok 2.8575 (3.2112)	Learning Rate [7.8125e-05]
2: TRAIN [2][6540/6832]	Time 0.095 (0.105)	Data 0.00097 (0.00094)	Tok/s 52743 (59680)	Loss/tok 3.3954 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][6540/6832]	Time 0.095 (0.105)	Data 0.00094 (0.00091)	Tok/s 52670 (59313)	Loss/tok 3.0448 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [2][6540/6832]	Time 0.095 (0.105)	Data 0.00092 (0.00096)	Tok/s 52653 (58856)	Loss/tok 3.2052 (3.2118)	Learning Rate [7.8125e-05]
3: TRAIN [2][6540/6832]	Time 0.095 (0.105)	Data 0.00095 (0.00094)	Tok/s 52718 (60127)	Loss/tok 3.3372 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][6550/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00091)	Tok/s 70238 (59310)	Loss/tok 3.2785 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6550/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 70226 (58853)	Loss/tok 3.3514 (3.2118)	Learning Rate [7.8125e-05]
2: TRAIN [2][6550/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 70230 (59677)	Loss/tok 3.4005 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6550/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 71086 (60124)	Loss/tok 3.3728 (3.2112)	Learning Rate [7.8125e-05]
1: TRAIN [2][6560/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00091)	Tok/s 67724 (59302)	Loss/tok 3.3911 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6560/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00096)	Tok/s 67710 (58844)	Loss/tok 3.4289 (3.2117)	Learning Rate [7.8125e-05]
2: TRAIN [2][6560/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 67700 (59671)	Loss/tok 3.1639 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6560/6832]	Time 0.131 (0.105)	Data 0.00083 (0.00094)	Tok/s 68639 (60118)	Loss/tok 3.3187 (3.2111)	Learning Rate [7.8125e-05]
2: TRAIN [2][6570/6832]	Time 0.100 (0.105)	Data 0.00100 (0.00094)	Tok/s 56336 (59665)	Loss/tok 3.0200 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][6570/6832]	Time 0.100 (0.105)	Data 0.00095 (0.00091)	Tok/s 55316 (59297)	Loss/tok 2.9797 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][6570/6832]	Time 0.100 (0.105)	Data 0.00095 (0.00095)	Tok/s 55044 (58839)	Loss/tok 2.9938 (3.2116)	Learning Rate [7.8125e-05]
3: TRAIN [2][6570/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00094)	Tok/s 56344 (60112)	Loss/tok 2.9234 (3.2110)	Learning Rate [7.8125e-05]
2: TRAIN [2][6580/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00094)	Tok/s 92560 (59665)	Loss/tok 3.0235 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][6580/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00091)	Tok/s 91374 (59296)	Loss/tok 3.1067 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][6580/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00094)	Tok/s 94429 (60112)	Loss/tok 3.1217 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6580/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 90367 (58838)	Loss/tok 3.1028 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][6590/6832]	Time 0.090 (0.105)	Data 0.00100 (0.00094)	Tok/s 52456 (59660)	Loss/tok 3.1495 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][6590/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00091)	Tok/s 52418 (59291)	Loss/tok 3.2192 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][6590/6832]	Time 0.090 (0.105)	Data 0.00088 (0.00094)	Tok/s 52479 (60107)	Loss/tok 3.0823 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6590/6832]	Time 0.090 (0.105)	Data 0.00095 (0.00095)	Tok/s 52443 (58833)	Loss/tok 3.2350 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][6600/6832]	Time 0.059 (0.105)	Data 0.00091 (0.00094)	Tok/s 52712 (59662)	Loss/tok 2.8100 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6600/6832]	Time 0.059 (0.105)	Data 0.00084 (0.00094)	Tok/s 53999 (60108)	Loss/tok 2.8617 (3.2109)	Learning Rate [7.8125e-05]
1: TRAIN [2][6600/6832]	Time 0.059 (0.105)	Data 0.00090 (0.00091)	Tok/s 51765 (59293)	Loss/tok 2.8062 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][6600/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00095)	Tok/s 51796 (58836)	Loss/tok 2.9099 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][6610/6832]	Time 0.056 (0.105)	Data 0.00091 (0.00094)	Tok/s 49999 (59670)	Loss/tok 2.6552 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][6610/6832]	Time 0.056 (0.105)	Data 0.00094 (0.00091)	Tok/s 50017 (59302)	Loss/tok 2.7576 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][6610/6832]	Time 0.056 (0.105)	Data 0.00082 (0.00094)	Tok/s 51053 (60117)	Loss/tok 2.6504 (3.2108)	Learning Rate [7.8125e-05]
0: TRAIN [2][6610/6832]	Time 0.056 (0.105)	Data 0.00093 (0.00095)	Tok/s 48664 (58844)	Loss/tok 2.5827 (3.2116)	Learning Rate [7.8125e-05]
2: TRAIN [2][6620/6832]	Time 0.064 (0.105)	Data 0.00098 (0.00094)	Tok/s 49721 (59662)	Loss/tok 3.0002 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][6620/6832]	Time 0.064 (0.105)	Data 0.00095 (0.00091)	Tok/s 47927 (59293)	Loss/tok 2.8042 (3.2112)	Learning Rate [7.8125e-05]
0: TRAIN [2][6620/6832]	Time 0.064 (0.105)	Data 0.00097 (0.00095)	Tok/s 47943 (58836)	Loss/tok 2.9349 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][6620/6832]	Time 0.064 (0.105)	Data 0.00084 (0.00094)	Tok/s 49935 (60109)	Loss/tok 2.7233 (3.2106)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [2][6630/6832]	Time 0.081 (0.105)	Data 0.00119 (0.00094)	Tok/s 51944 (59660)	Loss/tok 3.0658 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][6630/6832]	Time 0.081 (0.105)	Data 0.00096 (0.00091)	Tok/s 51301 (59291)	Loss/tok 2.9099 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][6630/6832]	Time 0.081 (0.105)	Data 0.00095 (0.00095)	Tok/s 50412 (58831)	Loss/tok 3.0935 (3.2115)	Learning Rate [7.8125e-05]
3: TRAIN [2][6630/6832]	Time 0.081 (0.105)	Data 0.00108 (0.00094)	Tok/s 51980 (60108)	Loss/tok 3.1011 (3.2105)	Learning Rate [7.8125e-05]
2: TRAIN [2][6640/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 60606 (59649)	Loss/tok 3.3180 (3.2105)	Learning Rate [7.8125e-05]
1: TRAIN [2][6640/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00091)	Tok/s 60578 (59278)	Loss/tok 3.2734 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][6640/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 60609 (60097)	Loss/tok 3.3647 (3.2104)	Learning Rate [7.8125e-05]
0: TRAIN [2][6640/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 59665 (58818)	Loss/tok 3.2916 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][6650/6832]	Time 0.112 (0.105)	Data 0.00094 (0.00094)	Tok/s 53760 (59645)	Loss/tok 3.2129 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][6650/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00095)	Tok/s 53747 (58815)	Loss/tok 3.1933 (3.2114)	Learning Rate [7.8125e-05]
1: TRAIN [2][6650/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00091)	Tok/s 53744 (59275)	Loss/tok 3.2961 (3.2111)	Learning Rate [7.8125e-05]
3: TRAIN [2][6650/6832]	Time 0.112 (0.105)	Data 0.00084 (0.00094)	Tok/s 53755 (60093)	Loss/tok 3.3128 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][6660/6832]	Time 0.117 (0.105)	Data 0.00099 (0.00091)	Tok/s 57562 (59271)	Loss/tok 3.3205 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][6660/6832]	Time 0.117 (0.105)	Data 0.00105 (0.00095)	Tok/s 56983 (58811)	Loss/tok 3.2377 (3.2114)	Learning Rate [7.8125e-05]
2: TRAIN [2][6660/6832]	Time 0.117 (0.105)	Data 0.00114 (0.00094)	Tok/s 58058 (59641)	Loss/tok 3.2285 (3.2105)	Learning Rate [7.8125e-05]
3: TRAIN [2][6660/6832]	Time 0.117 (0.105)	Data 0.00110 (0.00094)	Tok/s 58041 (60089)	Loss/tok 3.3097 (3.2104)	Learning Rate [7.8125e-05]
2: TRAIN [2][6670/6832]	Time 0.059 (0.105)	Data 0.00099 (0.00094)	Tok/s 50099 (59636)	Loss/tok 2.8604 (3.2105)	Learning Rate [7.8125e-05]
1: TRAIN [2][6670/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00091)	Tok/s 50102 (59266)	Loss/tok 2.7880 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6670/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00095)	Tok/s 50073 (58806)	Loss/tok 2.7612 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][6670/6832]	Time 0.059 (0.105)	Data 0.00094 (0.00094)	Tok/s 51704 (60084)	Loss/tok 2.9600 (3.2103)	Learning Rate [7.8125e-05]
2: TRAIN [2][6680/6832]	Time 0.095 (0.105)	Data 0.00093 (0.00094)	Tok/s 52591 (59639)	Loss/tok 3.1267 (3.2105)	Learning Rate [7.8125e-05]
1: TRAIN [2][6680/6832]	Time 0.095 (0.105)	Data 0.00107 (0.00091)	Tok/s 52600 (59270)	Loss/tok 3.2757 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][6680/6832]	Time 0.095 (0.105)	Data 0.00104 (0.00095)	Tok/s 52447 (58810)	Loss/tok 3.1747 (3.2114)	Learning Rate [7.8125e-05]
3: TRAIN [2][6680/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00094)	Tok/s 52585 (60087)	Loss/tok 3.0851 (3.2103)	Learning Rate [7.8125e-05]
2: TRAIN [2][6690/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00094)	Tok/s 53490 (59629)	Loss/tok 3.0901 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][6690/6832]	Time 0.084 (0.105)	Data 0.00093 (0.00091)	Tok/s 53485 (59259)	Loss/tok 3.2195 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6690/6832]	Time 0.084 (0.105)	Data 0.00092 (0.00095)	Tok/s 52519 (58799)	Loss/tok 3.0997 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][6690/6832]	Time 0.084 (0.105)	Data 0.00085 (0.00094)	Tok/s 53456 (60077)	Loss/tok 3.2239 (3.2101)	Learning Rate [7.8125e-05]
2: TRAIN [2][6700/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00094)	Tok/s 52151 (59630)	Loss/tok 3.0878 (3.2102)	Learning Rate [7.8125e-05]
1: TRAIN [2][6700/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00091)	Tok/s 52178 (59261)	Loss/tok 3.3517 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [2][6700/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00095)	Tok/s 52171 (58801)	Loss/tok 3.1106 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][6700/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00094)	Tok/s 52149 (60079)	Loss/tok 3.2916 (3.2100)	Learning Rate [7.8125e-05]
1: TRAIN [2][6710/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00091)	Tok/s 57886 (59257)	Loss/tok 3.3357 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6710/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00095)	Tok/s 57892 (58796)	Loss/tok 3.3008 (3.2111)	Learning Rate [7.8125e-05]
2: TRAIN [2][6710/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 57889 (59628)	Loss/tok 3.3765 (3.2103)	Learning Rate [7.8125e-05]
3: TRAIN [2][6710/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00094)	Tok/s 58844 (60077)	Loss/tok 3.2897 (3.2101)	Learning Rate [7.8125e-05]
2: TRAIN [2][6720/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00094)	Tok/s 88533 (59632)	Loss/tok 3.1517 (3.2104)	Learning Rate [7.8125e-05]
1: TRAIN [2][6720/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00091)	Tok/s 88045 (59262)	Loss/tok 3.0687 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6720/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00095)	Tok/s 87220 (58801)	Loss/tok 3.2373 (3.2112)	Learning Rate [7.8125e-05]
3: TRAIN [2][6720/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00094)	Tok/s 89416 (60081)	Loss/tok 3.1013 (3.2102)	Learning Rate [7.8125e-05]
2: TRAIN [2][6730/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00094)	Tok/s 51229 (59627)	Loss/tok 3.1003 (3.2103)	Learning Rate [7.8125e-05]
0: TRAIN [2][6730/6832]	Time 0.083 (0.105)	Data 0.00098 (0.00095)	Tok/s 51147 (58793)	Loss/tok 2.8658 (3.2111)	Learning Rate [7.8125e-05]
1: TRAIN [2][6730/6832]	Time 0.083 (0.105)	Data 0.00104 (0.00091)	Tok/s 51163 (59256)	Loss/tok 3.1294 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][6730/6832]	Time 0.082 (0.105)	Data 0.00094 (0.00094)	Tok/s 51424 (60077)	Loss/tok 3.1693 (3.2102)	Learning Rate [7.8125e-05]
2: TRAIN [2][6740/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00094)	Tok/s 52368 (59629)	Loss/tok 3.1291 (3.2104)	Learning Rate [7.8125e-05]
0: TRAIN [2][6740/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00095)	Tok/s 52076 (58796)	Loss/tok 3.2173 (3.2111)	Learning Rate [7.8125e-05]
1: TRAIN [2][6740/6832]	Time 0.091 (0.105)	Data 0.00097 (0.00091)	Tok/s 52058 (59258)	Loss/tok 3.1224 (3.2110)	Learning Rate [7.8125e-05]
3: TRAIN [2][6740/6832]	Time 0.091 (0.105)	Data 0.00092 (0.00094)	Tok/s 53457 (60079)	Loss/tok 3.2287 (3.2103)	Learning Rate [7.8125e-05]
2: TRAIN [2][6750/6832]	Time 0.057 (0.105)	Data 0.00089 (0.00094)	Tok/s 51721 (59627)	Loss/tok 2.7738 (3.2103)	Learning Rate [7.8125e-05]
0: TRAIN [2][6750/6832]	Time 0.057 (0.105)	Data 0.00092 (0.00095)	Tok/s 51299 (58795)	Loss/tok 2.9369 (3.2110)	Learning Rate [7.8125e-05]
1: TRAIN [2][6750/6832]	Time 0.057 (0.105)	Data 0.00095 (0.00091)	Tok/s 51267 (59257)	Loss/tok 2.8260 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][6750/6832]	Time 0.057 (0.105)	Data 0.00091 (0.00094)	Tok/s 53592 (60077)	Loss/tok 2.6590 (3.2102)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [2][6760/6832]	Time 0.073 (0.105)	Data 0.00107 (0.00094)	Tok/s 51119 (59624)	Loss/tok 2.9498 (3.2103)	Learning Rate [7.8125e-05]
1: TRAIN [2][6760/6832]	Time 0.073 (0.105)	Data 0.00099 (0.00091)	Tok/s 51118 (59254)	Loss/tok 3.0531 (3.2109)	Learning Rate [7.8125e-05]
3: TRAIN [2][6760/6832]	Time 0.073 (0.105)	Data 0.00102 (0.00094)	Tok/s 51197 (60074)	Loss/tok 2.9346 (3.2100)	Learning Rate [7.8125e-05]
0: TRAIN [2][6760/6832]	Time 0.073 (0.105)	Data 0.00098 (0.00095)	Tok/s 49058 (58791)	Loss/tok 3.0473 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [2][6770/6832]	Time 0.100 (0.105)	Data 0.00094 (0.00095)	Tok/s 51024 (58782)	Loss/tok 3.0995 (3.2108)	Learning Rate [7.8125e-05]
1: TRAIN [2][6770/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00091)	Tok/s 50993 (59245)	Loss/tok 3.1292 (3.2109)	Learning Rate [7.8125e-05]
2: TRAIN [2][6770/6832]	Time 0.100 (0.105)	Data 0.00113 (0.00094)	Tok/s 51930 (59615)	Loss/tok 3.1599 (3.2103)	Learning Rate [7.8125e-05]
3: TRAIN [2][6770/6832]	Time 0.100 (0.105)	Data 0.00087 (0.00094)	Tok/s 52277 (60064)	Loss/tok 3.0604 (3.2099)	Learning Rate [7.8125e-05]
1: TRAIN [2][6780/6832]	Time 0.121 (0.105)	Data 0.00096 (0.00091)	Tok/s 54014 (59238)	Loss/tok 3.2945 (3.2109)	Learning Rate [7.8125e-05]
2: TRAIN [2][6780/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00094)	Tok/s 54481 (59608)	Loss/tok 3.1323 (3.2102)	Learning Rate [7.8125e-05]
0: TRAIN [2][6780/6832]	Time 0.121 (0.105)	Data 0.00104 (0.00095)	Tok/s 53999 (58775)	Loss/tok 3.2709 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6780/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00094)	Tok/s 55003 (60057)	Loss/tok 3.1883 (3.2099)	Learning Rate [7.8125e-05]
2: TRAIN [2][6790/6832]	Time 0.086 (0.105)	Data 0.00097 (0.00094)	Tok/s 53708 (59612)	Loss/tok 3.2213 (3.2101)	Learning Rate [7.8125e-05]
0: TRAIN [2][6790/6832]	Time 0.086 (0.105)	Data 0.00100 (0.00095)	Tok/s 53620 (58779)	Loss/tok 2.9675 (3.2107)	Learning Rate [7.8125e-05]
1: TRAIN [2][6790/6832]	Time 0.086 (0.105)	Data 0.00099 (0.00091)	Tok/s 53624 (59241)	Loss/tok 3.0185 (3.2108)	Learning Rate [7.8125e-05]
3: TRAIN [2][6790/6832]	Time 0.086 (0.105)	Data 0.00099 (0.00094)	Tok/s 53714 (60061)	Loss/tok 3.0602 (3.2098)	Learning Rate [7.8125e-05]
2: TRAIN [2][6800/6832]	Time 0.084 (0.105)	Data 0.00102 (0.00094)	Tok/s 53374 (59605)	Loss/tok 3.2334 (3.2100)	Learning Rate [7.8125e-05]
1: TRAIN [2][6800/6832]	Time 0.084 (0.105)	Data 0.00103 (0.00091)	Tok/s 53396 (59233)	Loss/tok 3.0553 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][6800/6832]	Time 0.084 (0.105)	Data 0.00115 (0.00095)	Tok/s 51999 (58769)	Loss/tok 2.9912 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][6800/6832]	Time 0.084 (0.105)	Data 0.00110 (0.00094)	Tok/s 53369 (60054)	Loss/tok 3.0815 (3.2097)	Learning Rate [7.8125e-05]
2: TRAIN [2][6810/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00094)	Tok/s 91890 (59616)	Loss/tok 3.2512 (3.2099)	Learning Rate [7.8125e-05]
0: TRAIN [2][6810/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00095)	Tok/s 89581 (58780)	Loss/tok 3.1418 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][6810/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00091)	Tok/s 90617 (59244)	Loss/tok 3.0709 (3.2107)	Learning Rate [7.8125e-05]
3: TRAIN [2][6810/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00094)	Tok/s 93682 (60066)	Loss/tok 3.0385 (3.2096)	Learning Rate [7.8125e-05]
2: TRAIN [2][6820/6832]	Time 0.133 (0.105)	Data 0.00092 (0.00094)	Tok/s 83035 (59615)	Loss/tok 3.2511 (3.2100)	Learning Rate [7.8125e-05]
1: TRAIN [2][6820/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00091)	Tok/s 82853 (59244)	Loss/tok 3.2436 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][6820/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00095)	Tok/s 81905 (58780)	Loss/tok 3.2506 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][6820/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00094)	Tok/s 83832 (60065)	Loss/tok 3.2582 (3.2097)	Learning Rate [7.8125e-05]
2: Gradient norm: inf
1: Gradient norm: inf
0: Gradient norm: inf
3: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
2: TRAIN [2][6830/6832]	Time 0.047 (0.105)	Data 0.00087 (0.00094)	Tok/s 45305 (59612)	Loss/tok 2.3446 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][6830/6832]	Time 0.047 (0.105)	Data 0.00087 (0.00096)	Tok/s 40498 (58775)	Loss/tok 2.3209 (3.2106)	Learning Rate [7.8125e-05]
1: TRAIN [2][6830/6832]	Time 0.047 (0.105)	Data 0.00089 (0.00091)	Tok/s 42962 (59240)	Loss/tok 2.4867 (3.2106)	Learning Rate [7.8125e-05]
3: TRAIN [2][6830/6832]	Time 0.047 (0.105)	Data 0.00086 (0.00094)	Tok/s 46655 (60062)	Loss/tok 2.5281 (3.2095)	Learning Rate [7.8125e-05]
3: Running validation on dev set
1: Running validation on dev set
0: Running validation on dev set
2: Running validation on dev set
3: VALIDATION [2][0/20]	Time 0.035 (0.000)	Data 0.00212 (0.00000)	Tok/s 207525 (0)	Loss/tok 3.1917 (0.0000)	Learning Rate [7.8125e-05]
1: VALIDATION [2][0/20]	Time 0.040 (0.000)	Data 0.00210 (0.00000)	Tok/s 208898 (0)	Loss/tok 3.2949 (0.0000)	Learning Rate [7.8125e-05]
2: VALIDATION [2][0/20]	Time 0.042 (0.000)	Data 0.00213 (0.00000)	Tok/s 180655 (0)	Loss/tok 3.2898 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [2][0/20]	Time 0.065 (0.000)	Data 0.00212 (0.00000)	Tok/s 157546 (0)	Loss/tok 3.3863 (0.0000)	Learning Rate [7.8125e-05]
3: VALIDATION [2][10/20]	Time 0.015 (0.021)	Data 0.00175 (0.00191)	Tok/s 196398 (206284)	Loss/tok 3.0764 (3.1767)	Learning Rate [7.8125e-05]
1: VALIDATION [2][10/20]	Time 0.016 (0.022)	Data 0.00193 (0.00185)	Tok/s 198618 (206906)	Loss/tok 3.0662 (3.1845)	Learning Rate [7.8125e-05]
2: VALIDATION [2][10/20]	Time 0.015 (0.021)	Data 0.00168 (0.00184)	Tok/s 199125 (208778)	Loss/tok 2.9819 (3.1334)	Learning Rate [7.8125e-05]
0: VALIDATION [2][10/20]	Time 0.015 (0.022)	Data 0.00169 (0.00178)	Tok/s 204521 (210636)	Loss/tok 3.1252 (3.1420)	Learning Rate [7.8125e-05]
3: Running evaluation on test set
1: Running evaluation on test set
2: Running evaluation on test set
:::MLPv0.5.0 gnmt 1560384518.359483242 (train.py:459) eval_start: 2
0: Running evaluation on test set
1: TEST [2][0/6]	Time 1.161 (1.161)	Decoder iters 103.0 (103.0)	Tok/s 6565 (6565)
0: TEST [2][0/6]	Time 1.161 (1.161)	Decoder iters 68.0 (68.0)	Tok/s 6088 (6088)
3: TEST [2][0/6]	Time 1.161 (1.161)	Decoder iters 67.0 (67.0)	Tok/s 6605 (6605)
2: TEST [2][0/6]	Time 1.162 (1.162)	Decoder iters 149.0 (149.0)	Tok/s 6391 (6391)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
1: Finished evaluation on test set
2: Finished evaluation on test set
3: Finished evaluation on test set
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560384528.495575666 (train.py:464) eval_accuracy: {"epoch": 2, "value": 21.170000076293945}
:::MLPv0.5.0 gnmt 1560384528.496330738 (train.py:466) eval_target: 21.8
2: Summary: Epoch: 2	Training Loss 3.2101
3: Summary: Epoch: 2	Training Loss 3.2101
2: Performance: Epoch: 2	Training: 237684 Tok/s
3: Performance: Epoch: 2	Training: 237684 Tok/s
1: Summary: Epoch: 2	Training Loss 3.2101
2: Finished epoch 2
3: Finished epoch 2
2: Starting epoch 3
1: Performance: Epoch: 2	Training: 237684 Tok/s
3: Starting epoch 3
1: Finished epoch 2
1: Starting epoch 3
:::MLPv0.5.0 gnmt 1560384528.496960163 (train.py:467) eval_stop
0: Summary: Epoch: 2	Training Loss: 3.2101	Validation Loss: 3.1268	Test BLEU: 21.17
0: Performance: Epoch: 2	Training: 237684 Tok/s	Validation: 709774 Tok/s
0: Finished epoch 2
0: Starting epoch 3
:::MLPv0.5.0 gnmt 1560384528.497782230 (train.py:443) train_epoch: 3
3: Sampler for epoch 3 uses seed 913677063
2: Sampler for epoch 3 uses seed 913677063
1: Sampler for epoch 3 uses seed 913677063
:::MLPv0.5.0 gnmt 1560384528.761689425 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 3 uses seed 913677063
:::MLPv0.5.0 gnmt 1560384528.854102373 (seq2seq/data/sampler.py:66) input_shard: 40960
0: TRAIN [3][0/6832]	Time 1.485 (0.000)	Data 1.35259 (0.00000)	Tok/s 8024 (0)	Loss/tok 3.0419 (0.0000)	Learning Rate [7.8125e-05]
2: TRAIN [3][0/6832]	Time 1.485 (0.000)	Data 0.99449 (0.00000)	Tok/s 8224 (0)	Loss/tok 3.0186 (0.0000)	Learning Rate [7.8125e-05]
3: TRAIN [3][0/6832]	Time 1.485 (0.000)	Data 1.09499 (0.00000)	Tok/s 8403 (0)	Loss/tok 3.0553 (0.0000)	Learning Rate [7.8125e-05]
1: TRAIN [3][0/6832]	Time 1.485 (0.000)	Data 1.03668 (0.00000)	Tok/s 8116 (0)	Loss/tok 3.0715 (0.0000)	Learning Rate [7.8125e-05]
2: TRAIN [3][10/6832]	Time 0.130 (0.114)	Data 0.00101 (0.00101)	Tok/s 64208 (65704)	Loss/tok 3.3549 (3.1898)	Learning Rate [7.8125e-05]
3: TRAIN [3][10/6832]	Time 0.130 (0.114)	Data 0.00095 (0.00100)	Tok/s 64967 (66261)	Loss/tok 3.2070 (3.1473)	Learning Rate [7.8125e-05]
1: TRAIN [3][10/6832]	Time 0.130 (0.114)	Data 0.00102 (0.00106)	Tok/s 63958 (65283)	Loss/tok 3.4394 (3.2251)	Learning Rate [7.8125e-05]
0: TRAIN [3][10/6832]	Time 0.130 (0.114)	Data 0.00102 (0.00084)	Tok/s 63960 (64915)	Loss/tok 3.1893 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][20/6832]	Time 0.052 (0.104)	Data 0.00093 (0.00097)	Tok/s 47068 (61316)	Loss/tok 2.4301 (3.1838)	Learning Rate [7.8125e-05]
3: TRAIN [3][20/6832]	Time 0.052 (0.104)	Data 0.00091 (0.00096)	Tok/s 49054 (61981)	Loss/tok 2.5884 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [3][20/6832]	Time 0.052 (0.104)	Data 0.00100 (0.00090)	Tok/s 44558 (60498)	Loss/tok 2.4290 (3.1570)	Learning Rate [7.8125e-05]
1: TRAIN [3][20/6832]	Time 0.052 (0.104)	Data 0.00094 (0.00100)	Tok/s 46362 (60836)	Loss/tok 2.4787 (3.1749)	Learning Rate [7.8125e-05]
2: TRAIN [3][30/6832]	Time 0.118 (0.106)	Data 0.00089 (0.00095)	Tok/s 57713 (60603)	Loss/tok 3.1186 (3.1922)	Learning Rate [7.8125e-05]
3: TRAIN [3][30/6832]	Time 0.118 (0.106)	Data 0.00084 (0.00093)	Tok/s 58478 (61110)	Loss/tok 3.4067 (3.1816)	Learning Rate [7.8125e-05]
0: TRAIN [3][30/6832]	Time 0.118 (0.106)	Data 0.00096 (0.00092)	Tok/s 57720 (59890)	Loss/tok 3.3664 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][30/6832]	Time 0.118 (0.106)	Data 0.00098 (0.00099)	Tok/s 57709 (60253)	Loss/tok 3.1383 (3.1640)	Learning Rate [7.8125e-05]
2: TRAIN [3][40/6832]	Time 0.127 (0.107)	Data 0.00093 (0.00094)	Tok/s 59354 (60209)	Loss/tok 3.2832 (3.1850)	Learning Rate [7.8125e-05]
1: TRAIN [3][40/6832]	Time 0.127 (0.107)	Data 0.00088 (0.00097)	Tok/s 59313 (59915)	Loss/tok 3.2981 (3.1794)	Learning Rate [7.8125e-05]
3: TRAIN [3][40/6832]	Time 0.127 (0.107)	Data 0.00090 (0.00093)	Tok/s 59347 (60684)	Loss/tok 3.1969 (3.1791)	Learning Rate [7.8125e-05]
0: TRAIN [3][40/6832]	Time 0.127 (0.107)	Data 0.00097 (0.00094)	Tok/s 59288 (59569)	Loss/tok 3.2809 (3.1792)	Learning Rate [7.8125e-05]
2: TRAIN [3][50/6832]	Time 0.131 (0.108)	Data 0.00090 (0.00094)	Tok/s 80493 (61024)	Loss/tok 3.1501 (3.1810)	Learning Rate [7.8125e-05]
3: TRAIN [3][50/6832]	Time 0.131 (0.108)	Data 0.00092 (0.00093)	Tok/s 81134 (61502)	Loss/tok 3.0686 (3.1787)	Learning Rate [7.8125e-05]
1: TRAIN [3][50/6832]	Time 0.131 (0.108)	Data 0.00092 (0.00096)	Tok/s 80128 (60741)	Loss/tok 3.2249 (3.1844)	Learning Rate [7.8125e-05]
0: TRAIN [3][50/6832]	Time 0.131 (0.108)	Data 0.00099 (0.00095)	Tok/s 79991 (60416)	Loss/tok 3.3138 (3.1982)	Learning Rate [7.8125e-05]
2: TRAIN [3][60/6832]	Time 0.080 (0.107)	Data 0.00089 (0.00094)	Tok/s 54187 (60588)	Loss/tok 3.2063 (3.1813)	Learning Rate [7.8125e-05]
1: TRAIN [3][60/6832]	Time 0.080 (0.107)	Data 0.00090 (0.00095)	Tok/s 52878 (60191)	Loss/tok 2.8873 (3.1800)	Learning Rate [7.8125e-05]
0: TRAIN [3][60/6832]	Time 0.080 (0.107)	Data 0.00098 (0.00096)	Tok/s 52613 (59681)	Loss/tok 3.1229 (3.1907)	Learning Rate [7.8125e-05]
3: TRAIN [3][60/6832]	Time 0.080 (0.107)	Data 0.00088 (0.00093)	Tok/s 54118 (61067)	Loss/tok 2.9344 (3.1739)	Learning Rate [7.8125e-05]
2: TRAIN [3][70/6832]	Time 0.102 (0.106)	Data 0.00087 (0.00094)	Tok/s 52794 (60126)	Loss/tok 3.0564 (3.1772)	Learning Rate [7.8125e-05]
1: TRAIN [3][70/6832]	Time 0.102 (0.106)	Data 0.00090 (0.00095)	Tok/s 52797 (59758)	Loss/tok 3.1116 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][70/6832]	Time 0.102 (0.106)	Data 0.00086 (0.00093)	Tok/s 52807 (60575)	Loss/tok 3.2175 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][70/6832]	Time 0.102 (0.106)	Data 0.00101 (0.00096)	Tok/s 52812 (59300)	Loss/tok 3.1684 (3.1851)	Learning Rate [7.8125e-05]
2: TRAIN [3][80/6832]	Time 0.131 (0.107)	Data 0.00089 (0.00094)	Tok/s 82292 (60570)	Loss/tok 2.9939 (3.1762)	Learning Rate [7.8125e-05]
3: TRAIN [3][80/6832]	Time 0.131 (0.107)	Data 0.00086 (0.00093)	Tok/s 83146 (61053)	Loss/tok 3.2145 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][80/6832]	Time 0.131 (0.107)	Data 0.00098 (0.00094)	Tok/s 82092 (60167)	Loss/tok 3.1819 (3.1716)	Learning Rate [7.8125e-05]
0: TRAIN [3][80/6832]	Time 0.131 (0.107)	Data 0.00095 (0.00096)	Tok/s 81617 (59588)	Loss/tok 3.1326 (3.1784)	Learning Rate [7.8125e-05]
2: TRAIN [3][90/6832]	Time 0.082 (0.106)	Data 0.00095 (0.00094)	Tok/s 56260 (60154)	Loss/tok 3.0520 (3.1749)	Learning Rate [7.8125e-05]
3: TRAIN [3][90/6832]	Time 0.082 (0.106)	Data 0.00091 (0.00093)	Tok/s 56292 (60619)	Loss/tok 3.0081 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][90/6832]	Time 0.082 (0.106)	Data 0.00099 (0.00094)	Tok/s 54806 (59773)	Loss/tok 2.9278 (3.1741)	Learning Rate [7.8125e-05]
0: TRAIN [3][90/6832]	Time 0.082 (0.106)	Data 0.00104 (0.00096)	Tok/s 54715 (59230)	Loss/tok 3.2810 (3.1825)	Learning Rate [7.8125e-05]
2: TRAIN [3][100/6832]	Time 0.130 (0.106)	Data 0.00101 (0.00094)	Tok/s 67843 (59897)	Loss/tok 3.2033 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][100/6832]	Time 0.130 (0.106)	Data 0.00097 (0.00093)	Tok/s 68036 (60351)	Loss/tok 3.2407 (3.1748)	Learning Rate [7.8125e-05]
0: TRAIN [3][100/6832]	Time 0.130 (0.106)	Data 0.00110 (0.00097)	Tok/s 67923 (59019)	Loss/tok 3.2532 (3.1811)	Learning Rate [7.8125e-05]
1: TRAIN [3][100/6832]	Time 0.130 (0.106)	Data 0.00100 (0.00094)	Tok/s 67910 (59538)	Loss/tok 3.1273 (3.1703)	Learning Rate [7.8125e-05]
2: TRAIN [3][110/6832]	Time 0.096 (0.106)	Data 0.00090 (0.00094)	Tok/s 53111 (59740)	Loss/tok 3.1632 (3.1769)	Learning Rate [7.8125e-05]
3: TRAIN [3][110/6832]	Time 0.096 (0.106)	Data 0.00094 (0.00093)	Tok/s 53097 (60213)	Loss/tok 3.0325 (3.1740)	Learning Rate [7.8125e-05]
1: TRAIN [3][110/6832]	Time 0.096 (0.106)	Data 0.00096 (0.00094)	Tok/s 53098 (59401)	Loss/tok 3.1178 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][110/6832]	Time 0.096 (0.106)	Data 0.00094 (0.00097)	Tok/s 52703 (58894)	Loss/tok 3.1326 (3.1808)	Learning Rate [7.8125e-05]
2: TRAIN [3][120/6832]	Time 0.126 (0.107)	Data 0.00090 (0.00094)	Tok/s 64210 (59732)	Loss/tok 3.0686 (3.1803)	Learning Rate [7.8125e-05]
1: TRAIN [3][120/6832]	Time 0.126 (0.107)	Data 0.00089 (0.00094)	Tok/s 64249 (59404)	Loss/tok 3.4330 (3.1731)	Learning Rate [7.8125e-05]
0: TRAIN [3][120/6832]	Time 0.126 (0.107)	Data 0.00097 (0.00097)	Tok/s 64239 (58918)	Loss/tok 3.3118 (3.1794)	Learning Rate [7.8125e-05]
3: TRAIN [3][120/6832]	Time 0.126 (0.107)	Data 0.00085 (0.00093)	Tok/s 64444 (60187)	Loss/tok 3.2839 (3.1758)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][130/6832]	Time 0.132 (0.107)	Data 0.00092 (0.00094)	Tok/s 88540 (59967)	Loss/tok 3.0056 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][130/6832]	Time 0.132 (0.107)	Data 0.00091 (0.00094)	Tok/s 87975 (59634)	Loss/tok 3.0937 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][130/6832]	Time 0.132 (0.107)	Data 0.00093 (0.00097)	Tok/s 87164 (59170)	Loss/tok 3.0948 (3.1740)	Learning Rate [7.8125e-05]
3: TRAIN [3][130/6832]	Time 0.132 (0.107)	Data 0.00091 (0.00094)	Tok/s 89459 (60431)	Loss/tok 3.0507 (3.1743)	Learning Rate [7.8125e-05]
2: TRAIN [3][140/6832]	Time 0.071 (0.106)	Data 0.00102 (0.00094)	Tok/s 53744 (59900)	Loss/tok 2.7893 (3.1651)	Learning Rate [7.8125e-05]
3: TRAIN [3][140/6832]	Time 0.071 (0.106)	Data 0.00096 (0.00094)	Tok/s 53733 (60346)	Loss/tok 2.9222 (3.1710)	Learning Rate [7.8125e-05]
1: TRAIN [3][140/6832]	Time 0.072 (0.106)	Data 0.00091 (0.00094)	Tok/s 53698 (59553)	Loss/tok 2.9037 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][140/6832]	Time 0.072 (0.106)	Data 0.00097 (0.00097)	Tok/s 53174 (59095)	Loss/tok 3.0847 (3.1708)	Learning Rate [7.8125e-05]
2: TRAIN [3][150/6832]	Time 0.062 (0.106)	Data 0.00094 (0.00094)	Tok/s 51088 (59520)	Loss/tok 2.9181 (3.1643)	Learning Rate [7.8125e-05]
3: TRAIN [3][150/6832]	Time 0.062 (0.106)	Data 0.00091 (0.00094)	Tok/s 51408 (60006)	Loss/tok 2.8446 (3.1655)	Learning Rate [7.8125e-05]
1: TRAIN [3][150/6832]	Time 0.062 (0.106)	Data 0.00091 (0.00093)	Tok/s 49267 (59114)	Loss/tok 2.8671 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][150/6832]	Time 0.062 (0.106)	Data 0.00094 (0.00097)	Tok/s 49316 (58517)	Loss/tok 2.8624 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][160/6832]	Time 0.118 (0.106)	Data 0.00090 (0.00093)	Tok/s 58788 (59164)	Loss/tok 3.4409 (3.1695)	Learning Rate [7.8125e-05]
2: TRAIN [3][160/6832]	Time 0.118 (0.106)	Data 0.00092 (0.00094)	Tok/s 58981 (59569)	Loss/tok 3.2069 (3.1632)	Learning Rate [7.8125e-05]
0: TRAIN [3][160/6832]	Time 0.118 (0.106)	Data 0.00101 (0.00097)	Tok/s 58777 (58588)	Loss/tok 3.2175 (3.1667)	Learning Rate [7.8125e-05]
3: TRAIN [3][160/6832]	Time 0.118 (0.106)	Data 0.00090 (0.00095)	Tok/s 59848 (60037)	Loss/tok 3.2194 (3.1726)	Learning Rate [7.8125e-05]
2: TRAIN [3][170/6832]	Time 0.090 (0.106)	Data 0.00092 (0.00094)	Tok/s 52425 (59380)	Loss/tok 3.1328 (3.1635)	Learning Rate [7.8125e-05]
3: TRAIN [3][170/6832]	Time 0.090 (0.106)	Data 0.00092 (0.00095)	Tok/s 52440 (59851)	Loss/tok 3.1792 (3.1721)	Learning Rate [7.8125e-05]
1: TRAIN [3][170/6832]	Time 0.090 (0.106)	Data 0.00088 (0.00093)	Tok/s 52385 (58983)	Loss/tok 3.1482 (3.1707)	Learning Rate [7.8125e-05]
0: TRAIN [3][170/6832]	Time 0.090 (0.106)	Data 0.00096 (0.00097)	Tok/s 52373 (58436)	Loss/tok 3.1067 (3.1664)	Learning Rate [7.8125e-05]
2: TRAIN [3][180/6832]	Time 0.077 (0.105)	Data 0.00094 (0.00095)	Tok/s 51834 (59259)	Loss/tok 3.0385 (3.1605)	Learning Rate [7.8125e-05]
1: TRAIN [3][180/6832]	Time 0.077 (0.105)	Data 0.00085 (0.00093)	Tok/s 51817 (58842)	Loss/tok 2.9601 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][180/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00095)	Tok/s 51828 (59754)	Loss/tok 2.9575 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][180/6832]	Time 0.077 (0.105)	Data 0.00103 (0.00097)	Tok/s 51817 (58250)	Loss/tok 2.8071 (3.1651)	Learning Rate [7.8125e-05]
2: TRAIN [3][190/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00095)	Tok/s 61623 (59557)	Loss/tok 3.3700 (3.1615)	Learning Rate [7.8125e-05]
1: TRAIN [3][190/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00093)	Tok/s 61431 (59141)	Loss/tok 3.2965 (3.1663)	Learning Rate [7.8125e-05]
3: TRAIN [3][190/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00095)	Tok/s 62403 (60061)	Loss/tok 3.3577 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][190/6832]	Time 0.127 (0.105)	Data 0.00108 (0.00098)	Tok/s 61365 (58566)	Loss/tok 3.2723 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][200/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 68354 (59143)	Loss/tok 3.2718 (3.1695)	Learning Rate [7.8125e-05]
2: TRAIN [3][200/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 68308 (59540)	Loss/tok 3.1908 (3.1613)	Learning Rate [7.8125e-05]
3: TRAIN [3][200/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 68811 (60048)	Loss/tok 3.2683 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][200/6832]	Time 0.131 (0.105)	Data 0.00112 (0.00099)	Tok/s 68315 (58590)	Loss/tok 3.3400 (3.1698)	Learning Rate [7.8125e-05]
2: TRAIN [3][210/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00095)	Tok/s 55377 (59402)	Loss/tok 3.1035 (3.1597)	Learning Rate [7.8125e-05]
1: TRAIN [3][210/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00093)	Tok/s 55368 (59013)	Loss/tok 3.2182 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][210/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00095)	Tok/s 55769 (59903)	Loss/tok 3.3277 (3.1662)	Learning Rate [7.8125e-05]
0: TRAIN [3][210/6832]	Time 0.118 (0.105)	Data 0.00106 (0.00099)	Tok/s 55375 (58464)	Loss/tok 3.1172 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][220/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00095)	Tok/s 67026 (59347)	Loss/tok 3.1599 (3.1614)	Learning Rate [7.8125e-05]
3: TRAIN [3][220/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 67030 (59832)	Loss/tok 3.2580 (3.1657)	Learning Rate [7.8125e-05]
1: TRAIN [3][220/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00093)	Tok/s 66986 (58959)	Loss/tok 3.2515 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][220/6832]	Time 0.128 (0.105)	Data 0.00103 (0.00100)	Tok/s 66986 (58423)	Loss/tok 3.3205 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][230/6832]	Time 0.067 (0.105)	Data 0.00091 (0.00095)	Tok/s 51232 (59550)	Loss/tok 2.9130 (3.1589)	Learning Rate [7.8125e-05]
3: TRAIN [3][230/6832]	Time 0.067 (0.105)	Data 0.00090 (0.00095)	Tok/s 52118 (60043)	Loss/tok 2.8517 (3.1629)	Learning Rate [7.8125e-05]
1: TRAIN [3][230/6832]	Time 0.068 (0.105)	Data 0.00086 (0.00093)	Tok/s 51163 (59168)	Loss/tok 2.8481 (3.1653)	Learning Rate [7.8125e-05]
0: TRAIN [3][230/6832]	Time 0.067 (0.105)	Data 0.00107 (0.00100)	Tok/s 51220 (58632)	Loss/tok 2.9056 (3.1664)	Learning Rate [7.8125e-05]
2: TRAIN [3][240/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00095)	Tok/s 51304 (59764)	Loss/tok 2.7608 (3.1582)	Learning Rate [7.8125e-05]
1: TRAIN [3][240/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00093)	Tok/s 51287 (59394)	Loss/tok 2.7606 (3.1662)	Learning Rate [7.8125e-05]
3: TRAIN [3][240/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00095)	Tok/s 51612 (60248)	Loss/tok 2.8080 (3.1642)	Learning Rate [7.8125e-05]
0: TRAIN [3][240/6832]	Time 0.070 (0.105)	Data 0.00109 (0.00100)	Tok/s 51261 (58866)	Loss/tok 3.0791 (3.1692)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][250/6832]	Time 0.121 (0.105)	Data 0.00107 (0.00096)	Tok/s 62422 (59596)	Loss/tok 3.3570 (3.1579)	Learning Rate [7.8125e-05]
1: TRAIN [3][250/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00092)	Tok/s 62415 (59220)	Loss/tok 3.2764 (3.1639)	Learning Rate [7.8125e-05]
3: TRAIN [3][250/6832]	Time 0.121 (0.105)	Data 0.00096 (0.00094)	Tok/s 62460 (60091)	Loss/tok 2.9965 (3.1630)	Learning Rate [7.8125e-05]
0: TRAIN [3][250/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00100)	Tok/s 61644 (58657)	Loss/tok 3.2010 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][260/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00096)	Tok/s 51077 (59620)	Loss/tok 2.9697 (3.1584)	Learning Rate [7.8125e-05]
1: TRAIN [3][260/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00092)	Tok/s 50205 (59242)	Loss/tok 2.8575 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][260/6832]	Time 0.059 (0.105)	Data 0.00094 (0.00100)	Tok/s 50214 (58693)	Loss/tok 2.8473 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][260/6832]	Time 0.059 (0.105)	Data 0.00084 (0.00094)	Tok/s 52343 (60121)	Loss/tok 2.8807 (3.1650)	Learning Rate [7.8125e-05]
2: TRAIN [3][270/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00096)	Tok/s 53294 (59699)	Loss/tok 3.0917 (3.1597)	Learning Rate [7.8125e-05]
1: TRAIN [3][270/6832]	Time 0.089 (0.105)	Data 0.00091 (0.00092)	Tok/s 53345 (59327)	Loss/tok 3.2096 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][270/6832]	Time 0.089 (0.105)	Data 0.00091 (0.00100)	Tok/s 53341 (58783)	Loss/tok 3.0964 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][270/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00094)	Tok/s 53315 (60196)	Loss/tok 3.0408 (3.1648)	Learning Rate [7.8125e-05]
2: TRAIN [3][280/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00096)	Tok/s 73862 (59649)	Loss/tok 3.2702 (3.1606)	Learning Rate [7.8125e-05]
1: TRAIN [3][280/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00092)	Tok/s 73056 (59268)	Loss/tok 3.2845 (3.1708)	Learning Rate [7.8125e-05]
3: TRAIN [3][280/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 73840 (60140)	Loss/tok 3.1260 (3.1645)	Learning Rate [7.8125e-05]
0: TRAIN [3][280/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00100)	Tok/s 72845 (58733)	Loss/tok 3.2962 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][290/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00096)	Tok/s 52071 (59563)	Loss/tok 3.3208 (3.1618)	Learning Rate [7.8125e-05]
1: TRAIN [3][290/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00092)	Tok/s 52044 (59193)	Loss/tok 3.3067 (3.1711)	Learning Rate [7.8125e-05]
3: TRAIN [3][290/6832]	Time 0.121 (0.105)	Data 0.00105 (0.00095)	Tok/s 52117 (60050)	Loss/tok 3.1252 (3.1647)	Learning Rate [7.8125e-05]
0: TRAIN [3][290/6832]	Time 0.121 (0.105)	Data 0.00104 (0.00100)	Tok/s 51723 (58660)	Loss/tok 3.0688 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][300/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00096)	Tok/s 64172 (59562)	Loss/tok 3.3450 (3.1629)	Learning Rate [7.8125e-05]
1: TRAIN [3][300/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00092)	Tok/s 64173 (59191)	Loss/tok 3.2421 (3.1723)	Learning Rate [7.8125e-05]
0: TRAIN [3][300/6832]	Time 0.128 (0.105)	Data 0.00104 (0.00100)	Tok/s 64170 (58671)	Loss/tok 3.2094 (3.1700)	Learning Rate [7.8125e-05]
3: TRAIN [3][300/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00095)	Tok/s 64404 (60037)	Loss/tok 3.4036 (3.1650)	Learning Rate [7.8125e-05]
2: TRAIN [3][310/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00096)	Tok/s 53140 (59538)	Loss/tok 3.2606 (3.1644)	Learning Rate [7.8125e-05]
1: TRAIN [3][310/6832]	Time 0.106 (0.105)	Data 0.00093 (0.00093)	Tok/s 53179 (59177)	Loss/tok 3.1419 (3.1749)	Learning Rate [7.8125e-05]
3: TRAIN [3][310/6832]	Time 0.106 (0.105)	Data 0.00086 (0.00095)	Tok/s 53993 (60008)	Loss/tok 3.2312 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][310/6832]	Time 0.106 (0.105)	Data 0.00095 (0.00100)	Tok/s 53168 (58665)	Loss/tok 3.0321 (3.1711)	Learning Rate [7.8125e-05]
2: TRAIN [3][320/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00096)	Tok/s 54343 (59498)	Loss/tok 3.2983 (3.1656)	Learning Rate [7.8125e-05]
1: TRAIN [3][320/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00092)	Tok/s 53517 (59142)	Loss/tok 3.2063 (3.1758)	Learning Rate [7.8125e-05]
3: TRAIN [3][320/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00095)	Tok/s 54570 (59976)	Loss/tok 3.1141 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][320/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00100)	Tok/s 53491 (58641)	Loss/tok 3.2257 (3.1736)	Learning Rate [7.8125e-05]
2: TRAIN [3][330/6832]	Time 0.124 (0.105)	Data 0.00094 (0.00096)	Tok/s 63762 (59463)	Loss/tok 3.3181 (3.1668)	Learning Rate [7.8125e-05]
1: TRAIN [3][330/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00092)	Tok/s 62786 (59090)	Loss/tok 3.0991 (3.1767)	Learning Rate [7.8125e-05]
3: TRAIN [3][330/6832]	Time 0.124 (0.105)	Data 0.00100 (0.00095)	Tok/s 63818 (59950)	Loss/tok 3.2037 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][330/6832]	Time 0.124 (0.105)	Data 0.00101 (0.00100)	Tok/s 62784 (58568)	Loss/tok 3.3387 (3.1741)	Learning Rate [7.8125e-05]
1: TRAIN [3][340/6832]	Time 0.085 (0.105)	Data 0.00089 (0.00092)	Tok/s 53009 (59056)	Loss/tok 2.9710 (3.1763)	Learning Rate [7.8125e-05]
0: TRAIN [3][340/6832]	Time 0.085 (0.105)	Data 0.00095 (0.00100)	Tok/s 52976 (58537)	Loss/tok 2.9492 (3.1743)	Learning Rate [7.8125e-05]
2: TRAIN [3][340/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00096)	Tok/s 53088 (59425)	Loss/tok 3.0960 (3.1662)	Learning Rate [7.8125e-05]
3: TRAIN [3][340/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00094)	Tok/s 54446 (59913)	Loss/tok 3.1660 (3.1699)	Learning Rate [7.8125e-05]
2: TRAIN [3][350/6832]	Time 0.110 (0.105)	Data 0.00096 (0.00096)	Tok/s 51441 (59385)	Loss/tok 3.0884 (3.1682)	Learning Rate [7.8125e-05]
3: TRAIN [3][350/6832]	Time 0.110 (0.105)	Data 0.00098 (0.00094)	Tok/s 52399 (59873)	Loss/tok 3.2758 (3.1725)	Learning Rate [7.8125e-05]
1: TRAIN [3][350/6832]	Time 0.110 (0.105)	Data 0.00108 (0.00092)	Tok/s 51175 (59020)	Loss/tok 3.3017 (3.1781)	Learning Rate [7.8125e-05]
0: TRAIN [3][350/6832]	Time 0.110 (0.105)	Data 0.00093 (0.00100)	Tok/s 51216 (58511)	Loss/tok 3.2480 (3.1757)	Learning Rate [7.8125e-05]
2: TRAIN [3][360/6832]	Time 0.106 (0.105)	Data 0.00102 (0.00096)	Tok/s 53139 (59368)	Loss/tok 3.2500 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][360/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00092)	Tok/s 53058 (59008)	Loss/tok 3.1297 (3.1783)	Learning Rate [7.8125e-05]
0: TRAIN [3][360/6832]	Time 0.106 (0.105)	Data 0.00099 (0.00100)	Tok/s 53083 (58506)	Loss/tok 3.1436 (3.1764)	Learning Rate [7.8125e-05]
3: TRAIN [3][360/6832]	Time 0.106 (0.105)	Data 0.00100 (0.00094)	Tok/s 53744 (59848)	Loss/tok 3.1382 (3.1741)	Learning Rate [7.8125e-05]
2: TRAIN [3][370/6832]	Time 0.109 (0.105)	Data 0.00100 (0.00096)	Tok/s 53054 (59322)	Loss/tok 3.1759 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][370/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00092)	Tok/s 52982 (58966)	Loss/tok 3.2551 (3.1770)	Learning Rate [7.8125e-05]
0: TRAIN [3][370/6832]	Time 0.109 (0.105)	Data 0.00099 (0.00100)	Tok/s 53000 (58472)	Loss/tok 3.0710 (3.1746)	Learning Rate [7.8125e-05]
3: TRAIN [3][370/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00094)	Tok/s 53514 (59804)	Loss/tok 3.1992 (3.1732)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][380/6832]	Time 0.116 (0.105)	Data 0.00106 (0.00096)	Tok/s 53145 (59378)	Loss/tok 3.2405 (3.1665)	Learning Rate [7.8125e-05]
3: TRAIN [3][380/6832]	Time 0.116 (0.105)	Data 0.00104 (0.00095)	Tok/s 54110 (59864)	Loss/tok 3.2403 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][380/6832]	Time 0.116 (0.105)	Data 0.00113 (0.00093)	Tok/s 53148 (59026)	Loss/tok 3.1024 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [3][380/6832]	Time 0.116 (0.105)	Data 0.00118 (0.00100)	Tok/s 53152 (58537)	Loss/tok 3.4719 (3.1747)	Learning Rate [7.8125e-05]
2: TRAIN [3][390/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00096)	Tok/s 52375 (59239)	Loss/tok 3.0550 (3.1657)	Learning Rate [7.8125e-05]
1: TRAIN [3][390/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00093)	Tok/s 51658 (58883)	Loss/tok 3.1058 (3.1744)	Learning Rate [7.8125e-05]
3: TRAIN [3][390/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00095)	Tok/s 53008 (59717)	Loss/tok 3.2008 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][390/6832]	Time 0.104 (0.105)	Data 0.00103 (0.00100)	Tok/s 51681 (58400)	Loss/tok 3.1378 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][400/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00093)	Tok/s 55537 (58871)	Loss/tok 3.2003 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][400/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00096)	Tok/s 55506 (59232)	Loss/tok 3.1491 (3.1646)	Learning Rate [7.8125e-05]
0: TRAIN [3][400/6832]	Time 0.120 (0.105)	Data 0.00097 (0.00100)	Tok/s 55546 (58391)	Loss/tok 3.2465 (3.1736)	Learning Rate [7.8125e-05]
3: TRAIN [3][400/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00095)	Tok/s 55490 (59713)	Loss/tok 3.2027 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][410/6832]	Time 0.102 (0.105)	Data 0.00090 (0.00096)	Tok/s 52771 (59300)	Loss/tok 3.3233 (3.1651)	Learning Rate [7.8125e-05]
1: TRAIN [3][410/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00093)	Tok/s 51581 (58935)	Loss/tok 3.1115 (3.1731)	Learning Rate [7.8125e-05]
0: TRAIN [3][410/6832]	Time 0.102 (0.105)	Data 0.00095 (0.00100)	Tok/s 51627 (58460)	Loss/tok 2.8645 (3.1722)	Learning Rate [7.8125e-05]
3: TRAIN [3][410/6832]	Time 0.102 (0.105)	Data 0.00098 (0.00095)	Tok/s 52892 (59772)	Loss/tok 3.1681 (3.1709)	Learning Rate [7.8125e-05]
2: TRAIN [3][420/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00096)	Tok/s 53912 (59321)	Loss/tok 3.0870 (3.1630)	Learning Rate [7.8125e-05]
3: TRAIN [3][420/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00095)	Tok/s 53908 (59802)	Loss/tok 3.5119 (3.1702)	Learning Rate [7.8125e-05]
0: TRAIN [3][420/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00100)	Tok/s 53954 (58453)	Loss/tok 3.1400 (3.1702)	Learning Rate [7.8125e-05]
1: TRAIN [3][420/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00093)	Tok/s 53924 (58948)	Loss/tok 3.0894 (3.1712)	Learning Rate [7.8125e-05]
1: TRAIN [3][430/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00093)	Tok/s 61031 (58971)	Loss/tok 3.3027 (3.1704)	Learning Rate [7.8125e-05]
2: TRAIN [3][430/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00096)	Tok/s 61120 (59343)	Loss/tok 3.2761 (3.1646)	Learning Rate [7.8125e-05]
0: TRAIN [3][430/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00100)	Tok/s 60123 (58479)	Loss/tok 3.3326 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][430/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00095)	Tok/s 61131 (59820)	Loss/tok 3.2707 (3.1706)	Learning Rate [7.8125e-05]
2: TRAIN [3][440/6832]	Time 0.116 (0.105)	Data 0.00105 (0.00096)	Tok/s 50721 (59287)	Loss/tok 3.3100 (3.1649)	Learning Rate [7.8125e-05]
1: TRAIN [3][440/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00093)	Tok/s 50716 (58913)	Loss/tok 3.2610 (3.1706)	Learning Rate [7.8125e-05]
0: TRAIN [3][440/6832]	Time 0.116 (0.105)	Data 0.00100 (0.00100)	Tok/s 50761 (58429)	Loss/tok 3.2872 (3.1718)	Learning Rate [7.8125e-05]
3: TRAIN [3][440/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00095)	Tok/s 51305 (59763)	Loss/tok 3.1878 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][450/6832]	Time 0.079 (0.105)	Data 0.00091 (0.00096)	Tok/s 50109 (59210)	Loss/tok 2.9819 (3.1646)	Learning Rate [7.8125e-05]
1: TRAIN [3][450/6832]	Time 0.079 (0.105)	Data 0.00099 (0.00093)	Tok/s 50151 (58837)	Loss/tok 2.8316 (3.1704)	Learning Rate [7.8125e-05]
3: TRAIN [3][450/6832]	Time 0.079 (0.105)	Data 0.00093 (0.00095)	Tok/s 50553 (59681)	Loss/tok 3.0393 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][450/6832]	Time 0.079 (0.105)	Data 0.00101 (0.00100)	Tok/s 50091 (58360)	Loss/tok 2.9866 (3.1698)	Learning Rate [7.8125e-05]
2: TRAIN [3][460/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 83933 (59299)	Loss/tok 3.2783 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][460/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00093)	Tok/s 83282 (58933)	Loss/tok 3.3883 (3.1738)	Learning Rate [7.8125e-05]
0: TRAIN [3][460/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00100)	Tok/s 82831 (58461)	Loss/tok 2.9954 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][460/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 84328 (59764)	Loss/tok 3.1037 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][470/6832]	Time 0.085 (0.105)	Data 0.00087 (0.00096)	Tok/s 51368 (59202)	Loss/tok 2.9202 (3.1655)	Learning Rate [7.8125e-05]
0: TRAIN [3][470/6832]	Time 0.085 (0.105)	Data 0.00100 (0.00100)	Tok/s 51357 (58369)	Loss/tok 3.0219 (3.1706)	Learning Rate [7.8125e-05]
1: TRAIN [3][470/6832]	Time 0.085 (0.105)	Data 0.00088 (0.00093)	Tok/s 51372 (58839)	Loss/tok 3.1773 (3.1722)	Learning Rate [7.8125e-05]
3: TRAIN [3][470/6832]	Time 0.085 (0.105)	Data 0.00086 (0.00095)	Tok/s 51400 (59668)	Loss/tok 3.1027 (3.1707)	Learning Rate [7.8125e-05]
2: TRAIN [3][480/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00097)	Tok/s 47433 (59173)	Loss/tok 2.8823 (3.1654)	Learning Rate [7.8125e-05]
1: TRAIN [3][480/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00092)	Tok/s 47446 (58808)	Loss/tok 2.6387 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][480/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00095)	Tok/s 47464 (59639)	Loss/tok 2.7082 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][480/6832]	Time 0.059 (0.105)	Data 0.00096 (0.00100)	Tok/s 45498 (58335)	Loss/tok 2.7062 (3.1698)	Learning Rate [7.8125e-05]
2: TRAIN [3][490/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00097)	Tok/s 88202 (59313)	Loss/tok 3.1365 (3.1672)	Learning Rate [7.8125e-05]
1: TRAIN [3][490/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00092)	Tok/s 87661 (58945)	Loss/tok 3.0525 (3.1710)	Learning Rate [7.8125e-05]
3: TRAIN [3][490/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00095)	Tok/s 89193 (59778)	Loss/tok 3.1364 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][490/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00100)	Tok/s 86988 (58477)	Loss/tok 3.0882 (3.1712)	Learning Rate [7.8125e-05]
2: TRAIN [3][500/6832]	Time 0.088 (0.104)	Data 0.00094 (0.00097)	Tok/s 52501 (59276)	Loss/tok 3.1841 (3.1652)	Learning Rate [7.8125e-05]
1: TRAIN [3][500/6832]	Time 0.088 (0.104)	Data 0.00091 (0.00092)	Tok/s 52495 (58892)	Loss/tok 3.1674 (3.1702)	Learning Rate [7.8125e-05]
3: TRAIN [3][500/6832]	Time 0.088 (0.104)	Data 0.00090 (0.00095)	Tok/s 53056 (59755)	Loss/tok 3.1346 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][500/6832]	Time 0.088 (0.104)	Data 0.00099 (0.00100)	Tok/s 52531 (58403)	Loss/tok 2.9951 (3.1690)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][510/6832]	Time 0.114 (0.105)	Data 0.00096 (0.00097)	Tok/s 55154 (59295)	Loss/tok 3.1590 (3.1666)	Learning Rate [7.8125e-05]
1: TRAIN [3][510/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00092)	Tok/s 55207 (58912)	Loss/tok 3.2016 (3.1712)	Learning Rate [7.8125e-05]
3: TRAIN [3][510/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00095)	Tok/s 55199 (59775)	Loss/tok 3.0850 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][510/6832]	Time 0.114 (0.105)	Data 0.00098 (0.00099)	Tok/s 55174 (58426)	Loss/tok 3.2374 (3.1696)	Learning Rate [7.8125e-05]
2: TRAIN [3][520/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00097)	Tok/s 73896 (59276)	Loss/tok 3.1943 (3.1673)	Learning Rate [7.8125e-05]
1: TRAIN [3][520/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00092)	Tok/s 73608 (58893)	Loss/tok 3.1904 (3.1715)	Learning Rate [7.8125e-05]
3: TRAIN [3][520/6832]	Time 0.130 (0.105)	Data 0.00081 (0.00095)	Tok/s 73906 (59749)	Loss/tok 3.1920 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][520/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00099)	Tok/s 72949 (58406)	Loss/tok 3.3372 (3.1701)	Learning Rate [7.8125e-05]
2: TRAIN [3][530/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00097)	Tok/s 78398 (59248)	Loss/tok 3.1778 (3.1671)	Learning Rate [7.8125e-05]
1: TRAIN [3][530/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00092)	Tok/s 77501 (58869)	Loss/tok 3.2976 (3.1718)	Learning Rate [7.8125e-05]
3: TRAIN [3][530/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 78424 (59724)	Loss/tok 3.1933 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][530/6832]	Time 0.132 (0.105)	Data 0.00115 (0.00099)	Tok/s 77443 (58390)	Loss/tok 3.3343 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][540/6832]	Time 0.087 (0.104)	Data 0.00089 (0.00097)	Tok/s 53263 (59202)	Loss/tok 3.1696 (3.1668)	Learning Rate [7.8125e-05]
1: TRAIN [3][540/6832]	Time 0.087 (0.104)	Data 0.00086 (0.00092)	Tok/s 52995 (58823)	Loss/tok 3.0971 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][540/6832]	Time 0.086 (0.104)	Data 0.00083 (0.00094)	Tok/s 53282 (59677)	Loss/tok 2.8239 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][540/6832]	Time 0.087 (0.104)	Data 0.00099 (0.00099)	Tok/s 51729 (58346)	Loss/tok 3.1127 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][550/6832]	Time 0.042 (0.104)	Data 0.00086 (0.00092)	Tok/s 34155 (58763)	Loss/tok 2.0286 (3.1718)	Learning Rate [7.8125e-05]
2: TRAIN [3][550/6832]	Time 0.042 (0.104)	Data 0.00087 (0.00097)	Tok/s 39602 (59150)	Loss/tok 1.9058 (3.1668)	Learning Rate [7.8125e-05]
3: TRAIN [3][550/6832]	Time 0.042 (0.104)	Data 0.00083 (0.00094)	Tok/s 43998 (59631)	Loss/tok 2.2844 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][550/6832]	Time 0.042 (0.104)	Data 0.00099 (0.00100)	Tok/s 21836 (58270)	Loss/tok 1.7369 (3.1696)	Learning Rate [7.8125e-05]
2: TRAIN [3][560/6832]	Time 0.086 (0.105)	Data 0.00097 (0.00097)	Tok/s 53230 (59185)	Loss/tok 3.1994 (3.1671)	Learning Rate [7.8125e-05]
1: TRAIN [3][560/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00092)	Tok/s 52046 (58798)	Loss/tok 2.9963 (3.1724)	Learning Rate [7.8125e-05]
3: TRAIN [3][560/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00094)	Tok/s 53566 (59663)	Loss/tok 3.0066 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][560/6832]	Time 0.086 (0.105)	Data 0.00101 (0.00100)	Tok/s 52051 (58310)	Loss/tok 3.2613 (3.1703)	Learning Rate [7.8125e-05]
1: TRAIN [3][570/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00092)	Tok/s 60063 (58798)	Loss/tok 3.4088 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][570/6832]	Time 0.115 (0.105)	Data 0.00096 (0.00097)	Tok/s 60114 (59184)	Loss/tok 3.3803 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][570/6832]	Time 0.115 (0.105)	Data 0.00108 (0.00100)	Tok/s 60077 (58312)	Loss/tok 3.1124 (3.1700)	Learning Rate [7.8125e-05]
3: TRAIN [3][570/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00094)	Tok/s 60114 (59655)	Loss/tok 3.2676 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][580/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00092)	Tok/s 62683 (58804)	Loss/tok 3.3134 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][580/6832]	Time 0.125 (0.105)	Data 0.00092 (0.00097)	Tok/s 62887 (59191)	Loss/tok 3.1536 (3.1671)	Learning Rate [7.8125e-05]
0: TRAIN [3][580/6832]	Time 0.125 (0.105)	Data 0.00099 (0.00100)	Tok/s 62682 (58323)	Loss/tok 3.3504 (3.1710)	Learning Rate [7.8125e-05]
3: TRAIN [3][580/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00094)	Tok/s 63614 (59663)	Loss/tok 3.0742 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][590/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00097)	Tok/s 77868 (59209)	Loss/tok 3.1478 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][590/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00092)	Tok/s 77926 (58822)	Loss/tok 3.1821 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][590/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 78752 (59679)	Loss/tok 3.2689 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][590/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00100)	Tok/s 77304 (58345)	Loss/tok 3.2047 (3.1709)	Learning Rate [7.8125e-05]
1: TRAIN [3][600/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00092)	Tok/s 71661 (58785)	Loss/tok 3.2840 (3.1726)	Learning Rate [7.8125e-05]
2: TRAIN [3][600/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00097)	Tok/s 72624 (59172)	Loss/tok 3.2532 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][600/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 72642 (59641)	Loss/tok 3.4217 (3.1702)	Learning Rate [7.8125e-05]
0: TRAIN [3][600/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00100)	Tok/s 71654 (58310)	Loss/tok 3.3203 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][610/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00097)	Tok/s 62186 (59284)	Loss/tok 3.2487 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][610/6832]	Time 0.128 (0.105)	Data 0.00102 (0.00092)	Tok/s 62168 (58901)	Loss/tok 3.2321 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][610/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 62979 (59754)	Loss/tok 3.3537 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][610/6832]	Time 0.128 (0.105)	Data 0.00107 (0.00100)	Tok/s 62234 (58428)	Loss/tok 3.3381 (3.1722)	Learning Rate [7.8125e-05]
2: TRAIN [3][620/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00097)	Tok/s 86098 (59355)	Loss/tok 3.1661 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][620/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00092)	Tok/s 85468 (58975)	Loss/tok 3.0441 (3.1732)	Learning Rate [7.8125e-05]
0: TRAIN [3][620/6832]	Time 0.132 (0.105)	Data 0.00107 (0.00100)	Tok/s 84912 (58504)	Loss/tok 3.0725 (3.1721)	Learning Rate [7.8125e-05]
3: TRAIN [3][620/6832]	Time 0.132 (0.105)	Data 0.00122 (0.00094)	Tok/s 86679 (59824)	Loss/tok 3.0481 (3.1696)	Learning Rate [7.8125e-05]
1: TRAIN [3][630/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00092)	Tok/s 70399 (59067)	Loss/tok 3.2433 (3.1740)	Learning Rate [7.8125e-05]
0: TRAIN [3][630/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00100)	Tok/s 70362 (58601)	Loss/tok 3.4079 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][630/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00097)	Tok/s 70379 (59445)	Loss/tok 3.1696 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][630/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 71265 (59912)	Loss/tok 3.2623 (3.1700)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][640/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00097)	Tok/s 72015 (59499)	Loss/tok 3.3789 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][640/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00092)	Tok/s 71129 (59118)	Loss/tok 3.3579 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][640/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 72112 (59968)	Loss/tok 3.2172 (3.1707)	Learning Rate [7.8125e-05]
0: TRAIN [3][640/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00100)	Tok/s 71011 (58656)	Loss/tok 3.2816 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][650/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00092)	Tok/s 71712 (59107)	Loss/tok 3.1943 (3.1736)	Learning Rate [7.8125e-05]
2: TRAIN [3][650/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00097)	Tok/s 72598 (59487)	Loss/tok 3.3294 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][650/6832]	Time 0.128 (0.105)	Data 0.00102 (0.00100)	Tok/s 71742 (58649)	Loss/tok 3.1803 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][650/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 72690 (59953)	Loss/tok 3.3239 (3.1709)	Learning Rate [7.8125e-05]
1: TRAIN [3][660/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00091)	Tok/s 55075 (59151)	Loss/tok 2.8443 (3.1738)	Learning Rate [7.8125e-05]
2: TRAIN [3][660/6832]	Time 0.079 (0.105)	Data 0.00093 (0.00097)	Tok/s 55099 (59528)	Loss/tok 3.0992 (3.1707)	Learning Rate [7.8125e-05]
3: TRAIN [3][660/6832]	Time 0.079 (0.105)	Data 0.00091 (0.00094)	Tok/s 55768 (59992)	Loss/tok 3.2147 (3.1715)	Learning Rate [7.8125e-05]
0: TRAIN [3][660/6832]	Time 0.079 (0.105)	Data 0.00104 (0.00100)	Tok/s 55088 (58698)	Loss/tok 2.9178 (3.1736)	Learning Rate [7.8125e-05]
1: TRAIN [3][670/6832]	Time 0.103 (0.106)	Data 0.00086 (0.00091)	Tok/s 54315 (59225)	Loss/tok 3.1384 (3.1745)	Learning Rate [7.8125e-05]
2: TRAIN [3][670/6832]	Time 0.103 (0.106)	Data 0.00100 (0.00097)	Tok/s 54873 (59602)	Loss/tok 3.2101 (3.1715)	Learning Rate [7.8125e-05]
0: TRAIN [3][670/6832]	Time 0.103 (0.105)	Data 0.00096 (0.00100)	Tok/s 53601 (58769)	Loss/tok 3.1128 (3.1737)	Learning Rate [7.8125e-05]
3: TRAIN [3][670/6832]	Time 0.103 (0.105)	Data 0.00092 (0.00094)	Tok/s 54855 (60066)	Loss/tok 3.1225 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][680/6832]	Time 0.130 (0.106)	Data 0.00084 (0.00091)	Tok/s 73865 (59225)	Loss/tok 3.2610 (3.1751)	Learning Rate [7.8125e-05]
2: TRAIN [3][680/6832]	Time 0.130 (0.106)	Data 0.00094 (0.00097)	Tok/s 74006 (59602)	Loss/tok 3.2636 (3.1720)	Learning Rate [7.8125e-05]
0: TRAIN [3][680/6832]	Time 0.130 (0.106)	Data 0.00099 (0.00100)	Tok/s 73041 (58770)	Loss/tok 3.2417 (3.1745)	Learning Rate [7.8125e-05]
3: TRAIN [3][680/6832]	Time 0.130 (0.106)	Data 0.00089 (0.00094)	Tok/s 73998 (60063)	Loss/tok 3.1257 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][690/6832]	Time 0.089 (0.105)	Data 0.00084 (0.00091)	Tok/s 53204 (59180)	Loss/tok 3.1035 (3.1753)	Learning Rate [7.8125e-05]
3: TRAIN [3][690/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00094)	Tok/s 53232 (60012)	Loss/tok 3.2576 (3.1712)	Learning Rate [7.8125e-05]
0: TRAIN [3][690/6832]	Time 0.089 (0.105)	Data 0.00100 (0.00100)	Tok/s 53210 (58727)	Loss/tok 3.2745 (3.1752)	Learning Rate [7.8125e-05]
2: TRAIN [3][690/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00097)	Tok/s 53218 (59554)	Loss/tok 3.0830 (3.1723)	Learning Rate [7.8125e-05]
1: TRAIN [3][700/6832]	Time 0.071 (0.105)	Data 0.00085 (0.00091)	Tok/s 52523 (59193)	Loss/tok 2.8338 (3.1744)	Learning Rate [7.8125e-05]
2: TRAIN [3][700/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00097)	Tok/s 52608 (59568)	Loss/tok 2.9945 (3.1716)	Learning Rate [7.8125e-05]
3: TRAIN [3][700/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00094)	Tok/s 52648 (60024)	Loss/tok 3.0273 (3.1705)	Learning Rate [7.8125e-05]
0: TRAIN [3][700/6832]	Time 0.071 (0.105)	Data 0.00099 (0.00100)	Tok/s 52282 (58740)	Loss/tok 2.8366 (3.1752)	Learning Rate [7.8125e-05]
1: TRAIN [3][710/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00091)	Tok/s 51279 (59203)	Loss/tok 3.3220 (3.1750)	Learning Rate [7.8125e-05]
2: TRAIN [3][710/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00097)	Tok/s 51299 (59576)	Loss/tok 3.2155 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][710/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00094)	Tok/s 51318 (60030)	Loss/tok 3.1917 (3.1704)	Learning Rate [7.8125e-05]
0: TRAIN [3][710/6832]	Time 0.120 (0.105)	Data 0.00102 (0.00100)	Tok/s 50829 (58752)	Loss/tok 3.1548 (3.1747)	Learning Rate [7.8125e-05]
2: TRAIN [3][720/6832]	Time 0.087 (0.105)	Data 0.00094 (0.00097)	Tok/s 52792 (59567)	Loss/tok 3.1376 (3.1710)	Learning Rate [7.8125e-05]
1: TRAIN [3][720/6832]	Time 0.087 (0.105)	Data 0.00086 (0.00091)	Tok/s 51581 (59196)	Loss/tok 3.0412 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [3][720/6832]	Time 0.087 (0.105)	Data 0.00101 (0.00100)	Tok/s 51606 (58748)	Loss/tok 2.9272 (3.1749)	Learning Rate [7.8125e-05]
3: TRAIN [3][720/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00094)	Tok/s 53061 (60021)	Loss/tok 3.0822 (3.1708)	Learning Rate [7.8125e-05]
1: TRAIN [3][730/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00091)	Tok/s 55917 (59171)	Loss/tok 3.3339 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [3][730/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00100)	Tok/s 55919 (58727)	Loss/tok 3.2734 (3.1753)	Learning Rate [7.8125e-05]
2: TRAIN [3][730/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00097)	Tok/s 55889 (59543)	Loss/tok 3.0773 (3.1709)	Learning Rate [7.8125e-05]
3: TRAIN [3][730/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00094)	Tok/s 55909 (59997)	Loss/tok 3.2160 (3.1709)	Learning Rate [7.8125e-05]
1: TRAIN [3][740/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00091)	Tok/s 52576 (59147)	Loss/tok 3.2434 (3.1765)	Learning Rate [7.8125e-05]
3: TRAIN [3][740/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 53676 (59966)	Loss/tok 3.2310 (3.1713)	Learning Rate [7.8125e-05]
2: TRAIN [3][740/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00097)	Tok/s 53633 (59517)	Loss/tok 3.0246 (3.1717)	Learning Rate [7.8125e-05]
0: TRAIN [3][740/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00099)	Tok/s 52581 (58706)	Loss/tok 3.3136 (3.1748)	Learning Rate [7.8125e-05]
2: TRAIN [3][750/6832]	Time 0.080 (0.105)	Data 0.00093 (0.00097)	Tok/s 51261 (59525)	Loss/tok 2.9262 (3.1725)	Learning Rate [7.8125e-05]
1: TRAIN [3][750/6832]	Time 0.080 (0.105)	Data 0.00085 (0.00091)	Tok/s 51273 (59158)	Loss/tok 2.9247 (3.1758)	Learning Rate [7.8125e-05]
3: TRAIN [3][750/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00094)	Tok/s 51269 (59975)	Loss/tok 2.9554 (3.1714)	Learning Rate [7.8125e-05]
0: TRAIN [3][750/6832]	Time 0.080 (0.105)	Data 0.00110 (0.00100)	Tok/s 51270 (58719)	Loss/tok 2.9491 (3.1745)	Learning Rate [7.8125e-05]
1: TRAIN [3][760/6832]	Time 0.122 (0.106)	Data 0.00091 (0.00091)	Tok/s 58367 (59158)	Loss/tok 3.3358 (3.1763)	Learning Rate [7.8125e-05]
2: TRAIN [3][760/6832]	Time 0.122 (0.106)	Data 0.00088 (0.00097)	Tok/s 58725 (59528)	Loss/tok 3.2254 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][760/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00094)	Tok/s 58727 (59975)	Loss/tok 3.1584 (3.1726)	Learning Rate [7.8125e-05]
0: TRAIN [3][760/6832]	Time 0.121 (0.105)	Data 0.00113 (0.00100)	Tok/s 58295 (58721)	Loss/tok 3.1877 (3.1749)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][770/6832]	Time 0.099 (0.106)	Data 0.00090 (0.00091)	Tok/s 52785 (59154)	Loss/tok 3.1485 (3.1762)	Learning Rate [7.8125e-05]
2: TRAIN [3][770/6832]	Time 0.099 (0.106)	Data 0.00094 (0.00097)	Tok/s 52752 (59521)	Loss/tok 3.2210 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][770/6832]	Time 0.099 (0.106)	Data 0.00091 (0.00094)	Tok/s 52744 (59966)	Loss/tok 3.1271 (3.1724)	Learning Rate [7.8125e-05]
0: TRAIN [3][770/6832]	Time 0.099 (0.106)	Data 0.00113 (0.00100)	Tok/s 52776 (58716)	Loss/tok 3.2175 (3.1750)	Learning Rate [7.8125e-05]
1: TRAIN [3][780/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00091)	Tok/s 53721 (59085)	Loss/tok 3.0009 (3.1751)	Learning Rate [7.8125e-05]
2: TRAIN [3][780/6832]	Time 0.098 (0.105)	Data 0.00104 (0.00097)	Tok/s 53686 (59449)	Loss/tok 3.0715 (3.1724)	Learning Rate [7.8125e-05]
3: TRAIN [3][780/6832]	Time 0.098 (0.105)	Data 0.00098 (0.00094)	Tok/s 53693 (59891)	Loss/tok 3.0504 (3.1716)	Learning Rate [7.8125e-05]
0: TRAIN [3][780/6832]	Time 0.098 (0.105)	Data 0.00108 (0.00100)	Tok/s 53670 (58647)	Loss/tok 3.1140 (3.1741)	Learning Rate [7.8125e-05]
1: TRAIN [3][790/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00091)	Tok/s 85886 (59148)	Loss/tok 3.0816 (3.1743)	Learning Rate [7.8125e-05]
2: TRAIN [3][790/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00097)	Tok/s 86664 (59514)	Loss/tok 3.1089 (3.1717)	Learning Rate [7.8125e-05]
3: TRAIN [3][790/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 86978 (59957)	Loss/tok 2.9770 (3.1704)	Learning Rate [7.8125e-05]
0: TRAIN [3][790/6832]	Time 0.131 (0.105)	Data 0.00107 (0.00100)	Tok/s 85746 (58713)	Loss/tok 2.9716 (3.1735)	Learning Rate [7.8125e-05]
1: TRAIN [3][800/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00091)	Tok/s 52833 (59194)	Loss/tok 3.0763 (3.1742)	Learning Rate [7.8125e-05]
2: TRAIN [3][800/6832]	Time 0.085 (0.105)	Data 0.00098 (0.00097)	Tok/s 52800 (59558)	Loss/tok 3.0648 (3.1716)	Learning Rate [7.8125e-05]
3: TRAIN [3][800/6832]	Time 0.085 (0.105)	Data 0.00094 (0.00094)	Tok/s 52796 (60000)	Loss/tok 3.0691 (3.1704)	Learning Rate [7.8125e-05]
0: TRAIN [3][800/6832]	Time 0.085 (0.105)	Data 0.00113 (0.00100)	Tok/s 52780 (58760)	Loss/tok 3.1272 (3.1738)	Learning Rate [7.8125e-05]
1: TRAIN [3][810/6832]	Time 0.120 (0.105)	Data 0.00083 (0.00091)	Tok/s 61863 (59170)	Loss/tok 3.2054 (3.1741)	Learning Rate [7.8125e-05]
2: TRAIN [3][810/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00097)	Tok/s 61927 (59533)	Loss/tok 3.3056 (3.1713)	Learning Rate [7.8125e-05]
3: TRAIN [3][810/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00094)	Tok/s 61916 (59971)	Loss/tok 3.3483 (3.1705)	Learning Rate [7.8125e-05]
0: TRAIN [3][810/6832]	Time 0.120 (0.105)	Data 0.00110 (0.00100)	Tok/s 61873 (58738)	Loss/tok 3.4188 (3.1740)	Learning Rate [7.8125e-05]
1: TRAIN [3][820/6832]	Time 0.079 (0.105)	Data 0.00084 (0.00090)	Tok/s 52371 (59139)	Loss/tok 3.0175 (3.1738)	Learning Rate [7.8125e-05]
2: TRAIN [3][820/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00097)	Tok/s 53201 (59501)	Loss/tok 3.0450 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][820/6832]	Time 0.079 (0.105)	Data 0.00082 (0.00094)	Tok/s 53207 (59939)	Loss/tok 2.9598 (3.1707)	Learning Rate [7.8125e-05]
0: TRAIN [3][820/6832]	Time 0.079 (0.105)	Data 0.00109 (0.00100)	Tok/s 51595 (58710)	Loss/tok 2.9966 (3.1739)	Learning Rate [7.8125e-05]
1: TRAIN [3][830/6832]	Time 0.082 (0.105)	Data 0.00094 (0.00090)	Tok/s 55387 (59124)	Loss/tok 3.1201 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][830/6832]	Time 0.082 (0.105)	Data 0.00102 (0.00094)	Tok/s 56255 (59920)	Loss/tok 2.9673 (3.1711)	Learning Rate [7.8125e-05]
2: TRAIN [3][830/6832]	Time 0.082 (0.105)	Data 0.00107 (0.00097)	Tok/s 56243 (59485)	Loss/tok 3.0750 (3.1721)	Learning Rate [7.8125e-05]
0: TRAIN [3][830/6832]	Time 0.082 (0.105)	Data 0.00109 (0.00100)	Tok/s 54665 (58698)	Loss/tok 3.0123 (3.1735)	Learning Rate [7.8125e-05]
1: TRAIN [3][840/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00090)	Tok/s 61639 (59180)	Loss/tok 3.2028 (3.1736)	Learning Rate [7.8125e-05]
3: TRAIN [3][840/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00095)	Tok/s 62232 (59975)	Loss/tok 3.0589 (3.1705)	Learning Rate [7.8125e-05]
2: TRAIN [3][840/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00097)	Tok/s 61631 (59540)	Loss/tok 3.2405 (3.1723)	Learning Rate [7.8125e-05]
0: TRAIN [3][840/6832]	Time 0.121 (0.105)	Data 0.00116 (0.00100)	Tok/s 61582 (58754)	Loss/tok 3.1238 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][850/6832]	Time 0.076 (0.105)	Data 0.00090 (0.00090)	Tok/s 52290 (59182)	Loss/tok 3.1146 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][850/6832]	Time 0.076 (0.105)	Data 0.00094 (0.00095)	Tok/s 52424 (59985)	Loss/tok 3.0612 (3.1697)	Learning Rate [7.8125e-05]
2: TRAIN [3][850/6832]	Time 0.076 (0.105)	Data 0.00099 (0.00097)	Tok/s 52177 (59547)	Loss/tok 2.8759 (3.1719)	Learning Rate [7.8125e-05]
0: TRAIN [3][850/6832]	Time 0.076 (0.105)	Data 0.00112 (0.00100)	Tok/s 52279 (58744)	Loss/tok 2.8786 (3.1723)	Learning Rate [7.8125e-05]
1: TRAIN [3][860/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00090)	Tok/s 85484 (59234)	Loss/tok 3.0722 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][860/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 86544 (60038)	Loss/tok 3.2036 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][860/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00097)	Tok/s 86069 (59598)	Loss/tok 3.1270 (3.1717)	Learning Rate [7.8125e-05]
0: TRAIN [3][860/6832]	Time 0.132 (0.105)	Data 0.00110 (0.00100)	Tok/s 84920 (58799)	Loss/tok 3.1135 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][870/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00090)	Tok/s 52487 (59197)	Loss/tok 2.8998 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][870/6832]	Time 0.095 (0.105)	Data 0.00089 (0.00095)	Tok/s 52491 (59995)	Loss/tok 3.1023 (3.1695)	Learning Rate [7.8125e-05]
2: TRAIN [3][870/6832]	Time 0.095 (0.105)	Data 0.00094 (0.00097)	Tok/s 52483 (59559)	Loss/tok 3.0678 (3.1715)	Learning Rate [7.8125e-05]
0: TRAIN [3][870/6832]	Time 0.095 (0.105)	Data 0.00112 (0.00100)	Tok/s 52470 (58760)	Loss/tok 3.0884 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][880/6832]	Time 0.063 (0.105)	Data 0.00085 (0.00090)	Tok/s 46998 (59211)	Loss/tok 2.6330 (3.1723)	Learning Rate [7.8125e-05]
2: TRAIN [3][880/6832]	Time 0.063 (0.105)	Data 0.00090 (0.00097)	Tok/s 46932 (59571)	Loss/tok 2.7474 (3.1709)	Learning Rate [7.8125e-05]
3: TRAIN [3][880/6832]	Time 0.063 (0.105)	Data 0.00083 (0.00095)	Tok/s 48797 (60008)	Loss/tok 2.7694 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][880/6832]	Time 0.063 (0.105)	Data 0.00111 (0.00100)	Tok/s 47002 (58774)	Loss/tok 2.8697 (3.1722)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][890/6832]	Time 0.081 (0.105)	Data 0.00128 (0.00097)	Tok/s 52347 (59628)	Loss/tok 3.0249 (3.1712)	Learning Rate [7.8125e-05]
3: TRAIN [3][890/6832]	Time 0.081 (0.105)	Data 0.00127 (0.00095)	Tok/s 52346 (60064)	Loss/tok 2.9182 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][890/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00090)	Tok/s 52011 (59269)	Loss/tok 2.9307 (3.1730)	Learning Rate [7.8125e-05]
0: TRAIN [3][890/6832]	Time 0.081 (0.105)	Data 0.00119 (0.00101)	Tok/s 50710 (58833)	Loss/tok 3.1127 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][900/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00090)	Tok/s 91299 (59285)	Loss/tok 3.0025 (3.1725)	Learning Rate [7.8125e-05]
2: TRAIN [3][900/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00097)	Tok/s 92371 (59646)	Loss/tok 3.0219 (3.1702)	Learning Rate [7.8125e-05]
3: TRAIN [3][900/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 94259 (60082)	Loss/tok 2.9899 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][900/6832]	Time 0.132 (0.105)	Data 0.00114 (0.00101)	Tok/s 90172 (58848)	Loss/tok 3.0727 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][910/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00090)	Tok/s 73225 (59249)	Loss/tok 3.3163 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][910/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 73500 (60056)	Loss/tok 3.3764 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][910/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00097)	Tok/s 73466 (59615)	Loss/tok 3.4469 (3.1702)	Learning Rate [7.8125e-05]
0: TRAIN [3][910/6832]	Time 0.131 (0.105)	Data 0.00110 (0.00101)	Tok/s 72503 (58799)	Loss/tok 3.4541 (3.1728)	Learning Rate [7.8125e-05]
1: TRAIN [3][920/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00090)	Tok/s 87514 (59339)	Loss/tok 3.0722 (3.1722)	Learning Rate [7.8125e-05]
2: TRAIN [3][920/6832]	Time 0.133 (0.105)	Data 0.00096 (0.00097)	Tok/s 87976 (59708)	Loss/tok 3.1445 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][920/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00095)	Tok/s 88779 (60149)	Loss/tok 3.0059 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][920/6832]	Time 0.133 (0.105)	Data 0.00115 (0.00101)	Tok/s 86735 (58885)	Loss/tok 3.1525 (3.1722)	Learning Rate [7.8125e-05]
1: TRAIN [3][930/6832]	Time 0.069 (0.105)	Data 0.00087 (0.00090)	Tok/s 51578 (59297)	Loss/tok 2.8222 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][930/6832]	Time 0.069 (0.105)	Data 0.00085 (0.00095)	Tok/s 52429 (60106)	Loss/tok 2.8176 (3.1668)	Learning Rate [7.8125e-05]
2: TRAIN [3][930/6832]	Time 0.069 (0.105)	Data 0.00089 (0.00097)	Tok/s 51614 (59665)	Loss/tok 2.9452 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][930/6832]	Time 0.069 (0.105)	Data 0.00109 (0.00101)	Tok/s 51617 (58848)	Loss/tok 2.8573 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][940/6832]	Time 0.063 (0.105)	Data 0.00082 (0.00090)	Tok/s 46832 (59286)	Loss/tok 2.8308 (3.1713)	Learning Rate [7.8125e-05]
2: TRAIN [3][940/6832]	Time 0.063 (0.105)	Data 0.00088 (0.00097)	Tok/s 46821 (59652)	Loss/tok 2.7112 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][940/6832]	Time 0.063 (0.105)	Data 0.00082 (0.00095)	Tok/s 47256 (60093)	Loss/tok 2.8945 (3.1670)	Learning Rate [7.8125e-05]
0: TRAIN [3][940/6832]	Time 0.063 (0.105)	Data 0.00116 (0.00101)	Tok/s 46739 (58838)	Loss/tok 2.7455 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][950/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00090)	Tok/s 52650 (59280)	Loss/tok 3.2736 (3.1712)	Learning Rate [7.8125e-05]
2: TRAIN [3][950/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00097)	Tok/s 53282 (59644)	Loss/tok 3.1012 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][950/6832]	Time 0.101 (0.105)	Data 0.00083 (0.00095)	Tok/s 53275 (60087)	Loss/tok 3.0978 (3.1665)	Learning Rate [7.8125e-05]
0: TRAIN [3][950/6832]	Time 0.101 (0.105)	Data 0.00104 (0.00101)	Tok/s 51998 (58834)	Loss/tok 3.1487 (3.1711)	Learning Rate [7.8125e-05]
1: TRAIN [3][960/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00090)	Tok/s 53144 (59232)	Loss/tok 2.9136 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][960/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00095)	Tok/s 53777 (60037)	Loss/tok 3.0537 (3.1662)	Learning Rate [7.8125e-05]
2: TRAIN [3][960/6832]	Time 0.074 (0.105)	Data 0.00092 (0.00097)	Tok/s 53795 (59596)	Loss/tok 2.8941 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][960/6832]	Time 0.074 (0.105)	Data 0.00102 (0.00101)	Tok/s 52012 (58787)	Loss/tok 2.8951 (3.1707)	Learning Rate [7.8125e-05]
1: TRAIN [3][970/6832]	Time 0.090 (0.105)	Data 0.00085 (0.00090)	Tok/s 53806 (59195)	Loss/tok 3.1344 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][970/6832]	Time 0.090 (0.105)	Data 0.00084 (0.00095)	Tok/s 55270 (59998)	Loss/tok 3.2600 (3.1659)	Learning Rate [7.8125e-05]
2: TRAIN [3][970/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00097)	Tok/s 54668 (59558)	Loss/tok 2.9794 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][970/6832]	Time 0.090 (0.105)	Data 0.00107 (0.00101)	Tok/s 53812 (58748)	Loss/tok 3.1288 (3.1704)	Learning Rate [7.8125e-05]
1: TRAIN [3][980/6832]	Time 0.072 (0.105)	Data 0.00095 (0.00090)	Tok/s 52259 (59163)	Loss/tok 3.0063 (3.1708)	Learning Rate [7.8125e-05]
3: TRAIN [3][980/6832]	Time 0.072 (0.105)	Data 0.00092 (0.00095)	Tok/s 53066 (59972)	Loss/tok 3.0959 (3.1656)	Learning Rate [7.8125e-05]
2: TRAIN [3][980/6832]	Time 0.072 (0.105)	Data 0.00096 (0.00097)	Tok/s 53060 (59528)	Loss/tok 2.9764 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][980/6832]	Time 0.072 (0.105)	Data 0.00108 (0.00101)	Tok/s 51300 (58720)	Loss/tok 3.0147 (3.1699)	Learning Rate [7.8125e-05]
2: TRAIN [3][990/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00097)	Tok/s 51976 (59553)	Loss/tok 3.0215 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][990/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00095)	Tok/s 52839 (60003)	Loss/tok 3.0263 (3.1649)	Learning Rate [7.8125e-05]
1: TRAIN [3][990/6832]	Time 0.090 (0.105)	Data 0.00084 (0.00090)	Tok/s 51415 (59186)	Loss/tok 3.1558 (3.1698)	Learning Rate [7.8125e-05]
0: TRAIN [3][990/6832]	Time 0.090 (0.105)	Data 0.00122 (0.00101)	Tok/s 51370 (58742)	Loss/tok 2.9250 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][1000/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00090)	Tok/s 53471 (59209)	Loss/tok 3.0220 (3.1699)	Learning Rate [7.8125e-05]
2: TRAIN [3][1000/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00097)	Tok/s 53474 (59576)	Loss/tok 3.1298 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][1000/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00095)	Tok/s 53478 (60023)	Loss/tok 3.0073 (3.1659)	Learning Rate [7.8125e-05]
0: TRAIN [3][1000/6832]	Time 0.072 (0.105)	Data 0.00105 (0.00101)	Tok/s 51820 (58766)	Loss/tok 2.9700 (3.1702)	Learning Rate [7.8125e-05]
1: TRAIN [3][1010/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00090)	Tok/s 58768 (59226)	Loss/tok 3.4485 (3.1699)	Learning Rate [7.8125e-05]
2: TRAIN [3][1010/6832]	Time 0.121 (0.105)	Data 0.00096 (0.00097)	Tok/s 59220 (59594)	Loss/tok 3.2531 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][1010/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00095)	Tok/s 59210 (60040)	Loss/tok 3.2147 (3.1658)	Learning Rate [7.8125e-05]
0: TRAIN [3][1010/6832]	Time 0.121 (0.105)	Data 0.00100 (0.00101)	Tok/s 58179 (58784)	Loss/tok 3.3772 (3.1707)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][1020/6832]	Time 0.079 (0.105)	Data 0.00102 (0.00097)	Tok/s 51745 (59639)	Loss/tok 2.9005 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][1020/6832]	Time 0.079 (0.105)	Data 0.00089 (0.00095)	Tok/s 51745 (60085)	Loss/tok 2.9729 (3.1660)	Learning Rate [7.8125e-05]
1: TRAIN [3][1020/6832]	Time 0.079 (0.105)	Data 0.00086 (0.00090)	Tok/s 51710 (59272)	Loss/tok 2.9727 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][1020/6832]	Time 0.079 (0.105)	Data 0.00102 (0.00101)	Tok/s 51619 (58833)	Loss/tok 3.0295 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][1030/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00090)	Tok/s 70791 (59276)	Loss/tok 3.1951 (3.1700)	Learning Rate [7.8125e-05]
3: TRAIN [3][1030/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00095)	Tok/s 71769 (60087)	Loss/tok 3.3248 (3.1665)	Learning Rate [7.8125e-05]
2: TRAIN [3][1030/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00097)	Tok/s 71435 (59643)	Loss/tok 3.1511 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][1030/6832]	Time 0.128 (0.105)	Data 0.00100 (0.00101)	Tok/s 70776 (58839)	Loss/tok 3.2982 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][1040/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00090)	Tok/s 54078 (59296)	Loss/tok 3.3829 (3.1700)	Learning Rate [7.8125e-05]
2: TRAIN [3][1040/6832]	Time 0.118 (0.105)	Data 0.00100 (0.00097)	Tok/s 54100 (59664)	Loss/tok 3.1174 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][1040/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00095)	Tok/s 54089 (60107)	Loss/tok 3.0328 (3.1666)	Learning Rate [7.8125e-05]
0: TRAIN [3][1040/6832]	Time 0.119 (0.105)	Data 0.00099 (0.00101)	Tok/s 53997 (58858)	Loss/tok 3.0197 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][1050/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00090)	Tok/s 73315 (59313)	Loss/tok 3.2100 (3.1707)	Learning Rate [7.8125e-05]
2: TRAIN [3][1050/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00097)	Tok/s 73249 (59683)	Loss/tok 3.3068 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][1050/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 73270 (60124)	Loss/tok 3.2299 (3.1670)	Learning Rate [7.8125e-05]
0: TRAIN [3][1050/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00101)	Tok/s 72373 (58876)	Loss/tok 3.3130 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][1060/6832]	Time 0.078 (0.105)	Data 0.00084 (0.00090)	Tok/s 52811 (59266)	Loss/tok 2.9940 (3.1697)	Learning Rate [7.8125e-05]
2: TRAIN [3][1060/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00097)	Tok/s 52874 (59634)	Loss/tok 3.0354 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][1060/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00095)	Tok/s 52866 (60080)	Loss/tok 2.9182 (3.1663)	Learning Rate [7.8125e-05]
0: TRAIN [3][1060/6832]	Time 0.078 (0.105)	Data 0.00104 (0.00101)	Tok/s 52500 (58830)	Loss/tok 3.0084 (3.1708)	Learning Rate [7.8125e-05]
3: TRAIN [3][1070/6832]	Time 0.073 (0.105)	Data 0.00084 (0.00095)	Tok/s 50612 (60085)	Loss/tok 2.8794 (3.1662)	Learning Rate [7.8125e-05]
2: TRAIN [3][1070/6832]	Time 0.073 (0.105)	Data 0.00088 (0.00097)	Tok/s 50574 (59641)	Loss/tok 2.8815 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][1070/6832]	Time 0.073 (0.105)	Data 0.00083 (0.00090)	Tok/s 50555 (59274)	Loss/tok 2.9207 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][1070/6832]	Time 0.073 (0.105)	Data 0.00106 (0.00101)	Tok/s 50159 (58840)	Loss/tok 2.8366 (3.1708)	Learning Rate [7.8125e-05]
1: TRAIN [3][1080/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00090)	Tok/s 52109 (59280)	Loss/tok 2.8531 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][1080/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00095)	Tok/s 53510 (60091)	Loss/tok 3.0265 (3.1670)	Learning Rate [7.8125e-05]
2: TRAIN [3][1080/6832]	Time 0.076 (0.105)	Data 0.00093 (0.00097)	Tok/s 52154 (59646)	Loss/tok 3.1255 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][1080/6832]	Time 0.076 (0.105)	Data 0.00104 (0.00101)	Tok/s 52091 (58848)	Loss/tok 2.9065 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][1090/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00090)	Tok/s 60839 (59301)	Loss/tok 3.0617 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][1090/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00095)	Tok/s 61729 (60108)	Loss/tok 3.3724 (3.1672)	Learning Rate [7.8125e-05]
2: TRAIN [3][1090/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00097)	Tok/s 61728 (59665)	Loss/tok 3.2224 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][1090/6832]	Time 0.127 (0.105)	Data 0.00103 (0.00101)	Tok/s 60645 (58871)	Loss/tok 3.3111 (3.1724)	Learning Rate [7.8125e-05]
2: TRAIN [3][1100/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00097)	Tok/s 60474 (59725)	Loss/tok 3.4526 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][1100/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 61095 (60167)	Loss/tok 3.3335 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][1100/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00090)	Tok/s 60440 (59361)	Loss/tok 3.1570 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][1100/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00101)	Tok/s 60386 (58931)	Loss/tok 3.2881 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][1110/6832]	Time 0.113 (0.105)	Data 0.00083 (0.00090)	Tok/s 53020 (59349)	Loss/tok 3.1773 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][1110/6832]	Time 0.113 (0.105)	Data 0.00083 (0.00095)	Tok/s 53053 (60154)	Loss/tok 3.0672 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][1110/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00097)	Tok/s 53060 (59713)	Loss/tok 3.1360 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][1110/6832]	Time 0.113 (0.105)	Data 0.00108 (0.00101)	Tok/s 53007 (58923)	Loss/tok 3.3630 (3.1736)	Learning Rate [7.8125e-05]
1: TRAIN [3][1120/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00090)	Tok/s 68006 (59352)	Loss/tok 3.2709 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][1120/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00101)	Tok/s 67428 (58928)	Loss/tok 3.3430 (3.1744)	Learning Rate [7.8125e-05]
3: TRAIN [3][1120/6832]	Time 0.128 (0.105)	Data 0.00082 (0.00095)	Tok/s 67975 (60154)	Loss/tok 3.3181 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][1120/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00097)	Tok/s 67970 (59715)	Loss/tok 3.4428 (3.1703)	Learning Rate [7.8125e-05]
1: TRAIN [3][1130/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00090)	Tok/s 52376 (59318)	Loss/tok 3.1229 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][1130/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00097)	Tok/s 52347 (59681)	Loss/tok 3.2757 (3.1704)	Learning Rate [7.8125e-05]
0: TRAIN [3][1130/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00101)	Tok/s 52386 (58894)	Loss/tok 3.4029 (3.1747)	Learning Rate [7.8125e-05]
3: TRAIN [3][1130/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00095)	Tok/s 52534 (60117)	Loss/tok 3.2893 (3.1673)	Learning Rate [7.8125e-05]
1: TRAIN [3][1140/6832]	Time 0.104 (0.105)	Data 0.00087 (0.00090)	Tok/s 50909 (59354)	Loss/tok 3.2081 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][1140/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00101)	Tok/s 50287 (58930)	Loss/tok 3.0572 (3.1746)	Learning Rate [7.8125e-05]
3: TRAIN [3][1140/6832]	Time 0.104 (0.105)	Data 0.00087 (0.00095)	Tok/s 51461 (60152)	Loss/tok 3.2284 (3.1667)	Learning Rate [7.8125e-05]
2: TRAIN [3][1140/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00097)	Tok/s 51381 (59717)	Loss/tok 3.0397 (3.1704)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][1150/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00090)	Tok/s 58901 (59341)	Loss/tok 3.4723 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][1150/6832]	Time 0.121 (0.105)	Data 0.00096 (0.00101)	Tok/s 58150 (58919)	Loss/tok 3.2967 (3.1751)	Learning Rate [7.8125e-05]
2: TRAIN [3][1150/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00097)	Tok/s 59138 (59702)	Loss/tok 3.2357 (3.1712)	Learning Rate [7.8125e-05]
3: TRAIN [3][1150/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00095)	Tok/s 59197 (60133)	Loss/tok 3.1822 (3.1673)	Learning Rate [7.8125e-05]
1: TRAIN [3][1160/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00090)	Tok/s 75679 (59367)	Loss/tok 3.1916 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][1160/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00097)	Tok/s 76269 (59726)	Loss/tok 3.3384 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][1160/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00095)	Tok/s 76263 (60155)	Loss/tok 3.1862 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][1160/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00101)	Tok/s 75334 (58945)	Loss/tok 3.2730 (3.1756)	Learning Rate [7.8125e-05]
1: TRAIN [3][1170/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00090)	Tok/s 52045 (59375)	Loss/tok 3.3322 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][1170/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00097)	Tok/s 52744 (59734)	Loss/tok 3.1596 (3.1713)	Learning Rate [7.8125e-05]
0: TRAIN [3][1170/6832]	Time 0.103 (0.105)	Data 0.00092 (0.00101)	Tok/s 52044 (58954)	Loss/tok 3.1680 (3.1754)	Learning Rate [7.8125e-05]
3: TRAIN [3][1170/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00095)	Tok/s 53295 (60165)	Loss/tok 3.1541 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][1180/6832]	Time 0.068 (0.105)	Data 0.00098 (0.00097)	Tok/s 49300 (59760)	Loss/tok 2.9227 (3.1719)	Learning Rate [7.8125e-05]
1: TRAIN [3][1180/6832]	Time 0.068 (0.105)	Data 0.00089 (0.00090)	Tok/s 49233 (59402)	Loss/tok 2.9096 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][1180/6832]	Time 0.067 (0.105)	Data 0.00093 (0.00095)	Tok/s 50500 (60190)	Loss/tok 2.7887 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][1180/6832]	Time 0.068 (0.105)	Data 0.00097 (0.00101)	Tok/s 49250 (58984)	Loss/tok 3.0018 (3.1756)	Learning Rate [7.8125e-05]
1: TRAIN [3][1190/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00090)	Tok/s 63714 (59405)	Loss/tok 3.3940 (3.1700)	Learning Rate [7.8125e-05]
2: TRAIN [3][1190/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00097)	Tok/s 63712 (59761)	Loss/tok 3.3224 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][1190/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 63689 (60191)	Loss/tok 3.3565 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][1190/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00101)	Tok/s 63712 (58987)	Loss/tok 3.3541 (3.1763)	Learning Rate [7.8125e-05]
1: TRAIN [3][1200/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00090)	Tok/s 51385 (59419)	Loss/tok 3.1664 (3.1700)	Learning Rate [7.8125e-05]
2: TRAIN [3][1200/6832]	Time 0.100 (0.105)	Data 0.00100 (0.00097)	Tok/s 51555 (59773)	Loss/tok 3.2620 (3.1720)	Learning Rate [7.8125e-05]
0: TRAIN [3][1200/6832]	Time 0.100 (0.105)	Data 0.00098 (0.00100)	Tok/s 51407 (59001)	Loss/tok 3.0622 (3.1763)	Learning Rate [7.8125e-05]
3: TRAIN [3][1200/6832]	Time 0.100 (0.105)	Data 0.00096 (0.00095)	Tok/s 52679 (60204)	Loss/tok 3.2644 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][1210/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00090)	Tok/s 61252 (59421)	Loss/tok 3.3132 (3.1709)	Learning Rate [7.8125e-05]
0: TRAIN [3][1210/6832]	Time 0.127 (0.105)	Data 0.00096 (0.00100)	Tok/s 60406 (59005)	Loss/tok 3.2864 (3.1764)	Learning Rate [7.8125e-05]
2: TRAIN [3][1210/6832]	Time 0.127 (0.105)	Data 0.00100 (0.00097)	Tok/s 61293 (59775)	Loss/tok 3.4796 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][1210/6832]	Time 0.127 (0.105)	Data 0.00096 (0.00095)	Tok/s 61279 (60208)	Loss/tok 3.2566 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][1220/6832]	Time 0.086 (0.105)	Data 0.00086 (0.00090)	Tok/s 54954 (59415)	Loss/tok 3.1401 (3.1711)	Learning Rate [7.8125e-05]
2: TRAIN [3][1220/6832]	Time 0.086 (0.105)	Data 0.00097 (0.00097)	Tok/s 55008 (59767)	Loss/tok 3.0307 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][1220/6832]	Time 0.086 (0.105)	Data 0.00091 (0.00095)	Tok/s 55019 (60198)	Loss/tok 2.8927 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][1220/6832]	Time 0.086 (0.105)	Data 0.00097 (0.00100)	Tok/s 53799 (58999)	Loss/tok 3.0158 (3.1765)	Learning Rate [7.8125e-05]
1: TRAIN [3][1230/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00090)	Tok/s 52992 (59396)	Loss/tok 3.1010 (3.1702)	Learning Rate [7.8125e-05]
2: TRAIN [3][1230/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00097)	Tok/s 52983 (59749)	Loss/tok 3.1841 (3.1720)	Learning Rate [7.8125e-05]
3: TRAIN [3][1230/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00095)	Tok/s 53013 (60185)	Loss/tok 3.3039 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][1230/6832]	Time 0.109 (0.105)	Data 0.00098 (0.00100)	Tok/s 52757 (58976)	Loss/tok 3.1962 (3.1761)	Learning Rate [7.8125e-05]
2: TRAIN [3][1240/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00097)	Tok/s 67754 (59799)	Loss/tok 3.1923 (3.1723)	Learning Rate [7.8125e-05]
3: TRAIN [3][1240/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 67849 (60234)	Loss/tok 3.2699 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][1240/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00090)	Tok/s 67769 (59447)	Loss/tok 3.3269 (3.1707)	Learning Rate [7.8125e-05]
0: TRAIN [3][1240/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00100)	Tok/s 67795 (59029)	Loss/tok 3.2111 (3.1760)	Learning Rate [7.8125e-05]
1: TRAIN [3][1250/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00090)	Tok/s 51299 (59425)	Loss/tok 2.9079 (3.1704)	Learning Rate [7.8125e-05]
2: TRAIN [3][1250/6832]	Time 0.075 (0.105)	Data 0.00102 (0.00097)	Tok/s 51877 (59776)	Loss/tok 2.9898 (3.1721)	Learning Rate [7.8125e-05]
0: TRAIN [3][1250/6832]	Time 0.075 (0.105)	Data 0.00098 (0.00100)	Tok/s 51280 (59009)	Loss/tok 3.1057 (3.1756)	Learning Rate [7.8125e-05]
3: TRAIN [3][1250/6832]	Time 0.074 (0.105)	Data 0.00086 (0.00095)	Tok/s 53616 (60212)	Loss/tok 3.0154 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][1260/6832]	Time 0.116 (0.105)	Data 0.00113 (0.00097)	Tok/s 55032 (59734)	Loss/tok 3.0864 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][1260/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00090)	Tok/s 54999 (59384)	Loss/tok 3.1327 (3.1701)	Learning Rate [7.8125e-05]
3: TRAIN [3][1260/6832]	Time 0.116 (0.105)	Data 0.00101 (0.00095)	Tok/s 55024 (60171)	Loss/tok 3.1696 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][1260/6832]	Time 0.116 (0.105)	Data 0.00098 (0.00100)	Tok/s 54993 (58969)	Loss/tok 3.1762 (3.1755)	Learning Rate [7.8125e-05]
2: TRAIN [3][1270/6832]	Time 0.055 (0.105)	Data 0.00093 (0.00097)	Tok/s 49319 (59721)	Loss/tok 2.5763 (3.1710)	Learning Rate [7.8125e-05]
1: TRAIN [3][1270/6832]	Time 0.055 (0.105)	Data 0.00092 (0.00090)	Tok/s 49003 (59372)	Loss/tok 2.6155 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][1270/6832]	Time 0.054 (0.105)	Data 0.00091 (0.00095)	Tok/s 49406 (60158)	Loss/tok 2.4808 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][1270/6832]	Time 0.055 (0.105)	Data 0.00095 (0.00100)	Tok/s 46947 (58958)	Loss/tok 2.6055 (3.1751)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][1280/6832]	Time 0.059 (0.105)	Data 0.00094 (0.00097)	Tok/s 52159 (59716)	Loss/tok 2.6647 (3.1704)	Learning Rate [7.8125e-05]
1: TRAIN [3][1280/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00089)	Tok/s 52119 (59368)	Loss/tok 2.8990 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][1280/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00095)	Tok/s 54327 (60154)	Loss/tok 2.9662 (3.1671)	Learning Rate [7.8125e-05]
0: TRAIN [3][1280/6832]	Time 0.059 (0.105)	Data 0.00099 (0.00100)	Tok/s 52115 (58955)	Loss/tok 2.7274 (3.1749)	Learning Rate [7.8125e-05]
2: TRAIN [3][1290/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00097)	Tok/s 70511 (59694)	Loss/tok 3.3999 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][1290/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00089)	Tok/s 70447 (59348)	Loss/tok 3.1075 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][1290/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00095)	Tok/s 71431 (60134)	Loss/tok 3.1257 (3.1669)	Learning Rate [7.8125e-05]
0: TRAIN [3][1290/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00100)	Tok/s 70440 (58935)	Loss/tok 3.4894 (3.1748)	Learning Rate [7.8125e-05]
2: TRAIN [3][1300/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00097)	Tok/s 53445 (59670)	Loss/tok 3.1299 (3.1704)	Learning Rate [7.8125e-05]
3: TRAIN [3][1300/6832]	Time 0.089 (0.105)	Data 0.00085 (0.00094)	Tok/s 53471 (60112)	Loss/tok 2.9531 (3.1669)	Learning Rate [7.8125e-05]
1: TRAIN [3][1300/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00089)	Tok/s 53429 (59321)	Loss/tok 3.0784 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][1300/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00100)	Tok/s 53459 (58901)	Loss/tok 3.1297 (3.1750)	Learning Rate [7.8125e-05]
1: TRAIN [3][1310/6832]	Time 0.054 (0.105)	Data 0.00088 (0.00089)	Tok/s 52091 (59338)	Loss/tok 2.6295 (3.1696)	Learning Rate [7.8125e-05]
2: TRAIN [3][1310/6832]	Time 0.054 (0.105)	Data 0.00090 (0.00097)	Tok/s 52039 (59687)	Loss/tok 2.6607 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][1310/6832]	Time 0.054 (0.105)	Data 0.00097 (0.00100)	Tok/s 50269 (58919)	Loss/tok 2.5807 (3.1751)	Learning Rate [7.8125e-05]
3: TRAIN [3][1310/6832]	Time 0.054 (0.105)	Data 0.00086 (0.00094)	Tok/s 52261 (60127)	Loss/tok 2.6722 (3.1670)	Learning Rate [7.8125e-05]
2: TRAIN [3][1320/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00097)	Tok/s 57980 (59698)	Loss/tok 3.3241 (3.1702)	Learning Rate [7.8125e-05]
1: TRAIN [3][1320/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00089)	Tok/s 57452 (59349)	Loss/tok 3.1661 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][1320/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 57985 (60137)	Loss/tok 3.1479 (3.1667)	Learning Rate [7.8125e-05]
0: TRAIN [3][1320/6832]	Time 0.117 (0.105)	Data 0.00099 (0.00100)	Tok/s 56910 (58932)	Loss/tok 3.2954 (3.1748)	Learning Rate [7.8125e-05]
2: TRAIN [3][1330/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00097)	Tok/s 54462 (59680)	Loss/tok 3.0637 (3.1699)	Learning Rate [7.8125e-05]
1: TRAIN [3][1330/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00089)	Tok/s 53037 (59330)	Loss/tok 2.8515 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][1330/6832]	Time 0.080 (0.105)	Data 0.00084 (0.00094)	Tok/s 54663 (60120)	Loss/tok 2.9104 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][1330/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00100)	Tok/s 53065 (58912)	Loss/tok 3.2136 (3.1742)	Learning Rate [7.8125e-05]
1: TRAIN [3][1340/6832]	Time 0.058 (0.105)	Data 0.00089 (0.00089)	Tok/s 51151 (59341)	Loss/tok 2.6073 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][1340/6832]	Time 0.058 (0.105)	Data 0.00089 (0.00097)	Tok/s 51090 (59690)	Loss/tok 2.9501 (3.1703)	Learning Rate [7.8125e-05]
0: TRAIN [3][1340/6832]	Time 0.058 (0.105)	Data 0.00092 (0.00100)	Tok/s 51170 (58924)	Loss/tok 2.7477 (3.1749)	Learning Rate [7.8125e-05]
3: TRAIN [3][1340/6832]	Time 0.058 (0.105)	Data 0.00084 (0.00094)	Tok/s 52984 (60130)	Loss/tok 2.6173 (3.1670)	Learning Rate [7.8125e-05]
2: TRAIN [3][1350/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00097)	Tok/s 62084 (59720)	Loss/tok 3.2670 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][1350/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00089)	Tok/s 62091 (59371)	Loss/tok 3.3184 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][1350/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00094)	Tok/s 62178 (60160)	Loss/tok 3.3974 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][1350/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00100)	Tok/s 62083 (58956)	Loss/tok 3.4592 (3.1746)	Learning Rate [7.8125e-05]
1: TRAIN [3][1360/6832]	Time 0.077 (0.105)	Data 0.00087 (0.00089)	Tok/s 55002 (59333)	Loss/tok 2.9901 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][1360/6832]	Time 0.077 (0.105)	Data 0.00106 (0.00099)	Tok/s 54530 (58911)	Loss/tok 3.0723 (3.1746)	Learning Rate [7.8125e-05]
2: TRAIN [3][1360/6832]	Time 0.077 (0.105)	Data 0.00087 (0.00097)	Tok/s 54621 (59685)	Loss/tok 3.0195 (3.1701)	Learning Rate [7.8125e-05]
3: TRAIN [3][1360/6832]	Time 0.078 (0.105)	Data 0.00084 (0.00094)	Tok/s 54418 (60127)	Loss/tok 2.9769 (3.1670)	Learning Rate [7.8125e-05]
2: TRAIN [3][1370/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00097)	Tok/s 63548 (59694)	Loss/tok 3.2982 (3.1704)	Learning Rate [7.8125e-05]
1: TRAIN [3][1370/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00089)	Tok/s 63502 (59342)	Loss/tok 3.1719 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][1370/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00099)	Tok/s 63489 (58921)	Loss/tok 3.4019 (3.1751)	Learning Rate [7.8125e-05]
3: TRAIN [3][1370/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 64121 (60134)	Loss/tok 3.4217 (3.1672)	Learning Rate [7.8125e-05]
2: TRAIN [3][1380/6832]	Time 0.115 (0.105)	Data 0.00097 (0.00097)	Tok/s 51242 (59667)	Loss/tok 3.2209 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][1380/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00089)	Tok/s 51086 (59314)	Loss/tok 3.1370 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][1380/6832]	Time 0.115 (0.105)	Data 0.00099 (0.00094)	Tok/s 52235 (60112)	Loss/tok 3.0514 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][1380/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00099)	Tok/s 51104 (58886)	Loss/tok 3.2017 (3.1748)	Learning Rate [7.8125e-05]
2: TRAIN [3][1390/6832]	Time 0.044 (0.105)	Data 0.00086 (0.00097)	Tok/s 38365 (59609)	Loss/tok 1.9329 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][1390/6832]	Time 0.044 (0.105)	Data 0.00086 (0.00089)	Tok/s 32206 (59249)	Loss/tok 2.0655 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][1390/6832]	Time 0.044 (0.105)	Data 0.00081 (0.00094)	Tok/s 42271 (60058)	Loss/tok 2.2419 (3.1662)	Learning Rate [7.8125e-05]
0: TRAIN [3][1390/6832]	Time 0.044 (0.105)	Data 0.00092 (0.00099)	Tok/s 21063 (58806)	Loss/tok 1.7630 (3.1743)	Learning Rate [7.8125e-05]
2: TRAIN [3][1400/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00097)	Tok/s 53088 (59593)	Loss/tok 3.0787 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][1400/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00089)	Tok/s 53086 (59234)	Loss/tok 3.1448 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][1400/6832]	Time 0.096 (0.105)	Data 0.00086 (0.00094)	Tok/s 53097 (60038)	Loss/tok 3.1804 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][1400/6832]	Time 0.096 (0.105)	Data 0.00125 (0.00099)	Tok/s 53063 (58792)	Loss/tok 2.9850 (3.1740)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][1410/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00097)	Tok/s 63615 (59573)	Loss/tok 3.4287 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][1410/6832]	Time 0.131 (0.105)	Data 0.00109 (0.00089)	Tok/s 63512 (59215)	Loss/tok 3.3506 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][1410/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 64512 (60019)	Loss/tok 3.4397 (3.1665)	Learning Rate [7.8125e-05]
0: TRAIN [3][1410/6832]	Time 0.131 (0.105)	Data 0.00126 (0.00099)	Tok/s 63560 (58776)	Loss/tok 3.2325 (3.1737)	Learning Rate [7.8125e-05]
2: TRAIN [3][1420/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00097)	Tok/s 51744 (59582)	Loss/tok 3.2908 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][1420/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00089)	Tok/s 51681 (59227)	Loss/tok 3.1214 (3.1684)	Learning Rate [7.8125e-05]
3: TRAIN [3][1420/6832]	Time 0.089 (0.105)	Data 0.00083 (0.00094)	Tok/s 52475 (60027)	Loss/tok 3.0136 (3.1670)	Learning Rate [7.8125e-05]
0: TRAIN [3][1420/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00099)	Tok/s 51684 (58789)	Loss/tok 3.0587 (3.1736)	Learning Rate [7.8125e-05]
1: TRAIN [3][1430/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00089)	Tok/s 63665 (59269)	Loss/tok 3.2818 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][1430/6832]	Time 0.131 (0.105)	Data 0.00111 (0.00099)	Tok/s 63697 (58832)	Loss/tok 3.3949 (3.1744)	Learning Rate [7.8125e-05]
2: TRAIN [3][1430/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00097)	Tok/s 63633 (59624)	Loss/tok 3.3649 (3.1703)	Learning Rate [7.8125e-05]
3: TRAIN [3][1430/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 63641 (60069)	Loss/tok 3.3755 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][1440/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00089)	Tok/s 52204 (59244)	Loss/tok 3.2197 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][1440/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00097)	Tok/s 53253 (59600)	Loss/tok 3.1968 (3.1700)	Learning Rate [7.8125e-05]
0: TRAIN [3][1440/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00099)	Tok/s 52227 (58810)	Loss/tok 3.2434 (3.1745)	Learning Rate [7.8125e-05]
3: TRAIN [3][1440/6832]	Time 0.113 (0.105)	Data 0.00083 (0.00094)	Tok/s 53372 (60043)	Loss/tok 3.0759 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][1450/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00089)	Tok/s 62198 (59264)	Loss/tok 3.3352 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][1450/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00097)	Tok/s 62168 (59619)	Loss/tok 3.3248 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][1450/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00099)	Tok/s 62211 (58831)	Loss/tok 3.5453 (3.1742)	Learning Rate [7.8125e-05]
3: TRAIN [3][1450/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 62262 (60062)	Loss/tok 3.2794 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][1460/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00089)	Tok/s 71684 (59279)	Loss/tok 3.1861 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][1460/6832]	Time 0.128 (0.105)	Data 0.00112 (0.00097)	Tok/s 72562 (59634)	Loss/tok 3.3651 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][1460/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00099)	Tok/s 71723 (58848)	Loss/tok 3.2017 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][1460/6832]	Time 0.129 (0.105)	Data 0.00122 (0.00094)	Tok/s 72669 (60079)	Loss/tok 3.1143 (3.1673)	Learning Rate [7.8125e-05]
1: TRAIN [3][1470/6832]	Time 0.059 (0.105)	Data 0.00087 (0.00089)	Tok/s 50073 (59272)	Loss/tok 2.7100 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][1470/6832]	Time 0.059 (0.105)	Data 0.00094 (0.00099)	Tok/s 50083 (58843)	Loss/tok 2.7482 (3.1737)	Learning Rate [7.8125e-05]
2: TRAIN [3][1470/6832]	Time 0.059 (0.105)	Data 0.00087 (0.00097)	Tok/s 50934 (59627)	Loss/tok 2.7290 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][1470/6832]	Time 0.059 (0.105)	Data 0.00087 (0.00094)	Tok/s 52215 (60072)	Loss/tok 2.7764 (3.1671)	Learning Rate [7.8125e-05]
2: TRAIN [3][1480/6832]	Time 0.043 (0.105)	Data 0.00087 (0.00097)	Tok/s 38665 (59623)	Loss/tok 1.9641 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][1480/6832]	Time 0.043 (0.105)	Data 0.00089 (0.00089)	Tok/s 33736 (59261)	Loss/tok 2.0448 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][1480/6832]	Time 0.043 (0.105)	Data 0.00093 (0.00099)	Tok/s 21370 (58817)	Loss/tok 1.6343 (3.1735)	Learning Rate [7.8125e-05]
3: TRAIN [3][1480/6832]	Time 0.043 (0.105)	Data 0.00085 (0.00094)	Tok/s 42264 (60072)	Loss/tok 2.2992 (3.1669)	Learning Rate [7.8125e-05]
2: TRAIN [3][1490/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00097)	Tok/s 76995 (59619)	Loss/tok 3.1500 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][1490/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00089)	Tok/s 76947 (59257)	Loss/tok 3.2963 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][1490/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00099)	Tok/s 76511 (58812)	Loss/tok 3.1817 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][1490/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 77902 (60069)	Loss/tok 3.2156 (3.1669)	Learning Rate [7.8125e-05]
2: TRAIN [3][1500/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00097)	Tok/s 57236 (59625)	Loss/tok 3.4331 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][1500/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00089)	Tok/s 57238 (59263)	Loss/tok 3.1955 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][1500/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00099)	Tok/s 57252 (58820)	Loss/tok 3.2871 (3.1736)	Learning Rate [7.8125e-05]
3: TRAIN [3][1500/6832]	Time 0.121 (0.105)	Data 0.00083 (0.00094)	Tok/s 57647 (60073)	Loss/tok 3.0443 (3.1673)	Learning Rate [7.8125e-05]
1: TRAIN [3][1510/6832]	Time 0.067 (0.105)	Data 0.00087 (0.00089)	Tok/s 49323 (59218)	Loss/tok 2.7963 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][1510/6832]	Time 0.067 (0.105)	Data 0.00091 (0.00099)	Tok/s 49359 (58777)	Loss/tok 3.0583 (3.1729)	Learning Rate [7.8125e-05]
2: TRAIN [3][1510/6832]	Time 0.068 (0.105)	Data 0.00089 (0.00097)	Tok/s 49706 (59579)	Loss/tok 2.8985 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][1510/6832]	Time 0.068 (0.105)	Data 0.00083 (0.00094)	Tok/s 51021 (60029)	Loss/tok 2.9828 (3.1667)	Learning Rate [7.8125e-05]
2: TRAIN [3][1520/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00097)	Tok/s 50089 (59577)	Loss/tok 2.7970 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][1520/6832]	Time 0.059 (0.105)	Data 0.00085 (0.00089)	Tok/s 50047 (59216)	Loss/tok 2.6734 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][1520/6832]	Time 0.059 (0.105)	Data 0.00096 (0.00099)	Tok/s 50073 (58774)	Loss/tok 2.7215 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][1520/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00094)	Tok/s 51405 (60027)	Loss/tok 2.7219 (3.1664)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][1530/6832]	Time 0.089 (0.105)	Data 0.00104 (0.00097)	Tok/s 54355 (59565)	Loss/tok 3.1011 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][1530/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00089)	Tok/s 54377 (59203)	Loss/tok 3.0843 (3.1667)	Learning Rate [7.8125e-05]
3: TRAIN [3][1530/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00094)	Tok/s 55522 (60017)	Loss/tok 3.1062 (3.1660)	Learning Rate [7.8125e-05]
0: TRAIN [3][1530/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00099)	Tok/s 54438 (58762)	Loss/tok 2.9105 (3.1720)	Learning Rate [7.8125e-05]
2: TRAIN [3][1540/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00097)	Tok/s 54151 (59555)	Loss/tok 2.9022 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][1540/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00089)	Tok/s 54150 (59195)	Loss/tok 3.1058 (3.1668)	Learning Rate [7.8125e-05]
3: TRAIN [3][1540/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00094)	Tok/s 54513 (60007)	Loss/tok 3.0521 (3.1663)	Learning Rate [7.8125e-05]
0: TRAIN [3][1540/6832]	Time 0.080 (0.105)	Data 0.00103 (0.00099)	Tok/s 54104 (58755)	Loss/tok 3.0747 (3.1722)	Learning Rate [7.8125e-05]
2: TRAIN [3][1550/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00097)	Tok/s 55286 (59536)	Loss/tok 3.1507 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][1550/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00089)	Tok/s 55279 (59176)	Loss/tok 3.2653 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][1550/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00098)	Tok/s 54238 (58734)	Loss/tok 3.1929 (3.1721)	Learning Rate [7.8125e-05]
3: TRAIN [3][1550/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 55303 (59987)	Loss/tok 2.9772 (3.1659)	Learning Rate [7.8125e-05]
2: TRAIN [3][1560/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00097)	Tok/s 59795 (59515)	Loss/tok 3.0990 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][1560/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00089)	Tok/s 59802 (59149)	Loss/tok 3.4818 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][1560/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 59819 (59970)	Loss/tok 3.5211 (3.1663)	Learning Rate [7.8125e-05]
0: TRAIN [3][1560/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00098)	Tok/s 59513 (58695)	Loss/tok 3.2979 (3.1722)	Learning Rate [7.8125e-05]
2: TRAIN [3][1570/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00097)	Tok/s 85955 (59537)	Loss/tok 3.1070 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][1570/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00089)	Tok/s 85221 (59172)	Loss/tok 3.1639 (3.1671)	Learning Rate [7.8125e-05]
3: TRAIN [3][1570/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 86418 (59993)	Loss/tok 3.1483 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][1570/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00098)	Tok/s 84693 (58719)	Loss/tok 3.1104 (3.1719)	Learning Rate [7.8125e-05]
2: TRAIN [3][1580/6832]	Time 0.090 (0.105)	Data 0.00097 (0.00097)	Tok/s 52748 (59554)	Loss/tok 3.0674 (3.1672)	Learning Rate [7.8125e-05]
1: TRAIN [3][1580/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00089)	Tok/s 52750 (59189)	Loss/tok 3.0609 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][1580/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00094)	Tok/s 52755 (60008)	Loss/tok 3.0416 (3.1666)	Learning Rate [7.8125e-05]
0: TRAIN [3][1580/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00098)	Tok/s 52327 (58737)	Loss/tok 3.0061 (3.1719)	Learning Rate [7.8125e-05]
2: TRAIN [3][1590/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00097)	Tok/s 52673 (59555)	Loss/tok 3.1507 (3.1670)	Learning Rate [7.8125e-05]
1: TRAIN [3][1590/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00089)	Tok/s 52673 (59192)	Loss/tok 3.0519 (3.1668)	Learning Rate [7.8125e-05]
3: TRAIN [3][1590/6832]	Time 0.104 (0.105)	Data 0.00095 (0.00094)	Tok/s 52695 (60010)	Loss/tok 2.9874 (3.1661)	Learning Rate [7.8125e-05]
0: TRAIN [3][1590/6832]	Time 0.104 (0.105)	Data 0.00097 (0.00098)	Tok/s 52688 (58741)	Loss/tok 3.2056 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][1600/6832]	Time 0.095 (0.105)	Data 0.00091 (0.00097)	Tok/s 53743 (59542)	Loss/tok 3.0680 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][1600/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00089)	Tok/s 53636 (59179)	Loss/tok 3.2895 (3.1670)	Learning Rate [7.8125e-05]
3: TRAIN [3][1600/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00094)	Tok/s 53760 (59994)	Loss/tok 3.1493 (3.1662)	Learning Rate [7.8125e-05]
0: TRAIN [3][1600/6832]	Time 0.095 (0.105)	Data 0.00090 (0.00098)	Tok/s 53643 (58729)	Loss/tok 3.1032 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][1610/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00089)	Tok/s 60899 (59178)	Loss/tok 3.2934 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][1610/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00098)	Tok/s 60339 (58721)	Loss/tok 3.2983 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][1610/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00097)	Tok/s 60819 (59545)	Loss/tok 3.3092 (3.1676)	Learning Rate [7.8125e-05]
3: TRAIN [3][1610/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 60838 (59997)	Loss/tok 3.5381 (3.1664)	Learning Rate [7.8125e-05]
1: TRAIN [3][1620/6832]	Time 0.067 (0.105)	Data 0.00087 (0.00089)	Tok/s 49719 (59165)	Loss/tok 2.8760 (3.1663)	Learning Rate [7.8125e-05]
2: TRAIN [3][1620/6832]	Time 0.067 (0.105)	Data 0.00089 (0.00097)	Tok/s 49628 (59531)	Loss/tok 3.0651 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][1620/6832]	Time 0.067 (0.105)	Data 0.00094 (0.00098)	Tok/s 49702 (58707)	Loss/tok 2.9861 (3.1717)	Learning Rate [7.8125e-05]
3: TRAIN [3][1620/6832]	Time 0.067 (0.105)	Data 0.00085 (0.00094)	Tok/s 50341 (59982)	Loss/tok 2.8824 (3.1664)	Learning Rate [7.8125e-05]
2: TRAIN [3][1630/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00096)	Tok/s 67381 (59527)	Loss/tok 3.1434 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][1630/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 67405 (59978)	Loss/tok 3.4563 (3.1666)	Learning Rate [7.8125e-05]
1: TRAIN [3][1630/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00089)	Tok/s 67310 (59162)	Loss/tok 3.1331 (3.1662)	Learning Rate [7.8125e-05]
0: TRAIN [3][1630/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00098)	Tok/s 67301 (58705)	Loss/tok 3.2821 (3.1719)	Learning Rate [7.8125e-05]
2: TRAIN [3][1640/6832]	Time 0.097 (0.105)	Data 0.00095 (0.00096)	Tok/s 52745 (59550)	Loss/tok 3.1876 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][1640/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00089)	Tok/s 51592 (59184)	Loss/tok 3.2505 (3.1663)	Learning Rate [7.8125e-05]
3: TRAIN [3][1640/6832]	Time 0.097 (0.105)	Data 0.00094 (0.00094)	Tok/s 52774 (59999)	Loss/tok 3.1120 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][1640/6832]	Time 0.097 (0.105)	Data 0.00093 (0.00098)	Tok/s 51455 (58727)	Loss/tok 3.1862 (3.1722)	Learning Rate [7.8125e-05]
2: TRAIN [3][1650/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00096)	Tok/s 58421 (59538)	Loss/tok 3.1384 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][1650/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00089)	Tok/s 58478 (59173)	Loss/tok 3.2066 (3.1666)	Learning Rate [7.8125e-05]
3: TRAIN [3][1650/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00094)	Tok/s 58709 (59987)	Loss/tok 3.2099 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][1650/6832]	Time 0.116 (0.105)	Data 0.00093 (0.00098)	Tok/s 58475 (58718)	Loss/tok 3.1195 (3.1722)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][1660/6832]	Time 0.096 (0.105)	Data 0.00090 (0.00096)	Tok/s 54712 (59519)	Loss/tok 3.2541 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][1660/6832]	Time 0.096 (0.105)	Data 0.00089 (0.00089)	Tok/s 54770 (59156)	Loss/tok 3.2529 (3.1667)	Learning Rate [7.8125e-05]
0: TRAIN [3][1660/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00098)	Tok/s 54794 (58701)	Loss/tok 3.0849 (3.1721)	Learning Rate [7.8125e-05]
3: TRAIN [3][1660/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00094)	Tok/s 54721 (59967)	Loss/tok 3.0566 (3.1666)	Learning Rate [7.8125e-05]
1: TRAIN [3][1670/6832]	Time 0.105 (0.105)	Data 0.00088 (0.00089)	Tok/s 53723 (59142)	Loss/tok 3.1877 (3.1667)	Learning Rate [7.8125e-05]
2: TRAIN [3][1670/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00096)	Tok/s 53677 (59506)	Loss/tok 3.1056 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][1670/6832]	Time 0.105 (0.105)	Data 0.00093 (0.00098)	Tok/s 52675 (58687)	Loss/tok 3.0229 (3.1723)	Learning Rate [7.8125e-05]
3: TRAIN [3][1670/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00094)	Tok/s 53689 (59952)	Loss/tok 3.0266 (3.1666)	Learning Rate [7.8125e-05]
1: TRAIN [3][1680/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00089)	Tok/s 61527 (59131)	Loss/tok 3.1779 (3.1671)	Learning Rate [7.8125e-05]
2: TRAIN [3][1680/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00096)	Tok/s 62445 (59495)	Loss/tok 3.3695 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][1680/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00098)	Tok/s 61442 (58679)	Loss/tok 3.2869 (3.1723)	Learning Rate [7.8125e-05]
3: TRAIN [3][1680/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 62447 (59940)	Loss/tok 3.2986 (3.1669)	Learning Rate [7.8125e-05]
1: TRAIN [3][1690/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00089)	Tok/s 67496 (59137)	Loss/tok 3.3166 (3.1668)	Learning Rate [7.8125e-05]
2: TRAIN [3][1690/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00096)	Tok/s 67422 (59500)	Loss/tok 3.1456 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][1690/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00098)	Tok/s 66952 (58687)	Loss/tok 3.2328 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][1690/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 67415 (59944)	Loss/tok 3.2349 (3.1668)	Learning Rate [7.8125e-05]
2: TRAIN [3][1700/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00096)	Tok/s 54320 (59486)	Loss/tok 3.1934 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][1700/6832]	Time 0.086 (0.105)	Data 0.00084 (0.00089)	Tok/s 53427 (59125)	Loss/tok 3.1059 (3.1673)	Learning Rate [7.8125e-05]
3: TRAIN [3][1700/6832]	Time 0.086 (0.105)	Data 0.00088 (0.00094)	Tok/s 54974 (59929)	Loss/tok 3.0840 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][1700/6832]	Time 0.086 (0.105)	Data 0.00090 (0.00098)	Tok/s 53424 (58675)	Loss/tok 3.1595 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][1710/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00096)	Tok/s 54068 (59477)	Loss/tok 2.9732 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][1710/6832]	Time 0.083 (0.105)	Data 0.00086 (0.00089)	Tok/s 54057 (59116)	Loss/tok 3.0099 (3.1673)	Learning Rate [7.8125e-05]
3: TRAIN [3][1710/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00094)	Tok/s 54059 (59919)	Loss/tok 3.0956 (3.1671)	Learning Rate [7.8125e-05]
0: TRAIN [3][1710/6832]	Time 0.083 (0.105)	Data 0.00096 (0.00098)	Tok/s 53215 (58668)	Loss/tok 3.0228 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][1720/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00089)	Tok/s 61002 (59128)	Loss/tok 3.1552 (3.1676)	Learning Rate [7.8125e-05]
2: TRAIN [3][1720/6832]	Time 0.120 (0.105)	Data 0.00103 (0.00096)	Tok/s 60961 (59489)	Loss/tok 3.2103 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][1720/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00098)	Tok/s 61005 (58682)	Loss/tok 3.1936 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][1720/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00094)	Tok/s 61966 (59931)	Loss/tok 3.2766 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][1730/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00096)	Tok/s 54454 (59465)	Loss/tok 3.0991 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][1730/6832]	Time 0.103 (0.105)	Data 0.00085 (0.00089)	Tok/s 54427 (59104)	Loss/tok 3.1624 (3.1673)	Learning Rate [7.8125e-05]
3: TRAIN [3][1730/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00094)	Tok/s 55143 (59906)	Loss/tok 3.1353 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][1730/6832]	Time 0.103 (0.105)	Data 0.00093 (0.00098)	Tok/s 54452 (58658)	Loss/tok 3.2593 (3.1724)	Learning Rate [7.8125e-05]
2: TRAIN [3][1740/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00096)	Tok/s 58977 (59478)	Loss/tok 3.1677 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][1740/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00094)	Tok/s 59002 (59918)	Loss/tok 3.1547 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][1740/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00089)	Tok/s 58192 (59117)	Loss/tok 3.1764 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][1740/6832]	Time 0.115 (0.105)	Data 0.00101 (0.00098)	Tok/s 57820 (58672)	Loss/tok 3.2333 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][1750/6832]	Time 0.060 (0.105)	Data 0.00086 (0.00089)	Tok/s 51154 (59132)	Loss/tok 2.8166 (3.1672)	Learning Rate [7.8125e-05]
2: TRAIN [3][1750/6832]	Time 0.060 (0.105)	Data 0.00090 (0.00096)	Tok/s 51144 (59492)	Loss/tok 2.8327 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][1750/6832]	Time 0.060 (0.105)	Data 0.00092 (0.00098)	Tok/s 51164 (58686)	Loss/tok 2.7451 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][1750/6832]	Time 0.060 (0.105)	Data 0.00091 (0.00094)	Tok/s 52606 (59933)	Loss/tok 2.7800 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][1760/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00089)	Tok/s 74329 (59111)	Loss/tok 3.4086 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][1760/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 74551 (59469)	Loss/tok 3.2351 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][1760/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00098)	Tok/s 74298 (58667)	Loss/tok 3.3034 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][1760/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 75326 (59911)	Loss/tok 3.2411 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][1770/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00089)	Tok/s 56931 (59090)	Loss/tok 3.2561 (3.1673)	Learning Rate [7.8125e-05]
2: TRAIN [3][1770/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00096)	Tok/s 57657 (59449)	Loss/tok 3.2869 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][1770/6832]	Time 0.126 (0.105)	Data 0.00084 (0.00094)	Tok/s 57937 (59890)	Loss/tok 3.2881 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][1770/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00098)	Tok/s 56898 (58647)	Loss/tok 3.1507 (3.1734)	Learning Rate [7.8125e-05]
1: TRAIN [3][1780/6832]	Time 0.061 (0.105)	Data 0.00085 (0.00089)	Tok/s 52132 (59126)	Loss/tok 2.8206 (3.1673)	Learning Rate [7.8125e-05]
2: TRAIN [3][1780/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00096)	Tok/s 52182 (59485)	Loss/tok 2.7127 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][1780/6832]	Time 0.061 (0.105)	Data 0.00097 (0.00098)	Tok/s 52128 (58682)	Loss/tok 2.9231 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][1780/6832]	Time 0.061 (0.105)	Data 0.00088 (0.00094)	Tok/s 52880 (59927)	Loss/tok 2.8636 (3.1674)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][1790/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00096)	Tok/s 58937 (59467)	Loss/tok 3.3899 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][1790/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00089)	Tok/s 58933 (59109)	Loss/tok 3.3580 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][1790/6832]	Time 0.124 (0.105)	Data 0.00094 (0.00098)	Tok/s 58968 (58667)	Loss/tok 3.2833 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][1790/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00094)	Tok/s 59650 (59909)	Loss/tok 3.3408 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][1800/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00096)	Tok/s 54737 (59460)	Loss/tok 3.1669 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][1800/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00089)	Tok/s 54748 (59103)	Loss/tok 3.1178 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][1800/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00094)	Tok/s 54719 (59902)	Loss/tok 2.9581 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][1800/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00098)	Tok/s 54733 (58662)	Loss/tok 3.0366 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][1810/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 64948 (59488)	Loss/tok 3.2624 (3.1701)	Learning Rate [7.8125e-05]
3: TRAIN [3][1810/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00094)	Tok/s 64959 (59928)	Loss/tok 3.1949 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][1810/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00089)	Tok/s 64668 (59131)	Loss/tok 3.2859 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][1810/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00098)	Tok/s 63884 (58691)	Loss/tok 3.1476 (3.1737)	Learning Rate [7.8125e-05]
1: TRAIN [3][1820/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00089)	Tok/s 91658 (59143)	Loss/tok 3.0611 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][1820/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00096)	Tok/s 92711 (59502)	Loss/tok 3.1599 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][1820/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00098)	Tok/s 90706 (58702)	Loss/tok 3.0648 (3.1734)	Learning Rate [7.8125e-05]
3: TRAIN [3][1820/6832]	Time 0.132 (0.105)	Data 0.00106 (0.00094)	Tok/s 94503 (59943)	Loss/tok 3.0858 (3.1673)	Learning Rate [7.8125e-05]
2: TRAIN [3][1830/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 77070 (59534)	Loss/tok 3.2125 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][1830/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00089)	Tok/s 76820 (59175)	Loss/tok 3.2730 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][1830/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00098)	Tok/s 76054 (58736)	Loss/tok 3.1874 (3.1735)	Learning Rate [7.8125e-05]
3: TRAIN [3][1830/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 77231 (59976)	Loss/tok 3.1338 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][1840/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00096)	Tok/s 62497 (59525)	Loss/tok 3.2886 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][1840/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00089)	Tok/s 62472 (59167)	Loss/tok 3.2510 (3.1676)	Learning Rate [7.8125e-05]
3: TRAIN [3][1840/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00094)	Tok/s 62523 (59965)	Loss/tok 3.2487 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][1840/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00098)	Tok/s 62095 (58728)	Loss/tok 3.2535 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][1850/6832]	Time 0.062 (0.105)	Data 0.00105 (0.00096)	Tok/s 49563 (59529)	Loss/tok 2.9568 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][1850/6832]	Time 0.062 (0.105)	Data 0.00096 (0.00089)	Tok/s 49553 (59168)	Loss/tok 2.6757 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][1850/6832]	Time 0.062 (0.105)	Data 0.00090 (0.00098)	Tok/s 49584 (58726)	Loss/tok 2.8863 (3.1734)	Learning Rate [7.8125e-05]
3: TRAIN [3][1850/6832]	Time 0.062 (0.105)	Data 0.00100 (0.00094)	Tok/s 50493 (59973)	Loss/tok 2.8308 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][1860/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00096)	Tok/s 62081 (59533)	Loss/tok 3.3007 (3.1700)	Learning Rate [7.8125e-05]
1: TRAIN [3][1860/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00089)	Tok/s 61927 (59173)	Loss/tok 3.2321 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][1860/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00098)	Tok/s 61117 (58731)	Loss/tok 3.3624 (3.1736)	Learning Rate [7.8125e-05]
3: TRAIN [3][1860/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 62087 (59976)	Loss/tok 3.1876 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][1870/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 62640 (59532)	Loss/tok 3.1350 (3.1700)	Learning Rate [7.8125e-05]
1: TRAIN [3][1870/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00089)	Tok/s 62603 (59172)	Loss/tok 3.2429 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][1870/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00098)	Tok/s 62632 (58732)	Loss/tok 3.2854 (3.1738)	Learning Rate [7.8125e-05]
3: TRAIN [3][1870/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 62827 (59975)	Loss/tok 3.3425 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][1880/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00089)	Tok/s 83403 (59196)	Loss/tok 3.2817 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][1880/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00098)	Tok/s 83040 (58757)	Loss/tok 3.2140 (3.1740)	Learning Rate [7.8125e-05]
2: TRAIN [3][1880/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00096)	Tok/s 83987 (59555)	Loss/tok 3.1718 (3.1700)	Learning Rate [7.8125e-05]
3: TRAIN [3][1880/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 84333 (59998)	Loss/tok 3.1857 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][1890/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00089)	Tok/s 87752 (59240)	Loss/tok 3.2014 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][1890/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00096)	Tok/s 88401 (59598)	Loss/tok 3.1163 (3.1703)	Learning Rate [7.8125e-05]
0: TRAIN [3][1890/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00097)	Tok/s 87194 (58802)	Loss/tok 3.0580 (3.1741)	Learning Rate [7.8125e-05]
3: TRAIN [3][1890/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 89341 (60042)	Loss/tok 3.1211 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][1900/6832]	Time 0.081 (0.105)	Data 0.00087 (0.00096)	Tok/s 53917 (59587)	Loss/tok 2.9791 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][1900/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00089)	Tok/s 53918 (59230)	Loss/tok 3.1278 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][1900/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00097)	Tok/s 53882 (58794)	Loss/tok 3.2765 (3.1742)	Learning Rate [7.8125e-05]
3: TRAIN [3][1900/6832]	Time 0.081 (0.105)	Data 0.00088 (0.00094)	Tok/s 53910 (60030)	Loss/tok 2.9451 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][1910/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00096)	Tok/s 53413 (59594)	Loss/tok 3.1728 (3.1703)	Learning Rate [7.8125e-05]
3: TRAIN [3][1910/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00094)	Tok/s 53406 (60037)	Loss/tok 3.3187 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][1910/6832]	Time 0.106 (0.105)	Data 0.00087 (0.00089)	Tok/s 53373 (59238)	Loss/tok 2.9228 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][1910/6832]	Time 0.105 (0.105)	Data 0.00088 (0.00097)	Tok/s 52536 (58802)	Loss/tok 3.1113 (3.1748)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [3][1920/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00089)	Tok/s 59661 (59237)	Loss/tok 3.1229 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][1920/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00096)	Tok/s 59706 (59592)	Loss/tok 3.4063 (3.1703)	Learning Rate [7.8125e-05]
3: TRAIN [3][1920/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00094)	Tok/s 59724 (60034)	Loss/tok 3.1214 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][1920/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00097)	Tok/s 59271 (58803)	Loss/tok 3.1456 (3.1746)	Learning Rate [7.8125e-05]
2: TRAIN [3][1930/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 80597 (59593)	Loss/tok 3.2005 (3.1704)	Learning Rate [7.8125e-05]
1: TRAIN [3][1930/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00089)	Tok/s 79873 (59234)	Loss/tok 3.1528 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][1930/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00097)	Tok/s 79884 (58795)	Loss/tok 3.2704 (3.1747)	Learning Rate [7.8125e-05]
3: TRAIN [3][1930/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 80904 (60036)	Loss/tok 3.1889 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][1940/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00089)	Tok/s 54378 (59224)	Loss/tok 3.0768 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][1940/6832]	Time 0.090 (0.105)	Data 0.00103 (0.00094)	Tok/s 55299 (60023)	Loss/tok 2.9143 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][1940/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00097)	Tok/s 54385 (58787)	Loss/tok 2.8515 (3.1744)	Learning Rate [7.8125e-05]
2: TRAIN [3][1940/6832]	Time 0.090 (0.105)	Data 0.00104 (0.00096)	Tok/s 54297 (59581)	Loss/tok 3.1462 (3.1704)	Learning Rate [7.8125e-05]
2: TRAIN [3][1950/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00096)	Tok/s 59638 (59559)	Loss/tok 3.1799 (3.1700)	Learning Rate [7.8125e-05]
1: TRAIN [3][1950/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00089)	Tok/s 59630 (59201)	Loss/tok 3.2252 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][1950/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00094)	Tok/s 59621 (60002)	Loss/tok 3.3132 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][1950/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00097)	Tok/s 59513 (58765)	Loss/tok 3.3089 (3.1741)	Learning Rate [7.8125e-05]
2: TRAIN [3][1960/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 64044 (59540)	Loss/tok 3.3113 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][1960/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00089)	Tok/s 64034 (59180)	Loss/tok 3.2514 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][1960/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00097)	Tok/s 64046 (58740)	Loss/tok 3.2688 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][1960/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00094)	Tok/s 64086 (59983)	Loss/tok 3.2067 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][1970/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00089)	Tok/s 50514 (59186)	Loss/tok 3.0456 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][1970/6832]	Time 0.104 (0.105)	Data 0.00094 (0.00096)	Tok/s 50405 (59545)	Loss/tok 2.9529 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][1970/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00097)	Tok/s 50508 (58745)	Loss/tok 3.2258 (3.1740)	Learning Rate [7.8125e-05]
3: TRAIN [3][1970/6832]	Time 0.104 (0.105)	Data 0.00094 (0.00094)	Tok/s 50415 (59989)	Loss/tok 2.9824 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][1980/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00089)	Tok/s 85574 (59200)	Loss/tok 3.0598 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][1980/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00096)	Tok/s 86403 (59558)	Loss/tok 3.1404 (3.1701)	Learning Rate [7.8125e-05]
3: TRAIN [3][1980/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 86650 (60001)	Loss/tok 3.2177 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][1980/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00097)	Tok/s 85037 (58761)	Loss/tok 2.9953 (3.1742)	Learning Rate [7.8125e-05]
2: TRAIN [3][1990/6832]	Time 0.085 (0.105)	Data 0.00096 (0.00096)	Tok/s 52960 (59537)	Loss/tok 3.0998 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][1990/6832]	Time 0.084 (0.105)	Data 0.00093 (0.00097)	Tok/s 53021 (58743)	Loss/tok 2.9808 (3.1741)	Learning Rate [7.8125e-05]
1: TRAIN [3][1990/6832]	Time 0.085 (0.105)	Data 0.00095 (0.00089)	Tok/s 52998 (59180)	Loss/tok 2.9563 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][1990/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00094)	Tok/s 52967 (59978)	Loss/tok 3.0602 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][2000/6832]	Time 0.126 (0.105)	Data 0.00097 (0.00096)	Tok/s 63923 (59532)	Loss/tok 3.2138 (3.1699)	Learning Rate [7.8125e-05]
1: TRAIN [3][2000/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00089)	Tok/s 63885 (59176)	Loss/tok 3.3826 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][2000/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00097)	Tok/s 63870 (58740)	Loss/tok 3.2020 (3.1738)	Learning Rate [7.8125e-05]
3: TRAIN [3][2000/6832]	Time 0.127 (0.105)	Data 0.00096 (0.00094)	Tok/s 63932 (59974)	Loss/tok 3.2057 (3.1676)	Learning Rate [7.8125e-05]
2: TRAIN [3][2010/6832]	Time 0.053 (0.105)	Data 0.00089 (0.00096)	Tok/s 45801 (59536)	Loss/tok 2.6229 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][2010/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00089)	Tok/s 45482 (59179)	Loss/tok 2.5499 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][2010/6832]	Time 0.053 (0.105)	Data 0.00093 (0.00097)	Tok/s 43434 (58736)	Loss/tok 2.4997 (3.1738)	Learning Rate [7.8125e-05]
3: TRAIN [3][2010/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00094)	Tok/s 47683 (59980)	Loss/tok 2.5518 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][2020/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00089)	Tok/s 58026 (59156)	Loss/tok 3.1277 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][2020/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00096)	Tok/s 57985 (59515)	Loss/tok 3.1731 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][2020/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00097)	Tok/s 58037 (58709)	Loss/tok 3.3890 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2020/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00094)	Tok/s 58005 (59961)	Loss/tok 3.2665 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][2030/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00089)	Tok/s 60149 (59147)	Loss/tok 3.0741 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][2030/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00096)	Tok/s 60109 (59506)	Loss/tok 3.2546 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][2030/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00097)	Tok/s 59278 (58702)	Loss/tok 3.4273 (3.1744)	Learning Rate [7.8125e-05]
3: TRAIN [3][2030/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00094)	Tok/s 60118 (59952)	Loss/tok 3.5036 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][2040/6832]	Time 0.121 (0.105)	Data 0.00099 (0.00089)	Tok/s 53088 (59157)	Loss/tok 3.0928 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][2040/6832]	Time 0.121 (0.105)	Data 0.00114 (0.00096)	Tok/s 53758 (59516)	Loss/tok 3.2493 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][2040/6832]	Time 0.121 (0.105)	Data 0.00105 (0.00097)	Tok/s 53109 (58712)	Loss/tok 3.1836 (3.1745)	Learning Rate [7.8125e-05]
3: TRAIN [3][2040/6832]	Time 0.121 (0.105)	Data 0.00109 (0.00094)	Tok/s 54143 (59960)	Loss/tok 3.2898 (3.1681)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [3][2050/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00089)	Tok/s 51196 (59158)	Loss/tok 3.2458 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][2050/6832]	Time 0.088 (0.105)	Data 0.00102 (0.00097)	Tok/s 50905 (58712)	Loss/tok 2.9968 (3.1741)	Learning Rate [7.8125e-05]
2: TRAIN [3][2050/6832]	Time 0.088 (0.105)	Data 0.00092 (0.00096)	Tok/s 52257 (59518)	Loss/tok 2.9351 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][2050/6832]	Time 0.088 (0.105)	Data 0.00091 (0.00094)	Tok/s 52250 (59964)	Loss/tok 3.2628 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2060/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00089)	Tok/s 56395 (59163)	Loss/tok 3.2595 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][2060/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00097)	Tok/s 55893 (58719)	Loss/tok 3.0568 (3.1740)	Learning Rate [7.8125e-05]
2: TRAIN [3][2060/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00096)	Tok/s 56978 (59523)	Loss/tok 3.2399 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][2060/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00094)	Tok/s 56983 (59968)	Loss/tok 3.3153 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][2070/6832]	Time 0.079 (0.105)	Data 0.00086 (0.00089)	Tok/s 53795 (59129)	Loss/tok 3.2420 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][2070/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00096)	Tok/s 55319 (59492)	Loss/tok 2.9771 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][2070/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00094)	Tok/s 55459 (59939)	Loss/tok 2.9338 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][2070/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00097)	Tok/s 53839 (58680)	Loss/tok 3.0987 (3.1737)	Learning Rate [7.8125e-05]
1: TRAIN [3][2080/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00089)	Tok/s 66877 (59153)	Loss/tok 3.4155 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][2080/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 66885 (59515)	Loss/tok 3.3565 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][2080/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00097)	Tok/s 66706 (58704)	Loss/tok 3.1307 (3.1738)	Learning Rate [7.8125e-05]
3: TRAIN [3][2080/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 67086 (59962)	Loss/tok 3.2575 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][2090/6832]	Time 0.095 (0.105)	Data 0.00091 (0.00089)	Tok/s 52500 (59152)	Loss/tok 3.2624 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][2090/6832]	Time 0.095 (0.105)	Data 0.00093 (0.00096)	Tok/s 52500 (59514)	Loss/tok 2.9602 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][2090/6832]	Time 0.095 (0.105)	Data 0.00089 (0.00094)	Tok/s 52469 (59961)	Loss/tok 3.2165 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][2090/6832]	Time 0.095 (0.105)	Data 0.00092 (0.00097)	Tok/s 52517 (58703)	Loss/tok 3.1934 (3.1737)	Learning Rate [7.8125e-05]
1: TRAIN [3][2100/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00089)	Tok/s 52956 (59139)	Loss/tok 3.2932 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][2100/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00096)	Tok/s 52954 (59500)	Loss/tok 3.2736 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][2100/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00094)	Tok/s 52954 (59948)	Loss/tok 3.1137 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][2100/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00097)	Tok/s 52480 (58692)	Loss/tok 3.2687 (3.1736)	Learning Rate [7.8125e-05]
1: TRAIN [3][2110/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00089)	Tok/s 54334 (59140)	Loss/tok 3.0808 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][2110/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00097)	Tok/s 54068 (58695)	Loss/tok 3.0893 (3.1738)	Learning Rate [7.8125e-05]
2: TRAIN [3][2110/6832]	Time 0.103 (0.105)	Data 0.00091 (0.00096)	Tok/s 54429 (59501)	Loss/tok 2.9867 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][2110/6832]	Time 0.104 (0.105)	Data 0.00087 (0.00095)	Tok/s 54414 (59947)	Loss/tok 3.1188 (3.1672)	Learning Rate [7.8125e-05]
2: TRAIN [3][2120/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00096)	Tok/s 55544 (59494)	Loss/tok 3.0758 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][2120/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00089)	Tok/s 55476 (59133)	Loss/tok 3.3292 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][2120/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00095)	Tok/s 55527 (59940)	Loss/tok 3.1854 (3.1670)	Learning Rate [7.8125e-05]
0: TRAIN [3][2120/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00097)	Tok/s 55210 (58688)	Loss/tok 3.3313 (3.1737)	Learning Rate [7.8125e-05]
1: TRAIN [3][2130/6832]	Time 0.067 (0.105)	Data 0.00084 (0.00089)	Tok/s 51814 (59098)	Loss/tok 2.8240 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][2130/6832]	Time 0.067 (0.105)	Data 0.00094 (0.00096)	Tok/s 51822 (59459)	Loss/tok 2.8380 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][2130/6832]	Time 0.067 (0.105)	Data 0.00090 (0.00095)	Tok/s 52117 (59906)	Loss/tok 2.8016 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][2130/6832]	Time 0.067 (0.105)	Data 0.00090 (0.00097)	Tok/s 51765 (58652)	Loss/tok 2.9083 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][2140/6832]	Time 0.080 (0.105)	Data 0.00086 (0.00089)	Tok/s 52978 (59103)	Loss/tok 2.9213 (3.1682)	Learning Rate [7.8125e-05]
3: TRAIN [3][2140/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00095)	Tok/s 53071 (59911)	Loss/tok 2.9787 (3.1669)	Learning Rate [7.8125e-05]
2: TRAIN [3][2140/6832]	Time 0.080 (0.105)	Data 0.00099 (0.00096)	Tok/s 53096 (59465)	Loss/tok 3.0605 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][2140/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00097)	Tok/s 52226 (58659)	Loss/tok 3.0209 (3.1734)	Learning Rate [7.8125e-05]
1: TRAIN [3][2150/6832]	Time 0.066 (0.105)	Data 0.00086 (0.00089)	Tok/s 50539 (59079)	Loss/tok 2.9171 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][2150/6832]	Time 0.066 (0.105)	Data 0.00086 (0.00094)	Tok/s 52511 (59890)	Loss/tok 2.8034 (3.1669)	Learning Rate [7.8125e-05]
2: TRAIN [3][2150/6832]	Time 0.066 (0.105)	Data 0.00092 (0.00096)	Tok/s 51069 (59442)	Loss/tok 2.9209 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][2150/6832]	Time 0.066 (0.105)	Data 0.00093 (0.00097)	Tok/s 50521 (58631)	Loss/tok 2.9165 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][2160/6832]	Time 0.118 (0.105)	Data 0.00084 (0.00089)	Tok/s 54407 (59076)	Loss/tok 3.3088 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][2160/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 55489 (59887)	Loss/tok 3.0381 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][2160/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00097)	Tok/s 54412 (58628)	Loss/tok 3.4688 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][2160/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00096)	Tok/s 55250 (59439)	Loss/tok 3.2309 (3.1681)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [3][2170/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00089)	Tok/s 67858 (59102)	Loss/tok 3.2966 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2170/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00097)	Tok/s 67877 (58654)	Loss/tok 3.2183 (3.1735)	Learning Rate [7.8125e-05]
3: TRAIN [3][2170/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00094)	Tok/s 68018 (59911)	Loss/tok 3.3660 (3.1666)	Learning Rate [7.8125e-05]
2: TRAIN [3][2170/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00096)	Tok/s 67966 (59464)	Loss/tok 3.1503 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][2180/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00089)	Tok/s 68394 (59102)	Loss/tok 3.3149 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2180/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00097)	Tok/s 68330 (58656)	Loss/tok 3.3078 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][2180/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 69235 (59912)	Loss/tok 3.3868 (3.1666)	Learning Rate [7.8125e-05]
2: TRAIN [3][2180/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 69217 (59465)	Loss/tok 3.5078 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][2190/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00089)	Tok/s 65502 (59125)	Loss/tok 3.1807 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][2190/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00096)	Tok/s 65582 (59488)	Loss/tok 3.3407 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][2190/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00097)	Tok/s 65463 (58680)	Loss/tok 3.3161 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][2190/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 66039 (59935)	Loss/tok 3.2829 (3.1667)	Learning Rate [7.8125e-05]
1: TRAIN [3][2200/6832]	Time 0.104 (0.105)	Data 0.00083 (0.00089)	Tok/s 53754 (59150)	Loss/tok 3.2051 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][2200/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00097)	Tok/s 52921 (58703)	Loss/tok 3.2267 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][2200/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00096)	Tok/s 54079 (59514)	Loss/tok 3.2666 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][2200/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00094)	Tok/s 54059 (59961)	Loss/tok 3.1985 (3.1666)	Learning Rate [7.8125e-05]
1: TRAIN [3][2210/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00089)	Tok/s 60492 (59172)	Loss/tok 3.3228 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2210/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00097)	Tok/s 60492 (58725)	Loss/tok 3.2346 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][2210/6832]	Time 0.119 (0.105)	Data 0.00084 (0.00094)	Tok/s 61555 (59982)	Loss/tok 3.2313 (3.1664)	Learning Rate [7.8125e-05]
2: TRAIN [3][2210/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00096)	Tok/s 60528 (59535)	Loss/tok 3.2536 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2220/6832]	Time 0.082 (0.105)	Data 0.00089 (0.00089)	Tok/s 53026 (59176)	Loss/tok 3.0060 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2220/6832]	Time 0.082 (0.105)	Data 0.00094 (0.00097)	Tok/s 53017 (58731)	Loss/tok 3.0557 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][2220/6832]	Time 0.082 (0.105)	Data 0.00093 (0.00096)	Tok/s 52962 (59540)	Loss/tok 3.0430 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][2220/6832]	Time 0.082 (0.105)	Data 0.00088 (0.00094)	Tok/s 53731 (59988)	Loss/tok 3.0770 (3.1665)	Learning Rate [7.8125e-05]
1: TRAIN [3][2230/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00089)	Tok/s 88079 (59197)	Loss/tok 3.1372 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2230/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00097)	Tok/s 87366 (58752)	Loss/tok 3.0129 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][2230/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 89396 (60007)	Loss/tok 3.0292 (3.1664)	Learning Rate [7.8125e-05]
2: TRAIN [3][2230/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00096)	Tok/s 88698 (59560)	Loss/tok 3.0799 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][2240/6832]	Time 0.130 (0.105)	Data 0.00082 (0.00089)	Tok/s 75898 (59193)	Loss/tok 3.3243 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][2240/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00097)	Tok/s 75892 (58749)	Loss/tok 3.1215 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][2240/6832]	Time 0.130 (0.105)	Data 0.00083 (0.00094)	Tok/s 76826 (60005)	Loss/tok 3.2396 (3.1664)	Learning Rate [7.8125e-05]
2: TRAIN [3][2240/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00096)	Tok/s 76680 (59557)	Loss/tok 3.1394 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2250/6832]	Time 0.091 (0.105)	Data 0.00091 (0.00089)	Tok/s 53277 (59169)	Loss/tok 2.9804 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][2250/6832]	Time 0.091 (0.105)	Data 0.00096 (0.00096)	Tok/s 53246 (59532)	Loss/tok 2.9269 (3.1676)	Learning Rate [7.8125e-05]
3: TRAIN [3][2250/6832]	Time 0.091 (0.105)	Data 0.00089 (0.00094)	Tok/s 54013 (59980)	Loss/tok 3.2221 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][2250/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00097)	Tok/s 53282 (58726)	Loss/tok 3.1559 (3.1729)	Learning Rate [7.8125e-05]
1: TRAIN [3][2260/6832]	Time 0.094 (0.105)	Data 0.00093 (0.00089)	Tok/s 50652 (59197)	Loss/tok 3.1284 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2260/6832]	Time 0.094 (0.105)	Data 0.00099 (0.00097)	Tok/s 50469 (58754)	Loss/tok 2.8637 (3.1725)	Learning Rate [7.8125e-05]
2: TRAIN [3][2260/6832]	Time 0.094 (0.105)	Data 0.00109 (0.00096)	Tok/s 51820 (59560)	Loss/tok 3.1110 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][2260/6832]	Time 0.094 (0.105)	Data 0.00102 (0.00094)	Tok/s 51808 (60008)	Loss/tok 3.0775 (3.1665)	Learning Rate [7.8125e-05]
1: TRAIN [3][2270/6832]	Time 0.085 (0.105)	Data 0.00086 (0.00089)	Tok/s 53986 (59192)	Loss/tok 3.1738 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][2270/6832]	Time 0.085 (0.105)	Data 0.00085 (0.00097)	Tok/s 52709 (58750)	Loss/tok 3.1429 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][2270/6832]	Time 0.085 (0.105)	Data 0.00090 (0.00094)	Tok/s 54259 (60002)	Loss/tok 3.0536 (3.1666)	Learning Rate [7.8125e-05]
2: TRAIN [3][2270/6832]	Time 0.085 (0.105)	Data 0.00095 (0.00096)	Tok/s 54271 (59554)	Loss/tok 2.9844 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][2280/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00089)	Tok/s 53245 (59197)	Loss/tok 3.1720 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][2280/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00096)	Tok/s 53268 (59558)	Loss/tok 3.1383 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][2280/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00094)	Tok/s 53644 (60005)	Loss/tok 3.1440 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][2280/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00097)	Tok/s 53254 (58755)	Loss/tok 3.2243 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][2290/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00089)	Tok/s 60097 (59180)	Loss/tok 3.2294 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][2290/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00097)	Tok/s 60085 (58740)	Loss/tok 3.1746 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][2290/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00096)	Tok/s 60811 (59541)	Loss/tok 3.2156 (3.1684)	Learning Rate [7.8125e-05]
3: TRAIN [3][2290/6832]	Time 0.121 (0.105)	Data 0.00114 (0.00094)	Tok/s 61153 (59987)	Loss/tok 3.3904 (3.1670)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: TRAIN [3][2300/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00094)	Tok/s 55597 (60001)	Loss/tok 3.2147 (3.1667)	Learning Rate [7.8125e-05]
2: TRAIN [3][2300/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00096)	Tok/s 55602 (59555)	Loss/tok 3.1555 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][2300/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00089)	Tok/s 54979 (59194)	Loss/tok 3.2905 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][2300/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00097)	Tok/s 54559 (58754)	Loss/tok 3.2406 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][2310/6832]	Time 0.042 (0.105)	Data 0.00085 (0.00094)	Tok/s 44118 (60001)	Loss/tok 2.3606 (3.1665)	Learning Rate [7.8125e-05]
2: TRAIN [3][2310/6832]	Time 0.042 (0.105)	Data 0.00088 (0.00096)	Tok/s 40237 (59553)	Loss/tok 1.8397 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][2310/6832]	Time 0.042 (0.105)	Data 0.00083 (0.00089)	Tok/s 33346 (59190)	Loss/tok 2.0069 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][2310/6832]	Time 0.042 (0.105)	Data 0.00084 (0.00097)	Tok/s 20641 (58745)	Loss/tok 1.7485 (3.1728)	Learning Rate [7.8125e-05]
1: TRAIN [3][2320/6832]	Time 0.073 (0.105)	Data 0.00085 (0.00089)	Tok/s 50668 (59183)	Loss/tok 2.9755 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2320/6832]	Time 0.073 (0.105)	Data 0.00105 (0.00097)	Tok/s 51091 (58740)	Loss/tok 2.7160 (3.1725)	Learning Rate [7.8125e-05]
2: TRAIN [3][2320/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00096)	Tok/s 50712 (59546)	Loss/tok 2.9990 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][2320/6832]	Time 0.074 (0.105)	Data 0.00089 (0.00094)	Tok/s 50471 (59995)	Loss/tok 2.9736 (3.1663)	Learning Rate [7.8125e-05]
1: TRAIN [3][2330/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00089)	Tok/s 62278 (59166)	Loss/tok 3.2426 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][2330/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00097)	Tok/s 61874 (58724)	Loss/tok 3.2516 (3.1724)	Learning Rate [7.8125e-05]
3: TRAIN [3][2330/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00094)	Tok/s 62867 (59977)	Loss/tok 3.1940 (3.1663)	Learning Rate [7.8125e-05]
2: TRAIN [3][2330/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00096)	Tok/s 62871 (59528)	Loss/tok 3.3602 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][2340/6832]	Time 0.065 (0.105)	Data 0.00089 (0.00089)	Tok/s 49350 (59152)	Loss/tok 2.9032 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][2340/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00097)	Tok/s 49339 (58710)	Loss/tok 2.7045 (3.1722)	Learning Rate [7.8125e-05]
3: TRAIN [3][2340/6832]	Time 0.065 (0.105)	Data 0.00089 (0.00094)	Tok/s 51130 (59962)	Loss/tok 2.7894 (3.1659)	Learning Rate [7.8125e-05]
2: TRAIN [3][2340/6832]	Time 0.065 (0.105)	Data 0.00090 (0.00096)	Tok/s 49309 (59513)	Loss/tok 2.7030 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][2350/6832]	Time 0.104 (0.105)	Data 0.00084 (0.00089)	Tok/s 51418 (59140)	Loss/tok 3.0431 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][2350/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00094)	Tok/s 51548 (59950)	Loss/tok 3.0357 (3.1662)	Learning Rate [7.8125e-05]
2: TRAIN [3][2350/6832]	Time 0.104 (0.105)	Data 0.00094 (0.00096)	Tok/s 51564 (59500)	Loss/tok 3.1842 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2350/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00097)	Tok/s 50310 (58699)	Loss/tok 2.9822 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][2360/6832]	Time 0.050 (0.105)	Data 0.00085 (0.00089)	Tok/s 48465 (59148)	Loss/tok 2.5095 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][2360/6832]	Time 0.050 (0.105)	Data 0.00089 (0.00097)	Tok/s 46026 (58707)	Loss/tok 2.5292 (3.1723)	Learning Rate [7.8125e-05]
2: TRAIN [3][2360/6832]	Time 0.050 (0.105)	Data 0.00096 (0.00096)	Tok/s 48583 (59508)	Loss/tok 2.5423 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][2360/6832]	Time 0.050 (0.105)	Data 0.00086 (0.00094)	Tok/s 51001 (59959)	Loss/tok 2.7122 (3.1663)	Learning Rate [7.8125e-05]
1: TRAIN [3][2370/6832]	Time 0.109 (0.105)	Data 0.00096 (0.00089)	Tok/s 51556 (59162)	Loss/tok 3.2844 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][2370/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00096)	Tok/s 51519 (59521)	Loss/tok 3.1058 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][2370/6832]	Time 0.109 (0.105)	Data 0.00086 (0.00094)	Tok/s 51990 (59972)	Loss/tok 3.1414 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][2370/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00097)	Tok/s 51591 (58721)	Loss/tok 2.9589 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][2380/6832]	Time 0.096 (0.105)	Data 0.00097 (0.00089)	Tok/s 51859 (59154)	Loss/tok 3.2564 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][2380/6832]	Time 0.096 (0.105)	Data 0.00099 (0.00096)	Tok/s 51809 (59512)	Loss/tok 3.0933 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][2380/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00094)	Tok/s 51809 (59962)	Loss/tok 3.0606 (3.1665)	Learning Rate [7.8125e-05]
0: TRAIN [3][2380/6832]	Time 0.096 (0.105)	Data 0.00100 (0.00097)	Tok/s 51841 (58715)	Loss/tok 3.2055 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][2390/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00089)	Tok/s 67736 (59170)	Loss/tok 3.1679 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2390/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00097)	Tok/s 67355 (58731)	Loss/tok 3.2162 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][2390/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00096)	Tok/s 67684 (59528)	Loss/tok 3.3157 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][2390/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 67682 (59977)	Loss/tok 3.2843 (3.1668)	Learning Rate [7.8125e-05]
1: TRAIN [3][2400/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00089)	Tok/s 61502 (59157)	Loss/tok 3.1377 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][2400/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00096)	Tok/s 62247 (59514)	Loss/tok 3.2815 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][2400/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 62241 (59964)	Loss/tok 3.1550 (3.1666)	Learning Rate [7.8125e-05]
0: TRAIN [3][2400/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00097)	Tok/s 61260 (58718)	Loss/tok 3.1296 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][2410/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00089)	Tok/s 68835 (59171)	Loss/tok 3.3155 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][2410/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00094)	Tok/s 68874 (59977)	Loss/tok 3.2826 (3.1669)	Learning Rate [7.8125e-05]
2: TRAIN [3][2410/6832]	Time 0.128 (0.105)	Data 0.00100 (0.00096)	Tok/s 68807 (59528)	Loss/tok 3.1396 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][2410/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00097)	Tok/s 68833 (58734)	Loss/tok 3.2863 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][2420/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00089)	Tok/s 54731 (59179)	Loss/tok 3.1188 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][2420/6832]	Time 0.114 (0.105)	Data 0.00086 (0.00094)	Tok/s 54798 (59986)	Loss/tok 3.0888 (3.1671)	Learning Rate [7.8125e-05]
0: TRAIN [3][2420/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00097)	Tok/s 54728 (58738)	Loss/tok 3.1906 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][2420/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00096)	Tok/s 54774 (59537)	Loss/tok 3.2468 (3.1684)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: TRAIN [3][2430/6832]	Time 0.043 (0.105)	Data 0.00084 (0.00094)	Tok/s 41343 (60009)	Loss/tok 2.2975 (3.1667)	Learning Rate [7.8125e-05]
2: TRAIN [3][2430/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00096)	Tok/s 38045 (59557)	Loss/tok 1.9192 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][2430/6832]	Time 0.044 (0.105)	Data 0.00083 (0.00089)	Tok/s 32224 (59196)	Loss/tok 2.0586 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2430/6832]	Time 0.044 (0.105)	Data 0.00090 (0.00097)	Tok/s 21433 (58751)	Loss/tok 1.6790 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][2440/6832]	Time 0.122 (0.105)	Data 0.00083 (0.00089)	Tok/s 58685 (59168)	Loss/tok 3.3176 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][2440/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00096)	Tok/s 58738 (59529)	Loss/tok 3.3505 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][2440/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00094)	Tok/s 58719 (59981)	Loss/tok 3.3472 (3.1663)	Learning Rate [7.8125e-05]
0: TRAIN [3][2440/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00096)	Tok/s 58671 (58721)	Loss/tok 3.4936 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][2450/6832]	Time 0.108 (0.105)	Data 0.00085 (0.00089)	Tok/s 50814 (59147)	Loss/tok 3.0201 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][2450/6832]	Time 0.108 (0.105)	Data 0.00089 (0.00096)	Tok/s 50319 (58701)	Loss/tok 3.0652 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][2450/6832]	Time 0.108 (0.105)	Data 0.00082 (0.00094)	Tok/s 50796 (59962)	Loss/tok 3.1522 (3.1665)	Learning Rate [7.8125e-05]
2: TRAIN [3][2450/6832]	Time 0.108 (0.105)	Data 0.00088 (0.00096)	Tok/s 50797 (59510)	Loss/tok 3.1802 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][2460/6832]	Time 0.079 (0.105)	Data 0.00084 (0.00089)	Tok/s 51918 (59130)	Loss/tok 3.2058 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][2460/6832]	Time 0.079 (0.105)	Data 0.00090 (0.00096)	Tok/s 51904 (58685)	Loss/tok 3.0160 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][2460/6832]	Time 0.079 (0.105)	Data 0.00083 (0.00094)	Tok/s 51924 (59944)	Loss/tok 3.0193 (3.1665)	Learning Rate [7.8125e-05]
2: TRAIN [3][2460/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00096)	Tok/s 51933 (59491)	Loss/tok 2.9795 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][2470/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00089)	Tok/s 82963 (59127)	Loss/tok 3.1764 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][2470/6832]	Time 0.133 (0.105)	Data 0.00097 (0.00096)	Tok/s 81973 (58682)	Loss/tok 3.1646 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][2470/6832]	Time 0.133 (0.105)	Data 0.00092 (0.00096)	Tok/s 83158 (59488)	Loss/tok 3.1297 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][2470/6832]	Time 0.133 (0.105)	Data 0.00091 (0.00094)	Tok/s 83876 (59941)	Loss/tok 3.1340 (3.1663)	Learning Rate [7.8125e-05]
2: TRAIN [3][2480/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00096)	Tok/s 52527 (59496)	Loss/tok 3.0337 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][2480/6832]	Time 0.100 (0.105)	Data 0.00084 (0.00089)	Tok/s 52518 (59136)	Loss/tok 2.9580 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][2480/6832]	Time 0.100 (0.105)	Data 0.00084 (0.00094)	Tok/s 52524 (59949)	Loss/tok 3.1384 (3.1663)	Learning Rate [7.8125e-05]
0: TRAIN [3][2480/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00096)	Tok/s 52527 (58692)	Loss/tok 3.0595 (3.1728)	Learning Rate [7.8125e-05]
1: TRAIN [3][2490/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00089)	Tok/s 70081 (59123)	Loss/tok 3.3234 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][2490/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 70843 (59484)	Loss/tok 3.4502 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][2490/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00096)	Tok/s 70139 (58681)	Loss/tok 3.4412 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][2490/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 71056 (59935)	Loss/tok 3.2700 (3.1664)	Learning Rate [7.8125e-05]
1: TRAIN [3][2500/6832]	Time 0.055 (0.105)	Data 0.00086 (0.00089)	Tok/s 51399 (59099)	Loss/tok 2.6229 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][2500/6832]	Time 0.055 (0.105)	Data 0.00088 (0.00096)	Tok/s 51380 (59458)	Loss/tok 2.6424 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][2500/6832]	Time 0.055 (0.105)	Data 0.00084 (0.00094)	Tok/s 52090 (59909)	Loss/tok 2.5728 (3.1660)	Learning Rate [7.8125e-05]
0: TRAIN [3][2500/6832]	Time 0.055 (0.105)	Data 0.00090 (0.00096)	Tok/s 50219 (58657)	Loss/tok 2.5776 (3.1728)	Learning Rate [7.8125e-05]
1: TRAIN [3][2510/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00089)	Tok/s 78197 (59126)	Loss/tok 3.2078 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][2510/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00096)	Tok/s 78954 (59485)	Loss/tok 3.1719 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][2510/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 78951 (59936)	Loss/tok 3.1996 (3.1659)	Learning Rate [7.8125e-05]
0: TRAIN [3][2510/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00096)	Tok/s 78034 (58684)	Loss/tok 3.2530 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][2520/6832]	Time 0.083 (0.105)	Data 0.00085 (0.00089)	Tok/s 53803 (59139)	Loss/tok 3.1947 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][2520/6832]	Time 0.083 (0.105)	Data 0.00086 (0.00094)	Tok/s 53790 (59947)	Loss/tok 3.1428 (3.1659)	Learning Rate [7.8125e-05]
2: TRAIN [3][2520/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00096)	Tok/s 53791 (59498)	Loss/tok 3.0244 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][2520/6832]	Time 0.083 (0.105)	Data 0.00092 (0.00096)	Tok/s 53232 (58698)	Loss/tok 3.1409 (3.1735)	Learning Rate [7.8125e-05]
1: TRAIN [3][2530/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00089)	Tok/s 54111 (59126)	Loss/tok 2.9880 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][2530/6832]	Time 0.090 (0.105)	Data 0.00106 (0.00094)	Tok/s 54043 (59934)	Loss/tok 3.2196 (3.1658)	Learning Rate [7.8125e-05]
0: TRAIN [3][2530/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00096)	Tok/s 52942 (58684)	Loss/tok 3.0793 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][2530/6832]	Time 0.090 (0.105)	Data 0.00111 (0.00096)	Tok/s 54016 (59484)	Loss/tok 2.9917 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][2540/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00096)	Tok/s 53162 (59464)	Loss/tok 3.0419 (3.1684)	Learning Rate [7.8125e-05]
3: TRAIN [3][2540/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00094)	Tok/s 53135 (59914)	Loss/tok 2.9915 (3.1658)	Learning Rate [7.8125e-05]
1: TRAIN [3][2540/6832]	Time 0.080 (0.105)	Data 0.00083 (0.00089)	Tok/s 53111 (59106)	Loss/tok 3.2382 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2540/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00096)	Tok/s 52423 (58664)	Loss/tok 3.0189 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][2550/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00096)	Tok/s 61864 (59453)	Loss/tok 3.2923 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][2550/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00089)	Tok/s 60920 (59093)	Loss/tok 3.3033 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][2550/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00094)	Tok/s 61861 (59903)	Loss/tok 3.3420 (3.1659)	Learning Rate [7.8125e-05]
0: TRAIN [3][2550/6832]	Time 0.126 (0.105)	Data 0.00097 (0.00096)	Tok/s 60851 (58647)	Loss/tok 3.2185 (3.1731)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [3][2560/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00089)	Tok/s 77580 (59130)	Loss/tok 3.3414 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2560/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 77287 (58685)	Loss/tok 3.1858 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][2560/6832]	Time 0.131 (0.105)	Data 0.00083 (0.00094)	Tok/s 78452 (59939)	Loss/tok 3.2032 (3.1661)	Learning Rate [7.8125e-05]
2: TRAIN [3][2560/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 77489 (59489)	Loss/tok 3.2544 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][2570/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00096)	Tok/s 58315 (59487)	Loss/tok 3.2125 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][2570/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00089)	Tok/s 58314 (59128)	Loss/tok 3.1741 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][2570/6832]	Time 0.118 (0.105)	Data 0.00081 (0.00094)	Tok/s 59138 (59937)	Loss/tok 3.2094 (3.1661)	Learning Rate [7.8125e-05]
0: TRAIN [3][2570/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00096)	Tok/s 58330 (58682)	Loss/tok 3.2825 (3.1734)	Learning Rate [7.8125e-05]
1: TRAIN [3][2580/6832]	Time 0.092 (0.105)	Data 0.00087 (0.00089)	Tok/s 54497 (59124)	Loss/tok 3.1747 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][2580/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00096)	Tok/s 54539 (59482)	Loss/tok 3.1197 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][2580/6832]	Time 0.092 (0.105)	Data 0.00083 (0.00094)	Tok/s 54500 (59931)	Loss/tok 3.0469 (3.1661)	Learning Rate [7.8125e-05]
0: TRAIN [3][2580/6832]	Time 0.092 (0.105)	Data 0.00092 (0.00096)	Tok/s 54477 (58680)	Loss/tok 3.1278 (3.1734)	Learning Rate [7.8125e-05]
1: TRAIN [3][2590/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00089)	Tok/s 55030 (59122)	Loss/tok 3.0620 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][2590/6832]	Time 0.093 (0.105)	Data 0.00097 (0.00096)	Tok/s 55010 (59480)	Loss/tok 2.9978 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][2590/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00094)	Tok/s 54987 (59929)	Loss/tok 3.1951 (3.1661)	Learning Rate [7.8125e-05]
0: TRAIN [3][2590/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00096)	Tok/s 54109 (58679)	Loss/tok 3.2792 (3.1734)	Learning Rate [7.8125e-05]
1: TRAIN [3][2600/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00089)	Tok/s 81609 (59120)	Loss/tok 3.0233 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2600/6832]	Time 0.132 (0.105)	Data 0.00099 (0.00096)	Tok/s 81067 (58677)	Loss/tok 3.2378 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][2600/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00096)	Tok/s 81851 (59477)	Loss/tok 3.1126 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][2600/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 82532 (59927)	Loss/tok 3.1497 (3.1660)	Learning Rate [7.8125e-05]
1: TRAIN [3][2610/6832]	Time 0.089 (0.105)	Data 0.00084 (0.00089)	Tok/s 53783 (59125)	Loss/tok 2.7979 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][2610/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00096)	Tok/s 52935 (58683)	Loss/tok 2.9512 (3.1736)	Learning Rate [7.8125e-05]
3: TRAIN [3][2610/6832]	Time 0.089 (0.105)	Data 0.00084 (0.00094)	Tok/s 54370 (59932)	Loss/tok 2.9403 (3.1662)	Learning Rate [7.8125e-05]
2: TRAIN [3][2610/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00096)	Tok/s 54361 (59482)	Loss/tok 3.1053 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][2620/6832]	Time 0.125 (0.105)	Data 0.00094 (0.00089)	Tok/s 62254 (59133)	Loss/tok 3.2618 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2620/6832]	Time 0.125 (0.105)	Data 0.00100 (0.00096)	Tok/s 61537 (58691)	Loss/tok 3.2773 (3.1736)	Learning Rate [7.8125e-05]
2: TRAIN [3][2620/6832]	Time 0.125 (0.105)	Data 0.00097 (0.00096)	Tok/s 62486 (59491)	Loss/tok 3.2018 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][2620/6832]	Time 0.125 (0.105)	Data 0.00094 (0.00094)	Tok/s 62498 (59941)	Loss/tok 3.0959 (3.1659)	Learning Rate [7.8125e-05]
2: TRAIN [3][2630/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00096)	Tok/s 54312 (59506)	Loss/tok 3.2238 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][2630/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00089)	Tok/s 54216 (59148)	Loss/tok 3.1973 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][2630/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 54335 (59954)	Loss/tok 3.0782 (3.1662)	Learning Rate [7.8125e-05]
0: TRAIN [3][2630/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00096)	Tok/s 54245 (58706)	Loss/tok 3.4071 (3.1740)	Learning Rate [7.8125e-05]
1: TRAIN [3][2640/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00089)	Tok/s 70250 (59147)	Loss/tok 3.2556 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][2640/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00096)	Tok/s 70293 (59504)	Loss/tok 3.3568 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][2640/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 71008 (59952)	Loss/tok 3.2885 (3.1666)	Learning Rate [7.8125e-05]
0: TRAIN [3][2640/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00096)	Tok/s 70291 (58706)	Loss/tok 3.3961 (3.1741)	Learning Rate [7.8125e-05]
2: TRAIN [3][2650/6832]	Time 0.046 (0.105)	Data 0.00087 (0.00096)	Tok/s 47075 (59473)	Loss/tok 2.4182 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][2650/6832]	Time 0.046 (0.105)	Data 0.00086 (0.00089)	Tok/s 44349 (59114)	Loss/tok 2.3391 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][2650/6832]	Time 0.046 (0.105)	Data 0.00083 (0.00094)	Tok/s 48720 (59922)	Loss/tok 2.4974 (3.1662)	Learning Rate [7.8125e-05]
0: TRAIN [3][2650/6832]	Time 0.046 (0.105)	Data 0.00095 (0.00096)	Tok/s 41849 (58669)	Loss/tok 2.2008 (3.1738)	Learning Rate [7.8125e-05]
1: TRAIN [3][2660/6832]	Time 0.053 (0.105)	Data 0.00091 (0.00089)	Tok/s 49950 (59117)	Loss/tok 2.6883 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][2660/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00096)	Tok/s 51117 (59476)	Loss/tok 2.5392 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][2660/6832]	Time 0.053 (0.105)	Data 0.00096 (0.00096)	Tok/s 48678 (58673)	Loss/tok 2.5093 (3.1736)	Learning Rate [7.8125e-05]
3: TRAIN [3][2660/6832]	Time 0.053 (0.105)	Data 0.00086 (0.00094)	Tok/s 51080 (59925)	Loss/tok 2.5826 (3.1662)	Learning Rate [7.8125e-05]
2: TRAIN [3][2670/6832]	Time 0.059 (0.105)	Data 0.00090 (0.00096)	Tok/s 51135 (59466)	Loss/tok 2.8598 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][2670/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00094)	Tok/s 52400 (59915)	Loss/tok 2.7762 (3.1660)	Learning Rate [7.8125e-05]
1: TRAIN [3][2670/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00089)	Tok/s 50137 (59106)	Loss/tok 2.7505 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][2670/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00096)	Tok/s 50137 (58664)	Loss/tok 2.8004 (3.1736)	Learning Rate [7.8125e-05]
2: TRAIN [3][2680/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00096)	Tok/s 81363 (59473)	Loss/tok 3.2303 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][2680/6832]	Time 0.132 (0.105)	Data 0.00083 (0.00094)	Tok/s 82161 (59922)	Loss/tok 3.2907 (3.1662)	Learning Rate [7.8125e-05]
1: TRAIN [3][2680/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00089)	Tok/s 81286 (59113)	Loss/tok 3.1277 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][2680/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00096)	Tok/s 80747 (58670)	Loss/tok 3.3487 (3.1737)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
2: TRAIN [3][2690/6832]	Time 0.081 (0.105)	Data 0.00091 (0.00096)	Tok/s 53598 (59497)	Loss/tok 3.0624 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][2690/6832]	Time 0.081 (0.105)	Data 0.00086 (0.00089)	Tok/s 52258 (59137)	Loss/tok 2.9997 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][2690/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00094)	Tok/s 53585 (59947)	Loss/tok 3.0036 (3.1663)	Learning Rate [7.8125e-05]
0: TRAIN [3][2690/6832]	Time 0.081 (0.105)	Data 0.00088 (0.00096)	Tok/s 51931 (58696)	Loss/tok 2.9540 (3.1739)	Learning Rate [7.8125e-05]
1: TRAIN [3][2700/6832]	Time 0.091 (0.105)	Data 0.00091 (0.00089)	Tok/s 52727 (59130)	Loss/tok 3.1671 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][2700/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00094)	Tok/s 53704 (59939)	Loss/tok 3.0071 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][2700/6832]	Time 0.091 (0.105)	Data 0.00097 (0.00096)	Tok/s 52324 (58690)	Loss/tok 3.2196 (3.1740)	Learning Rate [7.8125e-05]
2: TRAIN [3][2700/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00096)	Tok/s 53692 (59491)	Loss/tok 3.0576 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][2710/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00089)	Tok/s 71683 (59155)	Loss/tok 3.2227 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2710/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00096)	Tok/s 71628 (58714)	Loss/tok 3.2992 (3.1741)	Learning Rate [7.8125e-05]
3: TRAIN [3][2710/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00094)	Tok/s 72578 (59964)	Loss/tok 3.1431 (3.1665)	Learning Rate [7.8125e-05]
2: TRAIN [3][2710/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 72577 (59515)	Loss/tok 3.4603 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][2720/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00096)	Tok/s 61874 (59496)	Loss/tok 3.2557 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][2720/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00089)	Tok/s 61869 (59134)	Loss/tok 3.1571 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][2720/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00094)	Tok/s 61869 (59946)	Loss/tok 3.4779 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][2720/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00096)	Tok/s 61710 (58689)	Loss/tok 3.3726 (3.1741)	Learning Rate [7.8125e-05]
2: TRAIN [3][2730/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00096)	Tok/s 58182 (59473)	Loss/tok 3.0258 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][2730/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00089)	Tok/s 57519 (59112)	Loss/tok 3.0624 (3.1671)	Learning Rate [7.8125e-05]
3: TRAIN [3][2730/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00094)	Tok/s 57699 (59923)	Loss/tok 3.4468 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [3][2730/6832]	Time 0.118 (0.105)	Data 0.00104 (0.00096)	Tok/s 57555 (58669)	Loss/tok 3.3751 (3.1739)	Learning Rate [7.8125e-05]
2: TRAIN [3][2740/6832]	Time 0.133 (0.105)	Data 0.00102 (0.00096)	Tok/s 71378 (59476)	Loss/tok 3.2868 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2740/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00089)	Tok/s 70629 (59115)	Loss/tok 3.4254 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][2740/6832]	Time 0.133 (0.105)	Data 0.00095 (0.00094)	Tok/s 71400 (59925)	Loss/tok 3.2325 (3.1665)	Learning Rate [7.8125e-05]
0: TRAIN [3][2740/6832]	Time 0.133 (0.105)	Data 0.00093 (0.00096)	Tok/s 70414 (58672)	Loss/tok 3.2001 (3.1739)	Learning Rate [7.8125e-05]
1: TRAIN [3][2750/6832]	Time 0.063 (0.105)	Data 0.00087 (0.00089)	Tok/s 51006 (59129)	Loss/tok 2.7455 (3.1672)	Learning Rate [7.8125e-05]
2: TRAIN [3][2750/6832]	Time 0.063 (0.105)	Data 0.00091 (0.00096)	Tok/s 51599 (59490)	Loss/tok 2.7140 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][2750/6832]	Time 0.063 (0.105)	Data 0.00091 (0.00096)	Tok/s 51027 (58687)	Loss/tok 2.7991 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2750/6832]	Time 0.063 (0.105)	Data 0.00085 (0.00094)	Tok/s 53031 (59939)	Loss/tok 2.9530 (3.1666)	Learning Rate [7.8125e-05]
1: TRAIN [3][2760/6832]	Time 0.086 (0.105)	Data 0.00084 (0.00089)	Tok/s 55354 (59126)	Loss/tok 3.1052 (3.1671)	Learning Rate [7.8125e-05]
2: TRAIN [3][2760/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00096)	Tok/s 56360 (59487)	Loss/tok 2.9808 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][2760/6832]	Time 0.086 (0.105)	Data 0.00092 (0.00096)	Tok/s 54826 (58683)	Loss/tok 3.0557 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2760/6832]	Time 0.086 (0.105)	Data 0.00087 (0.00094)	Tok/s 56354 (59934)	Loss/tok 3.0303 (3.1667)	Learning Rate [7.8125e-05]
2: TRAIN [3][2770/6832]	Time 0.080 (0.105)	Data 0.00092 (0.00096)	Tok/s 52831 (59480)	Loss/tok 2.8412 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2770/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00089)	Tok/s 52774 (59119)	Loss/tok 2.9895 (3.1670)	Learning Rate [7.8125e-05]
3: TRAIN [3][2770/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00094)	Tok/s 52835 (59927)	Loss/tok 3.0651 (3.1667)	Learning Rate [7.8125e-05]
0: TRAIN [3][2770/6832]	Time 0.080 (0.105)	Data 0.00098 (0.00096)	Tok/s 51855 (58677)	Loss/tok 3.1507 (3.1738)	Learning Rate [7.8125e-05]
2: TRAIN [3][2780/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00096)	Tok/s 53576 (59465)	Loss/tok 3.1663 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][2780/6832]	Time 0.112 (0.105)	Data 0.00098 (0.00089)	Tok/s 52630 (59104)	Loss/tok 3.2063 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][2780/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00094)	Tok/s 53758 (59912)	Loss/tok 3.2141 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [3][2780/6832]	Time 0.112 (0.105)	Data 0.00107 (0.00096)	Tok/s 52623 (58663)	Loss/tok 3.1898 (3.1739)	Learning Rate [7.8125e-05]
2: TRAIN [3][2790/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00096)	Tok/s 54241 (59469)	Loss/tok 3.1883 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2790/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00089)	Tok/s 54240 (59109)	Loss/tok 3.2412 (3.1676)	Learning Rate [7.8125e-05]
3: TRAIN [3][2790/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00094)	Tok/s 54237 (59915)	Loss/tok 3.0717 (3.1671)	Learning Rate [7.8125e-05]
0: TRAIN [3][2790/6832]	Time 0.118 (0.105)	Data 0.00106 (0.00096)	Tok/s 54245 (58668)	Loss/tok 3.1845 (3.1739)	Learning Rate [7.8125e-05]
2: TRAIN [3][2800/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00096)	Tok/s 60783 (59471)	Loss/tok 3.3344 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2800/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00089)	Tok/s 60817 (59111)	Loss/tok 3.2651 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][2800/6832]	Time 0.124 (0.105)	Data 0.00097 (0.00096)	Tok/s 60267 (58669)	Loss/tok 3.1590 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2800/6832]	Time 0.126 (0.105)	Data 0.00084 (0.00094)	Tok/s 60084 (59917)	Loss/tok 3.3125 (3.1669)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][2810/6832]	Time 0.130 (0.105)	Data 0.00126 (0.00096)	Tok/s 75031 (59474)	Loss/tok 3.1728 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2810/6832]	Time 0.130 (0.105)	Data 0.00107 (0.00089)	Tok/s 74710 (59114)	Loss/tok 3.4494 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2810/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00096)	Tok/s 74985 (58673)	Loss/tok 3.2772 (3.1738)	Learning Rate [7.8125e-05]
3: TRAIN [3][2810/6832]	Time 0.130 (0.105)	Data 0.00133 (0.00094)	Tok/s 75670 (59921)	Loss/tok 3.2992 (3.1670)	Learning Rate [7.8125e-05]
2: TRAIN [3][2820/6832]	Time 0.120 (0.105)	Data 0.00096 (0.00096)	Tok/s 62778 (59468)	Loss/tok 3.1778 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][2820/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00089)	Tok/s 62733 (59105)	Loss/tok 3.2742 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][2820/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00094)	Tok/s 62761 (59917)	Loss/tok 3.2429 (3.1669)	Learning Rate [7.8125e-05]
0: TRAIN [3][2820/6832]	Time 0.120 (0.105)	Data 0.00096 (0.00096)	Tok/s 62227 (58654)	Loss/tok 3.0556 (3.1735)	Learning Rate [7.8125e-05]
2: TRAIN [3][2830/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00096)	Tok/s 59790 (59487)	Loss/tok 3.2036 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][2830/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00089)	Tok/s 59759 (59123)	Loss/tok 3.4568 (3.1673)	Learning Rate [7.8125e-05]
3: TRAIN [3][2830/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00094)	Tok/s 59788 (59936)	Loss/tok 3.2784 (3.1669)	Learning Rate [7.8125e-05]
0: TRAIN [3][2830/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00096)	Tok/s 59100 (58673)	Loss/tok 3.3220 (3.1734)	Learning Rate [7.8125e-05]
1: TRAIN [3][2840/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00089)	Tok/s 55440 (59129)	Loss/tok 3.1801 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][2840/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00096)	Tok/s 55424 (59493)	Loss/tok 3.2645 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2840/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00096)	Tok/s 55470 (58679)	Loss/tok 3.3432 (3.1734)	Learning Rate [7.8125e-05]
3: TRAIN [3][2840/6832]	Time 0.120 (0.105)	Data 0.00083 (0.00094)	Tok/s 55426 (59941)	Loss/tok 3.2524 (3.1671)	Learning Rate [7.8125e-05]
2: TRAIN [3][2850/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00096)	Tok/s 71699 (59506)	Loss/tok 3.3400 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][2850/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00089)	Tok/s 71468 (59140)	Loss/tok 3.3649 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][2850/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00096)	Tok/s 70736 (58687)	Loss/tok 3.3764 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2850/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 71699 (59955)	Loss/tok 3.3388 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][2860/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00096)	Tok/s 54154 (59507)	Loss/tok 3.0113 (3.1682)	Learning Rate [7.8125e-05]
3: TRAIN [3][2860/6832]	Time 0.080 (0.105)	Data 0.00088 (0.00094)	Tok/s 54179 (59954)	Loss/tok 2.9937 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][2860/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00096)	Tok/s 54051 (58690)	Loss/tok 2.9061 (3.1740)	Learning Rate [7.8125e-05]
1: TRAIN [3][2860/6832]	Time 0.081 (0.105)	Data 0.00086 (0.00089)	Tok/s 54058 (59142)	Loss/tok 2.9022 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][2870/6832]	Time 0.058 (0.105)	Data 0.00097 (0.00089)	Tok/s 50557 (59154)	Loss/tok 2.7579 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][2870/6832]	Time 0.058 (0.105)	Data 0.00099 (0.00096)	Tok/s 50473 (59519)	Loss/tok 2.7529 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][2870/6832]	Time 0.058 (0.105)	Data 0.00106 (0.00096)	Tok/s 50529 (58702)	Loss/tok 2.7154 (3.1740)	Learning Rate [7.8125e-05]
3: TRAIN [3][2870/6832]	Time 0.058 (0.105)	Data 0.00098 (0.00094)	Tok/s 51604 (59967)	Loss/tok 2.8336 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][2880/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00089)	Tok/s 52478 (59143)	Loss/tok 3.1782 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][2880/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00096)	Tok/s 52434 (59508)	Loss/tok 3.2503 (3.1682)	Learning Rate [7.8125e-05]
3: TRAIN [3][2880/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00094)	Tok/s 52441 (59954)	Loss/tok 3.1914 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2880/6832]	Time 0.117 (0.105)	Data 0.00100 (0.00096)	Tok/s 52470 (58692)	Loss/tok 3.2663 (3.1739)	Learning Rate [7.8125e-05]
1: TRAIN [3][2890/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00089)	Tok/s 77375 (59149)	Loss/tok 3.3066 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][2890/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00096)	Tok/s 77859 (59514)	Loss/tok 3.1782 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][2890/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00094)	Tok/s 78352 (59960)	Loss/tok 3.2351 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][2890/6832]	Time 0.131 (0.105)	Data 0.00114 (0.00096)	Tok/s 77350 (58698)	Loss/tok 3.1128 (3.1739)	Learning Rate [7.8125e-05]
2: TRAIN [3][2900/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00096)	Tok/s 67710 (59521)	Loss/tok 3.3031 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][2900/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00089)	Tok/s 67692 (59156)	Loss/tok 3.2704 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][2900/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00096)	Tok/s 67713 (58707)	Loss/tok 3.2790 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2900/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 68023 (59966)	Loss/tok 3.3172 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][2910/6832]	Time 0.041 (0.105)	Data 0.00090 (0.00096)	Tok/s 40778 (59503)	Loss/tok 2.0894 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2910/6832]	Time 0.041 (0.105)	Data 0.00095 (0.00089)	Tok/s 36043 (59137)	Loss/tok 1.9419 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][2910/6832]	Time 0.041 (0.105)	Data 0.00102 (0.00096)	Tok/s 23377 (58683)	Loss/tok 1.7331 (3.1737)	Learning Rate [7.8125e-05]
3: TRAIN [3][2910/6832]	Time 0.041 (0.105)	Data 0.00090 (0.00094)	Tok/s 43722 (59949)	Loss/tok 2.2477 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][2920/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00089)	Tok/s 53460 (59122)	Loss/tok 2.9202 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][2920/6832]	Time 0.084 (0.105)	Data 0.00088 (0.00096)	Tok/s 53469 (59488)	Loss/tok 2.9741 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][2920/6832]	Time 0.084 (0.105)	Data 0.00099 (0.00096)	Tok/s 53468 (58668)	Loss/tok 3.2895 (3.1737)	Learning Rate [7.8125e-05]
3: TRAIN [3][2920/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00094)	Tok/s 53499 (59933)	Loss/tok 2.9814 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][2930/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00089)	Tok/s 67914 (59147)	Loss/tok 3.2944 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][2930/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00096)	Tok/s 67927 (59512)	Loss/tok 3.2343 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][2930/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00096)	Tok/s 67382 (58693)	Loss/tok 3.3077 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2930/6832]	Time 0.130 (0.105)	Data 0.00111 (0.00094)	Tok/s 68079 (59957)	Loss/tok 3.3827 (3.1679)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][2940/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00096)	Tok/s 53356 (59534)	Loss/tok 3.1192 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2940/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00089)	Tok/s 53357 (59169)	Loss/tok 3.0188 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][2940/6832]	Time 0.091 (0.105)	Data 0.00101 (0.00096)	Tok/s 52318 (58715)	Loss/tok 3.2784 (3.1741)	Learning Rate [7.8125e-05]
3: TRAIN [3][2940/6832]	Time 0.091 (0.105)	Data 0.00089 (0.00094)	Tok/s 53366 (59979)	Loss/tok 3.1583 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][2950/6832]	Time 0.044 (0.105)	Data 0.00107 (0.00096)	Tok/s 37698 (59521)	Loss/tok 1.8526 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][2950/6832]	Time 0.044 (0.105)	Data 0.00135 (0.00094)	Tok/s 41524 (59967)	Loss/tok 2.3512 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][2950/6832]	Time 0.044 (0.105)	Data 0.00111 (0.00096)	Tok/s 20705 (58698)	Loss/tok 1.7495 (3.1741)	Learning Rate [7.8125e-05]
1: TRAIN [3][2950/6832]	Time 0.046 (0.105)	Data 0.00105 (0.00089)	Tok/s 31396 (59155)	Loss/tok 2.0525 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][2960/6832]	Time 0.055 (0.105)	Data 0.00091 (0.00096)	Tok/s 49312 (59503)	Loss/tok 2.6128 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][2960/6832]	Time 0.055 (0.105)	Data 0.00091 (0.00089)	Tok/s 47705 (59135)	Loss/tok 2.8551 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][2960/6832]	Time 0.054 (0.105)	Data 0.00087 (0.00094)	Tok/s 49367 (59947)	Loss/tok 2.7048 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][2960/6832]	Time 0.055 (0.105)	Data 0.00099 (0.00096)	Tok/s 46841 (58679)	Loss/tok 2.6055 (3.1738)	Learning Rate [7.8125e-05]
1: TRAIN [3][2970/6832]	Time 0.063 (0.105)	Data 0.00086 (0.00089)	Tok/s 52949 (59137)	Loss/tok 2.9459 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][2970/6832]	Time 0.063 (0.105)	Data 0.00090 (0.00096)	Tok/s 52998 (59504)	Loss/tok 2.9600 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][2970/6832]	Time 0.063 (0.105)	Data 0.00097 (0.00096)	Tok/s 52921 (58681)	Loss/tok 2.8845 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][2970/6832]	Time 0.063 (0.105)	Data 0.00093 (0.00094)	Tok/s 53047 (59948)	Loss/tok 2.9243 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][2980/6832]	Time 0.093 (0.105)	Data 0.00094 (0.00096)	Tok/s 52523 (59489)	Loss/tok 3.0295 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][2980/6832]	Time 0.093 (0.105)	Data 0.00093 (0.00094)	Tok/s 53900 (59933)	Loss/tok 3.0683 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][2980/6832]	Time 0.093 (0.105)	Data 0.00102 (0.00096)	Tok/s 52528 (58666)	Loss/tok 3.2045 (3.1739)	Learning Rate [7.8125e-05]
1: TRAIN [3][2980/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00089)	Tok/s 52499 (59122)	Loss/tok 3.0060 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][2990/6832]	Time 0.072 (0.105)	Data 0.00086 (0.00096)	Tok/s 51410 (59483)	Loss/tok 3.1570 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][2990/6832]	Time 0.072 (0.105)	Data 0.00106 (0.00096)	Tok/s 51454 (58661)	Loss/tok 3.0557 (3.1741)	Learning Rate [7.8125e-05]
3: TRAIN [3][2990/6832]	Time 0.072 (0.105)	Data 0.00103 (0.00094)	Tok/s 51427 (59926)	Loss/tok 2.9943 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][2990/6832]	Time 0.072 (0.105)	Data 0.00132 (0.00089)	Tok/s 51429 (59116)	Loss/tok 2.9088 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][3000/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00096)	Tok/s 54216 (59481)	Loss/tok 3.1846 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][3000/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00096)	Tok/s 52942 (58660)	Loss/tok 3.1473 (3.1739)	Learning Rate [7.8125e-05]
3: TRAIN [3][3000/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00094)	Tok/s 54237 (59925)	Loss/tok 3.1468 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][3000/6832]	Time 0.104 (0.105)	Data 0.00114 (0.00089)	Tok/s 54106 (59115)	Loss/tok 3.2020 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][3010/6832]	Time 0.043 (0.105)	Data 0.00093 (0.00094)	Tok/s 42215 (59921)	Loss/tok 2.2350 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3010/6832]	Time 0.043 (0.105)	Data 0.00090 (0.00096)	Tok/s 22187 (58649)	Loss/tok 1.6359 (3.1737)	Learning Rate [7.8125e-05]
2: TRAIN [3][3010/6832]	Time 0.044 (0.105)	Data 0.00108 (0.00096)	Tok/s 38087 (59477)	Loss/tok 1.9447 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][3010/6832]	Time 0.043 (0.105)	Data 0.00117 (0.00089)	Tok/s 34018 (59109)	Loss/tok 2.2208 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][3020/6832]	Time 0.115 (0.105)	Data 0.00096 (0.00096)	Tok/s 52223 (59473)	Loss/tok 3.3180 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][3020/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00096)	Tok/s 52162 (58646)	Loss/tok 2.9894 (3.1735)	Learning Rate [7.8125e-05]
3: TRAIN [3][3020/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00094)	Tok/s 52216 (59918)	Loss/tok 3.2752 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][3020/6832]	Time 0.115 (0.105)	Data 0.00107 (0.00090)	Tok/s 52163 (59105)	Loss/tok 3.3232 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][3030/6832]	Time 0.107 (0.105)	Data 0.00087 (0.00096)	Tok/s 52233 (59453)	Loss/tok 3.1926 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][3030/6832]	Time 0.107 (0.105)	Data 0.00105 (0.00090)	Tok/s 51435 (59085)	Loss/tok 3.1979 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][3030/6832]	Time 0.107 (0.105)	Data 0.00091 (0.00094)	Tok/s 52678 (59900)	Loss/tok 2.8816 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][3030/6832]	Time 0.107 (0.105)	Data 0.00095 (0.00096)	Tok/s 51429 (58622)	Loss/tok 3.1215 (3.1733)	Learning Rate [7.8125e-05]
2: TRAIN [3][3040/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00096)	Tok/s 53431 (59471)	Loss/tok 3.1558 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3040/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00096)	Tok/s 53396 (58639)	Loss/tok 3.2201 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][3040/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00094)	Tok/s 53433 (59919)	Loss/tok 3.0917 (3.1672)	Learning Rate [7.8125e-05]
1: TRAIN [3][3040/6832]	Time 0.113 (0.105)	Data 0.00102 (0.00090)	Tok/s 53384 (59101)	Loss/tok 3.3497 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3050/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00096)	Tok/s 79458 (59460)	Loss/tok 3.1540 (3.1676)	Learning Rate [7.8125e-05]
3: TRAIN [3][3050/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 79664 (59909)	Loss/tok 3.3249 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][3050/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00096)	Tok/s 78476 (58623)	Loss/tok 3.1716 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][3050/6832]	Time 0.131 (0.105)	Data 0.00112 (0.00090)	Tok/s 79034 (59089)	Loss/tok 3.2274 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3060/6832]	Time 0.120 (0.105)	Data 0.00084 (0.00096)	Tok/s 55320 (59467)	Loss/tok 3.0923 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][3060/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 55347 (59915)	Loss/tok 3.1583 (3.1669)	Learning Rate [7.8125e-05]
0: TRAIN [3][3060/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00096)	Tok/s 55335 (58629)	Loss/tok 3.1027 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][3060/6832]	Time 0.120 (0.105)	Data 0.00102 (0.00090)	Tok/s 55292 (59094)	Loss/tok 3.0382 (3.1682)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][3070/6832]	Time 0.125 (0.105)	Data 0.00090 (0.00096)	Tok/s 62436 (59480)	Loss/tok 3.1515 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][3070/6832]	Time 0.125 (0.105)	Data 0.00089 (0.00096)	Tok/s 61311 (58642)	Loss/tok 3.1674 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][3070/6832]	Time 0.125 (0.105)	Data 0.00104 (0.00090)	Tok/s 61377 (59108)	Loss/tok 3.3099 (3.1682)	Learning Rate [7.8125e-05]
3: TRAIN [3][3070/6832]	Time 0.127 (0.105)	Data 0.00098 (0.00094)	Tok/s 61579 (59928)	Loss/tok 3.2762 (3.1672)	Learning Rate [7.8125e-05]
2: TRAIN [3][3080/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00096)	Tok/s 62386 (59469)	Loss/tok 3.3216 (3.1673)	Learning Rate [7.8125e-05]
3: TRAIN [3][3080/6832]	Time 0.123 (0.105)	Data 0.00100 (0.00094)	Tok/s 62396 (59917)	Loss/tok 3.2145 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][3080/6832]	Time 0.123 (0.105)	Data 0.00096 (0.00096)	Tok/s 61372 (58627)	Loss/tok 3.3867 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][3080/6832]	Time 0.123 (0.105)	Data 0.00104 (0.00090)	Tok/s 61523 (59095)	Loss/tok 3.3600 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][3090/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00096)	Tok/s 66469 (59494)	Loss/tok 3.2437 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3090/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00096)	Tok/s 66310 (58654)	Loss/tok 3.3461 (3.1737)	Learning Rate [7.8125e-05]
3: TRAIN [3][3090/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 66488 (59942)	Loss/tok 3.2857 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][3090/6832]	Time 0.129 (0.105)	Data 0.00114 (0.00090)	Tok/s 66383 (59121)	Loss/tok 3.3994 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3100/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00096)	Tok/s 58647 (59488)	Loss/tok 3.2374 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][3100/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00094)	Tok/s 59726 (59935)	Loss/tok 3.1447 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][3100/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00096)	Tok/s 58611 (58648)	Loss/tok 3.0461 (3.1735)	Learning Rate [7.8125e-05]
1: TRAIN [3][3100/6832]	Time 0.116 (0.105)	Data 0.00116 (0.00090)	Tok/s 58639 (59115)	Loss/tok 3.1756 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][3110/6832]	Time 0.100 (0.105)	Data 0.00092 (0.00096)	Tok/s 52477 (59485)	Loss/tok 3.1879 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][3110/6832]	Time 0.100 (0.105)	Data 0.00100 (0.00096)	Tok/s 52498 (58647)	Loss/tok 3.1548 (3.1735)	Learning Rate [7.8125e-05]
3: TRAIN [3][3110/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00094)	Tok/s 53121 (59932)	Loss/tok 3.2834 (3.1674)	Learning Rate [7.8125e-05]
1: TRAIN [3][3110/6832]	Time 0.100 (0.105)	Data 0.00110 (0.00090)	Tok/s 52606 (59113)	Loss/tok 2.9640 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][3120/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00096)	Tok/s 60531 (59484)	Loss/tok 3.2576 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][3120/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00096)	Tok/s 59777 (58644)	Loss/tok 3.2510 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][3120/6832]	Time 0.118 (0.105)	Data 0.00099 (0.00094)	Tok/s 60546 (59931)	Loss/tok 3.3998 (3.1673)	Learning Rate [7.8125e-05]
1: TRAIN [3][3120/6832]	Time 0.118 (0.105)	Data 0.00105 (0.00090)	Tok/s 60540 (59112)	Loss/tok 3.2715 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3130/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00096)	Tok/s 88906 (59480)	Loss/tok 2.9862 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][3130/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00090)	Tok/s 88380 (59108)	Loss/tok 2.9832 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][3130/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 89790 (59927)	Loss/tok 3.1883 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][3130/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 87781 (58641)	Loss/tok 3.1565 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][3140/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00096)	Tok/s 76894 (59516)	Loss/tok 3.1890 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][3140/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 77504 (59964)	Loss/tok 3.4227 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][3140/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00096)	Tok/s 75970 (58676)	Loss/tok 3.1935 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][3140/6832]	Time 0.131 (0.105)	Data 0.00112 (0.00090)	Tok/s 76907 (59144)	Loss/tok 3.2173 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3150/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00096)	Tok/s 80334 (59505)	Loss/tok 3.0634 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][3150/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 79822 (58666)	Loss/tok 3.1095 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][3150/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 81005 (59953)	Loss/tok 3.2625 (3.1672)	Learning Rate [7.8125e-05]
1: TRAIN [3][3150/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00090)	Tok/s 80047 (59133)	Loss/tok 3.1244 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][3160/6832]	Time 0.069 (0.105)	Data 0.00086 (0.00096)	Tok/s 51959 (59503)	Loss/tok 2.7544 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][3160/6832]	Time 0.069 (0.105)	Data 0.00091 (0.00094)	Tok/s 51976 (59950)	Loss/tok 2.8214 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][3160/6832]	Time 0.069 (0.105)	Data 0.00087 (0.00096)	Tok/s 51599 (58666)	Loss/tok 2.8517 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][3160/6832]	Time 0.069 (0.105)	Data 0.00109 (0.00090)	Tok/s 51959 (59132)	Loss/tok 2.7111 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][3170/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00096)	Tok/s 52675 (59505)	Loss/tok 3.1463 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][3170/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00096)	Tok/s 51783 (58669)	Loss/tok 3.0424 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][3170/6832]	Time 0.104 (0.105)	Data 0.00093 (0.00094)	Tok/s 53051 (59953)	Loss/tok 3.2585 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][3170/6832]	Time 0.104 (0.105)	Data 0.00109 (0.00090)	Tok/s 51822 (59134)	Loss/tok 3.0635 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3180/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00096)	Tok/s 59911 (59524)	Loss/tok 3.1772 (3.1673)	Learning Rate [7.8125e-05]
0: TRAIN [3][3180/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00096)	Tok/s 59951 (58688)	Loss/tok 3.2225 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3180/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00094)	Tok/s 59925 (59972)	Loss/tok 3.3285 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][3180/6832]	Time 0.115 (0.105)	Data 0.00104 (0.00090)	Tok/s 59954 (59153)	Loss/tok 3.3203 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][3190/6832]	Time 0.096 (0.105)	Data 0.00105 (0.00096)	Tok/s 53193 (59509)	Loss/tok 3.1123 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][3190/6832]	Time 0.096 (0.105)	Data 0.00103 (0.00094)	Tok/s 53191 (59955)	Loss/tok 3.0348 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][3190/6832]	Time 0.096 (0.105)	Data 0.00095 (0.00096)	Tok/s 53141 (58674)	Loss/tok 3.2615 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][3190/6832]	Time 0.096 (0.105)	Data 0.00103 (0.00090)	Tok/s 53168 (59138)	Loss/tok 3.1556 (3.1681)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: TRAIN [3][3200/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00096)	Tok/s 54752 (58687)	Loss/tok 2.8707 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][3200/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00096)	Tok/s 55683 (59521)	Loss/tok 3.1054 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][3200/6832]	Time 0.077 (0.105)	Data 0.00088 (0.00094)	Tok/s 56354 (59969)	Loss/tok 3.1155 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][3200/6832]	Time 0.077 (0.105)	Data 0.00110 (0.00090)	Tok/s 54707 (59150)	Loss/tok 3.0156 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][3210/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00096)	Tok/s 53842 (58704)	Loss/tok 3.1984 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][3210/6832]	Time 0.098 (0.105)	Data 0.00085 (0.00096)	Tok/s 53759 (59537)	Loss/tok 2.9345 (3.1670)	Learning Rate [7.8125e-05]
3: TRAIN [3][3210/6832]	Time 0.098 (0.105)	Data 0.00088 (0.00094)	Tok/s 53754 (59986)	Loss/tok 2.9949 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][3210/6832]	Time 0.098 (0.105)	Data 0.00099 (0.00090)	Tok/s 53818 (59167)	Loss/tok 3.0983 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][3220/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00096)	Tok/s 55021 (59549)	Loss/tok 3.2463 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][3220/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 55804 (59999)	Loss/tok 3.2976 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3220/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00096)	Tok/s 54705 (58717)	Loss/tok 3.0996 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][3220/6832]	Time 0.117 (0.105)	Data 0.00108 (0.00090)	Tok/s 54677 (59179)	Loss/tok 3.1634 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3230/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00096)	Tok/s 65229 (59557)	Loss/tok 3.4323 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][3230/6832]	Time 0.132 (0.105)	Data 0.00121 (0.00090)	Tok/s 65184 (59187)	Loss/tok 3.0942 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][3230/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 66030 (60006)	Loss/tok 3.2249 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][3230/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00096)	Tok/s 65201 (58726)	Loss/tok 3.3348 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][3240/6832]	Time 0.096 (0.105)	Data 0.00085 (0.00096)	Tok/s 53576 (59565)	Loss/tok 3.0898 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][3240/6832]	Time 0.096 (0.105)	Data 0.00086 (0.00094)	Tok/s 54455 (60014)	Loss/tok 2.9436 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][3240/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00096)	Tok/s 53572 (58735)	Loss/tok 3.1545 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][3240/6832]	Time 0.096 (0.105)	Data 0.00105 (0.00091)	Tok/s 53570 (59195)	Loss/tok 3.1128 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3250/6832]	Time 0.085 (0.105)	Data 0.00091 (0.00096)	Tok/s 53957 (59570)	Loss/tok 3.0054 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][3250/6832]	Time 0.085 (0.105)	Data 0.00089 (0.00094)	Tok/s 53933 (60018)	Loss/tok 3.2212 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][3250/6832]	Time 0.085 (0.105)	Data 0.00090 (0.00096)	Tok/s 52421 (58741)	Loss/tok 3.0929 (3.1732)	Learning Rate [7.8125e-05]
1: TRAIN [3][3250/6832]	Time 0.085 (0.105)	Data 0.00104 (0.00091)	Tok/s 52495 (59200)	Loss/tok 2.9500 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][3260/6832]	Time 0.059 (0.105)	Data 0.00094 (0.00096)	Tok/s 52433 (59584)	Loss/tok 2.6914 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][3260/6832]	Time 0.059 (0.105)	Data 0.00096 (0.00096)	Tok/s 52268 (58756)	Loss/tok 2.9562 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3260/6832]	Time 0.059 (0.105)	Data 0.00091 (0.00094)	Tok/s 54491 (60033)	Loss/tok 2.8739 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][3260/6832]	Time 0.059 (0.105)	Data 0.00102 (0.00091)	Tok/s 52204 (59215)	Loss/tok 2.9759 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3270/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00096)	Tok/s 51791 (59583)	Loss/tok 3.0755 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][3270/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00094)	Tok/s 51767 (60031)	Loss/tok 3.1292 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][3270/6832]	Time 0.092 (0.105)	Data 0.00091 (0.00096)	Tok/s 51690 (58754)	Loss/tok 3.0900 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][3270/6832]	Time 0.092 (0.105)	Data 0.00109 (0.00091)	Tok/s 51689 (59213)	Loss/tok 3.0229 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3280/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00096)	Tok/s 63018 (59589)	Loss/tok 3.2911 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][3280/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 63953 (60036)	Loss/tok 3.3322 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][3280/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 63109 (58762)	Loss/tok 3.2663 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][3280/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00091)	Tok/s 63095 (59219)	Loss/tok 3.3650 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3290/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00096)	Tok/s 56191 (59596)	Loss/tok 3.3930 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][3290/6832]	Time 0.125 (0.105)	Data 0.00091 (0.00096)	Tok/s 56215 (58769)	Loss/tok 3.1848 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3290/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00094)	Tok/s 56183 (60042)	Loss/tok 3.3244 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][3290/6832]	Time 0.125 (0.105)	Data 0.00104 (0.00091)	Tok/s 56168 (59227)	Loss/tok 3.1870 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3300/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00096)	Tok/s 55660 (59585)	Loss/tok 3.3245 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][3300/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00094)	Tok/s 55664 (60031)	Loss/tok 2.9754 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][3300/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00096)	Tok/s 54586 (58760)	Loss/tok 3.1270 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][3300/6832]	Time 0.117 (0.105)	Data 0.00103 (0.00091)	Tok/s 55037 (59216)	Loss/tok 3.0063 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][3310/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00096)	Tok/s 62737 (59598)	Loss/tok 3.3022 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][3310/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00094)	Tok/s 62775 (60043)	Loss/tok 3.1441 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][3310/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00096)	Tok/s 61615 (58774)	Loss/tok 3.2158 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][3310/6832]	Time 0.116 (0.105)	Data 0.00121 (0.00091)	Tok/s 61735 (59230)	Loss/tok 3.2950 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][3320/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 60548 (59589)	Loss/tok 3.2195 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][3320/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 61452 (60035)	Loss/tok 3.3963 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][3320/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00096)	Tok/s 60408 (58767)	Loss/tok 3.3956 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][3320/6832]	Time 0.129 (0.105)	Data 0.00121 (0.00091)	Tok/s 60492 (59222)	Loss/tok 3.3470 (3.1684)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [3][3330/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00096)	Tok/s 88921 (59592)	Loss/tok 3.1012 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][3330/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00096)	Tok/s 87379 (58770)	Loss/tok 3.1627 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][3330/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00094)	Tok/s 89490 (60036)	Loss/tok 3.1491 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][3330/6832]	Time 0.132 (0.105)	Data 0.00110 (0.00091)	Tok/s 88048 (59224)	Loss/tok 3.0579 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3340/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00096)	Tok/s 52437 (59587)	Loss/tok 3.0874 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][3340/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00094)	Tok/s 52714 (60032)	Loss/tok 2.8083 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3340/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00096)	Tok/s 50952 (58764)	Loss/tok 2.8828 (3.1729)	Learning Rate [7.8125e-05]
1: TRAIN [3][3340/6832]	Time 0.075 (0.105)	Data 0.00104 (0.00091)	Tok/s 50940 (59219)	Loss/tok 2.9857 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][3350/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00094)	Tok/s 52163 (60021)	Loss/tok 3.1493 (3.1676)	Learning Rate [7.8125e-05]
2: TRAIN [3][3350/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00096)	Tok/s 52180 (59574)	Loss/tok 3.0318 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [3][3350/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00096)	Tok/s 52190 (58746)	Loss/tok 3.0590 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][3350/6832]	Time 0.088 (0.105)	Data 0.00104 (0.00091)	Tok/s 52163 (59204)	Loss/tok 3.1424 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][3360/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00096)	Tok/s 52402 (59557)	Loss/tok 3.3472 (3.1672)	Learning Rate [7.8125e-05]
3: TRAIN [3][3360/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00094)	Tok/s 53083 (60003)	Loss/tok 3.1388 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3360/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00096)	Tok/s 51958 (58729)	Loss/tok 3.2386 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][3360/6832]	Time 0.113 (0.105)	Data 0.00104 (0.00091)	Tok/s 51914 (59187)	Loss/tok 3.1764 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][3370/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00096)	Tok/s 55787 (59579)	Loss/tok 3.1961 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][3370/6832]	Time 0.117 (0.105)	Data 0.00099 (0.00096)	Tok/s 55801 (58751)	Loss/tok 3.2789 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][3370/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00094)	Tok/s 55786 (60024)	Loss/tok 3.3691 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][3370/6832]	Time 0.117 (0.105)	Data 0.00105 (0.00091)	Tok/s 55853 (59209)	Loss/tok 3.4267 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3380/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00096)	Tok/s 71484 (59574)	Loss/tok 3.3344 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][3380/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 71488 (60019)	Loss/tok 3.3626 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][3380/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00096)	Tok/s 70401 (58747)	Loss/tok 3.2167 (3.1728)	Learning Rate [7.8125e-05]
1: TRAIN [3][3380/6832]	Time 0.131 (0.105)	Data 0.00106 (0.00091)	Tok/s 70621 (59204)	Loss/tok 3.1816 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3390/6832]	Time 0.076 (0.105)	Data 0.00092 (0.00096)	Tok/s 53572 (59561)	Loss/tok 3.1704 (3.1674)	Learning Rate [7.8125e-05]
3: TRAIN [3][3390/6832]	Time 0.076 (0.105)	Data 0.00092 (0.00094)	Tok/s 53599 (60005)	Loss/tok 2.8680 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][3390/6832]	Time 0.076 (0.105)	Data 0.00091 (0.00096)	Tok/s 53549 (58734)	Loss/tok 2.7716 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][3390/6832]	Time 0.076 (0.105)	Data 0.00105 (0.00091)	Tok/s 53558 (59191)	Loss/tok 3.0337 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3400/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00096)	Tok/s 60114 (59567)	Loss/tok 3.5027 (3.1677)	Learning Rate [7.8125e-05]
3: TRAIN [3][3400/6832]	Time 0.121 (0.105)	Data 0.00087 (0.00094)	Tok/s 60089 (60012)	Loss/tok 3.3528 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][3400/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00096)	Tok/s 59028 (58742)	Loss/tok 3.2015 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][3400/6832]	Time 0.121 (0.105)	Data 0.00106 (0.00091)	Tok/s 59270 (59198)	Loss/tok 3.2872 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3410/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00096)	Tok/s 81637 (59577)	Loss/tok 3.1349 (3.1675)	Learning Rate [7.8125e-05]
3: TRAIN [3][3410/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 82234 (60022)	Loss/tok 3.2107 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][3410/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00096)	Tok/s 80255 (58752)	Loss/tok 3.1751 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][3410/6832]	Time 0.134 (0.105)	Data 0.00104 (0.00091)	Tok/s 80451 (59207)	Loss/tok 2.9690 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3420/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00096)	Tok/s 80539 (59585)	Loss/tok 3.1271 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [3][3420/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 79780 (58762)	Loss/tok 3.3033 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][3420/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 80913 (60030)	Loss/tok 3.0724 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][3420/6832]	Time 0.131 (0.105)	Data 0.00111 (0.00091)	Tok/s 79981 (59216)	Loss/tok 3.1838 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][3430/6832]	Time 0.086 (0.105)	Data 0.00083 (0.00096)	Tok/s 55040 (59593)	Loss/tok 3.0627 (3.1676)	Learning Rate [7.8125e-05]
3: TRAIN [3][3430/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00094)	Tok/s 55024 (60038)	Loss/tok 2.9824 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][3430/6832]	Time 0.086 (0.105)	Data 0.00090 (0.00096)	Tok/s 54933 (58772)	Loss/tok 2.8647 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][3430/6832]	Time 0.086 (0.105)	Data 0.00097 (0.00091)	Tok/s 54945 (59225)	Loss/tok 2.9478 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][3440/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00096)	Tok/s 59865 (59592)	Loss/tok 3.2954 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3440/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00096)	Tok/s 59763 (58771)	Loss/tok 3.2636 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][3440/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 59853 (60037)	Loss/tok 3.2559 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][3440/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00091)	Tok/s 59856 (59224)	Loss/tok 3.2021 (3.1683)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: TRAIN [3][3450/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00096)	Tok/s 68756 (58792)	Loss/tok 3.1615 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][3450/6832]	Time 0.130 (0.105)	Data 0.00127 (0.00096)	Tok/s 69234 (59611)	Loss/tok 3.3320 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][3450/6832]	Time 0.130 (0.105)	Data 0.00120 (0.00094)	Tok/s 69659 (60056)	Loss/tok 3.3316 (3.1691)	Learning Rate [7.8125e-05]
1: TRAIN [3][3450/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00091)	Tok/s 68793 (59244)	Loss/tok 3.3334 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3460/6832]	Time 0.082 (0.105)	Data 0.00091 (0.00096)	Tok/s 52981 (59604)	Loss/tok 3.1595 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][3460/6832]	Time 0.082 (0.105)	Data 0.00087 (0.00094)	Tok/s 52973 (60050)	Loss/tok 3.0869 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][3460/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00096)	Tok/s 52990 (58785)	Loss/tok 3.0206 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][3460/6832]	Time 0.082 (0.105)	Data 0.00100 (0.00091)	Tok/s 52879 (59237)	Loss/tok 2.9363 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3470/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00096)	Tok/s 55131 (59592)	Loss/tok 3.0985 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][3470/6832]	Time 0.084 (0.105)	Data 0.00094 (0.00094)	Tok/s 55152 (60038)	Loss/tok 2.9207 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3470/6832]	Time 0.084 (0.105)	Data 0.00094 (0.00096)	Tok/s 53601 (58774)	Loss/tok 3.1173 (3.1725)	Learning Rate [7.8125e-05]
1: TRAIN [3][3470/6832]	Time 0.084 (0.105)	Data 0.00103 (0.00091)	Tok/s 53811 (59225)	Loss/tok 2.8930 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][3480/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00096)	Tok/s 54943 (59588)	Loss/tok 3.1689 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][3480/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00094)	Tok/s 54915 (60034)	Loss/tok 3.0393 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][3480/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00096)	Tok/s 54915 (58771)	Loss/tok 3.3010 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][3480/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00091)	Tok/s 54905 (59222)	Loss/tok 3.2172 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3490/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00096)	Tok/s 92281 (59597)	Loss/tok 2.9163 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][3490/6832]	Time 0.133 (0.105)	Data 0.00095 (0.00096)	Tok/s 90144 (58780)	Loss/tok 2.9505 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][3490/6832]	Time 0.133 (0.105)	Data 0.00098 (0.00094)	Tok/s 94190 (60043)	Loss/tok 3.1245 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3490/6832]	Time 0.133 (0.105)	Data 0.00097 (0.00091)	Tok/s 91059 (59231)	Loss/tok 2.9254 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3500/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00096)	Tok/s 65945 (59618)	Loss/tok 3.2798 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][3500/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00094)	Tok/s 66208 (60063)	Loss/tok 3.1086 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][3500/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00096)	Tok/s 65994 (58801)	Loss/tok 3.3381 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][3500/6832]	Time 0.124 (0.105)	Data 0.00100 (0.00091)	Tok/s 65985 (59251)	Loss/tok 3.3470 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3510/6832]	Time 0.103 (0.105)	Data 0.00083 (0.00096)	Tok/s 53584 (59609)	Loss/tok 3.2782 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][3510/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00094)	Tok/s 53607 (60055)	Loss/tok 3.1174 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][3510/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00096)	Tok/s 53578 (58788)	Loss/tok 3.2629 (3.1728)	Learning Rate [7.8125e-05]
1: TRAIN [3][3510/6832]	Time 0.103 (0.105)	Data 0.00095 (0.00091)	Tok/s 53577 (59241)	Loss/tok 3.2543 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][3520/6832]	Time 0.077 (0.105)	Data 0.00084 (0.00096)	Tok/s 52993 (59600)	Loss/tok 3.1919 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][3520/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00094)	Tok/s 53040 (60044)	Loss/tok 2.8704 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3520/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00096)	Tok/s 53060 (58780)	Loss/tok 3.0397 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][3520/6832]	Time 0.077 (0.105)	Data 0.00102 (0.00091)	Tok/s 53005 (59233)	Loss/tok 2.9571 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3530/6832]	Time 0.109 (0.105)	Data 0.00082 (0.00096)	Tok/s 53080 (59598)	Loss/tok 3.1067 (3.1679)	Learning Rate [7.8125e-05]
3: TRAIN [3][3530/6832]	Time 0.108 (0.105)	Data 0.00089 (0.00094)	Tok/s 53103 (60042)	Loss/tok 3.2710 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][3530/6832]	Time 0.109 (0.105)	Data 0.00085 (0.00096)	Tok/s 53082 (58779)	Loss/tok 3.1602 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][3530/6832]	Time 0.108 (0.105)	Data 0.00097 (0.00091)	Tok/s 53098 (59232)	Loss/tok 3.1269 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][3540/6832]	Time 0.127 (0.105)	Data 0.00083 (0.00096)	Tok/s 64711 (59605)	Loss/tok 3.2444 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][3540/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00096)	Tok/s 64700 (58788)	Loss/tok 3.2045 (3.1727)	Learning Rate [7.8125e-05]
3: TRAIN [3][3540/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00094)	Tok/s 64713 (60050)	Loss/tok 3.1886 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][3540/6832]	Time 0.127 (0.105)	Data 0.00096 (0.00092)	Tok/s 64638 (59240)	Loss/tok 3.4795 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][3550/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00096)	Tok/s 55863 (58790)	Loss/tok 3.3695 (3.1726)	Learning Rate [7.8125e-05]
2: TRAIN [3][3550/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00096)	Tok/s 55818 (59607)	Loss/tok 3.1327 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][3550/6832]	Time 0.117 (0.105)	Data 0.00101 (0.00094)	Tok/s 56131 (60052)	Loss/tok 3.1459 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3550/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00092)	Tok/s 55926 (59242)	Loss/tok 3.1758 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][3560/6832]	Time 0.058 (0.105)	Data 0.00085 (0.00096)	Tok/s 50352 (59598)	Loss/tok 2.7081 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][3560/6832]	Time 0.058 (0.105)	Data 0.00088 (0.00096)	Tok/s 50337 (58781)	Loss/tok 2.6535 (3.1727)	Learning Rate [7.8125e-05]
3: TRAIN [3][3560/6832]	Time 0.058 (0.105)	Data 0.00089 (0.00094)	Tok/s 51802 (60043)	Loss/tok 2.7330 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3560/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00092)	Tok/s 50307 (59232)	Loss/tok 2.8066 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][3570/6832]	Time 0.102 (0.105)	Data 0.00086 (0.00096)	Tok/s 56708 (58794)	Loss/tok 2.8983 (3.1729)	Learning Rate [7.8125e-05]
2: TRAIN [3][3570/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00096)	Tok/s 56618 (59610)	Loss/tok 3.1113 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][3570/6832]	Time 0.102 (0.105)	Data 0.00086 (0.00094)	Tok/s 56603 (60055)	Loss/tok 3.2426 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3570/6832]	Time 0.102 (0.105)	Data 0.00103 (0.00092)	Tok/s 56688 (59245)	Loss/tok 3.0848 (3.1690)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [3][3580/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00096)	Tok/s 88413 (59619)	Loss/tok 3.1950 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][3580/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00095)	Tok/s 87151 (58802)	Loss/tok 3.0935 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][3580/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 89472 (60063)	Loss/tok 3.1071 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][3580/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00092)	Tok/s 87786 (59253)	Loss/tok 3.0986 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][3590/6832]	Time 0.062 (0.105)	Data 0.00084 (0.00096)	Tok/s 51386 (59621)	Loss/tok 2.8614 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][3590/6832]	Time 0.062 (0.105)	Data 0.00087 (0.00095)	Tok/s 51202 (58801)	Loss/tok 2.8609 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][3590/6832]	Time 0.062 (0.105)	Data 0.00087 (0.00094)	Tok/s 52771 (60067)	Loss/tok 3.0179 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3590/6832]	Time 0.063 (0.105)	Data 0.00095 (0.00092)	Tok/s 51044 (59254)	Loss/tok 2.9021 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][3600/6832]	Time 0.074 (0.105)	Data 0.00083 (0.00096)	Tok/s 53627 (59617)	Loss/tok 3.0267 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][3600/6832]	Time 0.074 (0.105)	Data 0.00084 (0.00094)	Tok/s 53657 (60062)	Loss/tok 2.9932 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3600/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00095)	Tok/s 51902 (58795)	Loss/tok 2.9351 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][3600/6832]	Time 0.074 (0.105)	Data 0.00097 (0.00092)	Tok/s 53020 (59250)	Loss/tok 3.0142 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][3610/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 70262 (59636)	Loss/tok 3.2415 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][3610/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00094)	Tok/s 71092 (60081)	Loss/tok 3.1686 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3610/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00095)	Tok/s 70127 (58816)	Loss/tok 3.2394 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][3610/6832]	Time 0.130 (0.105)	Data 0.00104 (0.00092)	Tok/s 70133 (59269)	Loss/tok 3.3331 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][3620/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00096)	Tok/s 63473 (59648)	Loss/tok 3.2857 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][3620/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00095)	Tok/s 63491 (58828)	Loss/tok 3.3149 (3.1734)	Learning Rate [7.8125e-05]
3: TRAIN [3][3620/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 64465 (60093)	Loss/tok 3.2928 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][3620/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00092)	Tok/s 63475 (59281)	Loss/tok 3.2753 (3.1695)	Learning Rate [7.8125e-05]
2: TRAIN [3][3630/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00095)	Tok/s 79269 (59639)	Loss/tok 3.3157 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][3630/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 78365 (58817)	Loss/tok 3.2061 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3630/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00094)	Tok/s 79296 (60085)	Loss/tok 3.2233 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][3630/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00092)	Tok/s 78615 (59270)	Loss/tok 3.2219 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][3640/6832]	Time 0.108 (0.105)	Data 0.00099 (0.00095)	Tok/s 53236 (59639)	Loss/tok 3.3202 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][3640/6832]	Time 0.108 (0.105)	Data 0.00097 (0.00095)	Tok/s 53152 (58817)	Loss/tok 3.2675 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3640/6832]	Time 0.108 (0.105)	Data 0.00106 (0.00094)	Tok/s 53200 (60085)	Loss/tok 3.1801 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3640/6832]	Time 0.108 (0.105)	Data 0.00111 (0.00092)	Tok/s 53129 (59270)	Loss/tok 3.1215 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][3650/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00095)	Tok/s 82025 (58833)	Loss/tok 3.3483 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][3650/6832]	Time 0.131 (0.105)	Data 0.00081 (0.00095)	Tok/s 82810 (59654)	Loss/tok 3.1530 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][3650/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00094)	Tok/s 83614 (60099)	Loss/tok 3.1628 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3650/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00092)	Tok/s 82116 (59285)	Loss/tok 3.1278 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][3660/6832]	Time 0.083 (0.105)	Data 0.00083 (0.00095)	Tok/s 52642 (59644)	Loss/tok 3.1379 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][3660/6832]	Time 0.082 (0.105)	Data 0.00096 (0.00095)	Tok/s 51707 (58823)	Loss/tok 2.9523 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3660/6832]	Time 0.082 (0.105)	Data 0.00085 (0.00094)	Tok/s 52773 (60090)	Loss/tok 2.9243 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][3660/6832]	Time 0.083 (0.105)	Data 0.00088 (0.00092)	Tok/s 51142 (59275)	Loss/tok 2.9508 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][3670/6832]	Time 0.119 (0.105)	Data 0.00085 (0.00095)	Tok/s 53949 (59637)	Loss/tok 3.3149 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][3670/6832]	Time 0.119 (0.105)	Data 0.00084 (0.00095)	Tok/s 53948 (58816)	Loss/tok 3.3562 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][3670/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00094)	Tok/s 53929 (60083)	Loss/tok 3.2174 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][3670/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00092)	Tok/s 53925 (59268)	Loss/tok 3.2789 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][3680/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00095)	Tok/s 66886 (59635)	Loss/tok 3.2746 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][3680/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00095)	Tok/s 66620 (58815)	Loss/tok 3.2310 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][3680/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 66984 (60080)	Loss/tok 3.3281 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][3680/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00092)	Tok/s 66819 (59267)	Loss/tok 3.1197 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][3690/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 63951 (59655)	Loss/tok 3.3491 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][3690/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 63932 (58835)	Loss/tok 3.4877 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][3690/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00092)	Tok/s 63954 (59286)	Loss/tok 3.3261 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][3690/6832]	Time 0.127 (0.105)	Data 0.00103 (0.00094)	Tok/s 65052 (60100)	Loss/tok 3.3229 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][3700/6832]	Time 0.067 (0.105)	Data 0.00092 (0.00095)	Tok/s 50100 (59650)	Loss/tok 2.8603 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][3700/6832]	Time 0.067 (0.105)	Data 0.00096 (0.00095)	Tok/s 49916 (58832)	Loss/tok 2.7744 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][3700/6832]	Time 0.067 (0.105)	Data 0.00098 (0.00092)	Tok/s 49901 (59282)	Loss/tok 2.9677 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][3700/6832]	Time 0.067 (0.105)	Data 0.00198 (0.00094)	Tok/s 51824 (60095)	Loss/tok 2.9216 (3.1689)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][3710/6832]	Time 0.067 (0.105)	Data 0.00086 (0.00095)	Tok/s 49427 (59653)	Loss/tok 2.8463 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][3710/6832]	Time 0.067 (0.105)	Data 0.00092 (0.00092)	Tok/s 49401 (59286)	Loss/tok 2.7621 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][3710/6832]	Time 0.067 (0.105)	Data 0.00089 (0.00095)	Tok/s 49373 (58836)	Loss/tok 2.9491 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][3710/6832]	Time 0.067 (0.105)	Data 0.00086 (0.00094)	Tok/s 50926 (60099)	Loss/tok 2.8708 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][3720/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00095)	Tok/s 84095 (59652)	Loss/tok 3.2846 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][3720/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00095)	Tok/s 82984 (58836)	Loss/tok 3.2449 (3.1729)	Learning Rate [7.8125e-05]
1: TRAIN [3][3720/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00092)	Tok/s 83453 (59285)	Loss/tok 3.0207 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][3720/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 84438 (60097)	Loss/tok 3.0788 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][3730/6832]	Time 0.121 (0.105)	Data 0.00083 (0.00095)	Tok/s 60051 (59651)	Loss/tok 3.2268 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][3730/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00092)	Tok/s 59366 (59284)	Loss/tok 3.4085 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][3730/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00095)	Tok/s 59354 (58834)	Loss/tok 3.2397 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][3730/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00094)	Tok/s 60420 (60096)	Loss/tok 3.2678 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][3740/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 70265 (59634)	Loss/tok 3.2146 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][3740/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00092)	Tok/s 70283 (59267)	Loss/tok 3.2393 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][3740/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 70289 (58817)	Loss/tok 3.1206 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][3740/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 71112 (60078)	Loss/tok 3.3599 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3750/6832]	Time 0.110 (0.105)	Data 0.00099 (0.00092)	Tok/s 54668 (59265)	Loss/tok 3.1647 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][3750/6832]	Time 0.110 (0.105)	Data 0.00093 (0.00095)	Tok/s 54620 (59632)	Loss/tok 3.1279 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][3750/6832]	Time 0.110 (0.105)	Data 0.00094 (0.00095)	Tok/s 54671 (58815)	Loss/tok 3.1793 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][3750/6832]	Time 0.110 (0.105)	Data 0.00094 (0.00094)	Tok/s 54606 (60077)	Loss/tok 3.2187 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][3760/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00095)	Tok/s 52828 (59621)	Loss/tok 3.0637 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][3760/6832]	Time 0.082 (0.105)	Data 0.00099 (0.00092)	Tok/s 52860 (59253)	Loss/tok 3.1122 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][3760/6832]	Time 0.082 (0.105)	Data 0.00089 (0.00094)	Tok/s 53450 (60065)	Loss/tok 2.8969 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3760/6832]	Time 0.082 (0.105)	Data 0.00105 (0.00095)	Tok/s 52804 (58804)	Loss/tok 3.1122 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][3770/6832]	Time 0.088 (0.105)	Data 0.00091 (0.00092)	Tok/s 51975 (59246)	Loss/tok 3.2481 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][3770/6832]	Time 0.088 (0.105)	Data 0.00096 (0.00095)	Tok/s 52517 (59614)	Loss/tok 3.1254 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][3770/6832]	Time 0.088 (0.105)	Data 0.00101 (0.00095)	Tok/s 51076 (58798)	Loss/tok 3.1677 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][3770/6832]	Time 0.088 (0.105)	Data 0.00100 (0.00094)	Tok/s 52517 (60058)	Loss/tok 3.0873 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][3780/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00092)	Tok/s 62532 (59254)	Loss/tok 3.3850 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][3780/6832]	Time 0.129 (0.105)	Data 0.00104 (0.00095)	Tok/s 62525 (59622)	Loss/tok 3.2515 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][3780/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00095)	Tok/s 62531 (58806)	Loss/tok 3.3034 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][3780/6832]	Time 0.129 (0.105)	Data 0.00105 (0.00094)	Tok/s 63486 (60065)	Loss/tok 3.2766 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][3790/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00092)	Tok/s 49947 (59254)	Loss/tok 2.7968 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][3790/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00095)	Tok/s 51001 (59622)	Loss/tok 2.8760 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][3790/6832]	Time 0.059 (0.105)	Data 0.00096 (0.00095)	Tok/s 50028 (58807)	Loss/tok 2.8695 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][3790/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00094)	Tok/s 52092 (60065)	Loss/tok 2.7559 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][3800/6832]	Time 0.112 (0.105)	Data 0.00089 (0.00095)	Tok/s 51310 (59623)	Loss/tok 3.1623 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][3800/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00092)	Tok/s 51282 (59256)	Loss/tok 3.0640 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][3800/6832]	Time 0.112 (0.105)	Data 0.00089 (0.00094)	Tok/s 51310 (60066)	Loss/tok 3.2914 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][3800/6832]	Time 0.112 (0.105)	Data 0.00122 (0.00095)	Tok/s 51316 (58809)	Loss/tok 3.1404 (3.1727)	Learning Rate [7.8125e-05]
2: TRAIN [3][3810/6832]	Time 0.055 (0.105)	Data 0.00085 (0.00095)	Tok/s 48901 (59634)	Loss/tok 2.6755 (3.1684)	Learning Rate [7.8125e-05]
3: TRAIN [3][3810/6832]	Time 0.055 (0.105)	Data 0.00083 (0.00094)	Tok/s 48954 (60077)	Loss/tok 2.6746 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][3810/6832]	Time 0.055 (0.105)	Data 0.00092 (0.00092)	Tok/s 46814 (59266)	Loss/tok 2.6255 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][3810/6832]	Time 0.055 (0.105)	Data 0.00100 (0.00095)	Tok/s 46616 (58820)	Loss/tok 2.6074 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][3820/6832]	Time 0.113 (0.105)	Data 0.00094 (0.00092)	Tok/s 51885 (59272)	Loss/tok 3.0295 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][3820/6832]	Time 0.113 (0.105)	Data 0.00095 (0.00095)	Tok/s 51909 (58826)	Loss/tok 3.1782 (3.1727)	Learning Rate [7.8125e-05]
3: TRAIN [3][3820/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00094)	Tok/s 51852 (60082)	Loss/tok 3.1639 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][3820/6832]	Time 0.114 (0.105)	Data 0.00085 (0.00095)	Tok/s 51504 (59639)	Loss/tok 3.1842 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3830/6832]	Time 0.087 (0.105)	Data 0.00094 (0.00095)	Tok/s 52912 (59627)	Loss/tok 3.2689 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][3830/6832]	Time 0.087 (0.105)	Data 0.00094 (0.00092)	Tok/s 52912 (59260)	Loss/tok 3.0308 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][3830/6832]	Time 0.087 (0.105)	Data 0.00093 (0.00094)	Tok/s 53708 (60070)	Loss/tok 2.9743 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][3830/6832]	Time 0.087 (0.105)	Data 0.00099 (0.00095)	Tok/s 52873 (58814)	Loss/tok 3.1659 (3.1727)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][3840/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00095)	Tok/s 56335 (59636)	Loss/tok 3.3576 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][3840/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00092)	Tok/s 55687 (59269)	Loss/tok 3.2846 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][3840/6832]	Time 0.122 (0.105)	Data 0.00099 (0.00094)	Tok/s 56771 (60079)	Loss/tok 3.3349 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][3840/6832]	Time 0.122 (0.105)	Data 0.00100 (0.00095)	Tok/s 55710 (58824)	Loss/tok 3.3148 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][3850/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 65018 (59281)	Loss/tok 3.3359 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][3850/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 65052 (59648)	Loss/tok 3.4515 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][3850/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00095)	Tok/s 64383 (58836)	Loss/tok 3.3487 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][3850/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 65054 (60091)	Loss/tok 3.1721 (3.1691)	Learning Rate [7.8125e-05]
1: TRAIN [3][3860/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00092)	Tok/s 71642 (59276)	Loss/tok 3.3546 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][3860/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00095)	Tok/s 71673 (59642)	Loss/tok 3.2555 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][3860/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 72034 (60084)	Loss/tok 3.2668 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][3860/6832]	Time 0.129 (0.105)	Data 0.00109 (0.00095)	Tok/s 71398 (58831)	Loss/tok 3.3143 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][3870/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00095)	Tok/s 92897 (59662)	Loss/tok 3.0770 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][3870/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00092)	Tok/s 91643 (59295)	Loss/tok 2.9600 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][3870/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 90820 (58851)	Loss/tok 3.0936 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][3870/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 94747 (60103)	Loss/tok 3.1993 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][3880/6832]	Time 0.098 (0.105)	Data 0.00099 (0.00095)	Tok/s 53694 (59658)	Loss/tok 3.2263 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][3880/6832]	Time 0.098 (0.105)	Data 0.00096 (0.00092)	Tok/s 53593 (59289)	Loss/tok 3.1021 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][3880/6832]	Time 0.098 (0.105)	Data 0.00093 (0.00094)	Tok/s 53714 (60101)	Loss/tok 3.0502 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3880/6832]	Time 0.098 (0.105)	Data 0.00103 (0.00095)	Tok/s 53633 (58839)	Loss/tok 3.1684 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][3890/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00092)	Tok/s 60900 (59297)	Loss/tok 3.1874 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3890/6832]	Time 0.126 (0.105)	Data 0.00084 (0.00095)	Tok/s 61039 (59665)	Loss/tok 3.2823 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][3890/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00095)	Tok/s 60942 (58847)	Loss/tok 3.2271 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][3890/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00094)	Tok/s 61887 (60109)	Loss/tok 3.4399 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][3900/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00092)	Tok/s 51112 (59291)	Loss/tok 2.9707 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][3900/6832]	Time 0.090 (0.105)	Data 0.00087 (0.00095)	Tok/s 51067 (59659)	Loss/tok 3.0325 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][3900/6832]	Time 0.090 (0.105)	Data 0.00088 (0.00094)	Tok/s 52241 (60102)	Loss/tok 3.1770 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][3900/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00095)	Tok/s 49808 (58841)	Loss/tok 3.0557 (3.1727)	Learning Rate [7.8125e-05]
2: TRAIN [3][3910/6832]	Time 0.102 (0.105)	Data 0.00089 (0.00095)	Tok/s 55044 (59654)	Loss/tok 3.1244 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][3910/6832]	Time 0.102 (0.105)	Data 0.00089 (0.00092)	Tok/s 55000 (59287)	Loss/tok 2.9565 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][3910/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00094)	Tok/s 55036 (60097)	Loss/tok 3.0791 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3910/6832]	Time 0.102 (0.105)	Data 0.00101 (0.00095)	Tok/s 54600 (58837)	Loss/tok 3.0287 (3.1729)	Learning Rate [7.8125e-05]
1: TRAIN [3][3920/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00092)	Tok/s 54030 (59293)	Loss/tok 3.0931 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][3920/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00094)	Tok/s 54865 (60102)	Loss/tok 3.1676 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][3920/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00095)	Tok/s 54876 (59660)	Loss/tok 3.2864 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][3920/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00095)	Tok/s 53359 (58844)	Loss/tok 3.1737 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][3930/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00095)	Tok/s 56373 (59687)	Loss/tok 3.1778 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][3930/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00092)	Tok/s 55996 (59319)	Loss/tok 3.1326 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][3930/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00094)	Tok/s 57034 (60130)	Loss/tok 3.3053 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][3930/6832]	Time 0.121 (0.105)	Data 0.00100 (0.00095)	Tok/s 55984 (58871)	Loss/tok 3.1376 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][3940/6832]	Time 0.103 (0.105)	Data 0.00085 (0.00095)	Tok/s 52111 (59688)	Loss/tok 3.0731 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][3940/6832]	Time 0.103 (0.105)	Data 0.00092 (0.00092)	Tok/s 52103 (59321)	Loss/tok 3.2771 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][3940/6832]	Time 0.103 (0.105)	Data 0.00097 (0.00095)	Tok/s 52154 (58873)	Loss/tok 3.1314 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3940/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00094)	Tok/s 52128 (60130)	Loss/tok 3.1312 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][3950/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00095)	Tok/s 63654 (59705)	Loss/tok 3.3235 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][3950/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00092)	Tok/s 63659 (59338)	Loss/tok 3.2302 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][3950/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 63645 (60147)	Loss/tok 3.1694 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][3950/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 63643 (58891)	Loss/tok 3.4048 (3.1733)	Learning Rate [7.8125e-05]
2: TRAIN [3][3960/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00095)	Tok/s 61949 (59696)	Loss/tok 3.3201 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][3960/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00092)	Tok/s 61738 (59328)	Loss/tok 3.1998 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][3960/6832]	Time 0.124 (0.105)	Data 0.00087 (0.00094)	Tok/s 61971 (60138)	Loss/tok 3.4039 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][3960/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00095)	Tok/s 60936 (58881)	Loss/tok 3.4147 (3.1732)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [3][3970/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00092)	Tok/s 77214 (59338)	Loss/tok 3.2972 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][3970/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00095)	Tok/s 76508 (58892)	Loss/tok 3.2479 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][3970/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 77159 (59706)	Loss/tok 3.2119 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][3970/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 77631 (60148)	Loss/tok 3.1059 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][3980/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00092)	Tok/s 62221 (59338)	Loss/tok 3.1667 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][3980/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00095)	Tok/s 62398 (59705)	Loss/tok 3.4027 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][3980/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 62231 (58892)	Loss/tok 3.3302 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][3980/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 63234 (60147)	Loss/tok 3.2896 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][3990/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00095)	Tok/s 68356 (59711)	Loss/tok 3.4953 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][3990/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 68998 (60152)	Loss/tok 3.3523 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][3990/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00092)	Tok/s 67959 (59344)	Loss/tok 3.1579 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][3990/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 67950 (58898)	Loss/tok 3.2534 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][4000/6832]	Time 0.093 (0.105)	Data 0.00083 (0.00095)	Tok/s 54338 (59702)	Loss/tok 3.1050 (3.1691)	Learning Rate [7.8125e-05]
1: TRAIN [3][4000/6832]	Time 0.093 (0.105)	Data 0.00089 (0.00092)	Tok/s 53449 (59334)	Loss/tok 3.1610 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][4000/6832]	Time 0.093 (0.105)	Data 0.00088 (0.00095)	Tok/s 53493 (58885)	Loss/tok 3.1562 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][4000/6832]	Time 0.093 (0.105)	Data 0.00086 (0.00094)	Tok/s 54870 (60145)	Loss/tok 3.1394 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][4010/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00092)	Tok/s 73537 (59335)	Loss/tok 3.2862 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][4010/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 72557 (58886)	Loss/tok 3.3110 (3.1735)	Learning Rate [7.8125e-05]
2: TRAIN [3][4010/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00095)	Tok/s 73495 (59703)	Loss/tok 3.1250 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][4010/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00094)	Tok/s 73486 (60144)	Loss/tok 3.3060 (3.1697)	Learning Rate [7.8125e-05]
2: TRAIN [3][4020/6832]	Time 0.077 (0.105)	Data 0.00093 (0.00095)	Tok/s 54714 (59699)	Loss/tok 2.8923 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][4020/6832]	Time 0.077 (0.105)	Data 0.00096 (0.00094)	Tok/s 54736 (60141)	Loss/tok 2.8903 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][4020/6832]	Time 0.077 (0.105)	Data 0.00093 (0.00092)	Tok/s 54629 (59331)	Loss/tok 2.9526 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][4020/6832]	Time 0.077 (0.105)	Data 0.00089 (0.00095)	Tok/s 53453 (58884)	Loss/tok 3.0722 (3.1736)	Learning Rate [7.8125e-05]
1: TRAIN [3][4030/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00092)	Tok/s 69776 (59328)	Loss/tok 3.2447 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][4030/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 69786 (58880)	Loss/tok 3.1682 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][4030/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00095)	Tok/s 70094 (59696)	Loss/tok 3.2609 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][4030/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 70736 (60137)	Loss/tok 3.2636 (3.1699)	Learning Rate [7.8125e-05]
2: TRAIN [3][4040/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00095)	Tok/s 60650 (59700)	Loss/tok 3.0472 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][4040/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00092)	Tok/s 60638 (59332)	Loss/tok 3.1635 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][4040/6832]	Time 0.116 (0.105)	Data 0.00098 (0.00095)	Tok/s 60644 (58885)	Loss/tok 3.2153 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][4040/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00094)	Tok/s 60645 (60141)	Loss/tok 3.2267 (3.1699)	Learning Rate [7.8125e-05]
2: TRAIN [3][4050/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00095)	Tok/s 88818 (59712)	Loss/tok 3.1131 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][4050/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 88307 (59344)	Loss/tok 3.0935 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][4050/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00095)	Tok/s 87736 (58897)	Loss/tok 3.1553 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][4050/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 89774 (60153)	Loss/tok 2.9825 (3.1698)	Learning Rate [7.8125e-05]
2: TRAIN [3][4060/6832]	Time 0.063 (0.105)	Data 0.00096 (0.00095)	Tok/s 48642 (59701)	Loss/tok 2.6983 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][4060/6832]	Time 0.063 (0.105)	Data 0.00095 (0.00095)	Tok/s 48654 (58882)	Loss/tok 2.8525 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][4060/6832]	Time 0.063 (0.105)	Data 0.00236 (0.00092)	Tok/s 48556 (59332)	Loss/tok 2.8015 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][4060/6832]	Time 0.063 (0.105)	Data 0.00102 (0.00094)	Tok/s 50143 (60143)	Loss/tok 2.7627 (3.1696)	Learning Rate [7.8125e-05]
2: TRAIN [3][4070/6832]	Time 0.079 (0.105)	Data 0.00084 (0.00095)	Tok/s 54135 (59712)	Loss/tok 3.0877 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][4070/6832]	Time 0.079 (0.105)	Data 0.00090 (0.00092)	Tok/s 53545 (59343)	Loss/tok 2.9802 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][4070/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00094)	Tok/s 55150 (60155)	Loss/tok 2.7702 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][4070/6832]	Time 0.079 (0.105)	Data 0.00089 (0.00095)	Tok/s 53527 (58894)	Loss/tok 2.8767 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][4080/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00092)	Tok/s 63806 (59340)	Loss/tok 3.0368 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][4080/6832]	Time 0.126 (0.105)	Data 0.00103 (0.00095)	Tok/s 63820 (59709)	Loss/tok 3.3914 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][4080/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00095)	Tok/s 63788 (58891)	Loss/tok 3.3540 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][4080/6832]	Time 0.126 (0.105)	Data 0.00097 (0.00094)	Tok/s 63865 (60151)	Loss/tok 3.3970 (3.1697)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][4090/6832]	Time 0.076 (0.105)	Data 0.00108 (0.00095)	Tok/s 52684 (59706)	Loss/tok 3.1204 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][4090/6832]	Time 0.076 (0.105)	Data 0.00094 (0.00092)	Tok/s 52045 (59337)	Loss/tok 2.7961 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][4090/6832]	Time 0.076 (0.105)	Data 0.00089 (0.00095)	Tok/s 52054 (58889)	Loss/tok 3.1813 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][4090/6832]	Time 0.076 (0.105)	Data 0.00107 (0.00094)	Tok/s 53719 (60147)	Loss/tok 2.8136 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][4100/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00092)	Tok/s 52434 (59337)	Loss/tok 3.1257 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][4100/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00095)	Tok/s 52428 (59705)	Loss/tok 3.0314 (3.1698)	Learning Rate [7.8125e-05]
0: TRAIN [3][4100/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00095)	Tok/s 52405 (58889)	Loss/tok 3.3095 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][4100/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00094)	Tok/s 52422 (60147)	Loss/tok 3.1576 (3.1697)	Learning Rate [7.8125e-05]
2: TRAIN [3][4110/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00095)	Tok/s 61578 (59713)	Loss/tok 3.2182 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][4110/6832]	Time 0.127 (0.105)	Data 0.00100 (0.00092)	Tok/s 60972 (59345)	Loss/tok 3.1151 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][4110/6832]	Time 0.127 (0.105)	Data 0.00095 (0.00095)	Tok/s 60599 (58897)	Loss/tok 3.2198 (3.1734)	Learning Rate [7.8125e-05]
3: TRAIN [3][4110/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00094)	Tok/s 61587 (60155)	Loss/tok 3.1974 (3.1696)	Learning Rate [7.8125e-05]
1: TRAIN [3][4120/6832]	Time 0.104 (0.105)	Data 0.00099 (0.00092)	Tok/s 53912 (59350)	Loss/tok 3.0307 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][4120/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00095)	Tok/s 53862 (59717)	Loss/tok 3.0854 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][4120/6832]	Time 0.105 (0.105)	Data 0.00096 (0.00095)	Tok/s 53893 (58902)	Loss/tok 3.1277 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][4120/6832]	Time 0.105 (0.105)	Data 0.00093 (0.00094)	Tok/s 53402 (60159)	Loss/tok 3.2250 (3.1696)	Learning Rate [7.8125e-05]
2: TRAIN [3][4130/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 81436 (59710)	Loss/tok 3.0798 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][4130/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00092)	Tok/s 80502 (59342)	Loss/tok 3.2542 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][4130/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 80417 (58895)	Loss/tok 3.2453 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][4130/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00094)	Tok/s 81752 (60151)	Loss/tok 3.3313 (3.1696)	Learning Rate [7.8125e-05]
2: TRAIN [3][4140/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00095)	Tok/s 54291 (59692)	Loss/tok 3.0863 (3.1696)	Learning Rate [7.8125e-05]
1: TRAIN [3][4140/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00092)	Tok/s 54263 (59324)	Loss/tok 3.0716 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4140/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00095)	Tok/s 54297 (58875)	Loss/tok 3.0914 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][4140/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00094)	Tok/s 54299 (60134)	Loss/tok 3.1470 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][4150/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00095)	Tok/s 55555 (59684)	Loss/tok 3.1956 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][4150/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00095)	Tok/s 54441 (58869)	Loss/tok 2.9505 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][4150/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00092)	Tok/s 54455 (59317)	Loss/tok 3.2020 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][4150/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00094)	Tok/s 55941 (60126)	Loss/tok 3.1791 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][4160/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00095)	Tok/s 60455 (59701)	Loss/tok 3.2822 (3.1696)	Learning Rate [7.8125e-05]
1: TRAIN [3][4160/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00092)	Tok/s 60467 (59334)	Loss/tok 3.1420 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4160/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00095)	Tok/s 60437 (58886)	Loss/tok 3.0369 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][4160/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00094)	Tok/s 60462 (60144)	Loss/tok 3.2887 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][4170/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00095)	Tok/s 52321 (59691)	Loss/tok 2.9768 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4170/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00092)	Tok/s 51387 (59324)	Loss/tok 2.9007 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4170/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00095)	Tok/s 50567 (58876)	Loss/tok 3.0227 (3.1727)	Learning Rate [7.8125e-05]
3: TRAIN [3][4170/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00094)	Tok/s 52351 (60134)	Loss/tok 2.9625 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][4180/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00095)	Tok/s 81575 (59690)	Loss/tok 3.0835 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4180/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00092)	Tok/s 81574 (59322)	Loss/tok 3.2075 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4180/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00095)	Tok/s 80638 (58874)	Loss/tok 3.1088 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][4180/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 82450 (60132)	Loss/tok 3.1226 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][4190/6832]	Time 0.053 (0.105)	Data 0.00085 (0.00095)	Tok/s 46297 (59684)	Loss/tok 2.4702 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4190/6832]	Time 0.053 (0.105)	Data 0.00091 (0.00092)	Tok/s 46002 (59317)	Loss/tok 2.5935 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4190/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00095)	Tok/s 44145 (58869)	Loss/tok 2.6045 (3.1724)	Learning Rate [7.8125e-05]
3: TRAIN [3][4190/6832]	Time 0.053 (0.105)	Data 0.00087 (0.00094)	Tok/s 48437 (60127)	Loss/tok 2.6575 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][4200/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00092)	Tok/s 52705 (59307)	Loss/tok 2.8700 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4200/6832]	Time 0.078 (0.105)	Data 0.00086 (0.00095)	Tok/s 52698 (59675)	Loss/tok 2.8070 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][4200/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00095)	Tok/s 52647 (58859)	Loss/tok 2.9796 (3.1722)	Learning Rate [7.8125e-05]
3: TRAIN [3][4200/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00094)	Tok/s 52660 (60118)	Loss/tok 3.0086 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][4210/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00095)	Tok/s 52922 (59675)	Loss/tok 3.3193 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][4210/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00092)	Tok/s 51847 (59307)	Loss/tok 3.1496 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4210/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00095)	Tok/s 51875 (58860)	Loss/tok 3.2844 (3.1721)	Learning Rate [7.8125e-05]
3: TRAIN [3][4210/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00094)	Tok/s 52984 (60118)	Loss/tok 3.0531 (3.1688)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][4220/6832]	Time 0.101 (0.105)	Data 0.00097 (0.00095)	Tok/s 53368 (59676)	Loss/tok 3.1620 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4220/6832]	Time 0.101 (0.105)	Data 0.00093 (0.00092)	Tok/s 52937 (59308)	Loss/tok 2.9849 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4220/6832]	Time 0.101 (0.105)	Data 0.00097 (0.00095)	Tok/s 52141 (58861)	Loss/tok 3.0230 (3.1721)	Learning Rate [7.8125e-05]
3: TRAIN [3][4220/6832]	Time 0.101 (0.105)	Data 0.00090 (0.00094)	Tok/s 53407 (60119)	Loss/tok 3.0440 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][4230/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00095)	Tok/s 61558 (59670)	Loss/tok 3.1614 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4230/6832]	Time 0.121 (0.105)	Data 0.00092 (0.00092)	Tok/s 61182 (59302)	Loss/tok 3.2428 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4230/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00095)	Tok/s 60478 (58854)	Loss/tok 3.3849 (3.1723)	Learning Rate [7.8125e-05]
3: TRAIN [3][4230/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00094)	Tok/s 61543 (60112)	Loss/tok 3.2605 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][4240/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00095)	Tok/s 51532 (59673)	Loss/tok 3.0056 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4240/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00092)	Tok/s 50749 (59305)	Loss/tok 2.7160 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][4240/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00094)	Tok/s 52476 (60115)	Loss/tok 2.8258 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4240/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00095)	Tok/s 50788 (58858)	Loss/tok 2.7209 (3.1722)	Learning Rate [7.8125e-05]
2: TRAIN [3][4250/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00095)	Tok/s 54672 (59678)	Loss/tok 3.0841 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4250/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00092)	Tok/s 53925 (59310)	Loss/tok 2.9403 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][4250/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00095)	Tok/s 53931 (58863)	Loss/tok 3.3518 (3.1723)	Learning Rate [7.8125e-05]
3: TRAIN [3][4250/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00094)	Tok/s 55151 (60121)	Loss/tok 3.0577 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4260/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00095)	Tok/s 54370 (59686)	Loss/tok 3.4145 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4260/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00092)	Tok/s 54490 (59316)	Loss/tok 3.0266 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][4260/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00095)	Tok/s 54463 (58870)	Loss/tok 3.2918 (3.1723)	Learning Rate [7.8125e-05]
3: TRAIN [3][4260/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00094)	Tok/s 54343 (60128)	Loss/tok 3.2273 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4270/6832]	Time 0.057 (0.105)	Data 0.00089 (0.00095)	Tok/s 49332 (59673)	Loss/tok 2.7750 (3.1691)	Learning Rate [7.8125e-05]
1: TRAIN [3][4270/6832]	Time 0.057 (0.105)	Data 0.00087 (0.00092)	Tok/s 49147 (59304)	Loss/tok 2.7367 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][4270/6832]	Time 0.057 (0.105)	Data 0.00088 (0.00095)	Tok/s 48253 (58858)	Loss/tok 2.5671 (3.1722)	Learning Rate [7.8125e-05]
3: TRAIN [3][4270/6832]	Time 0.057 (0.105)	Data 0.00090 (0.00094)	Tok/s 49657 (60116)	Loss/tok 2.6634 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4280/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00095)	Tok/s 67513 (59677)	Loss/tok 3.4036 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4280/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00092)	Tok/s 67540 (59308)	Loss/tok 3.2693 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][4280/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00095)	Tok/s 66637 (58862)	Loss/tok 3.1766 (3.1723)	Learning Rate [7.8125e-05]
3: TRAIN [3][4280/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 67491 (60119)	Loss/tok 3.1485 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][4290/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00092)	Tok/s 52947 (59314)	Loss/tok 2.9256 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][4290/6832]	Time 0.075 (0.105)	Data 0.00089 (0.00095)	Tok/s 52993 (59682)	Loss/tok 2.7930 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][4290/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00095)	Tok/s 52978 (58869)	Loss/tok 2.9706 (3.1724)	Learning Rate [7.8125e-05]
3: TRAIN [3][4290/6832]	Time 0.075 (0.105)	Data 0.00096 (0.00094)	Tok/s 54391 (60125)	Loss/tok 2.8552 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4300/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00095)	Tok/s 54265 (59679)	Loss/tok 3.3030 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][4300/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00092)	Tok/s 53554 (59311)	Loss/tok 3.1415 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][4300/6832]	Time 0.111 (0.105)	Data 0.00099 (0.00095)	Tok/s 53083 (58867)	Loss/tok 3.1225 (3.1724)	Learning Rate [7.8125e-05]
3: TRAIN [3][4300/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00094)	Tok/s 54293 (60121)	Loss/tok 3.3297 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4310/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00095)	Tok/s 54794 (59684)	Loss/tok 3.2073 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][4310/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00094)	Tok/s 55362 (60126)	Loss/tok 3.2215 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][4310/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00092)	Tok/s 54191 (59316)	Loss/tok 3.0897 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4310/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00095)	Tok/s 54190 (58872)	Loss/tok 3.1258 (3.1724)	Learning Rate [7.8125e-05]
2: TRAIN [3][4320/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00095)	Tok/s 62152 (59683)	Loss/tok 3.2677 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][4320/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00092)	Tok/s 62121 (59315)	Loss/tok 3.1921 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][4320/6832]	Time 0.126 (0.105)	Data 0.00107 (0.00095)	Tok/s 62149 (58871)	Loss/tok 3.2148 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][4320/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00094)	Tok/s 63173 (60124)	Loss/tok 3.3663 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][4330/6832]	Time 0.098 (0.105)	Data 0.00095 (0.00092)	Tok/s 52451 (59307)	Loss/tok 3.1947 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4330/6832]	Time 0.098 (0.105)	Data 0.00087 (0.00095)	Tok/s 52344 (59676)	Loss/tok 3.0253 (3.1698)	Learning Rate [7.8125e-05]
0: TRAIN [3][4330/6832]	Time 0.098 (0.105)	Data 0.00094 (0.00095)	Tok/s 51231 (58861)	Loss/tok 2.9154 (3.1727)	Learning Rate [7.8125e-05]
3: TRAIN [3][4330/6832]	Time 0.098 (0.105)	Data 0.00088 (0.00094)	Tok/s 52347 (60118)	Loss/tok 3.1381 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4340/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 72344 (59685)	Loss/tok 3.1880 (3.1699)	Learning Rate [7.8125e-05]
1: TRAIN [3][4340/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00092)	Tok/s 71461 (59317)	Loss/tok 3.3450 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][4340/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00094)	Tok/s 72470 (60127)	Loss/tok 3.5095 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4340/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00095)	Tok/s 71483 (58872)	Loss/tok 3.2610 (3.1728)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][4350/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00095)	Tok/s 60456 (59679)	Loss/tok 3.3854 (3.1699)	Learning Rate [7.8125e-05]
1: TRAIN [3][4350/6832]	Time 0.125 (0.105)	Data 0.00094 (0.00092)	Tok/s 60424 (59309)	Loss/tok 3.2601 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4350/6832]	Time 0.125 (0.105)	Data 0.00099 (0.00095)	Tok/s 59975 (58862)	Loss/tok 3.2202 (3.1727)	Learning Rate [7.8125e-05]
3: TRAIN [3][4350/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00094)	Tok/s 60422 (60121)	Loss/tok 3.3411 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][4360/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00095)	Tok/s 58158 (59674)	Loss/tok 3.2304 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][4360/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00092)	Tok/s 58033 (59302)	Loss/tok 3.2554 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4360/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00095)	Tok/s 58014 (58850)	Loss/tok 3.1446 (3.1727)	Learning Rate [7.8125e-05]
3: TRAIN [3][4360/6832]	Time 0.119 (0.105)	Data 0.00098 (0.00094)	Tok/s 59140 (60118)	Loss/tok 3.1918 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4370/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 73697 (59676)	Loss/tok 3.2413 (3.1699)	Learning Rate [7.8125e-05]
1: TRAIN [3][4370/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00092)	Tok/s 73520 (59304)	Loss/tok 3.3148 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4370/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00095)	Tok/s 72709 (58852)	Loss/tok 3.3284 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][4370/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 73731 (60119)	Loss/tok 3.2875 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][4380/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00092)	Tok/s 55020 (59289)	Loss/tok 3.1474 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][4380/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00095)	Tok/s 54996 (59661)	Loss/tok 3.0537 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][4380/6832]	Time 0.112 (0.105)	Data 0.00094 (0.00095)	Tok/s 55036 (58838)	Loss/tok 3.2299 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][4380/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00094)	Tok/s 54988 (60105)	Loss/tok 3.0982 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4390/6832]	Time 0.104 (0.105)	Data 0.00092 (0.00095)	Tok/s 54092 (59653)	Loss/tok 3.1007 (3.1699)	Learning Rate [7.8125e-05]
1: TRAIN [3][4390/6832]	Time 0.104 (0.105)	Data 0.00097 (0.00092)	Tok/s 54112 (59282)	Loss/tok 3.1216 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][4390/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00094)	Tok/s 55263 (60096)	Loss/tok 3.0895 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4390/6832]	Time 0.104 (0.105)	Data 0.00098 (0.00095)	Tok/s 54118 (58832)	Loss/tok 3.1376 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][4400/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00095)	Tok/s 53077 (59676)	Loss/tok 3.1650 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][4400/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00092)	Tok/s 53092 (59305)	Loss/tok 3.1006 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][4400/6832]	Time 0.097 (0.105)	Data 0.00093 (0.00094)	Tok/s 53730 (60119)	Loss/tok 2.9542 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4400/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00095)	Tok/s 53098 (58855)	Loss/tok 3.1524 (3.1727)	Learning Rate [7.8125e-05]
2: TRAIN [3][4410/6832]	Time 0.069 (0.105)	Data 0.00088 (0.00095)	Tok/s 51963 (59669)	Loss/tok 3.1327 (3.1702)	Learning Rate [7.8125e-05]
1: TRAIN [3][4410/6832]	Time 0.069 (0.105)	Data 0.00091 (0.00092)	Tok/s 51904 (59298)	Loss/tok 2.7267 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4410/6832]	Time 0.069 (0.105)	Data 0.00090 (0.00095)	Tok/s 51831 (58849)	Loss/tok 3.0179 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][4410/6832]	Time 0.069 (0.105)	Data 0.00085 (0.00094)	Tok/s 52923 (60112)	Loss/tok 2.8840 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][4420/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00092)	Tok/s 56580 (59294)	Loss/tok 3.4425 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4420/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00095)	Tok/s 56572 (58845)	Loss/tok 3.2259 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][4420/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00095)	Tok/s 56573 (59664)	Loss/tok 3.0238 (3.1701)	Learning Rate [7.8125e-05]
3: TRAIN [3][4420/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00094)	Tok/s 56604 (60108)	Loss/tok 3.2231 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4430/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00095)	Tok/s 52154 (59659)	Loss/tok 3.0917 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][4430/6832]	Time 0.079 (0.105)	Data 0.00094 (0.00092)	Tok/s 52145 (59289)	Loss/tok 3.1538 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4430/6832]	Time 0.079 (0.105)	Data 0.00094 (0.00095)	Tok/s 51863 (58840)	Loss/tok 3.1097 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][4430/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00094)	Tok/s 52161 (60102)	Loss/tok 2.9227 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4440/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 61965 (59662)	Loss/tok 3.2243 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][4440/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00092)	Tok/s 61894 (59292)	Loss/tok 3.3071 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4440/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 61908 (58844)	Loss/tok 3.3276 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][4440/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 62603 (60104)	Loss/tok 3.4036 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][4450/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00092)	Tok/s 61141 (59293)	Loss/tok 3.1278 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4450/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00095)	Tok/s 60365 (58845)	Loss/tok 3.2115 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][4450/6832]	Time 0.119 (0.105)	Data 0.00110 (0.00095)	Tok/s 61406 (59662)	Loss/tok 3.2973 (3.1701)	Learning Rate [7.8125e-05]
3: TRAIN [3][4450/6832]	Time 0.119 (0.105)	Data 0.00099 (0.00094)	Tok/s 62028 (60105)	Loss/tok 3.2568 (3.1689)	Learning Rate [7.8125e-05]
1: TRAIN [3][4460/6832]	Time 0.063 (0.105)	Data 0.00091 (0.00092)	Tok/s 46961 (59288)	Loss/tok 2.6645 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4460/6832]	Time 0.063 (0.105)	Data 0.00092 (0.00095)	Tok/s 46956 (58840)	Loss/tok 2.7117 (3.1730)	Learning Rate [7.8125e-05]
3: TRAIN [3][4460/6832]	Time 0.063 (0.105)	Data 0.00089 (0.00094)	Tok/s 49042 (60099)	Loss/tok 2.8245 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][4460/6832]	Time 0.063 (0.105)	Data 0.00092 (0.00095)	Tok/s 47040 (59657)	Loss/tok 2.5564 (3.1702)	Learning Rate [7.8125e-05]
1: TRAIN [3][4470/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00092)	Tok/s 51216 (59306)	Loss/tok 2.9901 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4470/6832]	Time 0.105 (0.105)	Data 0.00104 (0.00095)	Tok/s 51317 (59675)	Loss/tok 3.1650 (3.1703)	Learning Rate [7.8125e-05]
0: TRAIN [3][4470/6832]	Time 0.105 (0.105)	Data 0.00094 (0.00095)	Tok/s 51226 (58858)	Loss/tok 3.2735 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][4470/6832]	Time 0.105 (0.105)	Data 0.00100 (0.00094)	Tok/s 52474 (60118)	Loss/tok 3.2624 (3.1689)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [3][4480/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00092)	Tok/s 74045 (59317)	Loss/tok 3.3638 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][4480/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 73982 (58870)	Loss/tok 3.3348 (3.1733)	Learning Rate [7.8125e-05]
2: TRAIN [3][4480/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 74445 (59686)	Loss/tok 3.3615 (3.1704)	Learning Rate [7.8125e-05]
3: TRAIN [3][4480/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 75050 (60128)	Loss/tok 3.2105 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4490/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00092)	Tok/s 54141 (59312)	Loss/tok 3.2696 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][4490/6832]	Time 0.113 (0.105)	Data 0.00095 (0.00095)	Tok/s 54205 (59681)	Loss/tok 3.2838 (3.1706)	Learning Rate [7.8125e-05]
0: TRAIN [3][4490/6832]	Time 0.113 (0.105)	Data 0.00093 (0.00095)	Tok/s 54142 (58866)	Loss/tok 3.2062 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][4490/6832]	Time 0.113 (0.105)	Data 0.00099 (0.00094)	Tok/s 55280 (60123)	Loss/tok 3.1455 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4500/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00092)	Tok/s 57610 (59308)	Loss/tok 3.1359 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][4500/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00095)	Tok/s 57627 (58862)	Loss/tok 3.1822 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][4500/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00095)	Tok/s 57636 (59676)	Loss/tok 3.2733 (3.1704)	Learning Rate [7.8125e-05]
3: TRAIN [3][4500/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00094)	Tok/s 57639 (60119)	Loss/tok 3.1929 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4510/6832]	Time 0.120 (0.105)	Data 0.00103 (0.00092)	Tok/s 50957 (59319)	Loss/tok 3.3175 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][4510/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00095)	Tok/s 50204 (58874)	Loss/tok 3.2034 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][4510/6832]	Time 0.119 (0.105)	Data 0.00115 (0.00095)	Tok/s 51540 (59687)	Loss/tok 3.2402 (3.1705)	Learning Rate [7.8125e-05]
3: TRAIN [3][4510/6832]	Time 0.120 (0.105)	Data 0.00104 (0.00094)	Tok/s 51276 (60129)	Loss/tok 3.1239 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4520/6832]	Time 0.083 (0.105)	Data 0.00089 (0.00092)	Tok/s 50898 (59324)	Loss/tok 3.0231 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][4520/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00095)	Tok/s 50920 (58878)	Loss/tok 3.0861 (3.1734)	Learning Rate [7.8125e-05]
2: TRAIN [3][4520/6832]	Time 0.083 (0.105)	Data 0.00096 (0.00095)	Tok/s 50852 (59691)	Loss/tok 3.0710 (3.1705)	Learning Rate [7.8125e-05]
3: TRAIN [3][4520/6832]	Time 0.083 (0.105)	Data 0.00096 (0.00094)	Tok/s 51963 (60133)	Loss/tok 3.1277 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4530/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00092)	Tok/s 70546 (59326)	Loss/tok 3.3582 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][4530/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 70521 (58881)	Loss/tok 3.3624 (3.1736)	Learning Rate [7.8125e-05]
2: TRAIN [3][4530/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 70539 (59693)	Loss/tok 3.3307 (3.1707)	Learning Rate [7.8125e-05]
3: TRAIN [3][4530/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 71352 (60135)	Loss/tok 3.1614 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4540/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00092)	Tok/s 73722 (59331)	Loss/tok 3.5172 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][4540/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 72881 (58887)	Loss/tok 3.4042 (3.1737)	Learning Rate [7.8125e-05]
2: TRAIN [3][4540/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00095)	Tok/s 73727 (59698)	Loss/tok 3.2918 (3.1706)	Learning Rate [7.8125e-05]
3: TRAIN [3][4540/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 73861 (60141)	Loss/tok 3.3004 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][4550/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 69000 (59337)	Loss/tok 3.3369 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][4550/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 68962 (58893)	Loss/tok 3.2083 (3.1735)	Learning Rate [7.8125e-05]
2: TRAIN [3][4550/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 68924 (59704)	Loss/tok 3.5541 (3.1707)	Learning Rate [7.8125e-05]
3: TRAIN [3][4550/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 69803 (60147)	Loss/tok 3.2119 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][4560/6832]	Time 0.082 (0.105)	Data 0.00098 (0.00092)	Tok/s 52591 (59329)	Loss/tok 3.0046 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][4560/6832]	Time 0.082 (0.105)	Data 0.00094 (0.00095)	Tok/s 53260 (59696)	Loss/tok 2.9776 (3.1707)	Learning Rate [7.8125e-05]
0: TRAIN [3][4560/6832]	Time 0.082 (0.105)	Data 0.00100 (0.00095)	Tok/s 51766 (58885)	Loss/tok 3.0470 (3.1734)	Learning Rate [7.8125e-05]
3: TRAIN [3][4560/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00094)	Tok/s 53303 (60138)	Loss/tok 2.9471 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][4570/6832]	Time 0.058 (0.105)	Data 0.00090 (0.00092)	Tok/s 48264 (59337)	Loss/tok 2.7042 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][4570/6832]	Time 0.058 (0.105)	Data 0.00091 (0.00095)	Tok/s 47145 (58893)	Loss/tok 2.8499 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][4570/6832]	Time 0.058 (0.105)	Data 0.00094 (0.00094)	Tok/s 49357 (60146)	Loss/tok 2.8215 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][4570/6832]	Time 0.058 (0.105)	Data 0.00097 (0.00095)	Tok/s 48318 (59704)	Loss/tok 2.7261 (3.1707)	Learning Rate [7.8125e-05]
1: TRAIN [3][4580/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00092)	Tok/s 49938 (59328)	Loss/tok 3.3439 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][4580/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 50277 (60137)	Loss/tok 2.9702 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][4580/6832]	Time 0.120 (0.105)	Data 0.00106 (0.00095)	Tok/s 50195 (59695)	Loss/tok 3.3594 (3.1707)	Learning Rate [7.8125e-05]
0: TRAIN [3][4580/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00095)	Tok/s 49932 (58884)	Loss/tok 3.1960 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][4590/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00092)	Tok/s 82144 (59330)	Loss/tok 3.1515 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4590/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 82124 (58886)	Loss/tok 3.2946 (3.1732)	Learning Rate [7.8125e-05]
3: TRAIN [3][4590/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 83097 (60140)	Loss/tok 3.1414 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][4590/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 82892 (59697)	Loss/tok 3.3044 (3.1708)	Learning Rate [7.8125e-05]
1: TRAIN [3][4600/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00092)	Tok/s 62005 (59327)	Loss/tok 3.2951 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][4600/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 62016 (58883)	Loss/tok 3.2128 (3.1732)	Learning Rate [7.8125e-05]
2: TRAIN [3][4600/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00095)	Tok/s 61985 (59694)	Loss/tok 3.1952 (3.1708)	Learning Rate [7.8125e-05]
3: TRAIN [3][4600/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 61973 (60136)	Loss/tok 3.3128 (3.1690)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [3][4610/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00092)	Tok/s 54637 (59319)	Loss/tok 3.2838 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4610/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00095)	Tok/s 54530 (58872)	Loss/tok 3.3948 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][4610/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 55580 (60130)	Loss/tok 3.0899 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4610/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00095)	Tok/s 55568 (59687)	Loss/tok 3.1358 (3.1706)	Learning Rate [7.8125e-05]
1: TRAIN [3][4620/6832]	Time 0.080 (0.105)	Data 0.00093 (0.00092)	Tok/s 51927 (59310)	Loss/tok 2.9205 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4620/6832]	Time 0.080 (0.105)	Data 0.00096 (0.00095)	Tok/s 51131 (58864)	Loss/tok 3.0105 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][4620/6832]	Time 0.080 (0.105)	Data 0.00098 (0.00095)	Tok/s 52687 (59679)	Loss/tok 3.1924 (3.1706)	Learning Rate [7.8125e-05]
3: TRAIN [3][4620/6832]	Time 0.080 (0.105)	Data 0.00093 (0.00094)	Tok/s 52668 (60123)	Loss/tok 2.9552 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][4630/6832]	Time 0.114 (0.105)	Data 0.00088 (0.00092)	Tok/s 56378 (59309)	Loss/tok 3.1358 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][4630/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00094)	Tok/s 56446 (60121)	Loss/tok 3.1779 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][4630/6832]	Time 0.113 (0.105)	Data 0.00093 (0.00095)	Tok/s 56466 (59678)	Loss/tok 3.3376 (3.1706)	Learning Rate [7.8125e-05]
0: TRAIN [3][4630/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00095)	Tok/s 56378 (58863)	Loss/tok 3.2839 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][4640/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00092)	Tok/s 57355 (59295)	Loss/tok 3.3135 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][4640/6832]	Time 0.114 (0.105)	Data 0.00086 (0.00094)	Tok/s 57992 (60109)	Loss/tok 3.3119 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4640/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00095)	Tok/s 57321 (59664)	Loss/tok 3.1899 (3.1703)	Learning Rate [7.8125e-05]
0: TRAIN [3][4640/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00095)	Tok/s 57335 (58846)	Loss/tok 3.2235 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][4650/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 66764 (60112)	Loss/tok 3.2008 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4650/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 66778 (59668)	Loss/tok 3.2117 (3.1703)	Learning Rate [7.8125e-05]
1: TRAIN [3][4650/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00092)	Tok/s 66850 (59298)	Loss/tok 3.2047 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][4650/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00095)	Tok/s 66352 (58847)	Loss/tok 3.4230 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][4660/6832]	Time 0.116 (0.105)	Data 0.00096 (0.00092)	Tok/s 51650 (59295)	Loss/tok 3.2386 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4660/6832]	Time 0.116 (0.105)	Data 0.00093 (0.00095)	Tok/s 51640 (59664)	Loss/tok 3.1540 (3.1702)	Learning Rate [7.8125e-05]
3: TRAIN [3][4660/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 52187 (60109)	Loss/tok 3.1951 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][4660/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00095)	Tok/s 51626 (58844)	Loss/tok 3.2115 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][4670/6832]	Time 0.059 (0.105)	Data 0.00095 (0.00092)	Tok/s 47966 (59290)	Loss/tok 2.6052 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4670/6832]	Time 0.059 (0.105)	Data 0.00097 (0.00095)	Tok/s 47934 (59660)	Loss/tok 2.7674 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][4670/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00095)	Tok/s 47530 (58837)	Loss/tok 2.7170 (3.1729)	Learning Rate [7.8125e-05]
3: TRAIN [3][4670/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00094)	Tok/s 48900 (60106)	Loss/tok 2.6967 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][4680/6832]	Time 0.108 (0.105)	Data 0.00087 (0.00092)	Tok/s 51788 (59300)	Loss/tok 3.0787 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4680/6832]	Time 0.108 (0.105)	Data 0.00091 (0.00095)	Tok/s 52013 (59670)	Loss/tok 2.9836 (3.1703)	Learning Rate [7.8125e-05]
3: TRAIN [3][4680/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00094)	Tok/s 52032 (60116)	Loss/tok 3.0723 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4680/6832]	Time 0.108 (0.105)	Data 0.00098 (0.00095)	Tok/s 50849 (58848)	Loss/tok 3.2747 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][4690/6832]	Time 0.129 (0.105)	Data 0.00107 (0.00092)	Tok/s 66432 (59300)	Loss/tok 3.2192 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][4690/6832]	Time 0.129 (0.105)	Data 0.00103 (0.00095)	Tok/s 66418 (59670)	Loss/tok 3.3861 (3.1704)	Learning Rate [7.8125e-05]
0: TRAIN [3][4690/6832]	Time 0.129 (0.105)	Data 0.00113 (0.00095)	Tok/s 65493 (58848)	Loss/tok 3.4114 (3.1733)	Learning Rate [7.8125e-05]
3: TRAIN [3][4690/6832]	Time 0.129 (0.105)	Data 0.00103 (0.00094)	Tok/s 66412 (60115)	Loss/tok 3.1658 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][4700/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00092)	Tok/s 78237 (59299)	Loss/tok 3.3501 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4700/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 78873 (59669)	Loss/tok 2.9926 (3.1704)	Learning Rate [7.8125e-05]
3: TRAIN [3][4700/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 78877 (60113)	Loss/tok 3.1689 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][4700/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 77931 (58847)	Loss/tok 3.1678 (3.1733)	Learning Rate [7.8125e-05]
2: TRAIN [3][4710/6832]	Time 0.100 (0.105)	Data 0.00088 (0.00095)	Tok/s 52417 (59670)	Loss/tok 3.0732 (3.1704)	Learning Rate [7.8125e-05]
1: TRAIN [3][4710/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00092)	Tok/s 52425 (59300)	Loss/tok 3.1795 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][4710/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00094)	Tok/s 52419 (60114)	Loss/tok 3.2280 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4710/6832]	Time 0.100 (0.105)	Data 0.00098 (0.00095)	Tok/s 52394 (58848)	Loss/tok 3.2360 (3.1733)	Learning Rate [7.8125e-05]
1: TRAIN [3][4720/6832]	Time 0.086 (0.105)	Data 0.00094 (0.00092)	Tok/s 53431 (59298)	Loss/tok 3.0637 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][4720/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00095)	Tok/s 53404 (59667)	Loss/tok 3.0791 (3.1702)	Learning Rate [7.8125e-05]
0: TRAIN [3][4720/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00095)	Tok/s 53415 (58846)	Loss/tok 2.9020 (3.1731)	Learning Rate [7.8125e-05]
3: TRAIN [3][4720/6832]	Time 0.086 (0.105)	Data 0.00095 (0.00094)	Tok/s 53419 (60112)	Loss/tok 2.9801 (3.1687)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][4730/6832]	Time 0.128 (0.105)	Data 0.00116 (0.00095)	Tok/s 67857 (59655)	Loss/tok 3.3210 (3.1701)	Learning Rate [7.8125e-05]
1: TRAIN [3][4730/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00092)	Tok/s 67826 (59286)	Loss/tok 3.3115 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][4730/6832]	Time 0.128 (0.105)	Data 0.00113 (0.00094)	Tok/s 68121 (60100)	Loss/tok 3.2190 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][4730/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00095)	Tok/s 67841 (58834)	Loss/tok 3.6039 (3.1731)	Learning Rate [7.8125e-05]
1: TRAIN [3][4740/6832]	Time 0.110 (0.105)	Data 0.00097 (0.00092)	Tok/s 55294 (59278)	Loss/tok 3.1343 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][4740/6832]	Time 0.110 (0.105)	Data 0.00098 (0.00095)	Tok/s 54866 (58826)	Loss/tok 3.0240 (3.1729)	Learning Rate [7.8125e-05]
2: TRAIN [3][4740/6832]	Time 0.110 (0.105)	Data 0.00092 (0.00095)	Tok/s 55958 (59648)	Loss/tok 3.1864 (3.1699)	Learning Rate [7.8125e-05]
3: TRAIN [3][4740/6832]	Time 0.110 (0.105)	Data 0.00091 (0.00094)	Tok/s 55957 (60093)	Loss/tok 3.1542 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][4750/6832]	Time 0.110 (0.105)	Data 0.00091 (0.00094)	Tok/s 53732 (60095)	Loss/tok 3.1633 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4750/6832]	Time 0.110 (0.105)	Data 0.00090 (0.00095)	Tok/s 53491 (59651)	Loss/tok 3.2333 (3.1700)	Learning Rate [7.8125e-05]
1: TRAIN [3][4750/6832]	Time 0.110 (0.105)	Data 0.00099 (0.00092)	Tok/s 53490 (59282)	Loss/tok 3.1407 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4750/6832]	Time 0.110 (0.105)	Data 0.00095 (0.00095)	Tok/s 53474 (58830)	Loss/tok 3.2197 (3.1730)	Learning Rate [7.8125e-05]
2: TRAIN [3][4760/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 78933 (59660)	Loss/tok 3.1139 (3.1700)	Learning Rate [7.8125e-05]
1: TRAIN [3][4760/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00092)	Tok/s 78012 (59290)	Loss/tok 3.2140 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][4760/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 78922 (60104)	Loss/tok 3.2837 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4760/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 77973 (58839)	Loss/tok 3.2089 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][4770/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00095)	Tok/s 52938 (59662)	Loss/tok 3.1081 (3.1701)	Learning Rate [7.8125e-05]
3: TRAIN [3][4770/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 53664 (60105)	Loss/tok 3.2300 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][4770/6832]	Time 0.117 (0.105)	Data 0.00104 (0.00092)	Tok/s 52631 (59292)	Loss/tok 3.3051 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4770/6832]	Time 0.117 (0.105)	Data 0.00102 (0.00095)	Tok/s 52612 (58841)	Loss/tok 2.9663 (3.1731)	Learning Rate [7.8125e-05]
2: TRAIN [3][4780/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 57685 (59663)	Loss/tok 3.3139 (3.1702)	Learning Rate [7.8125e-05]
3: TRAIN [3][4780/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 57691 (60107)	Loss/tok 3.2302 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][4780/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00092)	Tok/s 57641 (59294)	Loss/tok 3.2297 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4780/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00095)	Tok/s 57644 (58844)	Loss/tok 3.2897 (3.1730)	Learning Rate [7.8125e-05]
1: TRAIN [3][4790/6832]	Time 0.070 (0.105)	Data 0.00099 (0.00092)	Tok/s 51449 (59286)	Loss/tok 2.8569 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4790/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00095)	Tok/s 51373 (59655)	Loss/tok 2.8092 (3.1700)	Learning Rate [7.8125e-05]
0: TRAIN [3][4790/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00095)	Tok/s 51375 (58836)	Loss/tok 2.9216 (3.1728)	Learning Rate [7.8125e-05]
3: TRAIN [3][4790/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00094)	Tok/s 51351 (60099)	Loss/tok 2.8785 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][4800/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00092)	Tok/s 67313 (59288)	Loss/tok 3.2347 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4800/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 67343 (59658)	Loss/tok 3.2984 (3.1700)	Learning Rate [7.8125e-05]
0: TRAIN [3][4800/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 66502 (58838)	Loss/tok 3.3795 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][4800/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 67332 (60102)	Loss/tok 3.2237 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][4810/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00092)	Tok/s 80915 (59288)	Loss/tok 3.1621 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][4810/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 81861 (60104)	Loss/tok 3.3286 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][4810/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 81818 (59658)	Loss/tok 3.0997 (3.1698)	Learning Rate [7.8125e-05]
0: TRAIN [3][4810/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00095)	Tok/s 80908 (58835)	Loss/tok 3.2594 (3.1726)	Learning Rate [7.8125e-05]
1: TRAIN [3][4820/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00092)	Tok/s 61307 (59305)	Loss/tok 3.2725 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][4820/6832]	Time 0.119 (0.105)	Data 0.00096 (0.00095)	Tok/s 61351 (58853)	Loss/tok 3.3215 (3.1728)	Learning Rate [7.8125e-05]
2: TRAIN [3][4820/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00095)	Tok/s 61283 (59675)	Loss/tok 3.1195 (3.1699)	Learning Rate [7.8125e-05]
3: TRAIN [3][4820/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00094)	Tok/s 61266 (60120)	Loss/tok 3.1979 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][4830/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00092)	Tok/s 53151 (59304)	Loss/tok 2.9943 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4830/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00095)	Tok/s 53167 (59674)	Loss/tok 3.1468 (3.1699)	Learning Rate [7.8125e-05]
3: TRAIN [3][4830/6832]	Time 0.111 (0.105)	Data 0.00087 (0.00094)	Tok/s 53168 (60119)	Loss/tok 3.1164 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4830/6832]	Time 0.111 (0.105)	Data 0.00094 (0.00095)	Tok/s 53154 (58853)	Loss/tok 3.0870 (3.1727)	Learning Rate [7.8125e-05]
1: TRAIN [3][4840/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00092)	Tok/s 54063 (59313)	Loss/tok 3.0142 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4840/6832]	Time 0.080 (0.105)	Data 0.00101 (0.00095)	Tok/s 54143 (59682)	Loss/tok 3.0607 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][4840/6832]	Time 0.080 (0.105)	Data 0.00100 (0.00094)	Tok/s 54129 (60127)	Loss/tok 2.9858 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4840/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00095)	Tok/s 54082 (58860)	Loss/tok 3.0549 (3.1726)	Learning Rate [7.8125e-05]
2: TRAIN [3][4850/6832]	Time 0.068 (0.105)	Data 0.00089 (0.00095)	Tok/s 52475 (59668)	Loss/tok 3.0745 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][4850/6832]	Time 0.068 (0.105)	Data 0.00086 (0.00092)	Tok/s 52445 (59298)	Loss/tok 2.9436 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][4850/6832]	Time 0.068 (0.105)	Data 0.00089 (0.00094)	Tok/s 52480 (60113)	Loss/tok 2.9529 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][4850/6832]	Time 0.068 (0.105)	Data 0.00125 (0.00095)	Tok/s 52527 (58844)	Loss/tok 2.7810 (3.1725)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [3][4860/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00092)	Tok/s 74900 (59294)	Loss/tok 3.3650 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4860/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 74683 (58840)	Loss/tok 3.3330 (3.1724)	Learning Rate [7.8125e-05]
2: TRAIN [3][4860/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 74865 (59664)	Loss/tok 3.1191 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][4860/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 75575 (60108)	Loss/tok 3.3362 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][4870/6832]	Time 0.076 (0.105)	Data 0.00085 (0.00095)	Tok/s 52132 (59660)	Loss/tok 3.2095 (3.1696)	Learning Rate [7.8125e-05]
1: TRAIN [3][4870/6832]	Time 0.076 (0.105)	Data 0.00088 (0.00092)	Tok/s 52065 (59289)	Loss/tok 2.9033 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][4870/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00094)	Tok/s 54106 (60105)	Loss/tok 2.9816 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][4870/6832]	Time 0.076 (0.105)	Data 0.00095 (0.00095)	Tok/s 52109 (58833)	Loss/tok 2.9823 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][4880/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 80428 (59292)	Loss/tok 3.1157 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4880/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 80603 (59663)	Loss/tok 3.2539 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][4880/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 81439 (60108)	Loss/tok 3.0742 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][4880/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00095)	Tok/s 79864 (58837)	Loss/tok 3.2241 (3.1725)	Learning Rate [7.8125e-05]
2: TRAIN [3][4890/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00095)	Tok/s 52511 (59667)	Loss/tok 2.9577 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][4890/6832]	Time 0.061 (0.105)	Data 0.00090 (0.00092)	Tok/s 50557 (59297)	Loss/tok 2.9468 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4890/6832]	Time 0.061 (0.105)	Data 0.00092 (0.00095)	Tok/s 50580 (58843)	Loss/tok 2.8364 (3.1725)	Learning Rate [7.8125e-05]
3: TRAIN [3][4890/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00094)	Tok/s 52685 (60112)	Loss/tok 2.7563 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][4900/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00092)	Tok/s 67833 (59307)	Loss/tok 3.1914 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][4900/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00095)	Tok/s 67860 (58854)	Loss/tok 3.2907 (3.1725)	Learning Rate [7.8125e-05]
2: TRAIN [3][4900/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00095)	Tok/s 67625 (59678)	Loss/tok 3.1556 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][4900/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 67645 (60123)	Loss/tok 3.1697 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4910/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 92420 (59687)	Loss/tok 3.1214 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][4910/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00092)	Tok/s 91283 (59316)	Loss/tok 3.2003 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][4910/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 94147 (60133)	Loss/tok 3.0990 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][4910/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00095)	Tok/s 90263 (58863)	Loss/tok 3.0537 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][4920/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00092)	Tok/s 52459 (59315)	Loss/tok 2.8717 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][4920/6832]	Time 0.071 (0.105)	Data 0.00094 (0.00095)	Tok/s 52408 (59686)	Loss/tok 2.9369 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][4920/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00094)	Tok/s 52474 (60131)	Loss/tok 2.9948 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][4920/6832]	Time 0.071 (0.105)	Data 0.00098 (0.00095)	Tok/s 52365 (58862)	Loss/tok 2.8851 (3.1725)	Learning Rate [7.8125e-05]
2: TRAIN [3][4930/6832]	Time 0.068 (0.105)	Data 0.00095 (0.00095)	Tok/s 52357 (59689)	Loss/tok 3.0583 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][4930/6832]	Time 0.068 (0.105)	Data 0.00093 (0.00094)	Tok/s 52384 (60134)	Loss/tok 2.8773 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][4930/6832]	Time 0.069 (0.105)	Data 0.00090 (0.00092)	Tok/s 52301 (59318)	Loss/tok 2.8615 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][4930/6832]	Time 0.069 (0.105)	Data 0.00100 (0.00095)	Tok/s 52288 (58865)	Loss/tok 2.6397 (3.1726)	Learning Rate [7.8125e-05]
3: TRAIN [3][4940/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 73793 (60144)	Loss/tok 3.1921 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][4940/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00092)	Tok/s 73739 (59328)	Loss/tok 3.3226 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4940/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 73778 (59699)	Loss/tok 3.3030 (3.1697)	Learning Rate [7.8125e-05]
0: TRAIN [3][4940/6832]	Time 0.130 (0.105)	Data 0.00102 (0.00095)	Tok/s 72866 (58876)	Loss/tok 3.2144 (3.1725)	Learning Rate [7.8125e-05]
1: TRAIN [3][4950/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00092)	Tok/s 92062 (59335)	Loss/tok 3.0784 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][4950/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 93152 (59707)	Loss/tok 3.0598 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][4950/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 94983 (60152)	Loss/tok 3.0588 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][4950/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 91205 (58883)	Loss/tok 2.9626 (3.1725)	Learning Rate [7.8125e-05]
2: TRAIN [3][4960/6832]	Time 0.098 (0.105)	Data 0.00094 (0.00095)	Tok/s 51919 (59706)	Loss/tok 2.9927 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][4960/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00092)	Tok/s 50781 (59335)	Loss/tok 3.1281 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][4960/6832]	Time 0.098 (0.105)	Data 0.00096 (0.00094)	Tok/s 52084 (60151)	Loss/tok 3.0792 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][4960/6832]	Time 0.098 (0.105)	Data 0.00100 (0.00095)	Tok/s 50824 (58884)	Loss/tok 3.1505 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][4970/6832]	Time 0.058 (0.105)	Data 0.00087 (0.00092)	Tok/s 48718 (59328)	Loss/tok 2.6082 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][4970/6832]	Time 0.058 (0.105)	Data 0.00091 (0.00095)	Tok/s 48671 (59699)	Loss/tok 2.8321 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][4970/6832]	Time 0.058 (0.105)	Data 0.00089 (0.00094)	Tok/s 48731 (60144)	Loss/tok 2.7089 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][4970/6832]	Time 0.058 (0.105)	Data 0.00105 (0.00095)	Tok/s 46925 (58878)	Loss/tok 2.7585 (3.1724)	Learning Rate [7.8125e-05]
1: TRAIN [3][4980/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00092)	Tok/s 59559 (59333)	Loss/tok 3.4439 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][4980/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 60043 (59704)	Loss/tok 3.3760 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][4980/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00094)	Tok/s 60011 (60149)	Loss/tok 3.2221 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][4980/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 59104 (58883)	Loss/tok 3.2534 (3.1724)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][4990/6832]	Time 0.108 (0.105)	Data 0.00084 (0.00092)	Tok/s 53159 (59320)	Loss/tok 3.2257 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][4990/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00095)	Tok/s 53134 (59691)	Loss/tok 3.1334 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][4990/6832]	Time 0.108 (0.105)	Data 0.00089 (0.00094)	Tok/s 53125 (60136)	Loss/tok 3.0164 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][4990/6832]	Time 0.108 (0.105)	Data 0.00096 (0.00095)	Tok/s 53185 (58870)	Loss/tok 3.0461 (3.1723)	Learning Rate [7.8125e-05]
1: TRAIN [3][5000/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00092)	Tok/s 56529 (59324)	Loss/tok 3.4543 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][5000/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 57532 (60140)	Loss/tok 3.1714 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][5000/6832]	Time 0.127 (0.105)	Data 0.00104 (0.00095)	Tok/s 57137 (59695)	Loss/tok 3.2316 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][5000/6832]	Time 0.127 (0.105)	Data 0.00107 (0.00095)	Tok/s 56516 (58874)	Loss/tok 3.2698 (3.1723)	Learning Rate [7.8125e-05]
1: TRAIN [3][5010/6832]	Time 0.094 (0.105)	Data 0.00085 (0.00092)	Tok/s 51768 (59320)	Loss/tok 3.0753 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][5010/6832]	Time 0.094 (0.105)	Data 0.00096 (0.00095)	Tok/s 51812 (58869)	Loss/tok 3.0021 (3.1722)	Learning Rate [7.8125e-05]
3: TRAIN [3][5010/6832]	Time 0.094 (0.105)	Data 0.00089 (0.00094)	Tok/s 53138 (60136)	Loss/tok 3.0029 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5010/6832]	Time 0.094 (0.105)	Data 0.00095 (0.00095)	Tok/s 51824 (59690)	Loss/tok 3.0107 (3.1696)	Learning Rate [7.8125e-05]
1: TRAIN [3][5020/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00092)	Tok/s 54468 (59304)	Loss/tok 3.1334 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5020/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00095)	Tok/s 54906 (59675)	Loss/tok 3.1458 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5020/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00094)	Tok/s 54888 (60120)	Loss/tok 3.2772 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5020/6832]	Time 0.116 (0.105)	Data 0.00101 (0.00095)	Tok/s 53889 (58854)	Loss/tok 3.2000 (3.1720)	Learning Rate [7.8125e-05]
2: TRAIN [3][5030/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 68031 (59684)	Loss/tok 3.2832 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5030/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 68177 (60129)	Loss/tok 3.3615 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][5030/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00092)	Tok/s 68028 (59313)	Loss/tok 3.3499 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5030/6832]	Time 0.128 (0.105)	Data 0.00108 (0.00095)	Tok/s 67989 (58863)	Loss/tok 3.3532 (3.1720)	Learning Rate [7.8125e-05]
2: TRAIN [3][5040/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00095)	Tok/s 53095 (59678)	Loss/tok 3.5224 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5040/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00094)	Tok/s 53102 (60123)	Loss/tok 3.3318 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][5040/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00092)	Tok/s 53093 (59307)	Loss/tok 3.1930 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5040/6832]	Time 0.119 (0.105)	Data 0.00110 (0.00095)	Tok/s 52618 (58858)	Loss/tok 3.1542 (3.1721)	Learning Rate [7.8125e-05]
2: TRAIN [3][5050/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00095)	Tok/s 54843 (59672)	Loss/tok 3.1695 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][5050/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00092)	Tok/s 54813 (59302)	Loss/tok 3.4131 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][5050/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 54842 (60117)	Loss/tok 3.2939 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5050/6832]	Time 0.117 (0.105)	Data 0.00099 (0.00095)	Tok/s 54828 (58852)	Loss/tok 3.3235 (3.1721)	Learning Rate [7.8125e-05]
1: TRAIN [3][5060/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00092)	Tok/s 71624 (59297)	Loss/tok 3.2325 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][5060/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 72438 (59667)	Loss/tok 3.2241 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5060/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 72427 (60112)	Loss/tok 3.3365 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5060/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 71540 (58848)	Loss/tok 3.3719 (3.1720)	Learning Rate [7.8125e-05]
1: TRAIN [3][5070/6832]	Time 0.087 (0.105)	Data 0.00086 (0.00092)	Tok/s 52436 (59289)	Loss/tok 3.1350 (3.1682)	Learning Rate [7.8125e-05]
3: TRAIN [3][5070/6832]	Time 0.087 (0.105)	Data 0.00096 (0.00094)	Tok/s 52846 (60104)	Loss/tok 2.9782 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5070/6832]	Time 0.087 (0.105)	Data 0.00098 (0.00095)	Tok/s 52837 (59659)	Loss/tok 3.2184 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][5070/6832]	Time 0.087 (0.105)	Data 0.00110 (0.00095)	Tok/s 51419 (58840)	Loss/tok 3.0821 (3.1719)	Learning Rate [7.8125e-05]
1: TRAIN [3][5080/6832]	Time 0.089 (0.105)	Data 0.00085 (0.00092)	Tok/s 53508 (59288)	Loss/tok 3.1271 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][5080/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00095)	Tok/s 53533 (59658)	Loss/tok 3.1755 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5080/6832]	Time 0.088 (0.105)	Data 0.00088 (0.00094)	Tok/s 53520 (60102)	Loss/tok 3.2201 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5080/6832]	Time 0.089 (0.105)	Data 0.00100 (0.00095)	Tok/s 53494 (58839)	Loss/tok 2.9474 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5090/6832]	Time 0.124 (0.105)	Data 0.00105 (0.00092)	Tok/s 61812 (59294)	Loss/tok 3.2784 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5090/6832]	Time 0.124 (0.105)	Data 0.00106 (0.00095)	Tok/s 62754 (59665)	Loss/tok 3.4011 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5090/6832]	Time 0.124 (0.105)	Data 0.00106 (0.00094)	Tok/s 62747 (60108)	Loss/tok 3.2565 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5090/6832]	Time 0.125 (0.105)	Data 0.00111 (0.00095)	Tok/s 61681 (58846)	Loss/tok 3.3181 (3.1719)	Learning Rate [7.8125e-05]
1: TRAIN [3][5100/6832]	Time 0.062 (0.105)	Data 0.00090 (0.00092)	Tok/s 51240 (59283)	Loss/tok 2.7877 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][5100/6832]	Time 0.062 (0.105)	Data 0.00091 (0.00095)	Tok/s 51661 (59654)	Loss/tok 2.9913 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5100/6832]	Time 0.062 (0.105)	Data 0.00088 (0.00094)	Tok/s 53294 (60097)	Loss/tok 2.9662 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5100/6832]	Time 0.062 (0.105)	Data 0.00095 (0.00095)	Tok/s 51280 (58836)	Loss/tok 2.7535 (3.1718)	Learning Rate [7.8125e-05]
2: TRAIN [3][5110/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00095)	Tok/s 52886 (59652)	Loss/tok 3.2502 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][5110/6832]	Time 0.099 (0.105)	Data 0.00087 (0.00092)	Tok/s 52869 (59281)	Loss/tok 3.0320 (3.1680)	Learning Rate [7.8125e-05]
3: TRAIN [3][5110/6832]	Time 0.099 (0.105)	Data 0.00088 (0.00094)	Tok/s 52886 (60095)	Loss/tok 3.1965 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5110/6832]	Time 0.099 (0.105)	Data 0.00106 (0.00095)	Tok/s 52855 (58833)	Loss/tok 3.1438 (3.1717)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [3][5120/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00092)	Tok/s 79378 (59284)	Loss/tok 3.1928 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][5120/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 79773 (59656)	Loss/tok 3.1616 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5120/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 80351 (60099)	Loss/tok 3.1960 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5120/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00095)	Tok/s 79139 (58837)	Loss/tok 3.3061 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5130/6832]	Time 0.125 (0.105)	Data 0.00098 (0.00092)	Tok/s 65461 (59287)	Loss/tok 3.2536 (3.1681)	Learning Rate [7.8125e-05]
3: TRAIN [3][5130/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00094)	Tok/s 66324 (60102)	Loss/tok 3.3203 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5130/6832]	Time 0.125 (0.105)	Data 0.00094 (0.00095)	Tok/s 65461 (59659)	Loss/tok 3.2176 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][5130/6832]	Time 0.125 (0.105)	Data 0.00104 (0.00095)	Tok/s 65479 (58841)	Loss/tok 3.1844 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5140/6832]	Time 0.104 (0.105)	Data 0.00086 (0.00092)	Tok/s 54396 (59281)	Loss/tok 3.0511 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][5140/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00095)	Tok/s 54411 (59652)	Loss/tok 3.2145 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5140/6832]	Time 0.104 (0.105)	Data 0.00088 (0.00094)	Tok/s 54717 (60095)	Loss/tok 3.0905 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5140/6832]	Time 0.104 (0.105)	Data 0.00096 (0.00095)	Tok/s 54351 (58834)	Loss/tok 3.0966 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5150/6832]	Time 0.127 (0.105)	Data 0.00084 (0.00092)	Tok/s 68285 (59297)	Loss/tok 3.3164 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5150/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00095)	Tok/s 68394 (59668)	Loss/tok 3.3369 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5150/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 68414 (60111)	Loss/tok 3.1051 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5150/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 68048 (58851)	Loss/tok 3.3273 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5160/6832]	Time 0.073 (0.105)	Data 0.00085 (0.00092)	Tok/s 52887 (59295)	Loss/tok 2.8368 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][5160/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00095)	Tok/s 54382 (59666)	Loss/tok 2.9469 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5160/6832]	Time 0.073 (0.105)	Data 0.00087 (0.00094)	Tok/s 54663 (60108)	Loss/tok 2.8964 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5160/6832]	Time 0.073 (0.105)	Data 0.00101 (0.00095)	Tok/s 52870 (58849)	Loss/tok 2.9628 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5170/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00092)	Tok/s 74287 (59293)	Loss/tok 3.3127 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5170/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00095)	Tok/s 74528 (59665)	Loss/tok 3.1962 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5170/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 74535 (60107)	Loss/tok 3.0945 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][5170/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00095)	Tok/s 73514 (58845)	Loss/tok 3.3035 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5180/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00092)	Tok/s 68182 (59286)	Loss/tok 3.3021 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][5180/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 68417 (60099)	Loss/tok 3.1984 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][5180/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00095)	Tok/s 68138 (59658)	Loss/tok 3.2711 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][5180/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00095)	Tok/s 68152 (58839)	Loss/tok 3.2896 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5190/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00092)	Tok/s 60096 (59282)	Loss/tok 3.1552 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][5190/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00094)	Tok/s 60081 (60095)	Loss/tok 3.2886 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5190/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00095)	Tok/s 60081 (59654)	Loss/tok 3.2220 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][5190/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00095)	Tok/s 60016 (58836)	Loss/tok 3.2413 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5200/6832]	Time 0.069 (0.105)	Data 0.00086 (0.00092)	Tok/s 51646 (59278)	Loss/tok 2.7965 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][5200/6832]	Time 0.069 (0.105)	Data 0.00099 (0.00095)	Tok/s 51642 (59650)	Loss/tok 3.0103 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5200/6832]	Time 0.069 (0.105)	Data 0.00092 (0.00094)	Tok/s 51611 (60090)	Loss/tok 2.7783 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5200/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00095)	Tok/s 51548 (58832)	Loss/tok 2.8289 (3.1718)	Learning Rate [7.8125e-05]
2: TRAIN [3][5210/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00095)	Tok/s 56519 (59640)	Loss/tok 3.2745 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][5210/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00092)	Tok/s 55900 (59268)	Loss/tok 3.2631 (3.1682)	Learning Rate [7.8125e-05]
3: TRAIN [3][5210/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00094)	Tok/s 56977 (60081)	Loss/tok 3.0080 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5210/6832]	Time 0.117 (0.105)	Data 0.00106 (0.00095)	Tok/s 55878 (58820)	Loss/tok 3.2591 (3.1717)	Learning Rate [7.8125e-05]
2: TRAIN [3][5220/6832]	Time 0.085 (0.105)	Data 0.00088 (0.00095)	Tok/s 52791 (59638)	Loss/tok 3.1252 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][5220/6832]	Time 0.085 (0.105)	Data 0.00086 (0.00092)	Tok/s 52747 (59266)	Loss/tok 2.9850 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][5220/6832]	Time 0.085 (0.105)	Data 0.00086 (0.00094)	Tok/s 52774 (60080)	Loss/tok 2.9344 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5220/6832]	Time 0.085 (0.105)	Data 0.00098 (0.00095)	Tok/s 51335 (58818)	Loss/tok 3.0768 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5230/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00092)	Tok/s 63134 (59262)	Loss/tok 3.4854 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][5230/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00095)	Tok/s 63470 (59634)	Loss/tok 3.2155 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5230/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 63491 (60075)	Loss/tok 3.1513 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5230/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00095)	Tok/s 62663 (58814)	Loss/tok 3.0959 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][5240/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00095)	Tok/s 53610 (59623)	Loss/tok 3.3312 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5240/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00094)	Tok/s 53658 (60065)	Loss/tok 3.0543 (3.1683)	Learning Rate [7.8125e-05]
1: TRAIN [3][5240/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00092)	Tok/s 52591 (59251)	Loss/tok 3.0695 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5240/6832]	Time 0.122 (0.105)	Data 0.00098 (0.00095)	Tok/s 52615 (58804)	Loss/tok 3.1953 (3.1715)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][5250/6832]	Time 0.102 (0.105)	Data 0.00100 (0.00092)	Tok/s 52624 (59256)	Loss/tok 3.0064 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][5250/6832]	Time 0.102 (0.105)	Data 0.00109 (0.00095)	Tok/s 52669 (59628)	Loss/tok 3.1037 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5250/6832]	Time 0.102 (0.105)	Data 0.00101 (0.00094)	Tok/s 52691 (60069)	Loss/tok 3.2278 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5250/6832]	Time 0.102 (0.105)	Data 0.00096 (0.00095)	Tok/s 52103 (58809)	Loss/tok 3.1679 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5260/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00092)	Tok/s 83442 (59258)	Loss/tok 3.1841 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][5260/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00095)	Tok/s 83739 (59630)	Loss/tok 3.0898 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5260/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00094)	Tok/s 84450 (60071)	Loss/tok 3.0951 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5260/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00095)	Tok/s 82789 (58811)	Loss/tok 2.9796 (3.1717)	Learning Rate [7.8125e-05]
2: TRAIN [3][5270/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00095)	Tok/s 55695 (59623)	Loss/tok 3.1602 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5270/6832]	Time 0.097 (0.105)	Data 0.00086 (0.00094)	Tok/s 55705 (60064)	Loss/tok 3.1255 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][5270/6832]	Time 0.096 (0.105)	Data 0.00084 (0.00092)	Tok/s 55718 (59251)	Loss/tok 3.0915 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5270/6832]	Time 0.097 (0.105)	Data 0.00094 (0.00095)	Tok/s 55630 (58805)	Loss/tok 3.0949 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5280/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00092)	Tok/s 59516 (59247)	Loss/tok 3.1913 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][5280/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00094)	Tok/s 60460 (60059)	Loss/tok 3.2691 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][5280/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00095)	Tok/s 60458 (59619)	Loss/tok 3.2797 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][5280/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00095)	Tok/s 59405 (58801)	Loss/tok 3.2448 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5290/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00092)	Tok/s 70226 (59248)	Loss/tok 3.2196 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][5290/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 71203 (60059)	Loss/tok 3.1863 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][5290/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00095)	Tok/s 70451 (59619)	Loss/tok 3.1207 (3.1697)	Learning Rate [7.8125e-05]
0: TRAIN [3][5290/6832]	Time 0.129 (0.105)	Data 0.00103 (0.00095)	Tok/s 70231 (58802)	Loss/tok 3.2677 (3.1717)	Learning Rate [7.8125e-05]
2: TRAIN [3][5300/6832]	Time 0.062 (0.105)	Data 0.00088 (0.00095)	Tok/s 51589 (59616)	Loss/tok 2.8022 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5300/6832]	Time 0.062 (0.105)	Data 0.00086 (0.00094)	Tok/s 53586 (60056)	Loss/tok 2.7125 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][5300/6832]	Time 0.062 (0.105)	Data 0.00084 (0.00092)	Tok/s 51586 (59245)	Loss/tok 2.6463 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][5300/6832]	Time 0.062 (0.105)	Data 0.00095 (0.00095)	Tok/s 51537 (58799)	Loss/tok 2.6875 (3.1717)	Learning Rate [7.8125e-05]
2: TRAIN [3][5310/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 74965 (59612)	Loss/tok 3.1379 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][5310/6832]	Time 0.130 (0.105)	Data 0.00082 (0.00092)	Tok/s 74922 (59241)	Loss/tok 3.3211 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][5310/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00094)	Tok/s 75923 (60052)	Loss/tok 3.2727 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5310/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 74989 (58796)	Loss/tok 3.2497 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5320/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00092)	Tok/s 61121 (59241)	Loss/tok 3.2555 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][5320/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 61555 (59613)	Loss/tok 3.3673 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5320/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 62080 (60054)	Loss/tok 3.3354 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5320/6832]	Time 0.128 (0.105)	Data 0.00106 (0.00095)	Tok/s 61094 (58794)	Loss/tok 3.2792 (3.1717)	Learning Rate [7.8125e-05]
2: TRAIN [3][5330/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00095)	Tok/s 62883 (59620)	Loss/tok 3.3525 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5330/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 62879 (60060)	Loss/tok 3.2245 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][5330/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00092)	Tok/s 62843 (59248)	Loss/tok 3.4284 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][5330/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00095)	Tok/s 62817 (58801)	Loss/tok 3.3404 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5340/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00092)	Tok/s 67388 (59253)	Loss/tok 3.5012 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][5340/6832]	Time 0.129 (0.105)	Data 0.00119 (0.00095)	Tok/s 67503 (59624)	Loss/tok 3.1404 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5340/6832]	Time 0.129 (0.105)	Data 0.00116 (0.00094)	Tok/s 67484 (60065)	Loss/tok 3.2895 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5340/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00095)	Tok/s 67055 (58806)	Loss/tok 3.2634 (3.1719)	Learning Rate [7.8125e-05]
1: TRAIN [3][5350/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00092)	Tok/s 59983 (59250)	Loss/tok 3.2514 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][5350/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00095)	Tok/s 60000 (59621)	Loss/tok 3.2053 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5350/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00094)	Tok/s 61012 (60062)	Loss/tok 3.2774 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5350/6832]	Time 0.122 (0.105)	Data 0.00095 (0.00095)	Tok/s 59974 (58804)	Loss/tok 3.1799 (3.1719)	Learning Rate [7.8125e-05]
2: TRAIN [3][5360/6832]	Time 0.125 (0.105)	Data 0.00088 (0.00095)	Tok/s 62968 (59621)	Loss/tok 3.0607 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5360/6832]	Time 0.125 (0.105)	Data 0.00086 (0.00094)	Tok/s 63554 (60061)	Loss/tok 3.3659 (3.1688)	Learning Rate [7.8125e-05]
1: TRAIN [3][5360/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00092)	Tok/s 62508 (59250)	Loss/tok 3.3284 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][5360/6832]	Time 0.125 (0.105)	Data 0.00109 (0.00095)	Tok/s 62452 (58804)	Loss/tok 3.3401 (3.1720)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][5370/6832]	Time 0.108 (0.105)	Data 0.00122 (0.00095)	Tok/s 52102 (59616)	Loss/tok 3.1535 (3.1698)	Learning Rate [7.8125e-05]
1: TRAIN [3][5370/6832]	Time 0.108 (0.105)	Data 0.00099 (0.00092)	Tok/s 51421 (59246)	Loss/tok 3.0205 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5370/6832]	Time 0.108 (0.105)	Data 0.00122 (0.00094)	Tok/s 52098 (60056)	Loss/tok 3.1074 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][5370/6832]	Time 0.108 (0.105)	Data 0.00101 (0.00095)	Tok/s 50834 (58800)	Loss/tok 3.2988 (3.1720)	Learning Rate [7.8125e-05]
1: TRAIN [3][5380/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00092)	Tok/s 56534 (59254)	Loss/tok 3.1317 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][5380/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00095)	Tok/s 56557 (59625)	Loss/tok 3.2670 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5380/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00094)	Tok/s 57482 (60065)	Loss/tok 3.3321 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][5380/6832]	Time 0.116 (0.105)	Data 0.00099 (0.00095)	Tok/s 56509 (58809)	Loss/tok 3.2887 (3.1721)	Learning Rate [7.8125e-05]
1: TRAIN [3][5390/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00092)	Tok/s 56196 (59249)	Loss/tok 3.1118 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][5390/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00095)	Tok/s 57156 (59620)	Loss/tok 3.1902 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5390/6832]	Time 0.112 (0.105)	Data 0.00083 (0.00094)	Tok/s 57137 (60061)	Loss/tok 3.1366 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][5390/6832]	Time 0.112 (0.105)	Data 0.00104 (0.00095)	Tok/s 56033 (58805)	Loss/tok 3.0480 (3.1720)	Learning Rate [7.8125e-05]
1: TRAIN [3][5400/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00092)	Tok/s 63015 (59250)	Loss/tok 3.2426 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][5400/6832]	Time 0.123 (0.105)	Data 0.00093 (0.00095)	Tok/s 63304 (59620)	Loss/tok 3.4407 (3.1698)	Learning Rate [7.8125e-05]
3: TRAIN [3][5400/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00094)	Tok/s 63297 (60060)	Loss/tok 3.2333 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][5400/6832]	Time 0.123 (0.105)	Data 0.00100 (0.00095)	Tok/s 62276 (58806)	Loss/tok 3.2687 (3.1720)	Learning Rate [7.8125e-05]
2: TRAIN [3][5410/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00095)	Tok/s 53561 (59624)	Loss/tok 3.0118 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5410/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00094)	Tok/s 53553 (60064)	Loss/tok 3.0765 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][5410/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00092)	Tok/s 52659 (59253)	Loss/tok 2.8202 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][5410/6832]	Time 0.091 (0.105)	Data 0.00106 (0.00095)	Tok/s 52108 (58810)	Loss/tok 3.1586 (3.1720)	Learning Rate [7.8125e-05]
1: TRAIN [3][5420/6832]	Time 0.107 (0.105)	Data 0.00090 (0.00092)	Tok/s 53634 (59257)	Loss/tok 3.1808 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][5420/6832]	Time 0.107 (0.105)	Data 0.00090 (0.00095)	Tok/s 53616 (59628)	Loss/tok 3.1435 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5420/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00094)	Tok/s 53605 (60068)	Loss/tok 3.2216 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5420/6832]	Time 0.107 (0.105)	Data 0.00099 (0.00095)	Tok/s 53619 (58814)	Loss/tok 3.2465 (3.1720)	Learning Rate [7.8125e-05]
1: TRAIN [3][5430/6832]	Time 0.064 (0.105)	Data 0.00085 (0.00092)	Tok/s 49959 (59255)	Loss/tok 2.7674 (3.1693)	Learning Rate [7.8125e-05]
2: TRAIN [3][5430/6832]	Time 0.064 (0.105)	Data 0.00089 (0.00095)	Tok/s 49978 (59625)	Loss/tok 2.7404 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5430/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00094)	Tok/s 51905 (60065)	Loss/tok 2.8426 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5430/6832]	Time 0.064 (0.105)	Data 0.00097 (0.00095)	Tok/s 49934 (58812)	Loss/tok 2.8380 (3.1720)	Learning Rate [7.8125e-05]
1: TRAIN [3][5440/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00092)	Tok/s 56911 (59252)	Loss/tok 3.2752 (3.1694)	Learning Rate [7.8125e-05]
2: TRAIN [3][5440/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00095)	Tok/s 56960 (59622)	Loss/tok 3.3532 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5440/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00094)	Tok/s 56935 (60062)	Loss/tok 3.4039 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][5440/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00095)	Tok/s 56918 (58809)	Loss/tok 3.3260 (3.1721)	Learning Rate [7.8125e-05]
1: TRAIN [3][5450/6832]	Time 0.125 (0.105)	Data 0.00092 (0.00092)	Tok/s 61403 (59251)	Loss/tok 3.0593 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5450/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00094)	Tok/s 61376 (60061)	Loss/tok 3.2695 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5450/6832]	Time 0.125 (0.105)	Data 0.00097 (0.00095)	Tok/s 61374 (59621)	Loss/tok 3.4544 (3.1698)	Learning Rate [7.8125e-05]
0: TRAIN [3][5450/6832]	Time 0.125 (0.105)	Data 0.00098 (0.00095)	Tok/s 60965 (58808)	Loss/tok 3.2858 (3.1720)	Learning Rate [7.8125e-05]
1: TRAIN [3][5460/6832]	Time 0.060 (0.105)	Data 0.00091 (0.00092)	Tok/s 51204 (59248)	Loss/tok 2.8334 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][5460/6832]	Time 0.060 (0.105)	Data 0.00090 (0.00094)	Tok/s 53304 (60059)	Loss/tok 2.8106 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][5460/6832]	Time 0.060 (0.105)	Data 0.00091 (0.00095)	Tok/s 51645 (59618)	Loss/tok 2.7102 (3.1696)	Learning Rate [7.8125e-05]
0: TRAIN [3][5460/6832]	Time 0.060 (0.105)	Data 0.00098 (0.00095)	Tok/s 51129 (58806)	Loss/tok 2.6769 (3.1719)	Learning Rate [7.8125e-05]
3: TRAIN [3][5470/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 60161 (60053)	Loss/tok 3.2766 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][5470/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 59717 (59612)	Loss/tok 3.1600 (3.1697)	Learning Rate [7.8125e-05]
1: TRAIN [3][5470/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00092)	Tok/s 59140 (59242)	Loss/tok 3.3733 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][5470/6832]	Time 0.130 (0.105)	Data 0.00114 (0.00095)	Tok/s 59127 (58800)	Loss/tok 3.1255 (3.1719)	Learning Rate [7.8125e-05]
1: TRAIN [3][5480/6832]	Time 0.096 (0.105)	Data 0.00086 (0.00092)	Tok/s 50675 (59236)	Loss/tok 3.0828 (3.1692)	Learning Rate [7.8125e-05]
2: TRAIN [3][5480/6832]	Time 0.096 (0.105)	Data 0.00096 (0.00095)	Tok/s 50781 (59606)	Loss/tok 3.1418 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5480/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00094)	Tok/s 52058 (60048)	Loss/tok 2.9565 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5480/6832]	Time 0.096 (0.105)	Data 0.00104 (0.00095)	Tok/s 50670 (58794)	Loss/tok 3.1908 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5490/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 77632 (59234)	Loss/tok 3.0691 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][5490/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00095)	Tok/s 77657 (59604)	Loss/tok 3.1263 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5490/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 78116 (60046)	Loss/tok 3.3163 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5490/6832]	Time 0.130 (0.105)	Data 0.00102 (0.00095)	Tok/s 76695 (58792)	Loss/tok 3.2743 (3.1717)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][5500/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00092)	Tok/s 54757 (59245)	Loss/tok 3.0175 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][5500/6832]	Time 0.086 (0.105)	Data 0.00098 (0.00095)	Tok/s 54781 (59615)	Loss/tok 3.0560 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5500/6832]	Time 0.087 (0.105)	Data 0.00096 (0.00094)	Tok/s 54750 (60057)	Loss/tok 3.2214 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5500/6832]	Time 0.087 (0.105)	Data 0.00114 (0.00095)	Tok/s 54748 (58804)	Loss/tok 3.1566 (3.1718)	Learning Rate [7.8125e-05]
2: TRAIN [3][5510/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 66752 (59605)	Loss/tok 3.3420 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5510/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 67592 (60047)	Loss/tok 3.2104 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][5510/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00092)	Tok/s 66830 (59233)	Loss/tok 3.4774 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][5510/6832]	Time 0.128 (0.105)	Data 0.00104 (0.00095)	Tok/s 66850 (58791)	Loss/tok 3.2104 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5520/6832]	Time 0.131 (0.105)	Data 0.00080 (0.00092)	Tok/s 78701 (59241)	Loss/tok 3.2239 (3.1691)	Learning Rate [7.8125e-05]
2: TRAIN [3][5520/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00095)	Tok/s 79390 (59612)	Loss/tok 3.3285 (3.1697)	Learning Rate [7.8125e-05]
3: TRAIN [3][5520/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 79372 (60053)	Loss/tok 3.1230 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][5520/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00095)	Tok/s 78413 (58798)	Loss/tok 3.3416 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5530/6832]	Time 0.117 (0.105)	Data 0.00082 (0.00092)	Tok/s 57800 (59237)	Loss/tok 3.2293 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5530/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00095)	Tok/s 57844 (59608)	Loss/tok 3.0510 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5530/6832]	Time 0.117 (0.105)	Data 0.00083 (0.00094)	Tok/s 57823 (60050)	Loss/tok 3.3300 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5530/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00095)	Tok/s 57560 (58795)	Loss/tok 3.2052 (3.1717)	Learning Rate [7.8125e-05]
2: TRAIN [3][5540/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00095)	Tok/s 71063 (59608)	Loss/tok 3.3319 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5540/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 71907 (60049)	Loss/tok 3.2689 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][5540/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 71012 (59237)	Loss/tok 3.2122 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][5540/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00095)	Tok/s 71021 (58796)	Loss/tok 3.3681 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5550/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00092)	Tok/s 53530 (59244)	Loss/tok 3.3331 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][5550/6832]	Time 0.115 (0.105)	Data 0.00083 (0.00094)	Tok/s 53527 (60056)	Loss/tok 3.3417 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5550/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00095)	Tok/s 53529 (59615)	Loss/tok 3.2521 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][5550/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00095)	Tok/s 52647 (58803)	Loss/tok 3.2065 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5560/6832]	Time 0.131 (0.105)	Data 0.00082 (0.00092)	Tok/s 63551 (59236)	Loss/tok 3.3869 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5560/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 63532 (59607)	Loss/tok 3.2609 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5560/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 63524 (60049)	Loss/tok 3.2906 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5560/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00095)	Tok/s 63237 (58794)	Loss/tok 3.2945 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5570/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00092)	Tok/s 53218 (59244)	Loss/tok 3.2585 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5570/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00095)	Tok/s 53145 (59616)	Loss/tok 3.2359 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5570/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00094)	Tok/s 53871 (60057)	Loss/tok 3.2169 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5570/6832]	Time 0.118 (0.105)	Data 0.00107 (0.00095)	Tok/s 53209 (58802)	Loss/tok 3.3043 (3.1718)	Learning Rate [7.8125e-05]
2: TRAIN [3][5580/6832]	Time 0.048 (0.105)	Data 0.00096 (0.00095)	Tok/s 44899 (59614)	Loss/tok 2.4129 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5580/6832]	Time 0.048 (0.105)	Data 0.00095 (0.00094)	Tok/s 46577 (60056)	Loss/tok 2.3844 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][5580/6832]	Time 0.048 (0.105)	Data 0.00094 (0.00092)	Tok/s 42611 (59242)	Loss/tok 2.4691 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5580/6832]	Time 0.049 (0.105)	Data 0.00102 (0.00095)	Tok/s 40416 (58800)	Loss/tok 2.3872 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5590/6832]	Time 0.098 (0.105)	Data 0.00091 (0.00092)	Tok/s 52461 (59247)	Loss/tok 3.1331 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5590/6832]	Time 0.098 (0.105)	Data 0.00097 (0.00095)	Tok/s 52337 (59619)	Loss/tok 3.2424 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][5590/6832]	Time 0.098 (0.105)	Data 0.00096 (0.00094)	Tok/s 52359 (60061)	Loss/tok 3.0987 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5590/6832]	Time 0.098 (0.105)	Data 0.00094 (0.00095)	Tok/s 51737 (58804)	Loss/tok 3.3067 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5600/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00092)	Tok/s 54604 (59249)	Loss/tok 3.0261 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][5600/6832]	Time 0.101 (0.105)	Data 0.00090 (0.00095)	Tok/s 54564 (59621)	Loss/tok 3.1147 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5600/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00094)	Tok/s 54566 (60064)	Loss/tok 3.3150 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5600/6832]	Time 0.101 (0.105)	Data 0.00096 (0.00095)	Tok/s 54599 (58806)	Loss/tok 3.1207 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5610/6832]	Time 0.044 (0.105)	Data 0.00083 (0.00092)	Tok/s 32598 (59247)	Loss/tok 2.1163 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][5610/6832]	Time 0.044 (0.105)	Data 0.00086 (0.00095)	Tok/s 37934 (59620)	Loss/tok 2.0452 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][5610/6832]	Time 0.045 (0.105)	Data 0.00084 (0.00094)	Tok/s 41675 (60063)	Loss/tok 2.2043 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5610/6832]	Time 0.044 (0.105)	Data 0.00095 (0.00096)	Tok/s 21502 (58803)	Loss/tok 1.6858 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][5620/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 70452 (59620)	Loss/tok 3.4001 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5620/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 70483 (60063)	Loss/tok 3.2639 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][5620/6832]	Time 0.131 (0.105)	Data 0.00083 (0.00092)	Tok/s 69471 (59248)	Loss/tok 3.4583 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5620/6832]	Time 0.131 (0.105)	Data 0.00109 (0.00096)	Tok/s 69466 (58804)	Loss/tok 3.2014 (3.1716)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][5630/6832]	Time 0.128 (0.105)	Data 0.00082 (0.00092)	Tok/s 68769 (59243)	Loss/tok 3.3255 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][5630/6832]	Time 0.128 (0.105)	Data 0.00082 (0.00095)	Tok/s 68808 (59616)	Loss/tok 3.3224 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5630/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 70015 (60059)	Loss/tok 3.1626 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5630/6832]	Time 0.128 (0.105)	Data 0.00102 (0.00096)	Tok/s 68781 (58799)	Loss/tok 3.2129 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5640/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00092)	Tok/s 81321 (59238)	Loss/tok 3.1269 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5640/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00095)	Tok/s 81772 (59610)	Loss/tok 3.1066 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][5640/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 82257 (60053)	Loss/tok 3.1038 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5640/6832]	Time 0.132 (0.105)	Data 0.00108 (0.00096)	Tok/s 80959 (58794)	Loss/tok 3.1476 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][5650/6832]	Time 0.096 (0.105)	Data 0.00087 (0.00092)	Tok/s 53115 (59238)	Loss/tok 3.2279 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5650/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00095)	Tok/s 53103 (59610)	Loss/tok 3.3928 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5650/6832]	Time 0.096 (0.105)	Data 0.00090 (0.00094)	Tok/s 53088 (60053)	Loss/tok 2.9955 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5650/6832]	Time 0.097 (0.105)	Data 0.00110 (0.00096)	Tok/s 53045 (58795)	Loss/tok 3.1902 (3.1715)	Learning Rate [7.8125e-05]
0: Gradient norm: inf
2: Gradient norm: inf
3: Gradient norm: inf
1: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
1: Skipped batch, new scale: 4096.0
2: Skipped batch, new scale: 4096.0
3: Skipped batch, new scale: 4096.0
1: TRAIN [3][5660/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00092)	Tok/s 77389 (59244)	Loss/tok 3.0985 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][5660/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 77398 (59616)	Loss/tok 3.3048 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][5660/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00094)	Tok/s 78334 (60059)	Loss/tok 3.2064 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5660/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00096)	Tok/s 77090 (58800)	Loss/tok 3.2434 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][5670/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00092)	Tok/s 60117 (59248)	Loss/tok 3.1048 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][5670/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00094)	Tok/s 61171 (60063)	Loss/tok 3.0873 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][5670/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00095)	Tok/s 61167 (59621)	Loss/tok 3.1922 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][5670/6832]	Time 0.113 (0.105)	Data 0.00117 (0.00096)	Tok/s 59952 (58805)	Loss/tok 3.1075 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][5680/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00092)	Tok/s 61170 (59247)	Loss/tok 3.4903 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][5680/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00095)	Tok/s 61162 (59618)	Loss/tok 3.3037 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][5680/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 61244 (60061)	Loss/tok 3.3444 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][5680/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00096)	Tok/s 61199 (58804)	Loss/tok 3.2394 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][5690/6832]	Time 0.107 (0.105)	Data 0.00087 (0.00095)	Tok/s 52466 (59617)	Loss/tok 3.2948 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5690/6832]	Time 0.107 (0.105)	Data 0.00085 (0.00094)	Tok/s 52893 (60059)	Loss/tok 3.3087 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][5690/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00092)	Tok/s 52463 (59245)	Loss/tok 3.2162 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][5690/6832]	Time 0.107 (0.105)	Data 0.00106 (0.00096)	Tok/s 52447 (58802)	Loss/tok 3.1325 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5700/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00092)	Tok/s 62537 (59253)	Loss/tok 3.1152 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][5700/6832]	Time 0.122 (0.105)	Data 0.00098 (0.00094)	Tok/s 63005 (60067)	Loss/tok 3.4375 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][5700/6832]	Time 0.122 (0.105)	Data 0.00099 (0.00095)	Tok/s 62992 (59625)	Loss/tok 3.1999 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][5700/6832]	Time 0.122 (0.105)	Data 0.00105 (0.00096)	Tok/s 61850 (58811)	Loss/tok 3.2939 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5710/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00092)	Tok/s 51405 (59247)	Loss/tok 2.8884 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5710/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00095)	Tok/s 51338 (59619)	Loss/tok 3.0250 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][5710/6832]	Time 0.070 (0.105)	Data 0.00086 (0.00094)	Tok/s 52419 (60061)	Loss/tok 2.8543 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5710/6832]	Time 0.070 (0.105)	Data 0.00105 (0.00096)	Tok/s 51348 (58806)	Loss/tok 2.8569 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5720/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00092)	Tok/s 56691 (59247)	Loss/tok 3.2927 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][5720/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00095)	Tok/s 56682 (59620)	Loss/tok 3.2432 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5720/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00094)	Tok/s 57255 (60061)	Loss/tok 3.3080 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][5720/6832]	Time 0.126 (0.105)	Data 0.00111 (0.00096)	Tok/s 56725 (58806)	Loss/tok 3.3238 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5730/6832]	Time 0.128 (0.105)	Data 0.00081 (0.00092)	Tok/s 72171 (59243)	Loss/tok 3.3010 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][5730/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00095)	Tok/s 72816 (59616)	Loss/tok 3.0785 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5730/6832]	Time 0.128 (0.105)	Data 0.00083 (0.00094)	Tok/s 73117 (60057)	Loss/tok 3.2688 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5730/6832]	Time 0.128 (0.105)	Data 0.00105 (0.00096)	Tok/s 72185 (58799)	Loss/tok 3.2545 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5740/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00092)	Tok/s 52363 (59239)	Loss/tok 3.1183 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5740/6832]	Time 0.088 (0.105)	Data 0.00089 (0.00095)	Tok/s 53228 (59612)	Loss/tok 3.0519 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][5740/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00094)	Tok/s 53778 (60053)	Loss/tok 3.1083 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5740/6832]	Time 0.088 (0.105)	Data 0.00105 (0.00096)	Tok/s 52363 (58796)	Loss/tok 3.0851 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5750/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00092)	Tok/s 61364 (59246)	Loss/tok 3.1675 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5750/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00095)	Tok/s 61382 (59619)	Loss/tok 3.1372 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5750/6832]	Time 0.125 (0.105)	Data 0.00085 (0.00094)	Tok/s 61378 (60060)	Loss/tok 3.2470 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][5750/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00096)	Tok/s 60720 (58803)	Loss/tok 3.2582 (3.1718)	Learning Rate [7.8125e-05]
1: TRAIN [3][5760/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00091)	Tok/s 52780 (59255)	Loss/tok 2.9013 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][5760/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00096)	Tok/s 52805 (58813)	Loss/tok 2.9269 (3.1718)	Learning Rate [7.8125e-05]
3: TRAIN [3][5760/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00094)	Tok/s 52819 (60069)	Loss/tok 3.1194 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][5760/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00095)	Tok/s 52806 (59628)	Loss/tok 2.8989 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][5770/6832]	Time 0.089 (0.105)	Data 0.00085 (0.00091)	Tok/s 53855 (59249)	Loss/tok 3.0425 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][5770/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00095)	Tok/s 54597 (59621)	Loss/tok 2.9661 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5770/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00094)	Tok/s 54586 (60063)	Loss/tok 3.0914 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5770/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00096)	Tok/s 53160 (58807)	Loss/tok 3.0619 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][5780/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00091)	Tok/s 57645 (59240)	Loss/tok 3.2600 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5780/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00095)	Tok/s 58222 (59613)	Loss/tok 3.1606 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][5780/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00094)	Tok/s 58736 (60055)	Loss/tok 3.1151 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][5780/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00096)	Tok/s 57640 (58797)	Loss/tok 3.0509 (3.1716)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][5790/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00091)	Tok/s 62266 (59251)	Loss/tok 3.2287 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5790/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00095)	Tok/s 62249 (59623)	Loss/tok 3.3753 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][5790/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00096)	Tok/s 62264 (58809)	Loss/tok 3.3154 (3.1717)	Learning Rate [7.8125e-05]
3: TRAIN [3][5790/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00094)	Tok/s 62862 (60065)	Loss/tok 3.3922 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][5800/6832]	Time 0.052 (0.105)	Data 0.00095 (0.00091)	Tok/s 39586 (59241)	Loss/tok 2.4195 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][5800/6832]	Time 0.052 (0.105)	Data 0.00092 (0.00096)	Tok/s 37211 (58799)	Loss/tok 2.1327 (3.1715)	Learning Rate [7.8125e-05]
3: TRAIN [3][5800/6832]	Time 0.052 (0.105)	Data 0.00092 (0.00094)	Tok/s 43412 (60056)	Loss/tok 2.4573 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][5800/6832]	Time 0.052 (0.105)	Data 0.00094 (0.00095)	Tok/s 41919 (59614)	Loss/tok 2.4508 (3.1690)	Learning Rate [7.8125e-05]
1: TRAIN [3][5810/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00091)	Tok/s 51457 (59239)	Loss/tok 3.0950 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][5810/6832]	Time 0.107 (0.105)	Data 0.00093 (0.00094)	Tok/s 51424 (60053)	Loss/tok 3.0843 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][5810/6832]	Time 0.107 (0.105)	Data 0.00093 (0.00095)	Tok/s 51420 (59612)	Loss/tok 3.2188 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][5810/6832]	Time 0.107 (0.105)	Data 0.00091 (0.00096)	Tok/s 51417 (58797)	Loss/tok 3.2697 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5820/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00091)	Tok/s 73889 (59237)	Loss/tok 3.2124 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5820/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00096)	Tok/s 73846 (58795)	Loss/tok 3.2982 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][5820/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 73884 (59610)	Loss/tok 3.2517 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][5820/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 74812 (60051)	Loss/tok 3.1509 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][5830/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00091)	Tok/s 54240 (59243)	Loss/tok 3.0748 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5830/6832]	Time 0.078 (0.105)	Data 0.00095 (0.00096)	Tok/s 52791 (58802)	Loss/tok 2.9679 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][5830/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00095)	Tok/s 54043 (59617)	Loss/tok 2.9986 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][5830/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00094)	Tok/s 54058 (60058)	Loss/tok 2.9215 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][5840/6832]	Time 0.090 (0.105)	Data 0.00090 (0.00091)	Tok/s 52404 (59239)	Loss/tok 3.2702 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5840/6832]	Time 0.090 (0.105)	Data 0.00088 (0.00095)	Tok/s 52404 (59613)	Loss/tok 3.1118 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][5840/6832]	Time 0.090 (0.105)	Data 0.00086 (0.00094)	Tok/s 52374 (60054)	Loss/tok 3.1840 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][5840/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00096)	Tok/s 52409 (58796)	Loss/tok 2.9801 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5850/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00091)	Tok/s 79664 (59252)	Loss/tok 3.2326 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][5850/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00095)	Tok/s 79832 (59626)	Loss/tok 3.1941 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5850/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00094)	Tok/s 80659 (60067)	Loss/tok 3.1629 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][5850/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00096)	Tok/s 78900 (58809)	Loss/tok 3.3057 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5860/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00091)	Tok/s 51002 (59250)	Loss/tok 2.8300 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][5860/6832]	Time 0.075 (0.105)	Data 0.00094 (0.00095)	Tok/s 51305 (59624)	Loss/tok 2.9973 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5860/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00094)	Tok/s 52756 (60065)	Loss/tok 3.1384 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][5860/6832]	Time 0.075 (0.105)	Data 0.00096 (0.00096)	Tok/s 51046 (58807)	Loss/tok 3.0291 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5870/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00091)	Tok/s 57403 (59263)	Loss/tok 3.2262 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][5870/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00096)	Tok/s 56901 (58820)	Loss/tok 3.0465 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][5870/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00095)	Tok/s 57383 (59637)	Loss/tok 3.2236 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5870/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 57386 (60078)	Loss/tok 3.3377 (3.1681)	Learning Rate [7.8125e-05]
1: TRAIN [3][5880/6832]	Time 0.090 (0.105)	Data 0.00087 (0.00091)	Tok/s 55569 (59263)	Loss/tok 3.2645 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][5880/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00095)	Tok/s 55569 (59636)	Loss/tok 3.1645 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5880/6832]	Time 0.090 (0.105)	Data 0.00087 (0.00094)	Tok/s 55575 (60077)	Loss/tok 3.0668 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][5880/6832]	Time 0.090 (0.105)	Data 0.00092 (0.00096)	Tok/s 55558 (58821)	Loss/tok 2.9173 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][5890/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 76465 (59635)	Loss/tok 3.1540 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5890/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 76469 (60075)	Loss/tok 3.1429 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][5890/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00091)	Tok/s 75705 (59261)	Loss/tok 3.1829 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][5890/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00096)	Tok/s 75466 (58820)	Loss/tok 3.1712 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][5900/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00095)	Tok/s 86292 (59637)	Loss/tok 3.1423 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][5900/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00091)	Tok/s 85507 (59264)	Loss/tok 3.0839 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][5900/6832]	Time 0.132 (0.105)	Data 0.00100 (0.00094)	Tok/s 86803 (60079)	Loss/tok 3.0925 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][5900/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00096)	Tok/s 85334 (58823)	Loss/tok 2.9928 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5910/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00091)	Tok/s 69690 (59264)	Loss/tok 3.1899 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5910/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00095)	Tok/s 69669 (59637)	Loss/tok 3.1995 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5910/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 70598 (60078)	Loss/tok 3.1222 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][5910/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00096)	Tok/s 69653 (58823)	Loss/tok 3.2308 (3.1716)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [3][5920/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 60701 (59632)	Loss/tok 3.3981 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][5920/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00091)	Tok/s 60090 (59258)	Loss/tok 3.5515 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][5920/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 61082 (60073)	Loss/tok 3.2493 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][5920/6832]	Time 0.128 (0.105)	Data 0.00098 (0.00096)	Tok/s 60095 (58815)	Loss/tok 3.2473 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][5930/6832]	Time 0.084 (0.105)	Data 0.00109 (0.00095)	Tok/s 53337 (59633)	Loss/tok 3.0746 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5930/6832]	Time 0.084 (0.105)	Data 0.00110 (0.00094)	Tok/s 53323 (60074)	Loss/tok 2.9593 (3.1682)	Learning Rate [7.8125e-05]
1: TRAIN [3][5930/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00091)	Tok/s 53294 (59259)	Loss/tok 3.2153 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][5930/6832]	Time 0.084 (0.105)	Data 0.00108 (0.00096)	Tok/s 52037 (58817)	Loss/tok 2.9555 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][5940/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 58132 (59628)	Loss/tok 3.2462 (3.1696)	Learning Rate [7.8125e-05]
1: TRAIN [3][5940/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00091)	Tok/s 58073 (59254)	Loss/tok 3.1492 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][5940/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 59106 (60069)	Loss/tok 3.1701 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5940/6832]	Time 0.128 (0.105)	Data 0.00101 (0.00096)	Tok/s 58089 (58812)	Loss/tok 3.4376 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5950/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00091)	Tok/s 55687 (59245)	Loss/tok 3.3204 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5950/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00095)	Tok/s 55668 (59619)	Loss/tok 3.2457 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5950/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 55680 (60060)	Loss/tok 3.2677 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][5950/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00096)	Tok/s 55697 (58803)	Loss/tok 3.2854 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][5960/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00091)	Tok/s 81824 (59248)	Loss/tok 3.1776 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5960/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 82045 (59621)	Loss/tok 3.1481 (3.1696)	Learning Rate [7.8125e-05]
3: TRAIN [3][5960/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 82792 (60063)	Loss/tok 3.1726 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][5960/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00096)	Tok/s 81292 (58805)	Loss/tok 3.3179 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5970/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00091)	Tok/s 64913 (59249)	Loss/tok 3.5376 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][5970/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 64937 (59622)	Loss/tok 3.3284 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][5970/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 65455 (60063)	Loss/tok 3.4657 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][5970/6832]	Time 0.130 (0.105)	Data 0.00109 (0.00096)	Tok/s 64912 (58807)	Loss/tok 3.3090 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][5980/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00091)	Tok/s 81431 (59247)	Loss/tok 3.1418 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][5980/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00096)	Tok/s 80485 (58804)	Loss/tok 3.1519 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][5980/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 81417 (59620)	Loss/tok 3.1034 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][5980/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 82368 (60061)	Loss/tok 3.1701 (3.1681)	Learning Rate [7.8125e-05]
2: TRAIN [3][5990/6832]	Time 0.052 (0.105)	Data 0.00090 (0.00095)	Tok/s 46919 (59618)	Loss/tok 2.5037 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][5990/6832]	Time 0.052 (0.105)	Data 0.00087 (0.00094)	Tok/s 49215 (60059)	Loss/tok 2.6720 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][5990/6832]	Time 0.052 (0.105)	Data 0.00093 (0.00091)	Tok/s 46895 (59245)	Loss/tok 2.5136 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][5990/6832]	Time 0.052 (0.105)	Data 0.00093 (0.00096)	Tok/s 44522 (58802)	Loss/tok 2.5059 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6000/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 67171 (59616)	Loss/tok 3.2782 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][6000/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00091)	Tok/s 67149 (59243)	Loss/tok 3.2359 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][6000/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 67174 (60057)	Loss/tok 3.2976 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][6000/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00096)	Tok/s 66884 (58801)	Loss/tok 3.2112 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6010/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00091)	Tok/s 77480 (59245)	Loss/tok 3.2604 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6010/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00096)	Tok/s 76560 (58803)	Loss/tok 3.2359 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][6010/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00095)	Tok/s 77424 (59617)	Loss/tok 3.2352 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][6010/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 77780 (60057)	Loss/tok 3.1292 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][6020/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00091)	Tok/s 64504 (59252)	Loss/tok 3.3608 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][6020/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 64491 (59623)	Loss/tok 3.3876 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][6020/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 64611 (60063)	Loss/tok 3.1869 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][6020/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00096)	Tok/s 64512 (58810)	Loss/tok 3.2713 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6030/6832]	Time 0.105 (0.105)	Data 0.00085 (0.00091)	Tok/s 53554 (59253)	Loss/tok 3.1720 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][6030/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00095)	Tok/s 53569 (59625)	Loss/tok 3.2597 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][6030/6832]	Time 0.105 (0.105)	Data 0.00086 (0.00094)	Tok/s 53748 (60065)	Loss/tok 3.1362 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][6030/6832]	Time 0.105 (0.105)	Data 0.00097 (0.00096)	Tok/s 53567 (58812)	Loss/tok 3.0950 (3.1715)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
2: TRAIN [3][6040/6832]	Time 0.098 (0.105)	Data 0.00119 (0.00095)	Tok/s 51987 (59614)	Loss/tok 3.1651 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][6040/6832]	Time 0.099 (0.105)	Data 0.00094 (0.00091)	Tok/s 51404 (59243)	Loss/tok 3.0822 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6040/6832]	Time 0.099 (0.105)	Data 0.00105 (0.00094)	Tok/s 51814 (60053)	Loss/tok 2.9949 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][6040/6832]	Time 0.099 (0.105)	Data 0.00099 (0.00096)	Tok/s 50499 (58802)	Loss/tok 2.9646 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][6050/6832]	Time 0.073 (0.105)	Data 0.00088 (0.00095)	Tok/s 49343 (59605)	Loss/tok 3.0424 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][6050/6832]	Time 0.073 (0.105)	Data 0.00093 (0.00091)	Tok/s 49343 (59234)	Loss/tok 2.8273 (3.1684)	Learning Rate [7.8125e-05]
3: TRAIN [3][6050/6832]	Time 0.073 (0.105)	Data 0.00086 (0.00094)	Tok/s 49336 (60045)	Loss/tok 2.8119 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][6050/6832]	Time 0.073 (0.105)	Data 0.00099 (0.00096)	Tok/s 49183 (58793)	Loss/tok 2.7612 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6060/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00091)	Tok/s 54705 (59238)	Loss/tok 3.1155 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][6060/6832]	Time 0.108 (0.105)	Data 0.00090 (0.00095)	Tok/s 54695 (59609)	Loss/tok 3.1179 (3.1695)	Learning Rate [7.8125e-05]
3: TRAIN [3][6060/6832]	Time 0.108 (0.105)	Data 0.00088 (0.00094)	Tok/s 55257 (60049)	Loss/tok 3.0892 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][6060/6832]	Time 0.108 (0.105)	Data 0.00101 (0.00096)	Tok/s 53591 (58798)	Loss/tok 2.9837 (3.1712)	Learning Rate [7.8125e-05]
3: TRAIN [3][6070/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00094)	Tok/s 53990 (60054)	Loss/tok 3.1026 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][6070/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00095)	Tok/s 52789 (59615)	Loss/tok 2.9322 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][6070/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00091)	Tok/s 52780 (59244)	Loss/tok 3.3293 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][6070/6832]	Time 0.097 (0.105)	Data 0.00093 (0.00096)	Tok/s 52768 (58803)	Loss/tok 3.0099 (3.1712)	Learning Rate [7.8125e-05]
2: TRAIN [3][6080/6832]	Time 0.110 (0.105)	Data 0.00092 (0.00095)	Tok/s 53753 (59611)	Loss/tok 3.1143 (3.1695)	Learning Rate [7.8125e-05]
1: TRAIN [3][6080/6832]	Time 0.110 (0.105)	Data 0.00095 (0.00091)	Tok/s 53334 (59240)	Loss/tok 3.0253 (3.1684)	Learning Rate [7.8125e-05]
3: TRAIN [3][6080/6832]	Time 0.110 (0.105)	Data 0.00096 (0.00094)	Tok/s 53756 (60051)	Loss/tok 3.0382 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][6080/6832]	Time 0.109 (0.105)	Data 0.00094 (0.00096)	Tok/s 52610 (58798)	Loss/tok 3.2826 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6090/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00091)	Tok/s 71568 (59239)	Loss/tok 3.3394 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][6090/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 71651 (59611)	Loss/tok 3.3125 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][6090/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 72587 (60051)	Loss/tok 3.1091 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][6090/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00096)	Tok/s 71568 (58797)	Loss/tok 3.2484 (3.1712)	Learning Rate [7.8125e-05]
1: TRAIN [3][6100/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00091)	Tok/s 73554 (59236)	Loss/tok 3.2284 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][6100/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 74358 (60050)	Loss/tok 3.2463 (3.1676)	Learning Rate [7.8125e-05]
2: TRAIN [3][6100/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00095)	Tok/s 73647 (59608)	Loss/tok 3.3481 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][6100/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00096)	Tok/s 73527 (58792)	Loss/tok 3.2176 (3.1712)	Learning Rate [7.8125e-05]
2: TRAIN [3][6110/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 65306 (59606)	Loss/tok 3.2638 (3.1694)	Learning Rate [7.8125e-05]
1: TRAIN [3][6110/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00091)	Tok/s 65290 (59233)	Loss/tok 3.3343 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][6110/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 65289 (60047)	Loss/tok 3.3340 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][6110/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00096)	Tok/s 65107 (58787)	Loss/tok 3.4009 (3.1712)	Learning Rate [7.8125e-05]
2: TRAIN [3][6120/6832]	Time 0.065 (0.105)	Data 0.00086 (0.00095)	Tok/s 50212 (59594)	Loss/tok 2.8350 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][6120/6832]	Time 0.065 (0.105)	Data 0.00089 (0.00091)	Tok/s 48893 (59221)	Loss/tok 2.9703 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][6120/6832]	Time 0.065 (0.105)	Data 0.00087 (0.00094)	Tok/s 50847 (60036)	Loss/tok 2.9270 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][6120/6832]	Time 0.065 (0.105)	Data 0.00098 (0.00096)	Tok/s 48881 (58776)	Loss/tok 2.7963 (3.1712)	Learning Rate [7.8125e-05]
1: TRAIN [3][6130/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00091)	Tok/s 78088 (59238)	Loss/tok 3.1356 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][6130/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00096)	Tok/s 78089 (58793)	Loss/tok 3.2172 (3.1712)	Learning Rate [7.8125e-05]
2: TRAIN [3][6130/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00095)	Tok/s 78543 (59611)	Loss/tok 3.2374 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][6130/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00094)	Tok/s 78993 (60054)	Loss/tok 3.1521 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][6140/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00091)	Tok/s 58098 (59244)	Loss/tok 3.2394 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][6140/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00095)	Tok/s 58004 (59617)	Loss/tok 3.2822 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][6140/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00096)	Tok/s 58117 (58800)	Loss/tok 3.2403 (3.1713)	Learning Rate [7.8125e-05]
3: TRAIN [3][6140/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 57987 (60060)	Loss/tok 3.1941 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][6150/6832]	Time 0.056 (0.105)	Data 0.00084 (0.00095)	Tok/s 49895 (59616)	Loss/tok 2.5487 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][6150/6832]	Time 0.056 (0.105)	Data 0.00087 (0.00094)	Tok/s 51115 (60059)	Loss/tok 2.7381 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][6150/6832]	Time 0.057 (0.105)	Data 0.00088 (0.00091)	Tok/s 49835 (59243)	Loss/tok 2.5635 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][6150/6832]	Time 0.056 (0.105)	Data 0.00105 (0.00096)	Tok/s 49166 (58797)	Loss/tok 2.6364 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6160/6832]	Time 0.101 (0.105)	Data 0.00093 (0.00091)	Tok/s 52040 (59244)	Loss/tok 3.1535 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][6160/6832]	Time 0.101 (0.105)	Data 0.00106 (0.00095)	Tok/s 52040 (59618)	Loss/tok 3.1867 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][6160/6832]	Time 0.101 (0.105)	Data 0.00100 (0.00094)	Tok/s 52043 (60060)	Loss/tok 2.7597 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][6160/6832]	Time 0.101 (0.105)	Data 0.00102 (0.00096)	Tok/s 52051 (58798)	Loss/tok 3.2199 (3.1715)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][6170/6832]	Time 0.042 (0.105)	Data 0.00087 (0.00091)	Tok/s 34347 (59229)	Loss/tok 2.2125 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][6170/6832]	Time 0.042 (0.105)	Data 0.00085 (0.00095)	Tok/s 39233 (59605)	Loss/tok 1.9400 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][6170/6832]	Time 0.042 (0.105)	Data 0.00085 (0.00094)	Tok/s 43047 (60048)	Loss/tok 2.3726 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][6170/6832]	Time 0.043 (0.105)	Data 0.00099 (0.00096)	Tok/s 21616 (58780)	Loss/tok 1.7653 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][6180/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00095)	Tok/s 52942 (59603)	Loss/tok 2.8927 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][6180/6832]	Time 0.059 (0.105)	Data 0.00097 (0.00091)	Tok/s 52112 (59227)	Loss/tok 2.8180 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][6180/6832]	Time 0.059 (0.105)	Data 0.00098 (0.00094)	Tok/s 54304 (60047)	Loss/tok 2.8160 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][6180/6832]	Time 0.059 (0.105)	Data 0.00105 (0.00096)	Tok/s 52173 (58775)	Loss/tok 2.8206 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6190/6832]	Time 0.058 (0.105)	Data 0.00092 (0.00091)	Tok/s 50847 (59226)	Loss/tok 2.7528 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][6190/6832]	Time 0.058 (0.105)	Data 0.00095 (0.00095)	Tok/s 51055 (59602)	Loss/tok 2.7229 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][6190/6832]	Time 0.058 (0.105)	Data 0.00093 (0.00094)	Tok/s 53048 (60047)	Loss/tok 2.7265 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [3][6190/6832]	Time 0.058 (0.105)	Data 0.00096 (0.00096)	Tok/s 50848 (58772)	Loss/tok 2.8600 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6200/6832]	Time 0.082 (0.105)	Data 0.00089 (0.00091)	Tok/s 54366 (59232)	Loss/tok 3.0689 (3.1685)	Learning Rate [7.8125e-05]
2: TRAIN [3][6200/6832]	Time 0.082 (0.105)	Data 0.00085 (0.00095)	Tok/s 54330 (59608)	Loss/tok 3.0005 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][6200/6832]	Time 0.082 (0.105)	Data 0.00087 (0.00094)	Tok/s 54350 (60052)	Loss/tok 2.8897 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][6200/6832]	Time 0.082 (0.105)	Data 0.00095 (0.00096)	Tok/s 54395 (58779)	Loss/tok 2.9400 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6210/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 63085 (59603)	Loss/tok 3.2817 (3.1694)	Learning Rate [7.8125e-05]
3: TRAIN [3][6210/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00094)	Tok/s 64017 (60047)	Loss/tok 3.3056 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][6210/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00091)	Tok/s 63078 (59227)	Loss/tok 3.3097 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][6210/6832]	Time 0.128 (0.105)	Data 0.00105 (0.00096)	Tok/s 63101 (58775)	Loss/tok 3.1563 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][6220/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00095)	Tok/s 51798 (59591)	Loss/tok 2.8794 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][6220/6832]	Time 0.072 (0.105)	Data 0.00095 (0.00094)	Tok/s 51790 (60035)	Loss/tok 2.7466 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][6220/6832]	Time 0.072 (0.105)	Data 0.00098 (0.00091)	Tok/s 51734 (59213)	Loss/tok 3.0823 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][6220/6832]	Time 0.072 (0.105)	Data 0.00099 (0.00096)	Tok/s 51148 (58760)	Loss/tok 2.8252 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6230/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00091)	Tok/s 52707 (59218)	Loss/tok 3.1624 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6230/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00094)	Tok/s 52752 (60040)	Loss/tok 3.3230 (3.1676)	Learning Rate [7.8125e-05]
2: TRAIN [3][6230/6832]	Time 0.109 (0.105)	Data 0.00095 (0.00095)	Tok/s 52757 (59595)	Loss/tok 3.1300 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][6230/6832]	Time 0.109 (0.105)	Data 0.00095 (0.00096)	Tok/s 52717 (58765)	Loss/tok 3.1888 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6240/6832]	Time 0.108 (0.105)	Data 0.00088 (0.00091)	Tok/s 49576 (59218)	Loss/tok 3.1255 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6240/6832]	Time 0.108 (0.105)	Data 0.00089 (0.00094)	Tok/s 50786 (60040)	Loss/tok 2.9875 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][6240/6832]	Time 0.108 (0.105)	Data 0.00094 (0.00095)	Tok/s 50347 (59595)	Loss/tok 3.1114 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][6240/6832]	Time 0.108 (0.105)	Data 0.00099 (0.00096)	Tok/s 49590 (58765)	Loss/tok 3.1386 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6250/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00091)	Tok/s 63920 (59221)	Loss/tok 3.2865 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][6250/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 64601 (60041)	Loss/tok 3.2015 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][6250/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00095)	Tok/s 63953 (59598)	Loss/tok 3.1674 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][6250/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00096)	Tok/s 63950 (58768)	Loss/tok 3.3425 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6260/6832]	Time 0.047 (0.105)	Data 0.00090 (0.00091)	Tok/s 43788 (59222)	Loss/tok 2.2778 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6260/6832]	Time 0.047 (0.105)	Data 0.00094 (0.00096)	Tok/s 41527 (58769)	Loss/tok 2.3050 (3.1715)	Learning Rate [7.8125e-05]
3: TRAIN [3][6260/6832]	Time 0.047 (0.105)	Data 0.00087 (0.00094)	Tok/s 47898 (60043)	Loss/tok 2.4554 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][6260/6832]	Time 0.047 (0.105)	Data 0.00090 (0.00095)	Tok/s 46252 (59600)	Loss/tok 2.4065 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][6270/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00091)	Tok/s 68573 (59218)	Loss/tok 3.3533 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][6270/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 68823 (60040)	Loss/tok 3.0922 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][6270/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00095)	Tok/s 68812 (59596)	Loss/tok 3.2467 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][6270/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00096)	Tok/s 67855 (58766)	Loss/tok 3.2383 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][6280/6832]	Time 0.058 (0.105)	Data 0.00112 (0.00091)	Tok/s 48953 (59218)	Loss/tok 2.5827 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6280/6832]	Time 0.058 (0.105)	Data 0.00101 (0.00094)	Tok/s 50889 (60040)	Loss/tok 2.7374 (3.1674)	Learning Rate [7.8125e-05]
2: TRAIN [3][6280/6832]	Time 0.058 (0.105)	Data 0.00105 (0.00095)	Tok/s 48918 (59596)	Loss/tok 2.7028 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][6280/6832]	Time 0.058 (0.105)	Data 0.00116 (0.00096)	Tok/s 48690 (58766)	Loss/tok 2.8414 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6290/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00091)	Tok/s 58319 (59217)	Loss/tok 3.2264 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6290/6832]	Time 0.118 (0.105)	Data 0.00099 (0.00094)	Tok/s 58593 (60039)	Loss/tok 3.3679 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [3][6290/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00096)	Tok/s 57492 (58764)	Loss/tok 3.2236 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][6290/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00095)	Tok/s 58579 (59595)	Loss/tok 3.2803 (3.1692)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [3][6300/6832]	Time 0.047 (0.105)	Data 0.00092 (0.00095)	Tok/s 46060 (59593)	Loss/tok 2.3871 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][6300/6832]	Time 0.047 (0.105)	Data 0.00087 (0.00094)	Tok/s 47666 (60037)	Loss/tok 2.4294 (3.1674)	Learning Rate [7.8125e-05]
1: TRAIN [3][6300/6832]	Time 0.047 (0.105)	Data 0.00086 (0.00091)	Tok/s 43524 (59214)	Loss/tok 2.5623 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][6300/6832]	Time 0.047 (0.105)	Data 0.00092 (0.00096)	Tok/s 40990 (58761)	Loss/tok 2.2310 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6310/6832]	Time 0.113 (0.105)	Data 0.00089 (0.00091)	Tok/s 56208 (59214)	Loss/tok 3.1697 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][6310/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00094)	Tok/s 56592 (60037)	Loss/tok 3.1403 (3.1676)	Learning Rate [7.8125e-05]
2: TRAIN [3][6310/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00095)	Tok/s 56564 (59592)	Loss/tok 3.1483 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][6310/6832]	Time 0.113 (0.105)	Data 0.00093 (0.00096)	Tok/s 55471 (58761)	Loss/tok 3.2280 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6320/6832]	Time 0.083 (0.105)	Data 0.00088 (0.00091)	Tok/s 55386 (59216)	Loss/tok 3.0923 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][6320/6832]	Time 0.083 (0.105)	Data 0.00095 (0.00096)	Tok/s 55353 (58763)	Loss/tok 2.8983 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][6320/6832]	Time 0.083 (0.105)	Data 0.00088 (0.00094)	Tok/s 55426 (60039)	Loss/tok 2.9918 (3.1675)	Learning Rate [7.8125e-05]
2: TRAIN [3][6320/6832]	Time 0.083 (0.105)	Data 0.00091 (0.00095)	Tok/s 55394 (59594)	Loss/tok 3.0713 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][6330/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00094)	Tok/s 63465 (60036)	Loss/tok 3.1887 (3.1675)	Learning Rate [7.8125e-05]
1: TRAIN [3][6330/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00091)	Tok/s 63389 (59214)	Loss/tok 3.3646 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][6330/6832]	Time 0.121 (0.105)	Data 0.00098 (0.00095)	Tok/s 63478 (59592)	Loss/tok 3.4274 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][6330/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00096)	Tok/s 62418 (58762)	Loss/tok 3.1738 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6340/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00091)	Tok/s 68368 (59226)	Loss/tok 3.4112 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][6340/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00094)	Tok/s 68362 (60047)	Loss/tok 3.3448 (3.1676)	Learning Rate [7.8125e-05]
2: TRAIN [3][6340/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00095)	Tok/s 68268 (59603)	Loss/tok 3.2651 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][6340/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00096)	Tok/s 68278 (58774)	Loss/tok 3.2785 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][6350/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00095)	Tok/s 52907 (59601)	Loss/tok 3.0090 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][6350/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00091)	Tok/s 52908 (59223)	Loss/tok 2.8986 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][6350/6832]	Time 0.070 (0.105)	Data 0.00086 (0.00094)	Tok/s 52908 (60045)	Loss/tok 3.0302 (3.1677)	Learning Rate [7.8125e-05]
0: TRAIN [3][6350/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00096)	Tok/s 52329 (58769)	Loss/tok 2.9334 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6360/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00091)	Tok/s 81972 (59225)	Loss/tok 3.1803 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6360/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00096)	Tok/s 81053 (58771)	Loss/tok 3.2183 (3.1717)	Learning Rate [7.8125e-05]
3: TRAIN [3][6360/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 82874 (60046)	Loss/tok 3.1423 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][6360/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 81948 (59602)	Loss/tok 3.1818 (3.1692)	Learning Rate [7.8125e-05]
1: TRAIN [3][6370/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00091)	Tok/s 53846 (59224)	Loss/tok 2.9423 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][6370/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00094)	Tok/s 54590 (60045)	Loss/tok 3.2001 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][6370/6832]	Time 0.094 (0.105)	Data 0.00114 (0.00095)	Tok/s 54262 (59602)	Loss/tok 2.9853 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][6370/6832]	Time 0.095 (0.105)	Data 0.00091 (0.00096)	Tok/s 53831 (58772)	Loss/tok 3.0286 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][6380/6832]	Time 0.106 (0.105)	Data 0.00085 (0.00091)	Tok/s 54135 (59223)	Loss/tok 3.2400 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][6380/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00094)	Tok/s 54186 (60043)	Loss/tok 3.1957 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][6380/6832]	Time 0.106 (0.105)	Data 0.00103 (0.00095)	Tok/s 54183 (59600)	Loss/tok 3.2184 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][6380/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00096)	Tok/s 54122 (58770)	Loss/tok 3.1901 (3.1716)	Learning Rate [7.8125e-05]
3: TRAIN [3][6390/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00094)	Tok/s 54545 (60042)	Loss/tok 3.2117 (3.1676)	Learning Rate [7.8125e-05]
1: TRAIN [3][6390/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00091)	Tok/s 54536 (59221)	Loss/tok 3.2251 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6390/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00096)	Tok/s 54555 (58768)	Loss/tok 3.2050 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6390/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00095)	Tok/s 54526 (59598)	Loss/tok 3.2029 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][6400/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00094)	Tok/s 53468 (60036)	Loss/tok 3.1922 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][6400/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00095)	Tok/s 53483 (59592)	Loss/tok 3.1968 (3.1691)	Learning Rate [7.8125e-05]
1: TRAIN [3][6400/6832]	Time 0.101 (0.105)	Data 0.00093 (0.00091)	Tok/s 53477 (59215)	Loss/tok 3.1209 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6400/6832]	Time 0.101 (0.105)	Data 0.00097 (0.00095)	Tok/s 52832 (58762)	Loss/tok 3.0143 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6410/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00091)	Tok/s 52232 (59218)	Loss/tok 3.1986 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][6410/6832]	Time 0.097 (0.105)	Data 0.00086 (0.00094)	Tok/s 52538 (60039)	Loss/tok 3.1070 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][6410/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00095)	Tok/s 52519 (59596)	Loss/tok 3.0389 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][6410/6832]	Time 0.097 (0.105)	Data 0.00094 (0.00095)	Tok/s 51253 (58766)	Loss/tok 3.1166 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6420/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00091)	Tok/s 60199 (59224)	Loss/tok 3.2061 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][6420/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00094)	Tok/s 60935 (60044)	Loss/tok 3.0870 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [3][6420/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00095)	Tok/s 59831 (58772)	Loss/tok 3.0520 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6420/6832]	Time 0.117 (0.105)	Data 0.00107 (0.00095)	Tok/s 61012 (59601)	Loss/tok 3.2268 (3.1691)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [3][6430/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00091)	Tok/s 63486 (59231)	Loss/tok 3.2152 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6430/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 63469 (58779)	Loss/tok 3.1380 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6430/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00095)	Tok/s 63495 (59607)	Loss/tok 3.5798 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][6430/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 64276 (60051)	Loss/tok 3.1678 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][6440/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00091)	Tok/s 60521 (59236)	Loss/tok 3.3880 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][6440/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 61532 (60056)	Loss/tok 3.2403 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][6440/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00095)	Tok/s 60703 (59612)	Loss/tok 3.2623 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][6440/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00095)	Tok/s 60518 (58784)	Loss/tok 3.4182 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][6450/6832]	Time 0.091 (0.105)	Data 0.00103 (0.00095)	Tok/s 55036 (59613)	Loss/tok 3.1408 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][6450/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00091)	Tok/s 55014 (59236)	Loss/tok 3.0241 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][6450/6832]	Time 0.091 (0.105)	Data 0.00098 (0.00094)	Tok/s 55036 (60056)	Loss/tok 3.2572 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][6450/6832]	Time 0.091 (0.105)	Data 0.00093 (0.00095)	Tok/s 54373 (58785)	Loss/tok 3.1508 (3.1716)	Learning Rate [7.8125e-05]
3: TRAIN [3][6460/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00094)	Tok/s 74759 (60052)	Loss/tok 3.1830 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][6460/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 74551 (59609)	Loss/tok 3.0678 (3.1693)	Learning Rate [7.8125e-05]
1: TRAIN [3][6460/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00091)	Tok/s 74502 (59233)	Loss/tok 3.2115 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][6460/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 73808 (58781)	Loss/tok 3.2984 (3.1717)	Learning Rate [7.8125e-05]
1: TRAIN [3][6470/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00091)	Tok/s 51929 (59225)	Loss/tok 3.2379 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][6470/6832]	Time 0.117 (0.105)	Data 0.00098 (0.00095)	Tok/s 52668 (59602)	Loss/tok 3.1137 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][6470/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00094)	Tok/s 52663 (60044)	Loss/tok 3.2500 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [3][6470/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00095)	Tok/s 51579 (58774)	Loss/tok 3.2608 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][6480/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00091)	Tok/s 84050 (59232)	Loss/tok 3.2698 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6480/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 83266 (58781)	Loss/tok 3.2232 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][6480/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 84254 (59609)	Loss/tok 3.0878 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][6480/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 85081 (60052)	Loss/tok 3.1373 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][6490/6832]	Time 0.123 (0.105)	Data 0.00095 (0.00095)	Tok/s 58442 (59605)	Loss/tok 3.3332 (3.1693)	Learning Rate [7.8125e-05]
3: TRAIN [3][6490/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00094)	Tok/s 58442 (60047)	Loss/tok 3.4095 (3.1680)	Learning Rate [7.8125e-05]
1: TRAIN [3][6490/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00091)	Tok/s 58416 (59228)	Loss/tok 3.3608 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][6490/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00095)	Tok/s 58431 (58778)	Loss/tok 3.2509 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][6500/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00095)	Tok/s 62889 (59608)	Loss/tok 3.2689 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][6500/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 62883 (60050)	Loss/tok 3.2177 (3.1679)	Learning Rate [7.8125e-05]
1: TRAIN [3][6500/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00091)	Tok/s 62891 (59232)	Loss/tok 3.3147 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6500/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00095)	Tok/s 62888 (58781)	Loss/tok 3.4468 (3.1716)	Learning Rate [7.8125e-05]
2: TRAIN [3][6510/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00095)	Tok/s 54722 (59612)	Loss/tok 3.0589 (3.1692)	Learning Rate [7.8125e-05]
3: TRAIN [3][6510/6832]	Time 0.090 (0.105)	Data 0.00083 (0.00094)	Tok/s 54113 (60055)	Loss/tok 3.0108 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][6510/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00095)	Tok/s 52975 (58785)	Loss/tok 3.0970 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6510/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00091)	Tok/s 54067 (59236)	Loss/tok 3.0915 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6520/6832]	Time 0.113 (0.105)	Data 0.00096 (0.00095)	Tok/s 58851 (58782)	Loss/tok 3.1907 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6520/6832]	Time 0.113 (0.105)	Data 0.00100 (0.00091)	Tok/s 58826 (59233)	Loss/tok 3.3841 (3.1689)	Learning Rate [7.8125e-05]
2: TRAIN [3][6520/6832]	Time 0.113 (0.105)	Data 0.00095 (0.00095)	Tok/s 58809 (59609)	Loss/tok 3.3599 (3.1691)	Learning Rate [7.8125e-05]
3: TRAIN [3][6520/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00094)	Tok/s 58804 (60052)	Loss/tok 3.2820 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][6530/6832]	Time 0.109 (0.105)	Data 0.00098 (0.00094)	Tok/s 53821 (60050)	Loss/tok 3.2094 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][6530/6832]	Time 0.109 (0.105)	Data 0.00104 (0.00095)	Tok/s 53061 (59607)	Loss/tok 3.2373 (3.1691)	Learning Rate [7.8125e-05]
1: TRAIN [3][6530/6832]	Time 0.108 (0.105)	Data 0.00101 (0.00091)	Tok/s 53104 (59232)	Loss/tok 3.1081 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6530/6832]	Time 0.108 (0.105)	Data 0.00100 (0.00095)	Tok/s 53093 (58781)	Loss/tok 3.4288 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6540/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00091)	Tok/s 68613 (59237)	Loss/tok 3.2168 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6540/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 68596 (58786)	Loss/tok 3.3789 (3.1715)	Learning Rate [7.8125e-05]
3: TRAIN [3][6540/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 69297 (60055)	Loss/tok 3.2026 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][6540/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 68552 (59612)	Loss/tok 3.2412 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6550/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00095)	Tok/s 52952 (58797)	Loss/tok 3.2689 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][6550/6832]	Time 0.111 (0.105)	Data 0.00093 (0.00091)	Tok/s 52963 (59248)	Loss/tok 3.2033 (3.1690)	Learning Rate [7.8125e-05]
3: TRAIN [3][6550/6832]	Time 0.111 (0.105)	Data 0.00085 (0.00094)	Tok/s 54089 (60066)	Loss/tok 3.2311 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][6550/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00095)	Tok/s 53708 (59623)	Loss/tok 3.1916 (3.1690)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [3][6560/6832]	Time 0.075 (0.105)	Data 0.00096 (0.00091)	Tok/s 53061 (59242)	Loss/tok 3.0488 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6560/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00095)	Tok/s 53070 (58791)	Loss/tok 2.9138 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6560/6832]	Time 0.075 (0.105)	Data 0.00099 (0.00095)	Tok/s 53022 (59618)	Loss/tok 2.9007 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][6560/6832]	Time 0.075 (0.105)	Data 0.00096 (0.00094)	Tok/s 53967 (60062)	Loss/tok 3.0948 (3.1678)	Learning Rate [7.8125e-05]
3: TRAIN [3][6570/6832]	Time 0.078 (0.105)	Data 0.00086 (0.00094)	Tok/s 54216 (60062)	Loss/tok 3.0581 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][6570/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00095)	Tok/s 54211 (59618)	Loss/tok 2.7731 (3.1687)	Learning Rate [7.8125e-05]
1: TRAIN [3][6570/6832]	Time 0.078 (0.105)	Data 0.00093 (0.00091)	Tok/s 54130 (59242)	Loss/tok 2.9585 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6570/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00095)	Tok/s 53881 (58790)	Loss/tok 2.9614 (3.1715)	Learning Rate [7.8125e-05]
3: TRAIN [3][6580/6832]	Time 0.054 (0.105)	Data 0.00087 (0.00094)	Tok/s 49691 (60061)	Loss/tok 2.5643 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [3][6580/6832]	Time 0.054 (0.105)	Data 0.00091 (0.00095)	Tok/s 47339 (58790)	Loss/tok 2.6334 (3.1716)	Learning Rate [7.8125e-05]
1: TRAIN [3][6580/6832]	Time 0.054 (0.105)	Data 0.00094 (0.00091)	Tok/s 48899 (59242)	Loss/tok 2.7313 (3.1690)	Learning Rate [7.8125e-05]
2: TRAIN [3][6580/6832]	Time 0.054 (0.105)	Data 0.00089 (0.00095)	Tok/s 49693 (59617)	Loss/tok 2.6028 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][6590/6832]	Time 0.117 (0.105)	Data 0.00102 (0.00095)	Tok/s 52321 (59613)	Loss/tok 3.0205 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][6590/6832]	Time 0.117 (0.105)	Data 0.00100 (0.00094)	Tok/s 52315 (60057)	Loss/tok 3.1205 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][6590/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00091)	Tok/s 52338 (59238)	Loss/tok 3.2345 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6590/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00095)	Tok/s 51410 (58786)	Loss/tok 3.3989 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6600/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00091)	Tok/s 52089 (59238)	Loss/tok 3.0015 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][6600/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00094)	Tok/s 52591 (60056)	Loss/tok 2.9586 (3.1678)	Learning Rate [7.8125e-05]
2: TRAIN [3][6600/6832]	Time 0.097 (0.105)	Data 0.00092 (0.00095)	Tok/s 52607 (59613)	Loss/tok 3.1565 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6600/6832]	Time 0.097 (0.105)	Data 0.00093 (0.00095)	Tok/s 51284 (58786)	Loss/tok 3.0053 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6610/6832]	Time 0.086 (0.105)	Data 0.00098 (0.00091)	Tok/s 52294 (59236)	Loss/tok 2.9546 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6610/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00095)	Tok/s 52303 (58783)	Loss/tok 3.1039 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6610/6832]	Time 0.086 (0.105)	Data 0.00099 (0.00095)	Tok/s 52296 (59612)	Loss/tok 3.0991 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][6610/6832]	Time 0.086 (0.105)	Data 0.00094 (0.00094)	Tok/s 52290 (60055)	Loss/tok 3.0053 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][6620/6832]	Time 0.122 (0.105)	Data 0.00101 (0.00091)	Tok/s 54771 (59230)	Loss/tok 3.2549 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6620/6832]	Time 0.122 (0.105)	Data 0.00099 (0.00095)	Tok/s 54745 (58777)	Loss/tok 3.1662 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][6620/6832]	Time 0.122 (0.105)	Data 0.00096 (0.00094)	Tok/s 55353 (60051)	Loss/tok 3.3096 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][6620/6832]	Time 0.122 (0.105)	Data 0.00117 (0.00095)	Tok/s 54713 (59607)	Loss/tok 3.2480 (3.1686)	Learning Rate [7.8125e-05]
3: TRAIN [3][6630/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 81409 (60057)	Loss/tok 3.1243 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][6630/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00095)	Tok/s 81199 (59613)	Loss/tok 3.1623 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][6630/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 80487 (58784)	Loss/tok 3.1788 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6630/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00091)	Tok/s 80447 (59236)	Loss/tok 3.2682 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][6640/6832]	Time 0.110 (0.105)	Data 0.00098 (0.00094)	Tok/s 54486 (60057)	Loss/tok 3.3561 (3.1677)	Learning Rate [7.8125e-05]
2: TRAIN [3][6640/6832]	Time 0.110 (0.105)	Data 0.00101 (0.00095)	Tok/s 53409 (59613)	Loss/tok 2.9780 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][6640/6832]	Time 0.110 (0.105)	Data 0.00100 (0.00091)	Tok/s 53382 (59236)	Loss/tok 3.0518 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6640/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00095)	Tok/s 53379 (58784)	Loss/tok 3.3432 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][6650/6832]	Time 0.072 (0.105)	Data 0.00086 (0.00094)	Tok/s 55400 (60050)	Loss/tok 2.9533 (3.1677)	Learning Rate [7.8125e-05]
1: TRAIN [3][6650/6832]	Time 0.072 (0.105)	Data 0.00096 (0.00091)	Tok/s 53638 (59229)	Loss/tok 2.9528 (3.1687)	Learning Rate [7.8125e-05]
2: TRAIN [3][6650/6832]	Time 0.072 (0.105)	Data 0.00089 (0.00095)	Tok/s 53609 (59606)	Loss/tok 2.9859 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][6650/6832]	Time 0.072 (0.105)	Data 0.00092 (0.00095)	Tok/s 53621 (58777)	Loss/tok 2.9745 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6660/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00091)	Tok/s 60754 (59225)	Loss/tok 3.2535 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6660/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00095)	Tok/s 60734 (58772)	Loss/tok 3.1689 (3.1713)	Learning Rate [7.8125e-05]
2: TRAIN [3][6660/6832]	Time 0.114 (0.105)	Data 0.00103 (0.00095)	Tok/s 60668 (59601)	Loss/tok 3.1903 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6660/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00094)	Tok/s 60658 (60045)	Loss/tok 3.1732 (3.1678)	Learning Rate [7.8125e-05]
1: TRAIN [3][6670/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00091)	Tok/s 51013 (59229)	Loss/tok 3.2242 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6670/6832]	Time 0.098 (0.105)	Data 0.00087 (0.00095)	Tok/s 51006 (58778)	Loss/tok 3.0404 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][6670/6832]	Time 0.098 (0.105)	Data 0.00087 (0.00094)	Tok/s 50998 (60050)	Loss/tok 3.2271 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][6670/6832]	Time 0.098 (0.105)	Data 0.00088 (0.00095)	Tok/s 50982 (59606)	Loss/tok 3.0883 (3.1685)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: TRAIN [3][6680/6832]	Time 0.059 (0.105)	Data 0.00110 (0.00094)	Tok/s 52485 (60044)	Loss/tok 2.9462 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][6680/6832]	Time 0.057 (0.105)	Data 0.00101 (0.00095)	Tok/s 52388 (59600)	Loss/tok 2.8178 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][6680/6832]	Time 0.059 (0.105)	Data 0.00097 (0.00091)	Tok/s 50288 (59224)	Loss/tok 2.6607 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6680/6832]	Time 0.059 (0.105)	Data 0.00094 (0.00095)	Tok/s 50293 (58772)	Loss/tok 2.6243 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6690/6832]	Time 0.106 (0.105)	Data 0.00096 (0.00091)	Tok/s 53253 (59223)	Loss/tok 3.0123 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6690/6832]	Time 0.106 (0.105)	Data 0.00092 (0.00095)	Tok/s 52952 (58771)	Loss/tok 3.2069 (3.1713)	Learning Rate [7.8125e-05]
3: TRAIN [3][6690/6832]	Time 0.106 (0.105)	Data 0.00095 (0.00094)	Tok/s 53184 (60042)	Loss/tok 3.2052 (3.1679)	Learning Rate [7.8125e-05]
2: TRAIN [3][6690/6832]	Time 0.106 (0.105)	Data 0.00102 (0.00095)	Tok/s 53184 (59599)	Loss/tok 3.0023 (3.1684)	Learning Rate [7.8125e-05]
3: TRAIN [3][6700/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00094)	Tok/s 52436 (60037)	Loss/tok 3.2074 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][6700/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00095)	Tok/s 51643 (59594)	Loss/tok 2.8874 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][6700/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00091)	Tok/s 51613 (59217)	Loss/tok 3.2797 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][6700/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00095)	Tok/s 51572 (58764)	Loss/tok 2.9706 (3.1714)	Learning Rate [7.8125e-05]
0: TRAIN [3][6710/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00095)	Tok/s 52824 (58762)	Loss/tok 3.1699 (3.1714)	Learning Rate [7.8125e-05]
3: TRAIN [3][6710/6832]	Time 0.090 (0.105)	Data 0.00085 (0.00094)	Tok/s 52785 (60035)	Loss/tok 2.9621 (3.1680)	Learning Rate [7.8125e-05]
2: TRAIN [3][6710/6832]	Time 0.090 (0.105)	Data 0.00087 (0.00095)	Tok/s 52783 (59592)	Loss/tok 3.0888 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][6710/6832]	Time 0.090 (0.105)	Data 0.00096 (0.00091)	Tok/s 52776 (59216)	Loss/tok 3.1756 (3.1687)	Learning Rate [7.8125e-05]
3: TRAIN [3][6720/6832]	Time 0.062 (0.105)	Data 0.00095 (0.00094)	Tok/s 51204 (60036)	Loss/tok 2.8005 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [3][6720/6832]	Time 0.063 (0.105)	Data 0.00089 (0.00095)	Tok/s 49122 (58764)	Loss/tok 2.8594 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6720/6832]	Time 0.062 (0.105)	Data 0.00102 (0.00095)	Tok/s 49194 (59593)	Loss/tok 2.7843 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][6720/6832]	Time 0.063 (0.105)	Data 0.00093 (0.00091)	Tok/s 49121 (59217)	Loss/tok 2.7340 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][6730/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 64141 (60037)	Loss/tok 3.4710 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][6730/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 63487 (59594)	Loss/tok 3.3217 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][6730/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00091)	Tok/s 63500 (59218)	Loss/tok 3.4467 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6730/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 63464 (58766)	Loss/tok 3.2733 (3.1716)	Learning Rate [7.8125e-05]
3: TRAIN [3][6740/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 82835 (60038)	Loss/tok 3.2402 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][6740/6832]	Time 0.131 (0.105)	Data 0.00099 (0.00095)	Tok/s 82458 (59595)	Loss/tok 3.1184 (3.1686)	Learning Rate [7.8125e-05]
1: TRAIN [3][6740/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00091)	Tok/s 81833 (59219)	Loss/tok 3.0285 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6740/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 81559 (58767)	Loss/tok 3.1150 (3.1716)	Learning Rate [7.8125e-05]
3: TRAIN [3][6750/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00094)	Tok/s 70325 (60040)	Loss/tok 3.2455 (3.1682)	Learning Rate [7.8125e-05]
2: TRAIN [3][6750/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 69775 (59595)	Loss/tok 3.1690 (3.1685)	Learning Rate [7.8125e-05]
1: TRAIN [3][6750/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00091)	Tok/s 69717 (59219)	Loss/tok 3.3800 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6750/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 69701 (58764)	Loss/tok 3.4394 (3.1715)	Learning Rate [7.8125e-05]
2: TRAIN [3][6760/6832]	Time 0.056 (0.105)	Data 0.00093 (0.00095)	Tok/s 50408 (59598)	Loss/tok 2.7367 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][6760/6832]	Time 0.056 (0.105)	Data 0.00092 (0.00095)	Tok/s 49300 (58768)	Loss/tok 2.8015 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6760/6832]	Time 0.056 (0.105)	Data 0.00095 (0.00091)	Tok/s 50403 (59222)	Loss/tok 2.5078 (3.1689)	Learning Rate [7.8125e-05]
3: TRAIN [3][6760/6832]	Time 0.056 (0.105)	Data 0.00116 (0.00094)	Tok/s 50981 (60042)	Loss/tok 2.8074 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][6770/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 75284 (58778)	Loss/tok 3.2963 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6770/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00091)	Tok/s 75955 (59232)	Loss/tok 3.1474 (3.1688)	Learning Rate [7.8125e-05]
2: TRAIN [3][6770/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 76235 (59608)	Loss/tok 3.3011 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6770/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 76351 (60053)	Loss/tok 3.3156 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][6780/6832]	Time 0.106 (0.105)	Data 0.00090 (0.00094)	Tok/s 51810 (60048)	Loss/tok 3.2540 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][6780/6832]	Time 0.106 (0.105)	Data 0.00094 (0.00095)	Tok/s 51800 (59603)	Loss/tok 3.2351 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [3][6780/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00095)	Tok/s 51793 (58770)	Loss/tok 3.3335 (3.1715)	Learning Rate [7.8125e-05]
1: TRAIN [3][6780/6832]	Time 0.106 (0.105)	Data 0.00093 (0.00091)	Tok/s 51789 (59226)	Loss/tok 3.0592 (3.1688)	Learning Rate [7.8125e-05]
3: TRAIN [3][6790/6832]	Time 0.062 (0.105)	Data 0.00087 (0.00094)	Tok/s 51787 (60046)	Loss/tok 2.8577 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][6790/6832]	Time 0.062 (0.105)	Data 0.00090 (0.00095)	Tok/s 49945 (59600)	Loss/tok 2.7969 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [3][6790/6832]	Time 0.062 (0.105)	Data 0.00091 (0.00095)	Tok/s 49670 (58769)	Loss/tok 2.7428 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6790/6832]	Time 0.062 (0.105)	Data 0.00093 (0.00091)	Tok/s 49659 (59224)	Loss/tok 2.6793 (3.1686)	Learning Rate [7.8125e-05]
2: TRAIN [3][6800/6832]	Time 0.093 (0.105)	Data 0.00089 (0.00095)	Tok/s 54784 (59600)	Loss/tok 3.1264 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][6800/6832]	Time 0.093 (0.105)	Data 0.00084 (0.00094)	Tok/s 54783 (60046)	Loss/tok 3.0264 (3.1682)	Learning Rate [7.8125e-05]
0: TRAIN [3][6800/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00095)	Tok/s 53452 (58768)	Loss/tok 3.0797 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6800/6832]	Time 0.093 (0.105)	Data 0.00097 (0.00091)	Tok/s 53707 (59224)	Loss/tok 2.9875 (3.1686)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
3: TRAIN [3][6810/6832]	Time 0.073 (0.105)	Data 0.00084 (0.00094)	Tok/s 52930 (60039)	Loss/tok 2.9799 (3.1683)	Learning Rate [7.8125e-05]
2: TRAIN [3][6810/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00095)	Tok/s 52571 (59594)	Loss/tok 2.9204 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][6810/6832]	Time 0.073 (0.105)	Data 0.00088 (0.00095)	Tok/s 51157 (58763)	Loss/tok 2.9855 (3.1713)	Learning Rate [7.8125e-05]
1: TRAIN [3][6810/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00091)	Tok/s 51124 (59217)	Loss/tok 2.9281 (3.1685)	Learning Rate [7.8125e-05]
3: TRAIN [3][6820/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00094)	Tok/s 63268 (60037)	Loss/tok 3.2375 (3.1684)	Learning Rate [7.8125e-05]
2: TRAIN [3][6820/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 62386 (59592)	Loss/tok 3.2425 (3.1684)	Learning Rate [7.8125e-05]
1: TRAIN [3][6820/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00091)	Tok/s 62248 (59216)	Loss/tok 3.2033 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][6820/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00095)	Tok/s 62262 (58762)	Loss/tok 3.2979 (3.1714)	Learning Rate [7.8125e-05]
2: TRAIN [3][6830/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00096)	Tok/s 70663 (59598)	Loss/tok 3.2548 (3.1683)	Learning Rate [7.8125e-05]
3: TRAIN [3][6830/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 71501 (60043)	Loss/tok 3.2878 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [3][6830/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00095)	Tok/s 70508 (58767)	Loss/tok 3.3164 (3.1714)	Learning Rate [7.8125e-05]
1: TRAIN [3][6830/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00092)	Tok/s 70481 (59222)	Loss/tok 3.2953 (3.1686)	Learning Rate [7.8125e-05]
3: Running validation on dev set
2: Running validation on dev set
0: Running validation on dev set
1: Running validation on dev set
3: VALIDATION [3][0/20]	Time 0.034 (0.000)	Data 0.00210 (0.00000)	Tok/s 211022 (0)	Loss/tok 3.1675 (0.0000)	Learning Rate [7.8125e-05]
2: VALIDATION [3][0/20]	Time 0.037 (0.000)	Data 0.00210 (0.00000)	Tok/s 207509 (0)	Loss/tok 3.2553 (0.0000)	Learning Rate [7.8125e-05]
1: VALIDATION [3][0/20]	Time 0.041 (0.000)	Data 0.00210 (0.00000)	Tok/s 204746 (0)	Loss/tok 3.2669 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [3][0/20]	Time 0.064 (0.000)	Data 0.00220 (0.00000)	Tok/s 158194 (0)	Loss/tok 3.3568 (0.0000)	Learning Rate [7.8125e-05]
3: VALIDATION [3][10/20]	Time 0.015 (0.021)	Data 0.00177 (0.00197)	Tok/s 196159 (205631)	Loss/tok 3.0499 (3.1512)	Learning Rate [7.8125e-05]
2: VALIDATION [3][10/20]	Time 0.015 (0.021)	Data 0.00177 (0.00191)	Tok/s 201457 (206857)	Loss/tok 2.9570 (3.1067)	Learning Rate [7.8125e-05]
1: VALIDATION [3][10/20]	Time 0.015 (0.022)	Data 0.00174 (0.00181)	Tok/s 202230 (207044)	Loss/tok 3.0464 (3.1610)	Learning Rate [7.8125e-05]
0: VALIDATION [3][10/20]	Time 0.016 (0.022)	Data 0.00167 (0.00180)	Tok/s 202232 (210005)	Loss/tok 3.1093 (3.1190)	Learning Rate [7.8125e-05]
2: Running evaluation on test set
1: Running evaluation on test set
3: Running evaluation on test set
:::MLPv0.5.0 gnmt 1560385249.497544289 (train.py:459) eval_start: 3
0: Running evaluation on test set
3: TEST [3][0/6]	Time 1.195 (1.195)	Decoder iters 73.0 (73.0)	Tok/s 6459 (6459)
1: TEST [3][0/6]	Time 1.195 (1.195)	Decoder iters 99.0 (99.0)	Tok/s 6376 (6376)
0: TEST [3][0/6]	Time 1.195 (1.195)	Decoder iters 70.0 (70.0)	Tok/s 5878 (5878)
2: TEST [3][0/6]	Time 1.196 (1.196)	Decoder iters 149.0 (149.0)	Tok/s 6247 (6247)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
3: Finished evaluation on test set
0: Finished evaluation on test set
2: Finished evaluation on test set
1: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560385259.677738190 (train.py:464) eval_accuracy: {"epoch": 3, "value": 21.6299991607666}
:::MLPv0.5.0 gnmt 1560385259.678440094 (train.py:466) eval_target: 21.8
2: Summary: Epoch: 3	Training Loss 3.1692
3: Summary: Epoch: 3	Training Loss 3.1692
3: Performance: Epoch: 3	Training: 237625 Tok/s
2: Performance: Epoch: 3	Training: 237625 Tok/s
1: Summary: Epoch: 3	Training Loss 3.1692
3: Finished epoch 3
2: Finished epoch 3
3: Starting epoch 4
1: Performance: Epoch: 3	Training: 237625 Tok/s
1: Finished epoch 3
2: Starting epoch 4
1: Starting epoch 4
:::MLPv0.5.0 gnmt 1560385259.679080248 (train.py:467) eval_stop
0: Summary: Epoch: 3	Training Loss: 3.1692	Validation Loss: 3.1038	Test BLEU: 21.63
0: Performance: Epoch: 3	Training: 237625 Tok/s	Validation: 708922 Tok/s
0: Finished epoch 3
0: Starting epoch 4
:::MLPv0.5.0 gnmt 1560385259.679862738 (train.py:443) train_epoch: 4
2: Sampler for epoch 4 uses seed 697068581
3: Sampler for epoch 4 uses seed 697068581
1: Sampler for epoch 4 uses seed 697068581
:::MLPv0.5.0 gnmt 1560385259.942459822 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 4 uses seed 697068581
:::MLPv0.5.0 gnmt 1560385260.042493582 (seq2seq/data/sampler.py:66) input_shard: 40960
1: TRAIN [4][0/6832]	Time 1.415 (0.000)	Data 1.30844 (0.00000)	Tok/s 2443 (0)	Loss/tok 2.9733 (0.0000)	Learning Rate [7.8125e-05]
2: TRAIN [4][0/6832]	Time 1.415 (0.000)	Data 1.31578 (0.00000)	Tok/s 2443 (0)	Loss/tok 2.9464 (0.0000)	Learning Rate [7.8125e-05]
3: TRAIN [4][0/6832]	Time 1.415 (0.000)	Data 1.29910 (0.00000)	Tok/s 2454 (0)	Loss/tok 2.8327 (0.0000)	Learning Rate [7.8125e-05]
0: TRAIN [4][0/6832]	Time 1.415 (0.000)	Data 1.34959 (0.00000)	Tok/s 2443 (0)	Loss/tok 2.8125 (0.0000)	Learning Rate [7.8125e-05]
1: TRAIN [4][10/6832]	Time 0.066 (0.114)	Data 0.00086 (0.00089)	Tok/s 50057 (67051)	Loss/tok 2.9769 (3.0864)	Learning Rate [7.8125e-05]
0: TRAIN [4][10/6832]	Time 0.066 (0.114)	Data 0.00091 (0.00079)	Tok/s 50045 (66724)	Loss/tok 2.8345 (3.0674)	Learning Rate [7.8125e-05]
3: TRAIN [4][10/6832]	Time 0.067 (0.114)	Data 0.00088 (0.00097)	Tok/s 51736 (68129)	Loss/tok 2.7917 (3.1256)	Learning Rate [7.8125e-05]
2: TRAIN [4][10/6832]	Time 0.067 (0.114)	Data 0.00092 (0.00098)	Tok/s 49951 (67454)	Loss/tok 2.9705 (3.1665)	Learning Rate [7.8125e-05]
3: TRAIN [4][20/6832]	Time 0.124 (0.110)	Data 0.00094 (0.00093)	Tok/s 65053 (64236)	Loss/tok 3.1372 (3.1103)	Learning Rate [7.8125e-05]
1: TRAIN [4][20/6832]	Time 0.124 (0.110)	Data 0.00090 (0.00090)	Tok/s 64219 (63412)	Loss/tok 3.2465 (3.0963)	Learning Rate [7.8125e-05]
0: TRAIN [4][20/6832]	Time 0.124 (0.110)	Data 0.00095 (0.00087)	Tok/s 64217 (63112)	Loss/tok 3.1473 (3.0984)	Learning Rate [7.8125e-05]
2: TRAIN [4][20/6832]	Time 0.124 (0.110)	Data 0.00101 (0.00096)	Tok/s 64148 (63708)	Loss/tok 3.2470 (3.1592)	Learning Rate [7.8125e-05]
3: TRAIN [4][30/6832]	Time 0.091 (0.107)	Data 0.00088 (0.00093)	Tok/s 55007 (61580)	Loss/tok 2.9204 (3.1121)	Learning Rate [7.8125e-05]
2: TRAIN [4][30/6832]	Time 0.091 (0.107)	Data 0.00092 (0.00099)	Tok/s 55004 (61040)	Loss/tok 3.2544 (3.1535)	Learning Rate [7.8125e-05]
1: TRAIN [4][30/6832]	Time 0.091 (0.107)	Data 0.00087 (0.00089)	Tok/s 54970 (60609)	Loss/tok 3.1275 (3.1208)	Learning Rate [7.8125e-05]
0: TRAIN [4][30/6832]	Time 0.091 (0.107)	Data 0.00098 (0.00090)	Tok/s 54950 (59980)	Loss/tok 2.9795 (3.1021)	Learning Rate [7.8125e-05]
3: TRAIN [4][40/6832]	Time 0.132 (0.107)	Data 0.00094 (0.00093)	Tok/s 75702 (60571)	Loss/tok 3.1827 (3.1159)	Learning Rate [7.8125e-05]
2: TRAIN [4][40/6832]	Time 0.132 (0.107)	Data 0.00106 (0.00099)	Tok/s 75382 (60104)	Loss/tok 3.2613 (3.1514)	Learning Rate [7.8125e-05]
1: TRAIN [4][40/6832]	Time 0.132 (0.107)	Data 0.00090 (0.00089)	Tok/s 74665 (59730)	Loss/tok 3.1979 (3.1202)	Learning Rate [7.8125e-05]
0: TRAIN [4][40/6832]	Time 0.132 (0.107)	Data 0.00097 (0.00091)	Tok/s 74655 (59240)	Loss/tok 3.4415 (3.1199)	Learning Rate [7.8125e-05]
3: TRAIN [4][50/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00092)	Tok/s 54912 (59878)	Loss/tok 3.0408 (3.1106)	Learning Rate [7.8125e-05]
1: TRAIN [4][50/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00090)	Tok/s 54875 (59016)	Loss/tok 3.0666 (3.1081)	Learning Rate [7.8125e-05]
2: TRAIN [4][50/6832]	Time 0.112 (0.105)	Data 0.00095 (0.00098)	Tok/s 54900 (59407)	Loss/tok 3.1801 (3.1494)	Learning Rate [7.8125e-05]
0: TRAIN [4][50/6832]	Time 0.112 (0.105)	Data 0.00096 (0.00092)	Tok/s 54136 (58531)	Loss/tok 3.0397 (3.1152)	Learning Rate [7.8125e-05]
1: TRAIN [4][60/6832]	Time 0.118 (0.106)	Data 0.00093 (0.00090)	Tok/s 60715 (58371)	Loss/tok 3.2523 (3.1188)	Learning Rate [7.8125e-05]
3: TRAIN [4][60/6832]	Time 0.118 (0.106)	Data 0.00098 (0.00092)	Tok/s 60780 (59129)	Loss/tok 3.2416 (3.1147)	Learning Rate [7.8125e-05]
0: TRAIN [4][60/6832]	Time 0.118 (0.106)	Data 0.00096 (0.00092)	Tok/s 59739 (57908)	Loss/tok 3.0454 (3.1145)	Learning Rate [7.8125e-05]
2: TRAIN [4][60/6832]	Time 0.118 (0.106)	Data 0.00101 (0.00098)	Tok/s 60775 (58730)	Loss/tok 3.4179 (3.1591)	Learning Rate [7.8125e-05]
2: TRAIN [4][70/6832]	Time 0.058 (0.104)	Data 0.00092 (0.00097)	Tok/s 48758 (58178)	Loss/tok 2.6914 (3.1522)	Learning Rate [7.8125e-05]
1: TRAIN [4][70/6832]	Time 0.058 (0.104)	Data 0.00088 (0.00089)	Tok/s 48735 (57856)	Loss/tok 2.6936 (3.1181)	Learning Rate [7.8125e-05]
3: TRAIN [4][70/6832]	Time 0.058 (0.104)	Data 0.00090 (0.00091)	Tok/s 49022 (58613)	Loss/tok 2.7318 (3.1112)	Learning Rate [7.8125e-05]
0: TRAIN [4][70/6832]	Time 0.058 (0.104)	Data 0.00093 (0.00092)	Tok/s 47111 (57413)	Loss/tok 2.5783 (3.1062)	Learning Rate [7.8125e-05]
3: TRAIN [4][80/6832]	Time 0.122 (0.104)	Data 0.00093 (0.00091)	Tok/s 52626 (58522)	Loss/tok 3.2476 (3.1222)	Learning Rate [7.8125e-05]
2: TRAIN [4][80/6832]	Time 0.122 (0.104)	Data 0.00095 (0.00097)	Tok/s 52620 (58058)	Loss/tok 3.1171 (3.1582)	Learning Rate [7.8125e-05]
1: TRAIN [4][80/6832]	Time 0.122 (0.104)	Data 0.00089 (0.00089)	Tok/s 52605 (57704)	Loss/tok 3.0531 (3.1255)	Learning Rate [7.8125e-05]
0: TRAIN [4][80/6832]	Time 0.122 (0.104)	Data 0.00092 (0.00093)	Tok/s 52623 (57146)	Loss/tok 3.0511 (3.1202)	Learning Rate [7.8125e-05]
2: TRAIN [4][90/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00097)	Tok/s 74295 (58121)	Loss/tok 3.1388 (3.1570)	Learning Rate [7.8125e-05]
3: TRAIN [4][90/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00091)	Tok/s 74506 (58549)	Loss/tok 3.2751 (3.1251)	Learning Rate [7.8125e-05]
1: TRAIN [4][90/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00089)	Tok/s 74318 (57774)	Loss/tok 3.2701 (3.1326)	Learning Rate [7.8125e-05]
0: TRAIN [4][90/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00093)	Tok/s 73495 (57230)	Loss/tok 3.2807 (3.1226)	Learning Rate [7.8125e-05]
3: TRAIN [4][100/6832]	Time 0.126 (0.104)	Data 0.00087 (0.00091)	Tok/s 66046 (58543)	Loss/tok 3.1575 (3.1144)	Learning Rate [7.8125e-05]
2: TRAIN [4][100/6832]	Time 0.126 (0.104)	Data 0.00093 (0.00097)	Tok/s 66020 (58097)	Loss/tok 3.2743 (3.1489)	Learning Rate [7.8125e-05]
1: TRAIN [4][100/6832]	Time 0.126 (0.104)	Data 0.00089 (0.00090)	Tok/s 65958 (57755)	Loss/tok 3.3412 (3.1281)	Learning Rate [7.8125e-05]
0: TRAIN [4][100/6832]	Time 0.126 (0.104)	Data 0.00097 (0.00093)	Tok/s 65893 (57241)	Loss/tok 3.2073 (3.1181)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: TRAIN [4][110/6832]	Time 0.119 (0.104)	Data 0.00102 (0.00092)	Tok/s 55078 (58466)	Loss/tok 3.1466 (3.1196)	Learning Rate [7.8125e-05]
2: TRAIN [4][110/6832]	Time 0.119 (0.104)	Data 0.00108 (0.00097)	Tok/s 54650 (58024)	Loss/tok 3.1492 (3.1514)	Learning Rate [7.8125e-05]
1: TRAIN [4][110/6832]	Time 0.119 (0.104)	Data 0.00094 (0.00090)	Tok/s 54002 (57703)	Loss/tok 3.0775 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][110/6832]	Time 0.118 (0.104)	Data 0.00100 (0.00093)	Tok/s 54015 (57231)	Loss/tok 3.3168 (3.1207)	Learning Rate [7.8125e-05]
1: TRAIN [4][120/6832]	Time 0.118 (0.105)	Data 0.00097 (0.00090)	Tok/s 57439 (57643)	Loss/tok 3.0594 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][120/6832]	Time 0.118 (0.105)	Data 0.00112 (0.00097)	Tok/s 57387 (57974)	Loss/tok 3.1730 (3.1543)	Learning Rate [7.8125e-05]
3: TRAIN [4][120/6832]	Time 0.118 (0.105)	Data 0.00107 (0.00092)	Tok/s 57399 (58400)	Loss/tok 3.2560 (3.1266)	Learning Rate [7.8125e-05]
0: TRAIN [4][120/6832]	Time 0.118 (0.105)	Data 0.00099 (0.00093)	Tok/s 56858 (57188)	Loss/tok 3.1929 (3.1258)	Learning Rate [7.8125e-05]
3: TRAIN [4][130/6832]	Time 0.125 (0.106)	Data 0.00089 (0.00092)	Tok/s 61507 (58724)	Loss/tok 3.1575 (3.1341)	Learning Rate [7.8125e-05]
2: TRAIN [4][130/6832]	Time 0.125 (0.106)	Data 0.00091 (0.00097)	Tok/s 61504 (58309)	Loss/tok 3.1407 (3.1573)	Learning Rate [7.8125e-05]
1: TRAIN [4][130/6832]	Time 0.125 (0.106)	Data 0.00092 (0.00090)	Tok/s 61446 (57985)	Loss/tok 3.2896 (3.1390)	Learning Rate [7.8125e-05]
0: TRAIN [4][130/6832]	Time 0.125 (0.106)	Data 0.00095 (0.00093)	Tok/s 61483 (57558)	Loss/tok 3.2664 (3.1295)	Learning Rate [7.8125e-05]
1: TRAIN [4][140/6832]	Time 0.126 (0.106)	Data 0.00088 (0.00090)	Tok/s 63854 (58193)	Loss/tok 3.2910 (3.1338)	Learning Rate [7.8125e-05]
2: TRAIN [4][140/6832]	Time 0.126 (0.106)	Data 0.00091 (0.00097)	Tok/s 63841 (58512)	Loss/tok 3.2456 (3.1493)	Learning Rate [7.8125e-05]
3: TRAIN [4][140/6832]	Time 0.126 (0.106)	Data 0.00087 (0.00092)	Tok/s 64712 (58939)	Loss/tok 3.2222 (3.1247)	Learning Rate [7.8125e-05]
0: TRAIN [4][140/6832]	Time 0.126 (0.106)	Data 0.00091 (0.00094)	Tok/s 63866 (57778)	Loss/tok 3.2356 (3.1300)	Learning Rate [7.8125e-05]
2: TRAIN [4][150/6832]	Time 0.068 (0.106)	Data 0.00099 (0.00097)	Tok/s 51095 (58453)	Loss/tok 2.7587 (3.1467)	Learning Rate [7.8125e-05]
3: TRAIN [4][150/6832]	Time 0.068 (0.106)	Data 0.00093 (0.00092)	Tok/s 52103 (58875)	Loss/tok 3.1004 (3.1248)	Learning Rate [7.8125e-05]
1: TRAIN [4][150/6832]	Time 0.068 (0.106)	Data 0.00096 (0.00090)	Tok/s 51032 (58143)	Loss/tok 2.8873 (3.1384)	Learning Rate [7.8125e-05]
0: TRAIN [4][150/6832]	Time 0.068 (0.106)	Data 0.00094 (0.00094)	Tok/s 50981 (57747)	Loss/tok 2.7423 (3.1292)	Learning Rate [7.8125e-05]
2: TRAIN [4][160/6832]	Time 0.126 (0.106)	Data 0.00092 (0.00097)	Tok/s 61856 (58611)	Loss/tok 3.3476 (3.1487)	Learning Rate [7.8125e-05]
3: TRAIN [4][160/6832]	Time 0.126 (0.106)	Data 0.00086 (0.00092)	Tok/s 62061 (59033)	Loss/tok 3.3518 (3.1262)	Learning Rate [7.8125e-05]
1: TRAIN [4][160/6832]	Time 0.126 (0.106)	Data 0.00089 (0.00090)	Tok/s 60990 (58304)	Loss/tok 2.9682 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][160/6832]	Time 0.126 (0.106)	Data 0.00088 (0.00093)	Tok/s 60957 (57909)	Loss/tok 3.2190 (3.1273)	Learning Rate [7.8125e-05]
1: TRAIN [4][170/6832]	Time 0.116 (0.106)	Data 0.00088 (0.00090)	Tok/s 54937 (58150)	Loss/tok 3.3165 (3.1376)	Learning Rate [7.8125e-05]
0: TRAIN [4][170/6832]	Time 0.117 (0.106)	Data 0.00089 (0.00093)	Tok/s 54928 (57753)	Loss/tok 3.3186 (3.1308)	Learning Rate [7.8125e-05]
2: TRAIN [4][170/6832]	Time 0.117 (0.106)	Data 0.00090 (0.00097)	Tok/s 54904 (58443)	Loss/tok 3.2978 (3.1472)	Learning Rate [7.8125e-05]
3: TRAIN [4][170/6832]	Time 0.117 (0.106)	Data 0.00083 (0.00092)	Tok/s 55707 (58853)	Loss/tok 2.9963 (3.1256)	Learning Rate [7.8125e-05]
1: TRAIN [4][180/6832]	Time 0.096 (0.106)	Data 0.00086 (0.00089)	Tok/s 51959 (58194)	Loss/tok 3.1962 (3.1424)	Learning Rate [7.8125e-05]
3: TRAIN [4][180/6832]	Time 0.096 (0.106)	Data 0.00089 (0.00092)	Tok/s 51943 (58885)	Loss/tok 3.0502 (3.1286)	Learning Rate [7.8125e-05]
0: TRAIN [4][180/6832]	Time 0.096 (0.106)	Data 0.00091 (0.00093)	Tok/s 51884 (57810)	Loss/tok 3.2139 (3.1360)	Learning Rate [7.8125e-05]
2: TRAIN [4][180/6832]	Time 0.096 (0.106)	Data 0.00112 (0.00097)	Tok/s 51967 (58485)	Loss/tok 3.1597 (3.1509)	Learning Rate [7.8125e-05]
1: TRAIN [4][190/6832]	Time 0.120 (0.106)	Data 0.00086 (0.00089)	Tok/s 56360 (58151)	Loss/tok 3.0710 (3.1428)	Learning Rate [7.8125e-05]
2: TRAIN [4][190/6832]	Time 0.120 (0.106)	Data 0.00089 (0.00097)	Tok/s 56957 (58433)	Loss/tok 3.3149 (3.1522)	Learning Rate [7.8125e-05]
3: TRAIN [4][190/6832]	Time 0.120 (0.106)	Data 0.00086 (0.00092)	Tok/s 57378 (58818)	Loss/tok 3.2577 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][190/6832]	Time 0.120 (0.106)	Data 0.00091 (0.00094)	Tok/s 56362 (57783)	Loss/tok 3.1990 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][200/6832]	Time 0.061 (0.106)	Data 0.00088 (0.00089)	Tok/s 48503 (58144)	Loss/tok 2.7837 (3.1421)	Learning Rate [7.8125e-05]
2: TRAIN [4][200/6832]	Time 0.061 (0.106)	Data 0.00099 (0.00097)	Tok/s 48555 (58440)	Loss/tok 2.8018 (3.1528)	Learning Rate [7.8125e-05]
3: TRAIN [4][200/6832]	Time 0.061 (0.106)	Data 0.00096 (0.00092)	Tok/s 48832 (58842)	Loss/tok 2.6592 (3.1272)	Learning Rate [7.8125e-05]
0: TRAIN [4][200/6832]	Time 0.061 (0.106)	Data 0.00088 (0.00093)	Tok/s 47839 (57773)	Loss/tok 2.6355 (3.1339)	Learning Rate [7.8125e-05]
2: TRAIN [4][210/6832]	Time 0.132 (0.107)	Data 0.00111 (0.00097)	Tok/s 88432 (58717)	Loss/tok 2.9930 (3.1519)	Learning Rate [7.8125e-05]
3: TRAIN [4][210/6832]	Time 0.132 (0.107)	Data 0.00107 (0.00092)	Tok/s 89266 (59124)	Loss/tok 3.0994 (3.1269)	Learning Rate [7.8125e-05]
0: TRAIN [4][210/6832]	Time 0.132 (0.107)	Data 0.00097 (0.00093)	Tok/s 87273 (58056)	Loss/tok 3.0343 (3.1320)	Learning Rate [7.8125e-05]
1: TRAIN [4][210/6832]	Time 0.132 (0.107)	Data 0.00095 (0.00090)	Tok/s 87849 (58423)	Loss/tok 3.1222 (3.1405)	Learning Rate [7.8125e-05]
2: TRAIN [4][220/6832]	Time 0.116 (0.107)	Data 0.00093 (0.00097)	Tok/s 53867 (58659)	Loss/tok 3.2868 (3.1529)	Learning Rate [7.8125e-05]
1: TRAIN [4][220/6832]	Time 0.117 (0.107)	Data 0.00088 (0.00090)	Tok/s 53263 (58373)	Loss/tok 3.1747 (3.1395)	Learning Rate [7.8125e-05]
3: TRAIN [4][220/6832]	Time 0.116 (0.107)	Data 0.00088 (0.00092)	Tok/s 53856 (59070)	Loss/tok 3.2569 (3.1248)	Learning Rate [7.8125e-05]
0: TRAIN [4][220/6832]	Time 0.116 (0.107)	Data 0.00092 (0.00093)	Tok/s 52775 (58011)	Loss/tok 3.1980 (3.1310)	Learning Rate [7.8125e-05]
1: TRAIN [4][230/6832]	Time 0.084 (0.106)	Data 0.00088 (0.00090)	Tok/s 53163 (58330)	Loss/tok 3.0593 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][230/6832]	Time 0.084 (0.106)	Data 0.00092 (0.00092)	Tok/s 53349 (59057)	Loss/tok 3.1900 (3.1239)	Learning Rate [7.8125e-05]
2: TRAIN [4][230/6832]	Time 0.084 (0.106)	Data 0.00093 (0.00097)	Tok/s 53351 (58630)	Loss/tok 3.1475 (3.1495)	Learning Rate [7.8125e-05]
0: TRAIN [4][230/6832]	Time 0.084 (0.106)	Data 0.00087 (0.00093)	Tok/s 51828 (57963)	Loss/tok 3.0904 (3.1302)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [4][240/6832]	Time 0.125 (0.106)	Data 0.00095 (0.00090)	Tok/s 59367 (58457)	Loss/tok 3.2153 (3.1406)	Learning Rate [7.8125e-05]
0: TRAIN [4][240/6832]	Time 0.125 (0.106)	Data 0.00091 (0.00093)	Tok/s 59375 (58098)	Loss/tok 3.3107 (3.1335)	Learning Rate [7.8125e-05]
2: TRAIN [4][240/6832]	Time 0.125 (0.106)	Data 0.00117 (0.00097)	Tok/s 59573 (58760)	Loss/tok 3.1903 (3.1496)	Learning Rate [7.8125e-05]
3: TRAIN [4][240/6832]	Time 0.125 (0.106)	Data 0.00115 (0.00092)	Tok/s 60422 (59182)	Loss/tok 3.2108 (3.1254)	Learning Rate [7.8125e-05]
1: TRAIN [4][250/6832]	Time 0.129 (0.107)	Data 0.00088 (0.00090)	Tok/s 64383 (58607)	Loss/tok 3.1564 (3.1425)	Learning Rate [7.8125e-05]
0: TRAIN [4][250/6832]	Time 0.129 (0.107)	Data 0.00092 (0.00093)	Tok/s 64373 (58258)	Loss/tok 3.2376 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][250/6832]	Time 0.129 (0.107)	Data 0.00092 (0.00097)	Tok/s 64375 (58904)	Loss/tok 3.2823 (3.1522)	Learning Rate [7.8125e-05]
3: TRAIN [4][250/6832]	Time 0.129 (0.107)	Data 0.00089 (0.00092)	Tok/s 64723 (59327)	Loss/tok 3.2070 (3.1283)	Learning Rate [7.8125e-05]
2: TRAIN [4][260/6832]	Time 0.128 (0.107)	Data 0.00092 (0.00097)	Tok/s 63846 (58917)	Loss/tok 3.1371 (3.1521)	Learning Rate [7.8125e-05]
3: TRAIN [4][260/6832]	Time 0.128 (0.107)	Data 0.00088 (0.00092)	Tok/s 63850 (59341)	Loss/tok 3.1982 (3.1275)	Learning Rate [7.8125e-05]
1: TRAIN [4][260/6832]	Time 0.128 (0.107)	Data 0.00087 (0.00090)	Tok/s 63865 (58621)	Loss/tok 3.1925 (3.1416)	Learning Rate [7.8125e-05]
0: TRAIN [4][260/6832]	Time 0.128 (0.107)	Data 0.00093 (0.00093)	Tok/s 63714 (58281)	Loss/tok 3.3443 (3.1396)	Learning Rate [7.8125e-05]
1: TRAIN [4][270/6832]	Time 0.118 (0.107)	Data 0.00108 (0.00090)	Tok/s 52066 (58607)	Loss/tok 3.1694 (3.1396)	Learning Rate [7.8125e-05]
0: TRAIN [4][270/6832]	Time 0.118 (0.107)	Data 0.00107 (0.00093)	Tok/s 51291 (58267)	Loss/tok 3.0415 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][270/6832]	Time 0.118 (0.107)	Data 0.00112 (0.00097)	Tok/s 51973 (58902)	Loss/tok 3.1856 (3.1505)	Learning Rate [7.8125e-05]
3: TRAIN [4][270/6832]	Time 0.118 (0.107)	Data 0.00108 (0.00092)	Tok/s 51926 (59325)	Loss/tok 3.1069 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][280/6832]	Time 0.108 (0.107)	Data 0.00088 (0.00090)	Tok/s 55198 (58545)	Loss/tok 3.1963 (3.1407)	Learning Rate [7.8125e-05]
2: TRAIN [4][280/6832]	Time 0.108 (0.107)	Data 0.00107 (0.00097)	Tok/s 55778 (58849)	Loss/tok 3.0059 (3.1503)	Learning Rate [7.8125e-05]
3: TRAIN [4][280/6832]	Time 0.108 (0.107)	Data 0.00088 (0.00092)	Tok/s 55775 (59277)	Loss/tok 3.1597 (3.1309)	Learning Rate [7.8125e-05]
0: TRAIN [4][280/6832]	Time 0.108 (0.107)	Data 0.00088 (0.00093)	Tok/s 54576 (58165)	Loss/tok 3.1417 (3.1387)	Learning Rate [7.8125e-05]
2: TRAIN [4][290/6832]	Time 0.118 (0.107)	Data 0.00094 (0.00097)	Tok/s 53248 (58950)	Loss/tok 3.0773 (3.1511)	Learning Rate [7.8125e-05]
3: TRAIN [4][290/6832]	Time 0.118 (0.107)	Data 0.00089 (0.00092)	Tok/s 53248 (59377)	Loss/tok 3.2484 (3.1336)	Learning Rate [7.8125e-05]
1: TRAIN [4][290/6832]	Time 0.118 (0.107)	Data 0.00087 (0.00090)	Tok/s 52177 (58645)	Loss/tok 3.0640 (3.1413)	Learning Rate [7.8125e-05]
0: TRAIN [4][290/6832]	Time 0.118 (0.107)	Data 0.00086 (0.00093)	Tok/s 52156 (58272)	Loss/tok 3.2287 (3.1406)	Learning Rate [7.8125e-05]
1: TRAIN [4][300/6832]	Time 0.080 (0.108)	Data 0.00094 (0.00090)	Tok/s 54156 (58678)	Loss/tok 2.9661 (3.1407)	Learning Rate [7.8125e-05]
2: TRAIN [4][300/6832]	Time 0.080 (0.108)	Data 0.00099 (0.00097)	Tok/s 54156 (58980)	Loss/tok 3.0373 (3.1515)	Learning Rate [7.8125e-05]
3: TRAIN [4][300/6832]	Time 0.080 (0.108)	Data 0.00095 (0.00092)	Tok/s 54146 (59407)	Loss/tok 3.0518 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [4][300/6832]	Time 0.080 (0.108)	Data 0.00094 (0.00093)	Tok/s 54132 (58314)	Loss/tok 3.0907 (3.1415)	Learning Rate [7.8125e-05]
1: TRAIN [4][310/6832]	Time 0.124 (0.107)	Data 0.00094 (0.00090)	Tok/s 62460 (58531)	Loss/tok 3.2836 (3.1392)	Learning Rate [7.8125e-05]
0: TRAIN [4][310/6832]	Time 0.124 (0.107)	Data 0.00092 (0.00093)	Tok/s 62135 (58168)	Loss/tok 3.1122 (3.1392)	Learning Rate [7.8125e-05]
2: TRAIN [4][310/6832]	Time 0.124 (0.107)	Data 0.00096 (0.00097)	Tok/s 63090 (58833)	Loss/tok 3.1713 (3.1497)	Learning Rate [7.8125e-05]
3: TRAIN [4][310/6832]	Time 0.124 (0.107)	Data 0.00094 (0.00092)	Tok/s 63085 (59263)	Loss/tok 3.1957 (3.1315)	Learning Rate [7.8125e-05]
1: TRAIN [4][320/6832]	Time 0.130 (0.106)	Data 0.00086 (0.00090)	Tok/s 79201 (58465)	Loss/tok 3.1655 (3.1362)	Learning Rate [7.8125e-05]
2: TRAIN [4][320/6832]	Time 0.130 (0.106)	Data 0.00091 (0.00097)	Tok/s 79671 (58769)	Loss/tok 2.9958 (3.1452)	Learning Rate [7.8125e-05]
3: TRAIN [4][320/6832]	Time 0.130 (0.106)	Data 0.00087 (0.00092)	Tok/s 79855 (59213)	Loss/tok 3.1386 (3.1275)	Learning Rate [7.8125e-05]
0: TRAIN [4][320/6832]	Time 0.130 (0.106)	Data 0.00091 (0.00093)	Tok/s 78713 (58093)	Loss/tok 3.1009 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][330/6832]	Time 0.073 (0.106)	Data 0.00090 (0.00090)	Tok/s 52356 (58481)	Loss/tok 3.0676 (3.1366)	Learning Rate [7.8125e-05]
2: TRAIN [4][330/6832]	Time 0.073 (0.106)	Data 0.00091 (0.00097)	Tok/s 53460 (58786)	Loss/tok 2.9999 (3.1469)	Learning Rate [7.8125e-05]
3: TRAIN [4][330/6832]	Time 0.073 (0.106)	Data 0.00088 (0.00092)	Tok/s 54083 (59233)	Loss/tok 2.8411 (3.1274)	Learning Rate [7.8125e-05]
0: TRAIN [4][330/6832]	Time 0.073 (0.106)	Data 0.00087 (0.00093)	Tok/s 52334 (58103)	Loss/tok 3.0273 (3.1374)	Learning Rate [7.8125e-05]
3: TRAIN [4][340/6832]	Time 0.131 (0.106)	Data 0.00090 (0.00092)	Tok/s 73376 (59266)	Loss/tok 3.2513 (3.1273)	Learning Rate [7.8125e-05]
2: TRAIN [4][340/6832]	Time 0.131 (0.106)	Data 0.00091 (0.00096)	Tok/s 73367 (58819)	Loss/tok 3.2051 (3.1470)	Learning Rate [7.8125e-05]
0: TRAIN [4][340/6832]	Time 0.131 (0.106)	Data 0.00087 (0.00093)	Tok/s 72327 (58134)	Loss/tok 3.2033 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][340/6832]	Time 0.131 (0.106)	Data 0.00087 (0.00090)	Tok/s 73158 (58518)	Loss/tok 3.2790 (3.1378)	Learning Rate [7.8125e-05]
2: TRAIN [4][350/6832]	Time 0.102 (0.106)	Data 0.00098 (0.00096)	Tok/s 52211 (58791)	Loss/tok 3.0803 (3.1471)	Learning Rate [7.8125e-05]
1: TRAIN [4][350/6832]	Time 0.102 (0.106)	Data 0.00093 (0.00090)	Tok/s 51544 (58487)	Loss/tok 2.9796 (3.1371)	Learning Rate [7.8125e-05]
3: TRAIN [4][350/6832]	Time 0.102 (0.106)	Data 0.00100 (0.00092)	Tok/s 52829 (59234)	Loss/tok 3.0746 (3.1264)	Learning Rate [7.8125e-05]
0: TRAIN [4][350/6832]	Time 0.102 (0.106)	Data 0.00100 (0.00093)	Tok/s 51567 (58104)	Loss/tok 3.0526 (3.1367)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][360/6832]	Time 0.128 (0.106)	Data 0.00115 (0.00090)	Tok/s 60069 (58702)	Loss/tok 3.1283 (3.1367)	Learning Rate [7.8125e-05]
0: TRAIN [4][360/6832]	Time 0.128 (0.106)	Data 0.00104 (0.00093)	Tok/s 59276 (58314)	Loss/tok 3.2445 (3.1366)	Learning Rate [7.8125e-05]
2: TRAIN [4][360/6832]	Time 0.128 (0.106)	Data 0.00094 (0.00096)	Tok/s 60100 (59011)	Loss/tok 3.3198 (3.1459)	Learning Rate [7.8125e-05]
3: TRAIN [4][360/6832]	Time 0.128 (0.106)	Data 0.00092 (0.00092)	Tok/s 60090 (59455)	Loss/tok 3.3147 (3.1257)	Learning Rate [7.8125e-05]
2: TRAIN [4][370/6832]	Time 0.105 (0.106)	Data 0.00090 (0.00096)	Tok/s 53888 (59094)	Loss/tok 3.1036 (3.1464)	Learning Rate [7.8125e-05]
1: TRAIN [4][370/6832]	Time 0.105 (0.106)	Data 0.00087 (0.00090)	Tok/s 53199 (58782)	Loss/tok 2.9569 (3.1365)	Learning Rate [7.8125e-05]
0: TRAIN [4][370/6832]	Time 0.105 (0.106)	Data 0.00087 (0.00093)	Tok/s 52658 (58394)	Loss/tok 3.1801 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][370/6832]	Time 0.105 (0.106)	Data 0.00095 (0.00092)	Tok/s 53890 (59533)	Loss/tok 3.0197 (3.1249)	Learning Rate [7.8125e-05]
1: TRAIN [4][380/6832]	Time 0.066 (0.106)	Data 0.00087 (0.00090)	Tok/s 50739 (58711)	Loss/tok 2.9319 (3.1363)	Learning Rate [7.8125e-05]
0: TRAIN [4][380/6832]	Time 0.066 (0.106)	Data 0.00084 (0.00093)	Tok/s 50696 (58330)	Loss/tok 2.7315 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][380/6832]	Time 0.066 (0.106)	Data 0.00091 (0.00092)	Tok/s 52681 (59469)	Loss/tok 2.8735 (3.1250)	Learning Rate [7.8125e-05]
2: TRAIN [4][380/6832]	Time 0.066 (0.106)	Data 0.00091 (0.00096)	Tok/s 51218 (59024)	Loss/tok 2.8668 (3.1450)	Learning Rate [7.8125e-05]
2: TRAIN [4][390/6832]	Time 0.054 (0.105)	Data 0.00089 (0.00096)	Tok/s 49401 (58950)	Loss/tok 2.4096 (3.1428)	Learning Rate [7.8125e-05]
1: TRAIN [4][390/6832]	Time 0.054 (0.105)	Data 0.00086 (0.00090)	Tok/s 47462 (58629)	Loss/tok 2.6767 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][390/6832]	Time 0.054 (0.105)	Data 0.00092 (0.00092)	Tok/s 49436 (59393)	Loss/tok 2.5607 (3.1238)	Learning Rate [7.8125e-05]
0: TRAIN [4][390/6832]	Time 0.054 (0.105)	Data 0.00089 (0.00093)	Tok/s 47029 (58250)	Loss/tok 2.6576 (3.1337)	Learning Rate [7.8125e-05]
1: TRAIN [4][400/6832]	Time 0.121 (0.106)	Data 0.00090 (0.00090)	Tok/s 55045 (58733)	Loss/tok 3.2423 (3.1362)	Learning Rate [7.8125e-05]
2: TRAIN [4][400/6832]	Time 0.121 (0.106)	Data 0.00094 (0.00096)	Tok/s 55040 (59054)	Loss/tok 3.3063 (3.1442)	Learning Rate [7.8125e-05]
0: TRAIN [4][400/6832]	Time 0.121 (0.106)	Data 0.00088 (0.00093)	Tok/s 55037 (58361)	Loss/tok 3.4286 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][400/6832]	Time 0.121 (0.106)	Data 0.00097 (0.00093)	Tok/s 55040 (59501)	Loss/tok 3.0940 (3.1245)	Learning Rate [7.8125e-05]
1: TRAIN [4][410/6832]	Time 0.121 (0.106)	Data 0.00089 (0.00090)	Tok/s 51525 (58891)	Loss/tok 3.0964 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][410/6832]	Time 0.121 (0.106)	Data 0.00097 (0.00096)	Tok/s 51853 (59212)	Loss/tok 3.2162 (3.1436)	Learning Rate [7.8125e-05]
0: TRAIN [4][410/6832]	Time 0.121 (0.106)	Data 0.00095 (0.00093)	Tok/s 50778 (58518)	Loss/tok 3.1857 (3.1367)	Learning Rate [7.8125e-05]
3: TRAIN [4][410/6832]	Time 0.121 (0.106)	Data 0.00098 (0.00093)	Tok/s 51849 (59660)	Loss/tok 3.2590 (3.1260)	Learning Rate [7.8125e-05]
1: TRAIN [4][420/6832]	Time 0.083 (0.106)	Data 0.00086 (0.00090)	Tok/s 52396 (58951)	Loss/tok 3.0721 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][420/6832]	Time 0.083 (0.106)	Data 0.00093 (0.00096)	Tok/s 52640 (59274)	Loss/tok 3.2374 (3.1429)	Learning Rate [7.8125e-05]
3: TRAIN [4][420/6832]	Time 0.083 (0.106)	Data 0.00099 (0.00093)	Tok/s 52661 (59726)	Loss/tok 3.0142 (3.1256)	Learning Rate [7.8125e-05]
0: TRAIN [4][420/6832]	Time 0.083 (0.106)	Data 0.00089 (0.00093)	Tok/s 51091 (58572)	Loss/tok 3.0132 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][430/6832]	Time 0.128 (0.106)	Data 0.00088 (0.00090)	Tok/s 60972 (58973)	Loss/tok 3.1493 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][430/6832]	Time 0.128 (0.106)	Data 0.00087 (0.00093)	Tok/s 60109 (58594)	Loss/tok 3.2573 (3.1366)	Learning Rate [7.8125e-05]
2: TRAIN [4][430/6832]	Time 0.128 (0.106)	Data 0.00092 (0.00096)	Tok/s 61084 (59293)	Loss/tok 3.2222 (3.1430)	Learning Rate [7.8125e-05]
3: TRAIN [4][430/6832]	Time 0.128 (0.106)	Data 0.00095 (0.00093)	Tok/s 61067 (59741)	Loss/tok 3.2180 (3.1275)	Learning Rate [7.8125e-05]
1: TRAIN [4][440/6832]	Time 0.129 (0.106)	Data 0.00087 (0.00090)	Tok/s 63548 (59085)	Loss/tok 3.2539 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][440/6832]	Time 0.129 (0.106)	Data 0.00098 (0.00096)	Tok/s 63555 (59400)	Loss/tok 3.4214 (3.1441)	Learning Rate [7.8125e-05]
0: TRAIN [4][440/6832]	Time 0.129 (0.106)	Data 0.00090 (0.00093)	Tok/s 63549 (58704)	Loss/tok 3.4135 (3.1373)	Learning Rate [7.8125e-05]
3: TRAIN [4][440/6832]	Time 0.129 (0.106)	Data 0.00093 (0.00093)	Tok/s 63542 (59845)	Loss/tok 3.2697 (3.1268)	Learning Rate [7.8125e-05]
1: TRAIN [4][450/6832]	Time 0.073 (0.106)	Data 0.00088 (0.00090)	Tok/s 52339 (59049)	Loss/tok 2.9239 (3.1368)	Learning Rate [7.8125e-05]
0: TRAIN [4][450/6832]	Time 0.073 (0.106)	Data 0.00090 (0.00093)	Tok/s 50958 (58640)	Loss/tok 2.7264 (3.1359)	Learning Rate [7.8125e-05]
2: TRAIN [4][450/6832]	Time 0.073 (0.106)	Data 0.00093 (0.00096)	Tok/s 52400 (59377)	Loss/tok 2.9403 (3.1446)	Learning Rate [7.8125e-05]
3: TRAIN [4][450/6832]	Time 0.073 (0.106)	Data 0.00095 (0.00093)	Tok/s 52389 (59827)	Loss/tok 3.0407 (3.1275)	Learning Rate [7.8125e-05]
2: TRAIN [4][460/6832]	Time 0.119 (0.106)	Data 0.00095 (0.00096)	Tok/s 58746 (59348)	Loss/tok 3.1227 (3.1449)	Learning Rate [7.8125e-05]
1: TRAIN [4][460/6832]	Time 0.119 (0.106)	Data 0.00089 (0.00090)	Tok/s 58230 (59019)	Loss/tok 3.1203 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][460/6832]	Time 0.119 (0.106)	Data 0.00099 (0.00093)	Tok/s 59304 (59803)	Loss/tok 3.2248 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][460/6832]	Time 0.119 (0.106)	Data 0.00086 (0.00093)	Tok/s 58212 (58611)	Loss/tok 3.0735 (3.1363)	Learning Rate [7.8125e-05]
2: TRAIN [4][470/6832]	Time 0.123 (0.106)	Data 0.00089 (0.00096)	Tok/s 67372 (59371)	Loss/tok 3.3179 (3.1447)	Learning Rate [7.8125e-05]
1: TRAIN [4][470/6832]	Time 0.123 (0.106)	Data 0.00093 (0.00090)	Tok/s 67369 (59036)	Loss/tok 3.0957 (3.1367)	Learning Rate [7.8125e-05]
0: TRAIN [4][470/6832]	Time 0.123 (0.106)	Data 0.00088 (0.00093)	Tok/s 67000 (58606)	Loss/tok 3.3375 (3.1366)	Learning Rate [7.8125e-05]
3: TRAIN [4][470/6832]	Time 0.123 (0.106)	Data 0.00093 (0.00093)	Tok/s 67371 (59831)	Loss/tok 3.2867 (3.1304)	Learning Rate [7.8125e-05]
2: TRAIN [4][480/6832]	Time 0.083 (0.106)	Data 0.00097 (0.00096)	Tok/s 53682 (59288)	Loss/tok 2.8698 (3.1430)	Learning Rate [7.8125e-05]
1: TRAIN [4][480/6832]	Time 0.084 (0.106)	Data 0.00094 (0.00091)	Tok/s 53630 (58960)	Loss/tok 3.1923 (3.1366)	Learning Rate [7.8125e-05]
3: TRAIN [4][480/6832]	Time 0.084 (0.106)	Data 0.00093 (0.00093)	Tok/s 53625 (59751)	Loss/tok 3.0150 (3.1290)	Learning Rate [7.8125e-05]
0: TRAIN [4][480/6832]	Time 0.084 (0.106)	Data 0.00085 (0.00093)	Tok/s 53561 (58536)	Loss/tok 2.8588 (3.1365)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][490/6832]	Time 0.058 (0.106)	Data 0.00096 (0.00096)	Tok/s 48850 (59234)	Loss/tok 2.6926 (3.1425)	Learning Rate [7.8125e-05]
1: TRAIN [4][490/6832]	Time 0.057 (0.106)	Data 0.00089 (0.00091)	Tok/s 48999 (58907)	Loss/tok 2.6067 (3.1373)	Learning Rate [7.8125e-05]
0: TRAIN [4][490/6832]	Time 0.057 (0.106)	Data 0.00088 (0.00093)	Tok/s 47546 (58487)	Loss/tok 2.5822 (3.1362)	Learning Rate [7.8125e-05]
3: TRAIN [4][490/6832]	Time 0.058 (0.106)	Data 0.00098 (0.00093)	Tok/s 49472 (59693)	Loss/tok 2.7309 (3.1284)	Learning Rate [7.8125e-05]
1: TRAIN [4][500/6832]	Time 0.094 (0.106)	Data 0.00097 (0.00091)	Tok/s 52019 (58834)	Loss/tok 3.1193 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][500/6832]	Time 0.093 (0.106)	Data 0.00099 (0.00096)	Tok/s 52028 (59163)	Loss/tok 3.1007 (3.1408)	Learning Rate [7.8125e-05]
0: TRAIN [4][500/6832]	Time 0.094 (0.106)	Data 0.00091 (0.00093)	Tok/s 51121 (58406)	Loss/tok 3.1381 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][500/6832]	Time 0.094 (0.106)	Data 0.00104 (0.00093)	Tok/s 51991 (59623)	Loss/tok 2.8535 (3.1280)	Learning Rate [7.8125e-05]
2: TRAIN [4][510/6832]	Time 0.131 (0.106)	Data 0.00090 (0.00096)	Tok/s 82573 (59257)	Loss/tok 3.2045 (3.1414)	Learning Rate [7.8125e-05]
1: TRAIN [4][510/6832]	Time 0.131 (0.106)	Data 0.00088 (0.00091)	Tok/s 82010 (58926)	Loss/tok 3.0511 (3.1368)	Learning Rate [7.8125e-05]
0: TRAIN [4][510/6832]	Time 0.131 (0.106)	Data 0.00090 (0.00093)	Tok/s 81691 (58499)	Loss/tok 3.0787 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][510/6832]	Time 0.131 (0.106)	Data 0.00086 (0.00093)	Tok/s 82987 (59713)	Loss/tok 3.0392 (3.1281)	Learning Rate [7.8125e-05]
2: TRAIN [4][520/6832]	Time 0.119 (0.106)	Data 0.00089 (0.00096)	Tok/s 53956 (59276)	Loss/tok 3.1948 (3.1408)	Learning Rate [7.8125e-05]
3: TRAIN [4][520/6832]	Time 0.119 (0.106)	Data 0.00092 (0.00093)	Tok/s 53963 (59739)	Loss/tok 3.0820 (3.1291)	Learning Rate [7.8125e-05]
0: TRAIN [4][520/6832]	Time 0.119 (0.106)	Data 0.00086 (0.00093)	Tok/s 53176 (58488)	Loss/tok 3.1884 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][520/6832]	Time 0.119 (0.106)	Data 0.00115 (0.00091)	Tok/s 53968 (58940)	Loss/tok 3.2822 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][530/6832]	Time 0.129 (0.106)	Data 0.00093 (0.00091)	Tok/s 65501 (58941)	Loss/tok 3.0516 (3.1395)	Learning Rate [7.8125e-05]
0: TRAIN [4][530/6832]	Time 0.129 (0.106)	Data 0.00091 (0.00093)	Tok/s 65474 (58496)	Loss/tok 3.3081 (3.1359)	Learning Rate [7.8125e-05]
2: TRAIN [4][530/6832]	Time 0.129 (0.106)	Data 0.00094 (0.00096)	Tok/s 65444 (59275)	Loss/tok 3.3134 (3.1416)	Learning Rate [7.8125e-05]
3: TRAIN [4][530/6832]	Time 0.129 (0.106)	Data 0.00107 (0.00093)	Tok/s 65513 (59734)	Loss/tok 3.2040 (3.1302)	Learning Rate [7.8125e-05]
1: TRAIN [4][540/6832]	Time 0.130 (0.106)	Data 0.00087 (0.00091)	Tok/s 73600 (58966)	Loss/tok 3.1034 (3.1381)	Learning Rate [7.8125e-05]
0: TRAIN [4][540/6832]	Time 0.130 (0.106)	Data 0.00092 (0.00093)	Tok/s 72886 (58523)	Loss/tok 3.1743 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][540/6832]	Time 0.130 (0.106)	Data 0.00089 (0.00096)	Tok/s 73806 (59300)	Loss/tok 3.1977 (3.1404)	Learning Rate [7.8125e-05]
3: TRAIN [4][540/6832]	Time 0.130 (0.106)	Data 0.00093 (0.00093)	Tok/s 73818 (59760)	Loss/tok 3.2967 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][550/6832]	Time 0.073 (0.106)	Data 0.00088 (0.00091)	Tok/s 52356 (58962)	Loss/tok 2.8026 (3.1373)	Learning Rate [7.8125e-05]
2: TRAIN [4][550/6832]	Time 0.073 (0.106)	Data 0.00093 (0.00096)	Tok/s 52329 (59297)	Loss/tok 2.7654 (3.1401)	Learning Rate [7.8125e-05]
3: TRAIN [4][550/6832]	Time 0.073 (0.106)	Data 0.00094 (0.00093)	Tok/s 52332 (59757)	Loss/tok 2.7680 (3.1295)	Learning Rate [7.8125e-05]
0: TRAIN [4][550/6832]	Time 0.073 (0.106)	Data 0.00086 (0.00093)	Tok/s 51185 (58521)	Loss/tok 2.7997 (3.1333)	Learning Rate [7.8125e-05]
1: TRAIN [4][560/6832]	Time 0.097 (0.106)	Data 0.00096 (0.00091)	Tok/s 52723 (58973)	Loss/tok 3.1829 (3.1365)	Learning Rate [7.8125e-05]
2: TRAIN [4][560/6832]	Time 0.097 (0.106)	Data 0.00101 (0.00096)	Tok/s 52859 (59311)	Loss/tok 3.1194 (3.1384)	Learning Rate [7.8125e-05]
0: TRAIN [4][560/6832]	Time 0.097 (0.106)	Data 0.00094 (0.00093)	Tok/s 51531 (58530)	Loss/tok 2.9830 (3.1326)	Learning Rate [7.8125e-05]
3: TRAIN [4][560/6832]	Time 0.097 (0.106)	Data 0.00100 (0.00093)	Tok/s 52836 (59777)	Loss/tok 3.1373 (3.1282)	Learning Rate [7.8125e-05]
1: TRAIN [4][570/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00091)	Tok/s 91381 (58992)	Loss/tok 3.0023 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][570/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00093)	Tok/s 90221 (58525)	Loss/tok 3.0496 (3.1316)	Learning Rate [7.8125e-05]
2: TRAIN [4][570/6832]	Time 0.132 (0.105)	Data 0.00106 (0.00096)	Tok/s 92583 (59344)	Loss/tok 3.0113 (3.1365)	Learning Rate [7.8125e-05]
3: TRAIN [4][570/6832]	Time 0.132 (0.105)	Data 0.00118 (0.00093)	Tok/s 94408 (59821)	Loss/tok 2.9603 (3.1266)	Learning Rate [7.8125e-05]
1: TRAIN [4][580/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00091)	Tok/s 54046 (58978)	Loss/tok 3.0144 (3.1343)	Learning Rate [7.8125e-05]
2: TRAIN [4][580/6832]	Time 0.078 (0.105)	Data 0.00095 (0.00096)	Tok/s 54098 (59330)	Loss/tok 3.0212 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][580/6832]	Time 0.078 (0.105)	Data 0.00095 (0.00094)	Tok/s 54093 (59805)	Loss/tok 2.9847 (3.1265)	Learning Rate [7.8125e-05]
0: TRAIN [4][580/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00093)	Tok/s 52447 (58515)	Loss/tok 2.9470 (3.1312)	Learning Rate [7.8125e-05]
1: TRAIN [4][590/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00091)	Tok/s 73624 (58963)	Loss/tok 3.1618 (3.1337)	Learning Rate [7.8125e-05]
2: TRAIN [4][590/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00096)	Tok/s 73626 (59319)	Loss/tok 3.1153 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][590/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00093)	Tok/s 73231 (58503)	Loss/tok 3.1396 (3.1306)	Learning Rate [7.8125e-05]
3: TRAIN [4][590/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00094)	Tok/s 74065 (59791)	Loss/tok 3.3409 (3.1269)	Learning Rate [7.8125e-05]
1: TRAIN [4][600/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00091)	Tok/s 62962 (59055)	Loss/tok 3.2120 (3.1338)	Learning Rate [7.8125e-05]
2: TRAIN [4][600/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00096)	Tok/s 63491 (59411)	Loss/tok 3.1682 (3.1370)	Learning Rate [7.8125e-05]
0: TRAIN [4][600/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00093)	Tok/s 62982 (58597)	Loss/tok 3.0543 (3.1316)	Learning Rate [7.8125e-05]
3: TRAIN [4][600/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00094)	Tok/s 63961 (59879)	Loss/tok 3.3694 (3.1277)	Learning Rate [7.8125e-05]
1: TRAIN [4][610/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00091)	Tok/s 59481 (59079)	Loss/tok 3.3016 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][610/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00096)	Tok/s 59640 (59431)	Loss/tok 3.1973 (3.1378)	Learning Rate [7.8125e-05]
0: TRAIN [4][610/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00093)	Tok/s 59495 (58622)	Loss/tok 3.1419 (3.1315)	Learning Rate [7.8125e-05]
3: TRAIN [4][610/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00094)	Tok/s 60559 (59895)	Loss/tok 3.1403 (3.1276)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][620/6832]	Time 0.105 (0.105)	Data 0.00092 (0.00096)	Tok/s 53755 (59414)	Loss/tok 3.1112 (3.1378)	Learning Rate [7.8125e-05]
1: TRAIN [4][620/6832]	Time 0.105 (0.105)	Data 0.00086 (0.00091)	Tok/s 53708 (59063)	Loss/tok 3.1336 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][620/6832]	Time 0.105 (0.105)	Data 0.00091 (0.00094)	Tok/s 53758 (59877)	Loss/tok 3.0302 (3.1262)	Learning Rate [7.8125e-05]
0: TRAIN [4][620/6832]	Time 0.105 (0.105)	Data 0.00085 (0.00093)	Tok/s 53336 (58608)	Loss/tok 2.9155 (3.1310)	Learning Rate [7.8125e-05]
1: TRAIN [4][630/6832]	Time 0.131 (0.106)	Data 0.00090 (0.00091)	Tok/s 78785 (59050)	Loss/tok 3.0866 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][630/6832]	Time 0.131 (0.106)	Data 0.00090 (0.00096)	Tok/s 79262 (59400)	Loss/tok 3.1588 (3.1374)	Learning Rate [7.8125e-05]
0: TRAIN [4][630/6832]	Time 0.131 (0.106)	Data 0.00089 (0.00093)	Tok/s 78281 (58601)	Loss/tok 3.2243 (3.1314)	Learning Rate [7.8125e-05]
3: TRAIN [4][630/6832]	Time 0.131 (0.106)	Data 0.00093 (0.00094)	Tok/s 79283 (59864)	Loss/tok 3.1553 (3.1264)	Learning Rate [7.8125e-05]
1: TRAIN [4][640/6832]	Time 0.129 (0.106)	Data 0.00087 (0.00091)	Tok/s 61591 (59121)	Loss/tok 3.1997 (3.1352)	Learning Rate [7.8125e-05]
2: TRAIN [4][640/6832]	Time 0.129 (0.106)	Data 0.00091 (0.00096)	Tok/s 61634 (59471)	Loss/tok 3.3047 (3.1372)	Learning Rate [7.8125e-05]
0: TRAIN [4][640/6832]	Time 0.129 (0.106)	Data 0.00087 (0.00093)	Tok/s 61596 (58671)	Loss/tok 3.4447 (3.1313)	Learning Rate [7.8125e-05]
3: TRAIN [4][640/6832]	Time 0.129 (0.106)	Data 0.00092 (0.00094)	Tok/s 62026 (59936)	Loss/tok 3.1949 (3.1264)	Learning Rate [7.8125e-05]
1: TRAIN [4][650/6832]	Time 0.064 (0.106)	Data 0.00094 (0.00091)	Tok/s 49877 (59172)	Loss/tok 3.0231 (3.1345)	Learning Rate [7.8125e-05]
2: TRAIN [4][650/6832]	Time 0.064 (0.106)	Data 0.00095 (0.00096)	Tok/s 50761 (59524)	Loss/tok 2.7807 (3.1361)	Learning Rate [7.8125e-05]
3: TRAIN [4][650/6832]	Time 0.064 (0.106)	Data 0.00098 (0.00094)	Tok/s 51918 (59993)	Loss/tok 2.8525 (3.1251)	Learning Rate [7.8125e-05]
0: TRAIN [4][650/6832]	Time 0.064 (0.106)	Data 0.00098 (0.00093)	Tok/s 49901 (58724)	Loss/tok 2.8263 (3.1303)	Learning Rate [7.8125e-05]
1: TRAIN [4][660/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00091)	Tok/s 53664 (59105)	Loss/tok 2.9806 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][660/6832]	Time 0.081 (0.105)	Data 0.00092 (0.00096)	Tok/s 53627 (59465)	Loss/tok 2.9871 (3.1352)	Learning Rate [7.8125e-05]
0: TRAIN [4][660/6832]	Time 0.081 (0.105)	Data 0.00086 (0.00093)	Tok/s 53654 (58642)	Loss/tok 3.0306 (3.1299)	Learning Rate [7.8125e-05]
3: TRAIN [4][660/6832]	Time 0.081 (0.105)	Data 0.00093 (0.00094)	Tok/s 53975 (59934)	Loss/tok 3.0567 (3.1246)	Learning Rate [7.8125e-05]
1: TRAIN [4][670/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00091)	Tok/s 54783 (59064)	Loss/tok 3.0238 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][670/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00096)	Tok/s 54751 (59422)	Loss/tok 3.2204 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][670/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00094)	Tok/s 54765 (59889)	Loss/tok 3.0482 (3.1244)	Learning Rate [7.8125e-05]
0: TRAIN [4][670/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00093)	Tok/s 53987 (58607)	Loss/tok 3.0229 (3.1298)	Learning Rate [7.8125e-05]
2: TRAIN [4][680/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00096)	Tok/s 64280 (59336)	Loss/tok 3.1627 (3.1339)	Learning Rate [7.8125e-05]
1: TRAIN [4][680/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00091)	Tok/s 64022 (58962)	Loss/tok 3.3362 (3.1331)	Learning Rate [7.8125e-05]
3: TRAIN [4][680/6832]	Time 0.121 (0.105)	Data 0.00095 (0.00094)	Tok/s 64287 (59811)	Loss/tok 3.2533 (3.1240)	Learning Rate [7.8125e-05]
0: TRAIN [4][680/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00093)	Tok/s 63180 (58488)	Loss/tok 3.1064 (3.1287)	Learning Rate [7.8125e-05]
1: TRAIN [4][690/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00091)	Tok/s 78905 (59029)	Loss/tok 3.2656 (3.1339)	Learning Rate [7.8125e-05]
2: TRAIN [4][690/6832]	Time 0.133 (0.105)	Data 0.00099 (0.00096)	Tok/s 79545 (59406)	Loss/tok 3.0174 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][690/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00094)	Tok/s 79939 (59880)	Loss/tok 3.0508 (3.1247)	Learning Rate [7.8125e-05]
0: TRAIN [4][690/6832]	Time 0.133 (0.105)	Data 0.00091 (0.00093)	Tok/s 78928 (58556)	Loss/tok 3.0103 (3.1280)	Learning Rate [7.8125e-05]
1: TRAIN [4][700/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00091)	Tok/s 72136 (59123)	Loss/tok 3.1532 (3.1336)	Learning Rate [7.8125e-05]
2: TRAIN [4][700/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00096)	Tok/s 72384 (59499)	Loss/tok 3.1028 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][700/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 72375 (59973)	Loss/tok 3.2144 (3.1247)	Learning Rate [7.8125e-05]
0: TRAIN [4][700/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 71413 (58652)	Loss/tok 3.2753 (3.1289)	Learning Rate [7.8125e-05]
1: TRAIN [4][710/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00091)	Tok/s 53251 (59181)	Loss/tok 3.1718 (3.1330)	Learning Rate [7.8125e-05]
2: TRAIN [4][710/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00096)	Tok/s 53225 (59558)	Loss/tok 3.0733 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][710/6832]	Time 0.101 (0.105)	Data 0.00096 (0.00094)	Tok/s 53237 (60032)	Loss/tok 3.1223 (3.1241)	Learning Rate [7.8125e-05]
0: TRAIN [4][710/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00093)	Tok/s 52983 (58713)	Loss/tok 2.8956 (3.1275)	Learning Rate [7.8125e-05]
2: TRAIN [4][720/6832]	Time 0.091 (0.105)	Data 0.00084 (0.00095)	Tok/s 53433 (59539)	Loss/tok 2.9755 (3.1337)	Learning Rate [7.8125e-05]
1: TRAIN [4][720/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00091)	Tok/s 53395 (59164)	Loss/tok 3.1874 (3.1319)	Learning Rate [7.8125e-05]
3: TRAIN [4][720/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00094)	Tok/s 54636 (60014)	Loss/tok 3.0044 (3.1234)	Learning Rate [7.8125e-05]
0: TRAIN [4][720/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00093)	Tok/s 53411 (58693)	Loss/tok 3.0372 (3.1274)	Learning Rate [7.8125e-05]
2: TRAIN [4][730/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00095)	Tok/s 75712 (59535)	Loss/tok 3.3121 (3.1338)	Learning Rate [7.8125e-05]
1: TRAIN [4][730/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00091)	Tok/s 75694 (59161)	Loss/tok 3.2725 (3.1325)	Learning Rate [7.8125e-05]
0: TRAIN [4][730/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 74795 (58691)	Loss/tok 3.2097 (3.1285)	Learning Rate [7.8125e-05]
3: TRAIN [4][730/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00094)	Tok/s 75960 (60008)	Loss/tok 3.2183 (3.1242)	Learning Rate [7.8125e-05]
2: TRAIN [4][740/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00095)	Tok/s 70810 (59509)	Loss/tok 3.2020 (3.1340)	Learning Rate [7.8125e-05]
1: TRAIN [4][740/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00091)	Tok/s 69980 (59124)	Loss/tok 3.2087 (3.1326)	Learning Rate [7.8125e-05]
3: TRAIN [4][740/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 70815 (59989)	Loss/tok 3.3150 (3.1250)	Learning Rate [7.8125e-05]
0: TRAIN [4][740/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00093)	Tok/s 69840 (58625)	Loss/tok 3.4235 (3.1291)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][750/6832]	Time 0.072 (0.105)	Data 0.00119 (0.00095)	Tok/s 52942 (59493)	Loss/tok 2.9566 (3.1336)	Learning Rate [7.8125e-05]
1: TRAIN [4][750/6832]	Time 0.072 (0.105)	Data 0.00109 (0.00091)	Tok/s 51666 (59103)	Loss/tok 2.9769 (3.1314)	Learning Rate [7.8125e-05]
3: TRAIN [4][750/6832]	Time 0.072 (0.105)	Data 0.00130 (0.00094)	Tok/s 53271 (59977)	Loss/tok 2.9221 (3.1244)	Learning Rate [7.8125e-05]
0: TRAIN [4][750/6832]	Time 0.072 (0.105)	Data 0.00126 (0.00093)	Tok/s 51566 (58606)	Loss/tok 3.0066 (3.1286)	Learning Rate [7.8125e-05]
1: TRAIN [4][760/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00091)	Tok/s 53410 (59147)	Loss/tok 3.1032 (3.1315)	Learning Rate [7.8125e-05]
2: TRAIN [4][760/6832]	Time 0.117 (0.105)	Data 0.00109 (0.00095)	Tok/s 53429 (59535)	Loss/tok 3.2789 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][760/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00094)	Tok/s 53893 (60018)	Loss/tok 3.1248 (3.1246)	Learning Rate [7.8125e-05]
0: TRAIN [4][760/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00093)	Tok/s 53406 (58654)	Loss/tok 3.1728 (3.1286)	Learning Rate [7.8125e-05]
2: TRAIN [4][770/6832]	Time 0.073 (0.105)	Data 0.00090 (0.00095)	Tok/s 52651 (59463)	Loss/tok 3.0344 (3.1336)	Learning Rate [7.8125e-05]
1: TRAIN [4][770/6832]	Time 0.073 (0.105)	Data 0.00105 (0.00091)	Tok/s 52722 (59075)	Loss/tok 3.0037 (3.1307)	Learning Rate [7.8125e-05]
3: TRAIN [4][770/6832]	Time 0.073 (0.105)	Data 0.00091 (0.00094)	Tok/s 52666 (59944)	Loss/tok 2.8718 (3.1238)	Learning Rate [7.8125e-05]
0: TRAIN [4][770/6832]	Time 0.073 (0.105)	Data 0.00100 (0.00093)	Tok/s 51988 (58583)	Loss/tok 3.0048 (3.1279)	Learning Rate [7.8125e-05]
2: TRAIN [4][780/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00095)	Tok/s 55665 (59383)	Loss/tok 3.1828 (3.1338)	Learning Rate [7.8125e-05]
1: TRAIN [4][780/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00091)	Tok/s 55651 (58991)	Loss/tok 3.0542 (3.1306)	Learning Rate [7.8125e-05]
3: TRAIN [4][780/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00094)	Tok/s 55656 (59864)	Loss/tok 3.1583 (3.1233)	Learning Rate [7.8125e-05]
0: TRAIN [4][780/6832]	Time 0.115 (0.105)	Data 0.00096 (0.00093)	Tok/s 55570 (58487)	Loss/tok 3.2901 (3.1280)	Learning Rate [7.8125e-05]
2: TRAIN [4][790/6832]	Time 0.082 (0.105)	Data 0.00096 (0.00095)	Tok/s 51922 (59368)	Loss/tok 3.1234 (3.1337)	Learning Rate [7.8125e-05]
1: TRAIN [4][790/6832]	Time 0.082 (0.105)	Data 0.00092 (0.00091)	Tok/s 51275 (58977)	Loss/tok 3.0522 (3.1306)	Learning Rate [7.8125e-05]
3: TRAIN [4][790/6832]	Time 0.082 (0.105)	Data 0.00100 (0.00094)	Tok/s 52845 (59848)	Loss/tok 2.9852 (3.1236)	Learning Rate [7.8125e-05]
0: TRAIN [4][790/6832]	Time 0.082 (0.105)	Data 0.00097 (0.00093)	Tok/s 51289 (58477)	Loss/tok 2.8692 (3.1273)	Learning Rate [7.8125e-05]
2: TRAIN [4][800/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 83700 (59360)	Loss/tok 3.1465 (3.1326)	Learning Rate [7.8125e-05]
1: TRAIN [4][800/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00091)	Tok/s 83123 (58968)	Loss/tok 3.1541 (3.1297)	Learning Rate [7.8125e-05]
3: TRAIN [4][800/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 84433 (59840)	Loss/tok 2.9963 (3.1224)	Learning Rate [7.8125e-05]
0: TRAIN [4][800/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00093)	Tok/s 82411 (58467)	Loss/tok 3.1918 (3.1261)	Learning Rate [7.8125e-05]
2: TRAIN [4][810/6832]	Time 0.062 (0.105)	Data 0.00090 (0.00095)	Tok/s 51618 (59410)	Loss/tok 2.8066 (3.1318)	Learning Rate [7.8125e-05]
1: TRAIN [4][810/6832]	Time 0.062 (0.105)	Data 0.00093 (0.00091)	Tok/s 51520 (59020)	Loss/tok 2.8896 (3.1294)	Learning Rate [7.8125e-05]
3: TRAIN [4][810/6832]	Time 0.062 (0.105)	Data 0.00092 (0.00094)	Tok/s 53563 (59892)	Loss/tok 2.8077 (3.1219)	Learning Rate [7.8125e-05]
0: TRAIN [4][810/6832]	Time 0.062 (0.105)	Data 0.00099 (0.00093)	Tok/s 51547 (58519)	Loss/tok 2.8542 (3.1263)	Learning Rate [7.8125e-05]
2: TRAIN [4][820/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00095)	Tok/s 50966 (59397)	Loss/tok 2.8483 (3.1326)	Learning Rate [7.8125e-05]
1: TRAIN [4][820/6832]	Time 0.070 (0.105)	Data 0.00089 (0.00091)	Tok/s 51089 (59010)	Loss/tok 2.9423 (3.1299)	Learning Rate [7.8125e-05]
3: TRAIN [4][820/6832]	Time 0.070 (0.105)	Data 0.00094 (0.00094)	Tok/s 51935 (59876)	Loss/tok 2.8828 (3.1222)	Learning Rate [7.8125e-05]
0: TRAIN [4][820/6832]	Time 0.070 (0.105)	Data 0.00101 (0.00093)	Tok/s 51120 (58514)	Loss/tok 2.8272 (3.1273)	Learning Rate [7.8125e-05]
2: TRAIN [4][830/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00095)	Tok/s 72698 (59362)	Loss/tok 3.0868 (3.1315)	Learning Rate [7.8125e-05]
1: TRAIN [4][830/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00091)	Tok/s 72162 (58968)	Loss/tok 3.1579 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][830/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 71744 (58459)	Loss/tok 3.2753 (3.1271)	Learning Rate [7.8125e-05]
3: TRAIN [4][830/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 72691 (59841)	Loss/tok 3.2379 (3.1215)	Learning Rate [7.8125e-05]
2: TRAIN [4][840/6832]	Time 0.113 (0.104)	Data 0.00089 (0.00095)	Tok/s 53473 (59331)	Loss/tok 3.0412 (3.1302)	Learning Rate [7.8125e-05]
3: TRAIN [4][840/6832]	Time 0.113 (0.104)	Data 0.00093 (0.00094)	Tok/s 53463 (59810)	Loss/tok 3.2141 (3.1208)	Learning Rate [7.8125e-05]
0: TRAIN [4][840/6832]	Time 0.113 (0.104)	Data 0.00092 (0.00093)	Tok/s 52311 (58424)	Loss/tok 3.0301 (3.1265)	Learning Rate [7.8125e-05]
1: TRAIN [4][840/6832]	Time 0.113 (0.104)	Data 0.00088 (0.00091)	Tok/s 52439 (58935)	Loss/tok 3.1349 (3.1293)	Learning Rate [7.8125e-05]
2: TRAIN [4][850/6832]	Time 0.121 (0.104)	Data 0.00086 (0.00095)	Tok/s 56733 (59374)	Loss/tok 3.0772 (3.1296)	Learning Rate [7.8125e-05]
1: TRAIN [4][850/6832]	Time 0.121 (0.104)	Data 0.00089 (0.00091)	Tok/s 56060 (58977)	Loss/tok 3.1596 (3.1291)	Learning Rate [7.8125e-05]
3: TRAIN [4][850/6832]	Time 0.121 (0.104)	Data 0.00090 (0.00094)	Tok/s 57137 (59856)	Loss/tok 3.1307 (3.1209)	Learning Rate [7.8125e-05]
0: TRAIN [4][850/6832]	Time 0.121 (0.104)	Data 0.00091 (0.00093)	Tok/s 56066 (58469)	Loss/tok 3.2715 (3.1271)	Learning Rate [7.8125e-05]
2: TRAIN [4][860/6832]	Time 0.071 (0.104)	Data 0.00084 (0.00095)	Tok/s 52323 (59379)	Loss/tok 3.0772 (3.1296)	Learning Rate [7.8125e-05]
1: TRAIN [4][860/6832]	Time 0.071 (0.104)	Data 0.00089 (0.00091)	Tok/s 52337 (58986)	Loss/tok 2.8866 (3.1296)	Learning Rate [7.8125e-05]
3: TRAIN [4][860/6832]	Time 0.071 (0.104)	Data 0.00087 (0.00094)	Tok/s 52308 (59857)	Loss/tok 2.8412 (3.1215)	Learning Rate [7.8125e-05]
0: TRAIN [4][860/6832]	Time 0.071 (0.104)	Data 0.00091 (0.00093)	Tok/s 51538 (58481)	Loss/tok 2.8334 (3.1270)	Learning Rate [7.8125e-05]
2: TRAIN [4][870/6832]	Time 0.061 (0.104)	Data 0.00085 (0.00095)	Tok/s 50968 (59351)	Loss/tok 2.7810 (3.1298)	Learning Rate [7.8125e-05]
1: TRAIN [4][870/6832]	Time 0.061 (0.104)	Data 0.00087 (0.00091)	Tok/s 50405 (58959)	Loss/tok 2.8600 (3.1295)	Learning Rate [7.8125e-05]
3: TRAIN [4][870/6832]	Time 0.061 (0.104)	Data 0.00089 (0.00094)	Tok/s 52559 (59829)	Loss/tok 2.8017 (3.1216)	Learning Rate [7.8125e-05]
0: TRAIN [4][870/6832]	Time 0.061 (0.104)	Data 0.00089 (0.00093)	Tok/s 50420 (58458)	Loss/tok 2.8806 (3.1267)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [4][880/6832]	Time 0.095 (0.104)	Data 0.00098 (0.00091)	Tok/s 51131 (58918)	Loss/tok 2.8945 (3.1284)	Learning Rate [7.8125e-05]
0: TRAIN [4][880/6832]	Time 0.095 (0.104)	Data 0.00102 (0.00093)	Tok/s 51148 (58422)	Loss/tok 2.9742 (3.1262)	Learning Rate [7.8125e-05]
2: TRAIN [4][880/6832]	Time 0.095 (0.104)	Data 0.00095 (0.00095)	Tok/s 51213 (59309)	Loss/tok 2.8914 (3.1293)	Learning Rate [7.8125e-05]
3: TRAIN [4][880/6832]	Time 0.095 (0.104)	Data 0.00092 (0.00094)	Tok/s 52336 (59790)	Loss/tok 2.9736 (3.1214)	Learning Rate [7.8125e-05]
2: TRAIN [4][890/6832]	Time 0.097 (0.104)	Data 0.00088 (0.00094)	Tok/s 51646 (59252)	Loss/tok 3.0709 (3.1295)	Learning Rate [7.8125e-05]
1: TRAIN [4][890/6832]	Time 0.097 (0.104)	Data 0.00090 (0.00091)	Tok/s 51647 (58862)	Loss/tok 3.1317 (3.1281)	Learning Rate [7.8125e-05]
3: TRAIN [4][890/6832]	Time 0.097 (0.104)	Data 0.00095 (0.00094)	Tok/s 51672 (59730)	Loss/tok 3.2048 (3.1217)	Learning Rate [7.8125e-05]
0: TRAIN [4][890/6832]	Time 0.097 (0.104)	Data 0.00095 (0.00093)	Tok/s 51386 (58369)	Loss/tok 2.9911 (3.1268)	Learning Rate [7.8125e-05]
1: TRAIN [4][900/6832]	Time 0.128 (0.105)	Data 0.00097 (0.00091)	Tok/s 63046 (59053)	Loss/tok 3.2583 (3.1279)	Learning Rate [7.8125e-05]
2: TRAIN [4][900/6832]	Time 0.128 (0.105)	Data 0.00101 (0.00094)	Tok/s 62965 (59444)	Loss/tok 3.2721 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][900/6832]	Time 0.128 (0.105)	Data 0.00099 (0.00093)	Tok/s 62934 (58560)	Loss/tok 3.2468 (3.1277)	Learning Rate [7.8125e-05]
3: TRAIN [4][900/6832]	Time 0.128 (0.105)	Data 0.00104 (0.00094)	Tok/s 63000 (59922)	Loss/tok 3.2889 (3.1225)	Learning Rate [7.8125e-05]
2: TRAIN [4][910/6832]	Time 0.094 (0.105)	Data 0.00084 (0.00094)	Tok/s 51920 (59458)	Loss/tok 3.0295 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][910/6832]	Time 0.094 (0.105)	Data 0.00088 (0.00091)	Tok/s 51973 (59067)	Loss/tok 3.1091 (3.1271)	Learning Rate [7.8125e-05]
3: TRAIN [4][910/6832]	Time 0.094 (0.105)	Data 0.00088 (0.00094)	Tok/s 52525 (59938)	Loss/tok 2.9690 (3.1215)	Learning Rate [7.8125e-05]
0: TRAIN [4][910/6832]	Time 0.094 (0.105)	Data 0.00094 (0.00093)	Tok/s 51990 (58577)	Loss/tok 3.1045 (3.1271)	Learning Rate [7.8125e-05]
2: TRAIN [4][920/6832]	Time 0.131 (0.104)	Data 0.00088 (0.00094)	Tok/s 61591 (59459)	Loss/tok 3.2367 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][920/6832]	Time 0.131 (0.104)	Data 0.00086 (0.00091)	Tok/s 61578 (59069)	Loss/tok 3.3131 (3.1264)	Learning Rate [7.8125e-05]
0: TRAIN [4][920/6832]	Time 0.131 (0.104)	Data 0.00087 (0.00093)	Tok/s 61610 (58580)	Loss/tok 3.2176 (3.1275)	Learning Rate [7.8125e-05]
3: TRAIN [4][920/6832]	Time 0.131 (0.104)	Data 0.00090 (0.00094)	Tok/s 61668 (59940)	Loss/tok 3.3070 (3.1215)	Learning Rate [7.8125e-05]
2: TRAIN [4][930/6832]	Time 0.088 (0.104)	Data 0.00087 (0.00094)	Tok/s 53998 (59429)	Loss/tok 2.9837 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][930/6832]	Time 0.088 (0.104)	Data 0.00087 (0.00091)	Tok/s 54001 (59038)	Loss/tok 3.0008 (3.1264)	Learning Rate [7.8125e-05]
3: TRAIN [4][930/6832]	Time 0.088 (0.104)	Data 0.00089 (0.00094)	Tok/s 54009 (59912)	Loss/tok 2.9931 (3.1219)	Learning Rate [7.8125e-05]
0: TRAIN [4][930/6832]	Time 0.088 (0.104)	Data 0.00091 (0.00093)	Tok/s 54002 (58550)	Loss/tok 3.0473 (3.1279)	Learning Rate [7.8125e-05]
2: TRAIN [4][940/6832]	Time 0.062 (0.104)	Data 0.00091 (0.00094)	Tok/s 47744 (59399)	Loss/tok 2.6883 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][940/6832]	Time 0.062 (0.104)	Data 0.00088 (0.00091)	Tok/s 47675 (59010)	Loss/tok 2.7326 (3.1266)	Learning Rate [7.8125e-05]
3: TRAIN [4][940/6832]	Time 0.062 (0.104)	Data 0.00093 (0.00094)	Tok/s 49791 (59882)	Loss/tok 2.8089 (3.1222)	Learning Rate [7.8125e-05]
0: TRAIN [4][940/6832]	Time 0.062 (0.104)	Data 0.00089 (0.00093)	Tok/s 47705 (58525)	Loss/tok 2.6116 (3.1276)	Learning Rate [7.8125e-05]
2: TRAIN [4][950/6832]	Time 0.126 (0.104)	Data 0.00085 (0.00094)	Tok/s 63017 (59381)	Loss/tok 3.2923 (3.1285)	Learning Rate [7.8125e-05]
1: TRAIN [4][950/6832]	Time 0.126 (0.104)	Data 0.00086 (0.00091)	Tok/s 62710 (58993)	Loss/tok 3.3045 (3.1264)	Learning Rate [7.8125e-05]
3: TRAIN [4][950/6832]	Time 0.126 (0.104)	Data 0.00088 (0.00094)	Tok/s 63022 (59869)	Loss/tok 3.1216 (3.1215)	Learning Rate [7.8125e-05]
0: TRAIN [4][950/6832]	Time 0.126 (0.104)	Data 0.00092 (0.00093)	Tok/s 62018 (58509)	Loss/tok 3.3520 (3.1271)	Learning Rate [7.8125e-05]
2: TRAIN [4][960/6832]	Time 0.116 (0.104)	Data 0.00097 (0.00094)	Tok/s 55374 (59332)	Loss/tok 3.1580 (3.1285)	Learning Rate [7.8125e-05]
1: TRAIN [4][960/6832]	Time 0.116 (0.104)	Data 0.00092 (0.00091)	Tok/s 55295 (58946)	Loss/tok 3.1028 (3.1264)	Learning Rate [7.8125e-05]
3: TRAIN [4][960/6832]	Time 0.116 (0.104)	Data 0.00094 (0.00094)	Tok/s 56468 (59821)	Loss/tok 3.1341 (3.1215)	Learning Rate [7.8125e-05]
0: TRAIN [4][960/6832]	Time 0.116 (0.104)	Data 0.00095 (0.00093)	Tok/s 55329 (58466)	Loss/tok 3.0846 (3.1272)	Learning Rate [7.8125e-05]
2: TRAIN [4][970/6832]	Time 0.079 (0.104)	Data 0.00089 (0.00094)	Tok/s 53240 (59341)	Loss/tok 2.8535 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][970/6832]	Time 0.079 (0.104)	Data 0.00088 (0.00091)	Tok/s 53212 (58956)	Loss/tok 2.9621 (3.1258)	Learning Rate [7.8125e-05]
3: TRAIN [4][970/6832]	Time 0.079 (0.104)	Data 0.00089 (0.00094)	Tok/s 53282 (59830)	Loss/tok 2.7993 (3.1224)	Learning Rate [7.8125e-05]
0: TRAIN [4][970/6832]	Time 0.079 (0.104)	Data 0.00091 (0.00093)	Tok/s 52347 (58477)	Loss/tok 2.9949 (3.1275)	Learning Rate [7.8125e-05]
2: TRAIN [4][980/6832]	Time 0.068 (0.104)	Data 0.00098 (0.00094)	Tok/s 50512 (59375)	Loss/tok 2.8257 (3.1281)	Learning Rate [7.8125e-05]
1: TRAIN [4][980/6832]	Time 0.069 (0.104)	Data 0.00094 (0.00091)	Tok/s 50402 (58990)	Loss/tok 2.8817 (3.1253)	Learning Rate [7.8125e-05]
3: TRAIN [4][980/6832]	Time 0.068 (0.104)	Data 0.00102 (0.00094)	Tok/s 51759 (59866)	Loss/tok 2.9101 (3.1218)	Learning Rate [7.8125e-05]
0: TRAIN [4][980/6832]	Time 0.069 (0.104)	Data 0.00097 (0.00093)	Tok/s 50430 (58515)	Loss/tok 2.8982 (3.1263)	Learning Rate [7.8125e-05]
2: TRAIN [4][990/6832]	Time 0.056 (0.104)	Data 0.00096 (0.00094)	Tok/s 47746 (59337)	Loss/tok 2.6289 (3.1282)	Learning Rate [7.8125e-05]
1: TRAIN [4][990/6832]	Time 0.056 (0.104)	Data 0.00088 (0.00091)	Tok/s 46831 (58952)	Loss/tok 2.6228 (3.1252)	Learning Rate [7.8125e-05]
3: TRAIN [4][990/6832]	Time 0.056 (0.104)	Data 0.00098 (0.00094)	Tok/s 47794 (59825)	Loss/tok 2.5761 (3.1218)	Learning Rate [7.8125e-05]
0: TRAIN [4][990/6832]	Time 0.056 (0.104)	Data 0.00092 (0.00093)	Tok/s 45442 (58479)	Loss/tok 2.5284 (3.1263)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][1000/6832]	Time 0.080 (0.104)	Data 0.00108 (0.00094)	Tok/s 53761 (59328)	Loss/tok 3.1044 (3.1279)	Learning Rate [7.8125e-05]
1: TRAIN [4][1000/6832]	Time 0.080 (0.104)	Data 0.00087 (0.00091)	Tok/s 52867 (58943)	Loss/tok 2.9721 (3.1244)	Learning Rate [7.8125e-05]
3: TRAIN [4][1000/6832]	Time 0.080 (0.104)	Data 0.00099 (0.00094)	Tok/s 54594 (59819)	Loss/tok 2.8143 (3.1215)	Learning Rate [7.8125e-05]
0: TRAIN [4][1000/6832]	Time 0.080 (0.104)	Data 0.00091 (0.00093)	Tok/s 52835 (58472)	Loss/tok 2.8917 (3.1265)	Learning Rate [7.8125e-05]
2: TRAIN [4][1010/6832]	Time 0.106 (0.104)	Data 0.00093 (0.00094)	Tok/s 53273 (59295)	Loss/tok 3.1426 (3.1270)	Learning Rate [7.8125e-05]
1: TRAIN [4][1010/6832]	Time 0.106 (0.104)	Data 0.00105 (0.00092)	Tok/s 53269 (58903)	Loss/tok 3.1162 (3.1239)	Learning Rate [7.8125e-05]
3: TRAIN [4][1010/6832]	Time 0.106 (0.104)	Data 0.00099 (0.00094)	Tok/s 53292 (59788)	Loss/tok 3.3053 (3.1210)	Learning Rate [7.8125e-05]
0: TRAIN [4][1010/6832]	Time 0.106 (0.104)	Data 0.00107 (0.00093)	Tok/s 52161 (58421)	Loss/tok 3.1751 (3.1264)	Learning Rate [7.8125e-05]
1: TRAIN [4][1020/6832]	Time 0.131 (0.104)	Data 0.00088 (0.00091)	Tok/s 62473 (58903)	Loss/tok 3.2878 (3.1243)	Learning Rate [7.8125e-05]
2: TRAIN [4][1020/6832]	Time 0.131 (0.104)	Data 0.00089 (0.00094)	Tok/s 62456 (59294)	Loss/tok 3.1638 (3.1272)	Learning Rate [7.8125e-05]
0: TRAIN [4][1020/6832]	Time 0.131 (0.104)	Data 0.00091 (0.00093)	Tok/s 62484 (58422)	Loss/tok 3.0889 (3.1261)	Learning Rate [7.8125e-05]
3: TRAIN [4][1020/6832]	Time 0.131 (0.104)	Data 0.00086 (0.00094)	Tok/s 62652 (59785)	Loss/tok 3.3168 (3.1211)	Learning Rate [7.8125e-05]
2: TRAIN [4][1030/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00094)	Tok/s 78702 (59409)	Loss/tok 3.3426 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][1030/6832]	Time 0.132 (0.104)	Data 0.00088 (0.00091)	Tok/s 77706 (59017)	Loss/tok 3.1579 (3.1250)	Learning Rate [7.8125e-05]
0: TRAIN [4][1030/6832]	Time 0.132 (0.104)	Data 0.00090 (0.00093)	Tok/s 77732 (58538)	Loss/tok 3.1242 (3.1262)	Learning Rate [7.8125e-05]
3: TRAIN [4][1030/6832]	Time 0.132 (0.104)	Data 0.00090 (0.00094)	Tok/s 78711 (59898)	Loss/tok 3.0839 (3.1214)	Learning Rate [7.8125e-05]
2: TRAIN [4][1040/6832]	Time 0.119 (0.104)	Data 0.00088 (0.00094)	Tok/s 53848 (59444)	Loss/tok 3.2356 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][1040/6832]	Time 0.119 (0.104)	Data 0.00087 (0.00091)	Tok/s 53843 (59054)	Loss/tok 3.1342 (3.1256)	Learning Rate [7.8125e-05]
0: TRAIN [4][1040/6832]	Time 0.119 (0.104)	Data 0.00092 (0.00093)	Tok/s 53865 (58578)	Loss/tok 3.2300 (3.1268)	Learning Rate [7.8125e-05]
3: TRAIN [4][1040/6832]	Time 0.119 (0.104)	Data 0.00093 (0.00094)	Tok/s 53846 (59933)	Loss/tok 3.2774 (3.1218)	Learning Rate [7.8125e-05]
2: TRAIN [4][1050/6832]	Time 0.094 (0.104)	Data 0.00090 (0.00094)	Tok/s 53129 (59443)	Loss/tok 3.1667 (3.1285)	Learning Rate [7.8125e-05]
1: TRAIN [4][1050/6832]	Time 0.094 (0.104)	Data 0.00088 (0.00091)	Tok/s 53106 (59054)	Loss/tok 3.0857 (3.1258)	Learning Rate [7.8125e-05]
3: TRAIN [4][1050/6832]	Time 0.094 (0.104)	Data 0.00089 (0.00094)	Tok/s 53146 (59930)	Loss/tok 3.1125 (3.1223)	Learning Rate [7.8125e-05]
0: TRAIN [4][1050/6832]	Time 0.094 (0.104)	Data 0.00089 (0.00093)	Tok/s 53021 (58579)	Loss/tok 3.0159 (3.1267)	Learning Rate [7.8125e-05]
2: TRAIN [4][1060/6832]	Time 0.069 (0.104)	Data 0.00090 (0.00094)	Tok/s 53607 (59414)	Loss/tok 2.9451 (3.1289)	Learning Rate [7.8125e-05]
1: TRAIN [4][1060/6832]	Time 0.069 (0.104)	Data 0.00087 (0.00091)	Tok/s 53561 (59028)	Loss/tok 2.9578 (3.1262)	Learning Rate [7.8125e-05]
0: TRAIN [4][1060/6832]	Time 0.069 (0.104)	Data 0.00088 (0.00093)	Tok/s 52395 (58555)	Loss/tok 2.8729 (3.1270)	Learning Rate [7.8125e-05]
3: TRAIN [4][1060/6832]	Time 0.069 (0.104)	Data 0.00088 (0.00094)	Tok/s 53683 (59898)	Loss/tok 2.7588 (3.1225)	Learning Rate [7.8125e-05]
2: TRAIN [4][1070/6832]	Time 0.062 (0.104)	Data 0.00088 (0.00094)	Tok/s 49399 (59372)	Loss/tok 2.7978 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][1070/6832]	Time 0.063 (0.104)	Data 0.00086 (0.00091)	Tok/s 49130 (58988)	Loss/tok 2.6592 (3.1262)	Learning Rate [7.8125e-05]
3: TRAIN [4][1070/6832]	Time 0.062 (0.104)	Data 0.00091 (0.00094)	Tok/s 51296 (59855)	Loss/tok 2.9402 (3.1224)	Learning Rate [7.8125e-05]
0: TRAIN [4][1070/6832]	Time 0.063 (0.104)	Data 0.00091 (0.00093)	Tok/s 49133 (58518)	Loss/tok 2.7902 (3.1269)	Learning Rate [7.8125e-05]
2: TRAIN [4][1080/6832]	Time 0.126 (0.104)	Data 0.00088 (0.00094)	Tok/s 61811 (59390)	Loss/tok 3.2289 (3.1298)	Learning Rate [7.8125e-05]
1: TRAIN [4][1080/6832]	Time 0.126 (0.104)	Data 0.00087 (0.00091)	Tok/s 61275 (59007)	Loss/tok 3.2244 (3.1265)	Learning Rate [7.8125e-05]
0: TRAIN [4][1080/6832]	Time 0.126 (0.104)	Data 0.00090 (0.00093)	Tok/s 60739 (58537)	Loss/tok 3.3342 (3.1274)	Learning Rate [7.8125e-05]
3: TRAIN [4][1080/6832]	Time 0.126 (0.104)	Data 0.00092 (0.00094)	Tok/s 61814 (59872)	Loss/tok 3.4170 (3.1229)	Learning Rate [7.8125e-05]
2: TRAIN [4][1090/6832]	Time 0.121 (0.104)	Data 0.00086 (0.00094)	Tok/s 54933 (59370)	Loss/tok 3.1010 (3.1304)	Learning Rate [7.8125e-05]
1: TRAIN [4][1090/6832]	Time 0.121 (0.104)	Data 0.00094 (0.00091)	Tok/s 54951 (58988)	Loss/tok 3.3591 (3.1269)	Learning Rate [7.8125e-05]
0: TRAIN [4][1090/6832]	Time 0.121 (0.104)	Data 0.00092 (0.00093)	Tok/s 54985 (58521)	Loss/tok 3.1919 (3.1275)	Learning Rate [7.8125e-05]
3: TRAIN [4][1090/6832]	Time 0.121 (0.104)	Data 0.00087 (0.00094)	Tok/s 54942 (59851)	Loss/tok 3.2369 (3.1234)	Learning Rate [7.8125e-05]
2: TRAIN [4][1100/6832]	Time 0.101 (0.104)	Data 0.00092 (0.00094)	Tok/s 54324 (59336)	Loss/tok 3.0324 (3.1300)	Learning Rate [7.8125e-05]
1: TRAIN [4][1100/6832]	Time 0.101 (0.104)	Data 0.00093 (0.00091)	Tok/s 53353 (58953)	Loss/tok 3.1718 (3.1268)	Learning Rate [7.8125e-05]
0: TRAIN [4][1100/6832]	Time 0.101 (0.104)	Data 0.00088 (0.00093)	Tok/s 53371 (58485)	Loss/tok 3.0008 (3.1274)	Learning Rate [7.8125e-05]
3: TRAIN [4][1100/6832]	Time 0.101 (0.104)	Data 0.00089 (0.00094)	Tok/s 54669 (59814)	Loss/tok 3.0260 (3.1235)	Learning Rate [7.8125e-05]
2: TRAIN [4][1110/6832]	Time 0.094 (0.104)	Data 0.00087 (0.00094)	Tok/s 52913 (59300)	Loss/tok 3.0463 (3.1300)	Learning Rate [7.8125e-05]
1: TRAIN [4][1110/6832]	Time 0.094 (0.104)	Data 0.00088 (0.00091)	Tok/s 52945 (58919)	Loss/tok 2.9217 (3.1269)	Learning Rate [7.8125e-05]
0: TRAIN [4][1110/6832]	Time 0.094 (0.104)	Data 0.00090 (0.00093)	Tok/s 52968 (58452)	Loss/tok 3.2087 (3.1274)	Learning Rate [7.8125e-05]
3: TRAIN [4][1110/6832]	Time 0.094 (0.104)	Data 0.00094 (0.00094)	Tok/s 52928 (59775)	Loss/tok 2.9814 (3.1232)	Learning Rate [7.8125e-05]
1: TRAIN [4][1120/6832]	Time 0.124 (0.104)	Data 0.00092 (0.00091)	Tok/s 62102 (58900)	Loss/tok 3.2798 (3.1267)	Learning Rate [7.8125e-05]
2: TRAIN [4][1120/6832]	Time 0.124 (0.104)	Data 0.00085 (0.00094)	Tok/s 62036 (59280)	Loss/tok 3.1587 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][1120/6832]	Time 0.124 (0.104)	Data 0.00088 (0.00093)	Tok/s 61618 (58435)	Loss/tok 3.4144 (3.1277)	Learning Rate [7.8125e-05]
3: TRAIN [4][1120/6832]	Time 0.124 (0.104)	Data 0.00090 (0.00094)	Tok/s 62048 (59753)	Loss/tok 3.1775 (3.1234)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][1130/6832]	Time 0.132 (0.104)	Data 0.00094 (0.00094)	Tok/s 60335 (59300)	Loss/tok 3.2414 (3.1300)	Learning Rate [7.8125e-05]
1: TRAIN [4][1130/6832]	Time 0.132 (0.104)	Data 0.00096 (0.00091)	Tok/s 60324 (58921)	Loss/tok 3.3330 (3.1267)	Learning Rate [7.8125e-05]
0: TRAIN [4][1130/6832]	Time 0.131 (0.104)	Data 0.00096 (0.00093)	Tok/s 60365 (58458)	Loss/tok 3.2908 (3.1279)	Learning Rate [7.8125e-05]
3: TRAIN [4][1130/6832]	Time 0.131 (0.104)	Data 0.00101 (0.00094)	Tok/s 60570 (59775)	Loss/tok 3.3232 (3.1238)	Learning Rate [7.8125e-05]
1: TRAIN [4][1140/6832]	Time 0.128 (0.104)	Data 0.00095 (0.00091)	Tok/s 64827 (58913)	Loss/tok 3.2260 (3.1265)	Learning Rate [7.8125e-05]
0: TRAIN [4][1140/6832]	Time 0.128 (0.104)	Data 0.00101 (0.00093)	Tok/s 64575 (58453)	Loss/tok 3.2583 (3.1278)	Learning Rate [7.8125e-05]
2: TRAIN [4][1140/6832]	Time 0.129 (0.104)	Data 0.00086 (0.00094)	Tok/s 64732 (59290)	Loss/tok 3.3264 (3.1300)	Learning Rate [7.8125e-05]
3: TRAIN [4][1140/6832]	Time 0.129 (0.104)	Data 0.00088 (0.00094)	Tok/s 64713 (59764)	Loss/tok 3.3000 (3.1238)	Learning Rate [7.8125e-05]
1: TRAIN [4][1150/6832]	Time 0.128 (0.104)	Data 0.00088 (0.00091)	Tok/s 67225 (58967)	Loss/tok 3.3602 (3.1269)	Learning Rate [7.8125e-05]
2: TRAIN [4][1150/6832]	Time 0.128 (0.104)	Data 0.00091 (0.00094)	Tok/s 67207 (59344)	Loss/tok 3.2784 (3.1308)	Learning Rate [7.8125e-05]
0: TRAIN [4][1150/6832]	Time 0.128 (0.104)	Data 0.00095 (0.00093)	Tok/s 66707 (58509)	Loss/tok 3.2272 (3.1285)	Learning Rate [7.8125e-05]
3: TRAIN [4][1150/6832]	Time 0.128 (0.104)	Data 0.00093 (0.00094)	Tok/s 67223 (59818)	Loss/tok 3.2579 (3.1243)	Learning Rate [7.8125e-05]
1: TRAIN [4][1160/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00091)	Tok/s 59841 (58984)	Loss/tok 3.0778 (3.1275)	Learning Rate [7.8125e-05]
0: TRAIN [4][1160/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00093)	Tok/s 59862 (58529)	Loss/tok 3.1650 (3.1290)	Learning Rate [7.8125e-05]
2: TRAIN [4][1160/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00094)	Tok/s 60678 (59359)	Loss/tok 3.1762 (3.1314)	Learning Rate [7.8125e-05]
3: TRAIN [4][1160/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00094)	Tok/s 60877 (59833)	Loss/tok 3.1315 (3.1245)	Learning Rate [7.8125e-05]
2: TRAIN [4][1170/6832]	Time 0.065 (0.105)	Data 0.00086 (0.00094)	Tok/s 51683 (59327)	Loss/tok 2.9220 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][1170/6832]	Time 0.065 (0.105)	Data 0.00089 (0.00091)	Tok/s 50986 (58950)	Loss/tok 2.7445 (3.1273)	Learning Rate [7.8125e-05]
3: TRAIN [4][1170/6832]	Time 0.065 (0.105)	Data 0.00092 (0.00094)	Tok/s 52980 (59801)	Loss/tok 2.8543 (3.1244)	Learning Rate [7.8125e-05]
0: TRAIN [4][1170/6832]	Time 0.065 (0.104)	Data 0.00091 (0.00093)	Tok/s 51021 (58497)	Loss/tok 2.9044 (3.1286)	Learning Rate [7.8125e-05]
1: TRAIN [4][1180/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00091)	Tok/s 60728 (58938)	Loss/tok 3.3182 (3.1276)	Learning Rate [7.8125e-05]
2: TRAIN [4][1180/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00094)	Tok/s 60984 (59318)	Loss/tok 3.2951 (3.1311)	Learning Rate [7.8125e-05]
0: TRAIN [4][1180/6832]	Time 0.126 (0.104)	Data 0.00092 (0.00093)	Tok/s 59929 (58476)	Loss/tok 3.3216 (3.1291)	Learning Rate [7.8125e-05]
3: TRAIN [4][1180/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00094)	Tok/s 60981 (59795)	Loss/tok 3.3503 (3.1249)	Learning Rate [7.8125e-05]
2: TRAIN [4][1190/6832]	Time 0.074 (0.105)	Data 0.00093 (0.00094)	Tok/s 53729 (59323)	Loss/tok 3.0002 (3.1315)	Learning Rate [7.8125e-05]
1: TRAIN [4][1190/6832]	Time 0.074 (0.105)	Data 0.00088 (0.00091)	Tok/s 53752 (58944)	Loss/tok 2.9825 (3.1282)	Learning Rate [7.8125e-05]
3: TRAIN [4][1190/6832]	Time 0.074 (0.105)	Data 0.00089 (0.00094)	Tok/s 53717 (59800)	Loss/tok 2.9682 (3.1254)	Learning Rate [7.8125e-05]
0: TRAIN [4][1190/6832]	Time 0.074 (0.105)	Data 0.00099 (0.00093)	Tok/s 53767 (58485)	Loss/tok 3.0837 (3.1297)	Learning Rate [7.8125e-05]
2: TRAIN [4][1200/6832]	Time 0.096 (0.104)	Data 0.00086 (0.00094)	Tok/s 52181 (59326)	Loss/tok 2.9790 (3.1310)	Learning Rate [7.8125e-05]
3: TRAIN [4][1200/6832]	Time 0.096 (0.104)	Data 0.00084 (0.00094)	Tok/s 52206 (59805)	Loss/tok 2.9519 (3.1248)	Learning Rate [7.8125e-05]
1: TRAIN [4][1200/6832]	Time 0.096 (0.104)	Data 0.00086 (0.00091)	Tok/s 52135 (58948)	Loss/tok 3.0472 (3.1280)	Learning Rate [7.8125e-05]
0: TRAIN [4][1200/6832]	Time 0.096 (0.104)	Data 0.00090 (0.00093)	Tok/s 52152 (58488)	Loss/tok 2.9724 (3.1295)	Learning Rate [7.8125e-05]
2: TRAIN [4][1210/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 77674 (59362)	Loss/tok 3.1515 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][1210/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00091)	Tok/s 77458 (58984)	Loss/tok 3.3147 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][1210/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 77335 (58524)	Loss/tok 3.2281 (3.1299)	Learning Rate [7.8125e-05]
3: TRAIN [4][1210/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00094)	Tok/s 78502 (59844)	Loss/tok 3.2038 (3.1251)	Learning Rate [7.8125e-05]
1: TRAIN [4][1220/6832]	Time 0.113 (0.105)	Data 0.00093 (0.00091)	Tok/s 56887 (59033)	Loss/tok 3.0187 (3.1280)	Learning Rate [7.8125e-05]
2: TRAIN [4][1220/6832]	Time 0.113 (0.105)	Data 0.00090 (0.00094)	Tok/s 57748 (59410)	Loss/tok 3.2088 (3.1311)	Learning Rate [7.8125e-05]
3: TRAIN [4][1220/6832]	Time 0.113 (0.105)	Data 0.00094 (0.00094)	Tok/s 57832 (59892)	Loss/tok 3.2584 (3.1252)	Learning Rate [7.8125e-05]
0: TRAIN [4][1220/6832]	Time 0.113 (0.105)	Data 0.00096 (0.00093)	Tok/s 56687 (58573)	Loss/tok 3.3946 (3.1303)	Learning Rate [7.8125e-05]
2: TRAIN [4][1230/6832]	Time 0.055 (0.105)	Data 0.00087 (0.00094)	Tok/s 48963 (59386)	Loss/tok 2.5657 (3.1307)	Learning Rate [7.8125e-05]
1: TRAIN [4][1230/6832]	Time 0.055 (0.105)	Data 0.00087 (0.00091)	Tok/s 47797 (59008)	Loss/tok 2.5406 (3.1276)	Learning Rate [7.8125e-05]
3: TRAIN [4][1230/6832]	Time 0.055 (0.105)	Data 0.00086 (0.00094)	Tok/s 48953 (59866)	Loss/tok 2.6203 (3.1252)	Learning Rate [7.8125e-05]
0: TRAIN [4][1230/6832]	Time 0.055 (0.105)	Data 0.00091 (0.00093)	Tok/s 46738 (58548)	Loss/tok 2.7319 (3.1306)	Learning Rate [7.8125e-05]
2: TRAIN [4][1240/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00094)	Tok/s 53338 (59426)	Loss/tok 3.1853 (3.1316)	Learning Rate [7.8125e-05]
3: TRAIN [4][1240/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00094)	Tok/s 53343 (59904)	Loss/tok 3.1183 (3.1258)	Learning Rate [7.8125e-05]
1: TRAIN [4][1240/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00091)	Tok/s 53251 (59049)	Loss/tok 3.0365 (3.1280)	Learning Rate [7.8125e-05]
0: TRAIN [4][1240/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00094)	Tok/s 53259 (58590)	Loss/tok 2.9949 (3.1315)	Learning Rate [7.8125e-05]
1: TRAIN [4][1250/6832]	Time 0.093 (0.105)	Data 0.00092 (0.00091)	Tok/s 52267 (59068)	Loss/tok 3.0727 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [4][1250/6832]	Time 0.093 (0.105)	Data 0.00105 (0.00094)	Tok/s 52286 (59445)	Loss/tok 3.0831 (3.1316)	Learning Rate [7.8125e-05]
0: TRAIN [4][1250/6832]	Time 0.093 (0.105)	Data 0.00097 (0.00094)	Tok/s 52044 (58609)	Loss/tok 2.9537 (3.1317)	Learning Rate [7.8125e-05]
3: TRAIN [4][1250/6832]	Time 0.093 (0.105)	Data 0.00104 (0.00094)	Tok/s 52299 (59923)	Loss/tok 2.9152 (3.1258)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][1260/6832]	Time 0.066 (0.105)	Data 0.00085 (0.00094)	Tok/s 50467 (59449)	Loss/tok 2.7685 (3.1321)	Learning Rate [7.8125e-05]
3: TRAIN [4][1260/6832]	Time 0.066 (0.105)	Data 0.00083 (0.00094)	Tok/s 51464 (59926)	Loss/tok 2.5895 (3.1257)	Learning Rate [7.8125e-05]
1: TRAIN [4][1260/6832]	Time 0.066 (0.105)	Data 0.00086 (0.00091)	Tok/s 50407 (59073)	Loss/tok 2.7414 (3.1289)	Learning Rate [7.8125e-05]
0: TRAIN [4][1260/6832]	Time 0.066 (0.105)	Data 0.00094 (0.00094)	Tok/s 50467 (58617)	Loss/tok 2.7682 (3.1319)	Learning Rate [7.8125e-05]
1: TRAIN [4][1270/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00091)	Tok/s 63606 (59085)	Loss/tok 3.2783 (3.1292)	Learning Rate [7.8125e-05]
2: TRAIN [4][1270/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00094)	Tok/s 63580 (59466)	Loss/tok 3.2524 (3.1322)	Learning Rate [7.8125e-05]
0: TRAIN [4][1270/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 63604 (58622)	Loss/tok 3.2215 (3.1322)	Learning Rate [7.8125e-05]
3: TRAIN [4][1270/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00094)	Tok/s 63561 (59945)	Loss/tok 3.2193 (3.1258)	Learning Rate [7.8125e-05]
2: TRAIN [4][1280/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00094)	Tok/s 51942 (59471)	Loss/tok 3.1183 (3.1319)	Learning Rate [7.8125e-05]
1: TRAIN [4][1280/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00091)	Tok/s 51279 (59090)	Loss/tok 3.1520 (3.1294)	Learning Rate [7.8125e-05]
3: TRAIN [4][1280/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00094)	Tok/s 51934 (59949)	Loss/tok 3.1329 (3.1258)	Learning Rate [7.8125e-05]
0: TRAIN [4][1280/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00094)	Tok/s 50836 (58627)	Loss/tok 3.1055 (3.1321)	Learning Rate [7.8125e-05]
2: TRAIN [4][1290/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00094)	Tok/s 58832 (59487)	Loss/tok 3.2143 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][1290/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00091)	Tok/s 58855 (59109)	Loss/tok 3.2823 (3.1303)	Learning Rate [7.8125e-05]
3: TRAIN [4][1290/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 59760 (59966)	Loss/tok 3.2000 (3.1261)	Learning Rate [7.8125e-05]
0: TRAIN [4][1290/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00094)	Tok/s 58849 (58649)	Loss/tok 3.2838 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][1300/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00094)	Tok/s 66432 (59534)	Loss/tok 3.1415 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][1300/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00091)	Tok/s 66451 (59156)	Loss/tok 3.2355 (3.1309)	Learning Rate [7.8125e-05]
3: TRAIN [4][1300/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 66447 (60013)	Loss/tok 3.3452 (3.1264)	Learning Rate [7.8125e-05]
0: TRAIN [4][1300/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 65579 (58696)	Loss/tok 3.2879 (3.1333)	Learning Rate [7.8125e-05]
2: TRAIN [4][1310/6832]	Time 0.119 (0.105)	Data 0.00103 (0.00094)	Tok/s 61066 (59524)	Loss/tok 3.3405 (3.1326)	Learning Rate [7.8125e-05]
1: TRAIN [4][1310/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00091)	Tok/s 61044 (59148)	Loss/tok 3.3167 (3.1312)	Learning Rate [7.8125e-05]
3: TRAIN [4][1310/6832]	Time 0.120 (0.105)	Data 0.00096 (0.00094)	Tok/s 61030 (60002)	Loss/tok 3.1863 (3.1262)	Learning Rate [7.8125e-05]
0: TRAIN [4][1310/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00094)	Tok/s 60027 (58688)	Loss/tok 3.3025 (3.1335)	Learning Rate [7.8125e-05]
1: TRAIN [4][1320/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00091)	Tok/s 80798 (59145)	Loss/tok 3.0134 (3.1309)	Learning Rate [7.8125e-05]
2: TRAIN [4][1320/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 81121 (59521)	Loss/tok 3.2563 (3.1330)	Learning Rate [7.8125e-05]
0: TRAIN [4][1320/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00093)	Tok/s 80519 (58685)	Loss/tok 3.1521 (3.1333)	Learning Rate [7.8125e-05]
3: TRAIN [4][1320/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 81792 (59998)	Loss/tok 3.2299 (3.1264)	Learning Rate [7.8125e-05]
2: TRAIN [4][1330/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00094)	Tok/s 52572 (59517)	Loss/tok 3.1526 (3.1333)	Learning Rate [7.8125e-05]
3: TRAIN [4][1330/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00094)	Tok/s 52553 (59994)	Loss/tok 3.0043 (3.1272)	Learning Rate [7.8125e-05]
1: TRAIN [4][1330/6832]	Time 0.095 (0.105)	Data 0.00086 (0.00091)	Tok/s 52544 (59142)	Loss/tok 3.2069 (3.1313)	Learning Rate [7.8125e-05]
0: TRAIN [4][1330/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00093)	Tok/s 52472 (58682)	Loss/tok 3.1269 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][1340/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00093)	Tok/s 57771 (58710)	Loss/tok 3.3811 (3.1347)	Learning Rate [7.8125e-05]
3: TRAIN [4][1340/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00094)	Tok/s 58910 (60018)	Loss/tok 3.1264 (3.1274)	Learning Rate [7.8125e-05]
1: TRAIN [4][1340/6832]	Time 0.115 (0.105)	Data 0.00113 (0.00091)	Tok/s 58037 (59167)	Loss/tok 3.0436 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][1340/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00094)	Tok/s 58885 (59542)	Loss/tok 3.2268 (3.1336)	Learning Rate [7.8125e-05]
1: TRAIN [4][1350/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00091)	Tok/s 59453 (59147)	Loss/tok 3.2280 (3.1317)	Learning Rate [7.8125e-05]
2: TRAIN [4][1350/6832]	Time 0.121 (0.105)	Data 0.00094 (0.00094)	Tok/s 59450 (59521)	Loss/tok 3.2305 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][1350/6832]	Time 0.121 (0.105)	Data 0.00096 (0.00093)	Tok/s 59148 (58693)	Loss/tok 3.1577 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][1350/6832]	Time 0.121 (0.105)	Data 0.00097 (0.00094)	Tok/s 59441 (59996)	Loss/tok 3.2151 (3.1278)	Learning Rate [7.8125e-05]
1: TRAIN [4][1360/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00091)	Tok/s 60015 (59150)	Loss/tok 3.1292 (3.1318)	Learning Rate [7.8125e-05]
0: TRAIN [4][1360/6832]	Time 0.124 (0.105)	Data 0.00094 (0.00093)	Tok/s 60065 (58688)	Loss/tok 3.2073 (3.1346)	Learning Rate [7.8125e-05]
3: TRAIN [4][1360/6832]	Time 0.124 (0.105)	Data 0.00086 (0.00094)	Tok/s 60740 (60003)	Loss/tok 3.3941 (3.1275)	Learning Rate [7.8125e-05]
2: TRAIN [4][1360/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00094)	Tok/s 59718 (59527)	Loss/tok 3.2936 (3.1332)	Learning Rate [7.8125e-05]
1: TRAIN [4][1370/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00091)	Tok/s 61287 (59176)	Loss/tok 3.2622 (3.1322)	Learning Rate [7.8125e-05]
0: TRAIN [4][1370/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00093)	Tok/s 60829 (58714)	Loss/tok 3.0746 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][1370/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00094)	Tok/s 61805 (59553)	Loss/tok 3.1921 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][1370/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00094)	Tok/s 61789 (60028)	Loss/tok 3.3331 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][1380/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00091)	Tok/s 69742 (59173)	Loss/tok 3.1231 (3.1314)	Learning Rate [7.8125e-05]
2: TRAIN [4][1380/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00094)	Tok/s 69755 (59550)	Loss/tok 3.3233 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][1380/6832]	Time 0.128 (0.105)	Data 0.00103 (0.00093)	Tok/s 69466 (58710)	Loss/tok 3.1993 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][1380/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00094)	Tok/s 69888 (60024)	Loss/tok 3.2370 (3.1278)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][1390/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 67495 (59539)	Loss/tok 3.2316 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][1390/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00091)	Tok/s 67456 (59161)	Loss/tok 3.1751 (3.1315)	Learning Rate [7.8125e-05]
3: TRAIN [4][1390/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 67512 (60013)	Loss/tok 3.1910 (3.1273)	Learning Rate [7.8125e-05]
0: TRAIN [4][1390/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00093)	Tok/s 67435 (58698)	Loss/tok 3.2040 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][1400/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00094)	Tok/s 52862 (59543)	Loss/tok 2.7206 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][1400/6832]	Time 0.060 (0.105)	Data 0.00087 (0.00094)	Tok/s 53498 (60016)	Loss/tok 2.8574 (3.1273)	Learning Rate [7.8125e-05]
1: TRAIN [4][1400/6832]	Time 0.061 (0.105)	Data 0.00092 (0.00091)	Tok/s 52857 (59165)	Loss/tok 2.7794 (3.1321)	Learning Rate [7.8125e-05]
0: TRAIN [4][1400/6832]	Time 0.060 (0.105)	Data 0.00099 (0.00093)	Tok/s 52899 (58703)	Loss/tok 2.7532 (3.1352)	Learning Rate [7.8125e-05]
2: TRAIN [4][1410/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 61822 (59555)	Loss/tok 3.3422 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][1410/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00091)	Tok/s 61505 (59176)	Loss/tok 3.4565 (3.1325)	Learning Rate [7.8125e-05]
3: TRAIN [4][1410/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00094)	Tok/s 61817 (60027)	Loss/tok 3.3207 (3.1271)	Learning Rate [7.8125e-05]
0: TRAIN [4][1410/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00093)	Tok/s 60796 (58716)	Loss/tok 3.1804 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][1420/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00091)	Tok/s 70445 (59192)	Loss/tok 3.2432 (3.1329)	Learning Rate [7.8125e-05]
0: TRAIN [4][1420/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00093)	Tok/s 70433 (58734)	Loss/tok 3.2649 (3.1355)	Learning Rate [7.8125e-05]
2: TRAIN [4][1420/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00094)	Tok/s 70392 (59569)	Loss/tok 3.3631 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][1420/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00094)	Tok/s 71358 (60042)	Loss/tok 3.2901 (3.1277)	Learning Rate [7.8125e-05]
2: TRAIN [4][1430/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00094)	Tok/s 52763 (59575)	Loss/tok 3.0353 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][1430/6832]	Time 0.099 (0.105)	Data 0.00088 (0.00091)	Tok/s 52665 (59200)	Loss/tok 3.2673 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][1430/6832]	Time 0.099 (0.105)	Data 0.00086 (0.00093)	Tok/s 51469 (58743)	Loss/tok 3.0383 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][1430/6832]	Time 0.099 (0.105)	Data 0.00086 (0.00094)	Tok/s 52774 (60047)	Loss/tok 3.3208 (3.1285)	Learning Rate [7.8125e-05]
2: TRAIN [4][1440/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 60801 (59593)	Loss/tok 3.2181 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][1440/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00091)	Tok/s 59982 (59218)	Loss/tok 3.4399 (3.1336)	Learning Rate [7.8125e-05]
3: TRAIN [4][1440/6832]	Time 0.128 (0.105)	Data 0.00085 (0.00094)	Tok/s 60795 (60064)	Loss/tok 3.1725 (3.1285)	Learning Rate [7.8125e-05]
0: TRAIN [4][1440/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00093)	Tok/s 59790 (58761)	Loss/tok 3.2988 (3.1359)	Learning Rate [7.8125e-05]
2: TRAIN [4][1450/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00094)	Tok/s 52831 (59571)	Loss/tok 3.1462 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][1450/6832]	Time 0.077 (0.105)	Data 0.00083 (0.00094)	Tok/s 52876 (60041)	Loss/tok 2.9686 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][1450/6832]	Time 0.078 (0.105)	Data 0.00086 (0.00091)	Tok/s 52808 (59197)	Loss/tok 3.0537 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][1450/6832]	Time 0.078 (0.105)	Data 0.00084 (0.00093)	Tok/s 52842 (58742)	Loss/tok 3.0032 (3.1356)	Learning Rate [7.8125e-05]
2: TRAIN [4][1460/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00094)	Tok/s 54978 (59571)	Loss/tok 3.0741 (3.1346)	Learning Rate [7.8125e-05]
0: TRAIN [4][1460/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00093)	Tok/s 55014 (58742)	Loss/tok 2.9973 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][1460/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00091)	Tok/s 55018 (59195)	Loss/tok 3.2136 (3.1335)	Learning Rate [7.8125e-05]
3: TRAIN [4][1460/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00094)	Tok/s 54970 (60039)	Loss/tok 3.1460 (3.1281)	Learning Rate [7.8125e-05]
2: TRAIN [4][1470/6832]	Time 0.124 (0.105)	Data 0.00101 (0.00094)	Tok/s 62888 (59553)	Loss/tok 3.5780 (3.1346)	Learning Rate [7.8125e-05]
1: TRAIN [4][1470/6832]	Time 0.124 (0.105)	Data 0.00107 (0.00091)	Tok/s 62938 (59173)	Loss/tok 3.2193 (3.1337)	Learning Rate [7.8125e-05]
3: TRAIN [4][1470/6832]	Time 0.124 (0.105)	Data 0.00097 (0.00094)	Tok/s 63930 (60022)	Loss/tok 3.1740 (3.1276)	Learning Rate [7.8125e-05]
0: TRAIN [4][1470/6832]	Time 0.124 (0.105)	Data 0.00107 (0.00093)	Tok/s 62933 (58714)	Loss/tok 3.2205 (3.1351)	Learning Rate [7.8125e-05]
2: TRAIN [4][1480/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 63513 (59548)	Loss/tok 3.3326 (3.1345)	Learning Rate [7.8125e-05]
1: TRAIN [4][1480/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00091)	Tok/s 63463 (59169)	Loss/tok 3.4140 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][1480/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00093)	Tok/s 63472 (58712)	Loss/tok 3.2105 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][1480/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 64191 (60018)	Loss/tok 3.2951 (3.1276)	Learning Rate [7.8125e-05]
2: TRAIN [4][1490/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 86526 (59547)	Loss/tok 3.0675 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][1490/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00094)	Tok/s 86950 (60017)	Loss/tok 3.0070 (3.1269)	Learning Rate [7.8125e-05]
0: TRAIN [4][1490/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 85365 (58710)	Loss/tok 3.0599 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][1490/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00091)	Tok/s 85576 (59168)	Loss/tok 3.0001 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][1500/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00094)	Tok/s 68694 (59627)	Loss/tok 3.2068 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][1500/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 69647 (60099)	Loss/tok 3.1659 (3.1273)	Learning Rate [7.8125e-05]
1: TRAIN [4][1500/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00091)	Tok/s 68669 (59247)	Loss/tok 3.3816 (3.1329)	Learning Rate [7.8125e-05]
0: TRAIN [4][1500/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00093)	Tok/s 68652 (58791)	Loss/tok 3.2240 (3.1352)	Learning Rate [7.8125e-05]
2: TRAIN [4][1510/6832]	Time 0.071 (0.105)	Data 0.00100 (0.00094)	Tok/s 48856 (59581)	Loss/tok 2.8676 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][1510/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00093)	Tok/s 48927 (58737)	Loss/tok 2.9316 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][1510/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00091)	Tok/s 48881 (59198)	Loss/tok 2.8905 (3.1326)	Learning Rate [7.8125e-05]
3: TRAIN [4][1510/6832]	Time 0.071 (0.105)	Data 0.00096 (0.00094)	Tok/s 48838 (60054)	Loss/tok 2.8875 (3.1271)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][1520/6832]	Time 0.081 (0.105)	Data 0.00093 (0.00094)	Tok/s 52152 (59579)	Loss/tok 2.9973 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][1520/6832]	Time 0.081 (0.105)	Data 0.00090 (0.00094)	Tok/s 52143 (60051)	Loss/tok 2.7778 (3.1275)	Learning Rate [7.8125e-05]
0: TRAIN [4][1520/6832]	Time 0.081 (0.105)	Data 0.00086 (0.00093)	Tok/s 52115 (58738)	Loss/tok 3.1225 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][1520/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00091)	Tok/s 52087 (59197)	Loss/tok 2.8934 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][1530/6832]	Time 0.044 (0.105)	Data 0.00099 (0.00094)	Tok/s 37458 (59602)	Loss/tok 1.9689 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][1530/6832]	Time 0.044 (0.105)	Data 0.00093 (0.00094)	Tok/s 41237 (60077)	Loss/tok 2.3201 (3.1273)	Learning Rate [7.8125e-05]
1: TRAIN [4][1530/6832]	Time 0.044 (0.105)	Data 0.00094 (0.00091)	Tok/s 32860 (59218)	Loss/tok 2.1798 (3.1332)	Learning Rate [7.8125e-05]
0: TRAIN [4][1530/6832]	Time 0.044 (0.105)	Data 0.00090 (0.00093)	Tok/s 21206 (58753)	Loss/tok 1.7877 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][1540/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 60510 (60084)	Loss/tok 3.2914 (3.1280)	Learning Rate [7.8125e-05]
2: TRAIN [4][1540/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 59607 (59609)	Loss/tok 3.2017 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][1540/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00091)	Tok/s 59628 (59227)	Loss/tok 3.3087 (3.1343)	Learning Rate [7.8125e-05]
0: TRAIN [4][1540/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 59605 (58763)	Loss/tok 3.1470 (3.1361)	Learning Rate [7.8125e-05]
2: TRAIN [4][1550/6832]	Time 0.064 (0.105)	Data 0.00097 (0.00094)	Tok/s 50436 (59578)	Loss/tok 2.6877 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][1550/6832]	Time 0.064 (0.105)	Data 0.00094 (0.00094)	Tok/s 51769 (60053)	Loss/tok 2.8180 (3.1279)	Learning Rate [7.8125e-05]
0: TRAIN [4][1550/6832]	Time 0.064 (0.105)	Data 0.00088 (0.00093)	Tok/s 49639 (58733)	Loss/tok 2.7364 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][1550/6832]	Time 0.064 (0.105)	Data 0.00089 (0.00091)	Tok/s 49664 (59196)	Loss/tok 2.6409 (3.1346)	Learning Rate [7.8125e-05]
2: TRAIN [4][1560/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00094)	Tok/s 57932 (59566)	Loss/tok 3.1884 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][1560/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00091)	Tok/s 57932 (59183)	Loss/tok 3.3155 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][1560/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00094)	Tok/s 57909 (60041)	Loss/tok 2.8885 (3.1277)	Learning Rate [7.8125e-05]
0: TRAIN [4][1560/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00093)	Tok/s 57906 (58721)	Loss/tok 3.0522 (3.1354)	Learning Rate [7.8125e-05]
2: TRAIN [4][1570/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00094)	Tok/s 53265 (59542)	Loss/tok 2.8890 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][1570/6832]	Time 0.072 (0.105)	Data 0.00086 (0.00094)	Tok/s 53240 (60017)	Loss/tok 3.0323 (3.1272)	Learning Rate [7.8125e-05]
0: TRAIN [4][1570/6832]	Time 0.072 (0.105)	Data 0.00091 (0.00093)	Tok/s 51486 (58686)	Loss/tok 2.9031 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][1570/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00091)	Tok/s 52591 (59156)	Loss/tok 2.8927 (3.1345)	Learning Rate [7.8125e-05]
2: TRAIN [4][1580/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 62698 (59583)	Loss/tok 3.5002 (3.1346)	Learning Rate [7.8125e-05]
3: TRAIN [4][1580/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 63324 (60060)	Loss/tok 3.2297 (3.1268)	Learning Rate [7.8125e-05]
1: TRAIN [4][1580/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00091)	Tok/s 62679 (59193)	Loss/tok 3.3010 (3.1346)	Learning Rate [7.8125e-05]
0: TRAIN [4][1580/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 62695 (58718)	Loss/tok 3.5804 (3.1353)	Learning Rate [7.8125e-05]
2: TRAIN [4][1590/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00094)	Tok/s 61523 (59587)	Loss/tok 3.1678 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][1590/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00094)	Tok/s 61524 (60063)	Loss/tok 3.3502 (3.1277)	Learning Rate [7.8125e-05]
0: TRAIN [4][1590/6832]	Time 0.121 (0.105)	Data 0.00084 (0.00093)	Tok/s 61484 (58725)	Loss/tok 3.1822 (3.1360)	Learning Rate [7.8125e-05]
1: TRAIN [4][1590/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00091)	Tok/s 61474 (59199)	Loss/tok 3.2770 (3.1353)	Learning Rate [7.8125e-05]
2: TRAIN [4][1600/6832]	Time 0.066 (0.105)	Data 0.00087 (0.00094)	Tok/s 51163 (59581)	Loss/tok 2.9968 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][1600/6832]	Time 0.066 (0.105)	Data 0.00085 (0.00094)	Tok/s 52240 (60057)	Loss/tok 2.8522 (3.1280)	Learning Rate [7.8125e-05]
0: TRAIN [4][1600/6832]	Time 0.066 (0.105)	Data 0.00085 (0.00093)	Tok/s 50312 (58720)	Loss/tok 2.9528 (3.1363)	Learning Rate [7.8125e-05]
1: TRAIN [4][1600/6832]	Time 0.066 (0.105)	Data 0.00087 (0.00091)	Tok/s 50322 (59194)	Loss/tok 2.9102 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][1610/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00094)	Tok/s 68859 (59598)	Loss/tok 3.2791 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][1610/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 69513 (60075)	Loss/tok 3.1204 (3.1276)	Learning Rate [7.8125e-05]
0: TRAIN [4][1610/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00093)	Tok/s 68484 (58740)	Loss/tok 3.3403 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][1610/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00091)	Tok/s 68449 (59211)	Loss/tok 3.0636 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][1620/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00094)	Tok/s 55677 (60039)	Loss/tok 3.3701 (3.1277)	Learning Rate [7.8125e-05]
2: TRAIN [4][1620/6832]	Time 0.115 (0.105)	Data 0.00094 (0.00094)	Tok/s 55665 (59561)	Loss/tok 3.1170 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][1620/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00091)	Tok/s 54772 (59170)	Loss/tok 3.3316 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][1620/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00093)	Tok/s 54557 (58692)	Loss/tok 3.1863 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][1630/6832]	Time 0.124 (0.105)	Data 0.00086 (0.00092)	Tok/s 57683 (59182)	Loss/tok 3.1696 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][1630/6832]	Time 0.124 (0.105)	Data 0.00084 (0.00093)	Tok/s 56884 (58706)	Loss/tok 3.1510 (3.1360)	Learning Rate [7.8125e-05]
2: TRAIN [4][1630/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00094)	Tok/s 57875 (59574)	Loss/tok 3.1373 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][1630/6832]	Time 0.124 (0.105)	Data 0.00084 (0.00094)	Tok/s 57871 (60051)	Loss/tok 3.1837 (3.1274)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [4][1640/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00092)	Tok/s 65681 (59169)	Loss/tok 3.3251 (3.1351)	Learning Rate [7.8125e-05]
2: TRAIN [4][1640/6832]	Time 0.129 (0.105)	Data 0.00110 (0.00094)	Tok/s 65701 (59561)	Loss/tok 3.3119 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][1640/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00093)	Tok/s 65630 (58694)	Loss/tok 3.2446 (3.1361)	Learning Rate [7.8125e-05]
3: TRAIN [4][1640/6832]	Time 0.129 (0.105)	Data 0.00108 (0.00094)	Tok/s 65679 (60037)	Loss/tok 3.2017 (3.1275)	Learning Rate [7.8125e-05]
2: TRAIN [4][1650/6832]	Time 0.130 (0.105)	Data 0.00108 (0.00094)	Tok/s 73769 (59558)	Loss/tok 3.2362 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][1650/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00092)	Tok/s 73362 (59164)	Loss/tok 3.0123 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][1650/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00094)	Tok/s 73770 (60035)	Loss/tok 3.4361 (3.1276)	Learning Rate [7.8125e-05]
0: TRAIN [4][1650/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 72794 (58687)	Loss/tok 3.3630 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][1660/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00094)	Tok/s 62550 (60064)	Loss/tok 3.1279 (3.1275)	Learning Rate [7.8125e-05]
2: TRAIN [4][1660/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 62450 (59587)	Loss/tok 3.2516 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][1660/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00092)	Tok/s 61725 (59194)	Loss/tok 3.2328 (3.1351)	Learning Rate [7.8125e-05]
0: TRAIN [4][1660/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00093)	Tok/s 61426 (58718)	Loss/tok 3.1700 (3.1360)	Learning Rate [7.8125e-05]
1: TRAIN [4][1670/6832]	Time 0.120 (0.105)	Data 0.00087 (0.00092)	Tok/s 60695 (59201)	Loss/tok 3.1293 (3.1352)	Learning Rate [7.8125e-05]
2: TRAIN [4][1670/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00094)	Tok/s 61396 (59594)	Loss/tok 3.4068 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][1670/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00093)	Tok/s 60674 (58726)	Loss/tok 3.1253 (3.1362)	Learning Rate [7.8125e-05]
3: TRAIN [4][1670/6832]	Time 0.120 (0.105)	Data 0.00085 (0.00094)	Tok/s 61708 (60069)	Loss/tok 3.2332 (3.1281)	Learning Rate [7.8125e-05]
2: TRAIN [4][1680/6832]	Time 0.126 (0.105)	Data 0.00104 (0.00094)	Tok/s 61811 (59615)	Loss/tok 3.2981 (3.1366)	Learning Rate [7.8125e-05]
3: TRAIN [4][1680/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00094)	Tok/s 61813 (60089)	Loss/tok 3.2326 (3.1286)	Learning Rate [7.8125e-05]
0: TRAIN [4][1680/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00093)	Tok/s 60812 (58748)	Loss/tok 3.1008 (3.1366)	Learning Rate [7.8125e-05]
1: TRAIN [4][1680/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00092)	Tok/s 61070 (59223)	Loss/tok 3.2380 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][1690/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00093)	Tok/s 58991 (58753)	Loss/tok 3.2511 (3.1364)	Learning Rate [7.8125e-05]
1: TRAIN [4][1690/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00092)	Tok/s 58961 (59227)	Loss/tok 3.3280 (3.1355)	Learning Rate [7.8125e-05]
2: TRAIN [4][1690/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00094)	Tok/s 58913 (59619)	Loss/tok 3.2014 (3.1365)	Learning Rate [7.8125e-05]
3: TRAIN [4][1690/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00094)	Tok/s 58924 (60091)	Loss/tok 3.0356 (3.1283)	Learning Rate [7.8125e-05]
3: TRAIN [4][1700/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00094)	Tok/s 51828 (60109)	Loss/tok 2.8712 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [4][1700/6832]	Time 0.059 (0.105)	Data 0.00100 (0.00094)	Tok/s 50142 (59637)	Loss/tok 2.6507 (3.1368)	Learning Rate [7.8125e-05]
1: TRAIN [4][1700/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00092)	Tok/s 50102 (59245)	Loss/tok 2.7575 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][1700/6832]	Time 0.059 (0.105)	Data 0.00088 (0.00093)	Tok/s 50092 (58773)	Loss/tok 2.7083 (3.1366)	Learning Rate [7.8125e-05]
2: TRAIN [4][1710/6832]	Time 0.074 (0.105)	Data 0.00097 (0.00094)	Tok/s 53674 (59631)	Loss/tok 2.9477 (3.1367)	Learning Rate [7.8125e-05]
1: TRAIN [4][1710/6832]	Time 0.074 (0.105)	Data 0.00094 (0.00092)	Tok/s 52153 (59237)	Loss/tok 3.0687 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][1710/6832]	Time 0.074 (0.105)	Data 0.00093 (0.00094)	Tok/s 53901 (60101)	Loss/tok 2.7940 (3.1286)	Learning Rate [7.8125e-05]
0: TRAIN [4][1710/6832]	Time 0.074 (0.105)	Data 0.00092 (0.00093)	Tok/s 52168 (58767)	Loss/tok 3.0160 (3.1367)	Learning Rate [7.8125e-05]
1: TRAIN [4][1720/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00092)	Tok/s 69724 (59248)	Loss/tok 3.1458 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][1720/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 69714 (58780)	Loss/tok 3.2218 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][1720/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00094)	Tok/s 69689 (59641)	Loss/tok 3.2705 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][1720/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 70580 (60112)	Loss/tok 3.1467 (3.1286)	Learning Rate [7.8125e-05]
2: TRAIN [4][1730/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00094)	Tok/s 50796 (59630)	Loss/tok 2.5981 (3.1366)	Learning Rate [7.8125e-05]
3: TRAIN [4][1730/6832]	Time 0.053 (0.105)	Data 0.00084 (0.00094)	Tok/s 50809 (60100)	Loss/tok 2.5037 (3.1281)	Learning Rate [7.8125e-05]
1: TRAIN [4][1730/6832]	Time 0.053 (0.105)	Data 0.00087 (0.00092)	Tok/s 50227 (59238)	Loss/tok 2.6346 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][1730/6832]	Time 0.053 (0.105)	Data 0.00084 (0.00093)	Tok/s 48372 (58770)	Loss/tok 2.5640 (3.1364)	Learning Rate [7.8125e-05]
3: TRAIN [4][1740/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00094)	Tok/s 65187 (60101)	Loss/tok 3.4843 (3.1287)	Learning Rate [7.8125e-05]
2: TRAIN [4][1740/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 64765 (59631)	Loss/tok 3.3252 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][1740/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00092)	Tok/s 64684 (59240)	Loss/tok 3.3766 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][1740/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00093)	Tok/s 64693 (58774)	Loss/tok 3.3218 (3.1369)	Learning Rate [7.8125e-05]
2: TRAIN [4][1750/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00094)	Tok/s 50727 (59623)	Loss/tok 2.9946 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][1750/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00094)	Tok/s 51324 (60092)	Loss/tok 3.0208 (3.1289)	Learning Rate [7.8125e-05]
1: TRAIN [4][1750/6832]	Time 0.114 (0.105)	Data 0.00091 (0.00092)	Tok/s 50715 (59232)	Loss/tok 3.3298 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][1750/6832]	Time 0.114 (0.105)	Data 0.00088 (0.00093)	Tok/s 50709 (58768)	Loss/tok 3.1265 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][1760/6832]	Time 0.083 (0.105)	Data 0.00111 (0.00094)	Tok/s 52635 (59588)	Loss/tok 3.1609 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][1760/6832]	Time 0.083 (0.105)	Data 0.00108 (0.00094)	Tok/s 53549 (60056)	Loss/tok 2.9643 (3.1286)	Learning Rate [7.8125e-05]
1: TRAIN [4][1760/6832]	Time 0.083 (0.105)	Data 0.00092 (0.00092)	Tok/s 52618 (59196)	Loss/tok 2.9837 (3.1353)	Learning Rate [7.8125e-05]
0: TRAIN [4][1760/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00093)	Tok/s 52637 (58732)	Loss/tok 3.0996 (3.1370)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [4][1770/6832]	Time 0.117 (0.105)	Data 0.00090 (0.00094)	Tok/s 53653 (59589)	Loss/tok 3.3891 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][1770/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00094)	Tok/s 53659 (60056)	Loss/tok 3.1996 (3.1285)	Learning Rate [7.8125e-05]
1: TRAIN [4][1770/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00092)	Tok/s 53088 (59198)	Loss/tok 3.2692 (3.1353)	Learning Rate [7.8125e-05]
0: TRAIN [4][1770/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00093)	Tok/s 52550 (58734)	Loss/tok 3.1088 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][1780/6832]	Time 0.112 (0.105)	Data 0.00090 (0.00094)	Tok/s 52754 (59623)	Loss/tok 3.2741 (3.1370)	Learning Rate [7.8125e-05]
0: TRAIN [4][1780/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00093)	Tok/s 51632 (58769)	Loss/tok 3.0365 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][1780/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00094)	Tok/s 52757 (60091)	Loss/tok 2.9664 (3.1286)	Learning Rate [7.8125e-05]
1: TRAIN [4][1780/6832]	Time 0.112 (0.105)	Data 0.00089 (0.00092)	Tok/s 51626 (59230)	Loss/tok 3.1305 (3.1351)	Learning Rate [7.8125e-05]
2: TRAIN [4][1790/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00094)	Tok/s 53926 (59600)	Loss/tok 3.0364 (3.1367)	Learning Rate [7.8125e-05]
1: TRAIN [4][1790/6832]	Time 0.105 (0.105)	Data 0.00087 (0.00092)	Tok/s 53773 (59208)	Loss/tok 3.1463 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][1790/6832]	Time 0.105 (0.105)	Data 0.00089 (0.00093)	Tok/s 52661 (58746)	Loss/tok 3.0070 (3.1367)	Learning Rate [7.8125e-05]
3: TRAIN [4][1790/6832]	Time 0.104 (0.105)	Data 0.00085 (0.00094)	Tok/s 53928 (60069)	Loss/tok 3.1339 (3.1284)	Learning Rate [7.8125e-05]
2: TRAIN [4][1800/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00094)	Tok/s 61669 (59602)	Loss/tok 3.0545 (3.1365)	Learning Rate [7.8125e-05]
3: TRAIN [4][1800/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 62429 (60071)	Loss/tok 3.2671 (3.1284)	Learning Rate [7.8125e-05]
0: TRAIN [4][1800/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00093)	Tok/s 61669 (58739)	Loss/tok 3.2642 (3.1368)	Learning Rate [7.8125e-05]
1: TRAIN [4][1800/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00092)	Tok/s 61657 (59207)	Loss/tok 3.2228 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][1810/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00092)	Tok/s 57925 (59220)	Loss/tok 3.1301 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][1810/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 58420 (59614)	Loss/tok 3.2127 (3.1367)	Learning Rate [7.8125e-05]
3: TRAIN [4][1810/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 58433 (60083)	Loss/tok 3.3153 (3.1288)	Learning Rate [7.8125e-05]
0: TRAIN [4][1810/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00093)	Tok/s 57372 (58753)	Loss/tok 3.0040 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][1820/6832]	Time 0.067 (0.105)	Data 0.00097 (0.00094)	Tok/s 52006 (59606)	Loss/tok 2.6031 (3.1367)	Learning Rate [7.8125e-05]
3: TRAIN [4][1820/6832]	Time 0.067 (0.105)	Data 0.00091 (0.00094)	Tok/s 53727 (60076)	Loss/tok 2.8958 (3.1289)	Learning Rate [7.8125e-05]
1: TRAIN [4][1820/6832]	Time 0.067 (0.105)	Data 0.00095 (0.00092)	Tok/s 51675 (59213)	Loss/tok 2.7717 (3.1346)	Learning Rate [7.8125e-05]
0: TRAIN [4][1820/6832]	Time 0.067 (0.105)	Data 0.00093 (0.00093)	Tok/s 51671 (58746)	Loss/tok 2.8731 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][1830/6832]	Time 0.065 (0.105)	Data 0.00096 (0.00094)	Tok/s 51210 (60076)	Loss/tok 2.8100 (3.1294)	Learning Rate [7.8125e-05]
2: TRAIN [4][1830/6832]	Time 0.065 (0.105)	Data 0.00104 (0.00094)	Tok/s 49577 (59607)	Loss/tok 2.9089 (3.1371)	Learning Rate [7.8125e-05]
0: TRAIN [4][1830/6832]	Time 0.065 (0.105)	Data 0.00092 (0.00093)	Tok/s 49157 (58749)	Loss/tok 2.8011 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][1830/6832]	Time 0.065 (0.105)	Data 0.00094 (0.00092)	Tok/s 49144 (59215)	Loss/tok 2.6247 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][1840/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00092)	Tok/s 63162 (59207)	Loss/tok 3.2374 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][1840/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00094)	Tok/s 63139 (59598)	Loss/tok 3.2256 (3.1373)	Learning Rate [7.8125e-05]
0: TRAIN [4][1840/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00093)	Tok/s 63153 (58743)	Loss/tok 3.2910 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][1840/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00094)	Tok/s 63416 (60065)	Loss/tok 3.2776 (3.1298)	Learning Rate [7.8125e-05]
1: TRAIN [4][1850/6832]	Time 0.119 (0.105)	Data 0.00090 (0.00092)	Tok/s 52503 (59202)	Loss/tok 3.3134 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][1850/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00093)	Tok/s 52485 (58739)	Loss/tok 3.2233 (3.1382)	Learning Rate [7.8125e-05]
2: TRAIN [4][1850/6832]	Time 0.120 (0.105)	Data 0.00096 (0.00094)	Tok/s 52418 (59592)	Loss/tok 3.1622 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][1850/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00094)	Tok/s 52418 (60059)	Loss/tok 3.1493 (3.1302)	Learning Rate [7.8125e-05]
2: TRAIN [4][1860/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 81882 (59582)	Loss/tok 3.3021 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][1860/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00092)	Tok/s 81809 (59193)	Loss/tok 3.1288 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][1860/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 80923 (58731)	Loss/tok 3.1412 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][1860/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 82656 (60051)	Loss/tok 3.2168 (3.1296)	Learning Rate [7.8125e-05]
2: TRAIN [4][1870/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 58365 (59579)	Loss/tok 3.2266 (3.1368)	Learning Rate [7.8125e-05]
0: TRAIN [4][1870/6832]	Time 0.118 (0.105)	Data 0.00084 (0.00093)	Tok/s 57297 (58730)	Loss/tok 3.2488 (3.1379)	Learning Rate [7.8125e-05]
1: TRAIN [4][1870/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00092)	Tok/s 57528 (59192)	Loss/tok 3.2003 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][1870/6832]	Time 0.118 (0.105)	Data 0.00083 (0.00094)	Tok/s 58380 (60047)	Loss/tok 3.2612 (3.1299)	Learning Rate [7.8125e-05]
2: TRAIN [4][1880/6832]	Time 0.096 (0.105)	Data 0.00089 (0.00094)	Tok/s 53609 (59560)	Loss/tok 3.0889 (3.1367)	Learning Rate [7.8125e-05]
3: TRAIN [4][1880/6832]	Time 0.096 (0.105)	Data 0.00084 (0.00094)	Tok/s 53592 (60027)	Loss/tok 2.9440 (3.1297)	Learning Rate [7.8125e-05]
1: TRAIN [4][1880/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00092)	Tok/s 53137 (59173)	Loss/tok 3.0734 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][1880/6832]	Time 0.096 (0.105)	Data 0.00086 (0.00093)	Tok/s 52250 (58713)	Loss/tok 3.1710 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][1890/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 71660 (59596)	Loss/tok 3.2536 (3.1366)	Learning Rate [7.8125e-05]
1: TRAIN [4][1890/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00092)	Tok/s 71117 (59207)	Loss/tok 3.1837 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][1890/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 71667 (60064)	Loss/tok 3.2045 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][1890/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00093)	Tok/s 70714 (58740)	Loss/tok 3.2520 (3.1386)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][1900/6832]	Time 0.121 (0.105)	Data 0.00090 (0.00092)	Tok/s 59416 (59236)	Loss/tok 3.0937 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][1900/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00093)	Tok/s 59096 (58769)	Loss/tok 3.1694 (3.1383)	Learning Rate [7.8125e-05]
2: TRAIN [4][1900/6832]	Time 0.121 (0.105)	Data 0.00089 (0.00094)	Tok/s 59354 (59625)	Loss/tok 3.2019 (3.1362)	Learning Rate [7.8125e-05]
3: TRAIN [4][1900/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00094)	Tok/s 59348 (60093)	Loss/tok 3.1361 (3.1296)	Learning Rate [7.8125e-05]
1: TRAIN [4][1910/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00092)	Tok/s 76154 (59252)	Loss/tok 3.0395 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][1910/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 75786 (58785)	Loss/tok 3.2193 (3.1382)	Learning Rate [7.8125e-05]
2: TRAIN [4][1910/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 76729 (59643)	Loss/tok 3.1447 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][1910/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 76728 (60111)	Loss/tok 3.3241 (3.1297)	Learning Rate [7.8125e-05]
2: TRAIN [4][1920/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 62070 (59635)	Loss/tok 3.3659 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][1920/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00092)	Tok/s 61490 (59245)	Loss/tok 3.2414 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][1920/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00092)	Tok/s 61111 (58778)	Loss/tok 3.2561 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][1920/6832]	Time 0.126 (0.105)	Data 0.00083 (0.00094)	Tok/s 62061 (60102)	Loss/tok 3.3018 (3.1298)	Learning Rate [7.8125e-05]
2: TRAIN [4][1930/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00094)	Tok/s 52286 (59624)	Loss/tok 2.9543 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][1930/6832]	Time 0.087 (0.105)	Data 0.00084 (0.00093)	Tok/s 52947 (60090)	Loss/tok 3.2023 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][1930/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00092)	Tok/s 51539 (58769)	Loss/tok 3.0561 (3.1380)	Learning Rate [7.8125e-05]
1: TRAIN [4][1930/6832]	Time 0.087 (0.105)	Data 0.00092 (0.00092)	Tok/s 51515 (59234)	Loss/tok 2.7321 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][1940/6832]	Time 0.044 (0.105)	Data 0.00082 (0.00093)	Tok/s 42821 (60067)	Loss/tok 2.2459 (3.1296)	Learning Rate [7.8125e-05]
2: TRAIN [4][1940/6832]	Time 0.044 (0.105)	Data 0.00086 (0.00094)	Tok/s 38542 (59598)	Loss/tok 2.0056 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][1940/6832]	Time 0.044 (0.105)	Data 0.00083 (0.00092)	Tok/s 21127 (58728)	Loss/tok 1.7257 (3.1377)	Learning Rate [7.8125e-05]
1: TRAIN [4][1940/6832]	Time 0.044 (0.105)	Data 0.00090 (0.00092)	Tok/s 32974 (59203)	Loss/tok 2.0067 (3.1334)	Learning Rate [7.8125e-05]
1: TRAIN [4][1950/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00092)	Tok/s 81672 (59201)	Loss/tok 3.0218 (3.1332)	Learning Rate [7.8125e-05]
0: TRAIN [4][1950/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00092)	Tok/s 81263 (58728)	Loss/tok 3.2081 (3.1377)	Learning Rate [7.8125e-05]
2: TRAIN [4][1950/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 82156 (59594)	Loss/tok 3.2283 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][1950/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00093)	Tok/s 82560 (60063)	Loss/tok 3.0463 (3.1296)	Learning Rate [7.8125e-05]
2: TRAIN [4][1960/6832]	Time 0.071 (0.105)	Data 0.00094 (0.00094)	Tok/s 52512 (59565)	Loss/tok 3.1151 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][1960/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00093)	Tok/s 52520 (60035)	Loss/tok 2.8989 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][1960/6832]	Time 0.071 (0.105)	Data 0.00092 (0.00092)	Tok/s 52500 (59173)	Loss/tok 3.0086 (3.1328)	Learning Rate [7.8125e-05]
0: TRAIN [4][1960/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00092)	Tok/s 52503 (58696)	Loss/tok 3.0988 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][1970/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00092)	Tok/s 65330 (59188)	Loss/tok 3.4319 (3.1327)	Learning Rate [7.8125e-05]
3: TRAIN [4][1970/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00093)	Tok/s 65314 (60050)	Loss/tok 3.2494 (3.1291)	Learning Rate [7.8125e-05]
2: TRAIN [4][1970/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 65296 (59580)	Loss/tok 3.2795 (3.1351)	Learning Rate [7.8125e-05]
0: TRAIN [4][1970/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00092)	Tok/s 65127 (58712)	Loss/tok 3.3094 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][1980/6832]	Time 0.102 (0.105)	Data 0.00087 (0.00094)	Tok/s 51526 (59548)	Loss/tok 2.9966 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][1980/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00092)	Tok/s 51454 (59157)	Loss/tok 2.8324 (3.1322)	Learning Rate [7.8125e-05]
3: TRAIN [4][1980/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00093)	Tok/s 52694 (60017)	Loss/tok 2.9730 (3.1288)	Learning Rate [7.8125e-05]
0: TRAIN [4][1980/6832]	Time 0.102 (0.105)	Data 0.00087 (0.00092)	Tok/s 51446 (58682)	Loss/tok 3.0340 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][1990/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00094)	Tok/s 68208 (59548)	Loss/tok 3.0963 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][1990/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00093)	Tok/s 68186 (60015)	Loss/tok 3.4097 (3.1291)	Learning Rate [7.8125e-05]
0: TRAIN [4][1990/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00092)	Tok/s 68011 (58684)	Loss/tok 3.3829 (3.1375)	Learning Rate [7.8125e-05]
1: TRAIN [4][1990/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00092)	Tok/s 68229 (59157)	Loss/tok 3.3307 (3.1326)	Learning Rate [7.8125e-05]
1: TRAIN [4][2000/6832]	Time 0.073 (0.105)	Data 0.00086 (0.00092)	Tok/s 51970 (59170)	Loss/tok 2.8906 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][2000/6832]	Time 0.073 (0.105)	Data 0.00088 (0.00094)	Tok/s 52249 (59562)	Loss/tok 3.0386 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][2000/6832]	Time 0.074 (0.105)	Data 0.00084 (0.00092)	Tok/s 50496 (58697)	Loss/tok 3.0587 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][2000/6832]	Time 0.074 (0.105)	Data 0.00085 (0.00093)	Tok/s 52204 (60030)	Loss/tok 2.9647 (3.1288)	Learning Rate [7.8125e-05]
1: TRAIN [4][2010/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00092)	Tok/s 54443 (59176)	Loss/tok 2.8348 (3.1327)	Learning Rate [7.8125e-05]
2: TRAIN [4][2010/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00094)	Tok/s 54449 (59568)	Loss/tok 3.0011 (3.1346)	Learning Rate [7.8125e-05]
3: TRAIN [4][2010/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00093)	Tok/s 56111 (60035)	Loss/tok 3.0442 (3.1288)	Learning Rate [7.8125e-05]
0: TRAIN [4][2010/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00092)	Tok/s 54456 (58705)	Loss/tok 2.9061 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][2020/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 82354 (59575)	Loss/tok 3.0822 (3.1346)	Learning Rate [7.8125e-05]
1: TRAIN [4][2020/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00092)	Tok/s 82224 (59183)	Loss/tok 3.1591 (3.1329)	Learning Rate [7.8125e-05]
0: TRAIN [4][2020/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00092)	Tok/s 81565 (58712)	Loss/tok 3.1426 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][2020/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00093)	Tok/s 83192 (60041)	Loss/tok 3.1268 (3.1288)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][2030/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00092)	Tok/s 62110 (59186)	Loss/tok 3.3389 (3.1332)	Learning Rate [7.8125e-05]
0: TRAIN [4][2030/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00092)	Tok/s 61099 (58716)	Loss/tok 3.4368 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][2030/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00094)	Tok/s 61977 (59578)	Loss/tok 3.4255 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][2030/6832]	Time 0.124 (0.105)	Data 0.00086 (0.00093)	Tok/s 61973 (60042)	Loss/tok 3.2500 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][2040/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00092)	Tok/s 52732 (59170)	Loss/tok 3.1002 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][2040/6832]	Time 0.102 (0.105)	Data 0.00088 (0.00094)	Tok/s 53457 (59560)	Loss/tok 3.0090 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][2040/6832]	Time 0.102 (0.105)	Data 0.00085 (0.00093)	Tok/s 53950 (60024)	Loss/tok 3.1406 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][2040/6832]	Time 0.102 (0.105)	Data 0.00086 (0.00092)	Tok/s 52695 (58701)	Loss/tok 2.9925 (3.1381)	Learning Rate [7.8125e-05]
1: TRAIN [4][2050/6832]	Time 0.062 (0.105)	Data 0.00084 (0.00092)	Tok/s 49566 (59158)	Loss/tok 2.6927 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][2050/6832]	Time 0.062 (0.105)	Data 0.00086 (0.00094)	Tok/s 50923 (59549)	Loss/tok 2.9035 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][2050/6832]	Time 0.062 (0.105)	Data 0.00083 (0.00093)	Tok/s 51604 (60012)	Loss/tok 2.9061 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][2050/6832]	Time 0.062 (0.105)	Data 0.00084 (0.00092)	Tok/s 49576 (58691)	Loss/tok 2.8623 (3.1378)	Learning Rate [7.8125e-05]
2: TRAIN [4][2060/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00094)	Tok/s 53577 (59560)	Loss/tok 3.1569 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][2060/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00093)	Tok/s 53584 (60023)	Loss/tok 2.9002 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][2060/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00092)	Tok/s 53586 (59170)	Loss/tok 3.1940 (3.1331)	Learning Rate [7.8125e-05]
0: TRAIN [4][2060/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00092)	Tok/s 52548 (58704)	Loss/tok 2.9385 (3.1378)	Learning Rate [7.8125e-05]
1: TRAIN [4][2070/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00092)	Tok/s 67424 (59192)	Loss/tok 3.1479 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][2070/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 67404 (59581)	Loss/tok 3.1581 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][2070/6832]	Time 0.127 (0.105)	Data 0.00084 (0.00093)	Tok/s 67954 (60044)	Loss/tok 3.3614 (3.1296)	Learning Rate [7.8125e-05]
0: TRAIN [4][2070/6832]	Time 0.127 (0.105)	Data 0.00085 (0.00092)	Tok/s 67434 (58726)	Loss/tok 3.2694 (3.1383)	Learning Rate [7.8125e-05]
2: TRAIN [4][2080/6832]	Time 0.060 (0.105)	Data 0.00105 (0.00094)	Tok/s 48772 (59572)	Loss/tok 2.6546 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][2080/6832]	Time 0.060 (0.105)	Data 0.00098 (0.00093)	Tok/s 49997 (60035)	Loss/tok 2.8181 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][2080/6832]	Time 0.060 (0.105)	Data 0.00101 (0.00092)	Tok/s 48946 (58718)	Loss/tok 2.8325 (3.1383)	Learning Rate [7.8125e-05]
1: TRAIN [4][2080/6832]	Time 0.060 (0.105)	Data 0.00105 (0.00092)	Tok/s 48923 (59184)	Loss/tok 2.6871 (3.1332)	Learning Rate [7.8125e-05]
1: TRAIN [4][2090/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00092)	Tok/s 61847 (59185)	Loss/tok 3.2221 (3.1334)	Learning Rate [7.8125e-05]
2: TRAIN [4][2090/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00094)	Tok/s 61868 (59572)	Loss/tok 3.3674 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][2090/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00093)	Tok/s 62556 (60035)	Loss/tok 3.0603 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2090/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00092)	Tok/s 61811 (58720)	Loss/tok 3.2857 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][2100/6832]	Time 0.103 (0.105)	Data 0.00095 (0.00092)	Tok/s 52200 (59185)	Loss/tok 3.0048 (3.1334)	Learning Rate [7.8125e-05]
2: TRAIN [4][2100/6832]	Time 0.103 (0.105)	Data 0.00101 (0.00094)	Tok/s 52196 (59572)	Loss/tok 2.8869 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][2100/6832]	Time 0.103 (0.105)	Data 0.00097 (0.00093)	Tok/s 52218 (60036)	Loss/tok 2.9948 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2100/6832]	Time 0.103 (0.105)	Data 0.00099 (0.00092)	Tok/s 52180 (58715)	Loss/tok 2.9798 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][2110/6832]	Time 0.097 (0.105)	Data 0.00085 (0.00092)	Tok/s 52612 (59216)	Loss/tok 3.0732 (3.1333)	Learning Rate [7.8125e-05]
0: TRAIN [4][2110/6832]	Time 0.097 (0.105)	Data 0.00083 (0.00092)	Tok/s 51289 (58747)	Loss/tok 3.0648 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][2110/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00094)	Tok/s 52557 (59603)	Loss/tok 2.9769 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][2110/6832]	Time 0.097 (0.105)	Data 0.00084 (0.00093)	Tok/s 52570 (60066)	Loss/tok 3.0494 (3.1302)	Learning Rate [7.8125e-05]
1: TRAIN [4][2120/6832]	Time 0.096 (0.105)	Data 0.00090 (0.00092)	Tok/s 54664 (59204)	Loss/tok 3.2625 (3.1334)	Learning Rate [7.8125e-05]
2: TRAIN [4][2120/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00094)	Tok/s 55936 (59592)	Loss/tok 3.0336 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][2120/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00093)	Tok/s 55937 (60055)	Loss/tok 2.9480 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][2120/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00092)	Tok/s 54589 (58735)	Loss/tok 3.1055 (3.1387)	Learning Rate [7.8125e-05]
2: TRAIN [4][2130/6832]	Time 0.077 (0.105)	Data 0.00090 (0.00094)	Tok/s 53348 (59610)	Loss/tok 2.9132 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][2130/6832]	Time 0.077 (0.105)	Data 0.00087 (0.00092)	Tok/s 53348 (59221)	Loss/tok 3.0371 (3.1334)	Learning Rate [7.8125e-05]
3: TRAIN [4][2130/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00093)	Tok/s 53340 (60072)	Loss/tok 2.9661 (3.1302)	Learning Rate [7.8125e-05]
0: TRAIN [4][2130/6832]	Time 0.077 (0.105)	Data 0.00086 (0.00092)	Tok/s 53379 (58754)	Loss/tok 2.8968 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][2140/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00092)	Tok/s 58001 (59211)	Loss/tok 3.3429 (3.1333)	Learning Rate [7.8125e-05]
2: TRAIN [4][2140/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00094)	Tok/s 58011 (59599)	Loss/tok 3.1933 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][2140/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00093)	Tok/s 58017 (60061)	Loss/tok 3.2001 (3.1302)	Learning Rate [7.8125e-05]
0: TRAIN [4][2140/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00092)	Tok/s 57969 (58744)	Loss/tok 3.3812 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][2150/6832]	Time 0.086 (0.105)	Data 0.00085 (0.00092)	Tok/s 53371 (59219)	Loss/tok 2.9870 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][2150/6832]	Time 0.086 (0.105)	Data 0.00084 (0.00092)	Tok/s 53357 (58753)	Loss/tok 3.0195 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][2150/6832]	Time 0.086 (0.105)	Data 0.00088 (0.00094)	Tok/s 53372 (59607)	Loss/tok 3.0971 (3.1361)	Learning Rate [7.8125e-05]
3: TRAIN [4][2150/6832]	Time 0.086 (0.105)	Data 0.00085 (0.00093)	Tok/s 53409 (60068)	Loss/tok 3.0995 (3.1305)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
1: TRAIN [4][2160/6832]	Time 0.046 (0.105)	Data 0.00087 (0.00092)	Tok/s 43866 (59206)	Loss/tok 2.3092 (3.1336)	Learning Rate [7.8125e-05]
2: TRAIN [4][2160/6832]	Time 0.046 (0.105)	Data 0.00087 (0.00094)	Tok/s 46522 (59594)	Loss/tok 2.3323 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][2160/6832]	Time 0.046 (0.105)	Data 0.00084 (0.00093)	Tok/s 47918 (60055)	Loss/tok 2.2615 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][2160/6832]	Time 0.046 (0.105)	Data 0.00085 (0.00092)	Tok/s 41551 (58739)	Loss/tok 2.1647 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][2170/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00092)	Tok/s 58859 (59185)	Loss/tok 3.1332 (3.1339)	Learning Rate [7.8125e-05]
2: TRAIN [4][2170/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00094)	Tok/s 58848 (59574)	Loss/tok 3.2096 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][2170/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00092)	Tok/s 58844 (58717)	Loss/tok 3.3570 (3.1387)	Learning Rate [7.8125e-05]
3: TRAIN [4][2170/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00093)	Tok/s 58841 (60035)	Loss/tok 3.1005 (3.1302)	Learning Rate [7.8125e-05]
2: TRAIN [4][2180/6832]	Time 0.124 (0.105)	Data 0.00102 (0.00094)	Tok/s 58923 (59588)	Loss/tok 3.1367 (3.1364)	Learning Rate [7.8125e-05]
1: TRAIN [4][2180/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00092)	Tok/s 58958 (59199)	Loss/tok 3.3056 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][2180/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00093)	Tok/s 59835 (60048)	Loss/tok 3.3232 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][2180/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00092)	Tok/s 58942 (58730)	Loss/tok 3.1724 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][2190/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00092)	Tok/s 53022 (59200)	Loss/tok 3.0386 (3.1336)	Learning Rate [7.8125e-05]
2: TRAIN [4][2190/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00094)	Tok/s 52995 (59588)	Loss/tok 3.0326 (3.1363)	Learning Rate [7.8125e-05]
3: TRAIN [4][2190/6832]	Time 0.101 (0.105)	Data 0.00083 (0.00093)	Tok/s 52990 (60047)	Loss/tok 3.1546 (3.1307)	Learning Rate [7.8125e-05]
0: TRAIN [4][2190/6832]	Time 0.101 (0.105)	Data 0.00084 (0.00092)	Tok/s 52177 (58731)	Loss/tok 3.0857 (3.1387)	Learning Rate [7.8125e-05]
2: TRAIN [4][2200/6832]	Time 0.123 (0.105)	Data 0.00105 (0.00094)	Tok/s 58088 (59590)	Loss/tok 3.1174 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][2200/6832]	Time 0.123 (0.105)	Data 0.00094 (0.00092)	Tok/s 58056 (59203)	Loss/tok 3.2001 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][2200/6832]	Time 0.123 (0.105)	Data 0.00102 (0.00093)	Tok/s 58070 (60049)	Loss/tok 3.3072 (3.1309)	Learning Rate [7.8125e-05]
0: TRAIN [4][2200/6832]	Time 0.123 (0.105)	Data 0.00094 (0.00092)	Tok/s 57484 (58735)	Loss/tok 3.2920 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][2210/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00094)	Tok/s 50060 (59594)	Loss/tok 2.8439 (3.1363)	Learning Rate [7.8125e-05]
1: TRAIN [4][2210/6832]	Time 0.064 (0.105)	Data 0.00084 (0.00092)	Tok/s 49776 (59207)	Loss/tok 2.7948 (3.1336)	Learning Rate [7.8125e-05]
3: TRAIN [4][2210/6832]	Time 0.064 (0.105)	Data 0.00084 (0.00093)	Tok/s 51775 (60054)	Loss/tok 2.6895 (3.1308)	Learning Rate [7.8125e-05]
0: TRAIN [4][2210/6832]	Time 0.064 (0.105)	Data 0.00085 (0.00092)	Tok/s 49832 (58738)	Loss/tok 2.7555 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][2220/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 71634 (59199)	Loss/tok 3.3539 (3.1338)	Learning Rate [7.8125e-05]
0: TRAIN [4][2220/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 71629 (58730)	Loss/tok 3.1031 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][2220/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 72299 (59585)	Loss/tok 2.9961 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][2220/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00093)	Tok/s 72588 (60046)	Loss/tok 3.3391 (3.1307)	Learning Rate [7.8125e-05]
2: TRAIN [4][2230/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00094)	Tok/s 49946 (59548)	Loss/tok 2.8237 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][2230/6832]	Time 0.070 (0.105)	Data 0.00083 (0.00093)	Tok/s 51460 (60010)	Loss/tok 2.7750 (3.1303)	Learning Rate [7.8125e-05]
1: TRAIN [4][2230/6832]	Time 0.070 (0.105)	Data 0.00083 (0.00092)	Tok/s 49604 (59160)	Loss/tok 2.7639 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][2230/6832]	Time 0.070 (0.105)	Data 0.00085 (0.00092)	Tok/s 49601 (58687)	Loss/tok 2.9071 (3.1383)	Learning Rate [7.8125e-05]
1: TRAIN [4][2240/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00092)	Tok/s 61541 (59157)	Loss/tok 3.2261 (3.1333)	Learning Rate [7.8125e-05]
2: TRAIN [4][2240/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 61536 (59547)	Loss/tok 3.1788 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][2240/6832]	Time 0.129 (0.105)	Data 0.00083 (0.00093)	Tok/s 62446 (60011)	Loss/tok 3.2021 (3.1302)	Learning Rate [7.8125e-05]
0: TRAIN [4][2240/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00092)	Tok/s 61537 (58679)	Loss/tok 3.2844 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][2250/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00092)	Tok/s 51968 (59157)	Loss/tok 2.9723 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][2250/6832]	Time 0.103 (0.105)	Data 0.00095 (0.00094)	Tok/s 51973 (59547)	Loss/tok 2.8753 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][2250/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00093)	Tok/s 51968 (60010)	Loss/tok 3.2268 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2250/6832]	Time 0.103 (0.105)	Data 0.00091 (0.00092)	Tok/s 51945 (58679)	Loss/tok 3.0854 (3.1382)	Learning Rate [7.8125e-05]
1: TRAIN [4][2260/6832]	Time 0.058 (0.105)	Data 0.00085 (0.00092)	Tok/s 48875 (59157)	Loss/tok 2.7774 (3.1331)	Learning Rate [7.8125e-05]
3: TRAIN [4][2260/6832]	Time 0.058 (0.105)	Data 0.00084 (0.00093)	Tok/s 50422 (60009)	Loss/tok 2.7268 (3.1302)	Learning Rate [7.8125e-05]
2: TRAIN [4][2260/6832]	Time 0.058 (0.105)	Data 0.00088 (0.00094)	Tok/s 48855 (59546)	Loss/tok 2.5685 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][2260/6832]	Time 0.058 (0.105)	Data 0.00084 (0.00092)	Tok/s 48548 (58680)	Loss/tok 2.6131 (3.1383)	Learning Rate [7.8125e-05]
2: TRAIN [4][2270/6832]	Time 0.114 (0.105)	Data 0.00094 (0.00094)	Tok/s 62810 (59533)	Loss/tok 3.0640 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][2270/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00093)	Tok/s 62811 (59996)	Loss/tok 3.4601 (3.1303)	Learning Rate [7.8125e-05]
1: TRAIN [4][2270/6832]	Time 0.114 (0.105)	Data 0.00088 (0.00092)	Tok/s 62759 (59145)	Loss/tok 3.2181 (3.1331)	Learning Rate [7.8125e-05]
0: TRAIN [4][2270/6832]	Time 0.114 (0.105)	Data 0.00088 (0.00092)	Tok/s 62136 (58670)	Loss/tok 3.3158 (3.1384)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [4][2280/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00092)	Tok/s 53051 (59138)	Loss/tok 3.1151 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][2280/6832]	Time 0.116 (0.105)	Data 0.00112 (0.00094)	Tok/s 53723 (59526)	Loss/tok 3.2781 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][2280/6832]	Time 0.116 (0.105)	Data 0.00104 (0.00093)	Tok/s 54176 (59989)	Loss/tok 3.0254 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][2280/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00092)	Tok/s 53056 (58664)	Loss/tok 3.1973 (3.1384)	Learning Rate [7.8125e-05]
2: TRAIN [4][2290/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00094)	Tok/s 53854 (59507)	Loss/tok 3.0680 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][2290/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00092)	Tok/s 53845 (59118)	Loss/tok 3.2720 (3.1332)	Learning Rate [7.8125e-05]
3: TRAIN [4][2290/6832]	Time 0.114 (0.105)	Data 0.00084 (0.00093)	Tok/s 53844 (59970)	Loss/tok 3.1461 (3.1302)	Learning Rate [7.8125e-05]
0: TRAIN [4][2290/6832]	Time 0.114 (0.105)	Data 0.00086 (0.00092)	Tok/s 53056 (58643)	Loss/tok 3.2941 (3.1384)	Learning Rate [7.8125e-05]
1: TRAIN [4][2300/6832]	Time 0.059 (0.105)	Data 0.00092 (0.00092)	Tok/s 47691 (59101)	Loss/tok 2.6558 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][2300/6832]	Time 0.059 (0.105)	Data 0.00089 (0.00094)	Tok/s 47641 (59491)	Loss/tok 2.5965 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][2300/6832]	Time 0.059 (0.105)	Data 0.00086 (0.00093)	Tok/s 48094 (59954)	Loss/tok 2.8120 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][2300/6832]	Time 0.059 (0.105)	Data 0.00094 (0.00092)	Tok/s 47162 (58620)	Loss/tok 2.5550 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][2310/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 67574 (59519)	Loss/tok 3.3229 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][2310/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00092)	Tok/s 67508 (59127)	Loss/tok 3.2653 (3.1326)	Learning Rate [7.8125e-05]
3: TRAIN [4][2310/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 68141 (59981)	Loss/tok 3.3090 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][2310/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00092)	Tok/s 67520 (58648)	Loss/tok 3.3846 (3.1383)	Learning Rate [7.8125e-05]
1: TRAIN [4][2320/6832]	Time 0.073 (0.105)	Data 0.00086 (0.00092)	Tok/s 52357 (59109)	Loss/tok 2.8478 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][2320/6832]	Time 0.073 (0.105)	Data 0.00087 (0.00094)	Tok/s 52367 (59500)	Loss/tok 2.7682 (3.1352)	Learning Rate [7.8125e-05]
0: TRAIN [4][2320/6832]	Time 0.073 (0.105)	Data 0.00089 (0.00092)	Tok/s 51259 (58631)	Loss/tok 2.8821 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][2320/6832]	Time 0.073 (0.105)	Data 0.00086 (0.00093)	Tok/s 52404 (59961)	Loss/tok 3.0944 (3.1302)	Learning Rate [7.8125e-05]
2: TRAIN [4][2330/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 79469 (59503)	Loss/tok 3.1249 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][2330/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 79692 (59965)	Loss/tok 3.1824 (3.1301)	Learning Rate [7.8125e-05]
1: TRAIN [4][2330/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00092)	Tok/s 78608 (59111)	Loss/tok 3.1644 (3.1324)	Learning Rate [7.8125e-05]
0: TRAIN [4][2330/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 78567 (58630)	Loss/tok 3.2724 (3.1383)	Learning Rate [7.8125e-05]
2: TRAIN [4][2340/6832]	Time 0.092 (0.105)	Data 0.00097 (0.00094)	Tok/s 52736 (59511)	Loss/tok 2.8986 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][2340/6832]	Time 0.092 (0.105)	Data 0.00092 (0.00092)	Tok/s 52647 (59120)	Loss/tok 3.0830 (3.1327)	Learning Rate [7.8125e-05]
0: TRAIN [4][2340/6832]	Time 0.092 (0.105)	Data 0.00093 (0.00092)	Tok/s 51708 (58639)	Loss/tok 2.9596 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][2340/6832]	Time 0.092 (0.105)	Data 0.00116 (0.00093)	Tok/s 52733 (59973)	Loss/tok 3.0117 (3.1303)	Learning Rate [7.8125e-05]
1: TRAIN [4][2350/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00092)	Tok/s 63657 (59123)	Loss/tok 3.3801 (3.1328)	Learning Rate [7.8125e-05]
0: TRAIN [4][2350/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00092)	Tok/s 63656 (58643)	Loss/tok 3.0732 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][2350/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00093)	Tok/s 64612 (59975)	Loss/tok 3.3449 (3.1302)	Learning Rate [7.8125e-05]
2: TRAIN [4][2350/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 63883 (59514)	Loss/tok 3.1541 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][2360/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00092)	Tok/s 58557 (59125)	Loss/tok 3.1109 (3.1328)	Learning Rate [7.8125e-05]
0: TRAIN [4][2360/6832]	Time 0.116 (0.105)	Data 0.00088 (0.00092)	Tok/s 58545 (58646)	Loss/tok 3.1028 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][2360/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00094)	Tok/s 58513 (59515)	Loss/tok 3.3484 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][2360/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00093)	Tok/s 59543 (59977)	Loss/tok 3.1968 (3.1301)	Learning Rate [7.8125e-05]
1: TRAIN [4][2370/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00092)	Tok/s 51783 (59138)	Loss/tok 2.9652 (3.1329)	Learning Rate [7.8125e-05]
3: TRAIN [4][2370/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00093)	Tok/s 52920 (59992)	Loss/tok 3.2115 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][2370/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00092)	Tok/s 51824 (58654)	Loss/tok 3.0246 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][2370/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00094)	Tok/s 52109 (59530)	Loss/tok 3.2257 (3.1352)	Learning Rate [7.8125e-05]
2: TRAIN [4][2380/6832]	Time 0.080 (0.105)	Data 0.00101 (0.00094)	Tok/s 54623 (59535)	Loss/tok 3.0308 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][2380/6832]	Time 0.080 (0.105)	Data 0.00090 (0.00092)	Tok/s 54475 (59142)	Loss/tok 2.9561 (3.1329)	Learning Rate [7.8125e-05]
3: TRAIN [4][2380/6832]	Time 0.080 (0.105)	Data 0.00097 (0.00093)	Tok/s 54634 (59997)	Loss/tok 2.9263 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][2380/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00092)	Tok/s 54453 (58658)	Loss/tok 3.0738 (3.1385)	Learning Rate [7.8125e-05]
1: TRAIN [4][2390/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00092)	Tok/s 83322 (59147)	Loss/tok 3.1893 (3.1330)	Learning Rate [7.8125e-05]
2: TRAIN [4][2390/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00094)	Tok/s 84028 (59540)	Loss/tok 3.0933 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][2390/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 84330 (60000)	Loss/tok 3.0149 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][2390/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00092)	Tok/s 83029 (58664)	Loss/tok 3.0857 (3.1385)	Learning Rate [7.8125e-05]
1: TRAIN [4][2400/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00092)	Tok/s 63621 (59149)	Loss/tok 3.1621 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][2400/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00094)	Tok/s 63624 (59542)	Loss/tok 3.3043 (3.1353)	Learning Rate [7.8125e-05]
0: TRAIN [4][2400/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00092)	Tok/s 63481 (58667)	Loss/tok 3.1835 (3.1383)	Learning Rate [7.8125e-05]
3: TRAIN [4][2400/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00093)	Tok/s 63610 (60002)	Loss/tok 3.3227 (3.1302)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][2410/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00092)	Tok/s 52336 (59149)	Loss/tok 3.2373 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][2410/6832]	Time 0.115 (0.105)	Data 0.00098 (0.00094)	Tok/s 52327 (59540)	Loss/tok 3.3324 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][2410/6832]	Time 0.115 (0.105)	Data 0.00093 (0.00093)	Tok/s 52324 (60000)	Loss/tok 3.0724 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][2410/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00092)	Tok/s 52317 (58669)	Loss/tok 3.1714 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][2420/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00092)	Tok/s 54179 (59142)	Loss/tok 3.0539 (3.1334)	Learning Rate [7.8125e-05]
0: TRAIN [4][2420/6832]	Time 0.111 (0.105)	Data 0.00094 (0.00092)	Tok/s 54191 (58663)	Loss/tok 3.2116 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][2420/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00094)	Tok/s 54169 (59532)	Loss/tok 3.1911 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][2420/6832]	Time 0.111 (0.105)	Data 0.00087 (0.00093)	Tok/s 54161 (59991)	Loss/tok 3.0255 (3.1304)	Learning Rate [7.8125e-05]
1: TRAIN [4][2430/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00092)	Tok/s 71607 (59152)	Loss/tok 3.1919 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][2430/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00092)	Tok/s 71623 (58674)	Loss/tok 3.2039 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][2430/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00093)	Tok/s 72565 (59999)	Loss/tok 3.1287 (3.1304)	Learning Rate [7.8125e-05]
2: TRAIN [4][2430/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00095)	Tok/s 72333 (59541)	Loss/tok 3.1832 (3.1360)	Learning Rate [7.8125e-05]
1: TRAIN [4][2440/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00092)	Tok/s 56069 (59158)	Loss/tok 3.0987 (3.1335)	Learning Rate [7.8125e-05]
3: TRAIN [4][2440/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00093)	Tok/s 57218 (60007)	Loss/tok 3.2130 (3.1304)	Learning Rate [7.8125e-05]
2: TRAIN [4][2440/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00095)	Tok/s 56850 (59548)	Loss/tok 3.1047 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][2440/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00092)	Tok/s 56069 (58679)	Loss/tok 3.0221 (3.1389)	Learning Rate [7.8125e-05]
1: TRAIN [4][2450/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00092)	Tok/s 54282 (59144)	Loss/tok 2.9625 (3.1330)	Learning Rate [7.8125e-05]
2: TRAIN [4][2450/6832]	Time 0.090 (0.105)	Data 0.00107 (0.00095)	Tok/s 54266 (59535)	Loss/tok 3.1566 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][2450/6832]	Time 0.090 (0.105)	Data 0.00106 (0.00093)	Tok/s 54449 (59995)	Loss/tok 3.0031 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][2450/6832]	Time 0.090 (0.105)	Data 0.00121 (0.00092)	Tok/s 54276 (58665)	Loss/tok 2.9230 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][2460/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 59963 (59560)	Loss/tok 3.1805 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][2460/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 60382 (60020)	Loss/tok 3.3550 (3.1306)	Learning Rate [7.8125e-05]
1: TRAIN [4][2460/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00092)	Tok/s 59364 (59169)	Loss/tok 3.3166 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][2460/6832]	Time 0.129 (0.105)	Data 0.00098 (0.00092)	Tok/s 59361 (58691)	Loss/tok 3.4426 (3.1388)	Learning Rate [7.8125e-05]
1: TRAIN [4][2470/6832]	Time 0.061 (0.105)	Data 0.00092 (0.00092)	Tok/s 46388 (59142)	Loss/tok 2.6759 (3.1333)	Learning Rate [7.8125e-05]
2: TRAIN [4][2470/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00095)	Tok/s 46368 (59532)	Loss/tok 2.6345 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][2470/6832]	Time 0.061 (0.105)	Data 0.00093 (0.00093)	Tok/s 47545 (59991)	Loss/tok 2.7522 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][2470/6832]	Time 0.061 (0.105)	Data 0.00098 (0.00092)	Tok/s 45168 (58664)	Loss/tok 2.5569 (3.1385)	Learning Rate [7.8125e-05]
1: TRAIN [4][2480/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00092)	Tok/s 79396 (59147)	Loss/tok 3.0983 (3.1329)	Learning Rate [7.8125e-05]
0: TRAIN [4][2480/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00092)	Tok/s 78831 (58669)	Loss/tok 3.2392 (3.1382)	Learning Rate [7.8125e-05]
2: TRAIN [4][2480/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00095)	Tok/s 79704 (59536)	Loss/tok 3.2637 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][2480/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 79882 (59995)	Loss/tok 3.1247 (3.1301)	Learning Rate [7.8125e-05]
2: TRAIN [4][2490/6832]	Time 0.072 (0.105)	Data 0.00092 (0.00095)	Tok/s 53649 (59531)	Loss/tok 2.9131 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][2490/6832]	Time 0.072 (0.105)	Data 0.00089 (0.00092)	Tok/s 53259 (59142)	Loss/tok 3.0130 (3.1328)	Learning Rate [7.8125e-05]
0: TRAIN [4][2490/6832]	Time 0.072 (0.105)	Data 0.00092 (0.00092)	Tok/s 51865 (58664)	Loss/tok 3.0170 (3.1386)	Learning Rate [7.8125e-05]
3: TRAIN [4][2490/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00093)	Tok/s 53595 (59990)	Loss/tok 2.8296 (3.1301)	Learning Rate [7.8125e-05]
2: TRAIN [4][2500/6832]	Time 0.070 (0.105)	Data 0.00091 (0.00095)	Tok/s 51047 (59524)	Loss/tok 3.0080 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][2500/6832]	Time 0.070 (0.105)	Data 0.00088 (0.00092)	Tok/s 51044 (59137)	Loss/tok 2.7720 (3.1326)	Learning Rate [7.8125e-05]
3: TRAIN [4][2500/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00093)	Tok/s 51869 (59982)	Loss/tok 3.0143 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2500/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00092)	Tok/s 51040 (58659)	Loss/tok 2.9250 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][2510/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00095)	Tok/s 52767 (59520)	Loss/tok 3.0035 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][2510/6832]	Time 0.075 (0.105)	Data 0.00095 (0.00093)	Tok/s 52778 (59980)	Loss/tok 3.0026 (3.1299)	Learning Rate [7.8125e-05]
1: TRAIN [4][2510/6832]	Time 0.075 (0.105)	Data 0.00094 (0.00092)	Tok/s 51801 (59133)	Loss/tok 2.8022 (3.1321)	Learning Rate [7.8125e-05]
0: TRAIN [4][2510/6832]	Time 0.075 (0.105)	Data 0.00099 (0.00092)	Tok/s 51093 (58655)	Loss/tok 3.1216 (3.1384)	Learning Rate [7.8125e-05]
1: TRAIN [4][2520/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00092)	Tok/s 58573 (59133)	Loss/tok 3.3868 (3.1323)	Learning Rate [7.8125e-05]
2: TRAIN [4][2520/6832]	Time 0.122 (0.105)	Data 0.00093 (0.00095)	Tok/s 59158 (59519)	Loss/tok 3.1055 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][2520/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00093)	Tok/s 59636 (59979)	Loss/tok 3.0716 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2520/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00092)	Tok/s 58581 (58654)	Loss/tok 3.2989 (3.1384)	Learning Rate [7.8125e-05]
1: TRAIN [4][2530/6832]	Time 0.056 (0.105)	Data 0.00088 (0.00092)	Tok/s 50402 (59141)	Loss/tok 2.5438 (3.1321)	Learning Rate [7.8125e-05]
0: TRAIN [4][2530/6832]	Time 0.056 (0.105)	Data 0.00093 (0.00092)	Tok/s 49181 (58664)	Loss/tok 2.5743 (3.1386)	Learning Rate [7.8125e-05]
2: TRAIN [4][2530/6832]	Time 0.056 (0.105)	Data 0.00100 (0.00095)	Tok/s 50301 (59528)	Loss/tok 2.6730 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][2530/6832]	Time 0.056 (0.105)	Data 0.00096 (0.00093)	Tok/s 51006 (59988)	Loss/tok 2.7735 (3.1302)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][2540/6832]	Time 0.109 (0.105)	Data 0.00102 (0.00092)	Tok/s 51810 (59135)	Loss/tok 3.0699 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][2540/6832]	Time 0.109 (0.105)	Data 0.00094 (0.00095)	Tok/s 51765 (59522)	Loss/tok 3.2440 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][2540/6832]	Time 0.109 (0.105)	Data 0.00103 (0.00092)	Tok/s 50766 (58657)	Loss/tok 2.9829 (3.1383)	Learning Rate [7.8125e-05]
3: TRAIN [4][2540/6832]	Time 0.109 (0.105)	Data 0.00094 (0.00093)	Tok/s 51753 (59982)	Loss/tok 3.0734 (3.1300)	Learning Rate [7.8125e-05]
2: TRAIN [4][2550/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 78871 (59520)	Loss/tok 3.2878 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][2550/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 79033 (59980)	Loss/tok 3.1576 (3.1299)	Learning Rate [7.8125e-05]
1: TRAIN [4][2550/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 78411 (59135)	Loss/tok 3.2489 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][2550/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00092)	Tok/s 77925 (58657)	Loss/tok 3.1345 (3.1384)	Learning Rate [7.8125e-05]
2: TRAIN [4][2560/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00095)	Tok/s 52372 (59533)	Loss/tok 3.0903 (3.1360)	Learning Rate [7.8125e-05]
1: TRAIN [4][2560/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00092)	Tok/s 52387 (59148)	Loss/tok 3.2541 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][2560/6832]	Time 0.100 (0.105)	Data 0.00091 (0.00092)	Tok/s 52056 (58670)	Loss/tok 2.9658 (3.1383)	Learning Rate [7.8125e-05]
3: TRAIN [4][2560/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00093)	Tok/s 52322 (59992)	Loss/tok 2.8599 (3.1297)	Learning Rate [7.8125e-05]
2: TRAIN [4][2570/6832]	Time 0.090 (0.105)	Data 0.00098 (0.00095)	Tok/s 53972 (59555)	Loss/tok 2.9664 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][2570/6832]	Time 0.090 (0.105)	Data 0.00097 (0.00092)	Tok/s 53058 (59170)	Loss/tok 3.0584 (3.1317)	Learning Rate [7.8125e-05]
3: TRAIN [4][2570/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00093)	Tok/s 53949 (60015)	Loss/tok 2.9592 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][2570/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00092)	Tok/s 52526 (58691)	Loss/tok 2.9370 (3.1380)	Learning Rate [7.8125e-05]
1: TRAIN [4][2580/6832]	Time 0.043 (0.105)	Data 0.00088 (0.00092)	Tok/s 33417 (59160)	Loss/tok 1.9763 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][2580/6832]	Time 0.043 (0.105)	Data 0.00093 (0.00095)	Tok/s 39003 (59548)	Loss/tok 1.9591 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][2580/6832]	Time 0.043 (0.105)	Data 0.00088 (0.00093)	Tok/s 42076 (60008)	Loss/tok 2.3285 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][2580/6832]	Time 0.043 (0.105)	Data 0.00085 (0.00092)	Tok/s 21599 (58677)	Loss/tok 1.7649 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][2590/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 73855 (59548)	Loss/tok 3.1325 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][2590/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00093)	Tok/s 73864 (60006)	Loss/tok 3.2158 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][2590/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00092)	Tok/s 73801 (59160)	Loss/tok 3.0908 (3.1318)	Learning Rate [7.8125e-05]
0: TRAIN [4][2590/6832]	Time 0.128 (0.105)	Data 0.00086 (0.00092)	Tok/s 72819 (58678)	Loss/tok 3.3268 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][2600/6832]	Time 0.124 (0.105)	Data 0.00102 (0.00095)	Tok/s 59022 (59544)	Loss/tok 3.3625 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][2600/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00092)	Tok/s 59055 (58663)	Loss/tok 3.1391 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][2600/6832]	Time 0.124 (0.105)	Data 0.00101 (0.00093)	Tok/s 59974 (60004)	Loss/tok 3.2257 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][2600/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00092)	Tok/s 59060 (59153)	Loss/tok 3.2718 (3.1318)	Learning Rate [7.8125e-05]
1: TRAIN [4][2610/6832]	Time 0.084 (0.105)	Data 0.00094 (0.00092)	Tok/s 50036 (59140)	Loss/tok 2.8368 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][2610/6832]	Time 0.084 (0.105)	Data 0.00095 (0.00095)	Tok/s 50015 (59531)	Loss/tok 2.8289 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][2610/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00093)	Tok/s 50014 (59990)	Loss/tok 2.8805 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][2610/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00092)	Tok/s 49468 (58651)	Loss/tok 2.9210 (3.1378)	Learning Rate [7.8125e-05]
1: TRAIN [4][2620/6832]	Time 0.104 (0.105)	Data 0.00094 (0.00092)	Tok/s 51497 (59149)	Loss/tok 3.1818 (3.1321)	Learning Rate [7.8125e-05]
2: TRAIN [4][2620/6832]	Time 0.104 (0.105)	Data 0.00097 (0.00095)	Tok/s 51489 (59539)	Loss/tok 3.0337 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][2620/6832]	Time 0.104 (0.105)	Data 0.00094 (0.00093)	Tok/s 51495 (59998)	Loss/tok 3.1041 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][2620/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00092)	Tok/s 51513 (58661)	Loss/tok 3.0137 (3.1381)	Learning Rate [7.8125e-05]
1: TRAIN [4][2630/6832]	Time 0.053 (0.105)	Data 0.00087 (0.00092)	Tok/s 45765 (59140)	Loss/tok 2.4225 (3.1320)	Learning Rate [7.8125e-05]
2: TRAIN [4][2630/6832]	Time 0.053 (0.105)	Data 0.00089 (0.00095)	Tok/s 45882 (59529)	Loss/tok 2.4317 (3.1352)	Learning Rate [7.8125e-05]
0: TRAIN [4][2630/6832]	Time 0.053 (0.105)	Data 0.00084 (0.00092)	Tok/s 43494 (58652)	Loss/tok 2.4802 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][2630/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00093)	Tok/s 48100 (59988)	Loss/tok 2.4977 (3.1296)	Learning Rate [7.8125e-05]
1: TRAIN [4][2640/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00092)	Tok/s 51552 (59122)	Loss/tok 3.1744 (3.1319)	Learning Rate [7.8125e-05]
2: TRAIN [4][2640/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00095)	Tok/s 51585 (59513)	Loss/tok 3.2059 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][2640/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00092)	Tok/s 51555 (58631)	Loss/tok 3.1219 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][2640/6832]	Time 0.114 (0.105)	Data 0.00097 (0.00093)	Tok/s 52506 (59973)	Loss/tok 3.3016 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][2650/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00092)	Tok/s 54573 (59120)	Loss/tok 2.8254 (3.1320)	Learning Rate [7.8125e-05]
2: TRAIN [4][2650/6832]	Time 0.077 (0.105)	Data 0.00098 (0.00095)	Tok/s 54572 (59510)	Loss/tok 2.9899 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][2650/6832]	Time 0.077 (0.105)	Data 0.00093 (0.00093)	Tok/s 54574 (59969)	Loss/tok 3.1092 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][2650/6832]	Time 0.077 (0.105)	Data 0.00088 (0.00092)	Tok/s 54608 (58629)	Loss/tok 2.9806 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][2660/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00093)	Tok/s 54862 (59965)	Loss/tok 2.8864 (3.1294)	Learning Rate [7.8125e-05]
2: TRAIN [4][2660/6832]	Time 0.083 (0.105)	Data 0.00095 (0.00095)	Tok/s 54023 (59506)	Loss/tok 3.0662 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][2660/6832]	Time 0.083 (0.105)	Data 0.00099 (0.00092)	Tok/s 54032 (59117)	Loss/tok 2.8751 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][2660/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00092)	Tok/s 54041 (58628)	Loss/tok 3.0264 (3.1375)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [4][2670/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00092)	Tok/s 60867 (59119)	Loss/tok 3.2440 (3.1321)	Learning Rate [7.8125e-05]
2: TRAIN [4][2670/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00095)	Tok/s 61383 (59509)	Loss/tok 3.2468 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][2670/6832]	Time 0.123 (0.105)	Data 0.00099 (0.00093)	Tok/s 61384 (59967)	Loss/tok 3.2023 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][2670/6832]	Time 0.123 (0.105)	Data 0.00093 (0.00092)	Tok/s 60348 (58631)	Loss/tok 3.1681 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][2680/6832]	Time 0.111 (0.105)	Data 0.00088 (0.00092)	Tok/s 52008 (59142)	Loss/tok 3.0537 (3.1321)	Learning Rate [7.8125e-05]
2: TRAIN [4][2680/6832]	Time 0.111 (0.105)	Data 0.00093 (0.00095)	Tok/s 52079 (59531)	Loss/tok 3.0698 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][2680/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00093)	Tok/s 52086 (59988)	Loss/tok 3.2101 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][2680/6832]	Time 0.111 (0.105)	Data 0.00091 (0.00092)	Tok/s 51806 (58654)	Loss/tok 3.1211 (3.1377)	Learning Rate [7.8125e-05]
2: TRAIN [4][2690/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00095)	Tok/s 60941 (59532)	Loss/tok 3.2658 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][2690/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00093)	Tok/s 60967 (59988)	Loss/tok 3.1503 (3.1299)	Learning Rate [7.8125e-05]
1: TRAIN [4][2690/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00092)	Tok/s 60900 (59144)	Loss/tok 3.4365 (3.1321)	Learning Rate [7.8125e-05]
0: TRAIN [4][2690/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00092)	Tok/s 59834 (58657)	Loss/tok 3.2452 (3.1378)	Learning Rate [7.8125e-05]
1: TRAIN [4][2700/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00092)	Tok/s 49101 (59135)	Loss/tok 2.5344 (3.1322)	Learning Rate [7.8125e-05]
3: TRAIN [4][2700/6832]	Time 0.053 (0.105)	Data 0.00091 (0.00093)	Tok/s 50722 (59979)	Loss/tok 2.6123 (3.1301)	Learning Rate [7.8125e-05]
2: TRAIN [4][2700/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00095)	Tok/s 50743 (59523)	Loss/tok 2.5503 (3.1356)	Learning Rate [7.8125e-05]
0: TRAIN [4][2700/6832]	Time 0.053 (0.105)	Data 0.00090 (0.00092)	Tok/s 48371 (58649)	Loss/tok 2.6862 (3.1377)	Learning Rate [7.8125e-05]
1: TRAIN [4][2710/6832]	Time 0.089 (0.105)	Data 0.00088 (0.00091)	Tok/s 51916 (59122)	Loss/tok 2.8015 (3.1320)	Learning Rate [7.8125e-05]
2: TRAIN [4][2710/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00095)	Tok/s 51957 (59512)	Loss/tok 3.1498 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][2710/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00093)	Tok/s 53172 (59968)	Loss/tok 3.2319 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][2710/6832]	Time 0.089 (0.105)	Data 0.00093 (0.00092)	Tok/s 51942 (58636)	Loss/tok 2.9724 (3.1374)	Learning Rate [7.8125e-05]
1: TRAIN [4][2720/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00091)	Tok/s 68197 (59108)	Loss/tok 3.1306 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][2720/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00095)	Tok/s 68745 (59496)	Loss/tok 3.2781 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][2720/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00093)	Tok/s 69143 (59954)	Loss/tok 3.3079 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][2720/6832]	Time 0.129 (0.105)	Data 0.00100 (0.00092)	Tok/s 68239 (58622)	Loss/tok 3.2996 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][2730/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00091)	Tok/s 51540 (59101)	Loss/tok 3.1842 (3.1322)	Learning Rate [7.8125e-05]
2: TRAIN [4][2730/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00095)	Tok/s 51561 (59491)	Loss/tok 3.2156 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][2730/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00093)	Tok/s 51949 (59949)	Loss/tok 3.1251 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2730/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00092)	Tok/s 51547 (58612)	Loss/tok 3.2948 (3.1375)	Learning Rate [7.8125e-05]
1: TRAIN [4][2740/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00091)	Tok/s 56536 (59085)	Loss/tok 3.1564 (3.1322)	Learning Rate [7.8125e-05]
2: TRAIN [4][2740/6832]	Time 0.124 (0.105)	Data 0.00095 (0.00095)	Tok/s 56568 (59475)	Loss/tok 3.2738 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][2740/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00092)	Tok/s 56556 (58597)	Loss/tok 3.2551 (3.1375)	Learning Rate [7.8125e-05]
3: TRAIN [4][2740/6832]	Time 0.124 (0.105)	Data 0.00093 (0.00093)	Tok/s 56551 (59934)	Loss/tok 3.1987 (3.1301)	Learning Rate [7.8125e-05]
1: TRAIN [4][2750/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00091)	Tok/s 53838 (59075)	Loss/tok 3.1139 (3.1323)	Learning Rate [7.8125e-05]
2: TRAIN [4][2750/6832]	Time 0.119 (0.105)	Data 0.00092 (0.00095)	Tok/s 54255 (59464)	Loss/tok 3.2041 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][2750/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00093)	Tok/s 54931 (59922)	Loss/tok 3.2403 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2750/6832]	Time 0.119 (0.105)	Data 0.00094 (0.00092)	Tok/s 53853 (58587)	Loss/tok 2.8731 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][2760/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00091)	Tok/s 51716 (59072)	Loss/tok 3.0849 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][2760/6832]	Time 0.097 (0.105)	Data 0.00092 (0.00095)	Tok/s 52653 (59461)	Loss/tok 3.1970 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][2760/6832]	Time 0.097 (0.105)	Data 0.00098 (0.00093)	Tok/s 52657 (59920)	Loss/tok 3.0516 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][2760/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00092)	Tok/s 51339 (58584)	Loss/tok 3.0843 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][2770/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00091)	Tok/s 57045 (59073)	Loss/tok 3.1167 (3.1327)	Learning Rate [7.8125e-05]
2: TRAIN [4][2770/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00095)	Tok/s 57122 (59461)	Loss/tok 3.2722 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][2770/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00093)	Tok/s 57125 (59920)	Loss/tok 3.0540 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2770/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00092)	Tok/s 57030 (58586)	Loss/tok 3.2564 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][2780/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00091)	Tok/s 76199 (59084)	Loss/tok 3.2999 (3.1327)	Learning Rate [7.8125e-05]
2: TRAIN [4][2780/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00095)	Tok/s 77095 (59472)	Loss/tok 3.2016 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][2780/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00093)	Tok/s 77184 (59931)	Loss/tok 3.1551 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][2780/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00092)	Tok/s 76193 (58598)	Loss/tok 3.1542 (3.1375)	Learning Rate [7.8125e-05]
1: TRAIN [4][2790/6832]	Time 0.074 (0.105)	Data 0.00100 (0.00091)	Tok/s 53202 (59070)	Loss/tok 3.0020 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][2790/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00095)	Tok/s 53804 (59458)	Loss/tok 2.8092 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][2790/6832]	Time 0.074 (0.105)	Data 0.00090 (0.00093)	Tok/s 53811 (59917)	Loss/tok 2.9515 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][2790/6832]	Time 0.074 (0.105)	Data 0.00110 (0.00092)	Tok/s 52217 (58585)	Loss/tok 2.9735 (3.1373)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [4][2800/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00091)	Tok/s 52722 (59085)	Loss/tok 2.8127 (3.1327)	Learning Rate [7.8125e-05]
2: TRAIN [4][2800/6832]	Time 0.075 (0.105)	Data 0.00096 (0.00095)	Tok/s 52699 (59473)	Loss/tok 3.0204 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][2800/6832]	Time 0.075 (0.105)	Data 0.00091 (0.00093)	Tok/s 52952 (59932)	Loss/tok 2.8731 (3.1302)	Learning Rate [7.8125e-05]
0: TRAIN [4][2800/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00092)	Tok/s 52732 (58599)	Loss/tok 2.9012 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][2810/6832]	Time 0.073 (0.105)	Data 0.00099 (0.00095)	Tok/s 52485 (59467)	Loss/tok 3.0130 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][2810/6832]	Time 0.073 (0.105)	Data 0.00095 (0.00093)	Tok/s 52466 (59927)	Loss/tok 3.0269 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][2810/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00092)	Tok/s 50671 (58589)	Loss/tok 2.9343 (3.1374)	Learning Rate [7.8125e-05]
1: TRAIN [4][2810/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00091)	Tok/s 51147 (59077)	Loss/tok 2.9325 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][2820/6832]	Time 0.078 (0.105)	Data 0.00099 (0.00095)	Tok/s 51604 (59462)	Loss/tok 3.0463 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][2820/6832]	Time 0.078 (0.105)	Data 0.00097 (0.00093)	Tok/s 52295 (59921)	Loss/tok 3.0024 (3.1300)	Learning Rate [7.8125e-05]
1: TRAIN [4][2820/6832]	Time 0.078 (0.105)	Data 0.00099 (0.00091)	Tok/s 50647 (59072)	Loss/tok 2.9554 (3.1325)	Learning Rate [7.8125e-05]
0: TRAIN [4][2820/6832]	Time 0.078 (0.105)	Data 0.00098 (0.00092)	Tok/s 50688 (58585)	Loss/tok 2.9606 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][2830/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00091)	Tok/s 72156 (59077)	Loss/tok 3.2971 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][2830/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00095)	Tok/s 72978 (59466)	Loss/tok 3.3124 (3.1351)	Learning Rate [7.8125e-05]
0: TRAIN [4][2830/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00092)	Tok/s 72045 (58590)	Loss/tok 3.2022 (3.1373)	Learning Rate [7.8125e-05]
3: TRAIN [4][2830/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00093)	Tok/s 72986 (59924)	Loss/tok 3.1658 (3.1301)	Learning Rate [7.8125e-05]
3: TRAIN [4][2840/6832]	Time 0.073 (0.105)	Data 0.00104 (0.00093)	Tok/s 52261 (59906)	Loss/tok 2.8801 (3.1301)	Learning Rate [7.8125e-05]
2: TRAIN [4][2840/6832]	Time 0.074 (0.105)	Data 0.00106 (0.00095)	Tok/s 52223 (59449)	Loss/tok 3.0028 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][2840/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00091)	Tok/s 52293 (59061)	Loss/tok 2.9296 (3.1329)	Learning Rate [7.8125e-05]
0: TRAIN [4][2840/6832]	Time 0.073 (0.105)	Data 0.00096 (0.00092)	Tok/s 50715 (58574)	Loss/tok 2.8613 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][2850/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00091)	Tok/s 63905 (59047)	Loss/tok 3.3763 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][2850/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 63884 (59435)	Loss/tok 3.2364 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][2850/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00092)	Tok/s 63939 (58560)	Loss/tok 3.4160 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][2850/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00093)	Tok/s 63884 (59892)	Loss/tok 3.2192 (3.1298)	Learning Rate [7.8125e-05]
1: TRAIN [4][2860/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00091)	Tok/s 90782 (59048)	Loss/tok 3.0043 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][2860/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00095)	Tok/s 92169 (59435)	Loss/tok 3.0308 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][2860/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00092)	Tok/s 89835 (58562)	Loss/tok 3.0099 (3.1369)	Learning Rate [7.8125e-05]
3: TRAIN [4][2860/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00093)	Tok/s 94292 (59893)	Loss/tok 3.0050 (3.1297)	Learning Rate [7.8125e-05]
2: TRAIN [4][2870/6832]	Time 0.126 (0.105)	Data 0.00104 (0.00095)	Tok/s 66106 (59440)	Loss/tok 3.2821 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][2870/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00093)	Tok/s 66089 (59897)	Loss/tok 3.3791 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][2870/6832]	Time 0.126 (0.105)	Data 0.00102 (0.00092)	Tok/s 65429 (58562)	Loss/tok 3.2906 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][2870/6832]	Time 0.126 (0.105)	Data 0.00097 (0.00091)	Tok/s 66066 (59051)	Loss/tok 3.2006 (3.1328)	Learning Rate [7.8125e-05]
3: TRAIN [4][2880/6832]	Time 0.103 (0.105)	Data 0.00092 (0.00093)	Tok/s 50840 (59899)	Loss/tok 2.9976 (3.1298)	Learning Rate [7.8125e-05]
2: TRAIN [4][2880/6832]	Time 0.103 (0.105)	Data 0.00095 (0.00095)	Tok/s 50834 (59443)	Loss/tok 3.0697 (3.1345)	Learning Rate [7.8125e-05]
1: TRAIN [4][2880/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00091)	Tok/s 50824 (59053)	Loss/tok 2.9124 (3.1326)	Learning Rate [7.8125e-05]
0: TRAIN [4][2880/6832]	Time 0.103 (0.105)	Data 0.00098 (0.00092)	Tok/s 50839 (58564)	Loss/tok 3.0955 (3.1368)	Learning Rate [7.8125e-05]
1: TRAIN [4][2890/6832]	Time 0.098 (0.105)	Data 0.00087 (0.00091)	Tok/s 52364 (59049)	Loss/tok 2.9812 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][2890/6832]	Time 0.098 (0.105)	Data 0.00089 (0.00095)	Tok/s 52347 (59437)	Loss/tok 3.0013 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][2890/6832]	Time 0.098 (0.105)	Data 0.00086 (0.00093)	Tok/s 52360 (59892)	Loss/tok 3.1420 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][2890/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00092)	Tok/s 52353 (58560)	Loss/tok 3.0662 (3.1368)	Learning Rate [7.8125e-05]
1: TRAIN [4][2900/6832]	Time 0.114 (0.105)	Data 0.00091 (0.00091)	Tok/s 54042 (59045)	Loss/tok 3.0430 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][2900/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00095)	Tok/s 54046 (59433)	Loss/tok 3.2863 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][2900/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00093)	Tok/s 54170 (59888)	Loss/tok 3.1794 (3.1298)	Learning Rate [7.8125e-05]
0: TRAIN [4][2900/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00092)	Tok/s 53115 (58557)	Loss/tok 3.2005 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][2910/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00091)	Tok/s 64327 (59035)	Loss/tok 3.2950 (3.1327)	Learning Rate [7.8125e-05]
3: TRAIN [4][2910/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00093)	Tok/s 64558 (59878)	Loss/tok 3.1951 (3.1296)	Learning Rate [7.8125e-05]
2: TRAIN [4][2910/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00095)	Tok/s 64538 (59423)	Loss/tok 3.2284 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][2910/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00092)	Tok/s 63636 (58546)	Loss/tok 3.2263 (3.1367)	Learning Rate [7.8125e-05]
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][2920/6832]	Time 0.086 (0.105)	Data 0.00108 (0.00095)	Tok/s 53640 (59408)	Loss/tok 3.0622 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][2920/6832]	Time 0.086 (0.105)	Data 0.00090 (0.00091)	Tok/s 53265 (59021)	Loss/tok 2.9182 (3.1326)	Learning Rate [7.8125e-05]
3: TRAIN [4][2920/6832]	Time 0.086 (0.105)	Data 0.00108 (0.00093)	Tok/s 53599 (59863)	Loss/tok 3.1338 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][2920/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00092)	Tok/s 52135 (58533)	Loss/tok 3.3237 (3.1367)	Learning Rate [7.8125e-05]
1: TRAIN [4][2930/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00091)	Tok/s 75014 (59022)	Loss/tok 3.3208 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][2930/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 75048 (59409)	Loss/tok 3.2166 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][2930/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00093)	Tok/s 75727 (59865)	Loss/tok 3.0615 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][2930/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00092)	Tok/s 74679 (58534)	Loss/tok 3.0890 (3.1367)	Learning Rate [7.8125e-05]
3: TRAIN [4][2940/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00093)	Tok/s 74155 (59886)	Loss/tok 3.0519 (3.1291)	Learning Rate [7.8125e-05]
2: TRAIN [4][2940/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00095)	Tok/s 74143 (59430)	Loss/tok 3.1738 (3.1343)	Learning Rate [7.8125e-05]
1: TRAIN [4][2940/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00091)	Tok/s 73765 (59043)	Loss/tok 3.3158 (3.1327)	Learning Rate [7.8125e-05]
0: TRAIN [4][2940/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00092)	Tok/s 73147 (58555)	Loss/tok 3.2314 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][2950/6832]	Time 0.120 (0.105)	Data 0.00097 (0.00095)	Tok/s 60907 (59418)	Loss/tok 3.1083 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][2950/6832]	Time 0.120 (0.105)	Data 0.00093 (0.00093)	Tok/s 60918 (59874)	Loss/tok 3.1633 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][2950/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00091)	Tok/s 60902 (59031)	Loss/tok 3.2504 (3.1326)	Learning Rate [7.8125e-05]
0: TRAIN [4][2950/6832]	Time 0.120 (0.105)	Data 0.00102 (0.00092)	Tok/s 60904 (58546)	Loss/tok 3.1508 (3.1370)	Learning Rate [7.8125e-05]
1: TRAIN [4][2960/6832]	Time 0.060 (0.105)	Data 0.00091 (0.00091)	Tok/s 43789 (59021)	Loss/tok 2.7152 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][2960/6832]	Time 0.060 (0.105)	Data 0.00091 (0.00095)	Tok/s 44975 (59407)	Loss/tok 2.6113 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][2960/6832]	Time 0.060 (0.105)	Data 0.00088 (0.00093)	Tok/s 44965 (59862)	Loss/tok 2.4467 (3.1290)	Learning Rate [7.8125e-05]
0: TRAIN [4][2960/6832]	Time 0.060 (0.105)	Data 0.00093 (0.00092)	Tok/s 42728 (58535)	Loss/tok 2.6183 (3.1368)	Learning Rate [7.8125e-05]
1: TRAIN [4][2970/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00091)	Tok/s 53472 (59011)	Loss/tok 3.0551 (3.1324)	Learning Rate [7.8125e-05]
3: TRAIN [4][2970/6832]	Time 0.086 (0.105)	Data 0.00090 (0.00093)	Tok/s 54181 (59855)	Loss/tok 3.0847 (3.1289)	Learning Rate [7.8125e-05]
2: TRAIN [4][2970/6832]	Time 0.086 (0.105)	Data 0.00096 (0.00095)	Tok/s 53496 (59399)	Loss/tok 3.0978 (3.1338)	Learning Rate [7.8125e-05]
0: TRAIN [4][2970/6832]	Time 0.086 (0.105)	Data 0.00094 (0.00092)	Tok/s 53471 (58524)	Loss/tok 3.1558 (3.1367)	Learning Rate [7.8125e-05]
1: TRAIN [4][2980/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00092)	Tok/s 59046 (59017)	Loss/tok 3.3127 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][2980/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 59152 (59404)	Loss/tok 3.1270 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][2980/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00093)	Tok/s 60019 (59859)	Loss/tok 3.2935 (3.1290)	Learning Rate [7.8125e-05]
0: TRAIN [4][2980/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00092)	Tok/s 59054 (58530)	Loss/tok 3.1381 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][2990/6832]	Time 0.098 (0.105)	Data 0.00089 (0.00091)	Tok/s 53363 (59003)	Loss/tok 3.0376 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][2990/6832]	Time 0.098 (0.105)	Data 0.00094 (0.00095)	Tok/s 53375 (59390)	Loss/tok 3.0404 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][2990/6832]	Time 0.098 (0.105)	Data 0.00088 (0.00093)	Tok/s 53364 (59845)	Loss/tok 3.2417 (3.1289)	Learning Rate [7.8125e-05]
0: TRAIN [4][2990/6832]	Time 0.098 (0.105)	Data 0.00093 (0.00092)	Tok/s 52522 (58517)	Loss/tok 3.1859 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3000/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00091)	Tok/s 75757 (59006)	Loss/tok 3.1667 (3.1327)	Learning Rate [7.8125e-05]
2: TRAIN [4][3000/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00095)	Tok/s 76351 (59393)	Loss/tok 3.2313 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][3000/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00093)	Tok/s 76338 (59848)	Loss/tok 3.1839 (3.1290)	Learning Rate [7.8125e-05]
0: TRAIN [4][3000/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00092)	Tok/s 75391 (58519)	Loss/tok 3.2899 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][3010/6832]	Time 0.050 (0.105)	Data 0.00085 (0.00091)	Tok/s 48652 (58991)	Loss/tok 2.5244 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][3010/6832]	Time 0.050 (0.105)	Data 0.00092 (0.00095)	Tok/s 48598 (59381)	Loss/tok 2.4878 (3.1337)	Learning Rate [7.8125e-05]
3: TRAIN [4][3010/6832]	Time 0.050 (0.105)	Data 0.00089 (0.00093)	Tok/s 50975 (59836)	Loss/tok 2.5786 (3.1288)	Learning Rate [7.8125e-05]
0: TRAIN [4][3010/6832]	Time 0.050 (0.105)	Data 0.00095 (0.00092)	Tok/s 46185 (58501)	Loss/tok 2.4548 (3.1370)	Learning Rate [7.8125e-05]
1: TRAIN [4][3020/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00091)	Tok/s 61735 (59005)	Loss/tok 3.3004 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][3020/6832]	Time 0.126 (0.105)	Data 0.00104 (0.00095)	Tok/s 61746 (59395)	Loss/tok 3.2447 (3.1335)	Learning Rate [7.8125e-05]
3: TRAIN [4][3020/6832]	Time 0.126 (0.105)	Data 0.00102 (0.00093)	Tok/s 62391 (59850)	Loss/tok 3.2942 (3.1288)	Learning Rate [7.8125e-05]
0: TRAIN [4][3020/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00092)	Tok/s 61766 (58516)	Loss/tok 3.4621 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3030/6832]	Time 0.086 (0.105)	Data 0.00087 (0.00091)	Tok/s 53454 (58996)	Loss/tok 3.0394 (3.1325)	Learning Rate [7.8125e-05]
3: TRAIN [4][3030/6832]	Time 0.086 (0.105)	Data 0.00090 (0.00093)	Tok/s 53716 (59840)	Loss/tok 2.9803 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [4][3030/6832]	Time 0.086 (0.105)	Data 0.00092 (0.00095)	Tok/s 53701 (59386)	Loss/tok 3.1392 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][3030/6832]	Time 0.086 (0.105)	Data 0.00092 (0.00092)	Tok/s 52210 (58507)	Loss/tok 3.0662 (3.1370)	Learning Rate [7.8125e-05]
1: TRAIN [4][3040/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00091)	Tok/s 63008 (59012)	Loss/tok 3.1818 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][3040/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00095)	Tok/s 62983 (59401)	Loss/tok 3.4377 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][3040/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00092)	Tok/s 63037 (58523)	Loss/tok 3.2873 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][3040/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00093)	Tok/s 62972 (59856)	Loss/tok 3.4743 (3.1289)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
3: TRAIN [4][3050/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00093)	Tok/s 65711 (59865)	Loss/tok 3.2236 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [4][3050/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00095)	Tok/s 65704 (59409)	Loss/tok 3.2137 (3.1339)	Learning Rate [7.8125e-05]
1: TRAIN [4][3050/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00091)	Tok/s 65718 (59020)	Loss/tok 3.2336 (3.1325)	Learning Rate [7.8125e-05]
0: TRAIN [4][3050/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00092)	Tok/s 65673 (58531)	Loss/tok 3.2536 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][3060/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00095)	Tok/s 53219 (59404)	Loss/tok 3.0233 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][3060/6832]	Time 0.087 (0.105)	Data 0.00093 (0.00093)	Tok/s 53241 (59858)	Loss/tok 3.0406 (3.1289)	Learning Rate [7.8125e-05]
1: TRAIN [4][3060/6832]	Time 0.087 (0.105)	Data 0.00099 (0.00091)	Tok/s 52391 (59015)	Loss/tok 3.2224 (3.1327)	Learning Rate [7.8125e-05]
0: TRAIN [4][3060/6832]	Time 0.087 (0.105)	Data 0.00100 (0.00092)	Tok/s 51790 (58527)	Loss/tok 3.0212 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3070/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00091)	Tok/s 53805 (58997)	Loss/tok 3.2663 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][3070/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00095)	Tok/s 53798 (59385)	Loss/tok 3.3416 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][3070/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00093)	Tok/s 53792 (59839)	Loss/tok 3.2216 (3.1289)	Learning Rate [7.8125e-05]
0: TRAIN [4][3070/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00092)	Tok/s 53816 (58510)	Loss/tok 3.1950 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][3080/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00095)	Tok/s 71279 (59400)	Loss/tok 3.2411 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][3080/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00093)	Tok/s 72080 (59853)	Loss/tok 3.1222 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][3080/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00091)	Tok/s 71256 (59013)	Loss/tok 3.2190 (3.1332)	Learning Rate [7.8125e-05]
0: TRAIN [4][3080/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00092)	Tok/s 71250 (58526)	Loss/tok 3.3034 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][3090/6832]	Time 0.118 (0.105)	Data 0.00100 (0.00091)	Tok/s 55231 (59004)	Loss/tok 3.2670 (3.1331)	Learning Rate [7.8125e-05]
3: TRAIN [4][3090/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00093)	Tok/s 55218 (59844)	Loss/tok 3.0428 (3.1290)	Learning Rate [7.8125e-05]
2: TRAIN [4][3090/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00095)	Tok/s 55208 (59391)	Loss/tok 3.0792 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [4][3090/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00092)	Tok/s 55154 (58517)	Loss/tok 3.1574 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][3100/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00091)	Tok/s 72880 (59011)	Loss/tok 3.3454 (3.1336)	Learning Rate [7.8125e-05]
2: TRAIN [4][3100/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00095)	Tok/s 73273 (59399)	Loss/tok 3.3723 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][3100/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 73267 (59852)	Loss/tok 3.3404 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][3100/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00092)	Tok/s 72333 (58522)	Loss/tok 3.3666 (3.1375)	Learning Rate [7.8125e-05]
3: TRAIN [4][3110/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00093)	Tok/s 84446 (59855)	Loss/tok 3.0363 (3.1294)	Learning Rate [7.8125e-05]
2: TRAIN [4][3110/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 83689 (59401)	Loss/tok 3.1500 (3.1343)	Learning Rate [7.8125e-05]
1: TRAIN [4][3110/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00091)	Tok/s 83429 (59011)	Loss/tok 3.2089 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][3110/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00092)	Tok/s 82741 (58518)	Loss/tok 3.2188 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][3120/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00092)	Tok/s 62690 (59017)	Loss/tok 3.1889 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [4][3120/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00092)	Tok/s 62681 (58524)	Loss/tok 3.1573 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][3120/6832]	Time 0.119 (0.105)	Data 0.00093 (0.00095)	Tok/s 62619 (59406)	Loss/tok 3.2831 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3120/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00093)	Tok/s 62614 (59860)	Loss/tok 3.1853 (3.1296)	Learning Rate [7.8125e-05]
2: TRAIN [4][3130/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 69961 (59404)	Loss/tok 3.1663 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3130/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00093)	Tok/s 70778 (59856)	Loss/tok 3.2825 (3.1296)	Learning Rate [7.8125e-05]
1: TRAIN [4][3130/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00092)	Tok/s 69955 (59015)	Loss/tok 3.3042 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][3130/6832]	Time 0.130 (0.105)	Data 0.00093 (0.00092)	Tok/s 69932 (58522)	Loss/tok 3.1785 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][3140/6832]	Time 0.118 (0.105)	Data 0.00112 (0.00092)	Tok/s 53103 (59022)	Loss/tok 3.4213 (3.1341)	Learning Rate [7.8125e-05]
2: TRAIN [4][3140/6832]	Time 0.118 (0.105)	Data 0.00110 (0.00095)	Tok/s 53078 (59411)	Loss/tok 3.0235 (3.1345)	Learning Rate [7.8125e-05]
0: TRAIN [4][3140/6832]	Time 0.118 (0.105)	Data 0.00112 (0.00092)	Tok/s 53078 (58529)	Loss/tok 3.0553 (3.1374)	Learning Rate [7.8125e-05]
3: TRAIN [4][3140/6832]	Time 0.118 (0.105)	Data 0.00105 (0.00093)	Tok/s 53068 (59864)	Loss/tok 3.2405 (3.1295)	Learning Rate [7.8125e-05]
3: TRAIN [4][3150/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00093)	Tok/s 53790 (59861)	Loss/tok 3.3545 (3.1294)	Learning Rate [7.8125e-05]
2: TRAIN [4][3150/6832]	Time 0.102 (0.105)	Data 0.00090 (0.00095)	Tok/s 52667 (59408)	Loss/tok 3.0337 (3.1345)	Learning Rate [7.8125e-05]
1: TRAIN [4][3150/6832]	Time 0.102 (0.105)	Data 0.00089 (0.00092)	Tok/s 52501 (59019)	Loss/tok 3.2333 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][3150/6832]	Time 0.102 (0.105)	Data 0.00092 (0.00092)	Tok/s 52460 (58527)	Loss/tok 3.0870 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][3160/6832]	Time 0.116 (0.105)	Data 0.00090 (0.00095)	Tok/s 56311 (59416)	Loss/tok 3.1618 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3160/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00093)	Tok/s 57280 (59870)	Loss/tok 3.1850 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][3160/6832]	Time 0.116 (0.105)	Data 0.00098 (0.00092)	Tok/s 56336 (59028)	Loss/tok 3.1465 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][3160/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00092)	Tok/s 56385 (58537)	Loss/tok 3.0747 (3.1374)	Learning Rate [7.8125e-05]
1: TRAIN [4][3170/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00092)	Tok/s 63970 (59033)	Loss/tok 3.3410 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][3170/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00095)	Tok/s 64077 (59421)	Loss/tok 3.2120 (3.1343)	Learning Rate [7.8125e-05]
0: TRAIN [4][3170/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00092)	Tok/s 63992 (58542)	Loss/tok 3.2405 (3.1374)	Learning Rate [7.8125e-05]
3: TRAIN [4][3170/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00093)	Tok/s 64186 (59876)	Loss/tok 3.1740 (3.1293)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][3180/6832]	Time 0.096 (0.105)	Data 0.00096 (0.00095)	Tok/s 53332 (59408)	Loss/tok 3.0047 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3180/6832]	Time 0.096 (0.105)	Data 0.00096 (0.00093)	Tok/s 53346 (59862)	Loss/tok 3.1018 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][3180/6832]	Time 0.096 (0.105)	Data 0.00104 (0.00092)	Tok/s 53327 (59020)	Loss/tok 3.0580 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][3180/6832]	Time 0.096 (0.105)	Data 0.00108 (0.00092)	Tok/s 52805 (58530)	Loss/tok 2.9944 (3.1373)	Learning Rate [7.8125e-05]
2: TRAIN [4][3190/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00095)	Tok/s 52690 (59400)	Loss/tok 3.1010 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3190/6832]	Time 0.087 (0.105)	Data 0.00086 (0.00093)	Tok/s 52683 (59855)	Loss/tok 3.0683 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][3190/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00092)	Tok/s 51320 (59010)	Loss/tok 2.8106 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][3190/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00092)	Tok/s 51217 (58517)	Loss/tok 3.0182 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][3200/6832]	Time 0.067 (0.105)	Data 0.00088 (0.00095)	Tok/s 50272 (59390)	Loss/tok 3.0071 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3200/6832]	Time 0.067 (0.105)	Data 0.00085 (0.00093)	Tok/s 51770 (59845)	Loss/tok 2.7770 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][3200/6832]	Time 0.067 (0.105)	Data 0.00087 (0.00092)	Tok/s 49760 (59001)	Loss/tok 2.9873 (3.1338)	Learning Rate [7.8125e-05]
0: TRAIN [4][3200/6832]	Time 0.067 (0.105)	Data 0.00088 (0.00092)	Tok/s 49791 (58509)	Loss/tok 2.7976 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][3210/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00095)	Tok/s 52788 (59384)	Loss/tok 2.9751 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3210/6832]	Time 0.090 (0.105)	Data 0.00087 (0.00093)	Tok/s 52801 (59838)	Loss/tok 3.1261 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][3210/6832]	Time 0.090 (0.105)	Data 0.00089 (0.00092)	Tok/s 52782 (58995)	Loss/tok 3.0312 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [4][3210/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00092)	Tok/s 52825 (58505)	Loss/tok 3.0690 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][3220/6832]	Time 0.085 (0.105)	Data 0.00101 (0.00095)	Tok/s 54352 (59388)	Loss/tok 3.1354 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][3220/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00093)	Tok/s 54363 (59840)	Loss/tok 3.1069 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][3220/6832]	Time 0.085 (0.105)	Data 0.00090 (0.00092)	Tok/s 54279 (59000)	Loss/tok 3.0195 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][3220/6832]	Time 0.085 (0.105)	Data 0.00092 (0.00092)	Tok/s 54297 (58509)	Loss/tok 2.9300 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][3230/6832]	Time 0.071 (0.105)	Data 0.00096 (0.00095)	Tok/s 52283 (59396)	Loss/tok 2.8177 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][3230/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00093)	Tok/s 52295 (59848)	Loss/tok 2.9944 (3.1296)	Learning Rate [7.8125e-05]
1: TRAIN [4][3230/6832]	Time 0.071 (0.105)	Data 0.00094 (0.00092)	Tok/s 52256 (59008)	Loss/tok 2.8542 (3.1338)	Learning Rate [7.8125e-05]
0: TRAIN [4][3230/6832]	Time 0.071 (0.105)	Data 0.00093 (0.00092)	Tok/s 50667 (58517)	Loss/tok 2.7548 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][3240/6832]	Time 0.127 (0.105)	Data 0.00086 (0.00093)	Tok/s 62604 (59858)	Loss/tok 3.2314 (3.1295)	Learning Rate [7.8125e-05]
2: TRAIN [4][3240/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00095)	Tok/s 62603 (59407)	Loss/tok 3.3073 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3240/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00092)	Tok/s 62346 (59018)	Loss/tok 3.1190 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][3240/6832]	Time 0.127 (0.105)	Data 0.00094 (0.00092)	Tok/s 61598 (58528)	Loss/tok 3.3955 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3250/6832]	Time 0.062 (0.105)	Data 0.00088 (0.00092)	Tok/s 49712 (59008)	Loss/tok 2.8329 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][3250/6832]	Time 0.062 (0.105)	Data 0.00093 (0.00092)	Tok/s 49672 (58518)	Loss/tok 2.6183 (3.1373)	Learning Rate [7.8125e-05]
2: TRAIN [4][3250/6832]	Time 0.062 (0.105)	Data 0.00089 (0.00095)	Tok/s 51113 (59397)	Loss/tok 2.7328 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][3250/6832]	Time 0.062 (0.105)	Data 0.00085 (0.00093)	Tok/s 51514 (59848)	Loss/tok 2.7470 (3.1294)	Learning Rate [7.8125e-05]
2: TRAIN [4][3260/6832]	Time 0.128 (0.105)	Data 0.00089 (0.00095)	Tok/s 67785 (59421)	Loss/tok 3.2502 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3260/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00093)	Tok/s 67807 (59872)	Loss/tok 3.2082 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][3260/6832]	Time 0.128 (0.105)	Data 0.00093 (0.00092)	Tok/s 67814 (59033)	Loss/tok 3.0833 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][3260/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00092)	Tok/s 67809 (58544)	Loss/tok 3.2876 (3.1374)	Learning Rate [7.8125e-05]
1: TRAIN [4][3270/6832]	Time 0.047 (0.105)	Data 0.00095 (0.00092)	Tok/s 43471 (59031)	Loss/tok 2.3666 (3.1338)	Learning Rate [7.8125e-05]
2: TRAIN [4][3270/6832]	Time 0.047 (0.105)	Data 0.00097 (0.00095)	Tok/s 46126 (59420)	Loss/tok 2.3512 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3270/6832]	Time 0.047 (0.105)	Data 0.00094 (0.00093)	Tok/s 47079 (59872)	Loss/tok 2.2171 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][3270/6832]	Time 0.047 (0.105)	Data 0.00102 (0.00092)	Tok/s 41228 (58542)	Loss/tok 2.2547 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][3280/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00092)	Tok/s 86021 (59032)	Loss/tok 3.0062 (3.1336)	Learning Rate [7.8125e-05]
2: TRAIN [4][3280/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00095)	Tok/s 86424 (59421)	Loss/tok 3.2219 (3.1347)	Learning Rate [7.8125e-05]
3: TRAIN [4][3280/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00093)	Tok/s 87326 (59872)	Loss/tok 3.1329 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][3280/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00092)	Tok/s 85511 (58544)	Loss/tok 3.0123 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][3290/6832]	Time 0.063 (0.105)	Data 0.00103 (0.00092)	Tok/s 48416 (59018)	Loss/tok 2.7942 (3.1334)	Learning Rate [7.8125e-05]
2: TRAIN [4][3290/6832]	Time 0.063 (0.105)	Data 0.00093 (0.00095)	Tok/s 49252 (59408)	Loss/tok 2.9157 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3290/6832]	Time 0.063 (0.105)	Data 0.00089 (0.00093)	Tok/s 50415 (59859)	Loss/tok 2.8315 (3.1290)	Learning Rate [7.8125e-05]
0: TRAIN [4][3290/6832]	Time 0.063 (0.105)	Data 0.00102 (0.00092)	Tok/s 48430 (58530)	Loss/tok 2.7114 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][3300/6832]	Time 0.065 (0.105)	Data 0.00094 (0.00095)	Tok/s 50963 (59407)	Loss/tok 2.8573 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3300/6832]	Time 0.065 (0.105)	Data 0.00087 (0.00093)	Tok/s 51081 (59859)	Loss/tok 2.9855 (3.1288)	Learning Rate [7.8125e-05]
1: TRAIN [4][3300/6832]	Time 0.065 (0.105)	Data 0.00090 (0.00092)	Tok/s 49088 (59018)	Loss/tok 2.7384 (3.1334)	Learning Rate [7.8125e-05]
0: TRAIN [4][3300/6832]	Time 0.065 (0.105)	Data 0.00095 (0.00092)	Tok/s 49098 (58531)	Loss/tok 2.7957 (3.1371)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][3310/6832]	Time 0.109 (0.105)	Data 0.00092 (0.00095)	Tok/s 56152 (59424)	Loss/tok 3.0316 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3310/6832]	Time 0.109 (0.105)	Data 0.00086 (0.00093)	Tok/s 56153 (59876)	Loss/tok 3.0660 (3.1287)	Learning Rate [7.8125e-05]
1: TRAIN [4][3310/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00092)	Tok/s 55217 (59034)	Loss/tok 3.0060 (3.1333)	Learning Rate [7.8125e-05]
0: TRAIN [4][3310/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00092)	Tok/s 54945 (58548)	Loss/tok 3.1620 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3320/6832]	Time 0.098 (0.105)	Data 0.00091 (0.00092)	Tok/s 52363 (59034)	Loss/tok 2.9763 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][3320/6832]	Time 0.098 (0.105)	Data 0.00096 (0.00095)	Tok/s 52382 (59424)	Loss/tok 2.9531 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3320/6832]	Time 0.098 (0.105)	Data 0.00090 (0.00093)	Tok/s 52390 (59878)	Loss/tok 3.0424 (3.1286)	Learning Rate [7.8125e-05]
0: TRAIN [4][3320/6832]	Time 0.098 (0.105)	Data 0.00092 (0.00092)	Tok/s 51077 (58544)	Loss/tok 3.0978 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][3330/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00093)	Tok/s 68154 (59900)	Loss/tok 3.1903 (3.1284)	Learning Rate [7.8125e-05]
2: TRAIN [4][3330/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00095)	Tok/s 68014 (59447)	Loss/tok 3.3134 (3.1343)	Learning Rate [7.8125e-05]
1: TRAIN [4][3330/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00092)	Tok/s 68010 (59056)	Loss/tok 3.0823 (3.1328)	Learning Rate [7.8125e-05]
0: TRAIN [4][3330/6832]	Time 0.128 (0.105)	Data 0.00095 (0.00092)	Tok/s 68025 (58566)	Loss/tok 3.3279 (3.1368)	Learning Rate [7.8125e-05]
3: TRAIN [4][3340/6832]	Time 0.104 (0.105)	Data 0.00084 (0.00093)	Tok/s 51791 (59889)	Loss/tok 3.1416 (3.1282)	Learning Rate [7.8125e-05]
2: TRAIN [4][3340/6832]	Time 0.104 (0.105)	Data 0.00095 (0.00095)	Tok/s 51777 (59436)	Loss/tok 3.1216 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3340/6832]	Time 0.104 (0.105)	Data 0.00091 (0.00092)	Tok/s 51798 (59045)	Loss/tok 3.2594 (3.1326)	Learning Rate [7.8125e-05]
0: TRAIN [4][3340/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00092)	Tok/s 51102 (58555)	Loss/tok 3.1350 (3.1368)	Learning Rate [7.8125e-05]
1: TRAIN [4][3350/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00092)	Tok/s 53246 (59043)	Loss/tok 3.2203 (3.1325)	Learning Rate [7.8125e-05]
0: TRAIN [4][3350/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00093)	Tok/s 53242 (58553)	Loss/tok 3.0316 (3.1366)	Learning Rate [7.8125e-05]
3: TRAIN [4][3350/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00093)	Tok/s 53225 (59887)	Loss/tok 3.1767 (3.1280)	Learning Rate [7.8125e-05]
2: TRAIN [4][3350/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00095)	Tok/s 53219 (59433)	Loss/tok 3.1396 (3.1339)	Learning Rate [7.8125e-05]
1: TRAIN [4][3360/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00092)	Tok/s 81602 (59047)	Loss/tok 3.1522 (3.1324)	Learning Rate [7.8125e-05]
0: TRAIN [4][3360/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00093)	Tok/s 80981 (58557)	Loss/tok 3.0964 (3.1367)	Learning Rate [7.8125e-05]
2: TRAIN [4][3360/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 81769 (59437)	Loss/tok 3.0842 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][3360/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00093)	Tok/s 82469 (59891)	Loss/tok 2.9549 (3.1280)	Learning Rate [7.8125e-05]
1: TRAIN [4][3370/6832]	Time 0.061 (0.105)	Data 0.00097 (0.00092)	Tok/s 48254 (59055)	Loss/tok 2.8225 (3.1323)	Learning Rate [7.8125e-05]
2: TRAIN [4][3370/6832]	Time 0.061 (0.105)	Data 0.00094 (0.00095)	Tok/s 48543 (59445)	Loss/tok 2.7206 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][3370/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00093)	Tok/s 50280 (59898)	Loss/tok 2.6579 (3.1281)	Learning Rate [7.8125e-05]
0: TRAIN [4][3370/6832]	Time 0.061 (0.105)	Data 0.00097 (0.00093)	Tok/s 48243 (58565)	Loss/tok 2.6778 (3.1369)	Learning Rate [7.8125e-05]
2: TRAIN [4][3380/6832]	Time 0.054 (0.105)	Data 0.00101 (0.00095)	Tok/s 51849 (59452)	Loss/tok 2.8331 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][3380/6832]	Time 0.054 (0.105)	Data 0.00094 (0.00093)	Tok/s 53088 (59906)	Loss/tok 2.6643 (3.1280)	Learning Rate [7.8125e-05]
1: TRAIN [4][3380/6832]	Time 0.054 (0.105)	Data 0.00090 (0.00092)	Tok/s 51719 (59063)	Loss/tok 2.7163 (3.1325)	Learning Rate [7.8125e-05]
0: TRAIN [4][3380/6832]	Time 0.054 (0.105)	Data 0.00090 (0.00093)	Tok/s 51061 (58574)	Loss/tok 2.7433 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][3390/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00092)	Tok/s 60023 (59076)	Loss/tok 3.3076 (3.1325)	Learning Rate [7.8125e-05]
0: TRAIN [4][3390/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00093)	Tok/s 59994 (58587)	Loss/tok 3.2926 (3.1369)	Learning Rate [7.8125e-05]
3: TRAIN [4][3390/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00093)	Tok/s 59946 (59920)	Loss/tok 3.1737 (3.1281)	Learning Rate [7.8125e-05]
2: TRAIN [4][3390/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00095)	Tok/s 59928 (59466)	Loss/tok 3.4112 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][3400/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00093)	Tok/s 54652 (59910)	Loss/tok 3.3317 (3.1282)	Learning Rate [7.8125e-05]
2: TRAIN [4][3400/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00095)	Tok/s 54654 (59456)	Loss/tok 3.2158 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3400/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00092)	Tok/s 54656 (59066)	Loss/tok 3.1767 (3.1325)	Learning Rate [7.8125e-05]
0: TRAIN [4][3400/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00093)	Tok/s 54650 (58578)	Loss/tok 3.1219 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3410/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00092)	Tok/s 57888 (59052)	Loss/tok 3.1276 (3.1324)	Learning Rate [7.8125e-05]
0: TRAIN [4][3410/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00093)	Tok/s 57866 (58564)	Loss/tok 3.2414 (3.1369)	Learning Rate [7.8125e-05]
2: TRAIN [4][3410/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00095)	Tok/s 58623 (59442)	Loss/tok 3.2731 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][3410/6832]	Time 0.122 (0.105)	Data 0.00085 (0.00093)	Tok/s 58869 (59896)	Loss/tok 3.1671 (3.1281)	Learning Rate [7.8125e-05]
3: TRAIN [4][3420/6832]	Time 0.114 (0.105)	Data 0.00083 (0.00093)	Tok/s 53984 (59896)	Loss/tok 3.3676 (3.1284)	Learning Rate [7.8125e-05]
2: TRAIN [4][3420/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00095)	Tok/s 53991 (59442)	Loss/tok 3.1036 (3.1343)	Learning Rate [7.8125e-05]
1: TRAIN [4][3420/6832]	Time 0.114 (0.105)	Data 0.00092 (0.00092)	Tok/s 52950 (59052)	Loss/tok 3.0615 (3.1322)	Learning Rate [7.8125e-05]
0: TRAIN [4][3420/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00093)	Tok/s 52824 (58566)	Loss/tok 3.0479 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][3430/6832]	Time 0.058 (0.105)	Data 0.00093 (0.00092)	Tok/s 48545 (59041)	Loss/tok 2.5586 (3.1322)	Learning Rate [7.8125e-05]
0: TRAIN [4][3430/6832]	Time 0.058 (0.105)	Data 0.00097 (0.00093)	Tok/s 46379 (58555)	Loss/tok 2.5739 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][3430/6832]	Time 0.058 (0.105)	Data 0.00098 (0.00095)	Tok/s 48602 (59430)	Loss/tok 2.6959 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][3430/6832]	Time 0.058 (0.105)	Data 0.00097 (0.00093)	Tok/s 48553 (59883)	Loss/tok 2.7345 (3.1283)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][3440/6832]	Time 0.107 (0.105)	Data 0.00102 (0.00095)	Tok/s 53737 (59431)	Loss/tok 3.1056 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3440/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00093)	Tok/s 53734 (59884)	Loss/tok 3.1485 (3.1285)	Learning Rate [7.8125e-05]
1: TRAIN [4][3440/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00092)	Tok/s 53664 (59042)	Loss/tok 3.0174 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][3440/6832]	Time 0.107 (0.105)	Data 0.00095 (0.00093)	Tok/s 53694 (58556)	Loss/tok 3.3163 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][3450/6832]	Time 0.097 (0.105)	Data 0.00093 (0.00095)	Tok/s 54370 (59422)	Loss/tok 3.0582 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][3450/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00093)	Tok/s 54347 (59873)	Loss/tok 3.0664 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][3450/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00092)	Tok/s 54369 (59032)	Loss/tok 3.0559 (3.1319)	Learning Rate [7.8125e-05]
0: TRAIN [4][3450/6832]	Time 0.096 (0.105)	Data 0.00095 (0.00093)	Tok/s 54384 (58546)	Loss/tok 3.0887 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][3460/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00095)	Tok/s 79416 (59437)	Loss/tok 3.2275 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3460/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00093)	Tok/s 79734 (59889)	Loss/tok 3.0627 (3.1281)	Learning Rate [7.8125e-05]
0: TRAIN [4][3460/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00093)	Tok/s 78480 (58563)	Loss/tok 3.1675 (3.1368)	Learning Rate [7.8125e-05]
1: TRAIN [4][3460/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00092)	Tok/s 78929 (59047)	Loss/tok 3.1923 (3.1319)	Learning Rate [7.8125e-05]
2: TRAIN [4][3470/6832]	Time 0.110 (0.105)	Data 0.00095 (0.00095)	Tok/s 53351 (59439)	Loss/tok 3.0920 (3.1346)	Learning Rate [7.8125e-05]
3: TRAIN [4][3470/6832]	Time 0.110 (0.105)	Data 0.00085 (0.00093)	Tok/s 53341 (59890)	Loss/tok 3.1738 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][3470/6832]	Time 0.110 (0.105)	Data 0.00099 (0.00092)	Tok/s 53315 (59050)	Loss/tok 3.0976 (3.1319)	Learning Rate [7.8125e-05]
0: TRAIN [4][3470/6832]	Time 0.110 (0.105)	Data 0.00090 (0.00093)	Tok/s 53360 (58566)	Loss/tok 3.1438 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3480/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00092)	Tok/s 73920 (59057)	Loss/tok 3.0854 (3.1317)	Learning Rate [7.8125e-05]
3: TRAIN [4][3480/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00093)	Tok/s 74872 (59898)	Loss/tok 3.1832 (3.1284)	Learning Rate [7.8125e-05]
0: TRAIN [4][3480/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00093)	Tok/s 73901 (58573)	Loss/tok 3.2341 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][3480/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 74051 (59447)	Loss/tok 3.2333 (3.1346)	Learning Rate [7.8125e-05]
3: TRAIN [4][3490/6832]	Time 0.097 (0.105)	Data 0.00084 (0.00093)	Tok/s 52692 (59905)	Loss/tok 3.1813 (3.1283)	Learning Rate [7.8125e-05]
2: TRAIN [4][3490/6832]	Time 0.097 (0.105)	Data 0.00088 (0.00095)	Tok/s 52701 (59454)	Loss/tok 3.0247 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3490/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00092)	Tok/s 52722 (59065)	Loss/tok 3.1528 (3.1318)	Learning Rate [7.8125e-05]
0: TRAIN [4][3490/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00093)	Tok/s 52726 (58582)	Loss/tok 3.2209 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][3500/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00095)	Tok/s 51871 (59451)	Loss/tok 3.0761 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][3500/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00093)	Tok/s 51883 (59901)	Loss/tok 3.2457 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][3500/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00092)	Tok/s 51899 (59061)	Loss/tok 3.1282 (3.1316)	Learning Rate [7.8125e-05]
0: TRAIN [4][3500/6832]	Time 0.101 (0.105)	Data 0.00096 (0.00093)	Tok/s 50881 (58578)	Loss/tok 3.1175 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][3510/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00092)	Tok/s 54476 (59051)	Loss/tok 3.1940 (3.1315)	Learning Rate [7.8125e-05]
3: TRAIN [4][3510/6832]	Time 0.115 (0.105)	Data 0.00084 (0.00093)	Tok/s 54452 (59892)	Loss/tok 3.2405 (3.1284)	Learning Rate [7.8125e-05]
2: TRAIN [4][3510/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00095)	Tok/s 54438 (59441)	Loss/tok 3.3706 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][3510/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00093)	Tok/s 54449 (58568)	Loss/tok 3.1113 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][3520/6832]	Time 0.069 (0.105)	Data 0.00093 (0.00095)	Tok/s 50724 (59449)	Loss/tok 2.9969 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][3520/6832]	Time 0.069 (0.105)	Data 0.00089 (0.00093)	Tok/s 51827 (59902)	Loss/tok 2.8651 (3.1284)	Learning Rate [7.8125e-05]
1: TRAIN [4][3520/6832]	Time 0.069 (0.105)	Data 0.00090 (0.00092)	Tok/s 49893 (59059)	Loss/tok 2.9671 (3.1314)	Learning Rate [7.8125e-05]
0: TRAIN [4][3520/6832]	Time 0.069 (0.105)	Data 0.00095 (0.00093)	Tok/s 49938 (58577)	Loss/tok 2.6500 (3.1367)	Learning Rate [7.8125e-05]
1: TRAIN [4][3530/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00092)	Tok/s 73617 (59064)	Loss/tok 3.2581 (3.1316)	Learning Rate [7.8125e-05]
2: TRAIN [4][3530/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 73611 (59453)	Loss/tok 3.3669 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][3530/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00093)	Tok/s 74043 (59905)	Loss/tok 3.1104 (3.1284)	Learning Rate [7.8125e-05]
0: TRAIN [4][3530/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00093)	Tok/s 73169 (58582)	Loss/tok 3.2470 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][3540/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00095)	Tok/s 52737 (59455)	Loss/tok 3.1067 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][3540/6832]	Time 0.109 (0.105)	Data 0.00086 (0.00093)	Tok/s 52730 (59907)	Loss/tok 3.1614 (3.1284)	Learning Rate [7.8125e-05]
1: TRAIN [4][3540/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00092)	Tok/s 52721 (59067)	Loss/tok 3.1847 (3.1315)	Learning Rate [7.8125e-05]
0: TRAIN [4][3540/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00093)	Tok/s 52731 (58585)	Loss/tok 3.0225 (3.1365)	Learning Rate [7.8125e-05]
2: TRAIN [4][3550/6832]	Time 0.101 (0.105)	Data 0.00092 (0.00095)	Tok/s 50884 (59448)	Loss/tok 2.9956 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3550/6832]	Time 0.101 (0.105)	Data 0.00090 (0.00093)	Tok/s 51864 (59900)	Loss/tok 3.1229 (3.1284)	Learning Rate [7.8125e-05]
1: TRAIN [4][3550/6832]	Time 0.101 (0.105)	Data 0.00107 (0.00092)	Tok/s 50597 (59060)	Loss/tok 3.1572 (3.1316)	Learning Rate [7.8125e-05]
0: TRAIN [4][3550/6832]	Time 0.101 (0.105)	Data 0.00109 (0.00093)	Tok/s 50588 (58579)	Loss/tok 3.0669 (3.1366)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][3560/6832]	Time 0.120 (0.105)	Data 0.00111 (0.00095)	Tok/s 54453 (59451)	Loss/tok 3.1767 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][3560/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00092)	Tok/s 54374 (59064)	Loss/tok 3.2511 (3.1314)	Learning Rate [7.8125e-05]
0: TRAIN [4][3560/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00093)	Tok/s 54507 (58584)	Loss/tok 3.3012 (3.1368)	Learning Rate [7.8125e-05]
3: TRAIN [4][3560/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00093)	Tok/s 55122 (59903)	Loss/tok 3.2040 (3.1284)	Learning Rate [7.8125e-05]
2: TRAIN [4][3570/6832]	Time 0.044 (0.105)	Data 0.00089 (0.00095)	Tok/s 37190 (59457)	Loss/tok 2.0902 (3.1345)	Learning Rate [7.8125e-05]
1: TRAIN [4][3570/6832]	Time 0.044 (0.105)	Data 0.00090 (0.00092)	Tok/s 30596 (59068)	Loss/tok 2.1359 (3.1313)	Learning Rate [7.8125e-05]
3: TRAIN [4][3570/6832]	Time 0.044 (0.105)	Data 0.00087 (0.00093)	Tok/s 40447 (59910)	Loss/tok 2.2539 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3570/6832]	Time 0.044 (0.105)	Data 0.00090 (0.00093)	Tok/s 19984 (58586)	Loss/tok 1.7162 (3.1367)	Learning Rate [7.8125e-05]
2: TRAIN [4][3580/6832]	Time 0.046 (0.105)	Data 0.00089 (0.00095)	Tok/s 47097 (59445)	Loss/tok 2.4093 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][3580/6832]	Time 0.046 (0.105)	Data 0.00091 (0.00092)	Tok/s 45235 (59054)	Loss/tok 2.4051 (3.1314)	Learning Rate [7.8125e-05]
0: TRAIN [4][3580/6832]	Time 0.046 (0.105)	Data 0.00089 (0.00093)	Tok/s 42359 (58569)	Loss/tok 2.3580 (3.1367)	Learning Rate [7.8125e-05]
3: TRAIN [4][3580/6832]	Time 0.046 (0.105)	Data 0.00090 (0.00093)	Tok/s 48868 (59899)	Loss/tok 2.3830 (3.1281)	Learning Rate [7.8125e-05]
2: TRAIN [4][3590/6832]	Time 0.114 (0.105)	Data 0.00087 (0.00095)	Tok/s 57441 (59453)	Loss/tok 3.0957 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][3590/6832]	Time 0.114 (0.105)	Data 0.00088 (0.00092)	Tok/s 57070 (59063)	Loss/tok 3.2426 (3.1315)	Learning Rate [7.8125e-05]
3: TRAIN [4][3590/6832]	Time 0.114 (0.105)	Data 0.00083 (0.00093)	Tok/s 58215 (59907)	Loss/tok 3.0884 (3.1282)	Learning Rate [7.8125e-05]
0: TRAIN [4][3590/6832]	Time 0.114 (0.105)	Data 0.00089 (0.00093)	Tok/s 57048 (58579)	Loss/tok 3.3393 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][3600/6832]	Time 0.065 (0.105)	Data 0.00088 (0.00095)	Tok/s 51702 (59455)	Loss/tok 2.9012 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3600/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00092)	Tok/s 51343 (59065)	Loss/tok 2.7183 (3.1314)	Learning Rate [7.8125e-05]
3: TRAIN [4][3600/6832]	Time 0.065 (0.105)	Data 0.00086 (0.00093)	Tok/s 53372 (59908)	Loss/tok 2.8001 (3.1280)	Learning Rate [7.8125e-05]
0: TRAIN [4][3600/6832]	Time 0.065 (0.105)	Data 0.00100 (0.00093)	Tok/s 51368 (58581)	Loss/tok 2.7765 (3.1367)	Learning Rate [7.8125e-05]
2: TRAIN [4][3610/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00095)	Tok/s 51443 (59455)	Loss/tok 3.1129 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][3610/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00093)	Tok/s 51447 (59908)	Loss/tok 3.1593 (3.1281)	Learning Rate [7.8125e-05]
1: TRAIN [4][3610/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00092)	Tok/s 51436 (59066)	Loss/tok 3.2025 (3.1314)	Learning Rate [7.8125e-05]
0: TRAIN [4][3610/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00093)	Tok/s 51455 (58582)	Loss/tok 3.1427 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][3620/6832]	Time 0.093 (0.105)	Data 0.00094 (0.00092)	Tok/s 53706 (59066)	Loss/tok 3.0436 (3.1314)	Learning Rate [7.8125e-05]
2: TRAIN [4][3620/6832]	Time 0.093 (0.105)	Data 0.00092 (0.00095)	Tok/s 53636 (59455)	Loss/tok 3.1656 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][3620/6832]	Time 0.093 (0.105)	Data 0.00091 (0.00093)	Tok/s 53658 (59908)	Loss/tok 3.0720 (3.1281)	Learning Rate [7.8125e-05]
0: TRAIN [4][3620/6832]	Time 0.093 (0.105)	Data 0.00097 (0.00093)	Tok/s 53723 (58583)	Loss/tok 3.0241 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][3630/6832]	Time 0.063 (0.105)	Data 0.00093 (0.00095)	Tok/s 51721 (59452)	Loss/tok 2.7201 (3.1340)	Learning Rate [7.8125e-05]
1: TRAIN [4][3630/6832]	Time 0.063 (0.105)	Data 0.00089 (0.00092)	Tok/s 50854 (59063)	Loss/tok 2.7948 (3.1314)	Learning Rate [7.8125e-05]
3: TRAIN [4][3630/6832]	Time 0.063 (0.105)	Data 0.00085 (0.00093)	Tok/s 52884 (59904)	Loss/tok 2.8664 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3630/6832]	Time 0.063 (0.105)	Data 0.00095 (0.00093)	Tok/s 50706 (58580)	Loss/tok 2.8777 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][3640/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00095)	Tok/s 73171 (59458)	Loss/tok 3.3619 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3640/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00092)	Tok/s 72731 (59068)	Loss/tok 3.2242 (3.1315)	Learning Rate [7.8125e-05]
3: TRAIN [4][3640/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00093)	Tok/s 73191 (59910)	Loss/tok 3.3988 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3640/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00093)	Tok/s 72122 (58586)	Loss/tok 3.1547 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][3650/6832]	Time 0.110 (0.105)	Data 0.00086 (0.00095)	Tok/s 53418 (59454)	Loss/tok 3.1397 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3650/6832]	Time 0.110 (0.105)	Data 0.00089 (0.00092)	Tok/s 53013 (59064)	Loss/tok 3.0565 (3.1315)	Learning Rate [7.8125e-05]
3: TRAIN [4][3650/6832]	Time 0.110 (0.105)	Data 0.00085 (0.00093)	Tok/s 53420 (59904)	Loss/tok 3.1313 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3650/6832]	Time 0.110 (0.105)	Data 0.00101 (0.00093)	Tok/s 52221 (58583)	Loss/tok 3.2779 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3660/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00092)	Tok/s 52631 (59069)	Loss/tok 3.1020 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][3660/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00095)	Tok/s 52640 (59457)	Loss/tok 2.9757 (3.1343)	Learning Rate [7.8125e-05]
0: TRAIN [4][3660/6832]	Time 0.090 (0.105)	Data 0.00100 (0.00093)	Tok/s 52585 (58589)	Loss/tok 2.9408 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][3660/6832]	Time 0.092 (0.105)	Data 0.00097 (0.00093)	Tok/s 51619 (59907)	Loss/tok 3.0157 (3.1284)	Learning Rate [7.8125e-05]
1: TRAIN [4][3670/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00092)	Tok/s 63810 (59081)	Loss/tok 3.2216 (3.1319)	Learning Rate [7.8125e-05]
2: TRAIN [4][3670/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 63763 (59468)	Loss/tok 3.2050 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][3670/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00093)	Tok/s 64195 (59919)	Loss/tok 3.0624 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3670/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00093)	Tok/s 63794 (58601)	Loss/tok 3.0918 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][3680/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00095)	Tok/s 63075 (59458)	Loss/tok 3.1256 (3.1342)	Learning Rate [7.8125e-05]
1: TRAIN [4][3680/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 63075 (59071)	Loss/tok 3.3351 (3.1318)	Learning Rate [7.8125e-05]
3: TRAIN [4][3680/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00093)	Tok/s 63530 (59908)	Loss/tok 3.4358 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3680/6832]	Time 0.130 (0.105)	Data 0.00103 (0.00093)	Tok/s 63066 (58591)	Loss/tok 3.3340 (3.1372)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][3690/6832]	Time 0.083 (0.105)	Data 0.00092 (0.00095)	Tok/s 54124 (59454)	Loss/tok 2.9869 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][3690/6832]	Time 0.083 (0.105)	Data 0.00098 (0.00092)	Tok/s 54109 (59068)	Loss/tok 2.8984 (3.1317)	Learning Rate [7.8125e-05]
0: TRAIN [4][3690/6832]	Time 0.083 (0.105)	Data 0.00098 (0.00093)	Tok/s 54108 (58589)	Loss/tok 2.9428 (3.1371)	Learning Rate [7.8125e-05]
3: TRAIN [4][3690/6832]	Time 0.083 (0.105)	Data 0.00099 (0.00093)	Tok/s 54128 (59904)	Loss/tok 3.0394 (3.1284)	Learning Rate [7.8125e-05]
2: TRAIN [4][3700/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00095)	Tok/s 55832 (59441)	Loss/tok 3.2312 (3.1343)	Learning Rate [7.8125e-05]
1: TRAIN [4][3700/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00092)	Tok/s 55574 (59055)	Loss/tok 3.2221 (3.1318)	Learning Rate [7.8125e-05]
3: TRAIN [4][3700/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00093)	Tok/s 56704 (59892)	Loss/tok 3.2265 (3.1282)	Learning Rate [7.8125e-05]
0: TRAIN [4][3700/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00093)	Tok/s 54708 (58576)	Loss/tok 3.2493 (3.1369)	Learning Rate [7.8125e-05]
2: TRAIN [4][3710/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00095)	Tok/s 74616 (59435)	Loss/tok 3.3474 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][3710/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00092)	Tok/s 74440 (59049)	Loss/tok 3.2130 (3.1318)	Learning Rate [7.8125e-05]
3: TRAIN [4][3710/6832]	Time 0.129 (0.105)	Data 0.00105 (0.00093)	Tok/s 76097 (59886)	Loss/tok 3.2181 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3710/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00093)	Tok/s 74315 (58570)	Loss/tok 3.2184 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3720/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00092)	Tok/s 68960 (59049)	Loss/tok 3.2346 (3.1320)	Learning Rate [7.8125e-05]
2: TRAIN [4][3720/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00095)	Tok/s 68936 (59434)	Loss/tok 3.2829 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][3720/6832]	Time 0.130 (0.105)	Data 0.00100 (0.00093)	Tok/s 68869 (58571)	Loss/tok 3.1930 (3.1371)	Learning Rate [7.8125e-05]
3: TRAIN [4][3720/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00093)	Tok/s 69217 (59885)	Loss/tok 3.1540 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][3730/6832]	Time 0.047 (0.105)	Data 0.00085 (0.00092)	Tok/s 43461 (59042)	Loss/tok 2.3574 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][3730/6832]	Time 0.047 (0.105)	Data 0.00087 (0.00095)	Tok/s 45889 (59427)	Loss/tok 2.4988 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][3730/6832]	Time 0.047 (0.105)	Data 0.00090 (0.00093)	Tok/s 40854 (58564)	Loss/tok 2.1924 (3.1368)	Learning Rate [7.8125e-05]
3: TRAIN [4][3730/6832]	Time 0.047 (0.105)	Data 0.00090 (0.00093)	Tok/s 46938 (59878)	Loss/tok 2.2844 (3.1282)	Learning Rate [7.8125e-05]
2: TRAIN [4][3740/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00095)	Tok/s 59081 (59435)	Loss/tok 3.2796 (3.1346)	Learning Rate [7.8125e-05]
1: TRAIN [4][3740/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00092)	Tok/s 59046 (59050)	Loss/tok 3.2775 (3.1319)	Learning Rate [7.8125e-05]
3: TRAIN [4][3740/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00093)	Tok/s 59103 (59886)	Loss/tok 3.4887 (3.1284)	Learning Rate [7.8125e-05]
0: TRAIN [4][3740/6832]	Time 0.126 (0.105)	Data 0.00102 (0.00093)	Tok/s 58546 (58573)	Loss/tok 3.3493 (3.1369)	Learning Rate [7.8125e-05]
1: TRAIN [4][3750/6832]	Time 0.057 (0.105)	Data 0.00089 (0.00092)	Tok/s 42792 (59060)	Loss/tok 2.4793 (3.1319)	Learning Rate [7.8125e-05]
0: TRAIN [4][3750/6832]	Time 0.057 (0.105)	Data 0.00087 (0.00093)	Tok/s 41099 (58583)	Loss/tok 2.4448 (3.1369)	Learning Rate [7.8125e-05]
2: TRAIN [4][3750/6832]	Time 0.057 (0.105)	Data 0.00090 (0.00095)	Tok/s 43691 (59445)	Loss/tok 2.6339 (3.1347)	Learning Rate [7.8125e-05]
3: TRAIN [4][3750/6832]	Time 0.057 (0.105)	Data 0.00090 (0.00093)	Tok/s 44977 (59896)	Loss/tok 2.5639 (3.1285)	Learning Rate [7.8125e-05]
2: TRAIN [4][3760/6832]	Time 0.089 (0.105)	Data 0.00089 (0.00095)	Tok/s 54903 (59444)	Loss/tok 2.9494 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][3760/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00092)	Tok/s 54852 (59060)	Loss/tok 3.1041 (3.1320)	Learning Rate [7.8125e-05]
3: TRAIN [4][3760/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00093)	Tok/s 54969 (59895)	Loss/tok 3.0177 (3.1285)	Learning Rate [7.8125e-05]
0: TRAIN [4][3760/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00093)	Tok/s 54868 (58583)	Loss/tok 3.2406 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3770/6832]	Time 0.124 (0.105)	Data 0.00086 (0.00092)	Tok/s 64919 (59059)	Loss/tok 3.2509 (3.1319)	Learning Rate [7.8125e-05]
2: TRAIN [4][3770/6832]	Time 0.124 (0.105)	Data 0.00085 (0.00095)	Tok/s 64878 (59443)	Loss/tok 3.2401 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][3770/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00093)	Tok/s 64913 (58583)	Loss/tok 3.2000 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][3770/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00093)	Tok/s 64900 (59893)	Loss/tok 3.2277 (3.1285)	Learning Rate [7.8125e-05]
1: TRAIN [4][3780/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00092)	Tok/s 50524 (59056)	Loss/tok 2.8613 (3.1320)	Learning Rate [7.8125e-05]
2: TRAIN [4][3780/6832]	Time 0.061 (0.105)	Data 0.00089 (0.00095)	Tok/s 50524 (59440)	Loss/tok 2.7018 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][3780/6832]	Time 0.061 (0.105)	Data 0.00092 (0.00093)	Tok/s 52299 (59890)	Loss/tok 2.8074 (3.1287)	Learning Rate [7.8125e-05]
0: TRAIN [4][3780/6832]	Time 0.061 (0.105)	Data 0.00091 (0.00093)	Tok/s 50553 (58581)	Loss/tok 2.6306 (3.1372)	Learning Rate [7.8125e-05]
1: TRAIN [4][3790/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 73831 (59067)	Loss/tok 3.2162 (3.1321)	Learning Rate [7.8125e-05]
2: TRAIN [4][3790/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00095)	Tok/s 73876 (59450)	Loss/tok 3.2425 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][3790/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00093)	Tok/s 73316 (58592)	Loss/tok 3.2667 (3.1373)	Learning Rate [7.8125e-05]
3: TRAIN [4][3790/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00093)	Tok/s 74118 (59900)	Loss/tok 3.0854 (3.1286)	Learning Rate [7.8125e-05]
1: TRAIN [4][3800/6832]	Time 0.085 (0.105)	Data 0.00086 (0.00092)	Tok/s 52497 (59070)	Loss/tok 3.1241 (3.1321)	Learning Rate [7.8125e-05]
2: TRAIN [4][3800/6832]	Time 0.085 (0.105)	Data 0.00087 (0.00095)	Tok/s 52495 (59453)	Loss/tok 2.9938 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][3800/6832]	Time 0.085 (0.105)	Data 0.00090 (0.00093)	Tok/s 51358 (58595)	Loss/tok 2.9374 (3.1373)	Learning Rate [7.8125e-05]
3: TRAIN [4][3800/6832]	Time 0.085 (0.105)	Data 0.00087 (0.00093)	Tok/s 52445 (59903)	Loss/tok 3.0420 (3.1284)	Learning Rate [7.8125e-05]
2: TRAIN [4][3810/6832]	Time 0.103 (0.105)	Data 0.00087 (0.00095)	Tok/s 54442 (59452)	Loss/tok 3.0237 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][3810/6832]	Time 0.103 (0.105)	Data 0.00089 (0.00093)	Tok/s 55307 (59902)	Loss/tok 3.1716 (3.1283)	Learning Rate [7.8125e-05]
1: TRAIN [4][3810/6832]	Time 0.104 (0.105)	Data 0.00087 (0.00092)	Tok/s 54326 (59070)	Loss/tok 3.1902 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][3810/6832]	Time 0.104 (0.105)	Data 0.00090 (0.00093)	Tok/s 54345 (58594)	Loss/tok 3.1633 (3.1371)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][3820/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00095)	Tok/s 80528 (59448)	Loss/tok 3.1914 (3.1344)	Learning Rate [7.8125e-05]
1: TRAIN [4][3820/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00092)	Tok/s 79961 (59067)	Loss/tok 3.1324 (3.1320)	Learning Rate [7.8125e-05]
3: TRAIN [4][3820/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00093)	Tok/s 80993 (59898)	Loss/tok 3.0542 (3.1283)	Learning Rate [7.8125e-05]
0: TRAIN [4][3820/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00093)	Tok/s 79877 (58592)	Loss/tok 3.2922 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][3830/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00095)	Tok/s 67495 (59447)	Loss/tok 3.2792 (3.1346)	Learning Rate [7.8125e-05]
1: TRAIN [4][3830/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00092)	Tok/s 67518 (59066)	Loss/tok 3.2241 (3.1321)	Learning Rate [7.8125e-05]
3: TRAIN [4][3830/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 67472 (59897)	Loss/tok 3.4091 (3.1284)	Learning Rate [7.8125e-05]
0: TRAIN [4][3830/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00093)	Tok/s 65585 (58592)	Loss/tok 3.1531 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][3840/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00092)	Tok/s 52254 (59059)	Loss/tok 3.0830 (3.1321)	Learning Rate [7.8125e-05]
0: TRAIN [4][3840/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00093)	Tok/s 52272 (58585)	Loss/tok 3.1342 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][3840/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00095)	Tok/s 52244 (59440)	Loss/tok 3.3381 (3.1347)	Learning Rate [7.8125e-05]
3: TRAIN [4][3840/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00093)	Tok/s 53129 (59889)	Loss/tok 3.2740 (3.1286)	Learning Rate [7.8125e-05]
2: TRAIN [4][3850/6832]	Time 0.122 (0.105)	Data 0.00089 (0.00095)	Tok/s 63852 (59448)	Loss/tok 3.2768 (3.1347)	Learning Rate [7.8125e-05]
1: TRAIN [4][3850/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00092)	Tok/s 63177 (59068)	Loss/tok 3.3639 (3.1322)	Learning Rate [7.8125e-05]
0: TRAIN [4][3850/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00093)	Tok/s 63176 (58595)	Loss/tok 3.1916 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][3850/6832]	Time 0.122 (0.105)	Data 0.00092 (0.00093)	Tok/s 64241 (59897)	Loss/tok 3.2229 (3.1286)	Learning Rate [7.8125e-05]
1: TRAIN [4][3860/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00092)	Tok/s 52228 (59072)	Loss/tok 3.0258 (3.1321)	Learning Rate [7.8125e-05]
2: TRAIN [4][3860/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00095)	Tok/s 52224 (59452)	Loss/tok 2.9754 (3.1346)	Learning Rate [7.8125e-05]
0: TRAIN [4][3860/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00093)	Tok/s 51621 (58599)	Loss/tok 3.0578 (3.1371)	Learning Rate [7.8125e-05]
3: TRAIN [4][3860/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00093)	Tok/s 52292 (59901)	Loss/tok 2.9092 (3.1286)	Learning Rate [7.8125e-05]
1: TRAIN [4][3870/6832]	Time 0.067 (0.105)	Data 0.00087 (0.00092)	Tok/s 49815 (59072)	Loss/tok 2.9127 (3.1323)	Learning Rate [7.8125e-05]
2: TRAIN [4][3870/6832]	Time 0.067 (0.105)	Data 0.00087 (0.00095)	Tok/s 49839 (59452)	Loss/tok 3.0185 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][3870/6832]	Time 0.067 (0.105)	Data 0.00090 (0.00093)	Tok/s 49863 (58601)	Loss/tok 2.9293 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][3870/6832]	Time 0.067 (0.105)	Data 0.00091 (0.00093)	Tok/s 50563 (59901)	Loss/tok 2.9025 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [4][3880/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00095)	Tok/s 53978 (59446)	Loss/tok 3.1324 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][3880/6832]	Time 0.095 (0.105)	Data 0.00090 (0.00093)	Tok/s 54079 (59895)	Loss/tok 3.0332 (3.1287)	Learning Rate [7.8125e-05]
1: TRAIN [4][3880/6832]	Time 0.095 (0.105)	Data 0.00087 (0.00092)	Tok/s 53922 (59067)	Loss/tok 3.0226 (3.1323)	Learning Rate [7.8125e-05]
0: TRAIN [4][3880/6832]	Time 0.095 (0.105)	Data 0.00093 (0.00093)	Tok/s 53963 (58596)	Loss/tok 3.0249 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][3890/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00092)	Tok/s 81355 (59064)	Loss/tok 3.1533 (3.1322)	Learning Rate [7.8125e-05]
2: TRAIN [4][3890/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 81980 (59446)	Loss/tok 3.2492 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][3890/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 81103 (58589)	Loss/tok 3.1148 (3.1375)	Learning Rate [7.8125e-05]
3: TRAIN [4][3890/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00093)	Tok/s 82290 (59896)	Loss/tok 3.1672 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [4][3900/6832]	Time 0.060 (0.105)	Data 0.00089 (0.00095)	Tok/s 50816 (59452)	Loss/tok 2.7801 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][3900/6832]	Time 0.061 (0.105)	Data 0.00088 (0.00092)	Tok/s 50766 (59071)	Loss/tok 2.8211 (3.1323)	Learning Rate [7.8125e-05]
0: TRAIN [4][3900/6832]	Time 0.060 (0.105)	Data 0.00089 (0.00093)	Tok/s 50786 (58596)	Loss/tok 2.7142 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][3900/6832]	Time 0.060 (0.105)	Data 0.00091 (0.00093)	Tok/s 52968 (59902)	Loss/tok 2.8486 (3.1288)	Learning Rate [7.8125e-05]
2: TRAIN [4][3910/6832]	Time 0.094 (0.105)	Data 0.00089 (0.00095)	Tok/s 53328 (59438)	Loss/tok 3.3214 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][3910/6832]	Time 0.094 (0.105)	Data 0.00089 (0.00092)	Tok/s 53347 (59055)	Loss/tok 2.8406 (3.1323)	Learning Rate [7.8125e-05]
0: TRAIN [4][3910/6832]	Time 0.094 (0.105)	Data 0.00090 (0.00093)	Tok/s 52277 (58579)	Loss/tok 3.0628 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][3910/6832]	Time 0.094 (0.105)	Data 0.00094 (0.00093)	Tok/s 53348 (59888)	Loss/tok 2.9948 (3.1287)	Learning Rate [7.8125e-05]
1: TRAIN [4][3920/6832]	Time 0.060 (0.105)	Data 0.00091 (0.00092)	Tok/s 48697 (59062)	Loss/tok 2.8994 (3.1321)	Learning Rate [7.8125e-05]
0: TRAIN [4][3920/6832]	Time 0.060 (0.105)	Data 0.00094 (0.00093)	Tok/s 48724 (58585)	Loss/tok 2.6909 (3.1376)	Learning Rate [7.8125e-05]
2: TRAIN [4][3920/6832]	Time 0.060 (0.105)	Data 0.00099 (0.00095)	Tok/s 48692 (59444)	Loss/tok 2.7056 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][3920/6832]	Time 0.060 (0.105)	Data 0.00099 (0.00093)	Tok/s 50741 (59894)	Loss/tok 2.7205 (3.1286)	Learning Rate [7.8125e-05]
2: TRAIN [4][3930/6832]	Time 0.078 (0.105)	Data 0.00094 (0.00095)	Tok/s 52631 (59436)	Loss/tok 2.9146 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][3930/6832]	Time 0.078 (0.105)	Data 0.00089 (0.00092)	Tok/s 52586 (59054)	Loss/tok 3.1300 (3.1321)	Learning Rate [7.8125e-05]
0: TRAIN [4][3930/6832]	Time 0.078 (0.105)	Data 0.00096 (0.00093)	Tok/s 52547 (58578)	Loss/tok 2.9207 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][3930/6832]	Time 0.078 (0.105)	Data 0.00098 (0.00093)	Tok/s 52635 (59885)	Loss/tok 3.0475 (3.1287)	Learning Rate [7.8125e-05]
2: TRAIN [4][3940/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00095)	Tok/s 58618 (59442)	Loss/tok 3.1913 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][3940/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00092)	Tok/s 58524 (59061)	Loss/tok 3.1095 (3.1323)	Learning Rate [7.8125e-05]
0: TRAIN [4][3940/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00093)	Tok/s 57534 (58586)	Loss/tok 3.1500 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][3940/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00093)	Tok/s 58619 (59892)	Loss/tok 3.2500 (3.1290)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][3950/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00092)	Tok/s 52056 (59062)	Loss/tok 3.1857 (3.1323)	Learning Rate [7.8125e-05]
0: TRAIN [4][3950/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00093)	Tok/s 52063 (58587)	Loss/tok 3.2662 (3.1379)	Learning Rate [7.8125e-05]
2: TRAIN [4][3950/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00095)	Tok/s 52928 (59443)	Loss/tok 3.1578 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][3950/6832]	Time 0.117 (0.105)	Data 0.00093 (0.00093)	Tok/s 53391 (59892)	Loss/tok 3.2497 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][3960/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00092)	Tok/s 83639 (59076)	Loss/tok 3.1884 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][3960/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00095)	Tok/s 84528 (59457)	Loss/tok 3.1647 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][3960/6832]	Time 0.132 (0.105)	Data 0.00097 (0.00093)	Tok/s 83343 (58602)	Loss/tok 3.1161 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][3960/6832]	Time 0.131 (0.105)	Data 0.00095 (0.00093)	Tok/s 84702 (59905)	Loss/tok 3.0353 (3.1293)	Learning Rate [7.8125e-05]
2: TRAIN [4][3970/6832]	Time 0.055 (0.105)	Data 0.00092 (0.00095)	Tok/s 51592 (59460)	Loss/tok 2.6710 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][3970/6832]	Time 0.055 (0.105)	Data 0.00088 (0.00092)	Tok/s 51047 (59079)	Loss/tok 2.6076 (3.1327)	Learning Rate [7.8125e-05]
3: TRAIN [4][3970/6832]	Time 0.055 (0.105)	Data 0.00097 (0.00093)	Tok/s 51575 (59907)	Loss/tok 2.6252 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][3970/6832]	Time 0.055 (0.105)	Data 0.00093 (0.00093)	Tok/s 49061 (58604)	Loss/tok 2.6286 (3.1381)	Learning Rate [7.8125e-05]
1: TRAIN [4][3980/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00092)	Tok/s 52161 (59083)	Loss/tok 3.0892 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][3980/6832]	Time 0.093 (0.105)	Data 0.00087 (0.00095)	Tok/s 52193 (59463)	Loss/tok 3.0849 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][3980/6832]	Time 0.093 (0.105)	Data 0.00090 (0.00093)	Tok/s 52228 (59910)	Loss/tok 3.0206 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][3980/6832]	Time 0.093 (0.105)	Data 0.00092 (0.00093)	Tok/s 52195 (58609)	Loss/tok 3.0999 (3.1382)	Learning Rate [7.8125e-05]
1: TRAIN [4][3990/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00092)	Tok/s 59655 (59083)	Loss/tok 3.2882 (3.1329)	Learning Rate [7.8125e-05]
0: TRAIN [4][3990/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 59654 (58610)	Loss/tok 3.3763 (3.1384)	Learning Rate [7.8125e-05]
2: TRAIN [4][3990/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00095)	Tok/s 60313 (59464)	Loss/tok 3.2830 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][3990/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00093)	Tok/s 60603 (59911)	Loss/tok 3.1957 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][4000/6832]	Time 0.064 (0.105)	Data 0.00087 (0.00092)	Tok/s 50311 (59077)	Loss/tok 2.7084 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][4000/6832]	Time 0.064 (0.105)	Data 0.00091 (0.00095)	Tok/s 50721 (59457)	Loss/tok 2.7732 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][4000/6832]	Time 0.063 (0.105)	Data 0.00093 (0.00093)	Tok/s 52461 (59904)	Loss/tok 2.9239 (3.1290)	Learning Rate [7.8125e-05]
0: TRAIN [4][4000/6832]	Time 0.064 (0.105)	Data 0.00092 (0.00093)	Tok/s 50344 (58604)	Loss/tok 2.7901 (3.1383)	Learning Rate [7.8125e-05]
1: TRAIN [4][4010/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00092)	Tok/s 88323 (59105)	Loss/tok 3.0711 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][4010/6832]	Time 0.132 (0.105)	Data 0.00091 (0.00095)	Tok/s 89001 (59485)	Loss/tok 3.0065 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][4010/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00093)	Tok/s 89629 (59932)	Loss/tok 3.0915 (3.1291)	Learning Rate [7.8125e-05]
0: TRAIN [4][4010/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00093)	Tok/s 87419 (58632)	Loss/tok 2.8759 (3.1383)	Learning Rate [7.8125e-05]
1: TRAIN [4][4020/6832]	Time 0.058 (0.105)	Data 0.00091 (0.00092)	Tok/s 50329 (59115)	Loss/tok 2.7006 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][4020/6832]	Time 0.058 (0.105)	Data 0.00092 (0.00095)	Tok/s 50465 (59495)	Loss/tok 2.7431 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][4020/6832]	Time 0.058 (0.105)	Data 0.00099 (0.00093)	Tok/s 50333 (58643)	Loss/tok 2.6531 (3.1383)	Learning Rate [7.8125e-05]
3: TRAIN [4][4020/6832]	Time 0.058 (0.105)	Data 0.00095 (0.00093)	Tok/s 52429 (59942)	Loss/tok 2.8069 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][4030/6832]	Time 0.049 (0.105)	Data 0.00089 (0.00092)	Tok/s 41971 (59103)	Loss/tok 2.4792 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][4030/6832]	Time 0.049 (0.105)	Data 0.00092 (0.00095)	Tok/s 44536 (59483)	Loss/tok 2.3414 (3.1356)	Learning Rate [7.8125e-05]
0: TRAIN [4][4030/6832]	Time 0.049 (0.105)	Data 0.00101 (0.00093)	Tok/s 39499 (58631)	Loss/tok 2.2025 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][4030/6832]	Time 0.049 (0.105)	Data 0.00094 (0.00093)	Tok/s 46188 (59931)	Loss/tok 2.5208 (3.1291)	Learning Rate [7.8125e-05]
1: TRAIN [4][4040/6832]	Time 0.112 (0.105)	Data 0.00088 (0.00092)	Tok/s 51237 (59103)	Loss/tok 3.1284 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][4040/6832]	Time 0.112 (0.105)	Data 0.00085 (0.00095)	Tok/s 51227 (59483)	Loss/tok 3.0563 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][4040/6832]	Time 0.112 (0.105)	Data 0.00091 (0.00093)	Tok/s 51249 (59931)	Loss/tok 3.0823 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][4040/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00093)	Tok/s 51239 (58631)	Loss/tok 3.0827 (3.1382)	Learning Rate [7.8125e-05]
1: TRAIN [4][4050/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00092)	Tok/s 81037 (59111)	Loss/tok 3.1829 (3.1328)	Learning Rate [7.8125e-05]
2: TRAIN [4][4050/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00095)	Tok/s 81009 (59491)	Loss/tok 2.9884 (3.1356)	Learning Rate [7.8125e-05]
0: TRAIN [4][4050/6832]	Time 0.133 (0.105)	Data 0.00095 (0.00093)	Tok/s 80122 (58639)	Loss/tok 3.0483 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][4050/6832]	Time 0.133 (0.105)	Data 0.00096 (0.00093)	Tok/s 81943 (59939)	Loss/tok 3.1572 (3.1293)	Learning Rate [7.8125e-05]
2: TRAIN [4][4060/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00095)	Tok/s 51616 (59480)	Loss/tok 3.2324 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4060/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00092)	Tok/s 51597 (59100)	Loss/tok 3.0323 (3.1327)	Learning Rate [7.8125e-05]
0: TRAIN [4][4060/6832]	Time 0.087 (0.105)	Data 0.00092 (0.00093)	Tok/s 51060 (58625)	Loss/tok 3.0467 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][4060/6832]	Time 0.086 (0.105)	Data 0.00097 (0.00093)	Tok/s 51799 (59929)	Loss/tok 3.2366 (3.1294)	Learning Rate [7.8125e-05]
2: TRAIN [4][4070/6832]	Time 0.074 (0.105)	Data 0.00094 (0.00095)	Tok/s 53419 (59475)	Loss/tok 2.9984 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][4070/6832]	Time 0.074 (0.105)	Data 0.00091 (0.00092)	Tok/s 53390 (59095)	Loss/tok 2.8340 (3.1329)	Learning Rate [7.8125e-05]
0: TRAIN [4][4070/6832]	Time 0.074 (0.105)	Data 0.00097 (0.00093)	Tok/s 53424 (58622)	Loss/tok 3.0275 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][4070/6832]	Time 0.074 (0.105)	Data 0.00464 (0.00093)	Tok/s 53809 (59924)	Loss/tok 3.0205 (3.1295)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][4080/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00095)	Tok/s 67808 (59474)	Loss/tok 3.1306 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][4080/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00092)	Tok/s 67775 (59094)	Loss/tok 3.3173 (3.1330)	Learning Rate [7.8125e-05]
0: TRAIN [4][4080/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00093)	Tok/s 67565 (58621)	Loss/tok 3.0762 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][4080/6832]	Time 0.128 (0.105)	Data 0.00096 (0.00093)	Tok/s 67827 (59922)	Loss/tok 3.1148 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][4090/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00092)	Tok/s 74396 (59085)	Loss/tok 3.3205 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][4090/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00095)	Tok/s 74370 (59464)	Loss/tok 3.3326 (3.1356)	Learning Rate [7.8125e-05]
0: TRAIN [4][4090/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00093)	Tok/s 73676 (58611)	Loss/tok 3.1960 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][4090/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00093)	Tok/s 74794 (59913)	Loss/tok 3.1488 (3.1293)	Learning Rate [7.8125e-05]
2: TRAIN [4][4100/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00095)	Tok/s 70335 (59466)	Loss/tok 3.2843 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][4100/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00092)	Tok/s 70286 (59086)	Loss/tok 3.2784 (3.1330)	Learning Rate [7.8125e-05]
3: TRAIN [4][4100/6832]	Time 0.126 (0.105)	Data 0.00104 (0.00093)	Tok/s 71636 (59915)	Loss/tok 3.0862 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][4100/6832]	Time 0.127 (0.105)	Data 0.00092 (0.00093)	Tok/s 70313 (58613)	Loss/tok 3.2619 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][4110/6832]	Time 0.093 (0.105)	Data 0.00095 (0.00095)	Tok/s 55306 (59474)	Loss/tok 3.1151 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][4110/6832]	Time 0.093 (0.105)	Data 0.00108 (0.00092)	Tok/s 55333 (59094)	Loss/tok 3.0366 (3.1331)	Learning Rate [7.8125e-05]
0: TRAIN [4][4110/6832]	Time 0.093 (0.105)	Data 0.00107 (0.00093)	Tok/s 55335 (58622)	Loss/tok 3.1598 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][4110/6832]	Time 0.092 (0.105)	Data 0.00096 (0.00093)	Tok/s 55699 (59923)	Loss/tok 2.9301 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][4120/6832]	Time 0.121 (0.105)	Data 0.00086 (0.00092)	Tok/s 64280 (59100)	Loss/tok 3.2548 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][4120/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00095)	Tok/s 64658 (59479)	Loss/tok 3.2649 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][4120/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00093)	Tok/s 64313 (58628)	Loss/tok 3.3264 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][4120/6832]	Time 0.121 (0.105)	Data 0.00093 (0.00093)	Tok/s 65347 (59927)	Loss/tok 3.3432 (3.1295)	Learning Rate [7.8125e-05]
1: TRAIN [4][4130/6832]	Time 0.065 (0.105)	Data 0.00093 (0.00092)	Tok/s 49334 (59097)	Loss/tok 2.6277 (3.1332)	Learning Rate [7.8125e-05]
0: TRAIN [4][4130/6832]	Time 0.065 (0.105)	Data 0.00099 (0.00093)	Tok/s 49337 (58622)	Loss/tok 2.7094 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][4130/6832]	Time 0.065 (0.105)	Data 0.00097 (0.00095)	Tok/s 49955 (59477)	Loss/tok 2.6438 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][4130/6832]	Time 0.065 (0.105)	Data 0.00098 (0.00094)	Tok/s 51134 (59927)	Loss/tok 2.7026 (3.1295)	Learning Rate [7.8125e-05]
2: TRAIN [4][4140/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00095)	Tok/s 60572 (59487)	Loss/tok 3.1928 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][4140/6832]	Time 0.123 (0.105)	Data 0.00101 (0.00092)	Tok/s 60560 (59107)	Loss/tok 3.2736 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][4140/6832]	Time 0.123 (0.105)	Data 0.00104 (0.00093)	Tok/s 60593 (58633)	Loss/tok 3.1285 (3.1384)	Learning Rate [7.8125e-05]
3: TRAIN [4][4140/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00094)	Tok/s 60922 (59937)	Loss/tok 3.1203 (3.1297)	Learning Rate [7.8125e-05]
2: TRAIN [4][4150/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00095)	Tok/s 51882 (59490)	Loss/tok 3.0522 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][4150/6832]	Time 0.109 (0.105)	Data 0.00087 (0.00092)	Tok/s 51864 (59111)	Loss/tok 3.2497 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][4150/6832]	Time 0.109 (0.105)	Data 0.00090 (0.00093)	Tok/s 51852 (58637)	Loss/tok 3.2264 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][4150/6832]	Time 0.109 (0.105)	Data 0.00093 (0.00094)	Tok/s 51897 (59939)	Loss/tok 3.0218 (3.1297)	Learning Rate [7.8125e-05]
2: TRAIN [4][4160/6832]	Time 0.086 (0.105)	Data 0.00087 (0.00095)	Tok/s 55129 (59482)	Loss/tok 3.0842 (3.1361)	Learning Rate [7.8125e-05]
1: TRAIN [4][4160/6832]	Time 0.086 (0.105)	Data 0.00086 (0.00092)	Tok/s 55093 (59102)	Loss/tok 3.0085 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][4160/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00093)	Tok/s 55120 (58628)	Loss/tok 2.9875 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][4160/6832]	Time 0.086 (0.105)	Data 0.00093 (0.00094)	Tok/s 55141 (59930)	Loss/tok 2.9951 (3.1295)	Learning Rate [7.8125e-05]
2: TRAIN [4][4170/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00095)	Tok/s 51183 (59481)	Loss/tok 3.2363 (3.1361)	Learning Rate [7.8125e-05]
1: TRAIN [4][4170/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00092)	Tok/s 51182 (59101)	Loss/tok 3.1450 (3.1334)	Learning Rate [7.8125e-05]
3: TRAIN [4][4170/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00094)	Tok/s 51186 (59930)	Loss/tok 3.1474 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][4170/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00093)	Tok/s 50920 (58627)	Loss/tok 3.2220 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][4180/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00095)	Tok/s 51102 (59486)	Loss/tok 2.7987 (3.1361)	Learning Rate [7.8125e-05]
1: TRAIN [4][4180/6832]	Time 0.070 (0.105)	Data 0.00110 (0.00092)	Tok/s 51132 (59107)	Loss/tok 2.8536 (3.1334)	Learning Rate [7.8125e-05]
0: TRAIN [4][4180/6832]	Time 0.070 (0.105)	Data 0.00097 (0.00093)	Tok/s 51099 (58634)	Loss/tok 2.9302 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][4180/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00094)	Tok/s 51106 (59935)	Loss/tok 2.8487 (3.1294)	Learning Rate [7.8125e-05]
2: TRAIN [4][4190/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00095)	Tok/s 60929 (59479)	Loss/tok 3.2320 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][4190/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00092)	Tok/s 60195 (59099)	Loss/tok 3.2913 (3.1334)	Learning Rate [7.8125e-05]
3: TRAIN [4][4190/6832]	Time 0.118 (0.105)	Data 0.00101 (0.00094)	Tok/s 60955 (59928)	Loss/tok 3.3132 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][4190/6832]	Time 0.118 (0.105)	Data 0.00103 (0.00093)	Tok/s 59857 (58627)	Loss/tok 3.0683 (3.1380)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][4200/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00095)	Tok/s 81948 (59475)	Loss/tok 3.0560 (3.1361)	Learning Rate [7.8125e-05]
1: TRAIN [4][4200/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00092)	Tok/s 81870 (59096)	Loss/tok 3.0860 (3.1334)	Learning Rate [7.8125e-05]
0: TRAIN [4][4200/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00093)	Tok/s 81182 (58624)	Loss/tok 3.1190 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][4200/6832]	Time 0.131 (0.105)	Data 0.00103 (0.00094)	Tok/s 82922 (59925)	Loss/tok 3.0864 (3.1295)	Learning Rate [7.8125e-05]
2: TRAIN [4][4210/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00095)	Tok/s 57007 (59483)	Loss/tok 3.4328 (3.1363)	Learning Rate [7.8125e-05]
1: TRAIN [4][4210/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00092)	Tok/s 56988 (59104)	Loss/tok 3.1555 (3.1334)	Learning Rate [7.8125e-05]
0: TRAIN [4][4210/6832]	Time 0.128 (0.105)	Data 0.00094 (0.00093)	Tok/s 56990 (58633)	Loss/tok 3.1943 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][4210/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 57653 (59932)	Loss/tok 3.2124 (3.1296)	Learning Rate [7.8125e-05]
2: TRAIN [4][4220/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00095)	Tok/s 85708 (59486)	Loss/tok 3.0852 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][4220/6832]	Time 0.133 (0.105)	Data 0.00096 (0.00093)	Tok/s 84314 (58636)	Loss/tok 2.9482 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][4220/6832]	Time 0.133 (0.105)	Data 0.00100 (0.00094)	Tok/s 86099 (59936)	Loss/tok 3.3589 (3.1296)	Learning Rate [7.8125e-05]
1: TRAIN [4][4220/6832]	Time 0.133 (0.105)	Data 0.00086 (0.00092)	Tok/s 84694 (59106)	Loss/tok 2.9139 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][4230/6832]	Time 0.075 (0.105)	Data 0.00085 (0.00095)	Tok/s 52642 (59469)	Loss/tok 2.9966 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][4230/6832]	Time 0.075 (0.105)	Data 0.00093 (0.00093)	Tok/s 52658 (58616)	Loss/tok 2.9189 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][4230/6832]	Time 0.075 (0.105)	Data 0.00098 (0.00094)	Tok/s 52674 (59920)	Loss/tok 2.8909 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][4230/6832]	Time 0.075 (0.105)	Data 0.00104 (0.00092)	Tok/s 52691 (59089)	Loss/tok 2.8328 (3.1329)	Learning Rate [7.8125e-05]
2: TRAIN [4][4240/6832]	Time 0.102 (0.105)	Data 0.00091 (0.00095)	Tok/s 51686 (59462)	Loss/tok 3.0389 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][4240/6832]	Time 0.102 (0.105)	Data 0.00092 (0.00093)	Tok/s 51700 (58610)	Loss/tok 3.0568 (3.1377)	Learning Rate [7.8125e-05]
1: TRAIN [4][4240/6832]	Time 0.102 (0.105)	Data 0.00099 (0.00092)	Tok/s 51670 (59082)	Loss/tok 3.1149 (3.1329)	Learning Rate [7.8125e-05]
3: TRAIN [4][4240/6832]	Time 0.103 (0.105)	Data 0.00096 (0.00094)	Tok/s 51100 (59912)	Loss/tok 3.0292 (3.1292)	Learning Rate [7.8125e-05]
2: TRAIN [4][4250/6832]	Time 0.115 (0.105)	Data 0.00091 (0.00095)	Tok/s 59647 (59473)	Loss/tok 3.2475 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][4250/6832]	Time 0.115 (0.105)	Data 0.00090 (0.00094)	Tok/s 60320 (59923)	Loss/tok 3.3231 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][4250/6832]	Time 0.115 (0.105)	Data 0.00092 (0.00093)	Tok/s 59135 (58621)	Loss/tok 2.9851 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][4250/6832]	Time 0.115 (0.105)	Data 0.00099 (0.00092)	Tok/s 59126 (59093)	Loss/tok 3.1955 (3.1331)	Learning Rate [7.8125e-05]
0: TRAIN [4][4260/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00093)	Tok/s 67227 (58619)	Loss/tok 3.3279 (3.1377)	Learning Rate [7.8125e-05]
2: TRAIN [4][4260/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00095)	Tok/s 67498 (59470)	Loss/tok 3.1119 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][4260/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 67511 (59920)	Loss/tok 3.1378 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][4260/6832]	Time 0.129 (0.105)	Data 0.00102 (0.00092)	Tok/s 67515 (59090)	Loss/tok 3.1359 (3.1330)	Learning Rate [7.8125e-05]
2: TRAIN [4][4270/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00095)	Tok/s 79015 (59465)	Loss/tok 3.2265 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][4270/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 78083 (58614)	Loss/tok 3.1841 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][4270/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 78994 (59916)	Loss/tok 3.1384 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][4270/6832]	Time 0.131 (0.105)	Data 0.00101 (0.00092)	Tok/s 78169 (59085)	Loss/tok 3.2158 (3.1330)	Learning Rate [7.8125e-05]
2: TRAIN [4][4280/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00095)	Tok/s 56181 (59459)	Loss/tok 3.0837 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][4280/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 56184 (59910)	Loss/tok 3.1593 (3.1292)	Learning Rate [7.8125e-05]
0: TRAIN [4][4280/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00093)	Tok/s 56171 (58604)	Loss/tok 3.1598 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][4280/6832]	Time 0.118 (0.105)	Data 0.00100 (0.00092)	Tok/s 56188 (59078)	Loss/tok 3.1294 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][4290/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00095)	Tok/s 72174 (59455)	Loss/tok 3.2975 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][4290/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 71294 (58601)	Loss/tok 3.2609 (3.1376)	Learning Rate [7.8125e-05]
3: TRAIN [4][4290/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 72314 (59906)	Loss/tok 3.0961 (3.1292)	Learning Rate [7.8125e-05]
1: TRAIN [4][4290/6832]	Time 0.129 (0.105)	Data 0.00105 (0.00092)	Tok/s 71276 (59074)	Loss/tok 3.3886 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][4300/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00095)	Tok/s 69020 (59456)	Loss/tok 3.1916 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][4300/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00093)	Tok/s 68903 (58603)	Loss/tok 3.1154 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][4300/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 69420 (59907)	Loss/tok 3.2929 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][4300/6832]	Time 0.130 (0.105)	Data 0.00113 (0.00092)	Tok/s 69044 (59076)	Loss/tok 3.3442 (3.1333)	Learning Rate [7.8125e-05]
2: TRAIN [4][4310/6832]	Time 0.130 (0.105)	Data 0.00083 (0.00095)	Tok/s 78833 (59458)	Loss/tok 3.1834 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][4310/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 79644 (59910)	Loss/tok 3.2450 (3.1294)	Learning Rate [7.8125e-05]
0: TRAIN [4][4310/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00093)	Tok/s 78480 (58605)	Loss/tok 3.1485 (3.1378)	Learning Rate [7.8125e-05]
1: TRAIN [4][4310/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00092)	Tok/s 78659 (59078)	Loss/tok 2.9940 (3.1333)	Learning Rate [7.8125e-05]
2: TRAIN [4][4320/6832]	Time 0.072 (0.105)	Data 0.00084 (0.00095)	Tok/s 53666 (59450)	Loss/tok 2.7990 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][4320/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00094)	Tok/s 53705 (59901)	Loss/tok 2.9000 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][4320/6832]	Time 0.072 (0.105)	Data 0.00090 (0.00093)	Tok/s 51934 (58598)	Loss/tok 2.7454 (3.1377)	Learning Rate [7.8125e-05]
1: TRAIN [4][4320/6832]	Time 0.072 (0.105)	Data 0.00099 (0.00092)	Tok/s 53641 (59070)	Loss/tok 2.9952 (3.1332)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
2: TRAIN [4][4330/6832]	Time 0.118 (0.105)	Data 0.00085 (0.00095)	Tok/s 51850 (59436)	Loss/tok 3.2508 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][4330/6832]	Time 0.119 (0.105)	Data 0.00088 (0.00093)	Tok/s 51791 (58585)	Loss/tok 3.2847 (3.1376)	Learning Rate [7.8125e-05]
3: TRAIN [4][4330/6832]	Time 0.118 (0.105)	Data 0.00083 (0.00094)	Tok/s 51855 (59886)	Loss/tok 3.1857 (3.1293)	Learning Rate [7.8125e-05]
1: TRAIN [4][4330/6832]	Time 0.119 (0.105)	Data 0.00100 (0.00092)	Tok/s 51794 (59056)	Loss/tok 3.1501 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][4340/6832]	Time 0.097 (0.105)	Data 0.00086 (0.00095)	Tok/s 52644 (59432)	Loss/tok 2.8990 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][4340/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00094)	Tok/s 52658 (59883)	Loss/tok 3.0805 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][4340/6832]	Time 0.097 (0.105)	Data 0.00090 (0.00093)	Tok/s 51809 (58582)	Loss/tok 2.9788 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][4340/6832]	Time 0.097 (0.105)	Data 0.00100 (0.00092)	Tok/s 52558 (59052)	Loss/tok 3.3071 (3.1330)	Learning Rate [7.8125e-05]
2: TRAIN [4][4350/6832]	Time 0.126 (0.105)	Data 0.00084 (0.00095)	Tok/s 63763 (59435)	Loss/tok 3.2657 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][4350/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00093)	Tok/s 62752 (58585)	Loss/tok 3.2863 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][4350/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00094)	Tok/s 63772 (59885)	Loss/tok 3.3119 (3.1295)	Learning Rate [7.8125e-05]
1: TRAIN [4][4350/6832]	Time 0.126 (0.105)	Data 0.00100 (0.00092)	Tok/s 63391 (59055)	Loss/tok 3.2980 (3.1331)	Learning Rate [7.8125e-05]
2: TRAIN [4][4360/6832]	Time 0.115 (0.105)	Data 0.00086 (0.00095)	Tok/s 53337 (59433)	Loss/tok 3.2909 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][4360/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00093)	Tok/s 53333 (58583)	Loss/tok 3.0425 (3.1378)	Learning Rate [7.8125e-05]
3: TRAIN [4][4360/6832]	Time 0.115 (0.105)	Data 0.00088 (0.00094)	Tok/s 53847 (59883)	Loss/tok 3.1812 (3.1295)	Learning Rate [7.8125e-05]
1: TRAIN [4][4360/6832]	Time 0.115 (0.105)	Data 0.00104 (0.00092)	Tok/s 53324 (59053)	Loss/tok 3.2391 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][4370/6832]	Time 0.079 (0.105)	Data 0.00097 (0.00095)	Tok/s 54875 (59434)	Loss/tok 3.1205 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][4370/6832]	Time 0.079 (0.105)	Data 0.00096 (0.00092)	Tok/s 54892 (59054)	Loss/tok 3.0155 (3.1331)	Learning Rate [7.8125e-05]
3: TRAIN [4][4370/6832]	Time 0.079 (0.105)	Data 0.00100 (0.00094)	Tok/s 54962 (59884)	Loss/tok 3.0017 (3.1296)	Learning Rate [7.8125e-05]
0: TRAIN [4][4370/6832]	Time 0.079 (0.105)	Data 0.00094 (0.00093)	Tok/s 54852 (58584)	Loss/tok 3.0210 (3.1377)	Learning Rate [7.8125e-05]
2: TRAIN [4][4380/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00095)	Tok/s 84173 (59434)	Loss/tok 3.0931 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][4380/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 84763 (59885)	Loss/tok 3.1456 (3.1295)	Learning Rate [7.8125e-05]
1: TRAIN [4][4380/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 83819 (59053)	Loss/tok 3.2149 (3.1330)	Learning Rate [7.8125e-05]
0: TRAIN [4][4380/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 83128 (58580)	Loss/tok 3.0880 (3.1376)	Learning Rate [7.8125e-05]
2: TRAIN [4][4390/6832]	Time 0.091 (0.105)	Data 0.00087 (0.00095)	Tok/s 52077 (59422)	Loss/tok 3.1694 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][4390/6832]	Time 0.091 (0.105)	Data 0.00095 (0.00094)	Tok/s 52118 (59872)	Loss/tok 3.0618 (3.1294)	Learning Rate [7.8125e-05]
1: TRAIN [4][4390/6832]	Time 0.091 (0.105)	Data 0.00089 (0.00092)	Tok/s 52079 (59040)	Loss/tok 3.1497 (3.1330)	Learning Rate [7.8125e-05]
0: TRAIN [4][4390/6832]	Time 0.091 (0.105)	Data 0.00107 (0.00093)	Tok/s 52147 (58566)	Loss/tok 3.1398 (3.1375)	Learning Rate [7.8125e-05]
2: TRAIN [4][4400/6832]	Time 0.132 (0.105)	Data 0.00085 (0.00095)	Tok/s 83417 (59423)	Loss/tok 3.0604 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][4400/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00092)	Tok/s 83212 (59042)	Loss/tok 3.3250 (3.1330)	Learning Rate [7.8125e-05]
3: TRAIN [4][4400/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 84379 (59875)	Loss/tok 3.2093 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][4400/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00093)	Tok/s 82354 (58568)	Loss/tok 3.1401 (3.1376)	Learning Rate [7.8125e-05]
2: TRAIN [4][4410/6832]	Time 0.128 (0.105)	Data 0.00084 (0.00095)	Tok/s 60018 (59419)	Loss/tok 3.1967 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4410/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00092)	Tok/s 60029 (59038)	Loss/tok 3.4532 (3.1330)	Learning Rate [7.8125e-05]
3: TRAIN [4][4410/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00094)	Tok/s 60026 (59870)	Loss/tok 3.2740 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][4410/6832]	Time 0.128 (0.105)	Data 0.00100 (0.00093)	Tok/s 59209 (58563)	Loss/tok 3.1588 (3.1375)	Learning Rate [7.8125e-05]
2: TRAIN [4][4420/6832]	Time 0.124 (0.105)	Data 0.00086 (0.00095)	Tok/s 67043 (59423)	Loss/tok 3.3130 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4420/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00092)	Tok/s 67050 (59043)	Loss/tok 3.1842 (3.1330)	Learning Rate [7.8125e-05]
3: TRAIN [4][4420/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00094)	Tok/s 67384 (59874)	Loss/tok 3.2679 (3.1293)	Learning Rate [7.8125e-05]
0: TRAIN [4][4420/6832]	Time 0.124 (0.105)	Data 0.00103 (0.00093)	Tok/s 67036 (58568)	Loss/tok 3.2671 (3.1375)	Learning Rate [7.8125e-05]
2: TRAIN [4][4430/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00095)	Tok/s 75491 (59420)	Loss/tok 3.0868 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][4430/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 75770 (59870)	Loss/tok 3.2445 (3.1295)	Learning Rate [7.8125e-05]
1: TRAIN [4][4430/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00092)	Tok/s 74835 (59040)	Loss/tok 3.2543 (3.1330)	Learning Rate [7.8125e-05]
0: TRAIN [4][4430/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00093)	Tok/s 74865 (58566)	Loss/tok 3.1258 (3.1375)	Learning Rate [7.8125e-05]
2: TRAIN [4][4440/6832]	Time 0.080 (0.105)	Data 0.00084 (0.00095)	Tok/s 51103 (59431)	Loss/tok 3.0431 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4440/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00092)	Tok/s 51042 (59051)	Loss/tok 2.9772 (3.1332)	Learning Rate [7.8125e-05]
3: TRAIN [4][4440/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00094)	Tok/s 51125 (59881)	Loss/tok 3.0664 (3.1296)	Learning Rate [7.8125e-05]
0: TRAIN [4][4440/6832]	Time 0.080 (0.105)	Data 0.00107 (0.00093)	Tok/s 51063 (58577)	Loss/tok 3.1513 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][4450/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00095)	Tok/s 79468 (59432)	Loss/tok 3.1503 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4450/6832]	Time 0.130 (0.105)	Data 0.00105 (0.00092)	Tok/s 78969 (59053)	Loss/tok 3.3149 (3.1334)	Learning Rate [7.8125e-05]
3: TRAIN [4][4450/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00094)	Tok/s 79565 (59882)	Loss/tok 3.2236 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][4450/6832]	Time 0.130 (0.105)	Data 0.00106 (0.00093)	Tok/s 78667 (58580)	Loss/tok 3.2047 (3.1376)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][4460/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00095)	Tok/s 61931 (59431)	Loss/tok 3.2612 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4460/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00092)	Tok/s 61899 (59051)	Loss/tok 3.2327 (3.1333)	Learning Rate [7.8125e-05]
3: TRAIN [4][4460/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 62426 (59881)	Loss/tok 3.1930 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][4460/6832]	Time 0.126 (0.105)	Data 0.00102 (0.00093)	Tok/s 61917 (58578)	Loss/tok 3.0987 (3.1373)	Learning Rate [7.8125e-05]
2: TRAIN [4][4470/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00095)	Tok/s 57733 (59441)	Loss/tok 3.3718 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4470/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00092)	Tok/s 57724 (59062)	Loss/tok 3.1304 (3.1334)	Learning Rate [7.8125e-05]
3: TRAIN [4][4470/6832]	Time 0.126 (0.105)	Data 0.00101 (0.00094)	Tok/s 58064 (59893)	Loss/tok 3.0990 (3.1297)	Learning Rate [7.8125e-05]
0: TRAIN [4][4470/6832]	Time 0.126 (0.105)	Data 0.00110 (0.00093)	Tok/s 57782 (58590)	Loss/tok 3.1295 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][4480/6832]	Time 0.118 (0.105)	Data 0.00095 (0.00095)	Tok/s 53572 (59440)	Loss/tok 3.2074 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4480/6832]	Time 0.118 (0.105)	Data 0.00098 (0.00092)	Tok/s 53034 (59061)	Loss/tok 3.3306 (3.1334)	Learning Rate [7.8125e-05]
3: TRAIN [4][4480/6832]	Time 0.118 (0.105)	Data 0.00104 (0.00094)	Tok/s 54132 (59892)	Loss/tok 3.2930 (3.1298)	Learning Rate [7.8125e-05]
0: TRAIN [4][4480/6832]	Time 0.118 (0.105)	Data 0.00111 (0.00093)	Tok/s 53065 (58589)	Loss/tok 3.2603 (3.1374)	Learning Rate [7.8125e-05]
1: TRAIN [4][4490/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00092)	Tok/s 59529 (59052)	Loss/tok 3.2062 (3.1333)	Learning Rate [7.8125e-05]
2: TRAIN [4][4490/6832]	Time 0.121 (0.105)	Data 0.00085 (0.00095)	Tok/s 59453 (59432)	Loss/tok 3.2953 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][4490/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00094)	Tok/s 59315 (59884)	Loss/tok 3.1308 (3.1296)	Learning Rate [7.8125e-05]
0: TRAIN [4][4490/6832]	Time 0.120 (0.105)	Data 0.00104 (0.00093)	Tok/s 59204 (58578)	Loss/tok 3.1888 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][4500/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00095)	Tok/s 74704 (59440)	Loss/tok 3.2751 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4500/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00092)	Tok/s 74583 (59061)	Loss/tok 3.2350 (3.1335)	Learning Rate [7.8125e-05]
3: TRAIN [4][4500/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00094)	Tok/s 75325 (59892)	Loss/tok 3.2291 (3.1298)	Learning Rate [7.8125e-05]
0: TRAIN [4][4500/6832]	Time 0.130 (0.105)	Data 0.00104 (0.00093)	Tok/s 74418 (58587)	Loss/tok 3.2779 (3.1377)	Learning Rate [7.8125e-05]
2: TRAIN [4][4510/6832]	Time 0.110 (0.105)	Data 0.00084 (0.00095)	Tok/s 55678 (59447)	Loss/tok 2.9736 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][4510/6832]	Time 0.110 (0.105)	Data 0.00092 (0.00093)	Tok/s 54586 (58595)	Loss/tok 3.2927 (3.1377)	Learning Rate [7.8125e-05]
1: TRAIN [4][4510/6832]	Time 0.110 (0.105)	Data 0.00097 (0.00092)	Tok/s 55651 (59068)	Loss/tok 3.2806 (3.1337)	Learning Rate [7.8125e-05]
3: TRAIN [4][4510/6832]	Time 0.110 (0.105)	Data 0.00102 (0.00094)	Tok/s 55676 (59899)	Loss/tok 3.1721 (3.1300)	Learning Rate [7.8125e-05]
2: TRAIN [4][4520/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 69106 (59448)	Loss/tok 3.2239 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4520/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00092)	Tok/s 69041 (59069)	Loss/tok 3.3419 (3.1337)	Learning Rate [7.8125e-05]
0: TRAIN [4][4520/6832]	Time 0.132 (0.105)	Data 0.00106 (0.00093)	Tok/s 69060 (58595)	Loss/tok 3.0702 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][4520/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 69801 (59900)	Loss/tok 3.1914 (3.1299)	Learning Rate [7.8125e-05]
2: TRAIN [4][4530/6832]	Time 0.059 (0.105)	Data 0.00087 (0.00094)	Tok/s 47346 (59444)	Loss/tok 2.6508 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][4530/6832]	Time 0.060 (0.105)	Data 0.00094 (0.00094)	Tok/s 48336 (59896)	Loss/tok 2.6432 (3.1298)	Learning Rate [7.8125e-05]
0: TRAIN [4][4530/6832]	Time 0.060 (0.105)	Data 0.00092 (0.00093)	Tok/s 46819 (58592)	Loss/tok 2.6091 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][4530/6832]	Time 0.059 (0.105)	Data 0.00093 (0.00092)	Tok/s 47363 (59065)	Loss/tok 2.7805 (3.1337)	Learning Rate [7.8125e-05]
2: TRAIN [4][4540/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00094)	Tok/s 50452 (59436)	Loss/tok 2.7831 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][4540/6832]	Time 0.061 (0.105)	Data 0.00084 (0.00093)	Tok/s 50456 (58582)	Loss/tok 2.9551 (3.1376)	Learning Rate [7.8125e-05]
3: TRAIN [4][4540/6832]	Time 0.061 (0.105)	Data 0.00090 (0.00094)	Tok/s 51120 (59889)	Loss/tok 2.7779 (3.1299)	Learning Rate [7.8125e-05]
1: TRAIN [4][4540/6832]	Time 0.061 (0.105)	Data 0.00094 (0.00092)	Tok/s 50342 (59057)	Loss/tok 2.7964 (3.1339)	Learning Rate [7.8125e-05]
2: TRAIN [4][4550/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00094)	Tok/s 54774 (59429)	Loss/tok 3.1175 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4550/6832]	Time 0.108 (0.105)	Data 0.00088 (0.00092)	Tok/s 54762 (59051)	Loss/tok 3.1603 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [4][4550/6832]	Time 0.107 (0.105)	Data 0.00089 (0.00093)	Tok/s 53631 (58576)	Loss/tok 3.0955 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][4550/6832]	Time 0.107 (0.105)	Data 0.00092 (0.00094)	Tok/s 54773 (59882)	Loss/tok 3.3234 (3.1300)	Learning Rate [7.8125e-05]
2: TRAIN [4][4560/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 77405 (59428)	Loss/tok 3.2991 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][4560/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 78309 (59881)	Loss/tok 2.9930 (3.1298)	Learning Rate [7.8125e-05]
0: TRAIN [4][4560/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00093)	Tok/s 76946 (58576)	Loss/tok 3.1527 (3.1377)	Learning Rate [7.8125e-05]
1: TRAIN [4][4560/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 77407 (59050)	Loss/tok 3.1576 (3.1339)	Learning Rate [7.8125e-05]
2: TRAIN [4][4570/6832]	Time 0.099 (0.105)	Data 0.00087 (0.00094)	Tok/s 53070 (59424)	Loss/tok 3.0606 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4570/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00092)	Tok/s 53087 (59046)	Loss/tok 3.0388 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][4570/6832]	Time 0.099 (0.105)	Data 0.00088 (0.00094)	Tok/s 53099 (59877)	Loss/tok 3.2944 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][4570/6832]	Time 0.099 (0.105)	Data 0.00088 (0.00093)	Tok/s 53070 (58573)	Loss/tok 3.0720 (3.1376)	Learning Rate [7.8125e-05]
2: TRAIN [4][4580/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00094)	Tok/s 57027 (59431)	Loss/tok 3.3059 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][4580/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00092)	Tok/s 56994 (59053)	Loss/tok 3.2918 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][4580/6832]	Time 0.117 (0.105)	Data 0.00094 (0.00093)	Tok/s 56974 (58580)	Loss/tok 3.0597 (3.1377)	Learning Rate [7.8125e-05]
3: TRAIN [4][4580/6832]	Time 0.117 (0.105)	Data 0.00103 (0.00094)	Tok/s 57024 (59883)	Loss/tok 3.3058 (3.1301)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][4590/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 59487 (59424)	Loss/tok 3.1245 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][4590/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00093)	Tok/s 59507 (58574)	Loss/tok 3.3384 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][4590/6832]	Time 0.129 (0.105)	Data 0.00345 (0.00092)	Tok/s 59511 (59047)	Loss/tok 3.1769 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][4590/6832]	Time 0.129 (0.105)	Data 0.00099 (0.00094)	Tok/s 60117 (59877)	Loss/tok 3.3345 (3.1300)	Learning Rate [7.8125e-05]
2: TRAIN [4][4600/6832]	Time 0.089 (0.105)	Data 0.00092 (0.00094)	Tok/s 51575 (59419)	Loss/tok 2.9848 (3.1356)	Learning Rate [7.8125e-05]
0: TRAIN [4][4600/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00093)	Tok/s 50823 (58569)	Loss/tok 3.0307 (3.1376)	Learning Rate [7.8125e-05]
1: TRAIN [4][4600/6832]	Time 0.089 (0.105)	Data 0.00094 (0.00092)	Tok/s 51622 (59043)	Loss/tok 2.9678 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][4600/6832]	Time 0.089 (0.105)	Data 0.00106 (0.00094)	Tok/s 51848 (59872)	Loss/tok 2.9412 (3.1300)	Learning Rate [7.8125e-05]
2: TRAIN [4][4610/6832]	Time 0.123 (0.105)	Data 0.00084 (0.00094)	Tok/s 62348 (59422)	Loss/tok 3.0901 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][4610/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00094)	Tok/s 62342 (59874)	Loss/tok 3.3129 (3.1300)	Learning Rate [7.8125e-05]
1: TRAIN [4][4610/6832]	Time 0.123 (0.105)	Data 0.00089 (0.00092)	Tok/s 62333 (59045)	Loss/tok 3.3047 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [4][4610/6832]	Time 0.123 (0.105)	Data 0.00088 (0.00093)	Tok/s 61871 (58573)	Loss/tok 3.2114 (3.1377)	Learning Rate [7.8125e-05]
2: TRAIN [4][4620/6832]	Time 0.120 (0.105)	Data 0.00100 (0.00094)	Tok/s 59583 (59426)	Loss/tok 3.1389 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4620/6832]	Time 0.120 (0.105)	Data 0.00089 (0.00092)	Tok/s 58998 (59049)	Loss/tok 3.2228 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][4620/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00094)	Tok/s 59590 (59878)	Loss/tok 3.1201 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][4620/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00093)	Tok/s 58459 (58577)	Loss/tok 3.2770 (3.1375)	Learning Rate [7.8125e-05]
2: TRAIN [4][4630/6832]	Time 0.114 (0.105)	Data 0.00093 (0.00094)	Tok/s 61527 (59431)	Loss/tok 3.1490 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4630/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00092)	Tok/s 61489 (59055)	Loss/tok 3.3211 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][4630/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00093)	Tok/s 61442 (58583)	Loss/tok 3.1582 (3.1375)	Learning Rate [7.8125e-05]
3: TRAIN [4][4630/6832]	Time 0.114 (0.105)	Data 0.00098 (0.00094)	Tok/s 61518 (59883)	Loss/tok 3.1677 (3.1299)	Learning Rate [7.8125e-05]
2: TRAIN [4][4640/6832]	Time 0.120 (0.105)	Data 0.00095 (0.00094)	Tok/s 60589 (59432)	Loss/tok 3.2197 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][4640/6832]	Time 0.120 (0.105)	Data 0.00105 (0.00094)	Tok/s 60585 (59883)	Loss/tok 3.4302 (3.1299)	Learning Rate [7.8125e-05]
1: TRAIN [4][4640/6832]	Time 0.121 (0.105)	Data 0.00091 (0.00092)	Tok/s 60518 (59056)	Loss/tok 3.3629 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][4640/6832]	Time 0.121 (0.105)	Data 0.00088 (0.00093)	Tok/s 60499 (58585)	Loss/tok 3.1662 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][4650/6832]	Time 0.124 (0.105)	Data 0.00096 (0.00094)	Tok/s 54737 (59445)	Loss/tok 3.1641 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4650/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00092)	Tok/s 54758 (59069)	Loss/tok 3.1189 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][4650/6832]	Time 0.124 (0.105)	Data 0.00104 (0.00094)	Tok/s 54736 (59896)	Loss/tok 3.2322 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][4650/6832]	Time 0.124 (0.105)	Data 0.00089 (0.00093)	Tok/s 54657 (58599)	Loss/tok 3.0926 (3.1375)	Learning Rate [7.8125e-05]
2: TRAIN [4][4660/6832]	Time 0.064 (0.105)	Data 0.00084 (0.00094)	Tok/s 50485 (59447)	Loss/tok 2.8227 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4660/6832]	Time 0.064 (0.105)	Data 0.00095 (0.00092)	Tok/s 49798 (59071)	Loss/tok 2.8517 (3.1339)	Learning Rate [7.8125e-05]
0: TRAIN [4][4660/6832]	Time 0.064 (0.105)	Data 0.00085 (0.00093)	Tok/s 49801 (58601)	Loss/tok 2.6872 (3.1374)	Learning Rate [7.8125e-05]
3: TRAIN [4][4660/6832]	Time 0.064 (0.105)	Data 0.00089 (0.00094)	Tok/s 51688 (59898)	Loss/tok 2.7948 (3.1300)	Learning Rate [7.8125e-05]
2: TRAIN [4][4670/6832]	Time 0.130 (0.105)	Data 0.00096 (0.00094)	Tok/s 68069 (59450)	Loss/tok 3.2574 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][4670/6832]	Time 0.130 (0.105)	Data 0.00101 (0.00094)	Tok/s 68870 (59900)	Loss/tok 3.3001 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][4670/6832]	Time 0.130 (0.105)	Data 0.00116 (0.00093)	Tok/s 68111 (58604)	Loss/tok 3.3050 (3.1374)	Learning Rate [7.8125e-05]
1: TRAIN [4][4670/6832]	Time 0.130 (0.105)	Data 0.00119 (0.00092)	Tok/s 68135 (59074)	Loss/tok 3.1385 (3.1339)	Learning Rate [7.8125e-05]
2: TRAIN [4][4680/6832]	Time 0.107 (0.105)	Data 0.00085 (0.00094)	Tok/s 51693 (59447)	Loss/tok 3.2696 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][4680/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00094)	Tok/s 52665 (59897)	Loss/tok 3.0258 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][4680/6832]	Time 0.107 (0.105)	Data 0.00086 (0.00093)	Tok/s 51492 (58601)	Loss/tok 2.9729 (3.1373)	Learning Rate [7.8125e-05]
1: TRAIN [4][4680/6832]	Time 0.107 (0.105)	Data 0.00118 (0.00092)	Tok/s 51640 (59070)	Loss/tok 3.1328 (3.1338)	Learning Rate [7.8125e-05]
2: TRAIN [4][4690/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 68310 (59440)	Loss/tok 3.2149 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][4690/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00092)	Tok/s 68293 (59063)	Loss/tok 3.2076 (3.1337)	Learning Rate [7.8125e-05]
3: TRAIN [4][4690/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 68298 (59891)	Loss/tok 3.2646 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][4690/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00093)	Tok/s 67650 (58594)	Loss/tok 3.3617 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][4700/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 71145 (59448)	Loss/tok 3.3230 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][4700/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 71133 (59898)	Loss/tok 3.2077 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][4700/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00093)	Tok/s 70131 (58602)	Loss/tok 3.1752 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][4700/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00092)	Tok/s 70227 (59071)	Loss/tok 3.1072 (3.1338)	Learning Rate [7.8125e-05]
2: TRAIN [4][4710/6832]	Time 0.117 (0.105)	Data 0.00092 (0.00094)	Tok/s 57907 (59447)	Loss/tok 3.0373 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][4710/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00092)	Tok/s 57740 (59070)	Loss/tok 3.0449 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][4710/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00094)	Tok/s 57902 (59898)	Loss/tok 3.1472 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][4710/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00093)	Tok/s 56735 (58601)	Loss/tok 3.3868 (3.1370)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][4720/6832]	Time 0.123 (0.105)	Data 0.00085 (0.00094)	Tok/s 52197 (59439)	Loss/tok 3.1986 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][4720/6832]	Time 0.123 (0.105)	Data 0.00086 (0.00094)	Tok/s 52225 (59890)	Loss/tok 3.0178 (3.1299)	Learning Rate [7.8125e-05]
1: TRAIN [4][4720/6832]	Time 0.123 (0.105)	Data 0.00091 (0.00092)	Tok/s 52225 (59063)	Loss/tok 3.2937 (3.1338)	Learning Rate [7.8125e-05]
0: TRAIN [4][4720/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00093)	Tok/s 52017 (58594)	Loss/tok 3.1828 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][4730/6832]	Time 0.103 (0.105)	Data 0.00100 (0.00094)	Tok/s 52220 (59452)	Loss/tok 3.1540 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][4730/6832]	Time 0.103 (0.105)	Data 0.00093 (0.00092)	Tok/s 52173 (59075)	Loss/tok 3.0821 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][4730/6832]	Time 0.103 (0.105)	Data 0.00099 (0.00094)	Tok/s 52224 (59902)	Loss/tok 3.2754 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][4730/6832]	Time 0.103 (0.105)	Data 0.00088 (0.00093)	Tok/s 52153 (58607)	Loss/tok 3.1672 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][4740/6832]	Time 0.084 (0.105)	Data 0.00093 (0.00094)	Tok/s 54684 (59446)	Loss/tok 3.0468 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][4740/6832]	Time 0.084 (0.105)	Data 0.00099 (0.00094)	Tok/s 55824 (59897)	Loss/tok 3.2087 (3.1301)	Learning Rate [7.8125e-05]
1: TRAIN [4][4740/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00092)	Tok/s 54692 (59070)	Loss/tok 3.0249 (3.1338)	Learning Rate [7.8125e-05]
0: TRAIN [4][4740/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00093)	Tok/s 54680 (58603)	Loss/tok 3.0945 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][4750/6832]	Time 0.083 (0.105)	Data 0.00096 (0.00094)	Tok/s 52360 (59454)	Loss/tok 3.1087 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4750/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00092)	Tok/s 52362 (59078)	Loss/tok 3.1866 (3.1340)	Learning Rate [7.8125e-05]
3: TRAIN [4][4750/6832]	Time 0.083 (0.105)	Data 0.00206 (0.00094)	Tok/s 52343 (59904)	Loss/tok 3.0807 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][4750/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00093)	Tok/s 52350 (58611)	Loss/tok 3.0361 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][4760/6832]	Time 0.059 (0.105)	Data 0.00085 (0.00094)	Tok/s 48114 (59445)	Loss/tok 2.6343 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][4760/6832]	Time 0.059 (0.105)	Data 0.00098 (0.00094)	Tok/s 49440 (59895)	Loss/tok 2.6752 (3.1300)	Learning Rate [7.8125e-05]
1: TRAIN [4][4760/6832]	Time 0.059 (0.105)	Data 0.00084 (0.00092)	Tok/s 48088 (59069)	Loss/tok 2.6568 (3.1338)	Learning Rate [7.8125e-05]
0: TRAIN [4][4760/6832]	Time 0.059 (0.105)	Data 0.00121 (0.00093)	Tok/s 47286 (58602)	Loss/tok 2.5475 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][4770/6832]	Time 0.078 (0.105)	Data 0.00089 (0.00094)	Tok/s 52295 (59452)	Loss/tok 2.8069 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][4770/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00092)	Tok/s 52301 (59077)	Loss/tok 3.0502 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][4770/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00094)	Tok/s 52318 (59902)	Loss/tok 3.0121 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][4770/6832]	Time 0.078 (0.105)	Data 0.00104 (0.00093)	Tok/s 52250 (58610)	Loss/tok 3.1490 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][4780/6832]	Time 0.053 (0.105)	Data 0.00088 (0.00094)	Tok/s 45897 (59442)	Loss/tok 2.5399 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][4780/6832]	Time 0.053 (0.105)	Data 0.00089 (0.00092)	Tok/s 45184 (59067)	Loss/tok 2.6956 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][4780/6832]	Time 0.053 (0.105)	Data 0.00094 (0.00094)	Tok/s 47660 (59893)	Loss/tok 2.7014 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][4780/6832]	Time 0.053 (0.105)	Data 0.00096 (0.00093)	Tok/s 43362 (58601)	Loss/tok 2.4910 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][4790/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00094)	Tok/s 55339 (59448)	Loss/tok 3.1275 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][4790/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00092)	Tok/s 54437 (59072)	Loss/tok 3.1859 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][4790/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00094)	Tok/s 55330 (59899)	Loss/tok 3.1784 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][4790/6832]	Time 0.118 (0.105)	Data 0.00104 (0.00093)	Tok/s 54310 (58606)	Loss/tok 2.9637 (3.1369)	Learning Rate [7.8125e-05]
2: TRAIN [4][4800/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00094)	Tok/s 60682 (59459)	Loss/tok 3.3300 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][4800/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00092)	Tok/s 60737 (59083)	Loss/tok 3.3202 (3.1338)	Learning Rate [7.8125e-05]
3: TRAIN [4][4800/6832]	Time 0.122 (0.105)	Data 0.00094 (0.00094)	Tok/s 60707 (59910)	Loss/tok 3.1558 (3.1301)	Learning Rate [7.8125e-05]
0: TRAIN [4][4800/6832]	Time 0.122 (0.105)	Data 0.00094 (0.00093)	Tok/s 60707 (58617)	Loss/tok 3.2472 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][4810/6832]	Time 0.072 (0.105)	Data 0.00084 (0.00094)	Tok/s 53146 (59449)	Loss/tok 2.8107 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][4810/6832]	Time 0.072 (0.105)	Data 0.00086 (0.00092)	Tok/s 52423 (59074)	Loss/tok 2.9232 (3.1337)	Learning Rate [7.8125e-05]
3: TRAIN [4][4810/6832]	Time 0.072 (0.105)	Data 0.00087 (0.00094)	Tok/s 53149 (59900)	Loss/tok 2.8947 (3.1300)	Learning Rate [7.8125e-05]
0: TRAIN [4][4810/6832]	Time 0.072 (0.105)	Data 0.00093 (0.00093)	Tok/s 51388 (58609)	Loss/tok 2.8603 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][4820/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 88375 (59452)	Loss/tok 3.0508 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][4820/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00092)	Tok/s 87657 (59077)	Loss/tok 3.0958 (3.1336)	Learning Rate [7.8125e-05]
3: TRAIN [4][4820/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 89281 (59903)	Loss/tok 3.0467 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][4820/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00093)	Tok/s 87087 (58611)	Loss/tok 3.0332 (3.1367)	Learning Rate [7.8125e-05]
2: TRAIN [4][4830/6832]	Time 0.099 (0.105)	Data 0.00086 (0.00094)	Tok/s 54359 (59454)	Loss/tok 3.1358 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][4830/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00092)	Tok/s 53830 (59079)	Loss/tok 3.0248 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][4830/6832]	Time 0.099 (0.105)	Data 0.00089 (0.00094)	Tok/s 54363 (59904)	Loss/tok 2.9057 (3.1299)	Learning Rate [7.8125e-05]
0: TRAIN [4][4830/6832]	Time 0.099 (0.105)	Data 0.00092 (0.00093)	Tok/s 53026 (58613)	Loss/tok 3.0243 (3.1368)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][4840/6832]	Time 0.130 (0.105)	Data 0.00124 (0.00094)	Tok/s 65961 (59459)	Loss/tok 3.2665 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][4840/6832]	Time 0.130 (0.105)	Data 0.00127 (0.00094)	Tok/s 66005 (59909)	Loss/tok 3.3257 (3.1300)	Learning Rate [7.8125e-05]
1: TRAIN [4][4840/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00092)	Tok/s 65823 (59084)	Loss/tok 3.3340 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][4840/6832]	Time 0.130 (0.105)	Data 0.00098 (0.00093)	Tok/s 65808 (58619)	Loss/tok 3.1909 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][4850/6832]	Time 0.125 (0.105)	Data 0.00096 (0.00094)	Tok/s 63313 (59467)	Loss/tok 3.3104 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][4850/6832]	Time 0.125 (0.105)	Data 0.00092 (0.00092)	Tok/s 62646 (59093)	Loss/tok 3.2777 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][4850/6832]	Time 0.125 (0.105)	Data 0.00095 (0.00093)	Tok/s 62217 (58628)	Loss/tok 3.3774 (3.1368)	Learning Rate [7.8125e-05]
3: TRAIN [4][4850/6832]	Time 0.125 (0.105)	Data 0.00100 (0.00094)	Tok/s 63634 (59918)	Loss/tok 3.2783 (3.1302)	Learning Rate [7.8125e-05]
2: TRAIN [4][4860/6832]	Time 0.097 (0.105)	Data 0.00087 (0.00094)	Tok/s 52556 (59467)	Loss/tok 2.9535 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][4860/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00092)	Tok/s 52583 (59093)	Loss/tok 2.9023 (3.1339)	Learning Rate [7.8125e-05]
3: TRAIN [4][4860/6832]	Time 0.097 (0.105)	Data 0.00089 (0.00094)	Tok/s 52540 (59917)	Loss/tok 3.0787 (3.1302)	Learning Rate [7.8125e-05]
0: TRAIN [4][4860/6832]	Time 0.097 (0.105)	Data 0.00101 (0.00093)	Tok/s 52306 (58629)	Loss/tok 3.0229 (3.1368)	Learning Rate [7.8125e-05]
2: TRAIN [4][4870/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00094)	Tok/s 60832 (59468)	Loss/tok 3.3416 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][4870/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00094)	Tok/s 60986 (59918)	Loss/tok 3.0508 (3.1302)	Learning Rate [7.8125e-05]
1: TRAIN [4][4870/6832]	Time 0.126 (0.105)	Data 0.00090 (0.00092)	Tok/s 59882 (59094)	Loss/tok 3.4234 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][4870/6832]	Time 0.126 (0.105)	Data 0.00094 (0.00093)	Tok/s 59881 (58630)	Loss/tok 3.3934 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][4880/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 65384 (59471)	Loss/tok 3.2488 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][4880/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 65362 (59921)	Loss/tok 3.2845 (3.1302)	Learning Rate [7.8125e-05]
1: TRAIN [4][4880/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00092)	Tok/s 65280 (59097)	Loss/tok 3.3853 (3.1340)	Learning Rate [7.8125e-05]
0: TRAIN [4][4880/6832]	Time 0.129 (0.105)	Data 0.00101 (0.00093)	Tok/s 65104 (58634)	Loss/tok 3.3408 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][4890/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00094)	Tok/s 52215 (59480)	Loss/tok 3.1194 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4890/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00092)	Tok/s 52226 (59107)	Loss/tok 3.1534 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][4890/6832]	Time 0.120 (0.105)	Data 0.00092 (0.00094)	Tok/s 52217 (59930)	Loss/tok 3.2080 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][4890/6832]	Time 0.120 (0.105)	Data 0.00110 (0.00093)	Tok/s 52200 (58644)	Loss/tok 3.2029 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][4900/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00094)	Tok/s 54205 (59484)	Loss/tok 3.2397 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][4900/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00094)	Tok/s 54217 (59934)	Loss/tok 3.0720 (3.1304)	Learning Rate [7.8125e-05]
1: TRAIN [4][4900/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00092)	Tok/s 54195 (59111)	Loss/tok 3.0872 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][4900/6832]	Time 0.113 (0.105)	Data 0.00103 (0.00093)	Tok/s 53040 (58649)	Loss/tok 3.2219 (3.1373)	Learning Rate [7.8125e-05]
2: TRAIN [4][4910/6832]	Time 0.125 (0.105)	Data 0.00085 (0.00094)	Tok/s 63487 (59493)	Loss/tok 3.2244 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][4910/6832]	Time 0.125 (0.105)	Data 0.00087 (0.00094)	Tok/s 64385 (59942)	Loss/tok 3.2458 (3.1305)	Learning Rate [7.8125e-05]
1: TRAIN [4][4910/6832]	Time 0.125 (0.105)	Data 0.00093 (0.00092)	Tok/s 63369 (59120)	Loss/tok 3.2707 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][4910/6832]	Time 0.125 (0.105)	Data 0.00096 (0.00093)	Tok/s 63374 (58657)	Loss/tok 3.2406 (3.1374)	Learning Rate [7.8125e-05]
2: TRAIN [4][4920/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 61970 (59497)	Loss/tok 3.1588 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][4920/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 61959 (59125)	Loss/tok 3.2230 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][4920/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 61960 (59947)	Loss/tok 3.3819 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][4920/6832]	Time 0.130 (0.105)	Data 0.00125 (0.00093)	Tok/s 62002 (58662)	Loss/tok 3.0760 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][4930/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00094)	Tok/s 57913 (59489)	Loss/tok 3.3830 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][4930/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00094)	Tok/s 57960 (59938)	Loss/tok 3.1290 (3.1303)	Learning Rate [7.8125e-05]
1: TRAIN [4][4930/6832]	Time 0.117 (0.105)	Data 0.00086 (0.00092)	Tok/s 57925 (59116)	Loss/tok 3.2768 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][4930/6832]	Time 0.117 (0.105)	Data 0.00130 (0.00093)	Tok/s 57867 (58654)	Loss/tok 3.1664 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][4940/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00092)	Tok/s 52911 (59115)	Loss/tok 2.9275 (3.1343)	Learning Rate [7.8125e-05]
2: TRAIN [4][4940/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00094)	Tok/s 53174 (59487)	Loss/tok 2.9510 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][4940/6832]	Time 0.091 (0.105)	Data 0.00092 (0.00094)	Tok/s 53162 (59936)	Loss/tok 3.2270 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][4940/6832]	Time 0.091 (0.105)	Data 0.00107 (0.00094)	Tok/s 51788 (58653)	Loss/tok 2.9457 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][4950/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00094)	Tok/s 55574 (59480)	Loss/tok 3.1504 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][4950/6832]	Time 0.090 (0.105)	Data 0.00101 (0.00094)	Tok/s 55573 (59930)	Loss/tok 3.1166 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][4950/6832]	Time 0.090 (0.105)	Data 0.00110 (0.00094)	Tok/s 55511 (58647)	Loss/tok 3.1212 (3.1370)	Learning Rate [7.8125e-05]
1: TRAIN [4][4950/6832]	Time 0.090 (0.105)	Data 0.00085 (0.00092)	Tok/s 55486 (59109)	Loss/tok 3.3111 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][4960/6832]	Time 0.127 (0.105)	Data 0.00097 (0.00094)	Tok/s 63684 (59481)	Loss/tok 3.0935 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4960/6832]	Time 0.127 (0.105)	Data 0.00093 (0.00092)	Tok/s 63603 (59110)	Loss/tok 3.0856 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][4960/6832]	Time 0.127 (0.105)	Data 0.00103 (0.00094)	Tok/s 64724 (59930)	Loss/tok 3.2463 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][4960/6832]	Time 0.127 (0.105)	Data 0.00106 (0.00094)	Tok/s 63642 (58648)	Loss/tok 3.2643 (3.1371)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][4970/6832]	Time 0.067 (0.105)	Data 0.00088 (0.00094)	Tok/s 49759 (59487)	Loss/tok 2.7664 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][4970/6832]	Time 0.067 (0.105)	Data 0.00086 (0.00092)	Tok/s 49407 (59116)	Loss/tok 2.7022 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][4970/6832]	Time 0.067 (0.105)	Data 0.00094 (0.00094)	Tok/s 51322 (59937)	Loss/tok 2.8544 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][4970/6832]	Time 0.067 (0.105)	Data 0.00110 (0.00094)	Tok/s 49406 (58655)	Loss/tok 2.8151 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][4980/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00094)	Tok/s 68356 (59481)	Loss/tok 3.1757 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][4980/6832]	Time 0.129 (0.105)	Data 0.00085 (0.00092)	Tok/s 68354 (59110)	Loss/tok 3.0547 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][4980/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00094)	Tok/s 68368 (59930)	Loss/tok 3.2376 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][4980/6832]	Time 0.129 (0.105)	Data 0.00117 (0.00094)	Tok/s 67833 (58649)	Loss/tok 3.3496 (3.1373)	Learning Rate [7.8125e-05]
2: TRAIN [4][4990/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00094)	Tok/s 58385 (59479)	Loss/tok 3.2304 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][4990/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00092)	Tok/s 57856 (59109)	Loss/tok 3.0876 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][4990/6832]	Time 0.117 (0.105)	Data 0.00104 (0.00094)	Tok/s 58997 (59929)	Loss/tok 3.1649 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][4990/6832]	Time 0.117 (0.105)	Data 0.00112 (0.00094)	Tok/s 57840 (58649)	Loss/tok 3.2118 (3.1373)	Learning Rate [7.8125e-05]
2: TRAIN [4][5000/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00094)	Tok/s 50748 (59480)	Loss/tok 2.8780 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][5000/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00092)	Tok/s 50724 (59109)	Loss/tok 2.8600 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][5000/6832]	Time 0.071 (0.105)	Data 0.00096 (0.00094)	Tok/s 51727 (59929)	Loss/tok 2.8903 (3.1306)	Learning Rate [7.8125e-05]
0: TRAIN [4][5000/6832]	Time 0.071 (0.105)	Data 0.00116 (0.00094)	Tok/s 50745 (58650)	Loss/tok 2.9129 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][5010/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00094)	Tok/s 52376 (59482)	Loss/tok 3.1289 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][5010/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00092)	Tok/s 52241 (59112)	Loss/tok 2.9225 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][5010/6832]	Time 0.088 (0.105)	Data 0.00092 (0.00094)	Tok/s 53737 (59932)	Loss/tok 3.0453 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][5010/6832]	Time 0.088 (0.105)	Data 0.00107 (0.00094)	Tok/s 52228 (58653)	Loss/tok 3.0786 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][5020/6832]	Time 0.075 (0.105)	Data 0.00093 (0.00092)	Tok/s 54549 (59121)	Loss/tok 2.8441 (3.1344)	Learning Rate [7.8125e-05]
2: TRAIN [4][5020/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00094)	Tok/s 54529 (59491)	Loss/tok 3.1207 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][5020/6832]	Time 0.075 (0.105)	Data 0.00100 (0.00094)	Tok/s 54507 (59941)	Loss/tok 3.1001 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][5020/6832]	Time 0.075 (0.105)	Data 0.00109 (0.00094)	Tok/s 54611 (58662)	Loss/tok 2.9204 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][5030/6832]	Time 0.053 (0.105)	Data 0.00089 (0.00094)	Tok/s 50511 (59489)	Loss/tok 2.6983 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][5030/6832]	Time 0.053 (0.105)	Data 0.00092 (0.00092)	Tok/s 48806 (59118)	Loss/tok 2.6166 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5030/6832]	Time 0.053 (0.105)	Data 0.00100 (0.00094)	Tok/s 50520 (59938)	Loss/tok 2.7231 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][5030/6832]	Time 0.053 (0.105)	Data 0.00105 (0.00094)	Tok/s 48122 (58659)	Loss/tok 2.6794 (3.1371)	Learning Rate [7.8125e-05]
1: TRAIN [4][5040/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00092)	Tok/s 74153 (59129)	Loss/tok 3.2227 (3.1344)	Learning Rate [7.8125e-05]
2: TRAIN [4][5040/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 74102 (59500)	Loss/tok 3.1646 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][5040/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 74631 (59949)	Loss/tok 3.1521 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][5040/6832]	Time 0.129 (0.105)	Data 0.00103 (0.00094)	Tok/s 73710 (58670)	Loss/tok 3.2634 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][5050/6832]	Time 0.056 (0.105)	Data 0.00085 (0.00094)	Tok/s 50506 (59501)	Loss/tok 2.6149 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][5050/6832]	Time 0.056 (0.105)	Data 0.00096 (0.00092)	Tok/s 50542 (59131)	Loss/tok 2.6567 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5050/6832]	Time 0.056 (0.105)	Data 0.00094 (0.00094)	Tok/s 51819 (59950)	Loss/tok 2.8159 (3.1305)	Learning Rate [7.8125e-05]
0: TRAIN [4][5050/6832]	Time 0.056 (0.105)	Data 0.00109 (0.00094)	Tok/s 50523 (58672)	Loss/tok 2.7354 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][5060/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00094)	Tok/s 56919 (59507)	Loss/tok 3.1372 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][5060/6832]	Time 0.117 (0.105)	Data 0.00091 (0.00092)	Tok/s 56931 (59137)	Loss/tok 3.2674 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][5060/6832]	Time 0.117 (0.105)	Data 0.00095 (0.00094)	Tok/s 56890 (59956)	Loss/tok 3.2463 (3.1306)	Learning Rate [7.8125e-05]
0: TRAIN [4][5060/6832]	Time 0.117 (0.105)	Data 0.00105 (0.00094)	Tok/s 56682 (58679)	Loss/tok 3.2336 (3.1372)	Learning Rate [7.8125e-05]
2: TRAIN [4][5070/6832]	Time 0.070 (0.105)	Data 0.00086 (0.00094)	Tok/s 51214 (59501)	Loss/tok 2.9627 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5070/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00094)	Tok/s 51296 (59950)	Loss/tok 2.8486 (3.1303)	Learning Rate [7.8125e-05]
1: TRAIN [4][5070/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00092)	Tok/s 51140 (59130)	Loss/tok 2.8647 (3.1343)	Learning Rate [7.8125e-05]
0: TRAIN [4][5070/6832]	Time 0.070 (0.105)	Data 0.00106 (0.00094)	Tok/s 51129 (58672)	Loss/tok 2.8190 (3.1370)	Learning Rate [7.8125e-05]
1: TRAIN [4][5080/6832]	Time 0.068 (0.105)	Data 0.00085 (0.00092)	Tok/s 50456 (59132)	Loss/tok 2.8354 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][5080/6832]	Time 0.068 (0.105)	Data 0.00090 (0.00094)	Tok/s 50543 (59502)	Loss/tok 2.8688 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5080/6832]	Time 0.068 (0.105)	Data 0.00095 (0.00094)	Tok/s 50944 (59950)	Loss/tok 2.9173 (3.1303)	Learning Rate [7.8125e-05]
0: TRAIN [4][5080/6832]	Time 0.068 (0.105)	Data 0.00121 (0.00094)	Tok/s 50469 (58673)	Loss/tok 2.8424 (3.1370)	Learning Rate [7.8125e-05]
2: TRAIN [4][5090/6832]	Time 0.069 (0.105)	Data 0.00092 (0.00094)	Tok/s 51960 (59508)	Loss/tok 2.8178 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][5090/6832]	Time 0.069 (0.105)	Data 0.00094 (0.00094)	Tok/s 52213 (59957)	Loss/tok 2.9302 (3.1305)	Learning Rate [7.8125e-05]
1: TRAIN [4][5090/6832]	Time 0.069 (0.105)	Data 0.00093 (0.00092)	Tok/s 51969 (59138)	Loss/tok 2.7091 (3.1343)	Learning Rate [7.8125e-05]
0: TRAIN [4][5090/6832]	Time 0.069 (0.105)	Data 0.00110 (0.00094)	Tok/s 52011 (58680)	Loss/tok 2.8318 (3.1370)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
1: TRAIN [4][5100/6832]	Time 0.044 (0.105)	Data 0.00088 (0.00092)	Tok/s 32939 (59134)	Loss/tok 2.1388 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][5100/6832]	Time 0.044 (0.105)	Data 0.00085 (0.00094)	Tok/s 38210 (59505)	Loss/tok 2.0062 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][5100/6832]	Time 0.044 (0.105)	Data 0.00104 (0.00094)	Tok/s 21190 (58674)	Loss/tok 1.7301 (3.1369)	Learning Rate [7.8125e-05]
3: TRAIN [4][5100/6832]	Time 0.044 (0.105)	Data 0.00090 (0.00094)	Tok/s 42030 (59955)	Loss/tok 2.1873 (3.1304)	Learning Rate [7.8125e-05]
2: TRAIN [4][5110/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00094)	Tok/s 52766 (59506)	Loss/tok 3.1779 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5110/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00092)	Tok/s 52807 (59135)	Loss/tok 3.0395 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][5110/6832]	Time 0.109 (0.105)	Data 0.00088 (0.00094)	Tok/s 52759 (59956)	Loss/tok 3.1544 (3.1304)	Learning Rate [7.8125e-05]
0: TRAIN [4][5110/6832]	Time 0.109 (0.105)	Data 0.00089 (0.00094)	Tok/s 52811 (58673)	Loss/tok 3.1198 (3.1369)	Learning Rate [7.8125e-05]
2: TRAIN [4][5120/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 58757 (59505)	Loss/tok 3.3882 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5120/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00092)	Tok/s 58730 (59134)	Loss/tok 2.9837 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][5120/6832]	Time 0.126 (0.105)	Data 0.00087 (0.00094)	Tok/s 58732 (58672)	Loss/tok 3.2640 (3.1370)	Learning Rate [7.8125e-05]
3: TRAIN [4][5120/6832]	Time 0.126 (0.105)	Data 0.00091 (0.00094)	Tok/s 59429 (59955)	Loss/tok 3.3294 (3.1306)	Learning Rate [7.8125e-05]
1: TRAIN [4][5130/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00092)	Tok/s 69485 (59131)	Loss/tok 3.2912 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][5130/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 69466 (59502)	Loss/tok 3.1902 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5130/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 70478 (59952)	Loss/tok 3.3330 (3.1307)	Learning Rate [7.8125e-05]
0: TRAIN [4][5130/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00094)	Tok/s 69493 (58670)	Loss/tok 3.1749 (3.1371)	Learning Rate [7.8125e-05]
2: TRAIN [4][5140/6832]	Time 0.116 (0.105)	Data 0.00084 (0.00094)	Tok/s 50695 (59499)	Loss/tok 3.1585 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5140/6832]	Time 0.116 (0.105)	Data 0.00085 (0.00092)	Tok/s 50764 (59128)	Loss/tok 3.1620 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][5140/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00094)	Tok/s 50749 (58667)	Loss/tok 3.1779 (3.1371)	Learning Rate [7.8125e-05]
3: TRAIN [4][5140/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00094)	Tok/s 51676 (59949)	Loss/tok 3.2252 (3.1306)	Learning Rate [7.8125e-05]
1: TRAIN [4][5150/6832]	Time 0.062 (0.105)	Data 0.00087 (0.00092)	Tok/s 51426 (59137)	Loss/tok 2.5829 (3.1340)	Learning Rate [7.8125e-05]
2: TRAIN [4][5150/6832]	Time 0.062 (0.105)	Data 0.00092 (0.00094)	Tok/s 51423 (59508)	Loss/tok 2.8037 (3.1353)	Learning Rate [7.8125e-05]
0: TRAIN [4][5150/6832]	Time 0.062 (0.105)	Data 0.00091 (0.00094)	Tok/s 51445 (58677)	Loss/tok 2.8361 (3.1371)	Learning Rate [7.8125e-05]
3: TRAIN [4][5150/6832]	Time 0.062 (0.105)	Data 0.00098 (0.00094)	Tok/s 52766 (59959)	Loss/tok 2.8549 (3.1305)	Learning Rate [7.8125e-05]
1: TRAIN [4][5160/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00092)	Tok/s 71233 (59135)	Loss/tok 3.1565 (3.1341)	Learning Rate [7.8125e-05]
2: TRAIN [4][5160/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00094)	Tok/s 71410 (59505)	Loss/tok 3.3262 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][5160/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 71269 (58675)	Loss/tok 3.3998 (3.1371)	Learning Rate [7.8125e-05]
3: TRAIN [4][5160/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 72175 (59956)	Loss/tok 3.3092 (3.1306)	Learning Rate [7.8125e-05]
1: TRAIN [4][5170/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00092)	Tok/s 69618 (59140)	Loss/tok 3.3152 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][5170/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 69653 (59510)	Loss/tok 3.1839 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][5170/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 69575 (58681)	Loss/tok 3.2795 (3.1372)	Learning Rate [7.8125e-05]
3: TRAIN [4][5170/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 70342 (59960)	Loss/tok 3.2580 (3.1307)	Learning Rate [7.8125e-05]
2: TRAIN [4][5180/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00094)	Tok/s 59438 (59522)	Loss/tok 3.0549 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5180/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00092)	Tok/s 59416 (59152)	Loss/tok 3.2029 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5180/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 59993 (59972)	Loss/tok 3.0672 (3.1308)	Learning Rate [7.8125e-05]
0: TRAIN [4][5180/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00094)	Tok/s 59445 (58694)	Loss/tok 3.1697 (3.1374)	Learning Rate [7.8125e-05]
1: TRAIN [4][5190/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00092)	Tok/s 52594 (59152)	Loss/tok 3.0820 (3.1344)	Learning Rate [7.8125e-05]
2: TRAIN [4][5190/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00094)	Tok/s 52586 (59521)	Loss/tok 3.0412 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][5190/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 51544 (58693)	Loss/tok 3.3144 (3.1375)	Learning Rate [7.8125e-05]
3: TRAIN [4][5190/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 52575 (59971)	Loss/tok 3.3628 (3.1309)	Learning Rate [7.8125e-05]
2: TRAIN [4][5200/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 80436 (59514)	Loss/tok 3.1107 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][5200/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00092)	Tok/s 80423 (59143)	Loss/tok 3.2401 (3.1345)	Learning Rate [7.8125e-05]
0: TRAIN [4][5200/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 79727 (58683)	Loss/tok 3.2797 (3.1376)	Learning Rate [7.8125e-05]
3: TRAIN [4][5200/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 81324 (59964)	Loss/tok 3.1211 (3.1307)	Learning Rate [7.8125e-05]
2: TRAIN [4][5210/6832]	Time 0.075 (0.105)	Data 0.00085 (0.00094)	Tok/s 52267 (59529)	Loss/tok 3.1753 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][5210/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00094)	Tok/s 52892 (59980)	Loss/tok 2.8676 (3.1309)	Learning Rate [7.8125e-05]
1: TRAIN [4][5210/6832]	Time 0.075 (0.105)	Data 0.00092 (0.00092)	Tok/s 51182 (59159)	Loss/tok 2.8822 (3.1345)	Learning Rate [7.8125e-05]
0: TRAIN [4][5210/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00094)	Tok/s 51198 (58699)	Loss/tok 2.9415 (3.1377)	Learning Rate [7.8125e-05]
1: TRAIN [4][5220/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 62233 (59164)	Loss/tok 3.2013 (3.1346)	Learning Rate [7.8125e-05]
0: TRAIN [4][5220/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 62234 (58705)	Loss/tok 3.0700 (3.1378)	Learning Rate [7.8125e-05]
2: TRAIN [4][5220/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 62223 (59534)	Loss/tok 3.3430 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5220/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 62784 (59984)	Loss/tok 3.2239 (3.1311)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][5230/6832]	Time 0.131 (0.105)	Data 0.00084 (0.00094)	Tok/s 64519 (59542)	Loss/tok 3.2648 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5230/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00092)	Tok/s 64501 (59172)	Loss/tok 3.2344 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][5230/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 63983 (58713)	Loss/tok 3.1800 (3.1379)	Learning Rate [7.8125e-05]
3: TRAIN [4][5230/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 64491 (59992)	Loss/tok 3.3081 (3.1311)	Learning Rate [7.8125e-05]
2: TRAIN [4][5240/6832]	Time 0.072 (0.105)	Data 0.00089 (0.00094)	Tok/s 49843 (59541)	Loss/tok 2.9933 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5240/6832]	Time 0.072 (0.105)	Data 0.00092 (0.00094)	Tok/s 50722 (59991)	Loss/tok 3.0383 (3.1311)	Learning Rate [7.8125e-05]
1: TRAIN [4][5240/6832]	Time 0.072 (0.105)	Data 0.00085 (0.00092)	Tok/s 49772 (59171)	Loss/tok 2.9811 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][5240/6832]	Time 0.072 (0.105)	Data 0.00088 (0.00094)	Tok/s 49797 (58712)	Loss/tok 2.8509 (3.1379)	Learning Rate [7.8125e-05]
2: TRAIN [4][5250/6832]	Time 0.078 (0.105)	Data 0.00092 (0.00094)	Tok/s 52685 (59538)	Loss/tok 3.1291 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][5250/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00092)	Tok/s 52675 (59168)	Loss/tok 3.1443 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][5250/6832]	Time 0.078 (0.105)	Data 0.00097 (0.00094)	Tok/s 52710 (59988)	Loss/tok 2.8218 (3.1311)	Learning Rate [7.8125e-05]
0: TRAIN [4][5250/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00094)	Tok/s 52691 (58711)	Loss/tok 3.0101 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5260/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00094)	Tok/s 67340 (59544)	Loss/tok 3.2553 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][5260/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00094)	Tok/s 66526 (58717)	Loss/tok 3.1714 (3.1381)	Learning Rate [7.8125e-05]
1: TRAIN [4][5260/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00092)	Tok/s 67312 (59175)	Loss/tok 3.2878 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5260/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 67338 (59993)	Loss/tok 3.2353 (3.1313)	Learning Rate [7.8125e-05]
2: TRAIN [4][5270/6832]	Time 0.046 (0.105)	Data 0.00098 (0.00094)	Tok/s 36503 (59541)	Loss/tok 2.0354 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][5270/6832]	Time 0.046 (0.105)	Data 0.00087 (0.00092)	Tok/s 32144 (59171)	Loss/tok 2.0840 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5270/6832]	Time 0.046 (0.105)	Data 0.00090 (0.00094)	Tok/s 40137 (59991)	Loss/tok 2.3396 (3.1313)	Learning Rate [7.8125e-05]
0: TRAIN [4][5270/6832]	Time 0.046 (0.105)	Data 0.00087 (0.00094)	Tok/s 20257 (58711)	Loss/tok 1.6988 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5280/6832]	Time 0.090 (0.105)	Data 0.00093 (0.00094)	Tok/s 54014 (59531)	Loss/tok 3.0692 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][5280/6832]	Time 0.090 (0.105)	Data 0.00094 (0.00092)	Tok/s 54033 (59161)	Loss/tok 3.0299 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][5280/6832]	Time 0.090 (0.105)	Data 0.00096 (0.00094)	Tok/s 54026 (59981)	Loss/tok 2.8708 (3.1313)	Learning Rate [7.8125e-05]
0: TRAIN [4][5280/6832]	Time 0.090 (0.105)	Data 0.00091 (0.00094)	Tok/s 52630 (58701)	Loss/tok 3.1328 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5290/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00094)	Tok/s 52966 (59534)	Loss/tok 3.1279 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][5290/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00092)	Tok/s 53016 (59165)	Loss/tok 2.8118 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5290/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00094)	Tok/s 54560 (59984)	Loss/tok 3.0991 (3.1313)	Learning Rate [7.8125e-05]
0: TRAIN [4][5290/6832]	Time 0.080 (0.105)	Data 0.00091 (0.00094)	Tok/s 53014 (58705)	Loss/tok 2.8694 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][5300/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 66920 (59529)	Loss/tok 3.1532 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][5300/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 67523 (59980)	Loss/tok 3.3093 (3.1314)	Learning Rate [7.8125e-05]
1: TRAIN [4][5300/6832]	Time 0.129 (0.105)	Data 0.00095 (0.00092)	Tok/s 66517 (59160)	Loss/tok 3.1867 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][5300/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 66547 (58701)	Loss/tok 3.2290 (3.1382)	Learning Rate [7.8125e-05]
2: TRAIN [4][5310/6832]	Time 0.043 (0.105)	Data 0.00084 (0.00094)	Tok/s 38465 (59527)	Loss/tok 1.9397 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][5310/6832]	Time 0.043 (0.105)	Data 0.00088 (0.00092)	Tok/s 33382 (59158)	Loss/tok 2.0802 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5310/6832]	Time 0.043 (0.105)	Data 0.00089 (0.00094)	Tok/s 41920 (59978)	Loss/tok 2.3881 (3.1315)	Learning Rate [7.8125e-05]
0: TRAIN [4][5310/6832]	Time 0.043 (0.105)	Data 0.00087 (0.00094)	Tok/s 20862 (58697)	Loss/tok 1.6933 (3.1382)	Learning Rate [7.8125e-05]
2: TRAIN [4][5320/6832]	Time 0.070 (0.105)	Data 0.00086 (0.00094)	Tok/s 51366 (59521)	Loss/tok 2.9330 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5320/6832]	Time 0.070 (0.105)	Data 0.00087 (0.00094)	Tok/s 51394 (59972)	Loss/tok 2.9288 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][5320/6832]	Time 0.070 (0.105)	Data 0.00090 (0.00092)	Tok/s 51362 (59152)	Loss/tok 2.9166 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][5320/6832]	Time 0.070 (0.105)	Data 0.00092 (0.00094)	Tok/s 51348 (58691)	Loss/tok 3.0283 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][5330/6832]	Time 0.130 (0.105)	Data 0.00095 (0.00094)	Tok/s 66784 (59529)	Loss/tok 3.1673 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5330/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00094)	Tok/s 66785 (59979)	Loss/tok 3.2035 (3.1313)	Learning Rate [7.8125e-05]
0: TRAIN [4][5330/6832]	Time 0.130 (0.105)	Data 0.00099 (0.00094)	Tok/s 66426 (58699)	Loss/tok 3.2485 (3.1382)	Learning Rate [7.8125e-05]
1: TRAIN [4][5330/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00092)	Tok/s 66507 (59159)	Loss/tok 3.2311 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][5340/6832]	Time 0.078 (0.105)	Data 0.00096 (0.00094)	Tok/s 52783 (59531)	Loss/tok 3.0671 (3.1355)	Learning Rate [7.8125e-05]
3: TRAIN [4][5340/6832]	Time 0.078 (0.105)	Data 0.00099 (0.00094)	Tok/s 52752 (59981)	Loss/tok 2.9691 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][5340/6832]	Time 0.078 (0.105)	Data 0.00101 (0.00092)	Tok/s 52783 (59161)	Loss/tok 2.9427 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][5340/6832]	Time 0.078 (0.105)	Data 0.00099 (0.00094)	Tok/s 52745 (58701)	Loss/tok 2.9671 (3.1382)	Learning Rate [7.8125e-05]
2: TRAIN [4][5350/6832]	Time 0.054 (0.105)	Data 0.00087 (0.00094)	Tok/s 45344 (59524)	Loss/tok 2.6561 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][5350/6832]	Time 0.054 (0.105)	Data 0.00089 (0.00092)	Tok/s 45392 (59153)	Loss/tok 2.5653 (3.1345)	Learning Rate [7.8125e-05]
3: TRAIN [4][5350/6832]	Time 0.054 (0.105)	Data 0.00093 (0.00094)	Tok/s 47446 (59976)	Loss/tok 2.5203 (3.1310)	Learning Rate [7.8125e-05]
0: TRAIN [4][5350/6832]	Time 0.054 (0.105)	Data 0.00088 (0.00094)	Tok/s 43197 (58691)	Loss/tok 2.4787 (3.1381)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][5360/6832]	Time 0.070 (0.105)	Data 0.00101 (0.00094)	Tok/s 50851 (59522)	Loss/tok 2.8643 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][5360/6832]	Time 0.070 (0.105)	Data 0.00103 (0.00094)	Tok/s 50905 (59974)	Loss/tok 2.9027 (3.1310)	Learning Rate [7.8125e-05]
1: TRAIN [4][5360/6832]	Time 0.071 (0.105)	Data 0.00091 (0.00092)	Tok/s 50668 (59151)	Loss/tok 2.8215 (3.1343)	Learning Rate [7.8125e-05]
0: TRAIN [4][5360/6832]	Time 0.071 (0.105)	Data 0.00090 (0.00094)	Tok/s 50635 (58687)	Loss/tok 2.8697 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5370/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 62055 (59514)	Loss/tok 3.1373 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][5370/6832]	Time 0.120 (0.105)	Data 0.00099 (0.00092)	Tok/s 62061 (59143)	Loss/tok 3.1834 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][5370/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00094)	Tok/s 62208 (59967)	Loss/tok 3.3445 (3.1311)	Learning Rate [7.8125e-05]
0: TRAIN [4][5370/6832]	Time 0.120 (0.105)	Data 0.00097 (0.00094)	Tok/s 62051 (58680)	Loss/tok 3.3138 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5380/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00094)	Tok/s 51556 (59517)	Loss/tok 3.1386 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][5380/6832]	Time 0.111 (0.105)	Data 0.00090 (0.00092)	Tok/s 51719 (59146)	Loss/tok 3.2501 (3.1344)	Learning Rate [7.8125e-05]
3: TRAIN [4][5380/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00094)	Tok/s 51558 (59970)	Loss/tok 3.3907 (3.1312)	Learning Rate [7.8125e-05]
0: TRAIN [4][5380/6832]	Time 0.112 (0.105)	Data 0.00086 (0.00094)	Tok/s 51570 (58683)	Loss/tok 3.1301 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][5390/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00094)	Tok/s 50974 (59509)	Loss/tok 3.0071 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][5390/6832]	Time 0.091 (0.105)	Data 0.00086 (0.00092)	Tok/s 50757 (59138)	Loss/tok 3.0342 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5390/6832]	Time 0.091 (0.105)	Data 0.00088 (0.00094)	Tok/s 52172 (59962)	Loss/tok 3.0010 (3.1312)	Learning Rate [7.8125e-05]
0: TRAIN [4][5390/6832]	Time 0.091 (0.105)	Data 0.00085 (0.00094)	Tok/s 50772 (58676)	Loss/tok 2.8344 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5400/6832]	Time 0.106 (0.105)	Data 0.00090 (0.00094)	Tok/s 51983 (59517)	Loss/tok 3.2007 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][5400/6832]	Time 0.106 (0.105)	Data 0.00093 (0.00094)	Tok/s 53199 (59971)	Loss/tok 3.2132 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][5400/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00092)	Tok/s 51897 (59146)	Loss/tok 2.9375 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][5400/6832]	Time 0.106 (0.105)	Data 0.00088 (0.00094)	Tok/s 51911 (58684)	Loss/tok 3.0462 (3.1380)	Learning Rate [7.8125e-05]
1: TRAIN [4][5410/6832]	Time 0.133 (0.105)	Data 0.00093 (0.00092)	Tok/s 90835 (59152)	Loss/tok 2.9910 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][5410/6832]	Time 0.133 (0.105)	Data 0.00090 (0.00094)	Tok/s 89813 (58690)	Loss/tok 3.0250 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5410/6832]	Time 0.133 (0.105)	Data 0.00093 (0.00094)	Tok/s 91929 (59522)	Loss/tok 2.9728 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][5410/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00094)	Tok/s 93808 (59976)	Loss/tok 2.8976 (3.1312)	Learning Rate [7.8125e-05]
2: TRAIN [4][5420/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00094)	Tok/s 62400 (59522)	Loss/tok 3.1712 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5420/6832]	Time 0.123 (0.105)	Data 0.00087 (0.00094)	Tok/s 62404 (59976)	Loss/tok 3.3701 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][5420/6832]	Time 0.123 (0.105)	Data 0.00093 (0.00092)	Tok/s 61816 (59152)	Loss/tok 3.2072 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][5420/6832]	Time 0.123 (0.105)	Data 0.00090 (0.00094)	Tok/s 61355 (58691)	Loss/tok 3.3119 (3.1381)	Learning Rate [7.8125e-05]
1: TRAIN [4][5430/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00092)	Tok/s 73061 (59155)	Loss/tok 3.0945 (3.1343)	Learning Rate [7.8125e-05]
2: TRAIN [4][5430/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00094)	Tok/s 73440 (59524)	Loss/tok 3.2163 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][5430/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 72436 (58694)	Loss/tok 3.1819 (3.1382)	Learning Rate [7.8125e-05]
3: TRAIN [4][5430/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 73456 (59979)	Loss/tok 3.2560 (3.1313)	Learning Rate [7.8125e-05]
2: TRAIN [4][5440/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00094)	Tok/s 51171 (59524)	Loss/tok 2.8761 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][5440/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00094)	Tok/s 51170 (59978)	Loss/tok 3.1350 (3.1312)	Learning Rate [7.8125e-05]
1: TRAIN [4][5440/6832]	Time 0.118 (0.105)	Data 0.00090 (0.00092)	Tok/s 51171 (59155)	Loss/tok 3.1679 (3.1343)	Learning Rate [7.8125e-05]
0: TRAIN [4][5440/6832]	Time 0.118 (0.105)	Data 0.00087 (0.00094)	Tok/s 51162 (58695)	Loss/tok 3.0490 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][5450/6832]	Time 0.089 (0.105)	Data 0.00087 (0.00094)	Tok/s 53144 (59527)	Loss/tok 2.9390 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][5450/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00092)	Tok/s 53112 (59158)	Loss/tok 3.0846 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5450/6832]	Time 0.089 (0.105)	Data 0.00086 (0.00094)	Tok/s 53141 (59981)	Loss/tok 3.1146 (3.1312)	Learning Rate [7.8125e-05]
0: TRAIN [4][5450/6832]	Time 0.089 (0.105)	Data 0.00091 (0.00094)	Tok/s 53128 (58698)	Loss/tok 3.2100 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][5460/6832]	Time 0.057 (0.105)	Data 0.00085 (0.00094)	Tok/s 47558 (59517)	Loss/tok 2.5299 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][5460/6832]	Time 0.057 (0.105)	Data 0.00091 (0.00092)	Tok/s 45967 (59149)	Loss/tok 2.6441 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5460/6832]	Time 0.057 (0.105)	Data 0.00086 (0.00094)	Tok/s 47564 (59971)	Loss/tok 2.5434 (3.1311)	Learning Rate [7.8125e-05]
0: TRAIN [4][5460/6832]	Time 0.057 (0.105)	Data 0.00095 (0.00094)	Tok/s 45277 (58689)	Loss/tok 2.7056 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][5470/6832]	Time 0.132 (0.105)	Data 0.00084 (0.00094)	Tok/s 92364 (59534)	Loss/tok 3.0260 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][5470/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00092)	Tok/s 91079 (59165)	Loss/tok 2.9984 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][5470/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 94114 (59988)	Loss/tok 2.8255 (3.1309)	Learning Rate [7.8125e-05]
0: TRAIN [4][5470/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 90115 (58705)	Loss/tok 3.0920 (3.1380)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][5480/6832]	Time 0.086 (0.105)	Data 0.00102 (0.00094)	Tok/s 53714 (59533)	Loss/tok 3.0595 (3.1348)	Learning Rate [7.8125e-05]
1: TRAIN [4][5480/6832]	Time 0.086 (0.105)	Data 0.00089 (0.00092)	Tok/s 53604 (59163)	Loss/tok 3.0397 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][5480/6832]	Time 0.086 (0.105)	Data 0.00088 (0.00094)	Tok/s 53597 (58701)	Loss/tok 3.0283 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][5480/6832]	Time 0.086 (0.105)	Data 0.00098 (0.00094)	Tok/s 54199 (59988)	Loss/tok 3.0517 (3.1308)	Learning Rate [7.8125e-05]
2: TRAIN [4][5490/6832]	Time 0.083 (0.105)	Data 0.00087 (0.00094)	Tok/s 53740 (59538)	Loss/tok 3.0843 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][5490/6832]	Time 0.083 (0.105)	Data 0.00090 (0.00092)	Tok/s 53774 (59169)	Loss/tok 3.1574 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][5490/6832]	Time 0.083 (0.105)	Data 0.00089 (0.00094)	Tok/s 53260 (58707)	Loss/tok 2.9783 (3.1379)	Learning Rate [7.8125e-05]
3: TRAIN [4][5490/6832]	Time 0.083 (0.105)	Data 0.00086 (0.00094)	Tok/s 53750 (59993)	Loss/tok 3.1901 (3.1308)	Learning Rate [7.8125e-05]
2: TRAIN [4][5500/6832]	Time 0.098 (0.105)	Data 0.00086 (0.00094)	Tok/s 53422 (59540)	Loss/tok 3.0409 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][5500/6832]	Time 0.098 (0.105)	Data 0.00088 (0.00094)	Tok/s 52106 (58710)	Loss/tok 3.0997 (3.1380)	Learning Rate [7.8125e-05]
3: TRAIN [4][5500/6832]	Time 0.098 (0.105)	Data 0.00088 (0.00094)	Tok/s 53435 (59995)	Loss/tok 3.1335 (3.1308)	Learning Rate [7.8125e-05]
1: TRAIN [4][5500/6832]	Time 0.099 (0.105)	Data 0.00090 (0.00092)	Tok/s 51776 (59171)	Loss/tok 2.9652 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][5510/6832]	Time 0.080 (0.105)	Data 0.00084 (0.00094)	Tok/s 54018 (59544)	Loss/tok 2.9224 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5510/6832]	Time 0.079 (0.105)	Data 0.00086 (0.00094)	Tok/s 54746 (59998)	Loss/tok 3.1194 (3.1309)	Learning Rate [7.8125e-05]
1: TRAIN [4][5510/6832]	Time 0.080 (0.105)	Data 0.00087 (0.00092)	Tok/s 53019 (59174)	Loss/tok 2.8864 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][5510/6832]	Time 0.080 (0.105)	Data 0.00085 (0.00094)	Tok/s 53025 (58713)	Loss/tok 2.9117 (3.1380)	Learning Rate [7.8125e-05]
1: TRAIN [4][5520/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00092)	Tok/s 54411 (59172)	Loss/tok 3.2313 (3.1341)	Learning Rate [7.8125e-05]
2: TRAIN [4][5520/6832]	Time 0.120 (0.105)	Data 0.00113 (0.00094)	Tok/s 54376 (59543)	Loss/tok 3.3657 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5520/6832]	Time 0.120 (0.105)	Data 0.00116 (0.00094)	Tok/s 54427 (59998)	Loss/tok 3.2129 (3.1308)	Learning Rate [7.8125e-05]
0: TRAIN [4][5520/6832]	Time 0.120 (0.105)	Data 0.00101 (0.00094)	Tok/s 54409 (58710)	Loss/tok 3.0628 (3.1380)	Learning Rate [7.8125e-05]
2: TRAIN [4][5530/6832]	Time 0.094 (0.105)	Data 0.00086 (0.00094)	Tok/s 54261 (59538)	Loss/tok 3.1311 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5530/6832]	Time 0.094 (0.105)	Data 0.00086 (0.00094)	Tok/s 54266 (59993)	Loss/tok 2.9386 (3.1309)	Learning Rate [7.8125e-05]
1: TRAIN [4][5530/6832]	Time 0.094 (0.105)	Data 0.00086 (0.00092)	Tok/s 53886 (59168)	Loss/tok 3.0825 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][5530/6832]	Time 0.094 (0.105)	Data 0.00094 (0.00094)	Tok/s 52886 (58706)	Loss/tok 3.0911 (3.1381)	Learning Rate [7.8125e-05]
2: TRAIN [4][5540/6832]	Time 0.087 (0.105)	Data 0.00086 (0.00094)	Tok/s 52904 (59536)	Loss/tok 3.1938 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][5540/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00092)	Tok/s 51628 (59166)	Loss/tok 2.9746 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][5540/6832]	Time 0.087 (0.105)	Data 0.00085 (0.00094)	Tok/s 53057 (59990)	Loss/tok 3.0912 (3.1310)	Learning Rate [7.8125e-05]
0: TRAIN [4][5540/6832]	Time 0.087 (0.105)	Data 0.00089 (0.00094)	Tok/s 51621 (58704)	Loss/tok 2.8869 (3.1382)	Learning Rate [7.8125e-05]
2: TRAIN [4][5550/6832]	Time 0.111 (0.105)	Data 0.00095 (0.00094)	Tok/s 53218 (59528)	Loss/tok 3.1898 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][5550/6832]	Time 0.111 (0.105)	Data 0.00099 (0.00092)	Tok/s 53200 (59158)	Loss/tok 3.0324 (3.1341)	Learning Rate [7.8125e-05]
3: TRAIN [4][5550/6832]	Time 0.111 (0.105)	Data 0.00096 (0.00094)	Tok/s 54174 (59983)	Loss/tok 3.1231 (3.1308)	Learning Rate [7.8125e-05]
0: TRAIN [4][5550/6832]	Time 0.111 (0.105)	Data 0.00093 (0.00094)	Tok/s 53249 (58694)	Loss/tok 3.0962 (3.1381)	Learning Rate [7.8125e-05]
1: TRAIN [4][5560/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00092)	Tok/s 61391 (59158)	Loss/tok 3.4078 (3.1342)	Learning Rate [7.8125e-05]
2: TRAIN [4][5560/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00094)	Tok/s 61742 (59528)	Loss/tok 3.3285 (3.1351)	Learning Rate [7.8125e-05]
0: TRAIN [4][5560/6832]	Time 0.127 (0.105)	Data 0.00089 (0.00094)	Tok/s 61356 (58695)	Loss/tok 3.3273 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][5560/6832]	Time 0.127 (0.105)	Data 0.00091 (0.00094)	Tok/s 62321 (59982)	Loss/tok 3.3185 (3.1309)	Learning Rate [7.8125e-05]
1: TRAIN [4][5570/6832]	Time 0.051 (0.105)	Data 0.00089 (0.00092)	Tok/s 39794 (59160)	Loss/tok 2.3588 (3.1341)	Learning Rate [7.8125e-05]
2: TRAIN [4][5570/6832]	Time 0.052 (0.105)	Data 0.00087 (0.00094)	Tok/s 42222 (59531)	Loss/tok 2.4980 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][5570/6832]	Time 0.051 (0.105)	Data 0.00091 (0.00094)	Tok/s 37612 (58695)	Loss/tok 2.2935 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][5570/6832]	Time 0.052 (0.105)	Data 0.00089 (0.00094)	Tok/s 43219 (59987)	Loss/tok 2.4854 (3.1308)	Learning Rate [7.8125e-05]
3: TRAIN [4][5580/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 71072 (59994)	Loss/tok 3.3125 (3.1309)	Learning Rate [7.8125e-05]
2: TRAIN [4][5580/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 70590 (59538)	Loss/tok 3.3390 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][5580/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 70094 (59167)	Loss/tok 3.2968 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][5580/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 70071 (58702)	Loss/tok 3.3695 (3.1381)	Learning Rate [7.8125e-05]
0: TRAIN [4][5590/6832]	Time 0.080 (0.105)	Data 0.00086 (0.00094)	Tok/s 55558 (58704)	Loss/tok 2.8278 (3.1381)	Learning Rate [7.8125e-05]
1: TRAIN [4][5590/6832]	Time 0.080 (0.105)	Data 0.00118 (0.00092)	Tok/s 56171 (59168)	Loss/tok 3.0612 (3.1341)	Learning Rate [7.8125e-05]
2: TRAIN [4][5590/6832]	Time 0.080 (0.105)	Data 0.00084 (0.00094)	Tok/s 55956 (59539)	Loss/tok 3.0628 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5590/6832]	Time 0.080 (0.105)	Data 0.00086 (0.00094)	Tok/s 55974 (59994)	Loss/tok 3.0792 (3.1308)	Learning Rate [7.8125e-05]
2: TRAIN [4][5600/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 81930 (59539)	Loss/tok 3.0121 (3.1349)	Learning Rate [7.8125e-05]
1: TRAIN [4][5600/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00092)	Tok/s 81866 (59169)	Loss/tok 3.2209 (3.1341)	Learning Rate [7.8125e-05]
0: TRAIN [4][5600/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 81093 (58705)	Loss/tok 3.0562 (3.1381)	Learning Rate [7.8125e-05]
3: TRAIN [4][5600/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 82809 (59994)	Loss/tok 3.1247 (3.1310)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][5610/6832]	Time 0.085 (0.105)	Data 0.00085 (0.00094)	Tok/s 53971 (59536)	Loss/tok 3.0166 (3.1350)	Learning Rate [7.8125e-05]
1: TRAIN [4][5610/6832]	Time 0.085 (0.105)	Data 0.00088 (0.00092)	Tok/s 53963 (59166)	Loss/tok 3.1565 (3.1342)	Learning Rate [7.8125e-05]
3: TRAIN [4][5610/6832]	Time 0.085 (0.105)	Data 0.00089 (0.00094)	Tok/s 53987 (59992)	Loss/tok 3.0988 (3.1311)	Learning Rate [7.8125e-05]
0: TRAIN [4][5610/6832]	Time 0.085 (0.105)	Data 0.00090 (0.00094)	Tok/s 53997 (58703)	Loss/tok 3.0716 (3.1383)	Learning Rate [7.8125e-05]
2: TRAIN [4][5620/6832]	Time 0.078 (0.105)	Data 0.00089 (0.00094)	Tok/s 49357 (59533)	Loss/tok 3.1490 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][5620/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00094)	Tok/s 50799 (59988)	Loss/tok 2.9861 (3.1311)	Learning Rate [7.8125e-05]
1: TRAIN [4][5620/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00092)	Tok/s 49222 (59163)	Loss/tok 3.0562 (3.1342)	Learning Rate [7.8125e-05]
0: TRAIN [4][5620/6832]	Time 0.078 (0.105)	Data 0.00090 (0.00094)	Tok/s 49237 (58700)	Loss/tok 2.8671 (3.1383)	Learning Rate [7.8125e-05]
1: TRAIN [4][5630/6832]	Time 0.095 (0.105)	Data 0.00093 (0.00092)	Tok/s 53585 (59162)	Loss/tok 3.1548 (3.1343)	Learning Rate [7.8125e-05]
2: TRAIN [4][5630/6832]	Time 0.095 (0.105)	Data 0.00089 (0.00094)	Tok/s 53800 (59532)	Loss/tok 3.1216 (3.1351)	Learning Rate [7.8125e-05]
0: TRAIN [4][5630/6832]	Time 0.095 (0.105)	Data 0.00096 (0.00094)	Tok/s 52483 (58696)	Loss/tok 3.1915 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][5630/6832]	Time 0.095 (0.105)	Data 0.00088 (0.00094)	Tok/s 53801 (59987)	Loss/tok 3.1642 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][5640/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00092)	Tok/s 55493 (59167)	Loss/tok 2.9339 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5640/6832]	Time 0.078 (0.105)	Data 0.00099 (0.00094)	Tok/s 55547 (59992)	Loss/tok 3.1226 (3.1313)	Learning Rate [7.8125e-05]
2: TRAIN [4][5640/6832]	Time 0.078 (0.105)	Data 0.00098 (0.00094)	Tok/s 55560 (59537)	Loss/tok 2.9459 (3.1352)	Learning Rate [7.8125e-05]
0: TRAIN [4][5640/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00094)	Tok/s 55515 (58702)	Loss/tok 3.0199 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][5650/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00094)	Tok/s 53171 (59532)	Loss/tok 3.0720 (3.1351)	Learning Rate [7.8125e-05]
1: TRAIN [4][5650/6832]	Time 0.096 (0.105)	Data 0.00088 (0.00092)	Tok/s 52087 (59162)	Loss/tok 3.3006 (3.1343)	Learning Rate [7.8125e-05]
3: TRAIN [4][5650/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00094)	Tok/s 53438 (59987)	Loss/tok 3.0190 (3.1312)	Learning Rate [7.8125e-05]
0: TRAIN [4][5650/6832]	Time 0.096 (0.105)	Data 0.00091 (0.00094)	Tok/s 52138 (58697)	Loss/tok 3.1039 (3.1385)	Learning Rate [7.8125e-05]
1: TRAIN [4][5660/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00092)	Tok/s 68849 (59171)	Loss/tok 3.3230 (3.1344)	Learning Rate [7.8125e-05]
2: TRAIN [4][5660/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00094)	Tok/s 68833 (59541)	Loss/tok 3.2832 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][5660/6832]	Time 0.130 (0.105)	Data 0.00084 (0.00094)	Tok/s 68861 (59996)	Loss/tok 3.2641 (3.1312)	Learning Rate [7.8125e-05]
0: TRAIN [4][5660/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 68290 (58707)	Loss/tok 3.2011 (3.1387)	Learning Rate [7.8125e-05]
2: TRAIN [4][5670/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 77482 (59553)	Loss/tok 3.0872 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][5670/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00094)	Tok/s 78492 (60007)	Loss/tok 3.2482 (3.1313)	Learning Rate [7.8125e-05]
1: TRAIN [4][5670/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00092)	Tok/s 77371 (59182)	Loss/tok 3.0666 (3.1344)	Learning Rate [7.8125e-05]
0: TRAIN [4][5670/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 77093 (58718)	Loss/tok 3.1157 (3.1386)	Learning Rate [7.8125e-05]
2: TRAIN [4][5680/6832]	Time 0.115 (0.105)	Data 0.00103 (0.00094)	Tok/s 59138 (59554)	Loss/tok 3.0358 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][5680/6832]	Time 0.115 (0.105)	Data 0.00100 (0.00094)	Tok/s 59171 (60008)	Loss/tok 3.0898 (3.1314)	Learning Rate [7.8125e-05]
1: TRAIN [4][5680/6832]	Time 0.115 (0.105)	Data 0.00095 (0.00092)	Tok/s 58823 (59184)	Loss/tok 3.1559 (3.1346)	Learning Rate [7.8125e-05]
0: TRAIN [4][5680/6832]	Time 0.115 (0.105)	Data 0.00100 (0.00094)	Tok/s 57985 (58720)	Loss/tok 3.1133 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][5690/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00092)	Tok/s 85114 (59185)	Loss/tok 3.1886 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][5690/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 85907 (59555)	Loss/tok 3.1586 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][5690/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 86274 (60009)	Loss/tok 3.0783 (3.1314)	Learning Rate [7.8125e-05]
0: TRAIN [4][5690/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 84794 (58722)	Loss/tok 3.0545 (3.1388)	Learning Rate [7.8125e-05]
1: TRAIN [4][5700/6832]	Time 0.062 (0.105)	Data 0.00088 (0.00092)	Tok/s 47557 (59180)	Loss/tok 2.7683 (3.1345)	Learning Rate [7.8125e-05]
2: TRAIN [4][5700/6832]	Time 0.062 (0.105)	Data 0.00100 (0.00094)	Tok/s 47587 (59551)	Loss/tok 2.7025 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][5700/6832]	Time 0.062 (0.105)	Data 0.00097 (0.00094)	Tok/s 49473 (60006)	Loss/tok 2.7518 (3.1313)	Learning Rate [7.8125e-05]
0: TRAIN [4][5700/6832]	Time 0.062 (0.105)	Data 0.00094 (0.00094)	Tok/s 47519 (58714)	Loss/tok 2.8084 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][5710/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00092)	Tok/s 51795 (59185)	Loss/tok 2.9687 (3.1346)	Learning Rate [7.8125e-05]
3: TRAIN [4][5710/6832]	Time 0.077 (0.105)	Data 0.00091 (0.00094)	Tok/s 51807 (60010)	Loss/tok 2.9666 (3.1312)	Learning Rate [7.8125e-05]
2: TRAIN [4][5710/6832]	Time 0.077 (0.105)	Data 0.00095 (0.00094)	Tok/s 51793 (59556)	Loss/tok 3.0497 (3.1352)	Learning Rate [7.8125e-05]
0: TRAIN [4][5710/6832]	Time 0.077 (0.105)	Data 0.00094 (0.00094)	Tok/s 51803 (58720)	Loss/tok 2.9099 (3.1386)	Learning Rate [7.8125e-05]
1: TRAIN [4][5720/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00092)	Tok/s 72198 (59186)	Loss/tok 3.2893 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][5720/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 72759 (59557)	Loss/tok 3.1378 (3.1352)	Learning Rate [7.8125e-05]
3: TRAIN [4][5720/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 73203 (60011)	Loss/tok 3.2978 (3.1315)	Learning Rate [7.8125e-05]
0: TRAIN [4][5720/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 72212 (58721)	Loss/tok 3.2937 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][5730/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00092)	Tok/s 56396 (59184)	Loss/tok 3.0867 (3.1346)	Learning Rate [7.8125e-05]
0: TRAIN [4][5730/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00094)	Tok/s 55503 (58719)	Loss/tok 3.3246 (3.1387)	Learning Rate [7.8125e-05]
3: TRAIN [4][5730/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00094)	Tok/s 56377 (60008)	Loss/tok 3.1682 (3.1315)	Learning Rate [7.8125e-05]
2: TRAIN [4][5730/6832]	Time 0.120 (0.105)	Data 0.00098 (0.00094)	Tok/s 56354 (59554)	Loss/tok 3.1310 (3.1351)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][5740/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00092)	Tok/s 74543 (59194)	Loss/tok 3.3130 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][5740/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 75296 (59565)	Loss/tok 3.2907 (3.1353)	Learning Rate [7.8125e-05]
0: TRAIN [4][5740/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 74576 (58730)	Loss/tok 3.1205 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][5740/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00094)	Tok/s 75520 (60018)	Loss/tok 3.1762 (3.1316)	Learning Rate [7.8125e-05]
1: TRAIN [4][5750/6832]	Time 0.049 (0.105)	Data 0.00085 (0.00092)	Tok/s 42105 (59203)	Loss/tok 2.3848 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][5750/6832]	Time 0.049 (0.105)	Data 0.00091 (0.00094)	Tok/s 39913 (58738)	Loss/tok 2.1887 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][5750/6832]	Time 0.049 (0.105)	Data 0.00086 (0.00094)	Tok/s 44567 (59573)	Loss/tok 2.3361 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][5750/6832]	Time 0.049 (0.105)	Data 0.00088 (0.00094)	Tok/s 45603 (60027)	Loss/tok 2.3874 (3.1317)	Learning Rate [7.8125e-05]
2: TRAIN [4][5760/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00094)	Tok/s 53232 (59565)	Loss/tok 3.0225 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][5760/6832]	Time 0.084 (0.105)	Data 0.00092 (0.00092)	Tok/s 53242 (59195)	Loss/tok 2.9710 (3.1346)	Learning Rate [7.8125e-05]
3: TRAIN [4][5760/6832]	Time 0.084 (0.105)	Data 0.00089 (0.00094)	Tok/s 53224 (60020)	Loss/tok 2.9865 (3.1316)	Learning Rate [7.8125e-05]
0: TRAIN [4][5760/6832]	Time 0.084 (0.105)	Data 0.00098 (0.00094)	Tok/s 52537 (58729)	Loss/tok 3.0703 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][5770/6832]	Time 0.122 (0.105)	Data 0.00087 (0.00092)	Tok/s 62787 (59194)	Loss/tok 3.2596 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][5770/6832]	Time 0.122 (0.105)	Data 0.00088 (0.00094)	Tok/s 62733 (59564)	Loss/tok 3.3592 (3.1353)	Learning Rate [7.8125e-05]
0: TRAIN [4][5770/6832]	Time 0.122 (0.105)	Data 0.00090 (0.00094)	Tok/s 62759 (58728)	Loss/tok 3.2565 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][5770/6832]	Time 0.122 (0.105)	Data 0.00086 (0.00094)	Tok/s 63437 (60018)	Loss/tok 3.1264 (3.1317)	Learning Rate [7.8125e-05]
2: TRAIN [4][5780/6832]	Time 0.101 (0.105)	Data 0.00085 (0.00094)	Tok/s 52989 (59565)	Loss/tok 2.9989 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][5780/6832]	Time 0.101 (0.105)	Data 0.00087 (0.00092)	Tok/s 52989 (59195)	Loss/tok 2.9518 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][5780/6832]	Time 0.101 (0.105)	Data 0.00089 (0.00094)	Tok/s 52985 (58729)	Loss/tok 3.0329 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][5780/6832]	Time 0.101 (0.105)	Data 0.00086 (0.00094)	Tok/s 53871 (60019)	Loss/tok 3.0303 (3.1317)	Learning Rate [7.8125e-05]
2: TRAIN [4][5790/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00094)	Tok/s 83186 (59566)	Loss/tok 3.1253 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][5790/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00092)	Tok/s 83047 (59196)	Loss/tok 3.1177 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][5790/6832]	Time 0.132 (0.105)	Data 0.00098 (0.00094)	Tok/s 84057 (60020)	Loss/tok 3.1265 (3.1318)	Learning Rate [7.8125e-05]
0: TRAIN [4][5790/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00094)	Tok/s 82139 (58731)	Loss/tok 3.0483 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][5800/6832]	Time 0.132 (0.105)	Data 0.00107 (0.00094)	Tok/s 71970 (59569)	Loss/tok 3.2022 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][5800/6832]	Time 0.132 (0.105)	Data 0.00102 (0.00094)	Tok/s 72002 (60022)	Loss/tok 3.3142 (3.1318)	Learning Rate [7.8125e-05]
1: TRAIN [4][5800/6832]	Time 0.132 (0.105)	Data 0.00107 (0.00092)	Tok/s 71657 (59199)	Loss/tok 3.3154 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][5800/6832]	Time 0.131 (0.105)	Data 0.00105 (0.00094)	Tok/s 71161 (58734)	Loss/tok 3.2609 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][5810/6832]	Time 0.102 (0.105)	Data 0.00095 (0.00094)	Tok/s 51527 (59567)	Loss/tok 2.9057 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5810/6832]	Time 0.102 (0.105)	Data 0.00088 (0.00092)	Tok/s 51592 (59198)	Loss/tok 3.0459 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5810/6832]	Time 0.102 (0.105)	Data 0.00095 (0.00094)	Tok/s 51513 (60020)	Loss/tok 3.1302 (3.1319)	Learning Rate [7.8125e-05]
0: TRAIN [4][5810/6832]	Time 0.102 (0.105)	Data 0.00097 (0.00094)	Tok/s 51588 (58733)	Loss/tok 3.1460 (3.1389)	Learning Rate [7.8125e-05]
2: TRAIN [4][5820/6832]	Time 0.082 (0.105)	Data 0.00095 (0.00094)	Tok/s 51821 (59564)	Loss/tok 2.9086 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][5820/6832]	Time 0.082 (0.105)	Data 0.00090 (0.00092)	Tok/s 51809 (59195)	Loss/tok 2.9365 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][5820/6832]	Time 0.082 (0.105)	Data 0.00094 (0.00094)	Tok/s 51309 (58730)	Loss/tok 2.9323 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][5820/6832]	Time 0.082 (0.105)	Data 0.00097 (0.00094)	Tok/s 51822 (60018)	Loss/tok 2.8861 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][5830/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 63894 (59569)	Loss/tok 3.2847 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5830/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00092)	Tok/s 63876 (59200)	Loss/tok 3.3420 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][5830/6832]	Time 0.130 (0.105)	Data 0.00090 (0.00094)	Tok/s 64039 (60022)	Loss/tok 3.4357 (3.1319)	Learning Rate [7.8125e-05]
0: TRAIN [4][5830/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 63889 (58735)	Loss/tok 3.2401 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][5840/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00092)	Tok/s 52890 (59190)	Loss/tok 3.2586 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][5840/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00094)	Tok/s 52827 (59559)	Loss/tok 3.3269 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][5840/6832]	Time 0.116 (0.105)	Data 0.00097 (0.00094)	Tok/s 52139 (58725)	Loss/tok 3.1993 (3.1386)	Learning Rate [7.8125e-05]
3: TRAIN [4][5840/6832]	Time 0.116 (0.105)	Data 0.00094 (0.00094)	Tok/s 52816 (60013)	Loss/tok 3.1821 (3.1318)	Learning Rate [7.8125e-05]
2: TRAIN [4][5850/6832]	Time 0.126 (0.105)	Data 0.00085 (0.00094)	Tok/s 65579 (59559)	Loss/tok 3.2853 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5850/6832]	Time 0.126 (0.105)	Data 0.00095 (0.00092)	Tok/s 64824 (59190)	Loss/tok 3.2381 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][5850/6832]	Time 0.126 (0.105)	Data 0.00089 (0.00094)	Tok/s 65843 (60012)	Loss/tok 3.2552 (3.1319)	Learning Rate [7.8125e-05]
0: TRAIN [4][5850/6832]	Time 0.126 (0.105)	Data 0.00098 (0.00094)	Tok/s 64802 (58726)	Loss/tok 3.0700 (3.1386)	Learning Rate [7.8125e-05]
2: TRAIN [4][5860/6832]	Time 0.087 (0.105)	Data 0.00085 (0.00094)	Tok/s 53114 (59563)	Loss/tok 3.0907 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][5860/6832]	Time 0.087 (0.105)	Data 0.00090 (0.00092)	Tok/s 52069 (59194)	Loss/tok 2.9188 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][5860/6832]	Time 0.087 (0.105)	Data 0.00087 (0.00094)	Tok/s 53090 (60016)	Loss/tok 3.1375 (3.1319)	Learning Rate [7.8125e-05]
0: TRAIN [4][5860/6832]	Time 0.087 (0.105)	Data 0.00092 (0.00094)	Tok/s 51644 (58730)	Loss/tok 3.0989 (3.1386)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][5870/6832]	Time 0.113 (0.105)	Data 0.00091 (0.00094)	Tok/s 52331 (59565)	Loss/tok 3.3237 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][5870/6832]	Time 0.112 (0.105)	Data 0.00085 (0.00092)	Tok/s 52342 (59196)	Loss/tok 3.0813 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][5870/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00094)	Tok/s 52342 (60018)	Loss/tok 3.1193 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][5870/6832]	Time 0.112 (0.105)	Data 0.00095 (0.00094)	Tok/s 51663 (58732)	Loss/tok 3.0142 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][5880/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00092)	Tok/s 62673 (59189)	Loss/tok 3.3739 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][5880/6832]	Time 0.131 (0.105)	Data 0.00092 (0.00094)	Tok/s 62697 (58725)	Loss/tok 3.2243 (3.1386)	Learning Rate [7.8125e-05]
3: TRAIN [4][5880/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00094)	Tok/s 63606 (60011)	Loss/tok 3.4169 (3.1319)	Learning Rate [7.8125e-05]
2: TRAIN [4][5880/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00094)	Tok/s 63342 (59558)	Loss/tok 3.2922 (3.1355)	Learning Rate [7.8125e-05]
2: TRAIN [4][5890/6832]	Time 0.129 (0.105)	Data 0.00093 (0.00094)	Tok/s 66366 (59554)	Loss/tok 3.2763 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5890/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00092)	Tok/s 66367 (59186)	Loss/tok 3.1881 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][5890/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 65744 (58722)	Loss/tok 3.1427 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][5890/6832]	Time 0.129 (0.105)	Data 0.00106 (0.00094)	Tok/s 66414 (60007)	Loss/tok 3.5541 (3.1321)	Learning Rate [7.8125e-05]
1: TRAIN [4][5900/6832]	Time 0.116 (0.105)	Data 0.00086 (0.00092)	Tok/s 58701 (59192)	Loss/tok 3.1835 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][5900/6832]	Time 0.116 (0.105)	Data 0.00095 (0.00094)	Tok/s 58674 (59561)	Loss/tok 3.1745 (3.1353)	Learning Rate [7.8125e-05]
0: TRAIN [4][5900/6832]	Time 0.116 (0.105)	Data 0.00092 (0.00094)	Tok/s 58645 (58726)	Loss/tok 3.2930 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][5900/6832]	Time 0.116 (0.105)	Data 0.00107 (0.00094)	Tok/s 58678 (60014)	Loss/tok 3.0125 (3.1320)	Learning Rate [7.8125e-05]
1: TRAIN [4][5910/6832]	Time 0.087 (0.105)	Data 0.00085 (0.00092)	Tok/s 54266 (59185)	Loss/tok 3.0579 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][5910/6832]	Time 0.087 (0.105)	Data 0.00095 (0.00094)	Tok/s 54324 (59554)	Loss/tok 3.1454 (3.1352)	Learning Rate [7.8125e-05]
0: TRAIN [4][5910/6832]	Time 0.087 (0.105)	Data 0.00091 (0.00094)	Tok/s 54297 (58719)	Loss/tok 2.9842 (3.1384)	Learning Rate [7.8125e-05]
3: TRAIN [4][5910/6832]	Time 0.087 (0.105)	Data 0.00109 (0.00094)	Tok/s 54331 (60007)	Loss/tok 3.2199 (3.1320)	Learning Rate [7.8125e-05]
1: TRAIN [4][5920/6832]	Time 0.109 (0.105)	Data 0.00086 (0.00092)	Tok/s 50633 (59186)	Loss/tok 3.0415 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][5920/6832]	Time 0.109 (0.105)	Data 0.00104 (0.00094)	Tok/s 51442 (59554)	Loss/tok 3.0376 (3.1353)	Learning Rate [7.8125e-05]
3: TRAIN [4][5920/6832]	Time 0.109 (0.105)	Data 0.00119 (0.00094)	Tok/s 51841 (60007)	Loss/tok 3.0390 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][5920/6832]	Time 0.109 (0.105)	Data 0.00091 (0.00094)	Tok/s 50620 (58720)	Loss/tok 3.1239 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][5930/6832]	Time 0.052 (0.105)	Data 0.00094 (0.00094)	Tok/s 47033 (59559)	Loss/tok 2.6296 (3.1352)	Learning Rate [7.8125e-05]
1: TRAIN [4][5930/6832]	Time 0.052 (0.105)	Data 0.00085 (0.00092)	Tok/s 46028 (59190)	Loss/tok 2.4386 (3.1347)	Learning Rate [7.8125e-05]
3: TRAIN [4][5930/6832]	Time 0.052 (0.105)	Data 0.00103 (0.00094)	Tok/s 48504 (60011)	Loss/tok 2.5085 (3.1320)	Learning Rate [7.8125e-05]
0: TRAIN [4][5930/6832]	Time 0.052 (0.105)	Data 0.00092 (0.00094)	Tok/s 44541 (58725)	Loss/tok 2.5486 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][5940/6832]	Time 0.092 (0.105)	Data 0.00099 (0.00094)	Tok/s 52634 (59557)	Loss/tok 3.0267 (3.1353)	Learning Rate [7.8125e-05]
1: TRAIN [4][5940/6832]	Time 0.092 (0.105)	Data 0.00089 (0.00092)	Tok/s 52700 (59188)	Loss/tok 3.2898 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][5940/6832]	Time 0.092 (0.105)	Data 0.00090 (0.00094)	Tok/s 51530 (58723)	Loss/tok 3.0565 (3.1386)	Learning Rate [7.8125e-05]
3: TRAIN [4][5940/6832]	Time 0.092 (0.105)	Data 0.00115 (0.00094)	Tok/s 52639 (60009)	Loss/tok 3.0219 (3.1321)	Learning Rate [7.8125e-05]
1: TRAIN [4][5950/6832]	Time 0.120 (0.105)	Data 0.00090 (0.00092)	Tok/s 57409 (59197)	Loss/tok 3.1976 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][5950/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00094)	Tok/s 57423 (58732)	Loss/tok 3.2355 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][5950/6832]	Time 0.121 (0.105)	Data 0.00100 (0.00094)	Tok/s 57349 (59565)	Loss/tok 3.3630 (3.1354)	Learning Rate [7.8125e-05]
3: TRAIN [4][5950/6832]	Time 0.121 (0.105)	Data 0.00116 (0.00094)	Tok/s 58337 (60018)	Loss/tok 3.2785 (3.1321)	Learning Rate [7.8125e-05]
1: TRAIN [4][5960/6832]	Time 0.073 (0.105)	Data 0.00093 (0.00092)	Tok/s 52399 (59196)	Loss/tok 2.8859 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][5960/6832]	Time 0.073 (0.105)	Data 0.00112 (0.00094)	Tok/s 52421 (59564)	Loss/tok 2.9780 (3.1354)	Learning Rate [7.8125e-05]
0: TRAIN [4][5960/6832]	Time 0.073 (0.105)	Data 0.00092 (0.00094)	Tok/s 51205 (58731)	Loss/tok 3.0488 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][5960/6832]	Time 0.073 (0.105)	Data 0.00112 (0.00094)	Tok/s 52500 (60016)	Loss/tok 3.0193 (3.1322)	Learning Rate [7.8125e-05]
2: TRAIN [4][5970/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00094)	Tok/s 52191 (59560)	Loss/tok 3.2911 (3.1354)	Learning Rate [7.8125e-05]
1: TRAIN [4][5970/6832]	Time 0.120 (0.105)	Data 0.00086 (0.00092)	Tok/s 51361 (59192)	Loss/tok 3.2484 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][5970/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 51365 (58728)	Loss/tok 3.1180 (3.1386)	Learning Rate [7.8125e-05]
3: TRAIN [4][5970/6832]	Time 0.120 (0.105)	Data 0.00107 (0.00094)	Tok/s 52465 (60012)	Loss/tok 3.2038 (3.1323)	Learning Rate [7.8125e-05]
2: TRAIN [4][5980/6832]	Time 0.096 (0.105)	Data 0.00102 (0.00094)	Tok/s 53308 (59550)	Loss/tok 2.8930 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5980/6832]	Time 0.096 (0.105)	Data 0.00093 (0.00092)	Tok/s 52841 (59182)	Loss/tok 3.0355 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][5980/6832]	Time 0.096 (0.105)	Data 0.00094 (0.00094)	Tok/s 51996 (58718)	Loss/tok 2.9913 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][5980/6832]	Time 0.096 (0.105)	Data 0.00109 (0.00094)	Tok/s 53338 (60001)	Loss/tok 3.0978 (3.1323)	Learning Rate [7.8125e-05]
2: TRAIN [4][5990/6832]	Time 0.132 (0.105)	Data 0.00118 (0.00094)	Tok/s 81820 (59567)	Loss/tok 3.1495 (3.1355)	Learning Rate [7.8125e-05]
1: TRAIN [4][5990/6832]	Time 0.132 (0.105)	Data 0.00096 (0.00092)	Tok/s 81349 (59199)	Loss/tok 3.0840 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][5990/6832]	Time 0.132 (0.105)	Data 0.00106 (0.00094)	Tok/s 81192 (58735)	Loss/tok 3.1090 (3.1386)	Learning Rate [7.8125e-05]
3: TRAIN [4][5990/6832]	Time 0.132 (0.105)	Data 0.00129 (0.00094)	Tok/s 82403 (60018)	Loss/tok 3.2116 (3.1324)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][6000/6832]	Time 0.058 (0.105)	Data 0.00096 (0.00092)	Tok/s 50523 (59197)	Loss/tok 2.6179 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][6000/6832]	Time 0.058 (0.105)	Data 0.00110 (0.00094)	Tok/s 50530 (59566)	Loss/tok 2.7678 (3.1355)	Learning Rate [7.8125e-05]
0: TRAIN [4][6000/6832]	Time 0.058 (0.105)	Data 0.00095 (0.00094)	Tok/s 50568 (58734)	Loss/tok 2.6698 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][6000/6832]	Time 0.058 (0.105)	Data 0.00109 (0.00094)	Tok/s 52452 (60017)	Loss/tok 2.7891 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6010/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00092)	Tok/s 88254 (59209)	Loss/tok 3.2203 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][6010/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 87622 (58746)	Loss/tok 2.9889 (3.1385)	Learning Rate [7.8125e-05]
2: TRAIN [4][6010/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00094)	Tok/s 89023 (59577)	Loss/tok 3.0551 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][6010/6832]	Time 0.132 (0.105)	Data 0.00118 (0.00094)	Tok/s 89815 (60028)	Loss/tok 3.0362 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6020/6832]	Time 0.100 (0.105)	Data 0.00093 (0.00092)	Tok/s 52235 (59222)	Loss/tok 2.9860 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][6020/6832]	Time 0.100 (0.105)	Data 0.00106 (0.00094)	Tok/s 53510 (59591)	Loss/tok 3.1055 (3.1356)	Learning Rate [7.8125e-05]
0: TRAIN [4][6020/6832]	Time 0.100 (0.105)	Data 0.00099 (0.00094)	Tok/s 52248 (58759)	Loss/tok 3.2431 (3.1385)	Learning Rate [7.8125e-05]
3: TRAIN [4][6020/6832]	Time 0.100 (0.105)	Data 0.00111 (0.00094)	Tok/s 53545 (60042)	Loss/tok 2.8235 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6030/6832]	Time 0.117 (0.105)	Data 0.00097 (0.00094)	Tok/s 59080 (59590)	Loss/tok 3.4190 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][6030/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 59071 (58756)	Loss/tok 3.3702 (3.1387)	Learning Rate [7.8125e-05]
1: TRAIN [4][6030/6832]	Time 0.117 (0.105)	Data 0.00083 (0.00092)	Tok/s 59048 (59220)	Loss/tok 3.3234 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][6030/6832]	Time 0.117 (0.105)	Data 0.00111 (0.00094)	Tok/s 59206 (60041)	Loss/tok 3.1969 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6040/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 71419 (59231)	Loss/tok 3.1272 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][6040/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 71883 (59600)	Loss/tok 3.2214 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6040/6832]	Time 0.131 (0.105)	Data 0.00091 (0.00094)	Tok/s 71435 (58766)	Loss/tok 3.2212 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][6040/6832]	Time 0.131 (0.105)	Data 0.00096 (0.00094)	Tok/s 72422 (60051)	Loss/tok 3.3314 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6050/6832]	Time 0.130 (0.105)	Data 0.00086 (0.00092)	Tok/s 75021 (59230)	Loss/tok 3.2445 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6050/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 74827 (58765)	Loss/tok 3.2005 (3.1389)	Learning Rate [7.8125e-05]
2: TRAIN [4][6050/6832]	Time 0.130 (0.105)	Data 0.00085 (0.00094)	Tok/s 74937 (59598)	Loss/tok 3.2011 (3.1361)	Learning Rate [7.8125e-05]
3: TRAIN [4][6050/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 75737 (60050)	Loss/tok 3.0799 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][6060/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00094)	Tok/s 68374 (59597)	Loss/tok 3.3013 (3.1361)	Learning Rate [7.8125e-05]
1: TRAIN [4][6060/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00092)	Tok/s 68380 (59229)	Loss/tok 3.2898 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6060/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 68026 (58765)	Loss/tok 3.1582 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][6060/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 68401 (60049)	Loss/tok 3.3116 (3.1326)	Learning Rate [7.8125e-05]
1: TRAIN [4][6070/6832]	Time 0.078 (0.105)	Data 0.00088 (0.00092)	Tok/s 54154 (59231)	Loss/tok 3.0003 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6070/6832]	Time 0.078 (0.105)	Data 0.00097 (0.00094)	Tok/s 52622 (58765)	Loss/tok 2.9545 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][6070/6832]	Time 0.078 (0.105)	Data 0.00087 (0.00094)	Tok/s 54203 (59600)	Loss/tok 3.1145 (3.1360)	Learning Rate [7.8125e-05]
3: TRAIN [4][6070/6832]	Time 0.078 (0.105)	Data 0.00091 (0.00094)	Tok/s 54190 (60052)	Loss/tok 3.1186 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][6080/6832]	Time 0.080 (0.105)	Data 0.00089 (0.00094)	Tok/s 53443 (59601)	Loss/tok 2.9008 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][6080/6832]	Time 0.081 (0.105)	Data 0.00085 (0.00092)	Tok/s 52451 (59232)	Loss/tok 2.9334 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6080/6832]	Time 0.081 (0.105)	Data 0.00089 (0.00094)	Tok/s 52440 (58766)	Loss/tok 2.9610 (3.1387)	Learning Rate [7.8125e-05]
3: TRAIN [4][6080/6832]	Time 0.080 (0.105)	Data 0.00095 (0.00094)	Tok/s 54122 (60053)	Loss/tok 3.0098 (3.1326)	Learning Rate [7.8125e-05]
1: TRAIN [4][6090/6832]	Time 0.088 (0.105)	Data 0.00085 (0.00092)	Tok/s 53997 (59233)	Loss/tok 2.8657 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6090/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00094)	Tok/s 55045 (59602)	Loss/tok 2.9047 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6090/6832]	Time 0.088 (0.105)	Data 0.00091 (0.00094)	Tok/s 53543 (58768)	Loss/tok 2.9531 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][6090/6832]	Time 0.088 (0.105)	Data 0.00090 (0.00094)	Tok/s 55067 (60054)	Loss/tok 3.0158 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][6100/6832]	Time 0.124 (0.105)	Data 0.00088 (0.00094)	Tok/s 58665 (59596)	Loss/tok 3.2076 (3.1360)	Learning Rate [7.8125e-05]
1: TRAIN [4][6100/6832]	Time 0.124 (0.105)	Data 0.00097 (0.00092)	Tok/s 58633 (59227)	Loss/tok 3.2234 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6100/6832]	Time 0.124 (0.105)	Data 0.00099 (0.00094)	Tok/s 58664 (58761)	Loss/tok 3.2840 (3.1388)	Learning Rate [7.8125e-05]
3: TRAIN [4][6100/6832]	Time 0.124 (0.105)	Data 0.00091 (0.00094)	Tok/s 58890 (60048)	Loss/tok 3.3003 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6110/6832]	Time 0.103 (0.105)	Data 0.00086 (0.00092)	Tok/s 52077 (59231)	Loss/tok 2.9062 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6110/6832]	Time 0.103 (0.105)	Data 0.00090 (0.00094)	Tok/s 51970 (58765)	Loss/tok 3.0281 (3.1388)	Learning Rate [7.8125e-05]
2: TRAIN [4][6110/6832]	Time 0.104 (0.105)	Data 0.00084 (0.00094)	Tok/s 53128 (59599)	Loss/tok 3.3018 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][6110/6832]	Time 0.105 (0.105)	Data 0.00088 (0.00094)	Tok/s 52473 (60052)	Loss/tok 3.1161 (3.1325)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][6120/6832]	Time 0.079 (0.105)	Data 0.00104 (0.00094)	Tok/s 53236 (59595)	Loss/tok 3.0500 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6120/6832]	Time 0.079 (0.105)	Data 0.00088 (0.00094)	Tok/s 51935 (58761)	Loss/tok 3.0977 (3.1389)	Learning Rate [7.8125e-05]
1: TRAIN [4][6120/6832]	Time 0.079 (0.105)	Data 0.00086 (0.00092)	Tok/s 53141 (59226)	Loss/tok 2.8711 (3.1348)	Learning Rate [7.8125e-05]
3: TRAIN [4][6120/6832]	Time 0.079 (0.105)	Data 0.00097 (0.00094)	Tok/s 53267 (60046)	Loss/tok 2.7862 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][6130/6832]	Time 0.120 (0.105)	Data 0.00091 (0.00094)	Tok/s 51350 (59587)	Loss/tok 3.0341 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][6130/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00092)	Tok/s 51348 (59217)	Loss/tok 2.9882 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6130/6832]	Time 0.120 (0.105)	Data 0.00088 (0.00094)	Tok/s 50533 (58750)	Loss/tok 3.0969 (3.1390)	Learning Rate [7.8125e-05]
3: TRAIN [4][6130/6832]	Time 0.120 (0.105)	Data 0.00094 (0.00094)	Tok/s 51354 (60038)	Loss/tok 2.9763 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][6140/6832]	Time 0.112 (0.105)	Data 0.00095 (0.00094)	Tok/s 52374 (59586)	Loss/tok 3.1080 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][6140/6832]	Time 0.112 (0.105)	Data 0.00092 (0.00092)	Tok/s 52392 (59217)	Loss/tok 3.3107 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6140/6832]	Time 0.112 (0.105)	Data 0.00093 (0.00094)	Tok/s 51506 (58750)	Loss/tok 3.1721 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][6140/6832]	Time 0.112 (0.105)	Data 0.00104 (0.00094)	Tok/s 52375 (60037)	Loss/tok 3.0613 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][6150/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 80324 (59585)	Loss/tok 3.1081 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6150/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00094)	Tok/s 79517 (58748)	Loss/tok 3.2027 (3.1390)	Learning Rate [7.8125e-05]
1: TRAIN [4][6150/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00092)	Tok/s 79529 (59215)	Loss/tok 3.1073 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][6150/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 80520 (60036)	Loss/tok 3.0786 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][6160/6832]	Time 0.127 (0.105)	Data 0.00087 (0.00094)	Tok/s 57337 (59593)	Loss/tok 3.3361 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][6160/6832]	Time 0.127 (0.105)	Data 0.00090 (0.00092)	Tok/s 56404 (59223)	Loss/tok 3.2216 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][6160/6832]	Time 0.127 (0.105)	Data 0.00088 (0.00094)	Tok/s 56335 (58754)	Loss/tok 3.3608 (3.1390)	Learning Rate [7.8125e-05]
3: TRAIN [4][6160/6832]	Time 0.127 (0.105)	Data 0.00096 (0.00094)	Tok/s 57336 (60045)	Loss/tok 3.4320 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6170/6832]	Time 0.091 (0.105)	Data 0.00102 (0.00094)	Tok/s 54989 (59590)	Loss/tok 2.9874 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][6170/6832]	Time 0.091 (0.105)	Data 0.00093 (0.00092)	Tok/s 54561 (59219)	Loss/tok 3.2038 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6170/6832]	Time 0.091 (0.105)	Data 0.00102 (0.00094)	Tok/s 53515 (58749)	Loss/tok 2.9604 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][6170/6832]	Time 0.091 (0.105)	Data 0.00109 (0.00094)	Tok/s 55000 (60043)	Loss/tok 3.0183 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6180/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00092)	Tok/s 53098 (59214)	Loss/tok 2.9438 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6180/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00094)	Tok/s 52201 (58743)	Loss/tok 3.1508 (3.1391)	Learning Rate [7.8125e-05]
2: TRAIN [4][6180/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00094)	Tok/s 53062 (59584)	Loss/tok 3.0202 (3.1356)	Learning Rate [7.8125e-05]
3: TRAIN [4][6180/6832]	Time 0.084 (0.105)	Data 0.00090 (0.00094)	Tok/s 53081 (60036)	Loss/tok 2.8681 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6190/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00092)	Tok/s 78560 (59213)	Loss/tok 3.1658 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6190/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 78132 (58743)	Loss/tok 3.4108 (3.1391)	Learning Rate [7.8125e-05]
2: TRAIN [4][6190/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00094)	Tok/s 79066 (59583)	Loss/tok 3.2708 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][6190/6832]	Time 0.131 (0.105)	Data 0.00104 (0.00094)	Tok/s 79187 (60035)	Loss/tok 3.1090 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6200/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00092)	Tok/s 61791 (59206)	Loss/tok 3.1528 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][6200/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00094)	Tok/s 61748 (59577)	Loss/tok 3.2157 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][6200/6832]	Time 0.126 (0.105)	Data 0.00099 (0.00094)	Tok/s 60910 (58734)	Loss/tok 3.3486 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6200/6832]	Time 0.126 (0.105)	Data 0.00096 (0.00094)	Tok/s 61763 (60030)	Loss/tok 3.2591 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6210/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00094)	Tok/s 52769 (59578)	Loss/tok 3.1326 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][6210/6832]	Time 0.095 (0.105)	Data 0.00085 (0.00092)	Tok/s 52785 (59207)	Loss/tok 3.0913 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6210/6832]	Time 0.095 (0.105)	Data 0.00091 (0.00094)	Tok/s 52748 (58736)	Loss/tok 3.1926 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6210/6832]	Time 0.095 (0.105)	Data 0.00094 (0.00094)	Tok/s 52770 (60031)	Loss/tok 3.1964 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6220/6832]	Time 0.118 (0.105)	Data 0.00091 (0.00092)	Tok/s 61750 (59216)	Loss/tok 3.2133 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6220/6832]	Time 0.118 (0.105)	Data 0.00094 (0.00094)	Tok/s 61754 (58745)	Loss/tok 3.2867 (3.1394)	Learning Rate [7.8125e-05]
2: TRAIN [4][6220/6832]	Time 0.118 (0.105)	Data 0.00088 (0.00094)	Tok/s 61738 (59587)	Loss/tok 3.2256 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][6220/6832]	Time 0.118 (0.105)	Data 0.00092 (0.00094)	Tok/s 61743 (60039)	Loss/tok 3.1825 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6230/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00092)	Tok/s 59122 (59229)	Loss/tok 3.2561 (3.1351)	Learning Rate [7.8125e-05]
0: TRAIN [4][6230/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 58402 (58758)	Loss/tok 3.1836 (3.1396)	Learning Rate [7.8125e-05]
2: TRAIN [4][6230/6832]	Time 0.128 (0.105)	Data 0.00092 (0.00094)	Tok/s 59084 (59599)	Loss/tok 3.1460 (3.1359)	Learning Rate [7.8125e-05]
3: TRAIN [4][6230/6832]	Time 0.128 (0.105)	Data 0.00111 (0.00094)	Tok/s 59065 (60051)	Loss/tok 3.1812 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6240/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 83681 (59603)	Loss/tok 3.1258 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][6240/6832]	Time 0.132 (0.105)	Data 0.00087 (0.00092)	Tok/s 83192 (59233)	Loss/tok 3.1172 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6240/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 82665 (58762)	Loss/tok 3.1390 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6240/6832]	Time 0.132 (0.105)	Data 0.00095 (0.00094)	Tok/s 84163 (60056)	Loss/tok 3.2967 (3.1323)	Learning Rate [7.8125e-05]
1: Upscaling, new scale: 8192.0
2: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][6250/6832]	Time 0.088 (0.105)	Data 0.00093 (0.00094)	Tok/s 52176 (59599)	Loss/tok 3.1579 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][6250/6832]	Time 0.088 (0.105)	Data 0.00086 (0.00092)	Tok/s 52104 (59228)	Loss/tok 3.1045 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6250/6832]	Time 0.088 (0.105)	Data 0.00087 (0.00094)	Tok/s 52150 (58758)	Loss/tok 3.0594 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6250/6832]	Time 0.088 (0.105)	Data 0.00098 (0.00094)	Tok/s 52411 (60051)	Loss/tok 2.9934 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6260/6832]	Time 0.122 (0.105)	Data 0.00084 (0.00092)	Tok/s 53676 (59237)	Loss/tok 3.1184 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6260/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00094)	Tok/s 53684 (58766)	Loss/tok 3.0186 (3.1394)	Learning Rate [7.8125e-05]
2: TRAIN [4][6260/6832]	Time 0.122 (0.105)	Data 0.00091 (0.00094)	Tok/s 53652 (59608)	Loss/tok 3.2775 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][6260/6832]	Time 0.122 (0.105)	Data 0.00099 (0.00094)	Tok/s 54220 (60060)	Loss/tok 3.1141 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6270/6832]	Time 0.130 (0.105)	Data 0.00097 (0.00094)	Tok/s 82421 (59608)	Loss/tok 3.1334 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][6270/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00092)	Tok/s 82389 (59238)	Loss/tok 3.1177 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6270/6832]	Time 0.131 (0.105)	Data 0.00090 (0.00094)	Tok/s 81529 (58766)	Loss/tok 3.3019 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6270/6832]	Time 0.131 (0.105)	Data 0.00102 (0.00094)	Tok/s 83286 (60060)	Loss/tok 3.0933 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6280/6832]	Time 0.050 (0.105)	Data 0.00088 (0.00092)	Tok/s 48190 (59234)	Loss/tok 2.5091 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6280/6832]	Time 0.050 (0.105)	Data 0.00089 (0.00094)	Tok/s 45751 (58763)	Loss/tok 2.5794 (3.1394)	Learning Rate [7.8125e-05]
2: TRAIN [4][6280/6832]	Time 0.050 (0.105)	Data 0.00089 (0.00094)	Tok/s 48192 (59604)	Loss/tok 2.4378 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][6280/6832]	Time 0.050 (0.105)	Data 0.00097 (0.00094)	Tok/s 50724 (60057)	Loss/tok 2.5603 (3.1324)	Learning Rate [7.8125e-05]
1: TRAIN [4][6290/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00092)	Tok/s 53579 (59233)	Loss/tok 3.3107 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6290/6832]	Time 0.112 (0.105)	Data 0.00087 (0.00094)	Tok/s 53550 (59603)	Loss/tok 3.1305 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][6290/6832]	Time 0.112 (0.105)	Data 0.00094 (0.00094)	Tok/s 53562 (58762)	Loss/tok 3.1411 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6290/6832]	Time 0.112 (0.105)	Data 0.00096 (0.00094)	Tok/s 53549 (60055)	Loss/tok 2.9444 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6300/6832]	Time 0.129 (0.105)	Data 0.00084 (0.00094)	Tok/s 65427 (59596)	Loss/tok 3.2517 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][6300/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00092)	Tok/s 65418 (59225)	Loss/tok 3.3289 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][6300/6832]	Time 0.129 (0.105)	Data 0.00123 (0.00094)	Tok/s 66279 (60048)	Loss/tok 3.2087 (3.1324)	Learning Rate [7.8125e-05]
0: TRAIN [4][6300/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 65439 (58753)	Loss/tok 3.4150 (3.1394)	Learning Rate [7.8125e-05]
2: TRAIN [4][6310/6832]	Time 0.098 (0.105)	Data 0.00086 (0.00094)	Tok/s 53763 (59593)	Loss/tok 3.2724 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][6310/6832]	Time 0.098 (0.105)	Data 0.00087 (0.00092)	Tok/s 53778 (59223)	Loss/tok 3.1932 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6310/6832]	Time 0.098 (0.105)	Data 0.00091 (0.00094)	Tok/s 53768 (58751)	Loss/tok 2.9900 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6310/6832]	Time 0.098 (0.105)	Data 0.00098 (0.00094)	Tok/s 53766 (60046)	Loss/tok 3.1655 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6320/6832]	Time 0.132 (0.105)	Data 0.00090 (0.00094)	Tok/s 76545 (59592)	Loss/tok 3.2703 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][6320/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00092)	Tok/s 76499 (59222)	Loss/tok 3.1473 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6320/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00094)	Tok/s 76187 (58750)	Loss/tok 3.1988 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6320/6832]	Time 0.132 (0.105)	Data 0.00094 (0.00094)	Tok/s 77400 (60044)	Loss/tok 3.2061 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6330/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00092)	Tok/s 77615 (59223)	Loss/tok 3.1514 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][6330/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 77588 (59593)	Loss/tok 3.2265 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][6330/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 77047 (58751)	Loss/tok 3.0841 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6330/6832]	Time 0.130 (0.105)	Data 0.00094 (0.00094)	Tok/s 78397 (60045)	Loss/tok 3.0822 (3.1324)	Learning Rate [7.8125e-05]
2: TRAIN [4][6340/6832]	Time 0.106 (0.105)	Data 0.00087 (0.00094)	Tok/s 53322 (59597)	Loss/tok 2.9884 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][6340/6832]	Time 0.106 (0.105)	Data 0.00086 (0.00092)	Tok/s 53331 (59227)	Loss/tok 3.2403 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6340/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00094)	Tok/s 53327 (58756)	Loss/tok 3.2065 (3.1395)	Learning Rate [7.8125e-05]
3: TRAIN [4][6340/6832]	Time 0.106 (0.105)	Data 0.00091 (0.00094)	Tok/s 53324 (60049)	Loss/tok 3.2420 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][6350/6832]	Time 0.118 (0.105)	Data 0.00089 (0.00094)	Tok/s 52095 (59602)	Loss/tok 3.1750 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][6350/6832]	Time 0.118 (0.105)	Data 0.00086 (0.00092)	Tok/s 52103 (59232)	Loss/tok 2.9499 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6350/6832]	Time 0.118 (0.105)	Data 0.00093 (0.00094)	Tok/s 51727 (58761)	Loss/tok 3.1761 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6350/6832]	Time 0.118 (0.105)	Data 0.00096 (0.00094)	Tok/s 52133 (60054)	Loss/tok 3.1569 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][6360/6832]	Time 0.092 (0.105)	Data 0.00086 (0.00094)	Tok/s 51725 (59615)	Loss/tok 3.1736 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][6360/6832]	Time 0.092 (0.105)	Data 0.00089 (0.00092)	Tok/s 51731 (59245)	Loss/tok 3.0790 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6360/6832]	Time 0.092 (0.105)	Data 0.00093 (0.00094)	Tok/s 51735 (58774)	Loss/tok 3.1835 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6360/6832]	Time 0.092 (0.105)	Data 0.00093 (0.00094)	Tok/s 51745 (60067)	Loss/tok 3.0829 (3.1327)	Learning Rate [7.8125e-05]
1: TRAIN [4][6370/6832]	Time 0.133 (0.105)	Data 0.00088 (0.00092)	Tok/s 90820 (59246)	Loss/tok 2.9354 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6370/6832]	Time 0.133 (0.105)	Data 0.00094 (0.00094)	Tok/s 89695 (58775)	Loss/tok 3.0164 (3.1394)	Learning Rate [7.8125e-05]
2: TRAIN [4][6370/6832]	Time 0.133 (0.105)	Data 0.00089 (0.00094)	Tok/s 91817 (59615)	Loss/tok 3.0804 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][6370/6832]	Time 0.133 (0.105)	Data 0.00096 (0.00094)	Tok/s 93865 (60067)	Loss/tok 2.9888 (3.1327)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
2: TRAIN [4][6380/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00094)	Tok/s 53592 (59613)	Loss/tok 3.2514 (3.1359)	Learning Rate [7.8125e-05]
1: TRAIN [4][6380/6832]	Time 0.119 (0.105)	Data 0.00089 (0.00092)	Tok/s 53575 (59243)	Loss/tok 3.1298 (3.1349)	Learning Rate [7.8125e-05]
0: TRAIN [4][6380/6832]	Time 0.119 (0.105)	Data 0.00091 (0.00094)	Tok/s 52674 (58772)	Loss/tok 3.0898 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6380/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00094)	Tok/s 53601 (60065)	Loss/tok 3.1058 (3.1327)	Learning Rate [7.8125e-05]
1: TRAIN [4][6390/6832]	Time 0.076 (0.105)	Data 0.00087 (0.00092)	Tok/s 52264 (59233)	Loss/tok 2.9705 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][6390/6832]	Time 0.076 (0.105)	Data 0.00085 (0.00094)	Tok/s 52250 (59602)	Loss/tok 3.0102 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][6390/6832]	Time 0.076 (0.105)	Data 0.00094 (0.00094)	Tok/s 53802 (60054)	Loss/tok 3.0139 (3.1326)	Learning Rate [7.8125e-05]
0: TRAIN [4][6390/6832]	Time 0.076 (0.105)	Data 0.00092 (0.00094)	Tok/s 52202 (58762)	Loss/tok 2.9905 (3.1393)	Learning Rate [7.8125e-05]
1: TRAIN [4][6400/6832]	Time 0.075 (0.105)	Data 0.00095 (0.00092)	Tok/s 52680 (59244)	Loss/tok 2.9726 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][6400/6832]	Time 0.075 (0.105)	Data 0.00096 (0.00094)	Tok/s 52649 (58773)	Loss/tok 3.0418 (3.1392)	Learning Rate [7.8125e-05]
2: TRAIN [4][6400/6832]	Time 0.075 (0.105)	Data 0.00088 (0.00094)	Tok/s 52599 (59613)	Loss/tok 3.0891 (3.1358)	Learning Rate [7.8125e-05]
3: TRAIN [4][6400/6832]	Time 0.075 (0.105)	Data 0.00090 (0.00094)	Tok/s 52569 (60065)	Loss/tok 3.0937 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][6410/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00094)	Tok/s 65544 (59615)	Loss/tok 3.2884 (3.1358)	Learning Rate [7.8125e-05]
1: TRAIN [4][6410/6832]	Time 0.129 (0.105)	Data 0.00086 (0.00092)	Tok/s 65512 (59246)	Loss/tok 3.2561 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][6410/6832]	Time 0.129 (0.105)	Data 0.00094 (0.00094)	Tok/s 64748 (58776)	Loss/tok 3.3290 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6410/6832]	Time 0.129 (0.105)	Data 0.00096 (0.00094)	Tok/s 65574 (60068)	Loss/tok 3.2539 (3.1326)	Learning Rate [7.8125e-05]
1: TRAIN [4][6420/6832]	Time 0.069 (0.105)	Data 0.00085 (0.00092)	Tok/s 50428 (59235)	Loss/tok 2.9175 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][6420/6832]	Time 0.068 (0.105)	Data 0.00093 (0.00094)	Tok/s 50470 (58765)	Loss/tok 2.8651 (3.1392)	Learning Rate [7.8125e-05]
2: TRAIN [4][6420/6832]	Time 0.069 (0.105)	Data 0.00086 (0.00094)	Tok/s 50428 (59604)	Loss/tok 2.8352 (3.1357)	Learning Rate [7.8125e-05]
3: TRAIN [4][6420/6832]	Time 0.069 (0.105)	Data 0.00093 (0.00094)	Tok/s 49796 (60057)	Loss/tok 2.6490 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6430/6832]	Time 0.119 (0.105)	Data 0.00086 (0.00092)	Tok/s 53675 (59239)	Loss/tok 3.1819 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][6430/6832]	Time 0.119 (0.105)	Data 0.00087 (0.00094)	Tok/s 54363 (59608)	Loss/tok 3.2131 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][6430/6832]	Time 0.119 (0.105)	Data 0.00095 (0.00094)	Tok/s 53679 (58769)	Loss/tok 3.2179 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6430/6832]	Time 0.119 (0.105)	Data 0.00097 (0.00094)	Tok/s 54726 (60061)	Loss/tok 3.1606 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6440/6832]	Time 0.132 (0.105)	Data 0.00088 (0.00091)	Tok/s 81402 (59246)	Loss/tok 3.0953 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][6440/6832]	Time 0.132 (0.105)	Data 0.00086 (0.00094)	Tok/s 81705 (59615)	Loss/tok 3.0957 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][6440/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 80829 (58776)	Loss/tok 3.0743 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6440/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00094)	Tok/s 82331 (60067)	Loss/tok 3.0719 (3.1326)	Learning Rate [7.8125e-05]
2: TRAIN [4][6450/6832]	Time 0.088 (0.105)	Data 0.00093 (0.00094)	Tok/s 52543 (59609)	Loss/tok 3.1857 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][6450/6832]	Time 0.088 (0.105)	Data 0.00092 (0.00091)	Tok/s 52471 (59240)	Loss/tok 2.9384 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][6450/6832]	Time 0.088 (0.105)	Data 0.00097 (0.00094)	Tok/s 51128 (58770)	Loss/tok 3.0253 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][6450/6832]	Time 0.088 (0.105)	Data 0.00099 (0.00094)	Tok/s 52555 (60062)	Loss/tok 2.9796 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6460/6832]	Time 0.126 (0.105)	Data 0.00088 (0.00091)	Tok/s 58763 (59242)	Loss/tok 3.2996 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][6460/6832]	Time 0.126 (0.105)	Data 0.00086 (0.00094)	Tok/s 58720 (59611)	Loss/tok 3.3216 (3.1356)	Learning Rate [7.8125e-05]
0: TRAIN [4][6460/6832]	Time 0.126 (0.105)	Data 0.00093 (0.00094)	Tok/s 58761 (58772)	Loss/tok 3.3261 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][6460/6832]	Time 0.126 (0.105)	Data 0.00092 (0.00094)	Tok/s 58857 (60064)	Loss/tok 3.3029 (3.1325)	Learning Rate [7.8125e-05]
2: TRAIN [4][6470/6832]	Time 0.129 (0.105)	Data 0.00092 (0.00094)	Tok/s 63732 (59615)	Loss/tok 3.3915 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][6470/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00091)	Tok/s 63744 (59245)	Loss/tok 3.2833 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][6470/6832]	Time 0.129 (0.105)	Data 0.00097 (0.00094)	Tok/s 63730 (58776)	Loss/tok 3.1776 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6470/6832]	Time 0.128 (0.105)	Data 0.00124 (0.00094)	Tok/s 64473 (60068)	Loss/tok 3.1903 (3.1325)	Learning Rate [7.8125e-05]
1: TRAIN [4][6480/6832]	Time 0.131 (0.105)	Data 0.00094 (0.00091)	Tok/s 70322 (59247)	Loss/tok 3.2210 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][6480/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00094)	Tok/s 70365 (59616)	Loss/tok 3.2497 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][6480/6832]	Time 0.131 (0.105)	Data 0.00100 (0.00094)	Tok/s 70370 (58779)	Loss/tok 3.1856 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6480/6832]	Time 0.131 (0.105)	Data 0.00098 (0.00094)	Tok/s 71290 (60069)	Loss/tok 3.4376 (3.1327)	Learning Rate [7.8125e-05]
2: TRAIN [4][6490/6832]	Time 0.061 (0.105)	Data 0.00086 (0.00094)	Tok/s 48437 (59613)	Loss/tok 2.6641 (3.1357)	Learning Rate [7.8125e-05]
1: TRAIN [4][6490/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00091)	Tok/s 48337 (59244)	Loss/tok 2.7601 (3.1348)	Learning Rate [7.8125e-05]
0: TRAIN [4][6490/6832]	Time 0.061 (0.105)	Data 0.00092 (0.00094)	Tok/s 48339 (58775)	Loss/tok 2.7525 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6490/6832]	Time 0.061 (0.105)	Data 0.00091 (0.00094)	Tok/s 50516 (60066)	Loss/tok 2.7434 (3.1327)	Learning Rate [7.8125e-05]
2: TRAIN [4][6500/6832]	Time 0.085 (0.105)	Data 0.00110 (0.00094)	Tok/s 52451 (59611)	Loss/tok 2.8346 (3.1356)	Learning Rate [7.8125e-05]
1: TRAIN [4][6500/6832]	Time 0.085 (0.105)	Data 0.00096 (0.00091)	Tok/s 52440 (59242)	Loss/tok 2.9662 (3.1347)	Learning Rate [7.8125e-05]
0: TRAIN [4][6500/6832]	Time 0.085 (0.105)	Data 0.00104 (0.00094)	Tok/s 52417 (58773)	Loss/tok 3.0032 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6500/6832]	Time 0.085 (0.105)	Data 0.00111 (0.00094)	Tok/s 52445 (60063)	Loss/tok 2.8957 (3.1328)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][6510/6832]	Time 0.129 (0.105)	Data 0.00087 (0.00091)	Tok/s 65306 (59239)	Loss/tok 3.3522 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][6510/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 65258 (59608)	Loss/tok 3.3118 (3.1357)	Learning Rate [7.8125e-05]
0: TRAIN [4][6510/6832]	Time 0.129 (0.105)	Data 0.00091 (0.00094)	Tok/s 65264 (58771)	Loss/tok 3.2687 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6510/6832]	Time 0.129 (0.105)	Data 0.00090 (0.00094)	Tok/s 65242 (60060)	Loss/tok 3.4251 (3.1328)	Learning Rate [7.8125e-05]
1: TRAIN [4][6520/6832]	Time 0.106 (0.105)	Data 0.00085 (0.00091)	Tok/s 54119 (59244)	Loss/tok 3.1037 (3.1347)	Learning Rate [7.8125e-05]
2: TRAIN [4][6520/6832]	Time 0.106 (0.105)	Data 0.00094 (0.00094)	Tok/s 54803 (59612)	Loss/tok 3.2609 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][6520/6832]	Time 0.106 (0.105)	Data 0.00095 (0.00094)	Tok/s 54116 (58776)	Loss/tok 3.3020 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6520/6832]	Time 0.106 (0.105)	Data 0.00098 (0.00094)	Tok/s 55328 (60064)	Loss/tok 3.0740 (3.1330)	Learning Rate [7.8125e-05]
1: TRAIN [4][6530/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00091)	Tok/s 71812 (59243)	Loss/tok 3.3106 (3.1348)	Learning Rate [7.8125e-05]
2: TRAIN [4][6530/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 72699 (59611)	Loss/tok 3.2223 (3.1358)	Learning Rate [7.8125e-05]
0: TRAIN [4][6530/6832]	Time 0.130 (0.105)	Data 0.00092 (0.00094)	Tok/s 71769 (58775)	Loss/tok 3.3482 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6530/6832]	Time 0.130 (0.105)	Data 0.00089 (0.00094)	Tok/s 72732 (60063)	Loss/tok 3.1736 (3.1330)	Learning Rate [7.8125e-05]
1: TRAIN [4][6540/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00091)	Tok/s 51401 (59242)	Loss/tok 3.2249 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][6540/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00094)	Tok/s 51358 (59610)	Loss/tok 3.1875 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][6540/6832]	Time 0.117 (0.105)	Data 0.00096 (0.00094)	Tok/s 51403 (58773)	Loss/tok 3.0034 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6540/6832]	Time 0.117 (0.105)	Data 0.00088 (0.00094)	Tok/s 51380 (60063)	Loss/tok 3.1806 (3.1330)	Learning Rate [7.8125e-05]
1: TRAIN [4][6550/6832]	Time 0.123 (0.105)	Data 0.00102 (0.00091)	Tok/s 59091 (59236)	Loss/tok 3.3438 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][6550/6832]	Time 0.124 (0.105)	Data 0.00092 (0.00095)	Tok/s 59994 (60057)	Loss/tok 3.0972 (3.1330)	Learning Rate [7.8125e-05]
0: TRAIN [4][6550/6832]	Time 0.124 (0.105)	Data 0.00106 (0.00094)	Tok/s 59075 (58768)	Loss/tok 3.3642 (3.1392)	Learning Rate [7.8125e-05]
2: TRAIN [4][6550/6832]	Time 0.124 (0.105)	Data 0.00090 (0.00094)	Tok/s 59752 (59605)	Loss/tok 3.2516 (3.1360)	Learning Rate [7.8125e-05]
1: TRAIN [4][6560/6832]	Time 0.131 (0.105)	Data 0.00086 (0.00091)	Tok/s 74498 (59246)	Loss/tok 3.0911 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][6560/6832]	Time 0.131 (0.105)	Data 0.00093 (0.00094)	Tok/s 74850 (59614)	Loss/tok 3.2348 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6560/6832]	Time 0.131 (0.105)	Data 0.00089 (0.00094)	Tok/s 74461 (58778)	Loss/tok 3.2293 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6560/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00095)	Tok/s 75480 (60066)	Loss/tok 3.1414 (3.1331)	Learning Rate [7.8125e-05]
1: TRAIN [4][6570/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00091)	Tok/s 66136 (59249)	Loss/tok 3.3666 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6570/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00094)	Tok/s 66100 (59617)	Loss/tok 3.3523 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6570/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00094)	Tok/s 65860 (58782)	Loss/tok 3.3896 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6570/6832]	Time 0.130 (0.105)	Data 0.00091 (0.00095)	Tok/s 66093 (60069)	Loss/tok 3.1710 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][6580/6832]	Time 0.063 (0.105)	Data 0.00088 (0.00094)	Tok/s 49063 (59620)	Loss/tok 2.8109 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][6580/6832]	Time 0.063 (0.105)	Data 0.00086 (0.00091)	Tok/s 48928 (59253)	Loss/tok 2.7732 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6580/6832]	Time 0.063 (0.105)	Data 0.00091 (0.00094)	Tok/s 48933 (58785)	Loss/tok 2.9597 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6580/6832]	Time 0.063 (0.105)	Data 0.00089 (0.00095)	Tok/s 50964 (60072)	Loss/tok 2.7398 (3.1332)	Learning Rate [7.8125e-05]
2: TRAIN [4][6590/6832]	Time 0.071 (0.105)	Data 0.00087 (0.00094)	Tok/s 51960 (59615)	Loss/tok 2.9549 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][6590/6832]	Time 0.071 (0.105)	Data 0.00086 (0.00091)	Tok/s 51956 (59247)	Loss/tok 2.9863 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6590/6832]	Time 0.071 (0.105)	Data 0.00089 (0.00094)	Tok/s 51007 (58780)	Loss/tok 2.8604 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6590/6832]	Time 0.071 (0.105)	Data 0.00088 (0.00095)	Tok/s 51999 (60067)	Loss/tok 3.0913 (3.1334)	Learning Rate [7.8125e-05]
1: TRAIN [4][6600/6832]	Time 0.128 (0.105)	Data 0.00088 (0.00091)	Tok/s 64140 (59252)	Loss/tok 3.2806 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6600/6832]	Time 0.128 (0.105)	Data 0.00087 (0.00094)	Tok/s 64116 (59619)	Loss/tok 3.4491 (3.1362)	Learning Rate [7.8125e-05]
3: TRAIN [4][6600/6832]	Time 0.128 (0.105)	Data 0.00091 (0.00095)	Tok/s 64806 (60072)	Loss/tok 3.3231 (3.1333)	Learning Rate [7.8125e-05]
0: TRAIN [4][6600/6832]	Time 0.128 (0.105)	Data 0.00090 (0.00094)	Tok/s 64142 (58785)	Loss/tok 3.2029 (3.1392)	Learning Rate [7.8125e-05]
1: TRAIN [4][6610/6832]	Time 0.074 (0.105)	Data 0.00087 (0.00091)	Tok/s 50013 (59251)	Loss/tok 2.9362 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6610/6832]	Time 0.074 (0.105)	Data 0.00091 (0.00094)	Tok/s 49818 (58785)	Loss/tok 2.9261 (3.1392)	Learning Rate [7.8125e-05]
2: TRAIN [4][6610/6832]	Time 0.074 (0.105)	Data 0.00093 (0.00094)	Tok/s 50017 (59618)	Loss/tok 2.8326 (3.1363)	Learning Rate [7.8125e-05]
3: TRAIN [4][6610/6832]	Time 0.074 (0.105)	Data 0.00096 (0.00095)	Tok/s 50094 (60071)	Loss/tok 3.0162 (3.1335)	Learning Rate [7.8125e-05]
1: TRAIN [4][6620/6832]	Time 0.075 (0.105)	Data 0.00098 (0.00091)	Tok/s 54569 (59248)	Loss/tok 2.9470 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6620/6832]	Time 0.075 (0.105)	Data 0.00099 (0.00094)	Tok/s 54610 (59614)	Loss/tok 2.9125 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6620/6832]	Time 0.075 (0.105)	Data 0.00103 (0.00094)	Tok/s 53537 (58781)	Loss/tok 3.0438 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6620/6832]	Time 0.075 (0.105)	Data 0.00105 (0.00095)	Tok/s 54609 (60066)	Loss/tok 2.9346 (3.1334)	Learning Rate [7.8125e-05]
2: TRAIN [4][6630/6832]	Time 0.089 (0.105)	Data 0.00090 (0.00094)	Tok/s 54777 (59617)	Loss/tok 2.8676 (3.1363)	Learning Rate [7.8125e-05]
1: TRAIN [4][6630/6832]	Time 0.089 (0.105)	Data 0.00095 (0.00091)	Tok/s 54195 (59251)	Loss/tok 3.0255 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6630/6832]	Time 0.089 (0.105)	Data 0.00098 (0.00094)	Tok/s 53308 (58785)	Loss/tok 3.0853 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6630/6832]	Time 0.089 (0.105)	Data 0.00097 (0.00095)	Tok/s 54734 (60069)	Loss/tok 3.0713 (3.1335)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
1: TRAIN [4][6640/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00091)	Tok/s 88093 (59255)	Loss/tok 3.0123 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6640/6832]	Time 0.132 (0.105)	Data 0.00092 (0.00094)	Tok/s 88909 (59622)	Loss/tok 3.0260 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6640/6832]	Time 0.132 (0.105)	Data 0.00103 (0.00094)	Tok/s 87413 (58787)	Loss/tok 3.1029 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][6640/6832]	Time 0.132 (0.105)	Data 0.00093 (0.00095)	Tok/s 89633 (60074)	Loss/tok 3.0223 (3.1335)	Learning Rate [7.8125e-05]
2: TRAIN [4][6650/6832]	Time 0.113 (0.105)	Data 0.00092 (0.00094)	Tok/s 52034 (59628)	Loss/tok 3.2341 (3.1361)	Learning Rate [7.8125e-05]
1: TRAIN [4][6650/6832]	Time 0.113 (0.105)	Data 0.00087 (0.00091)	Tok/s 52014 (59261)	Loss/tok 3.1923 (3.1351)	Learning Rate [7.8125e-05]
0: TRAIN [4][6650/6832]	Time 0.113 (0.105)	Data 0.00095 (0.00094)	Tok/s 52033 (58794)	Loss/tok 3.0374 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][6650/6832]	Time 0.113 (0.105)	Data 0.00096 (0.00095)	Tok/s 52717 (60080)	Loss/tok 3.1726 (3.1335)	Learning Rate [7.8125e-05]
1: TRAIN [4][6660/6832]	Time 0.088 (0.105)	Data 0.00096 (0.00091)	Tok/s 51055 (59252)	Loss/tok 3.2306 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6660/6832]	Time 0.088 (0.105)	Data 0.00098 (0.00094)	Tok/s 50793 (58783)	Loss/tok 3.0472 (3.1391)	Learning Rate [7.8125e-05]
2: TRAIN [4][6660/6832]	Time 0.088 (0.105)	Data 0.00107 (0.00094)	Tok/s 52266 (59619)	Loss/tok 3.0896 (3.1361)	Learning Rate [7.8125e-05]
3: TRAIN [4][6660/6832]	Time 0.088 (0.105)	Data 0.00105 (0.00095)	Tok/s 52250 (60072)	Loss/tok 2.8705 (3.1336)	Learning Rate [7.8125e-05]
1: TRAIN [4][6670/6832]	Time 0.079 (0.105)	Data 0.00087 (0.00091)	Tok/s 53181 (59249)	Loss/tok 3.1193 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6670/6832]	Time 0.079 (0.105)	Data 0.00085 (0.00094)	Tok/s 54216 (59616)	Loss/tok 3.1359 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6670/6832]	Time 0.079 (0.105)	Data 0.00091 (0.00094)	Tok/s 53153 (58781)	Loss/tok 3.0708 (3.1391)	Learning Rate [7.8125e-05]
3: TRAIN [4][6670/6832]	Time 0.079 (0.105)	Data 0.00098 (0.00095)	Tok/s 54791 (60069)	Loss/tok 2.9594 (3.1336)	Learning Rate [7.8125e-05]
1: TRAIN [4][6680/6832]	Time 0.130 (0.105)	Data 0.00087 (0.00091)	Tok/s 60275 (59249)	Loss/tok 3.2488 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6680/6832]	Time 0.129 (0.105)	Data 0.00089 (0.00094)	Tok/s 60298 (59616)	Loss/tok 3.1550 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6680/6832]	Time 0.130 (0.105)	Data 0.00088 (0.00094)	Tok/s 60266 (58781)	Loss/tok 3.2557 (3.1392)	Learning Rate [7.8125e-05]
3: TRAIN [4][6680/6832]	Time 0.129 (0.105)	Data 0.00088 (0.00095)	Tok/s 60308 (60068)	Loss/tok 3.2113 (3.1335)	Learning Rate [7.8125e-05]
2: TRAIN [4][6690/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00094)	Tok/s 52591 (59608)	Loss/tok 3.0052 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][6690/6832]	Time 0.100 (0.105)	Data 0.00089 (0.00091)	Tok/s 52605 (59241)	Loss/tok 3.0449 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][6690/6832]	Time 0.100 (0.105)	Data 0.00090 (0.00095)	Tok/s 52578 (60060)	Loss/tok 3.1191 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6690/6832]	Time 0.100 (0.105)	Data 0.00095 (0.00094)	Tok/s 52581 (58774)	Loss/tok 3.1765 (3.1393)	Learning Rate [7.8125e-05]
2: TRAIN [4][6700/6832]	Time 0.091 (0.105)	Data 0.00092 (0.00094)	Tok/s 53377 (59600)	Loss/tok 2.9000 (3.1362)	Learning Rate [7.8125e-05]
1: TRAIN [4][6700/6832]	Time 0.091 (0.105)	Data 0.00098 (0.00091)	Tok/s 51979 (59233)	Loss/tok 3.0796 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6700/6832]	Time 0.091 (0.105)	Data 0.00105 (0.00094)	Tok/s 51967 (58766)	Loss/tok 3.1632 (3.1393)	Learning Rate [7.8125e-05]
3: TRAIN [4][6700/6832]	Time 0.091 (0.105)	Data 0.00090 (0.00095)	Tok/s 53385 (60052)	Loss/tok 2.9982 (3.1334)	Learning Rate [7.8125e-05]
1: TRAIN [4][6710/6832]	Time 0.113 (0.105)	Data 0.00086 (0.00091)	Tok/s 55289 (59232)	Loss/tok 3.1176 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6710/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00094)	Tok/s 55502 (59598)	Loss/tok 3.2199 (3.1362)	Learning Rate [7.8125e-05]
3: TRAIN [4][6710/6832]	Time 0.113 (0.105)	Data 0.00088 (0.00095)	Tok/s 55500 (60050)	Loss/tok 2.9684 (3.1334)	Learning Rate [7.8125e-05]
0: TRAIN [4][6710/6832]	Time 0.113 (0.105)	Data 0.00098 (0.00094)	Tok/s 54368 (58765)	Loss/tok 3.1415 (3.1392)	Learning Rate [7.8125e-05]
1: TRAIN [4][6720/6832]	Time 0.117 (0.105)	Data 0.00085 (0.00091)	Tok/s 51573 (59228)	Loss/tok 3.2251 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6720/6832]	Time 0.117 (0.105)	Data 0.00087 (0.00094)	Tok/s 51638 (59594)	Loss/tok 3.0181 (3.1363)	Learning Rate [7.8125e-05]
3: TRAIN [4][6720/6832]	Time 0.117 (0.105)	Data 0.00089 (0.00095)	Tok/s 51677 (60046)	Loss/tok 3.3078 (3.1334)	Learning Rate [7.8125e-05]
0: TRAIN [4][6720/6832]	Time 0.117 (0.105)	Data 0.00099 (0.00094)	Tok/s 51563 (58761)	Loss/tok 3.0972 (3.1392)	Learning Rate [7.8125e-05]
1: TRAIN [4][6730/6832]	Time 0.132 (0.105)	Data 0.00089 (0.00091)	Tok/s 83372 (59231)	Loss/tok 3.1046 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6730/6832]	Time 0.132 (0.105)	Data 0.00105 (0.00094)	Tok/s 83683 (59597)	Loss/tok 3.1430 (3.1364)	Learning Rate [7.8125e-05]
3: TRAIN [4][6730/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00095)	Tok/s 84246 (60049)	Loss/tok 3.1135 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6730/6832]	Time 0.132 (0.105)	Data 0.00101 (0.00094)	Tok/s 82644 (58764)	Loss/tok 3.0572 (3.1392)	Learning Rate [7.8125e-05]
1: TRAIN [4][6740/6832]	Time 0.133 (0.105)	Data 0.00087 (0.00091)	Tok/s 90729 (59233)	Loss/tok 3.0773 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6740/6832]	Time 0.133 (0.105)	Data 0.00104 (0.00094)	Tok/s 91965 (59600)	Loss/tok 2.9530 (3.1363)	Learning Rate [7.8125e-05]
3: TRAIN [4][6740/6832]	Time 0.133 (0.105)	Data 0.00085 (0.00095)	Tok/s 93797 (60053)	Loss/tok 3.0500 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6740/6832]	Time 0.133 (0.105)	Data 0.00096 (0.00094)	Tok/s 89541 (58765)	Loss/tok 3.0334 (3.1392)	Learning Rate [7.8125e-05]
2: TRAIN [4][6750/6832]	Time 0.084 (0.105)	Data 0.00086 (0.00094)	Tok/s 54861 (59601)	Loss/tok 3.0177 (3.1363)	Learning Rate [7.8125e-05]
1: TRAIN [4][6750/6832]	Time 0.084 (0.105)	Data 0.00085 (0.00091)	Tok/s 54451 (59234)	Loss/tok 2.9652 (3.1350)	Learning Rate [7.8125e-05]
3: TRAIN [4][6750/6832]	Time 0.084 (0.105)	Data 0.00087 (0.00095)	Tok/s 54831 (60053)	Loss/tok 2.9820 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6750/6832]	Time 0.084 (0.105)	Data 0.00099 (0.00094)	Tok/s 53362 (58766)	Loss/tok 2.9989 (3.1393)	Learning Rate [7.8125e-05]
2: Upscaling, new scale: 8192.0
1: Upscaling, new scale: 8192.0
3: Upscaling, new scale: 8192.0
0: Upscaling, new scale: 8192.0
2: TRAIN [4][6760/6832]	Time 0.106 (0.105)	Data 0.00134 (0.00094)	Tok/s 53269 (59598)	Loss/tok 3.0873 (3.1364)	Learning Rate [7.8125e-05]
1: TRAIN [4][6760/6832]	Time 0.106 (0.105)	Data 0.00089 (0.00091)	Tok/s 53196 (59231)	Loss/tok 3.1191 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][6760/6832]	Time 0.106 (0.105)	Data 0.00132 (0.00095)	Tok/s 53899 (60050)	Loss/tok 3.0417 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][6760/6832]	Time 0.106 (0.105)	Data 0.00113 (0.00094)	Tok/s 53203 (58764)	Loss/tok 3.0008 (3.1393)	Learning Rate [7.8125e-05]
2: TRAIN [4][6770/6832]	Time 0.115 (0.105)	Data 0.00087 (0.00094)	Tok/s 59493 (59594)	Loss/tok 3.3922 (3.1364)	Learning Rate [7.8125e-05]
1: TRAIN [4][6770/6832]	Time 0.115 (0.105)	Data 0.00085 (0.00091)	Tok/s 58894 (59227)	Loss/tok 3.1388 (3.1351)	Learning Rate [7.8125e-05]
3: TRAIN [4][6770/6832]	Time 0.115 (0.105)	Data 0.00089 (0.00095)	Tok/s 60049 (60046)	Loss/tok 3.1250 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6770/6832]	Time 0.115 (0.105)	Data 0.00106 (0.00094)	Tok/s 58875 (58761)	Loss/tok 3.2622 (3.1392)	Learning Rate [7.8125e-05]
1: TRAIN [4][6780/6832]	Time 0.116 (0.105)	Data 0.00087 (0.00091)	Tok/s 58105 (59240)	Loss/tok 3.2801 (3.1351)	Learning Rate [7.8125e-05]
2: TRAIN [4][6780/6832]	Time 0.116 (0.105)	Data 0.00089 (0.00094)	Tok/s 58515 (59607)	Loss/tok 3.1345 (3.1364)	Learning Rate [7.8125e-05]
3: TRAIN [4][6780/6832]	Time 0.116 (0.105)	Data 0.00091 (0.00095)	Tok/s 58519 (60058)	Loss/tok 3.1465 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6780/6832]	Time 0.116 (0.105)	Data 0.00107 (0.00094)	Tok/s 57450 (58773)	Loss/tok 3.1193 (3.1393)	Learning Rate [7.8125e-05]
1: TRAIN [4][6790/6832]	Time 0.131 (0.105)	Data 0.00085 (0.00091)	Tok/s 64636 (59243)	Loss/tok 3.1672 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6790/6832]	Time 0.131 (0.105)	Data 0.00087 (0.00094)	Tok/s 64580 (59610)	Loss/tok 3.2454 (3.1365)	Learning Rate [7.8125e-05]
3: TRAIN [4][6790/6832]	Time 0.131 (0.105)	Data 0.00088 (0.00095)	Tok/s 65157 (60061)	Loss/tok 3.3931 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6790/6832]	Time 0.131 (0.105)	Data 0.00097 (0.00094)	Tok/s 64559 (58776)	Loss/tok 3.3199 (3.1394)	Learning Rate [7.8125e-05]
2: TRAIN [4][6800/6832]	Time 0.070 (0.105)	Data 0.00096 (0.00094)	Tok/s 51324 (59614)	Loss/tok 2.8293 (3.1366)	Learning Rate [7.8125e-05]
1: TRAIN [4][6800/6832]	Time 0.070 (0.105)	Data 0.00084 (0.00091)	Tok/s 51331 (59248)	Loss/tok 2.8287 (3.1350)	Learning Rate [7.8125e-05]
0: TRAIN [4][6800/6832]	Time 0.070 (0.105)	Data 0.00098 (0.00094)	Tok/s 51306 (58782)	Loss/tok 2.9603 (3.1394)	Learning Rate [7.8125e-05]
3: TRAIN [4][6800/6832]	Time 0.070 (0.105)	Data 0.00093 (0.00095)	Tok/s 51914 (60066)	Loss/tok 2.8833 (3.1335)	Learning Rate [7.8125e-05]
1: TRAIN [4][6810/6832]	Time 0.113 (0.105)	Data 0.00085 (0.00091)	Tok/s 49627 (59244)	Loss/tok 3.0855 (3.1350)	Learning Rate [7.8125e-05]
2: TRAIN [4][6810/6832]	Time 0.114 (0.105)	Data 0.00090 (0.00094)	Tok/s 49908 (59610)	Loss/tok 3.1447 (3.1366)	Learning Rate [7.8125e-05]
3: TRAIN [4][6810/6832]	Time 0.114 (0.105)	Data 0.00099 (0.00095)	Tok/s 50665 (60062)	Loss/tok 3.1323 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][6810/6832]	Time 0.113 (0.105)	Data 0.00111 (0.00094)	Tok/s 49623 (58778)	Loss/tok 3.2436 (3.1395)	Learning Rate [7.8125e-05]
2: TRAIN [4][6820/6832]	Time 0.061 (0.105)	Data 0.00088 (0.00094)	Tok/s 51683 (59604)	Loss/tok 2.9677 (3.1366)	Learning Rate [7.8125e-05]
1: TRAIN [4][6820/6832]	Time 0.061 (0.105)	Data 0.00087 (0.00091)	Tok/s 50375 (59237)	Loss/tok 2.7565 (3.1349)	Learning Rate [7.8125e-05]
3: TRAIN [4][6820/6832]	Time 0.061 (0.105)	Data 0.00095 (0.00095)	Tok/s 52485 (60055)	Loss/tok 2.7986 (3.1336)	Learning Rate [7.8125e-05]
0: TRAIN [4][6820/6832]	Time 0.061 (0.105)	Data 0.00096 (0.00094)	Tok/s 50339 (58772)	Loss/tok 2.6525 (3.1394)	Learning Rate [7.8125e-05]
1: TRAIN [4][6830/6832]	Time 0.087 (0.105)	Data 0.00085 (0.00092)	Tok/s 51408 (59236)	Loss/tok 3.0132 (3.1349)	Learning Rate [7.8125e-05]
2: TRAIN [4][6830/6832]	Time 0.087 (0.105)	Data 0.00086 (0.00094)	Tok/s 52719 (59604)	Loss/tok 3.0366 (3.1366)	Learning Rate [7.8125e-05]
3: TRAIN [4][6830/6832]	Time 0.087 (0.105)	Data 0.00086 (0.00095)	Tok/s 52823 (60054)	Loss/tok 2.9760 (3.1335)	Learning Rate [7.8125e-05]
0: TRAIN [4][6830/6832]	Time 0.087 (0.105)	Data 0.00088 (0.00094)	Tok/s 51293 (58771)	Loss/tok 2.9695 (3.1394)	Learning Rate [7.8125e-05]
3: Running validation on dev set
1: Running validation on dev set
2: Running validation on dev set
0: Running validation on dev set
3: VALIDATION [4][0/20]	Time 0.038 (0.000)	Data 0.00257 (0.00000)	Tok/s 193067 (0)	Loss/tok 3.1553 (0.0000)	Learning Rate [7.8125e-05]
1: VALIDATION [4][0/20]	Time 0.041 (0.000)	Data 0.00242 (0.00000)	Tok/s 204223 (0)	Loss/tok 3.2477 (0.0000)	Learning Rate [7.8125e-05]
2: VALIDATION [4][0/20]	Time 0.037 (0.000)	Data 0.00248 (0.00000)	Tok/s 206817 (0)	Loss/tok 3.2412 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [4][0/20]	Time 0.068 (0.000)	Data 0.00294 (0.00000)	Tok/s 150363 (0)	Loss/tok 3.3398 (0.0000)	Learning Rate [7.8125e-05]
3: VALIDATION [4][10/20]	Time 0.015 (0.021)	Data 0.00186 (0.00196)	Tok/s 194048 (205210)	Loss/tok 3.0324 (3.1332)	Learning Rate [7.8125e-05]
1: VALIDATION [4][10/20]	Time 0.015 (0.022)	Data 0.00174 (0.00184)	Tok/s 201589 (207798)	Loss/tok 3.0231 (3.1427)	Learning Rate [7.8125e-05]
2: VALIDATION [4][10/20]	Time 0.015 (0.021)	Data 0.00178 (0.00193)	Tok/s 200242 (206648)	Loss/tok 2.9380 (3.0888)	Learning Rate [7.8125e-05]
0: VALIDATION [4][10/20]	Time 0.017 (0.024)	Data 0.00241 (0.00248)	Tok/s 185431 (195270)	Loss/tok 3.0927 (3.1031)	Learning Rate [7.8125e-05]
2: Running evaluation on test set
3: Running evaluation on test set
1: Running evaluation on test set
:::MLPv0.5.0 gnmt 1560385980.650644541 (train.py:459) eval_start: 4
0: Running evaluation on test set
2: TEST [4][0/6]	Time 1.177 (1.177)	Decoder iters 149.0 (149.0)	Tok/s 6282 (6282)
1: TEST [4][0/6]	Time 1.178 (1.178)	Decoder iters 105.0 (105.0)	Tok/s 6472 (6472)
3: TEST [4][0/6]	Time 1.178 (1.178)	Decoder iters 87.0 (87.0)	Tok/s 6509 (6509)
0: TEST [4][0/6]	Time 1.178 (1.178)	Decoder iters 72.0 (72.0)	Tok/s 5970 (5970)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Target accuracy reached
1: Finished evaluation on test set
2: Finished evaluation on test set
3: Finished evaluation on test set
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560385991.269557238 (train.py:464) eval_accuracy: {"epoch": 4, "value": 21.850000381469727}
:::MLPv0.5.0 gnmt 1560385991.270313501 (train.py:466) eval_target: 21.8
2: Summary: Epoch: 4	Training Loss 3.1361
3: Summary: Epoch: 4	Training Loss 3.1361
2: Performance: Epoch: 4	Training: 237671 Tok/s
3: Performance: Epoch: 4	Training: 237671 Tok/s
1: Summary: Epoch: 4	Training Loss 3.1361
2: Finished epoch 4
3: Finished epoch 4
1: Performance: Epoch: 4	Training: 237671 Tok/s
1: Finished epoch 4
:::MLPv0.5.0 gnmt 1560385991.270975590 (train.py:467) eval_stop
0: Summary: Epoch: 4	Training Loss: 3.1361	Validation Loss: 3.0867	Test BLEU: 21.85
0: Performance: Epoch: 4	Training: 237671 Tok/s	Validation: 692147 Tok/s
0: Finished epoch 4
:::MLPv0.5.0 gnmt 1560385991.271779299 (train.py:488) run_stop: {"success": true}
:::MLPv0.5.0 gnmt 1560385991.272402763 (train.py:494) train_checkpoint
0: Saving model to results/gnmt_wmt16/model_best.pth
:::MLPv0.5.0 gnmt 1560385998.927773476 (train.py:498) run_final
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-06-13 12:33:24 AM
RESULT,RNN_TRANSLATOR,,3694,nvidia,2019-06-12 11:31:50 PM
