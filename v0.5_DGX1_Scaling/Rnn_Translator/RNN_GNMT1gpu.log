Clearing caches
:::MLPv0.5.0 gnmt 1560834263.065266371 (<string>:1) run_clear_caches
Launching on node dgx1-centos7
+ pids+=($!)
+ set +x
++ eval echo
+++ echo
+ docker exec -e DGXSYSTEM=DGX1 -e MULTI_NODE= -e SLURM_JOB_ID=190617122509 -e SLURM_NTASKS_PER_NODE= cont_190617122509 ./run_and_time.sh
Run vars: id 190617122509 gpus 8 mparams 
STARTING TIMING RUN AT 2019-06-18 05:04:23 AM
+ DATASET_DIR=/data
+ RESULTS_DIR=gnmt_wmt16
+ BATCH=512
+ TEST_BATCH_SIZE=512
+ LR=1.25e-3
+ TARGET=21.80
+ WARMUP_ITERS=200
+ REMAIN_STEPS=6000
+ DECAY_STEPS=500
+ echo 'running benchmark'
running benchmark
+ python train.py --save gnmt_wmt16 --dataset-dir /data --target-bleu 21.80 --epochs 60 --math fp16 --print-freq 10 --batch-size 512 --test-batch-size 512 --model-config '{'\''num_layers'\'': 4, '\''hidden_size'\'': 1024, '\''dropout'\'':0.2, '\''share_embedding'\'': True}' --optimization-config '{'\''optimizer'\'': '\''FusedAdam'\'', '\''lr'\'': 1.25e-3}' --scheduler-config '{'\''lr_method'\'':'\''mlperf'\'', '\''warmup_iters'\'':200, '\''remain_steps'\'':6000, '\''decay_steps'\'':500}'
:::MLPv0.5.0 gnmt 1560834264.839802742 (train.py:242) run_start
0: Saving results to: results/gnmt_wmt16
0: Run arguments: Namespace(apex_message_size=10000000.0, batch_size=512, beam_size=5, bucketing=True, cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data', disable_eval=False, enable_apex_allreduce_overlap=False, epochs=60, grad_clip=5.0, intra_epoch_eval=0, keep_checkpoints=0, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, math='fp16', max_length_test=150, max_length_train=50, max_length_val=150, max_size=None, min_length_test=0, min_length_train=0, min_length_val=0, model_config="{'num_layers': 4, 'hidden_size': 1024, 'dropout':0.2, 'share_embedding': True}", optimization_config="{'optimizer': 'FusedAdam', 'lr': 1.25e-3}", print_freq=10, rank=0, results_dir='results', resume=None, save='gnmt_wmt16', save_all=False, save_freq=5000, save_path='results/gnmt_wmt16', scheduler_config="{'lr_method':'mlperf', 'warmup_iters':200, 'remain_steps':6000, 'decay_steps':500}", seed=None, smoothing=0.1, start_epoch=0, target_bleu=21.8, test_batch_size=512, test_loader_workers=0, train_loader_workers=2, val_batch_size=64, val_loader_workers=0)
0: L2 promotion: 128B
:::MLPv0.5.0 gnmt 1560834265.984534502 (train.py:265) run_set_random_seed
0: Using random master seed: 3640707785
0: Worker 0 is using worker seed: 932306870
0: Building vocabulary from /data/vocab.bpe.32000
0: Size of vocabulary: 32320
:::MLPv0.5.0 gnmt 1560834266.007595301 (train.py:302) preproc_tokenize_training
:::MLPv0.5.0 gnmt 1560834266.008385181 (train.py:304) train_hp_max_sequence_length: 50
0: Processing data from /data/train.tok.clean.bpe.32000.en
0: Processing data from /data/train.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 50
0: Pairs before: 4068191, after: 3498161
:::MLPv0.5.0 gnmt 1560834276.677146673 (train.py:316) preproc_num_train_examples: 3498161
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.en
0: Processing data from /data/newstest_dev.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 5100, after: 5100
:::MLPv0.5.0 gnmt 1560834277.713601828 (train.py:326) preproc_tokenize_eval
0: Processing data from /data/newstest2014.tok.bpe.32000.en
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 3003, after: 3003
:::MLPv0.5.0 gnmt 1560834277.756739855 (train.py:336) preproc_num_eval_examples: 3003
:::MLPv0.5.0 gnmt 1560834277.757138491 (train.py:341) preproc_vocab_size: 32320
:::MLPv0.5.0 gnmt 1560834277.758285522 (seq2seq/models/gnmt.py:37) model_hp_num_layers: 4
:::MLPv0.5.0 gnmt 1560834277.758721828 (seq2seq/models/gnmt.py:39) model_hp_hidden_size: 1024
:::MLPv0.5.0 gnmt 1560834277.759263754 (seq2seq/models/gnmt.py:41) model_hp_dropout: 0.2
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): EmuBidirLSTM(
        (bidir): LSTM(1024, 1024, bidirectional=True)
        (layer1): LSTM(1024, 1024)
        (layer2): LSTM(1024, 1024)
      )
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2)
    (embedder): Embedding(32320, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
        (dropout): Dropout(p=0)
      )
      (dropout): Dropout(p=0)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(32320, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=32320, bias=True)
    )
    (dropout): Dropout(p=0.2)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
:::MLPv0.5.0 gnmt 1560834280.862464190 (train.py:208) model_hp_loss_fn: "Cross Entropy with label smoothing"
:::MLPv0.5.0 gnmt 1560834280.862896204 (train.py:210) model_hp_loss_smoothing: 0.1
0: Training optimizer: {'optimizer': 'FusedAdam', 'lr': 0.00125}
0: Training LR Schedule: {'lr_method': 'mlperf', 'warmup_iters': 200, 'remain_steps': 6000, 'decay_steps': 500}
0: Number of parameters: 160671297
:::MLPv0.5.0 gnmt 1560834280.863932371 (train.py:370) input_batch_size: 512
:::MLPv0.5.0 gnmt 1560834280.864352942 (train.py:372) input_size: 3497984
:::MLPv0.5.0 gnmt 1560834280.868028164 (train.py:386) eval_size: 3003
:::MLPv0.5.0 gnmt 1560834280.869578838 (seq2seq/inference/beam_search.py:43) eval_hp_beam_size: 5
:::MLPv0.5.0 gnmt 1560834280.870086670 (seq2seq/inference/beam_search.py:45) eval_hp_max_sequence_length: 150
:::MLPv0.5.0 gnmt 1560834280.870593309 (seq2seq/inference/beam_search.py:47) eval_hp_length_normalization_constant: 5.0
:::MLPv0.5.0 gnmt 1560834280.871086121 (seq2seq/inference/beam_search.py:49) eval_hp_length_normalization_factor: 0.6
:::MLPv0.5.0 gnmt 1560834280.871629477 (seq2seq/inference/beam_search.py:51) eval_hp_coverage_penalty_factor: 0.1
0: Saving state of the tokenizer
0: Initializing fp16 optimizer
0: Initializing fp32 clone weights
:::MLPv0.5.0 gnmt 1560834285.910613537 (seq2seq/train/trainer.py:99) opt_name: "adam"
:::MLPv0.5.0 gnmt 1560834285.911158085 (seq2seq/train/trainer.py:101) opt_learning_rate: 0.00125
:::MLPv0.5.0 gnmt 1560834285.911640882 (seq2seq/train/trainer.py:103) opt_hp_Adam_beta1: 0.9
:::MLPv0.5.0 gnmt 1560834285.912179708 (seq2seq/train/trainer.py:105) opt_hp_Adam_beta2: 0.999
:::MLPv0.5.0 gnmt 1560834285.912714243 (seq2seq/train/trainer.py:107) opt_hp_Adam_epsilon: 1e-08
0: Using optimizer: FusedAdam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    initial_lr: 0.00125
    lr: 1.2499999999999968e-05
    weight_decay: 0
)
:::MLPv0.5.0 gnmt 1560834285.913619995 (train.py:438) train_loop
0: Starting epoch 0
:::MLPv0.5.0 gnmt 1560834285.914276123 (train.py:443) train_epoch: 0
/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:182: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
  self.num_layers, self.dropout, self.training, self.bidirectional)
:::MLPv0.5.0 gnmt 1560834286.779630184 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 2037452816
:::MLPv0.5.0 gnmt 1560834286.866689682 (seq2seq/data/sampler.py:66) input_shard: 40960
0: TRAIN [0][0/6832]	Time 1.195 (0.000)	Data 0.90465 (0.00000)	Tok/s 18424 (0)	Loss/tok 10.3814 (0.0000)	Learning Rate [1.2499999999999968e-05]
0: TRAIN [0][10/6832]	Time 0.480 (0.345)	Data 0.00128 (0.00114)	Tok/s 96937 (74934)	Loss/tok 10.3547 (10.3652)	Learning Rate [1.5736567647427052e-05]
0: TRAIN [0][20/6832]	Time 0.373 (0.358)	Data 0.00126 (0.00114)	Tok/s 68601 (72761)	Loss/tok 10.2955 (10.3443)	Learning Rate [1.9811164905763877e-05]
0: TRAIN [0][30/6832]	Time 0.224 (0.335)	Data 0.00100 (0.00113)	Tok/s 73015 (73528)	Loss/tok 9.9867 (10.2987)	Learning Rate [2.4940778937110944e-05]
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: Gradient norm: inf
0: Skipped batch, new scale: 2048.0
0: Gradient norm: inf
0: Skipped batch, new scale: 1024.0
0: TRAIN [0][40/6832]	Time 0.480 (0.332)	Data 0.00101 (0.00112)	Tok/s 79644 (74774)	Loss/tok 9.8974 (10.1138)	Learning Rate [2.9302860191498968e-05]
0: TRAIN [0][50/6832]	Time 0.280 (0.328)	Data 0.00106 (0.00111)	Tok/s 71176 (75156)	Loss/tok 9.2689 (10.0795)	Learning Rate [3.689011533332975e-05]
0: TRAIN [0][60/6832]	Time 0.347 (0.326)	Data 0.00102 (0.00111)	Tok/s 69297 (73884)	Loss/tok 8.5077 (9.8696)	Learning Rate [4.6441903637146485e-05]
0: TRAIN [0][70/6832]	Time 0.473 (0.322)	Data 0.00098 (0.00110)	Tok/s 72343 (74291)	Loss/tok 8.2643 (9.6563)	Learning Rate [5.846689266089967e-05]
0: TRAIN [0][80/6832]	Time 0.109 (0.329)	Data 0.00111 (0.00110)	Tok/s 76872 (74006)	Loss/tok 7.3315 (9.4458)	Learning Rate [7.360545691944851e-05]
0: TRAIN [0][90/6832]	Time 0.164 (0.326)	Data 0.00125 (0.00110)	Tok/s 78662 (74579)	Loss/tok 7.6660 (9.2815)	Learning Rate [9.266378016261457e-05]
0: TRAIN [0][100/6832]	Time 0.317 (0.329)	Data 0.00099 (0.00109)	Tok/s 74555 (74561)	Loss/tok 7.9369 (9.1429)	Learning Rate [0.00011665678759962373]
0: TRAIN [0][110/6832]	Time 0.481 (0.330)	Data 0.00101 (0.00108)	Tok/s 73116 (74647)	Loss/tok 8.0423 (9.0294)	Learning Rate [0.00014686219436744102]
0: TRAIN [0][120/6832]	Time 0.218 (0.337)	Data 0.00110 (0.00542)	Tok/s 75126 (74383)	Loss/tok 7.7205 (8.9252)	Learning Rate [0.00018488854852102574]
0: TRAIN [0][130/6832]	Time 0.319 (0.335)	Data 0.00103 (0.00509)	Tok/s 70711 (74385)	Loss/tok 7.8097 (8.8499)	Learning Rate [0.00023276089208285823]
0: TRAIN [0][140/6832]	Time 0.345 (0.333)	Data 0.00100 (0.00480)	Tok/s 68721 (74165)	Loss/tok 7.7974 (8.7823)	Learning Rate [0.00029302860191499005]
0: TRAIN [0][150/6832]	Time 0.469 (0.337)	Data 0.00104 (0.00455)	Tok/s 71264 (73942)	Loss/tok 7.8757 (8.7111)	Learning Rate [0.000368901153333298]
0: TRAIN [0][160/6832]	Time 0.472 (0.338)	Data 0.00103 (0.00433)	Tok/s 71383 (74020)	Loss/tok 7.7472 (8.6500)	Learning Rate [0.00046441903637146545]
0: Upscaling, new scale: 2048.0
0: TRAIN [0][170/6832]	Time 0.147 (0.342)	Data 0.00103 (0.00414)	Tok/s 84924 (74066)	Loss/tok 7.2784 (8.5813)	Learning Rate [0.0005846689266089975]
0: TRAIN [0][180/6832]	Time 0.424 (0.342)	Data 0.00101 (0.00397)	Tok/s 68222 (73952)	Loss/tok 7.5456 (8.5267)	Learning Rate [0.000736054569194486]
0: TRAIN [0][190/6832]	Time 0.311 (0.343)	Data 0.00122 (0.00381)	Tok/s 69541 (73976)	Loss/tok 7.3838 (8.4702)	Learning Rate [0.0009266378016261468]
0: TRAIN [0][200/6832]	Time 0.482 (0.346)	Data 0.00103 (0.00368)	Tok/s 96658 (74308)	Loss/tok 7.3102 (8.3995)	Learning Rate [0.0011665678759962387]
0: TRAIN [0][210/6832]	Time 0.460 (0.346)	Data 0.00104 (0.00355)	Tok/s 105977 (74574)	Loss/tok 7.2702 (8.3378)	Learning Rate [0.00125]
0: TRAIN [0][220/6832]	Time 0.416 (0.347)	Data 0.00106 (0.00344)	Tok/s 65853 (74587)	Loss/tok 7.1060 (8.2777)	Learning Rate [0.00125]
0: TRAIN [0][230/6832]	Time 0.308 (0.347)	Data 0.00105 (0.00333)	Tok/s 71406 (74610)	Loss/tok 6.8268 (8.2192)	Learning Rate [0.00125]
0: TRAIN [0][240/6832]	Time 0.139 (0.347)	Data 0.00104 (0.00324)	Tok/s 82135 (74498)	Loss/tok 6.2966 (8.1653)	Learning Rate [0.00125]
0: TRAIN [0][250/6832]	Time 0.320 (0.345)	Data 0.00106 (0.00378)	Tok/s 70746 (74329)	Loss/tok 6.6868 (8.1194)	Learning Rate [0.00125]
0: TRAIN [0][260/6832]	Time 0.396 (0.345)	Data 0.00099 (0.00367)	Tok/s 65931 (74144)	Loss/tok 6.5870 (8.0694)	Learning Rate [0.00125]
0: TRAIN [0][270/6832]	Time 0.485 (0.344)	Data 0.00103 (0.00358)	Tok/s 100346 (74139)	Loss/tok 6.7437 (8.0197)	Learning Rate [0.00125]
0: TRAIN [0][280/6832]	Time 0.224 (0.343)	Data 0.00105 (0.00349)	Tok/s 74917 (74110)	Loss/tok 6.1006 (7.9712)	Learning Rate [0.00125]
0: TRAIN [0][290/6832]	Time 0.433 (0.344)	Data 0.00104 (0.00340)	Tok/s 66315 (73950)	Loss/tok 6.5393 (7.9188)	Learning Rate [0.00125]
0: Upscaling, new scale: 4096.0
0: TRAIN [0][300/6832]	Time 0.339 (0.343)	Data 0.00105 (0.00332)	Tok/s 70934 (73923)	Loss/tok 6.3545 (7.8719)	Learning Rate [0.00125]
0: TRAIN [0][310/6832]	Time 0.359 (0.344)	Data 0.00101 (0.00325)	Tok/s 68318 (73993)	Loss/tok 6.3121 (7.8185)	Learning Rate [0.00125]
0: TRAIN [0][320/6832]	Time 0.483 (0.346)	Data 0.00105 (0.00318)	Tok/s 79613 (74242)	Loss/tok 6.3745 (7.7596)	Learning Rate [0.00125]
0: TRAIN [0][330/6832]	Time 0.196 (0.346)	Data 0.00102 (0.00312)	Tok/s 77338 (74363)	Loss/tok 5.9120 (7.7094)	Learning Rate [0.00125]
0: TRAIN [0][340/6832]	Time 0.399 (0.347)	Data 0.00111 (0.00306)	Tok/s 69262 (74319)	Loss/tok 6.1367 (7.6613)	Learning Rate [0.00125]
0: TRAIN [0][350/6832]	Time 0.393 (0.347)	Data 0.00108 (0.00300)	Tok/s 68675 (74259)	Loss/tok 6.1132 (7.6163)	Learning Rate [0.00125]
0: TRAIN [0][360/6832]	Time 0.381 (0.346)	Data 0.00101 (0.00295)	Tok/s 67189 (74449)	Loss/tok 6.0825 (7.5730)	Learning Rate [0.00125]
0: TRAIN [0][370/6832]	Time 0.228 (0.347)	Data 0.00101 (0.00290)	Tok/s 74973 (74433)	Loss/tok 5.7071 (7.5280)	Learning Rate [0.00125]
0: TRAIN [0][380/6832]	Time 0.467 (0.348)	Data 0.00142 (0.00285)	Tok/s 94720 (74486)	Loss/tok 6.0633 (7.4829)	Learning Rate [0.00125]
0: TRAIN [0][390/6832]	Time 0.467 (0.348)	Data 0.00112 (0.00280)	Tok/s 65716 (74423)	Loss/tok 5.9582 (7.4443)	Learning Rate [0.00125]
0: TRAIN [0][400/6832]	Time 0.400 (0.347)	Data 0.00111 (0.00276)	Tok/s 67586 (74373)	Loss/tok 5.8767 (7.4069)	Learning Rate [0.00125]
0: TRAIN [0][410/6832]	Time 0.182 (0.346)	Data 0.00108 (0.00272)	Tok/s 76645 (74324)	Loss/tok 5.3114 (7.3721)	Learning Rate [0.00125]
0: TRAIN [0][420/6832]	Time 0.099 (0.346)	Data 0.00106 (0.00268)	Tok/s 57741 (74289)	Loss/tok 3.8056 (7.3332)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: TRAIN [0][430/6832]	Time 0.481 (0.347)	Data 0.00115 (0.00264)	Tok/s 85948 (74265)	Loss/tok 5.7571 (7.2918)	Learning Rate [0.00125]
0: TRAIN [0][440/6832]	Time 0.300 (0.348)	Data 0.00106 (0.00261)	Tok/s 70003 (74318)	Loss/tok 5.4667 (7.2514)	Learning Rate [0.00125]
0: TRAIN [0][450/6832]	Time 0.285 (0.347)	Data 0.00106 (0.00258)	Tok/s 72578 (74385)	Loss/tok 5.5363 (7.2144)	Learning Rate [0.00125]
0: TRAIN [0][460/6832]	Time 0.480 (0.349)	Data 0.00107 (0.00254)	Tok/s 70191 (74330)	Loss/tok 5.7488 (7.1767)	Learning Rate [0.00125]
0: TRAIN [0][470/6832]	Time 0.246 (0.350)	Data 0.00104 (0.00251)	Tok/s 74809 (74333)	Loss/tok 5.2766 (7.1369)	Learning Rate [0.00125]
0: TRAIN [0][480/6832]	Time 0.112 (0.349)	Data 0.00105 (0.00248)	Tok/s 75276 (74349)	Loss/tok 3.9110 (7.1031)	Learning Rate [0.00125]
0: TRAIN [0][490/6832]	Time 0.462 (0.350)	Data 0.00106 (0.00246)	Tok/s 71846 (74422)	Loss/tok 5.5119 (7.0637)	Learning Rate [0.00125]
0: TRAIN [0][500/6832]	Time 0.480 (0.351)	Data 0.00117 (0.00243)	Tok/s 67429 (74309)	Loss/tok 5.4627 (7.0301)	Learning Rate [0.00125]
0: TRAIN [0][510/6832]	Time 0.411 (0.351)	Data 0.00106 (0.00240)	Tok/s 67270 (74280)	Loss/tok 5.3345 (6.9978)	Learning Rate [0.00125]
0: TRAIN [0][520/6832]	Time 0.473 (0.351)	Data 0.00116 (0.00238)	Tok/s 73280 (74267)	Loss/tok 5.4028 (6.9636)	Learning Rate [0.00125]
0: TRAIN [0][530/6832]	Time 0.308 (0.352)	Data 0.00112 (0.00236)	Tok/s 69899 (74249)	Loss/tok 5.1627 (6.9280)	Learning Rate [0.00125]
0: TRAIN [0][540/6832]	Time 0.415 (0.350)	Data 0.00102 (0.00233)	Tok/s 65724 (74235)	Loss/tok 5.3916 (6.9023)	Learning Rate [0.00125]
0: TRAIN [0][550/6832]	Time 0.234 (0.349)	Data 0.00100 (0.00231)	Tok/s 70158 (74191)	Loss/tok 4.8571 (6.8763)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][560/6832]	Time 0.244 (0.349)	Data 0.00103 (0.00229)	Tok/s 73383 (74182)	Loss/tok 4.8512 (6.8434)	Learning Rate [0.00125]
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: TRAIN [0][570/6832]	Time 0.466 (0.350)	Data 0.00104 (0.00226)	Tok/s 65596 (74211)	Loss/tok 5.1968 (6.8081)	Learning Rate [0.00125]
0: TRAIN [0][580/6832]	Time 0.404 (0.350)	Data 0.00100 (0.00224)	Tok/s 66715 (74217)	Loss/tok 5.0248 (6.7789)	Learning Rate [0.00125]
0: TRAIN [0][590/6832]	Time 0.133 (0.350)	Data 0.00102 (0.00222)	Tok/s 84907 (74214)	Loss/tok 4.1277 (6.7485)	Learning Rate [0.00125]
0: TRAIN [0][600/6832]	Time 0.485 (0.351)	Data 0.00104 (0.00220)	Tok/s 77872 (74223)	Loss/tok 5.2371 (6.7183)	Learning Rate [0.00125]
0: TRAIN [0][610/6832]	Time 0.323 (0.351)	Data 0.00107 (0.00219)	Tok/s 71226 (74260)	Loss/tok 4.9316 (6.6870)	Learning Rate [0.00125]
0: TRAIN [0][620/6832]	Time 0.478 (0.352)	Data 0.00105 (0.00217)	Tok/s 75252 (74227)	Loss/tok 5.1913 (6.6563)	Learning Rate [0.00125]
0: TRAIN [0][630/6832]	Time 0.425 (0.351)	Data 0.00108 (0.00215)	Tok/s 68669 (74207)	Loss/tok 4.9521 (6.6312)	Learning Rate [0.00125]
0: TRAIN [0][640/6832]	Time 0.284 (0.351)	Data 0.00099 (0.00213)	Tok/s 71157 (74186)	Loss/tok 4.7999 (6.6073)	Learning Rate [0.00125]
0: TRAIN [0][650/6832]	Time 0.461 (0.351)	Data 0.00101 (0.00212)	Tok/s 70078 (74203)	Loss/tok 5.0322 (6.5791)	Learning Rate [0.00125]
0: TRAIN [0][660/6832]	Time 0.241 (0.352)	Data 0.00107 (0.00210)	Tok/s 71003 (74267)	Loss/tok 4.5278 (6.5479)	Learning Rate [0.00125]
0: TRAIN [0][670/6832]	Time 0.308 (0.352)	Data 0.00104 (0.00209)	Tok/s 71591 (74262)	Loss/tok 4.7112 (6.5207)	Learning Rate [0.00125]
0: TRAIN [0][680/6832]	Time 0.487 (0.351)	Data 0.00100 (0.00207)	Tok/s 81393 (74283)	Loss/tok 4.9438 (6.4973)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][690/6832]	Time 0.403 (0.352)	Data 0.00099 (0.00206)	Tok/s 64894 (74344)	Loss/tok 4.8236 (6.4683)	Learning Rate [0.00125]
0: TRAIN [0][700/6832]	Time 0.487 (0.351)	Data 0.00110 (0.00204)	Tok/s 79084 (74343)	Loss/tok 4.9943 (6.4439)	Learning Rate [0.00125]
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: TRAIN [0][710/6832]	Time 0.283 (0.352)	Data 0.00138 (0.00203)	Tok/s 71679 (74377)	Loss/tok 4.5205 (6.4155)	Learning Rate [0.00125]
0: TRAIN [0][720/6832]	Time 0.203 (0.352)	Data 0.00118 (0.00201)	Tok/s 77076 (74348)	Loss/tok 4.3032 (6.3937)	Learning Rate [0.00125]
0: TRAIN [0][730/6832]	Time 0.359 (0.351)	Data 0.00103 (0.00200)	Tok/s 66989 (74350)	Loss/tok 4.6940 (6.3732)	Learning Rate [0.00125]
0: TRAIN [0][740/6832]	Time 0.237 (0.351)	Data 0.00105 (0.00199)	Tok/s 73637 (74363)	Loss/tok 4.4003 (6.3496)	Learning Rate [0.00125]
0: TRAIN [0][750/6832]	Time 0.482 (0.351)	Data 0.00102 (0.00198)	Tok/s 96793 (74311)	Loss/tok 4.7149 (6.3270)	Learning Rate [0.00125]
0: TRAIN [0][760/6832]	Time 0.159 (0.351)	Data 0.00104 (0.00196)	Tok/s 78221 (74296)	Loss/tok 3.9789 (6.3047)	Learning Rate [0.00125]
0: TRAIN [0][770/6832]	Time 0.484 (0.351)	Data 0.00100 (0.00195)	Tok/s 67544 (74324)	Loss/tok 4.6722 (6.2808)	Learning Rate [0.00125]
0: TRAIN [0][780/6832]	Time 0.483 (0.352)	Data 0.00023 (0.00194)	Tok/s 70675 (74337)	Loss/tok 4.8596 (6.2577)	Learning Rate [0.00125]
0: TRAIN [0][790/6832]	Time 0.186 (0.352)	Data 0.00104 (0.00193)	Tok/s 81352 (74380)	Loss/tok 4.2512 (6.2347)	Learning Rate [0.00125]
0: TRAIN [0][800/6832]	Time 0.254 (0.351)	Data 0.00101 (0.00192)	Tok/s 71486 (74417)	Loss/tok 4.3751 (6.2151)	Learning Rate [0.00125]
0: TRAIN [0][810/6832]	Time 0.481 (0.351)	Data 0.00101 (0.00191)	Tok/s 78273 (74432)	Loss/tok 4.7206 (6.1957)	Learning Rate [0.00125]
0: TRAIN [0][820/6832]	Time 0.094 (0.351)	Data 0.00118 (0.00190)	Tok/s 60462 (74479)	Loss/tok 2.7285 (6.1733)	Learning Rate [0.00125]
0: TRAIN [0][830/6832]	Time 0.484 (0.351)	Data 0.00097 (0.00189)	Tok/s 81965 (74467)	Loss/tok 4.5797 (6.1530)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: TRAIN [0][840/6832]	Time 0.151 (0.352)	Data 0.00100 (0.00188)	Tok/s 79256 (74493)	Loss/tok 3.8203 (6.1314)	Learning Rate [0.00125]
0: TRAIN [0][850/6832]	Time 0.405 (0.351)	Data 0.00103 (0.00187)	Tok/s 67164 (74487)	Loss/tok 4.4016 (6.1132)	Learning Rate [0.00125]
0: TRAIN [0][860/6832]	Time 0.478 (0.352)	Data 0.00101 (0.00186)	Tok/s 77416 (74463)	Loss/tok 4.5494 (6.0927)	Learning Rate [0.00125]
0: TRAIN [0][870/6832]	Time 0.365 (0.351)	Data 0.00101 (0.00185)	Tok/s 67778 (74479)	Loss/tok 4.5672 (6.0759)	Learning Rate [0.00125]
0: TRAIN [0][880/6832]	Time 0.278 (0.352)	Data 0.00102 (0.00184)	Tok/s 73598 (74459)	Loss/tok 4.2842 (6.0569)	Learning Rate [0.00125]
0: TRAIN [0][890/6832]	Time 0.141 (0.351)	Data 0.00099 (0.00183)	Tok/s 79413 (74489)	Loss/tok 3.6426 (6.0395)	Learning Rate [0.00125]
0: TRAIN [0][900/6832]	Time 0.475 (0.351)	Data 0.00099 (0.00182)	Tok/s 70224 (74458)	Loss/tok 4.6756 (6.0237)	Learning Rate [0.00125]
0: TRAIN [0][910/6832]	Time 0.480 (0.350)	Data 0.00112 (0.00194)	Tok/s 73425 (74450)	Loss/tok 4.5305 (6.0077)	Learning Rate [0.00125]
0: TRAIN [0][920/6832]	Time 0.294 (0.351)	Data 0.00103 (0.00193)	Tok/s 69221 (74423)	Loss/tok 4.2699 (5.9912)	Learning Rate [0.00125]
0: TRAIN [0][930/6832]	Time 0.160 (0.350)	Data 0.00104 (0.00192)	Tok/s 80809 (74477)	Loss/tok 3.7684 (5.9755)	Learning Rate [0.00125]
0: TRAIN [0][940/6832]	Time 0.198 (0.349)	Data 0.00105 (0.00191)	Tok/s 74413 (74461)	Loss/tok 3.9944 (5.9600)	Learning Rate [0.00125]
0: TRAIN [0][950/6832]	Time 0.227 (0.349)	Data 0.00110 (0.00190)	Tok/s 73706 (74457)	Loss/tok 4.1049 (5.9437)	Learning Rate [0.00125]
0: TRAIN [0][960/6832]	Time 0.200 (0.349)	Data 0.00104 (0.00190)	Tok/s 77654 (74469)	Loss/tok 3.9413 (5.9280)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][970/6832]	Time 0.187 (0.349)	Data 0.00096 (0.00189)	Tok/s 74772 (74489)	Loss/tok 3.8969 (5.9121)	Learning Rate [0.00125]
0: TRAIN [0][980/6832]	Time 0.251 (0.348)	Data 0.00098 (0.00188)	Tok/s 73502 (74481)	Loss/tok 4.3036 (5.8980)	Learning Rate [0.00125]
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: TRAIN [0][990/6832]	Time 0.483 (0.348)	Data 0.00102 (0.00187)	Tok/s 85351 (74507)	Loss/tok 4.4435 (5.8822)	Learning Rate [0.00125]
0: TRAIN [0][1000/6832]	Time 0.212 (0.348)	Data 0.00097 (0.00186)	Tok/s 75708 (74530)	Loss/tok 3.9130 (5.8660)	Learning Rate [0.00125]
0: TRAIN [0][1010/6832]	Time 0.434 (0.348)	Data 0.00100 (0.00185)	Tok/s 64919 (74520)	Loss/tok 4.3375 (5.8525)	Learning Rate [0.00125]
0: TRAIN [0][1020/6832]	Time 0.487 (0.347)	Data 0.00101 (0.00184)	Tok/s 78737 (74519)	Loss/tok 4.5299 (5.8396)	Learning Rate [0.00125]
0: TRAIN [0][1030/6832]	Time 0.486 (0.347)	Data 0.00096 (0.00184)	Tok/s 76364 (74516)	Loss/tok 4.5171 (5.8264)	Learning Rate [0.00125]
0: TRAIN [0][1040/6832]	Time 0.469 (0.347)	Data 0.00138 (0.00183)	Tok/s 77719 (74539)	Loss/tok 4.4614 (5.8102)	Learning Rate [0.00125]
0: TRAIN [0][1050/6832]	Time 0.452 (0.348)	Data 0.00102 (0.00182)	Tok/s 63217 (74495)	Loss/tok 4.3756 (5.7951)	Learning Rate [0.00125]
0: TRAIN [0][1060/6832]	Time 0.283 (0.348)	Data 0.00104 (0.00181)	Tok/s 72254 (74473)	Loss/tok 4.2067 (5.7813)	Learning Rate [0.00125]
0: TRAIN [0][1070/6832]	Time 0.204 (0.347)	Data 0.00099 (0.00181)	Tok/s 74515 (74456)	Loss/tok 3.9744 (5.7692)	Learning Rate [0.00125]
0: TRAIN [0][1080/6832]	Time 0.157 (0.347)	Data 0.00102 (0.00180)	Tok/s 79499 (74445)	Loss/tok 3.7219 (5.7554)	Learning Rate [0.00125]
0: TRAIN [0][1090/6832]	Time 0.461 (0.348)	Data 0.00101 (0.00179)	Tok/s 84428 (74466)	Loss/tok 4.3516 (5.7411)	Learning Rate [0.00125]
0: TRAIN [0][1100/6832]	Time 0.478 (0.348)	Data 0.00101 (0.00179)	Tok/s 84869 (74474)	Loss/tok 4.3394 (5.7265)	Learning Rate [0.00125]
0: TRAIN [0][1110/6832]	Time 0.123 (0.348)	Data 0.00101 (0.00178)	Tok/s 85593 (74477)	Loss/tok 3.4321 (5.7125)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][1120/6832]	Time 0.481 (0.348)	Data 0.00104 (0.00177)	Tok/s 68643 (74447)	Loss/tok 4.4814 (5.7005)	Learning Rate [0.00125]
0: TRAIN [0][1130/6832]	Time 0.188 (0.347)	Data 0.00101 (0.00177)	Tok/s 78639 (74460)	Loss/tok 3.9177 (5.6893)	Learning Rate [0.00125]
0: TRAIN [0][1140/6832]	Time 0.457 (0.348)	Data 0.00111 (0.00176)	Tok/s 64036 (74444)	Loss/tok 4.3642 (5.6762)	Learning Rate [0.00125]
0: TRAIN [0][1150/6832]	Time 0.147 (0.348)	Data 0.00099 (0.00175)	Tok/s 75633 (74410)	Loss/tok 3.4016 (5.6644)	Learning Rate [0.00125]
0: TRAIN [0][1160/6832]	Time 0.285 (0.348)	Data 0.00101 (0.00175)	Tok/s 73591 (74425)	Loss/tok 4.1720 (5.6506)	Learning Rate [0.00125]
0: TRAIN [0][1170/6832]	Time 0.472 (0.348)	Data 0.00097 (0.00174)	Tok/s 65676 (74388)	Loss/tok 4.3543 (5.6393)	Learning Rate [0.00125]
0: TRAIN [0][1180/6832]	Time 0.282 (0.348)	Data 0.00101 (0.00173)	Tok/s 73268 (74435)	Loss/tok 4.0942 (5.6253)	Learning Rate [0.00125]
0: TRAIN [0][1190/6832]	Time 0.479 (0.349)	Data 0.00100 (0.00173)	Tok/s 71375 (74404)	Loss/tok 4.3298 (5.6134)	Learning Rate [0.00125]
0: TRAIN [0][1200/6832]	Time 0.485 (0.349)	Data 0.00100 (0.00172)	Tok/s 77395 (74407)	Loss/tok 4.2807 (5.6010)	Learning Rate [0.00125]
0: TRAIN [0][1210/6832]	Time 0.378 (0.348)	Data 0.00099 (0.00172)	Tok/s 66466 (74368)	Loss/tok 4.2314 (5.5905)	Learning Rate [0.00125]
0: TRAIN [0][1220/6832]	Time 0.484 (0.349)	Data 0.00098 (0.00171)	Tok/s 85366 (74364)	Loss/tok 4.2722 (5.5786)	Learning Rate [0.00125]
0: TRAIN [0][1230/6832]	Time 0.282 (0.348)	Data 0.00104 (0.00171)	Tok/s 76217 (74340)	Loss/tok 4.0761 (5.5688)	Learning Rate [0.00125]
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: TRAIN [0][1240/6832]	Time 0.481 (0.348)	Data 0.00108 (0.00170)	Tok/s 72426 (74363)	Loss/tok 4.3971 (5.5577)	Learning Rate [0.00125]
0: TRAIN [0][1250/6832]	Time 0.293 (0.348)	Data 0.00102 (0.00170)	Tok/s 73291 (74355)	Loss/tok 4.0659 (5.5481)	Learning Rate [0.00125]
0: TRAIN [0][1260/6832]	Time 0.199 (0.348)	Data 0.00103 (0.00169)	Tok/s 79949 (74354)	Loss/tok 3.8252 (5.5375)	Learning Rate [0.00125]
0: TRAIN [0][1270/6832]	Time 0.341 (0.348)	Data 0.00110 (0.00168)	Tok/s 68339 (74361)	Loss/tok 4.0981 (5.5259)	Learning Rate [0.00125]
0: TRAIN [0][1280/6832]	Time 0.453 (0.348)	Data 0.00101 (0.00168)	Tok/s 64438 (74368)	Loss/tok 4.3239 (5.5154)	Learning Rate [0.00125]
0: TRAIN [0][1290/6832]	Time 0.243 (0.348)	Data 0.00098 (0.00167)	Tok/s 70589 (74349)	Loss/tok 3.8503 (5.5057)	Learning Rate [0.00125]
0: TRAIN [0][1300/6832]	Time 0.183 (0.347)	Data 0.00100 (0.00167)	Tok/s 78127 (74356)	Loss/tok 3.7448 (5.4966)	Learning Rate [0.00125]
0: TRAIN [0][1310/6832]	Time 0.370 (0.347)	Data 0.00097 (0.00166)	Tok/s 69993 (74331)	Loss/tok 4.1339 (5.4876)	Learning Rate [0.00125]
0: TRAIN [0][1320/6832]	Time 0.459 (0.346)	Data 0.00101 (0.00166)	Tok/s 65821 (74320)	Loss/tok 4.3338 (5.4789)	Learning Rate [0.00125]
0: TRAIN [0][1330/6832]	Time 0.419 (0.346)	Data 0.00097 (0.00166)	Tok/s 69677 (74314)	Loss/tok 4.2228 (5.4695)	Learning Rate [0.00125]
0: TRAIN [0][1340/6832]	Time 0.421 (0.346)	Data 0.00103 (0.00165)	Tok/s 68115 (74287)	Loss/tok 4.2735 (5.4601)	Learning Rate [0.00125]
0: TRAIN [0][1350/6832]	Time 0.486 (0.346)	Data 0.00098 (0.00165)	Tok/s 90785 (74312)	Loss/tok 4.3008 (5.4500)	Learning Rate [0.00125]
0: TRAIN [0][1360/6832]	Time 0.281 (0.346)	Data 0.00100 (0.00164)	Tok/s 71660 (74311)	Loss/tok 3.9533 (5.4406)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][1370/6832]	Time 0.207 (0.346)	Data 0.00097 (0.00164)	Tok/s 75523 (74318)	Loss/tok 3.7469 (5.4319)	Learning Rate [0.00125]
0: TRAIN [0][1380/6832]	Time 0.334 (0.346)	Data 0.00097 (0.00163)	Tok/s 73308 (74336)	Loss/tok 4.1992 (5.4220)	Learning Rate [0.00125]
0: TRAIN [0][1390/6832]	Time 0.468 (0.345)	Data 0.00100 (0.00163)	Tok/s 70736 (74351)	Loss/tok 4.3203 (5.4139)	Learning Rate [0.00125]
0: TRAIN [0][1400/6832]	Time 0.367 (0.345)	Data 0.00109 (0.00162)	Tok/s 67891 (74365)	Loss/tok 4.0579 (5.4046)	Learning Rate [0.00125]
0: TRAIN [0][1410/6832]	Time 0.314 (0.345)	Data 0.00103 (0.00162)	Tok/s 70041 (74344)	Loss/tok 3.9223 (5.3959)	Learning Rate [0.00125]
0: TRAIN [0][1420/6832]	Time 0.483 (0.345)	Data 0.00103 (0.00161)	Tok/s 82221 (74351)	Loss/tok 4.3543 (5.3863)	Learning Rate [0.00125]
0: TRAIN [0][1430/6832]	Time 0.483 (0.345)	Data 0.00102 (0.00161)	Tok/s 87005 (74358)	Loss/tok 4.1034 (5.3772)	Learning Rate [0.00125]
0: TRAIN [0][1440/6832]	Time 0.113 (0.346)	Data 0.00107 (0.00161)	Tok/s 75071 (74366)	Loss/tok 2.9722 (5.3673)	Learning Rate [0.00125]
0: TRAIN [0][1450/6832]	Time 0.325 (0.345)	Data 0.00116 (0.00160)	Tok/s 68366 (74350)	Loss/tok 4.0191 (5.3586)	Learning Rate [0.00125]
0: TRAIN [0][1460/6832]	Time 0.139 (0.345)	Data 0.00102 (0.00160)	Tok/s 69604 (74355)	Loss/tok 3.1572 (5.3505)	Learning Rate [0.00125]
0: TRAIN [0][1470/6832]	Time 0.423 (0.345)	Data 0.00102 (0.00160)	Tok/s 66534 (74340)	Loss/tok 4.1693 (5.3414)	Learning Rate [0.00125]
0: TRAIN [0][1480/6832]	Time 0.484 (0.346)	Data 0.00109 (0.00159)	Tok/s 76437 (74344)	Loss/tok 4.1751 (5.3321)	Learning Rate [0.00125]
0: TRAIN [0][1490/6832]	Time 0.419 (0.346)	Data 0.00099 (0.00159)	Tok/s 66210 (74370)	Loss/tok 4.1191 (5.3222)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][1500/6832]	Time 0.487 (0.346)	Data 0.00104 (0.00158)	Tok/s 86453 (74383)	Loss/tok 4.1258 (5.3118)	Learning Rate [0.00125]
0: TRAIN [0][1510/6832]	Time 0.450 (0.347)	Data 0.00104 (0.00158)	Tok/s 69085 (74370)	Loss/tok 4.1718 (5.3030)	Learning Rate [0.00125]
0: TRAIN [0][1520/6832]	Time 0.481 (0.347)	Data 0.00099 (0.00158)	Tok/s 82514 (74374)	Loss/tok 4.0936 (5.2941)	Learning Rate [0.00125]
0: TRAIN [0][1530/6832]	Time 0.222 (0.347)	Data 0.00099 (0.00157)	Tok/s 75132 (74360)	Loss/tok 3.7915 (5.2867)	Learning Rate [0.00125]
0: TRAIN [0][1540/6832]	Time 0.142 (0.347)	Data 0.00097 (0.00157)	Tok/s 78840 (74380)	Loss/tok 3.3516 (5.2778)	Learning Rate [0.00125]
0: TRAIN [0][1550/6832]	Time 0.347 (0.347)	Data 0.00098 (0.00157)	Tok/s 69333 (74394)	Loss/tok 4.0759 (5.2686)	Learning Rate [0.00125]
0: TRAIN [0][1560/6832]	Time 0.120 (0.347)	Data 0.00100 (0.00156)	Tok/s 70188 (74365)	Loss/tok 2.9154 (5.2611)	Learning Rate [0.00125]
0: TRAIN [0][1570/6832]	Time 0.485 (0.347)	Data 0.00099 (0.00156)	Tok/s 100393 (74387)	Loss/tok 3.9027 (5.2515)	Learning Rate [0.00125]
0: TRAIN [0][1580/6832]	Time 0.483 (0.348)	Data 0.00098 (0.00156)	Tok/s 71129 (74364)	Loss/tok 4.1711 (5.2436)	Learning Rate [0.00125]
0: TRAIN [0][1590/6832]	Time 0.467 (0.348)	Data 0.00127 (0.00155)	Tok/s 74357 (74396)	Loss/tok 4.1453 (5.2338)	Learning Rate [0.00125]
0: TRAIN [0][1600/6832]	Time 0.259 (0.348)	Data 0.00107 (0.00155)	Tok/s 73092 (74419)	Loss/tok 3.8632 (5.2254)	Learning Rate [0.00125]
0: TRAIN [0][1610/6832]	Time 0.458 (0.348)	Data 0.00109 (0.00155)	Tok/s 69680 (74421)	Loss/tok 4.1649 (5.2179)	Learning Rate [0.00125]
0: TRAIN [0][1620/6832]	Time 0.112 (0.348)	Data 0.00104 (0.00154)	Tok/s 74567 (74403)	Loss/tok 2.8780 (5.2110)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][1630/6832]	Time 0.237 (0.348)	Data 0.00103 (0.00154)	Tok/s 77844 (74413)	Loss/tok 3.8623 (5.2029)	Learning Rate [0.00125]
0: TRAIN [0][1640/6832]	Time 0.330 (0.348)	Data 0.00105 (0.00154)	Tok/s 70481 (74380)	Loss/tok 3.9945 (5.1956)	Learning Rate [0.00125]
0: TRAIN [0][1650/6832]	Time 0.184 (0.348)	Data 0.00106 (0.00153)	Tok/s 80448 (74395)	Loss/tok 3.6548 (5.1873)	Learning Rate [0.00125]
0: TRAIN [0][1660/6832]	Time 0.197 (0.348)	Data 0.00109 (0.00153)	Tok/s 76756 (74379)	Loss/tok 3.6721 (5.1804)	Learning Rate [0.00125]
0: TRAIN [0][1670/6832]	Time 0.465 (0.348)	Data 0.00106 (0.00153)	Tok/s 90448 (74425)	Loss/tok 4.0459 (5.1722)	Learning Rate [0.00125]
0: TRAIN [0][1680/6832]	Time 0.169 (0.348)	Data 0.00105 (0.00153)	Tok/s 77032 (74430)	Loss/tok 3.5444 (5.1656)	Learning Rate [0.00125]
0: TRAIN [0][1690/6832]	Time 0.347 (0.348)	Data 0.00103 (0.00152)	Tok/s 70246 (74418)	Loss/tok 3.9260 (5.1583)	Learning Rate [0.00125]
0: TRAIN [0][1700/6832]	Time 0.431 (0.348)	Data 0.00138 (0.00152)	Tok/s 65964 (74397)	Loss/tok 4.0614 (5.1519)	Learning Rate [0.00125]
0: Gradient norm: inf
0: Skipped batch, new scale: 4096.0
0: TRAIN [0][1710/6832]	Time 0.454 (0.348)	Data 0.00096 (0.00152)	Tok/s 67283 (74417)	Loss/tok 4.0235 (5.1445)	Learning Rate [0.00125]
0: TRAIN [0][1720/6832]	Time 0.208 (0.349)	Data 0.00104 (0.00152)	Tok/s 75078 (74411)	Loss/tok 3.7660 (5.1368)	Learning Rate [0.00125]
0: TRAIN [0][1730/6832]	Time 0.147 (0.348)	Data 0.00113 (0.00151)	Tok/s 75989 (74412)	Loss/tok 3.2705 (5.1304)	Learning Rate [0.00125]
0: TRAIN [0][1740/6832]	Time 0.264 (0.348)	Data 0.00102 (0.00151)	Tok/s 73853 (74404)	Loss/tok 3.8741 (5.1242)	Learning Rate [0.00125]
0: TRAIN [0][1750/6832]	Time 0.485 (0.349)	Data 0.00104 (0.00151)	Tok/s 100357 (74409)	Loss/tok 3.9056 (5.1164)	Learning Rate [0.00125]
0: TRAIN [0][1760/6832]	Time 0.480 (0.349)	Data 0.00107 (0.00150)	Tok/s 67565 (74396)	Loss/tok 4.0602 (5.1096)	Learning Rate [0.00125]
0: TRAIN [0][1770/6832]	Time 0.397 (0.349)	Data 0.00099 (0.00150)	Tok/s 68858 (74380)	Loss/tok 3.9232 (5.1039)	Learning Rate [0.00125]
0: TRAIN [0][1780/6832]	Time 0.381 (0.348)	Data 0.00105 (0.00150)	Tok/s 67635 (74368)	Loss/tok 3.9377 (5.0985)	Learning Rate [0.00125]
0: TRAIN [0][1790/6832]	Time 0.461 (0.348)	Data 0.00098 (0.00150)	Tok/s 84779 (74371)	Loss/tok 4.1197 (5.0917)	Learning Rate [0.00125]
0: TRAIN [0][1800/6832]	Time 0.218 (0.348)	Data 0.00101 (0.00149)	Tok/s 75153 (74358)	Loss/tok 3.6838 (5.0862)	Learning Rate [0.00125]
0: TRAIN [0][1810/6832]	Time 0.485 (0.348)	Data 0.00102 (0.00149)	Tok/s 83645 (74380)	Loss/tok 4.0177 (5.0787)	Learning Rate [0.00125]
0: TRAIN [0][1820/6832]	Time 0.487 (0.348)	Data 0.00106 (0.00149)	Tok/s 86624 (74382)	Loss/tok 4.0661 (5.0728)	Learning Rate [0.00125]
0: TRAIN [0][1830/6832]	Time 0.297 (0.348)	Data 0.00106 (0.00149)	Tok/s 70641 (74366)	Loss/tok 3.9087 (5.0668)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][1840/6832]	Time 0.417 (0.348)	Data 0.00100 (0.00148)	Tok/s 66261 (74356)	Loss/tok 4.0748 (5.0611)	Learning Rate [0.00125]
0: TRAIN [0][1850/6832]	Time 0.470 (0.348)	Data 0.00097 (0.00148)	Tok/s 70592 (74353)	Loss/tok 4.2167 (5.0563)	Learning Rate [0.00125]
0: TRAIN [0][1860/6832]	Time 0.159 (0.348)	Data 0.00100 (0.00148)	Tok/s 74656 (74371)	Loss/tok 3.2844 (5.0497)	Learning Rate [0.00125]
0: TRAIN [0][1870/6832]	Time 0.290 (0.348)	Data 0.00100 (0.00148)	Tok/s 77036 (74376)	Loss/tok 3.9739 (5.0439)	Learning Rate [0.00125]
0: TRAIN [0][1880/6832]	Time 0.147 (0.348)	Data 0.00099 (0.00147)	Tok/s 75941 (74364)	Loss/tok 3.2577 (5.0383)	Learning Rate [0.00125]
0: TRAIN [0][1890/6832]	Time 0.486 (0.348)	Data 0.00102 (0.00147)	Tok/s 78706 (74379)	Loss/tok 4.0366 (5.0312)	Learning Rate [0.00125]
0: TRAIN [0][1900/6832]	Time 0.475 (0.348)	Data 0.00097 (0.00147)	Tok/s 62019 (74351)	Loss/tok 4.0792 (5.0259)	Learning Rate [0.00125]
0: TRAIN [0][1910/6832]	Time 0.315 (0.348)	Data 0.00101 (0.00147)	Tok/s 70704 (74337)	Loss/tok 3.8184 (5.0207)	Learning Rate [0.00125]
0: TRAIN [0][1920/6832]	Time 0.196 (0.348)	Data 0.00101 (0.00147)	Tok/s 77535 (74329)	Loss/tok 3.6074 (5.0159)	Learning Rate [0.00125]
0: TRAIN [0][1930/6832]	Time 0.231 (0.348)	Data 0.00102 (0.00146)	Tok/s 70901 (74308)	Loss/tok 3.6949 (5.0104)	Learning Rate [0.00125]
0: TRAIN [0][1940/6832]	Time 0.383 (0.348)	Data 0.00097 (0.00146)	Tok/s 68362 (74308)	Loss/tok 3.8890 (5.0047)	Learning Rate [0.00125]
0: TRAIN [0][1950/6832]	Time 0.142 (0.347)	Data 0.00104 (0.00146)	Tok/s 79159 (74307)	Loss/tok 3.2120 (4.9992)	Learning Rate [0.00125]
0: TRAIN [0][1960/6832]	Time 0.337 (0.347)	Data 0.00111 (0.00146)	Tok/s 69522 (74306)	Loss/tok 3.8554 (4.9943)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][1970/6832]	Time 0.376 (0.347)	Data 0.00104 (0.00146)	Tok/s 67955 (74307)	Loss/tok 3.8895 (4.9880)	Learning Rate [0.00125]
0: TRAIN [0][1980/6832]	Time 0.465 (0.347)	Data 0.00101 (0.00145)	Tok/s 77539 (74340)	Loss/tok 3.9807 (4.9819)	Learning Rate [0.00125]
0: TRAIN [0][1990/6832]	Time 0.156 (0.347)	Data 0.00098 (0.00145)	Tok/s 79970 (74342)	Loss/tok 3.3425 (4.9768)	Learning Rate [0.00125]
0: TRAIN [0][2000/6832]	Time 0.404 (0.347)	Data 0.00109 (0.00145)	Tok/s 66887 (74332)	Loss/tok 3.9527 (4.9716)	Learning Rate [0.00125]
0: TRAIN [0][2010/6832]	Time 0.144 (0.347)	Data 0.00100 (0.00145)	Tok/s 77446 (74348)	Loss/tok 3.2019 (4.9663)	Learning Rate [0.00125]
0: TRAIN [0][2020/6832]	Time 0.470 (0.347)	Data 0.00108 (0.00145)	Tok/s 63191 (74331)	Loss/tok 4.0554 (4.9619)	Learning Rate [0.00125]
0: TRAIN [0][2030/6832]	Time 0.410 (0.347)	Data 0.00105 (0.00144)	Tok/s 64997 (74322)	Loss/tok 4.0210 (4.9564)	Learning Rate [0.00125]
0: TRAIN [0][2040/6832]	Time 0.207 (0.347)	Data 0.00109 (0.00144)	Tok/s 73653 (74330)	Loss/tok 3.6088 (4.9513)	Learning Rate [0.00125]
0: TRAIN [0][2050/6832]	Time 0.200 (0.347)	Data 0.00104 (0.00144)	Tok/s 76417 (74330)	Loss/tok 3.5737 (4.9462)	Learning Rate [0.00125]
0: TRAIN [0][2060/6832]	Time 0.397 (0.347)	Data 0.00106 (0.00144)	Tok/s 68249 (74333)	Loss/tok 3.9832 (4.9408)	Learning Rate [0.00125]
0: TRAIN [0][2070/6832]	Time 0.339 (0.347)	Data 0.00103 (0.00144)	Tok/s 67061 (74322)	Loss/tok 3.9278 (4.9358)	Learning Rate [0.00125]
0: TRAIN [0][2080/6832]	Time 0.272 (0.347)	Data 0.00137 (0.00144)	Tok/s 70593 (74306)	Loss/tok 3.8000 (4.9311)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2090/6832]	Time 0.480 (0.347)	Data 0.00111 (0.00143)	Tok/s 101593 (74316)	Loss/tok 3.8154 (4.9257)	Learning Rate [0.00125]
0: TRAIN [0][2100/6832]	Time 0.409 (0.347)	Data 0.00106 (0.00143)	Tok/s 67616 (74298)	Loss/tok 4.0118 (4.9213)	Learning Rate [0.00125]
0: TRAIN [0][2110/6832]	Time 0.254 (0.347)	Data 0.00106 (0.00143)	Tok/s 71822 (74289)	Loss/tok 3.6757 (4.9159)	Learning Rate [0.00125]
0: TRAIN [0][2120/6832]	Time 0.394 (0.347)	Data 0.00107 (0.00143)	Tok/s 70298 (74268)	Loss/tok 3.9948 (4.9116)	Learning Rate [0.00125]
0: TRAIN [0][2130/6832]	Time 0.280 (0.347)	Data 0.00112 (0.00143)	Tok/s 71392 (74263)	Loss/tok 3.7508 (4.9067)	Learning Rate [0.00125]
0: TRAIN [0][2140/6832]	Time 0.459 (0.347)	Data 0.00106 (0.00143)	Tok/s 76726 (74261)	Loss/tok 4.0376 (4.9025)	Learning Rate [0.00125]
0: TRAIN [0][2150/6832]	Time 0.410 (0.347)	Data 0.00108 (0.00142)	Tok/s 69581 (74251)	Loss/tok 3.9673 (4.8973)	Learning Rate [0.00125]
0: TRAIN [0][2160/6832]	Time 0.480 (0.347)	Data 0.00104 (0.00142)	Tok/s 75232 (74246)	Loss/tok 4.0357 (4.8932)	Learning Rate [0.00125]
0: TRAIN [0][2170/6832]	Time 0.485 (0.347)	Data 0.00109 (0.00142)	Tok/s 80818 (74253)	Loss/tok 4.0556 (4.8882)	Learning Rate [0.00125]
0: TRAIN [0][2180/6832]	Time 0.258 (0.347)	Data 0.00105 (0.00142)	Tok/s 74306 (74260)	Loss/tok 3.6901 (4.8836)	Learning Rate [0.00125]
0: TRAIN [0][2190/6832]	Time 0.347 (0.347)	Data 0.00102 (0.00142)	Tok/s 69163 (74255)	Loss/tok 3.8316 (4.8791)	Learning Rate [0.00125]
0: TRAIN [0][2200/6832]	Time 0.186 (0.347)	Data 0.00106 (0.00142)	Tok/s 76967 (74265)	Loss/tok 3.5658 (4.8742)	Learning Rate [0.00125]
0: TRAIN [0][2210/6832]	Time 0.450 (0.347)	Data 0.00102 (0.00141)	Tok/s 64400 (74254)	Loss/tok 3.9206 (4.8693)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2220/6832]	Time 0.278 (0.347)	Data 0.00109 (0.00141)	Tok/s 69146 (74250)	Loss/tok 3.6602 (4.8651)	Learning Rate [0.00125]
0: TRAIN [0][2230/6832]	Time 0.436 (0.347)	Data 0.00108 (0.00141)	Tok/s 68920 (74236)	Loss/tok 3.9832 (4.8608)	Learning Rate [0.00125]
0: TRAIN [0][2240/6832]	Time 0.135 (0.347)	Data 0.00108 (0.00141)	Tok/s 77810 (74234)	Loss/tok 3.1206 (4.8563)	Learning Rate [0.00125]
0: TRAIN [0][2250/6832]	Time 0.454 (0.347)	Data 0.00107 (0.00141)	Tok/s 71011 (74247)	Loss/tok 4.0765 (4.8519)	Learning Rate [0.00125]
0: TRAIN [0][2260/6832]	Time 0.299 (0.347)	Data 0.00102 (0.00141)	Tok/s 73534 (74234)	Loss/tok 3.7435 (4.8482)	Learning Rate [0.00125]
0: TRAIN [0][2270/6832]	Time 0.130 (0.347)	Data 0.00108 (0.00141)	Tok/s 80956 (74246)	Loss/tok 3.2055 (4.8434)	Learning Rate [0.00125]
0: TRAIN [0][2280/6832]	Time 0.186 (0.347)	Data 0.00106 (0.00140)	Tok/s 76892 (74236)	Loss/tok 3.4189 (4.8393)	Learning Rate [0.00125]
0: TRAIN [0][2290/6832]	Time 0.323 (0.347)	Data 0.00107 (0.00140)	Tok/s 70081 (74228)	Loss/tok 3.8416 (4.8349)	Learning Rate [0.00125]
0: TRAIN [0][2300/6832]	Time 0.476 (0.347)	Data 0.00103 (0.00140)	Tok/s 67353 (74258)	Loss/tok 3.9629 (4.8292)	Learning Rate [0.00125]
0: TRAIN [0][2310/6832]	Time 0.229 (0.347)	Data 0.00101 (0.00140)	Tok/s 74615 (74242)	Loss/tok 3.6150 (4.8253)	Learning Rate [0.00125]
0: TRAIN [0][2320/6832]	Time 0.475 (0.347)	Data 0.00110 (0.00140)	Tok/s 71984 (74247)	Loss/tok 3.9290 (4.8212)	Learning Rate [0.00125]
0: TRAIN [0][2330/6832]	Time 0.266 (0.347)	Data 0.00105 (0.00140)	Tok/s 73113 (74254)	Loss/tok 3.6411 (4.8166)	Learning Rate [0.00125]
0: TRAIN [0][2340/6832]	Time 0.196 (0.347)	Data 0.00106 (0.00140)	Tok/s 75748 (74263)	Loss/tok 3.5612 (4.8126)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2350/6832]	Time 0.453 (0.347)	Data 0.00106 (0.00139)	Tok/s 65097 (74262)	Loss/tok 3.9457 (4.8077)	Learning Rate [0.00125]
0: TRAIN [0][2360/6832]	Time 0.356 (0.347)	Data 0.00142 (0.00139)	Tok/s 67670 (74246)	Loss/tok 3.8788 (4.8037)	Learning Rate [0.00125]
0: TRAIN [0][2370/6832]	Time 0.252 (0.347)	Data 0.00109 (0.00139)	Tok/s 70903 (74244)	Loss/tok 3.6118 (4.7999)	Learning Rate [0.00125]
0: TRAIN [0][2380/6832]	Time 0.354 (0.347)	Data 0.00103 (0.00139)	Tok/s 66320 (74258)	Loss/tok 3.7844 (4.7955)	Learning Rate [0.00125]
0: TRAIN [0][2390/6832]	Time 0.115 (0.347)	Data 0.00109 (0.00139)	Tok/s 72064 (74248)	Loss/tok 2.7114 (4.7921)	Learning Rate [0.00125]
0: TRAIN [0][2400/6832]	Time 0.154 (0.347)	Data 0.00111 (0.00139)	Tok/s 77054 (74251)	Loss/tok 3.2424 (4.7881)	Learning Rate [0.00125]
0: TRAIN [0][2410/6832]	Time 0.313 (0.346)	Data 0.00110 (0.00139)	Tok/s 70235 (74239)	Loss/tok 3.6626 (4.7844)	Learning Rate [0.00125]
0: TRAIN [0][2420/6832]	Time 0.382 (0.347)	Data 0.00104 (0.00138)	Tok/s 69700 (74239)	Loss/tok 3.7865 (4.7802)	Learning Rate [0.00125]
0: TRAIN [0][2430/6832]	Time 0.381 (0.347)	Data 0.00103 (0.00138)	Tok/s 69444 (74222)	Loss/tok 3.8550 (4.7762)	Learning Rate [0.00125]
0: TRAIN [0][2440/6832]	Time 0.398 (0.347)	Data 0.00109 (0.00138)	Tok/s 64934 (74219)	Loss/tok 3.9146 (4.7722)	Learning Rate [0.00125]
0: TRAIN [0][2450/6832]	Time 0.329 (0.347)	Data 0.00109 (0.00138)	Tok/s 70063 (74212)	Loss/tok 3.7946 (4.7687)	Learning Rate [0.00125]
0: TRAIN [0][2460/6832]	Time 0.448 (0.347)	Data 0.00101 (0.00138)	Tok/s 64536 (74218)	Loss/tok 3.8626 (4.7647)	Learning Rate [0.00125]
0: TRAIN [0][2470/6832]	Time 0.399 (0.347)	Data 0.00118 (0.00138)	Tok/s 67993 (74223)	Loss/tok 3.8321 (4.7603)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2480/6832]	Time 0.478 (0.347)	Data 0.00113 (0.00138)	Tok/s 65789 (74216)	Loss/tok 3.9256 (4.7564)	Learning Rate [0.00125]
0: TRAIN [0][2490/6832]	Time 0.481 (0.347)	Data 0.00111 (0.00138)	Tok/s 67195 (74214)	Loss/tok 4.0395 (4.7523)	Learning Rate [0.00125]
0: TRAIN [0][2500/6832]	Time 0.482 (0.347)	Data 0.00105 (0.00138)	Tok/s 89358 (74214)	Loss/tok 3.8558 (4.7483)	Learning Rate [0.00125]
0: TRAIN [0][2510/6832]	Time 0.486 (0.348)	Data 0.00109 (0.00137)	Tok/s 90971 (74209)	Loss/tok 3.8225 (4.7444)	Learning Rate [0.00125]
0: TRAIN [0][2520/6832]	Time 0.265 (0.347)	Data 0.00108 (0.00137)	Tok/s 73615 (74202)	Loss/tok 3.5630 (4.7413)	Learning Rate [0.00125]
0: TRAIN [0][2530/6832]	Time 0.481 (0.347)	Data 0.00104 (0.00137)	Tok/s 78403 (74206)	Loss/tok 3.9044 (4.7376)	Learning Rate [0.00125]
0: TRAIN [0][2540/6832]	Time 0.485 (0.347)	Data 0.00108 (0.00137)	Tok/s 80760 (74239)	Loss/tok 3.8859 (4.7327)	Learning Rate [0.00125]
0: TRAIN [0][2550/6832]	Time 0.469 (0.348)	Data 0.00107 (0.00137)	Tok/s 64422 (74219)	Loss/tok 3.9499 (4.7292)	Learning Rate [0.00125]
0: TRAIN [0][2560/6832]	Time 0.482 (0.348)	Data 0.00104 (0.00137)	Tok/s 93739 (74227)	Loss/tok 3.8277 (4.7253)	Learning Rate [0.00125]
0: TRAIN [0][2570/6832]	Time 0.273 (0.347)	Data 0.00103 (0.00137)	Tok/s 69984 (74220)	Loss/tok 3.7087 (4.7220)	Learning Rate [0.00125]
0: TRAIN [0][2580/6832]	Time 0.424 (0.348)	Data 0.00109 (0.00137)	Tok/s 67140 (74210)	Loss/tok 3.8931 (4.7183)	Learning Rate [0.00125]
0: TRAIN [0][2590/6832]	Time 0.486 (0.347)	Data 0.00105 (0.00137)	Tok/s 85170 (74201)	Loss/tok 3.8897 (4.7149)	Learning Rate [0.00125]
0: TRAIN [0][2600/6832]	Time 0.311 (0.347)	Data 0.00106 (0.00136)	Tok/s 69570 (74200)	Loss/tok 3.7604 (4.7118)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2610/6832]	Time 0.437 (0.347)	Data 0.00098 (0.00136)	Tok/s 65530 (74181)	Loss/tok 3.9116 (4.7086)	Learning Rate [0.00125]
0: TRAIN [0][2620/6832]	Time 0.224 (0.347)	Data 0.00106 (0.00136)	Tok/s 74319 (74190)	Loss/tok 3.4898 (4.7048)	Learning Rate [0.00125]
0: TRAIN [0][2630/6832]	Time 0.412 (0.347)	Data 0.00097 (0.00136)	Tok/s 67033 (74181)	Loss/tok 3.8846 (4.7017)	Learning Rate [0.00125]
0: TRAIN [0][2640/6832]	Time 0.478 (0.347)	Data 0.00100 (0.00136)	Tok/s 84398 (74197)	Loss/tok 3.9156 (4.6983)	Learning Rate [0.00125]
0: TRAIN [0][2650/6832]	Time 0.483 (0.347)	Data 0.00100 (0.00136)	Tok/s 74464 (74209)	Loss/tok 3.8903 (4.6943)	Learning Rate [0.00125]
0: TRAIN [0][2660/6832]	Time 0.486 (0.347)	Data 0.00116 (0.00136)	Tok/s 80281 (74210)	Loss/tok 3.8609 (4.6909)	Learning Rate [0.00125]
0: TRAIN [0][2670/6832]	Time 0.255 (0.347)	Data 0.00109 (0.00136)	Tok/s 74235 (74197)	Loss/tok 3.6865 (4.6874)	Learning Rate [0.00125]
0: TRAIN [0][2680/6832]	Time 0.403 (0.347)	Data 0.00112 (0.00136)	Tok/s 66126 (74200)	Loss/tok 3.8369 (4.6839)	Learning Rate [0.00125]
0: TRAIN [0][2690/6832]	Time 0.358 (0.347)	Data 0.00108 (0.00135)	Tok/s 70453 (74200)	Loss/tok 3.7493 (4.6807)	Learning Rate [0.00125]
0: TRAIN [0][2700/6832]	Time 0.469 (0.347)	Data 0.00098 (0.00135)	Tok/s 70977 (74197)	Loss/tok 3.8265 (4.6773)	Learning Rate [0.00125]
0: TRAIN [0][2710/6832]	Time 0.296 (0.347)	Data 0.00130 (0.00135)	Tok/s 72896 (74203)	Loss/tok 3.7327 (4.6740)	Learning Rate [0.00125]
0: TRAIN [0][2720/6832]	Time 0.402 (0.347)	Data 0.00112 (0.00135)	Tok/s 70015 (74203)	Loss/tok 3.8427 (4.6705)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2730/6832]	Time 0.229 (0.347)	Data 0.00150 (0.00135)	Tok/s 74958 (74196)	Loss/tok 3.5604 (4.6676)	Learning Rate [0.00125]
0: TRAIN [0][2740/6832]	Time 0.405 (0.347)	Data 0.00107 (0.00135)	Tok/s 66442 (74188)	Loss/tok 3.8567 (4.6644)	Learning Rate [0.00125]
0: TRAIN [0][2750/6832]	Time 0.388 (0.347)	Data 0.00110 (0.00135)	Tok/s 68705 (74188)	Loss/tok 3.8836 (4.6612)	Learning Rate [0.00125]
0: TRAIN [0][2760/6832]	Time 0.468 (0.347)	Data 0.00024 (0.00135)	Tok/s 70954 (74181)	Loss/tok 3.9380 (4.6581)	Learning Rate [0.00125]
0: TRAIN [0][2770/6832]	Time 0.479 (0.347)	Data 0.00101 (0.00135)	Tok/s 75885 (74173)	Loss/tok 3.9735 (4.6550)	Learning Rate [0.00125]
0: TRAIN [0][2780/6832]	Time 0.173 (0.347)	Data 0.00111 (0.00135)	Tok/s 78014 (74170)	Loss/tok 3.4041 (4.6516)	Learning Rate [0.00125]
0: TRAIN [0][2790/6832]	Time 0.373 (0.347)	Data 0.00103 (0.00135)	Tok/s 69075 (74165)	Loss/tok 3.7291 (4.6487)	Learning Rate [0.00125]
0: TRAIN [0][2800/6832]	Time 0.421 (0.347)	Data 0.00109 (0.00134)	Tok/s 68673 (74170)	Loss/tok 3.8147 (4.6454)	Learning Rate [0.00125]
0: TRAIN [0][2810/6832]	Time 0.490 (0.347)	Data 0.00114 (0.00134)	Tok/s 89974 (74183)	Loss/tok 3.8147 (4.6419)	Learning Rate [0.00125]
0: TRAIN [0][2820/6832]	Time 0.181 (0.347)	Data 0.00113 (0.00134)	Tok/s 79554 (74170)	Loss/tok 3.3826 (4.6392)	Learning Rate [0.00125]
0: TRAIN [0][2830/6832]	Time 0.484 (0.347)	Data 0.00102 (0.00134)	Tok/s 86882 (74172)	Loss/tok 3.8290 (4.6361)	Learning Rate [0.00125]
0: TRAIN [0][2840/6832]	Time 0.402 (0.347)	Data 0.00101 (0.00134)	Tok/s 65086 (74173)	Loss/tok 3.8196 (4.6333)	Learning Rate [0.00125]
0: TRAIN [0][2850/6832]	Time 0.369 (0.347)	Data 0.00101 (0.00134)	Tok/s 67011 (74163)	Loss/tok 3.8056 (4.6304)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2860/6832]	Time 0.345 (0.347)	Data 0.00103 (0.00134)	Tok/s 69722 (74170)	Loss/tok 3.9071 (4.6272)	Learning Rate [0.00125]
0: TRAIN [0][2870/6832]	Time 0.465 (0.347)	Data 0.00102 (0.00134)	Tok/s 62748 (74156)	Loss/tok 3.8045 (4.6239)	Learning Rate [0.00125]
0: TRAIN [0][2880/6832]	Time 0.316 (0.347)	Data 0.00109 (0.00134)	Tok/s 69576 (74144)	Loss/tok 3.7937 (4.6211)	Learning Rate [0.00125]
0: TRAIN [0][2890/6832]	Time 0.218 (0.347)	Data 0.00117 (0.00134)	Tok/s 73401 (74141)	Loss/tok 3.5194 (4.6184)	Learning Rate [0.00125]
0: TRAIN [0][2900/6832]	Time 0.109 (0.347)	Data 0.00114 (0.00134)	Tok/s 76892 (74127)	Loss/tok 2.7377 (4.6157)	Learning Rate [0.00125]
0: TRAIN [0][2910/6832]	Time 0.414 (0.347)	Data 0.00105 (0.00134)	Tok/s 66163 (74127)	Loss/tok 3.7765 (4.6125)	Learning Rate [0.00125]
0: TRAIN [0][2920/6832]	Time 0.386 (0.347)	Data 0.00100 (0.00133)	Tok/s 67598 (74115)	Loss/tok 3.6873 (4.6097)	Learning Rate [0.00125]
0: TRAIN [0][2930/6832]	Time 0.464 (0.347)	Data 0.00110 (0.00133)	Tok/s 72578 (74114)	Loss/tok 3.8609 (4.6068)	Learning Rate [0.00125]
0: TRAIN [0][2940/6832]	Time 0.486 (0.347)	Data 0.00106 (0.00133)	Tok/s 81935 (74134)	Loss/tok 3.8151 (4.6032)	Learning Rate [0.00125]
0: TRAIN [0][2950/6832]	Time 0.481 (0.347)	Data 0.00102 (0.00133)	Tok/s 77255 (74134)	Loss/tok 3.8330 (4.6002)	Learning Rate [0.00125]
0: TRAIN [0][2960/6832]	Time 0.470 (0.347)	Data 0.00109 (0.00133)	Tok/s 75163 (74141)	Loss/tok 3.9416 (4.5975)	Learning Rate [0.00125]
0: TRAIN [0][2970/6832]	Time 0.432 (0.347)	Data 0.00103 (0.00133)	Tok/s 66305 (74143)	Loss/tok 3.8720 (4.5943)	Learning Rate [0.00125]
0: TRAIN [0][2980/6832]	Time 0.469 (0.347)	Data 0.00103 (0.00133)	Tok/s 67552 (74141)	Loss/tok 3.8332 (4.5914)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][2990/6832]	Time 0.272 (0.347)	Data 0.00099 (0.00133)	Tok/s 71974 (74135)	Loss/tok 3.6013 (4.5889)	Learning Rate [0.00125]
0: TRAIN [0][3000/6832]	Time 0.465 (0.347)	Data 0.00101 (0.00133)	Tok/s 66766 (74127)	Loss/tok 3.8264 (4.5862)	Learning Rate [0.00125]
0: TRAIN [0][3010/6832]	Time 0.239 (0.346)	Data 0.00105 (0.00133)	Tok/s 72696 (74124)	Loss/tok 3.5845 (4.5837)	Learning Rate [0.00125]
0: TRAIN [0][3020/6832]	Time 0.219 (0.346)	Data 0.00146 (0.00133)	Tok/s 72506 (74151)	Loss/tok 3.4258 (4.5804)	Learning Rate [0.00125]
0: TRAIN [0][3030/6832]	Time 0.419 (0.347)	Data 0.00106 (0.00133)	Tok/s 68061 (74158)	Loss/tok 3.8069 (4.5767)	Learning Rate [0.00125]
0: TRAIN [0][3040/6832]	Time 0.345 (0.346)	Data 0.00109 (0.00132)	Tok/s 69833 (74154)	Loss/tok 3.6407 (4.5743)	Learning Rate [0.00125]
0: TRAIN [0][3050/6832]	Time 0.263 (0.346)	Data 0.00104 (0.00132)	Tok/s 74397 (74159)	Loss/tok 3.6469 (4.5714)	Learning Rate [0.00125]
0: TRAIN [0][3060/6832]	Time 0.425 (0.346)	Data 0.00100 (0.00132)	Tok/s 65977 (74163)	Loss/tok 3.7720 (4.5686)	Learning Rate [0.00125]
0: TRAIN [0][3070/6832]	Time 0.481 (0.347)	Data 0.00102 (0.00132)	Tok/s 70207 (74176)	Loss/tok 3.8435 (4.5654)	Learning Rate [0.00125]
0: TRAIN [0][3080/6832]	Time 0.296 (0.347)	Data 0.00108 (0.00132)	Tok/s 72136 (74177)	Loss/tok 3.6215 (4.5626)	Learning Rate [0.00125]
0: TRAIN [0][3090/6832]	Time 0.474 (0.347)	Data 0.00106 (0.00132)	Tok/s 72332 (74180)	Loss/tok 3.7942 (4.5599)	Learning Rate [0.00125]
0: TRAIN [0][3100/6832]	Time 0.477 (0.347)	Data 0.00109 (0.00132)	Tok/s 71683 (74178)	Loss/tok 3.8512 (4.5573)	Learning Rate [0.00125]
0: TRAIN [0][3110/6832]	Time 0.481 (0.347)	Data 0.00100 (0.00132)	Tok/s 77259 (74173)	Loss/tok 3.8783 (4.5547)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][3120/6832]	Time 0.477 (0.347)	Data 0.00100 (0.00132)	Tok/s 65027 (74161)	Loss/tok 3.9013 (4.5524)	Learning Rate [0.00125]
0: TRAIN [0][3130/6832]	Time 0.470 (0.347)	Data 0.00098 (0.00132)	Tok/s 69715 (74158)	Loss/tok 3.8049 (4.5496)	Learning Rate [0.00125]
0: TRAIN [0][3140/6832]	Time 0.465 (0.347)	Data 0.00101 (0.00132)	Tok/s 84090 (74162)	Loss/tok 3.8043 (4.5468)	Learning Rate [0.00125]
0: TRAIN [0][3150/6832]	Time 0.302 (0.347)	Data 0.00104 (0.00132)	Tok/s 69611 (74164)	Loss/tok 3.7187 (4.5441)	Learning Rate [0.00125]
0: TRAIN [0][3160/6832]	Time 0.456 (0.347)	Data 0.00104 (0.00131)	Tok/s 66629 (74158)	Loss/tok 3.7904 (4.5418)	Learning Rate [0.00125]
0: TRAIN [0][3170/6832]	Time 0.481 (0.346)	Data 0.00104 (0.00131)	Tok/s 87659 (74165)	Loss/tok 3.8057 (4.5393)	Learning Rate [0.00125]
0: TRAIN [0][3180/6832]	Time 0.476 (0.347)	Data 0.00100 (0.00131)	Tok/s 75262 (74161)	Loss/tok 3.8612 (4.5367)	Learning Rate [0.00125]
0: TRAIN [0][3190/6832]	Time 0.464 (0.347)	Data 0.00101 (0.00131)	Tok/s 82672 (74163)	Loss/tok 3.8519 (4.5339)	Learning Rate [0.00125]
0: TRAIN [0][3200/6832]	Time 0.381 (0.347)	Data 0.00099 (0.00131)	Tok/s 65882 (74156)	Loss/tok 3.8283 (4.5316)	Learning Rate [0.00125]
0: TRAIN [0][3210/6832]	Time 0.488 (0.347)	Data 0.00103 (0.00131)	Tok/s 95357 (74167)	Loss/tok 3.6424 (4.5288)	Learning Rate [0.00125]
0: TRAIN [0][3220/6832]	Time 0.368 (0.347)	Data 0.00102 (0.00131)	Tok/s 71052 (74173)	Loss/tok 3.7785 (4.5261)	Learning Rate [0.00125]
0: TRAIN [0][3230/6832]	Time 0.464 (0.347)	Data 0.00098 (0.00131)	Tok/s 95113 (74189)	Loss/tok 3.7038 (4.5232)	Learning Rate [0.00125]
0: TRAIN [0][3240/6832]	Time 0.356 (0.347)	Data 0.00104 (0.00131)	Tok/s 69040 (74194)	Loss/tok 3.6850 (4.5205)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][3250/6832]	Time 0.274 (0.347)	Data 0.00107 (0.00131)	Tok/s 71051 (74187)	Loss/tok 3.4215 (4.5182)	Learning Rate [0.00125]
0: TRAIN [0][3260/6832]	Time 0.210 (0.347)	Data 0.00104 (0.00131)	Tok/s 73804 (74194)	Loss/tok 3.3866 (4.5154)	Learning Rate [0.00125]
0: TRAIN [0][3270/6832]	Time 0.451 (0.347)	Data 0.00105 (0.00131)	Tok/s 65734 (74184)	Loss/tok 3.7656 (4.5128)	Learning Rate [0.00125]
0: TRAIN [0][3280/6832]	Time 0.338 (0.347)	Data 0.00111 (0.00131)	Tok/s 71201 (74184)	Loss/tok 3.6982 (4.5106)	Learning Rate [0.00125]
0: TRAIN [0][3290/6832]	Time 0.176 (0.347)	Data 0.00110 (0.00131)	Tok/s 78774 (74182)	Loss/tok 3.2956 (4.5082)	Learning Rate [0.00125]
0: TRAIN [0][3300/6832]	Time 0.133 (0.346)	Data 0.00100 (0.00130)	Tok/s 79188 (74182)	Loss/tok 2.9641 (4.5059)	Learning Rate [0.00125]
0: TRAIN [0][3310/6832]	Time 0.478 (0.347)	Data 0.00101 (0.00130)	Tok/s 67674 (74185)	Loss/tok 3.7766 (4.5033)	Learning Rate [0.00125]
0: TRAIN [0][3320/6832]	Time 0.346 (0.347)	Data 0.00106 (0.00130)	Tok/s 68043 (74179)	Loss/tok 3.6571 (4.5008)	Learning Rate [0.00125]
0: TRAIN [0][3330/6832]	Time 0.205 (0.346)	Data 0.00103 (0.00130)	Tok/s 73767 (74176)	Loss/tok 3.5188 (4.4990)	Learning Rate [0.00125]
0: TRAIN [0][3340/6832]	Time 0.217 (0.346)	Data 0.00124 (0.00130)	Tok/s 75373 (74186)	Loss/tok 3.4480 (4.4964)	Learning Rate [0.00125]
0: TRAIN [0][3350/6832]	Time 0.196 (0.346)	Data 0.00104 (0.00130)	Tok/s 75613 (74180)	Loss/tok 3.3402 (4.4942)	Learning Rate [0.00125]
0: TRAIN [0][3360/6832]	Time 0.279 (0.346)	Data 0.00099 (0.00130)	Tok/s 71522 (74174)	Loss/tok 3.6212 (4.4920)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][3370/6832]	Time 0.378 (0.346)	Data 0.00111 (0.00130)	Tok/s 68710 (74168)	Loss/tok 3.8507 (4.4897)	Learning Rate [0.00125]
0: TRAIN [0][3380/6832]	Time 0.310 (0.346)	Data 0.00108 (0.00130)	Tok/s 72263 (74158)	Loss/tok 3.5854 (4.4873)	Learning Rate [0.00125]
0: TRAIN [0][3390/6832]	Time 0.480 (0.346)	Data 0.00097 (0.00130)	Tok/s 72724 (74145)	Loss/tok 3.8320 (4.4853)	Learning Rate [0.00125]
0: TRAIN [0][3400/6832]	Time 0.274 (0.346)	Data 0.00106 (0.00130)	Tok/s 72650 (74142)	Loss/tok 3.6357 (4.4833)	Learning Rate [0.00125]
0: TRAIN [0][3410/6832]	Time 0.456 (0.346)	Data 0.00106 (0.00130)	Tok/s 68970 (74143)	Loss/tok 3.9130 (4.4809)	Learning Rate [0.00125]
0: TRAIN [0][3420/6832]	Time 0.244 (0.346)	Data 0.00098 (0.00130)	Tok/s 73452 (74151)	Loss/tok 3.4637 (4.4783)	Learning Rate [0.00125]
0: TRAIN [0][3430/6832]	Time 0.099 (0.346)	Data 0.00102 (0.00130)	Tok/s 57989 (74150)	Loss/tok 2.3779 (4.4761)	Learning Rate [0.00125]
0: TRAIN [0][3440/6832]	Time 0.259 (0.346)	Data 0.00103 (0.00129)	Tok/s 73189 (74149)	Loss/tok 3.5736 (4.4737)	Learning Rate [0.00125]
0: TRAIN [0][3450/6832]	Time 0.203 (0.346)	Data 0.00101 (0.00129)	Tok/s 74871 (74157)	Loss/tok 3.5067 (4.4712)	Learning Rate [0.00125]
0: TRAIN [0][3460/6832]	Time 0.308 (0.346)	Data 0.00104 (0.00129)	Tok/s 69965 (74155)	Loss/tok 3.6043 (4.4689)	Learning Rate [0.00125]
0: TRAIN [0][3470/6832]	Time 0.354 (0.346)	Data 0.00112 (0.00129)	Tok/s 67960 (74157)	Loss/tok 3.7360 (4.4662)	Learning Rate [0.00125]
0: TRAIN [0][3480/6832]	Time 0.464 (0.346)	Data 0.00105 (0.00129)	Tok/s 73187 (74154)	Loss/tok 3.7413 (4.4639)	Learning Rate [0.00125]
0: TRAIN [0][3490/6832]	Time 0.416 (0.346)	Data 0.00105 (0.00129)	Tok/s 68202 (74144)	Loss/tok 3.8121 (4.4618)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][3500/6832]	Time 0.480 (0.346)	Data 0.00103 (0.00129)	Tok/s 78591 (74145)	Loss/tok 3.7980 (4.4595)	Learning Rate [0.00125]
0: TRAIN [0][3510/6832]	Time 0.096 (0.346)	Data 0.00105 (0.00129)	Tok/s 61964 (74142)	Loss/tok 2.3296 (4.4574)	Learning Rate [0.00125]
0: TRAIN [0][3520/6832]	Time 0.263 (0.346)	Data 0.00105 (0.00129)	Tok/s 74418 (74132)	Loss/tok 3.4549 (4.4554)	Learning Rate [0.00125]
0: TRAIN [0][3530/6832]	Time 0.461 (0.346)	Data 0.00112 (0.00129)	Tok/s 66575 (74131)	Loss/tok 3.7530 (4.4531)	Learning Rate [0.00125]
0: TRAIN [0][3540/6832]	Time 0.474 (0.346)	Data 0.00106 (0.00129)	Tok/s 64450 (74131)	Loss/tok 3.7810 (4.4511)	Learning Rate [0.00125]
0: TRAIN [0][3550/6832]	Time 0.230 (0.346)	Data 0.00104 (0.00129)	Tok/s 73104 (74129)	Loss/tok 3.4273 (4.4490)	Learning Rate [0.00125]
0: TRAIN [0][3560/6832]	Time 0.448 (0.346)	Data 0.00113 (0.00129)	Tok/s 70180 (74129)	Loss/tok 3.7986 (4.4468)	Learning Rate [0.00125]
0: TRAIN [0][3570/6832]	Time 0.343 (0.346)	Data 0.00107 (0.00129)	Tok/s 68997 (74127)	Loss/tok 3.6503 (4.4446)	Learning Rate [0.00125]
0: TRAIN [0][3580/6832]	Time 0.412 (0.346)	Data 0.00107 (0.00129)	Tok/s 72186 (74133)	Loss/tok 3.7363 (4.4422)	Learning Rate [0.00125]
0: TRAIN [0][3590/6832]	Time 0.482 (0.346)	Data 0.00104 (0.00129)	Tok/s 69889 (74129)	Loss/tok 3.8065 (4.4399)	Learning Rate [0.00125]
0: TRAIN [0][3600/6832]	Time 0.458 (0.346)	Data 0.00100 (0.00128)	Tok/s 66842 (74132)	Loss/tok 3.8254 (4.4375)	Learning Rate [0.00125]
0: TRAIN [0][3610/6832]	Time 0.478 (0.347)	Data 0.00105 (0.00128)	Tok/s 78874 (74129)	Loss/tok 3.7939 (4.4353)	Learning Rate [0.00125]
0: TRAIN [0][3620/6832]	Time 0.377 (0.347)	Data 0.00102 (0.00128)	Tok/s 69533 (74122)	Loss/tok 3.7003 (4.4332)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][3630/6832]	Time 0.407 (0.347)	Data 0.00106 (0.00128)	Tok/s 68104 (74122)	Loss/tok 3.6955 (4.4310)	Learning Rate [0.00125]
0: TRAIN [0][3640/6832]	Time 0.157 (0.347)	Data 0.00105 (0.00128)	Tok/s 79171 (74122)	Loss/tok 3.1977 (4.4289)	Learning Rate [0.00125]
0: TRAIN [0][3650/6832]	Time 0.474 (0.347)	Data 0.00105 (0.00128)	Tok/s 71198 (74122)	Loss/tok 3.7981 (4.4268)	Learning Rate [0.00125]
0: TRAIN [0][3660/6832]	Time 0.481 (0.347)	Data 0.00108 (0.00128)	Tok/s 71229 (74128)	Loss/tok 3.7516 (4.4244)	Learning Rate [0.00125]
0: TRAIN [0][3670/6832]	Time 0.483 (0.347)	Data 0.00100 (0.00128)	Tok/s 79284 (74130)	Loss/tok 3.7969 (4.4222)	Learning Rate [0.00125]
0: TRAIN [0][3680/6832]	Time 0.148 (0.347)	Data 0.00145 (0.00128)	Tok/s 80172 (74141)	Loss/tok 3.1435 (4.4201)	Learning Rate [0.00125]
0: TRAIN [0][3690/6832]	Time 0.152 (0.347)	Data 0.00103 (0.00128)	Tok/s 74665 (74134)	Loss/tok 3.0301 (4.4184)	Learning Rate [0.00125]
0: TRAIN [0][3700/6832]	Time 0.469 (0.346)	Data 0.00109 (0.00128)	Tok/s 68902 (74133)	Loss/tok 3.7793 (4.4166)	Learning Rate [0.00125]
0: TRAIN [0][3710/6832]	Time 0.459 (0.346)	Data 0.00102 (0.00128)	Tok/s 101588 (74137)	Loss/tok 3.5903 (4.4145)	Learning Rate [0.00125]
0: TRAIN [0][3720/6832]	Time 0.180 (0.346)	Data 0.00105 (0.00128)	Tok/s 79525 (74136)	Loss/tok 3.3532 (4.4126)	Learning Rate [0.00125]
0: TRAIN [0][3730/6832]	Time 0.485 (0.346)	Data 0.00110 (0.00128)	Tok/s 80414 (74142)	Loss/tok 3.7845 (4.4105)	Learning Rate [0.00125]
0: TRAIN [0][3740/6832]	Time 0.245 (0.346)	Data 0.00104 (0.00128)	Tok/s 74891 (74142)	Loss/tok 3.5273 (4.4085)	Learning Rate [0.00125]
0: TRAIN [0][3750/6832]	Time 0.242 (0.346)	Data 0.00103 (0.00128)	Tok/s 71311 (74141)	Loss/tok 3.5069 (4.4064)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][3760/6832]	Time 0.172 (0.346)	Data 0.00104 (0.00128)	Tok/s 78101 (74149)	Loss/tok 3.2256 (4.4039)	Learning Rate [0.00125]
0: TRAIN [0][3770/6832]	Time 0.347 (0.346)	Data 0.00101 (0.00128)	Tok/s 72339 (74150)	Loss/tok 3.6359 (4.4021)	Learning Rate [0.00125]
0: TRAIN [0][3780/6832]	Time 0.371 (0.346)	Data 0.00101 (0.00127)	Tok/s 66772 (74144)	Loss/tok 3.6737 (4.4004)	Learning Rate [0.00125]
0: TRAIN [0][3790/6832]	Time 0.484 (0.346)	Data 0.00099 (0.00127)	Tok/s 76699 (74151)	Loss/tok 3.7312 (4.3984)	Learning Rate [0.00125]
0: TRAIN [0][3800/6832]	Time 0.382 (0.346)	Data 0.00107 (0.00127)	Tok/s 67588 (74141)	Loss/tok 3.7255 (4.3966)	Learning Rate [0.00125]
0: TRAIN [0][3810/6832]	Time 0.449 (0.346)	Data 0.00104 (0.00127)	Tok/s 67336 (74135)	Loss/tok 3.7811 (4.3948)	Learning Rate [0.00125]
0: TRAIN [0][3820/6832]	Time 0.244 (0.346)	Data 0.00105 (0.00127)	Tok/s 71812 (74136)	Loss/tok 3.4984 (4.3930)	Learning Rate [0.00125]
0: TRAIN [0][3830/6832]	Time 0.270 (0.346)	Data 0.00106 (0.00127)	Tok/s 71164 (74136)	Loss/tok 3.5238 (4.3911)	Learning Rate [0.00125]
0: TRAIN [0][3840/6832]	Time 0.471 (0.346)	Data 0.00102 (0.00127)	Tok/s 67537 (74126)	Loss/tok 3.8519 (4.3894)	Learning Rate [0.00125]
0: TRAIN [0][3850/6832]	Time 0.477 (0.346)	Data 0.00107 (0.00127)	Tok/s 71768 (74125)	Loss/tok 3.7708 (4.3874)	Learning Rate [0.00125]
0: TRAIN [0][3860/6832]	Time 0.253 (0.346)	Data 0.00100 (0.00127)	Tok/s 72031 (74139)	Loss/tok 3.4874 (4.3851)	Learning Rate [0.00125]
0: TRAIN [0][3870/6832]	Time 0.465 (0.346)	Data 0.00104 (0.00127)	Tok/s 67384 (74137)	Loss/tok 3.7192 (4.3832)	Learning Rate [0.00125]
0: TRAIN [0][3880/6832]	Time 0.478 (0.346)	Data 0.00101 (0.00127)	Tok/s 68718 (74130)	Loss/tok 3.8649 (4.3815)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][3890/6832]	Time 0.276 (0.346)	Data 0.00105 (0.00127)	Tok/s 70904 (74128)	Loss/tok 3.5280 (4.3799)	Learning Rate [0.00125]
0: TRAIN [0][3900/6832]	Time 0.335 (0.346)	Data 0.00101 (0.00127)	Tok/s 69496 (74124)	Loss/tok 3.6364 (4.3781)	Learning Rate [0.00125]
0: TRAIN [0][3910/6832]	Time 0.147 (0.346)	Data 0.00108 (0.00127)	Tok/s 76842 (74123)	Loss/tok 2.9904 (4.3764)	Learning Rate [0.00125]
0: TRAIN [0][3920/6832]	Time 0.490 (0.346)	Data 0.00104 (0.00127)	Tok/s 76110 (74128)	Loss/tok 3.7828 (4.3746)	Learning Rate [0.00125]
0: TRAIN [0][3930/6832]	Time 0.220 (0.346)	Data 0.00104 (0.00127)	Tok/s 74540 (74121)	Loss/tok 3.3439 (4.3726)	Learning Rate [0.00125]
0: TRAIN [0][3940/6832]	Time 0.480 (0.346)	Data 0.00102 (0.00127)	Tok/s 97039 (74132)	Loss/tok 3.4811 (4.3704)	Learning Rate [0.00125]
0: TRAIN [0][3950/6832]	Time 0.208 (0.346)	Data 0.00107 (0.00127)	Tok/s 75366 (74140)	Loss/tok 3.4367 (4.3684)	Learning Rate [0.00125]
0: TRAIN [0][3960/6832]	Time 0.366 (0.346)	Data 0.00102 (0.00127)	Tok/s 68477 (74145)	Loss/tok 3.7325 (4.3665)	Learning Rate [0.00125]
0: TRAIN [0][3970/6832]	Time 0.482 (0.346)	Data 0.00136 (0.00127)	Tok/s 78166 (74140)	Loss/tok 3.7802 (4.3648)	Learning Rate [0.00125]
0: TRAIN [0][3980/6832]	Time 0.478 (0.346)	Data 0.00109 (0.00127)	Tok/s 64051 (74132)	Loss/tok 3.7666 (4.3630)	Learning Rate [0.00125]
0: TRAIN [0][3990/6832]	Time 0.272 (0.346)	Data 0.00111 (0.00126)	Tok/s 70637 (74125)	Loss/tok 3.5407 (4.3613)	Learning Rate [0.00125]
0: TRAIN [0][4000/6832]	Time 0.423 (0.346)	Data 0.00109 (0.00126)	Tok/s 65359 (74119)	Loss/tok 3.6734 (4.3594)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4010/6832]	Time 0.480 (0.346)	Data 0.00108 (0.00126)	Tok/s 77209 (74123)	Loss/tok 3.6998 (4.3574)	Learning Rate [0.00125]
0: TRAIN [0][4020/6832]	Time 0.354 (0.346)	Data 0.00112 (0.00126)	Tok/s 65935 (74118)	Loss/tok 3.6159 (4.3557)	Learning Rate [0.00125]
0: TRAIN [0][4030/6832]	Time 0.464 (0.346)	Data 0.00103 (0.00126)	Tok/s 77065 (74117)	Loss/tok 3.7326 (4.3537)	Learning Rate [0.00125]
0: TRAIN [0][4040/6832]	Time 0.462 (0.346)	Data 0.00103 (0.00126)	Tok/s 69846 (74121)	Loss/tok 3.8470 (4.3517)	Learning Rate [0.00125]
0: TRAIN [0][4050/6832]	Time 0.200 (0.346)	Data 0.00108 (0.00126)	Tok/s 76217 (74118)	Loss/tok 3.3976 (4.3503)	Learning Rate [0.00125]
0: TRAIN [0][4060/6832]	Time 0.458 (0.346)	Data 0.00114 (0.00126)	Tok/s 71599 (74112)	Loss/tok 3.7628 (4.3484)	Learning Rate [0.00125]
0: TRAIN [0][4070/6832]	Time 0.472 (0.346)	Data 0.00103 (0.00126)	Tok/s 66009 (74108)	Loss/tok 3.7813 (4.3468)	Learning Rate [0.00125]
0: TRAIN [0][4080/6832]	Time 0.323 (0.346)	Data 0.00022 (0.00126)	Tok/s 71311 (74103)	Loss/tok 3.6238 (4.3451)	Learning Rate [0.00125]
0: TRAIN [0][4090/6832]	Time 0.469 (0.346)	Data 0.00102 (0.00126)	Tok/s 64339 (74104)	Loss/tok 3.8475 (4.3435)	Learning Rate [0.00125]
0: TRAIN [0][4100/6832]	Time 0.480 (0.346)	Data 0.00102 (0.00126)	Tok/s 66467 (74094)	Loss/tok 3.8025 (4.3419)	Learning Rate [0.00125]
0: TRAIN [0][4110/6832]	Time 0.266 (0.346)	Data 0.00101 (0.00126)	Tok/s 75010 (74090)	Loss/tok 3.4273 (4.3401)	Learning Rate [0.00125]
0: TRAIN [0][4120/6832]	Time 0.486 (0.346)	Data 0.00104 (0.00126)	Tok/s 68763 (74092)	Loss/tok 3.7940 (4.3382)	Learning Rate [0.00125]
0: TRAIN [0][4130/6832]	Time 0.327 (0.346)	Data 0.00107 (0.00126)	Tok/s 70445 (74085)	Loss/tok 3.5235 (4.3366)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4140/6832]	Time 0.482 (0.346)	Data 0.00127 (0.00126)	Tok/s 71157 (74079)	Loss/tok 3.8326 (4.3351)	Learning Rate [0.00125]
0: TRAIN [0][4150/6832]	Time 0.377 (0.346)	Data 0.00111 (0.00126)	Tok/s 67655 (74073)	Loss/tok 3.6650 (4.3336)	Learning Rate [0.00125]
0: TRAIN [0][4160/6832]	Time 0.142 (0.346)	Data 0.00111 (0.00126)	Tok/s 83598 (74070)	Loss/tok 3.1439 (4.3319)	Learning Rate [0.00125]
0: TRAIN [0][4170/6832]	Time 0.140 (0.346)	Data 0.00106 (0.00126)	Tok/s 80764 (74066)	Loss/tok 3.0922 (4.3303)	Learning Rate [0.00125]
0: TRAIN [0][4180/6832]	Time 0.140 (0.346)	Data 0.00108 (0.00126)	Tok/s 80752 (74067)	Loss/tok 2.9708 (4.3286)	Learning Rate [0.00125]
0: TRAIN [0][4190/6832]	Time 0.229 (0.346)	Data 0.00130 (0.00126)	Tok/s 73112 (74065)	Loss/tok 3.3457 (4.3269)	Learning Rate [0.00125]
0: TRAIN [0][4200/6832]	Time 0.233 (0.346)	Data 0.00105 (0.00126)	Tok/s 74553 (74064)	Loss/tok 3.4026 (4.3252)	Learning Rate [0.00125]
0: TRAIN [0][4210/6832]	Time 0.453 (0.346)	Data 0.00103 (0.00125)	Tok/s 68270 (74057)	Loss/tok 3.6819 (4.3237)	Learning Rate [0.00125]
0: TRAIN [0][4220/6832]	Time 0.483 (0.346)	Data 0.00106 (0.00125)	Tok/s 65990 (74050)	Loss/tok 3.7291 (4.3222)	Learning Rate [0.00125]
0: TRAIN [0][4230/6832]	Time 0.483 (0.346)	Data 0.00109 (0.00125)	Tok/s 87373 (74053)	Loss/tok 3.7066 (4.3204)	Learning Rate [0.00125]
0: TRAIN [0][4240/6832]	Time 0.298 (0.346)	Data 0.00107 (0.00125)	Tok/s 72405 (74052)	Loss/tok 3.6100 (4.3187)	Learning Rate [0.00125]
0: TRAIN [0][4250/6832]	Time 0.195 (0.346)	Data 0.00099 (0.00125)	Tok/s 76167 (74046)	Loss/tok 3.4067 (4.3173)	Learning Rate [0.00125]
0: TRAIN [0][4260/6832]	Time 0.466 (0.346)	Data 0.00100 (0.00125)	Tok/s 77942 (74044)	Loss/tok 3.7586 (4.3158)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4270/6832]	Time 0.429 (0.346)	Data 0.00104 (0.00125)	Tok/s 66346 (74043)	Loss/tok 3.7227 (4.3140)	Learning Rate [0.00125]
0: TRAIN [0][4280/6832]	Time 0.199 (0.346)	Data 0.00101 (0.00125)	Tok/s 76082 (74041)	Loss/tok 3.2904 (4.3126)	Learning Rate [0.00125]
0: TRAIN [0][4290/6832]	Time 0.414 (0.346)	Data 0.00104 (0.00125)	Tok/s 66055 (74038)	Loss/tok 3.5924 (4.3109)	Learning Rate [0.00125]
0: TRAIN [0][4300/6832]	Time 0.449 (0.346)	Data 0.00102 (0.00125)	Tok/s 68064 (74034)	Loss/tok 3.7078 (4.3092)	Learning Rate [0.00125]
0: TRAIN [0][4310/6832]	Time 0.320 (0.346)	Data 0.00108 (0.00125)	Tok/s 70789 (74028)	Loss/tok 3.5241 (4.3076)	Learning Rate [0.00125]
0: TRAIN [0][4320/6832]	Time 0.487 (0.347)	Data 0.00113 (0.00125)	Tok/s 85070 (74036)	Loss/tok 3.6497 (4.3057)	Learning Rate [0.00125]
0: TRAIN [0][4330/6832]	Time 0.245 (0.346)	Data 0.00099 (0.00125)	Tok/s 73805 (74034)	Loss/tok 3.4344 (4.3043)	Learning Rate [0.00125]
0: TRAIN [0][4340/6832]	Time 0.313 (0.347)	Data 0.00133 (0.00125)	Tok/s 70388 (74031)	Loss/tok 3.5980 (4.3027)	Learning Rate [0.00125]
0: TRAIN [0][4350/6832]	Time 0.207 (0.347)	Data 0.00103 (0.00125)	Tok/s 75099 (74037)	Loss/tok 3.2562 (4.3010)	Learning Rate [0.00125]
0: TRAIN [0][4360/6832]	Time 0.117 (0.347)	Data 0.00103 (0.00125)	Tok/s 72167 (74036)	Loss/tok 2.6284 (4.2995)	Learning Rate [0.00125]
0: TRAIN [0][4370/6832]	Time 0.239 (0.346)	Data 0.00103 (0.00125)	Tok/s 72996 (74032)	Loss/tok 3.4568 (4.2980)	Learning Rate [0.00125]
0: TRAIN [0][4380/6832]	Time 0.488 (0.347)	Data 0.00109 (0.00125)	Tok/s 95405 (74041)	Loss/tok 3.4839 (4.2961)	Learning Rate [0.00125]
0: TRAIN [0][4390/6832]	Time 0.138 (0.347)	Data 0.00112 (0.00125)	Tok/s 76467 (74055)	Loss/tok 2.8340 (4.2942)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4400/6832]	Time 0.479 (0.347)	Data 0.00112 (0.00125)	Tok/s 65756 (74067)	Loss/tok 3.7421 (4.2924)	Learning Rate [0.00125]
0: TRAIN [0][4410/6832]	Time 0.219 (0.347)	Data 0.00103 (0.00125)	Tok/s 76963 (74070)	Loss/tok 3.4927 (4.2909)	Learning Rate [0.00125]
0: TRAIN [0][4420/6832]	Time 0.479 (0.346)	Data 0.00118 (0.00125)	Tok/s 68596 (74066)	Loss/tok 3.8111 (4.2896)	Learning Rate [0.00125]
0: TRAIN [0][4430/6832]	Time 0.383 (0.346)	Data 0.00102 (0.00125)	Tok/s 67627 (74069)	Loss/tok 3.5797 (4.2880)	Learning Rate [0.00125]
0: TRAIN [0][4440/6832]	Time 0.483 (0.346)	Data 0.00113 (0.00125)	Tok/s 91363 (74067)	Loss/tok 3.6218 (4.2864)	Learning Rate [0.00125]
0: TRAIN [0][4450/6832]	Time 0.484 (0.346)	Data 0.00102 (0.00124)	Tok/s 72922 (74074)	Loss/tok 3.7725 (4.2848)	Learning Rate [0.00125]
0: TRAIN [0][4460/6832]	Time 0.481 (0.346)	Data 0.00109 (0.00124)	Tok/s 70088 (74074)	Loss/tok 3.7145 (4.2832)	Learning Rate [0.00125]
0: TRAIN [0][4470/6832]	Time 0.482 (0.347)	Data 0.00107 (0.00124)	Tok/s 74484 (74078)	Loss/tok 3.7553 (4.2814)	Learning Rate [0.00125]
0: TRAIN [0][4480/6832]	Time 0.485 (0.346)	Data 0.00109 (0.00124)	Tok/s 80590 (74079)	Loss/tok 3.6212 (4.2801)	Learning Rate [0.00125]
0: TRAIN [0][4490/6832]	Time 0.165 (0.346)	Data 0.00108 (0.00124)	Tok/s 78731 (74096)	Loss/tok 3.1600 (4.2782)	Learning Rate [0.00125]
0: TRAIN [0][4500/6832]	Time 0.481 (0.346)	Data 0.00102 (0.00124)	Tok/s 75783 (74094)	Loss/tok 3.8632 (4.2768)	Learning Rate [0.00125]
0: TRAIN [0][4510/6832]	Time 0.166 (0.346)	Data 0.00105 (0.00124)	Tok/s 77970 (74096)	Loss/tok 3.2316 (4.2753)	Learning Rate [0.00125]
0: TRAIN [0][4520/6832]	Time 0.344 (0.346)	Data 0.00101 (0.00124)	Tok/s 68229 (74099)	Loss/tok 3.5028 (4.2738)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4530/6832]	Time 0.471 (0.346)	Data 0.00102 (0.00124)	Tok/s 64936 (74095)	Loss/tok 3.6211 (4.2724)	Learning Rate [0.00125]
0: TRAIN [0][4540/6832]	Time 0.258 (0.346)	Data 0.00100 (0.00124)	Tok/s 75527 (74102)	Loss/tok 3.4893 (4.2709)	Learning Rate [0.00125]
0: TRAIN [0][4550/6832]	Time 0.443 (0.346)	Data 0.00105 (0.00124)	Tok/s 66190 (74098)	Loss/tok 3.6671 (4.2694)	Learning Rate [0.00125]
0: TRAIN [0][4560/6832]	Time 0.401 (0.346)	Data 0.00100 (0.00124)	Tok/s 68023 (74094)	Loss/tok 3.6769 (4.2680)	Learning Rate [0.00125]
0: TRAIN [0][4570/6832]	Time 0.479 (0.346)	Data 0.00105 (0.00124)	Tok/s 76085 (74093)	Loss/tok 3.7048 (4.2667)	Learning Rate [0.00125]
0: TRAIN [0][4580/6832]	Time 0.373 (0.346)	Data 0.00100 (0.00124)	Tok/s 67238 (74090)	Loss/tok 3.6604 (4.2653)	Learning Rate [0.00125]
0: TRAIN [0][4590/6832]	Time 0.432 (0.346)	Data 0.00103 (0.00124)	Tok/s 66244 (74094)	Loss/tok 3.6797 (4.2636)	Learning Rate [0.00125]
0: TRAIN [0][4600/6832]	Time 0.321 (0.347)	Data 0.00122 (0.00124)	Tok/s 71817 (74098)	Loss/tok 3.5621 (4.2620)	Learning Rate [0.00125]
0: TRAIN [0][4610/6832]	Time 0.109 (0.346)	Data 0.00103 (0.00124)	Tok/s 77399 (74096)	Loss/tok 2.6227 (4.2607)	Learning Rate [0.00125]
0: TRAIN [0][4620/6832]	Time 0.201 (0.346)	Data 0.00098 (0.00124)	Tok/s 77969 (74092)	Loss/tok 3.3591 (4.2594)	Learning Rate [0.00125]
0: TRAIN [0][4630/6832]	Time 0.474 (0.346)	Data 0.00097 (0.00124)	Tok/s 75528 (74090)	Loss/tok 3.6616 (4.2579)	Learning Rate [0.00125]
0: TRAIN [0][4640/6832]	Time 0.486 (0.346)	Data 0.00099 (0.00124)	Tok/s 79972 (74091)	Loss/tok 3.6832 (4.2564)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4650/6832]	Time 0.453 (0.346)	Data 0.00108 (0.00124)	Tok/s 68716 (74095)	Loss/tok 3.7393 (4.2549)	Learning Rate [0.00125]
0: TRAIN [0][4660/6832]	Time 0.133 (0.346)	Data 0.00098 (0.00124)	Tok/s 84071 (74110)	Loss/tok 2.9582 (4.2532)	Learning Rate [0.00125]
0: TRAIN [0][4670/6832]	Time 0.430 (0.346)	Data 0.00100 (0.00124)	Tok/s 67067 (74107)	Loss/tok 3.6362 (4.2517)	Learning Rate [0.00125]
0: TRAIN [0][4680/6832]	Time 0.314 (0.346)	Data 0.00108 (0.00124)	Tok/s 71152 (74111)	Loss/tok 3.5835 (4.2503)	Learning Rate [0.00125]
0: TRAIN [0][4690/6832]	Time 0.228 (0.346)	Data 0.00103 (0.00124)	Tok/s 74782 (74109)	Loss/tok 3.3808 (4.2489)	Learning Rate [0.00125]
0: TRAIN [0][4700/6832]	Time 0.377 (0.346)	Data 0.00099 (0.00124)	Tok/s 69432 (74103)	Loss/tok 3.5239 (4.2476)	Learning Rate [0.00125]
0: TRAIN [0][4710/6832]	Time 0.304 (0.346)	Data 0.00100 (0.00124)	Tok/s 70138 (74104)	Loss/tok 3.4580 (4.2461)	Learning Rate [0.00125]
0: TRAIN [0][4720/6832]	Time 0.414 (0.346)	Data 0.00098 (0.00123)	Tok/s 68014 (74098)	Loss/tok 3.7652 (4.2449)	Learning Rate [0.00125]
0: TRAIN [0][4730/6832]	Time 0.258 (0.346)	Data 0.00099 (0.00123)	Tok/s 73271 (74096)	Loss/tok 3.4584 (4.2435)	Learning Rate [0.00125]
0: TRAIN [0][4740/6832]	Time 0.224 (0.346)	Data 0.00101 (0.00123)	Tok/s 76005 (74105)	Loss/tok 3.3675 (4.2419)	Learning Rate [0.00125]
0: TRAIN [0][4750/6832]	Time 0.477 (0.346)	Data 0.00114 (0.00123)	Tok/s 63012 (74110)	Loss/tok 3.7707 (4.2403)	Learning Rate [0.00125]
0: TRAIN [0][4760/6832]	Time 0.266 (0.346)	Data 0.00101 (0.00123)	Tok/s 75022 (74106)	Loss/tok 3.4312 (4.2390)	Learning Rate [0.00125]
0: TRAIN [0][4770/6832]	Time 0.310 (0.346)	Data 0.00102 (0.00123)	Tok/s 73059 (74107)	Loss/tok 3.5259 (4.2377)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4780/6832]	Time 0.471 (0.346)	Data 0.00102 (0.00123)	Tok/s 67784 (74105)	Loss/tok 3.6762 (4.2363)	Learning Rate [0.00125]
0: TRAIN [0][4790/6832]	Time 0.486 (0.347)	Data 0.00098 (0.00123)	Tok/s 88960 (74105)	Loss/tok 3.5810 (4.2348)	Learning Rate [0.00125]
0: TRAIN [0][4800/6832]	Time 0.215 (0.346)	Data 0.00107 (0.00123)	Tok/s 74140 (74100)	Loss/tok 3.3537 (4.2336)	Learning Rate [0.00125]
0: TRAIN [0][4810/6832]	Time 0.225 (0.346)	Data 0.00096 (0.00123)	Tok/s 72994 (74103)	Loss/tok 3.3707 (4.2324)	Learning Rate [0.00125]
0: TRAIN [0][4820/6832]	Time 0.247 (0.346)	Data 0.00102 (0.00123)	Tok/s 75099 (74101)	Loss/tok 3.3758 (4.2309)	Learning Rate [0.00125]
0: TRAIN [0][4830/6832]	Time 0.380 (0.346)	Data 0.00101 (0.00123)	Tok/s 69870 (74105)	Loss/tok 3.6632 (4.2294)	Learning Rate [0.00125]
0: TRAIN [0][4840/6832]	Time 0.295 (0.346)	Data 0.00102 (0.00123)	Tok/s 68538 (74102)	Loss/tok 3.4985 (4.2282)	Learning Rate [0.00125]
0: TRAIN [0][4850/6832]	Time 0.248 (0.346)	Data 0.00099 (0.00123)	Tok/s 72007 (74097)	Loss/tok 3.3605 (4.2269)	Learning Rate [0.00125]
0: TRAIN [0][4860/6832]	Time 0.390 (0.346)	Data 0.00096 (0.00123)	Tok/s 70429 (74095)	Loss/tok 3.6020 (4.2257)	Learning Rate [0.00125]
0: TRAIN [0][4870/6832]	Time 0.436 (0.346)	Data 0.00100 (0.00123)	Tok/s 65668 (74093)	Loss/tok 3.5963 (4.2243)	Learning Rate [0.00125]
0: TRAIN [0][4880/6832]	Time 0.465 (0.347)	Data 0.00099 (0.00123)	Tok/s 97200 (74099)	Loss/tok 3.5704 (4.2228)	Learning Rate [0.00125]
0: TRAIN [0][4890/6832]	Time 0.305 (0.347)	Data 0.00103 (0.00123)	Tok/s 73948 (74099)	Loss/tok 3.4715 (4.2214)	Learning Rate [0.00125]
0: TRAIN [0][4900/6832]	Time 0.474 (0.347)	Data 0.00100 (0.00123)	Tok/s 67425 (74096)	Loss/tok 3.7244 (4.2201)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][4910/6832]	Time 0.202 (0.347)	Data 0.00104 (0.00123)	Tok/s 74764 (74108)	Loss/tok 3.3015 (4.2186)	Learning Rate [0.00125]
0: TRAIN [0][4920/6832]	Time 0.317 (0.347)	Data 0.00104 (0.00123)	Tok/s 71465 (74105)	Loss/tok 3.5548 (4.2173)	Learning Rate [0.00125]
0: TRAIN [0][4930/6832]	Time 0.235 (0.346)	Data 0.00103 (0.00123)	Tok/s 73990 (74101)	Loss/tok 3.4423 (4.2160)	Learning Rate [0.00125]
0: TRAIN [0][4940/6832]	Time 0.466 (0.346)	Data 0.00106 (0.00123)	Tok/s 67726 (74101)	Loss/tok 3.7322 (4.2147)	Learning Rate [0.00125]
0: TRAIN [0][4950/6832]	Time 0.359 (0.346)	Data 0.00100 (0.00123)	Tok/s 68265 (74098)	Loss/tok 3.5692 (4.2135)	Learning Rate [0.00125]
0: TRAIN [0][4960/6832]	Time 0.225 (0.346)	Data 0.00104 (0.00123)	Tok/s 69133 (74094)	Loss/tok 3.3426 (4.2124)	Learning Rate [0.00125]
0: TRAIN [0][4970/6832]	Time 0.147 (0.346)	Data 0.00100 (0.00123)	Tok/s 80699 (74106)	Loss/tok 3.1228 (4.2109)	Learning Rate [0.00125]
0: TRAIN [0][4980/6832]	Time 0.113 (0.346)	Data 0.00101 (0.00123)	Tok/s 75433 (74110)	Loss/tok 2.6295 (4.2096)	Learning Rate [0.00125]
0: TRAIN [0][4990/6832]	Time 0.158 (0.346)	Data 0.00103 (0.00123)	Tok/s 78445 (74111)	Loss/tok 3.0657 (4.2082)	Learning Rate [0.00125]
0: TRAIN [0][5000/6832]	Time 0.293 (0.346)	Data 0.00140 (0.00123)	Tok/s 70345 (74105)	Loss/tok 3.5357 (4.2070)	Learning Rate [0.00125]
0: TRAIN [0][5010/6832]	Time 0.276 (0.346)	Data 0.00109 (0.00123)	Tok/s 73207 (74107)	Loss/tok 3.4970 (4.2057)	Learning Rate [0.00125]
0: TRAIN [0][5020/6832]	Time 0.382 (0.346)	Data 0.00100 (0.00123)	Tok/s 68403 (74101)	Loss/tok 3.6320 (4.2045)	Learning Rate [0.00125]
0: TRAIN [0][5030/6832]	Time 0.466 (0.346)	Data 0.00098 (0.00122)	Tok/s 85119 (74094)	Loss/tok 3.6006 (4.2033)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5040/6832]	Time 0.480 (0.346)	Data 0.00102 (0.00122)	Tok/s 94117 (74095)	Loss/tok 3.5410 (4.2020)	Learning Rate [0.00125]
0: TRAIN [0][5050/6832]	Time 0.318 (0.346)	Data 0.00100 (0.00122)	Tok/s 69171 (74093)	Loss/tok 3.5375 (4.2008)	Learning Rate [0.00125]
0: TRAIN [0][5060/6832]	Time 0.335 (0.346)	Data 0.00096 (0.00122)	Tok/s 70929 (74088)	Loss/tok 3.5398 (4.1996)	Learning Rate [0.00125]
0: TRAIN [0][5070/6832]	Time 0.341 (0.346)	Data 0.00103 (0.00122)	Tok/s 69085 (74082)	Loss/tok 3.5748 (4.1985)	Learning Rate [0.00125]
0: TRAIN [0][5080/6832]	Time 0.482 (0.346)	Data 0.00096 (0.00122)	Tok/s 79506 (74082)	Loss/tok 3.6103 (4.1971)	Learning Rate [0.00125]
0: TRAIN [0][5090/6832]	Time 0.416 (0.346)	Data 0.00099 (0.00122)	Tok/s 66443 (74078)	Loss/tok 3.5594 (4.1959)	Learning Rate [0.00125]
0: TRAIN [0][5100/6832]	Time 0.347 (0.346)	Data 0.00097 (0.00122)	Tok/s 69417 (74076)	Loss/tok 3.5235 (4.1947)	Learning Rate [0.00125]
0: TRAIN [0][5110/6832]	Time 0.301 (0.346)	Data 0.00103 (0.00122)	Tok/s 72753 (74080)	Loss/tok 3.6011 (4.1937)	Learning Rate [0.00125]
0: TRAIN [0][5120/6832]	Time 0.482 (0.346)	Data 0.00102 (0.00122)	Tok/s 96473 (74081)	Loss/tok 3.5351 (4.1924)	Learning Rate [0.00125]
0: TRAIN [0][5130/6832]	Time 0.482 (0.346)	Data 0.00105 (0.00122)	Tok/s 82282 (74080)	Loss/tok 3.6076 (4.1911)	Learning Rate [0.00125]
0: TRAIN [0][5140/6832]	Time 0.483 (0.346)	Data 0.00107 (0.00122)	Tok/s 69876 (74073)	Loss/tok 3.6770 (4.1900)	Learning Rate [0.00125]
0: TRAIN [0][5150/6832]	Time 0.485 (0.346)	Data 0.00109 (0.00122)	Tok/s 80558 (74071)	Loss/tok 3.6918 (4.1887)	Learning Rate [0.00125]
0: TRAIN [0][5160/6832]	Time 0.396 (0.346)	Data 0.00098 (0.00122)	Tok/s 69867 (74070)	Loss/tok 3.7773 (4.1874)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5170/6832]	Time 0.257 (0.346)	Data 0.00099 (0.00122)	Tok/s 74918 (74076)	Loss/tok 3.4563 (4.1861)	Learning Rate [0.00125]
0: TRAIN [0][5180/6832]	Time 0.484 (0.346)	Data 0.00098 (0.00122)	Tok/s 77720 (74083)	Loss/tok 3.6989 (4.1847)	Learning Rate [0.00125]
0: TRAIN [0][5190/6832]	Time 0.103 (0.346)	Data 0.00099 (0.00122)	Tok/s 56431 (74085)	Loss/tok 2.2406 (4.1835)	Learning Rate [0.00125]
0: TRAIN [0][5200/6832]	Time 0.117 (0.346)	Data 0.00102 (0.00122)	Tok/s 82064 (74095)	Loss/tok 2.8441 (4.1822)	Learning Rate [0.00125]
0: TRAIN [0][5210/6832]	Time 0.457 (0.346)	Data 0.00107 (0.00122)	Tok/s 64983 (74088)	Loss/tok 3.7139 (4.1812)	Learning Rate [0.00125]
0: TRAIN [0][5220/6832]	Time 0.481 (0.346)	Data 0.00106 (0.00122)	Tok/s 101233 (74090)	Loss/tok 3.3312 (4.1798)	Learning Rate [0.00125]
0: TRAIN [0][5230/6832]	Time 0.185 (0.346)	Data 0.00174 (0.00122)	Tok/s 77540 (74088)	Loss/tok 3.1974 (4.1786)	Learning Rate [0.00125]
0: TRAIN [0][5240/6832]	Time 0.432 (0.346)	Data 0.00098 (0.00122)	Tok/s 65901 (74089)	Loss/tok 3.5548 (4.1774)	Learning Rate [0.00125]
0: TRAIN [0][5250/6832]	Time 0.363 (0.346)	Data 0.00104 (0.00122)	Tok/s 67445 (74089)	Loss/tok 3.5963 (4.1761)	Learning Rate [0.00125]
0: TRAIN [0][5260/6832]	Time 0.397 (0.346)	Data 0.00097 (0.00122)	Tok/s 67870 (74089)	Loss/tok 3.6459 (4.1749)	Learning Rate [0.00125]
0: TRAIN [0][5270/6832]	Time 0.283 (0.346)	Data 0.00095 (0.00122)	Tok/s 70547 (74095)	Loss/tok 3.5125 (4.1736)	Learning Rate [0.00125]
0: TRAIN [0][5280/6832]	Time 0.479 (0.346)	Data 0.00122 (0.00122)	Tok/s 76238 (74089)	Loss/tok 3.7132 (4.1726)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5290/6832]	Time 0.326 (0.346)	Data 0.00113 (0.00122)	Tok/s 73200 (74088)	Loss/tok 3.5607 (4.1713)	Learning Rate [0.00125]
0: TRAIN [0][5300/6832]	Time 0.234 (0.346)	Data 0.00101 (0.00122)	Tok/s 74396 (74095)	Loss/tok 3.4744 (4.1701)	Learning Rate [0.00125]
0: TRAIN [0][5310/6832]	Time 0.185 (0.346)	Data 0.00098 (0.00122)	Tok/s 77698 (74102)	Loss/tok 3.1761 (4.1687)	Learning Rate [0.00125]
0: TRAIN [0][5320/6832]	Time 0.293 (0.346)	Data 0.00105 (0.00122)	Tok/s 69236 (74098)	Loss/tok 3.4522 (4.1676)	Learning Rate [0.00125]
0: TRAIN [0][5330/6832]	Time 0.486 (0.346)	Data 0.00104 (0.00122)	Tok/s 99813 (74109)	Loss/tok 3.3967 (4.1663)	Learning Rate [0.00125]
0: TRAIN [0][5340/6832]	Time 0.240 (0.346)	Data 0.00099 (0.00121)	Tok/s 70371 (74111)	Loss/tok 3.3383 (4.1651)	Learning Rate [0.00125]
0: TRAIN [0][5350/6832]	Time 0.322 (0.346)	Data 0.00098 (0.00121)	Tok/s 73582 (74112)	Loss/tok 3.5351 (4.1641)	Learning Rate [0.00125]
0: TRAIN [0][5360/6832]	Time 0.432 (0.346)	Data 0.00106 (0.00121)	Tok/s 66042 (74109)	Loss/tok 3.7186 (4.1630)	Learning Rate [0.00125]
0: TRAIN [0][5370/6832]	Time 0.462 (0.346)	Data 0.00109 (0.00121)	Tok/s 105353 (74114)	Loss/tok 3.3888 (4.1617)	Learning Rate [0.00125]
0: TRAIN [0][5380/6832]	Time 0.481 (0.346)	Data 0.00104 (0.00121)	Tok/s 87427 (74115)	Loss/tok 3.5381 (4.1606)	Learning Rate [0.00125]
0: TRAIN [0][5390/6832]	Time 0.279 (0.346)	Data 0.00104 (0.00121)	Tok/s 72314 (74114)	Loss/tok 3.4696 (4.1596)	Learning Rate [0.00125]
0: TRAIN [0][5400/6832]	Time 0.345 (0.346)	Data 0.00023 (0.00121)	Tok/s 73300 (74118)	Loss/tok 3.5559 (4.1584)	Learning Rate [0.00125]
0: TRAIN [0][5410/6832]	Time 0.195 (0.346)	Data 0.00106 (0.00121)	Tok/s 78172 (74116)	Loss/tok 3.3298 (4.1573)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5420/6832]	Time 0.463 (0.346)	Data 0.00095 (0.00121)	Tok/s 67904 (74115)	Loss/tok 3.6841 (4.1563)	Learning Rate [0.00125]
0: TRAIN [0][5430/6832]	Time 0.353 (0.346)	Data 0.00097 (0.00121)	Tok/s 68350 (74114)	Loss/tok 3.5906 (4.1553)	Learning Rate [0.00125]
0: TRAIN [0][5440/6832]	Time 0.483 (0.346)	Data 0.00100 (0.00121)	Tok/s 100836 (74112)	Loss/tok 3.4339 (4.1542)	Learning Rate [0.00125]
0: TRAIN [0][5450/6832]	Time 0.486 (0.346)	Data 0.00096 (0.00121)	Tok/s 85071 (74116)	Loss/tok 3.5701 (4.1530)	Learning Rate [0.00125]
0: TRAIN [0][5460/6832]	Time 0.479 (0.346)	Data 0.00103 (0.00121)	Tok/s 69295 (74116)	Loss/tok 3.6712 (4.1518)	Learning Rate [0.00125]
0: TRAIN [0][5470/6832]	Time 0.341 (0.346)	Data 0.00106 (0.00121)	Tok/s 69099 (74113)	Loss/tok 3.4383 (4.1507)	Learning Rate [0.00125]
0: TRAIN [0][5480/6832]	Time 0.212 (0.346)	Data 0.00099 (0.00121)	Tok/s 75203 (74120)	Loss/tok 3.3031 (4.1496)	Learning Rate [0.00125]
0: TRAIN [0][5490/6832]	Time 0.133 (0.346)	Data 0.00156 (0.00121)	Tok/s 79502 (74123)	Loss/tok 2.8760 (4.1484)	Learning Rate [0.00125]
0: TRAIN [0][5500/6832]	Time 0.261 (0.346)	Data 0.00101 (0.00121)	Tok/s 72642 (74122)	Loss/tok 3.3946 (4.1473)	Learning Rate [0.00125]
0: TRAIN [0][5510/6832]	Time 0.107 (0.346)	Data 0.00100 (0.00121)	Tok/s 77897 (74127)	Loss/tok 2.6100 (4.1462)	Learning Rate [0.00125]
0: TRAIN [0][5520/6832]	Time 0.468 (0.346)	Data 0.00106 (0.00121)	Tok/s 86374 (74126)	Loss/tok 3.6117 (4.1450)	Learning Rate [0.00125]
0: TRAIN [0][5530/6832]	Time 0.215 (0.346)	Data 0.00115 (0.00121)	Tok/s 77889 (74131)	Loss/tok 3.3591 (4.1438)	Learning Rate [0.00125]
0: TRAIN [0][5540/6832]	Time 0.115 (0.346)	Data 0.00105 (0.00121)	Tok/s 74464 (74131)	Loss/tok 2.5988 (4.1428)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5550/6832]	Time 0.259 (0.346)	Data 0.00102 (0.00121)	Tok/s 71415 (74127)	Loss/tok 3.4211 (4.1417)	Learning Rate [0.00125]
0: TRAIN [0][5560/6832]	Time 0.121 (0.346)	Data 0.00103 (0.00121)	Tok/s 80117 (74125)	Loss/tok 2.8040 (4.1407)	Learning Rate [0.00125]
0: TRAIN [0][5570/6832]	Time 0.446 (0.346)	Data 0.00102 (0.00121)	Tok/s 68600 (74120)	Loss/tok 3.6354 (4.1397)	Learning Rate [0.00125]
0: TRAIN [0][5580/6832]	Time 0.464 (0.346)	Data 0.00105 (0.00121)	Tok/s 100424 (74122)	Loss/tok 3.4104 (4.1385)	Learning Rate [0.00125]
0: TRAIN [0][5590/6832]	Time 0.480 (0.346)	Data 0.00106 (0.00121)	Tok/s 72891 (74126)	Loss/tok 3.6546 (4.1373)	Learning Rate [0.00125]
0: TRAIN [0][5600/6832]	Time 0.328 (0.346)	Data 0.00106 (0.00121)	Tok/s 70198 (74127)	Loss/tok 3.5412 (4.1362)	Learning Rate [0.00125]
0: TRAIN [0][5610/6832]	Time 0.315 (0.346)	Data 0.00105 (0.00121)	Tok/s 73208 (74125)	Loss/tok 3.4287 (4.1352)	Learning Rate [0.00125]
0: TRAIN [0][5620/6832]	Time 0.483 (0.346)	Data 0.00108 (0.00121)	Tok/s 91351 (74129)	Loss/tok 3.4628 (4.1341)	Learning Rate [0.00125]
0: TRAIN [0][5630/6832]	Time 0.268 (0.346)	Data 0.00109 (0.00121)	Tok/s 74203 (74127)	Loss/tok 3.4577 (4.1330)	Learning Rate [0.00125]
0: TRAIN [0][5640/6832]	Time 0.127 (0.346)	Data 0.00114 (0.00121)	Tok/s 76663 (74122)	Loss/tok 2.8186 (4.1320)	Learning Rate [0.00125]
0: TRAIN [0][5650/6832]	Time 0.357 (0.346)	Data 0.00108 (0.00121)	Tok/s 68627 (74117)	Loss/tok 3.5873 (4.1311)	Learning Rate [0.00125]
0: TRAIN [0][5660/6832]	Time 0.408 (0.346)	Data 0.00146 (0.00121)	Tok/s 67425 (74118)	Loss/tok 3.6421 (4.1300)	Learning Rate [0.00125]
0: TRAIN [0][5670/6832]	Time 0.434 (0.346)	Data 0.00106 (0.00121)	Tok/s 64871 (74116)	Loss/tok 3.6080 (4.1289)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5680/6832]	Time 0.451 (0.346)	Data 0.00103 (0.00121)	Tok/s 69618 (74110)	Loss/tok 3.7040 (4.1280)	Learning Rate [0.00125]
0: TRAIN [0][5690/6832]	Time 0.155 (0.346)	Data 0.00105 (0.00121)	Tok/s 76947 (74116)	Loss/tok 3.0688 (4.1267)	Learning Rate [0.00125]
0: TRAIN [0][5700/6832]	Time 0.220 (0.346)	Data 0.00108 (0.00121)	Tok/s 75976 (74128)	Loss/tok 3.3114 (4.1253)	Learning Rate [0.00125]
0: TRAIN [0][5710/6832]	Time 0.382 (0.347)	Data 0.00111 (0.00120)	Tok/s 70381 (74133)	Loss/tok 3.5333 (4.1241)	Learning Rate [0.00125]
0: TRAIN [0][5720/6832]	Time 0.483 (0.347)	Data 0.00108 (0.00120)	Tok/s 65304 (74133)	Loss/tok 3.6769 (4.1231)	Learning Rate [0.00125]
0: TRAIN [0][5730/6832]	Time 0.254 (0.347)	Data 0.00104 (0.00120)	Tok/s 74446 (74131)	Loss/tok 3.5067 (4.1221)	Learning Rate [0.00125]
0: TRAIN [0][5740/6832]	Time 0.157 (0.347)	Data 0.00105 (0.00120)	Tok/s 79277 (74125)	Loss/tok 3.1896 (4.1212)	Learning Rate [0.00125]
0: TRAIN [0][5750/6832]	Time 0.425 (0.347)	Data 0.00112 (0.00120)	Tok/s 67142 (74117)	Loss/tok 3.6444 (4.1203)	Learning Rate [0.00125]
0: TRAIN [0][5760/6832]	Time 0.476 (0.347)	Data 0.00103 (0.00120)	Tok/s 68079 (74108)	Loss/tok 3.6640 (4.1193)	Learning Rate [0.00125]
0: TRAIN [0][5770/6832]	Time 0.146 (0.347)	Data 0.00104 (0.00120)	Tok/s 72127 (74109)	Loss/tok 2.9533 (4.1183)	Learning Rate [0.00125]
0: TRAIN [0][5780/6832]	Time 0.167 (0.347)	Data 0.00112 (0.00120)	Tok/s 74503 (74109)	Loss/tok 3.1164 (4.1174)	Learning Rate [0.00125]
0: TRAIN [0][5790/6832]	Time 0.363 (0.347)	Data 0.00101 (0.00120)	Tok/s 73416 (74110)	Loss/tok 3.5645 (4.1162)	Learning Rate [0.00125]
0: TRAIN [0][5800/6832]	Time 0.485 (0.347)	Data 0.00106 (0.00121)	Tok/s 81847 (74116)	Loss/tok 3.6341 (4.1152)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5810/6832]	Time 0.183 (0.347)	Data 0.00102 (0.00121)	Tok/s 75975 (74117)	Loss/tok 3.1559 (4.1141)	Learning Rate [0.00125]
0: TRAIN [0][5820/6832]	Time 0.460 (0.347)	Data 0.00102 (0.00121)	Tok/s 67626 (74112)	Loss/tok 3.6521 (4.1131)	Learning Rate [0.00125]
0: TRAIN [0][5830/6832]	Time 0.481 (0.346)	Data 0.00108 (0.00121)	Tok/s 79636 (74109)	Loss/tok 3.6746 (4.1122)	Learning Rate [0.00125]
0: TRAIN [0][5840/6832]	Time 0.482 (0.346)	Data 0.00109 (0.00121)	Tok/s 78222 (74107)	Loss/tok 3.5768 (4.1113)	Learning Rate [0.00125]
0: TRAIN [0][5850/6832]	Time 0.445 (0.347)	Data 0.00105 (0.00120)	Tok/s 64822 (74102)	Loss/tok 3.6333 (4.1103)	Learning Rate [0.00125]
0: TRAIN [0][5860/6832]	Time 0.434 (0.347)	Data 0.00125 (0.00120)	Tok/s 67705 (74110)	Loss/tok 3.6047 (4.1090)	Learning Rate [0.00125]
0: TRAIN [0][5870/6832]	Time 0.124 (0.347)	Data 0.00108 (0.00120)	Tok/s 77531 (74110)	Loss/tok 2.8561 (4.1081)	Learning Rate [0.00125]
0: TRAIN [0][5880/6832]	Time 0.301 (0.347)	Data 0.00109 (0.00120)	Tok/s 69733 (74111)	Loss/tok 3.6014 (4.1071)	Learning Rate [0.00125]
0: TRAIN [0][5890/6832]	Time 0.474 (0.347)	Data 0.00114 (0.00120)	Tok/s 71231 (74109)	Loss/tok 3.7229 (4.1061)	Learning Rate [0.00125]
0: TRAIN [0][5900/6832]	Time 0.478 (0.347)	Data 0.00099 (0.00120)	Tok/s 70543 (74106)	Loss/tok 3.7327 (4.1052)	Learning Rate [0.00125]
0: TRAIN [0][5910/6832]	Time 0.465 (0.347)	Data 0.00099 (0.00120)	Tok/s 92858 (74109)	Loss/tok 3.4542 (4.1042)	Learning Rate [0.00125]
0: TRAIN [0][5920/6832]	Time 0.486 (0.347)	Data 0.00104 (0.00120)	Tok/s 75059 (74114)	Loss/tok 3.6658 (4.1031)	Learning Rate [0.00125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][5930/6832]	Time 0.339 (0.347)	Data 0.00108 (0.00120)	Tok/s 68973 (74108)	Loss/tok 3.6249 (4.1022)	Learning Rate [0.00125]
0: TRAIN [0][5940/6832]	Time 0.489 (0.347)	Data 0.00102 (0.00120)	Tok/s 88228 (74117)	Loss/tok 3.5368 (4.1010)	Learning Rate [0.00125]
0: TRAIN [0][5950/6832]	Time 0.479 (0.347)	Data 0.00106 (0.00120)	Tok/s 72838 (74119)	Loss/tok 3.6987 (4.0999)	Learning Rate [0.00125]
0: TRAIN [0][5960/6832]	Time 0.274 (0.347)	Data 0.00106 (0.00120)	Tok/s 72972 (74116)	Loss/tok 3.3940 (4.0990)	Learning Rate [0.00125]
0: TRAIN [0][5970/6832]	Time 0.285 (0.347)	Data 0.00105 (0.00120)	Tok/s 71436 (74115)	Loss/tok 3.4539 (4.0981)	Learning Rate [0.00125]
0: TRAIN [0][5980/6832]	Time 0.483 (0.347)	Data 0.00101 (0.00120)	Tok/s 67412 (74112)	Loss/tok 3.6380 (4.0971)	Learning Rate [0.00125]
0: TRAIN [0][5990/6832]	Time 0.484 (0.347)	Data 0.00108 (0.00120)	Tok/s 80792 (74119)	Loss/tok 3.6489 (4.0960)	Learning Rate [0.00125]
0: TRAIN [0][6000/6832]	Time 0.478 (0.347)	Data 0.00102 (0.00120)	Tok/s 76141 (74120)	Loss/tok 3.6614 (4.0951)	Learning Rate [0.00125]
0: TRAIN [0][6010/6832]	Time 0.140 (0.347)	Data 0.00104 (0.00120)	Tok/s 80034 (74117)	Loss/tok 2.9472 (4.0942)	Learning Rate [0.000625]
0: TRAIN [0][6020/6832]	Time 0.477 (0.347)	Data 0.00110 (0.00120)	Tok/s 69675 (74117)	Loss/tok 3.7017 (4.0932)	Learning Rate [0.000625]
0: TRAIN [0][6030/6832]	Time 0.349 (0.347)	Data 0.00132 (0.00120)	Tok/s 68911 (74113)	Loss/tok 3.4990 (4.0923)	Learning Rate [0.000625]
0: TRAIN [0][6040/6832]	Time 0.463 (0.347)	Data 0.00106 (0.00120)	Tok/s 73865 (74116)	Loss/tok 3.6054 (4.0912)	Learning Rate [0.000625]
0: TRAIN [0][6050/6832]	Time 0.466 (0.347)	Data 0.00105 (0.00120)	Tok/s 63934 (74120)	Loss/tok 3.6376 (4.0900)	Learning Rate [0.000625]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][6060/6832]	Time 0.485 (0.347)	Data 0.00108 (0.00120)	Tok/s 88672 (74125)	Loss/tok 3.5246 (4.0889)	Learning Rate [0.000625]
0: TRAIN [0][6070/6832]	Time 0.222 (0.347)	Data 0.00107 (0.00120)	Tok/s 75938 (74130)	Loss/tok 3.2355 (4.0879)	Learning Rate [0.000625]
0: TRAIN [0][6080/6832]	Time 0.146 (0.347)	Data 0.00107 (0.00120)	Tok/s 81654 (74129)	Loss/tok 2.9568 (4.0870)	Learning Rate [0.000625]
0: TRAIN [0][6090/6832]	Time 0.480 (0.347)	Data 0.00109 (0.00120)	Tok/s 65329 (74131)	Loss/tok 3.6027 (4.0860)	Learning Rate [0.000625]
0: TRAIN [0][6100/6832]	Time 0.484 (0.347)	Data 0.00103 (0.00120)	Tok/s 80596 (74133)	Loss/tok 3.5000 (4.0849)	Learning Rate [0.000625]
0: TRAIN [0][6110/6832]	Time 0.456 (0.347)	Data 0.00105 (0.00120)	Tok/s 63300 (74131)	Loss/tok 3.5877 (4.0840)	Learning Rate [0.000625]
0: TRAIN [0][6120/6832]	Time 0.480 (0.347)	Data 0.00106 (0.00120)	Tok/s 74648 (74126)	Loss/tok 3.5403 (4.0830)	Learning Rate [0.000625]
0: TRAIN [0][6130/6832]	Time 0.154 (0.347)	Data 0.00107 (0.00120)	Tok/s 68323 (74122)	Loss/tok 2.8204 (4.0821)	Learning Rate [0.000625]
0: TRAIN [0][6140/6832]	Time 0.469 (0.347)	Data 0.00103 (0.00120)	Tok/s 68286 (74118)	Loss/tok 3.6750 (4.0812)	Learning Rate [0.000625]
0: TRAIN [0][6150/6832]	Time 0.452 (0.347)	Data 0.00109 (0.00120)	Tok/s 75974 (74117)	Loss/tok 3.6202 (4.0802)	Learning Rate [0.000625]
0: TRAIN [0][6160/6832]	Time 0.484 (0.347)	Data 0.00111 (0.00120)	Tok/s 88980 (74116)	Loss/tok 3.4644 (4.0791)	Learning Rate [0.000625]
0: TRAIN [0][6170/6832]	Time 0.375 (0.347)	Data 0.00113 (0.00120)	Tok/s 65463 (74117)	Loss/tok 3.4753 (4.0780)	Learning Rate [0.000625]
0: TRAIN [0][6180/6832]	Time 0.446 (0.348)	Data 0.00103 (0.00120)	Tok/s 66554 (74117)	Loss/tok 3.6474 (4.0769)	Learning Rate [0.000625]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][6190/6832]	Time 0.460 (0.348)	Data 0.00115 (0.00120)	Tok/s 65594 (74111)	Loss/tok 3.4902 (4.0759)	Learning Rate [0.000625]
0: TRAIN [0][6200/6832]	Time 0.203 (0.348)	Data 0.00108 (0.00120)	Tok/s 72584 (74108)	Loss/tok 3.2065 (4.0750)	Learning Rate [0.000625]
0: TRAIN [0][6210/6832]	Time 0.244 (0.348)	Data 0.00112 (0.00120)	Tok/s 73179 (74106)	Loss/tok 3.3014 (4.0741)	Learning Rate [0.000625]
0: TRAIN [0][6220/6832]	Time 0.486 (0.347)	Data 0.00108 (0.00120)	Tok/s 78597 (74108)	Loss/tok 3.5710 (4.0732)	Learning Rate [0.000625]
0: TRAIN [0][6230/6832]	Time 0.302 (0.347)	Data 0.00114 (0.00120)	Tok/s 70807 (74112)	Loss/tok 3.4632 (4.0720)	Learning Rate [0.000625]
0: TRAIN [0][6240/6832]	Time 0.228 (0.347)	Data 0.00099 (0.00120)	Tok/s 76503 (74112)	Loss/tok 3.3490 (4.0711)	Learning Rate [0.000625]
0: TRAIN [0][6250/6832]	Time 0.410 (0.347)	Data 0.00105 (0.00120)	Tok/s 65761 (74105)	Loss/tok 3.5569 (4.0703)	Learning Rate [0.000625]
0: TRAIN [0][6260/6832]	Time 0.409 (0.347)	Data 0.00114 (0.00120)	Tok/s 67765 (74104)	Loss/tok 3.4955 (4.0693)	Learning Rate [0.000625]
0: TRAIN [0][6270/6832]	Time 0.480 (0.347)	Data 0.00106 (0.00120)	Tok/s 87956 (74108)	Loss/tok 3.5311 (4.0683)	Learning Rate [0.000625]
0: TRAIN [0][6280/6832]	Time 0.211 (0.347)	Data 0.00109 (0.00120)	Tok/s 75145 (74107)	Loss/tok 3.2690 (4.0673)	Learning Rate [0.000625]
0: TRAIN [0][6290/6832]	Time 0.489 (0.347)	Data 0.00108 (0.00120)	Tok/s 87965 (74110)	Loss/tok 3.4923 (4.0663)	Learning Rate [0.000625]
0: TRAIN [0][6300/6832]	Time 0.312 (0.347)	Data 0.00105 (0.00120)	Tok/s 69027 (74106)	Loss/tok 3.3563 (4.0654)	Learning Rate [0.000625]
0: TRAIN [0][6310/6832]	Time 0.235 (0.347)	Data 0.00105 (0.00120)	Tok/s 76265 (74108)	Loss/tok 3.2522 (4.0644)	Learning Rate [0.000625]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][6320/6832]	Time 0.350 (0.347)	Data 0.00139 (0.00120)	Tok/s 69255 (74107)	Loss/tok 3.5432 (4.0634)	Learning Rate [0.000625]
0: TRAIN [0][6330/6832]	Time 0.184 (0.347)	Data 0.00112 (0.00120)	Tok/s 78427 (74110)	Loss/tok 3.2047 (4.0625)	Learning Rate [0.000625]
0: TRAIN [0][6340/6832]	Time 0.282 (0.347)	Data 0.00102 (0.00120)	Tok/s 72610 (74108)	Loss/tok 3.3844 (4.0615)	Learning Rate [0.000625]
0: TRAIN [0][6350/6832]	Time 0.343 (0.347)	Data 0.00105 (0.00120)	Tok/s 70154 (74107)	Loss/tok 3.5065 (4.0606)	Learning Rate [0.000625]
0: TRAIN [0][6360/6832]	Time 0.122 (0.347)	Data 0.00107 (0.00119)	Tok/s 79447 (74106)	Loss/tok 2.7466 (4.0598)	Learning Rate [0.000625]
0: TRAIN [0][6370/6832]	Time 0.284 (0.347)	Data 0.00103 (0.00119)	Tok/s 72293 (74104)	Loss/tok 3.3994 (4.0588)	Learning Rate [0.000625]
0: TRAIN [0][6380/6832]	Time 0.474 (0.347)	Data 0.00103 (0.00119)	Tok/s 73472 (74106)	Loss/tok 3.6315 (4.0579)	Learning Rate [0.000625]
0: TRAIN [0][6390/6832]	Time 0.279 (0.347)	Data 0.00107 (0.00119)	Tok/s 73317 (74106)	Loss/tok 3.3951 (4.0569)	Learning Rate [0.000625]
0: TRAIN [0][6400/6832]	Time 0.417 (0.347)	Data 0.00107 (0.00119)	Tok/s 66654 (74108)	Loss/tok 3.5605 (4.0558)	Learning Rate [0.000625]
0: TRAIN [0][6410/6832]	Time 0.432 (0.348)	Data 0.00105 (0.00119)	Tok/s 68771 (74110)	Loss/tok 3.5037 (4.0548)	Learning Rate [0.000625]
0: TRAIN [0][6420/6832]	Time 0.432 (0.348)	Data 0.00109 (0.00119)	Tok/s 65346 (74112)	Loss/tok 3.4891 (4.0538)	Learning Rate [0.000625]
0: TRAIN [0][6430/6832]	Time 0.317 (0.348)	Data 0.00110 (0.00119)	Tok/s 70548 (74110)	Loss/tok 3.4495 (4.0529)	Learning Rate [0.000625]
0: TRAIN [0][6440/6832]	Time 0.423 (0.348)	Data 0.00101 (0.00119)	Tok/s 68226 (74104)	Loss/tok 3.5327 (4.0521)	Learning Rate [0.000625]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][6450/6832]	Time 0.275 (0.348)	Data 0.00099 (0.00119)	Tok/s 70902 (74104)	Loss/tok 3.3424 (4.0511)	Learning Rate [0.000625]
0: TRAIN [0][6460/6832]	Time 0.423 (0.348)	Data 0.00110 (0.00119)	Tok/s 67585 (74102)	Loss/tok 3.6021 (4.0503)	Learning Rate [0.000625]
0: TRAIN [0][6470/6832]	Time 0.199 (0.348)	Data 0.00100 (0.00119)	Tok/s 76619 (74098)	Loss/tok 3.2849 (4.0494)	Learning Rate [0.000625]
0: TRAIN [0][6480/6832]	Time 0.484 (0.347)	Data 0.00108 (0.00119)	Tok/s 87268 (74100)	Loss/tok 3.5816 (4.0486)	Learning Rate [0.000625]
0: TRAIN [0][6490/6832]	Time 0.480 (0.347)	Data 0.00130 (0.00119)	Tok/s 72285 (74100)	Loss/tok 3.4684 (4.0477)	Learning Rate [0.000625]
0: TRAIN [0][6500/6832]	Time 0.301 (0.347)	Data 0.00109 (0.00119)	Tok/s 68850 (74093)	Loss/tok 3.3284 (4.0468)	Learning Rate [0.000625]
0: TRAIN [0][6510/6832]	Time 0.266 (0.347)	Data 0.00112 (0.00119)	Tok/s 73366 (74088)	Loss/tok 3.3315 (4.0460)	Learning Rate [0.0003125]
0: TRAIN [0][6520/6832]	Time 0.232 (0.347)	Data 0.00101 (0.00119)	Tok/s 72494 (74088)	Loss/tok 3.1742 (4.0451)	Learning Rate [0.0003125]
0: TRAIN [0][6530/6832]	Time 0.469 (0.347)	Data 0.00108 (0.00119)	Tok/s 65308 (74078)	Loss/tok 3.6127 (4.0443)	Learning Rate [0.0003125]
0: TRAIN [0][6540/6832]	Time 0.118 (0.347)	Data 0.00107 (0.00119)	Tok/s 70681 (74080)	Loss/tok 2.4829 (4.0434)	Learning Rate [0.0003125]
0: TRAIN [0][6550/6832]	Time 0.379 (0.347)	Data 0.00109 (0.00119)	Tok/s 65557 (74070)	Loss/tok 3.4763 (4.0425)	Learning Rate [0.0003125]
0: TRAIN [0][6560/6832]	Time 0.338 (0.347)	Data 0.00112 (0.00119)	Tok/s 68108 (74070)	Loss/tok 3.5264 (4.0415)	Learning Rate [0.0003125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][6570/6832]	Time 0.305 (0.347)	Data 0.00184 (0.00119)	Tok/s 68425 (74065)	Loss/tok 3.5417 (4.0406)	Learning Rate [0.0003125]
0: TRAIN [0][6580/6832]	Time 0.437 (0.348)	Data 0.00106 (0.00119)	Tok/s 64548 (74062)	Loss/tok 3.5527 (4.0397)	Learning Rate [0.0003125]
0: TRAIN [0][6590/6832]	Time 0.464 (0.348)	Data 0.00107 (0.00119)	Tok/s 66720 (74056)	Loss/tok 3.5426 (4.0388)	Learning Rate [0.0003125]
0: TRAIN [0][6600/6832]	Time 0.455 (0.348)	Data 0.00108 (0.00119)	Tok/s 65561 (74055)	Loss/tok 3.5143 (4.0379)	Learning Rate [0.0003125]
0: TRAIN [0][6610/6832]	Time 0.484 (0.348)	Data 0.00108 (0.00119)	Tok/s 93441 (74059)	Loss/tok 3.3176 (4.0368)	Learning Rate [0.0003125]
0: TRAIN [0][6620/6832]	Time 0.166 (0.348)	Data 0.00114 (0.00119)	Tok/s 75542 (74058)	Loss/tok 3.0562 (4.0360)	Learning Rate [0.0003125]
0: TRAIN [0][6630/6832]	Time 0.167 (0.348)	Data 0.00108 (0.00119)	Tok/s 78135 (74054)	Loss/tok 3.0127 (4.0351)	Learning Rate [0.0003125]
0: TRAIN [0][6640/6832]	Time 0.432 (0.348)	Data 0.00110 (0.00119)	Tok/s 67933 (74056)	Loss/tok 3.5236 (4.0341)	Learning Rate [0.0003125]
0: TRAIN [0][6650/6832]	Time 0.167 (0.347)	Data 0.00106 (0.00119)	Tok/s 77684 (74057)	Loss/tok 3.0010 (4.0334)	Learning Rate [0.0003125]
0: TRAIN [0][6660/6832]	Time 0.486 (0.347)	Data 0.00109 (0.00119)	Tok/s 90821 (74061)	Loss/tok 3.4164 (4.0324)	Learning Rate [0.0003125]
0: TRAIN [0][6670/6832]	Time 0.479 (0.347)	Data 0.00109 (0.00119)	Tok/s 68528 (74054)	Loss/tok 3.5785 (4.0316)	Learning Rate [0.0003125]
0: TRAIN [0][6680/6832]	Time 0.267 (0.347)	Data 0.00110 (0.00119)	Tok/s 69400 (74053)	Loss/tok 3.2945 (4.0307)	Learning Rate [0.0003125]
0: TRAIN [0][6690/6832]	Time 0.385 (0.347)	Data 0.00107 (0.00119)	Tok/s 67070 (74056)	Loss/tok 3.5020 (4.0297)	Learning Rate [0.0003125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][6700/6832]	Time 0.485 (0.347)	Data 0.00107 (0.00119)	Tok/s 81988 (74053)	Loss/tok 3.4819 (4.0289)	Learning Rate [0.0003125]
0: TRAIN [0][6710/6832]	Time 0.138 (0.347)	Data 0.00108 (0.00119)	Tok/s 80902 (74050)	Loss/tok 2.8842 (4.0281)	Learning Rate [0.0003125]
0: TRAIN [0][6720/6832]	Time 0.486 (0.347)	Data 0.00111 (0.00119)	Tok/s 84991 (74056)	Loss/tok 3.4370 (4.0272)	Learning Rate [0.0003125]
0: TRAIN [0][6730/6832]	Time 0.317 (0.347)	Data 0.00109 (0.00119)	Tok/s 70501 (74059)	Loss/tok 3.3730 (4.0262)	Learning Rate [0.0003125]
0: TRAIN [0][6740/6832]	Time 0.473 (0.347)	Data 0.00112 (0.00119)	Tok/s 75599 (74060)	Loss/tok 3.5106 (4.0254)	Learning Rate [0.0003125]
0: TRAIN [0][6750/6832]	Time 0.279 (0.347)	Data 0.00109 (0.00119)	Tok/s 73698 (74067)	Loss/tok 3.3584 (4.0243)	Learning Rate [0.0003125]
0: TRAIN [0][6760/6832]	Time 0.413 (0.347)	Data 0.00110 (0.00119)	Tok/s 65277 (74064)	Loss/tok 3.4724 (4.0234)	Learning Rate [0.0003125]
0: TRAIN [0][6770/6832]	Time 0.461 (0.347)	Data 0.00110 (0.00119)	Tok/s 65650 (74057)	Loss/tok 3.5811 (4.0227)	Learning Rate [0.0003125]
0: TRAIN [0][6780/6832]	Time 0.169 (0.347)	Data 0.00103 (0.00119)	Tok/s 82024 (74059)	Loss/tok 3.1539 (4.0218)	Learning Rate [0.0003125]
0: TRAIN [0][6790/6832]	Time 0.113 (0.347)	Data 0.00112 (0.00119)	Tok/s 74478 (74054)	Loss/tok 2.6155 (4.0210)	Learning Rate [0.0003125]
0: TRAIN [0][6800/6832]	Time 0.306 (0.347)	Data 0.00106 (0.00119)	Tok/s 72969 (74049)	Loss/tok 3.3490 (4.0201)	Learning Rate [0.0003125]
0: TRAIN [0][6810/6832]	Time 0.468 (0.347)	Data 0.00106 (0.00119)	Tok/s 91983 (74057)	Loss/tok 3.4218 (4.0190)	Learning Rate [0.0003125]
0: TRAIN [0][6820/6832]	Time 0.480 (0.347)	Data 0.00105 (0.00119)	Tok/s 78320 (74061)	Loss/tok 3.6089 (4.0181)	Learning Rate [0.0003125]
0: Upscaling, new scale: 8192.0
0: TRAIN [0][6830/6832]	Time 0.481 (0.348)	Data 0.00097 (0.00120)	Tok/s 75739 (74064)	Loss/tok 3.5446 (4.0171)	Learning Rate [0.0003125]
0: Running validation on dev set
0: VALIDATION [0][0/80]	Time 0.065 (0.000)	Data 0.00224 (0.00000)	Tok/s 157344 (0)	Loss/tok 3.5026 (0.0000)	Learning Rate [0.0003125]
0: VALIDATION [0][10/80]	Time 0.026 (0.031)	Data 0.00173 (0.00183)	Tok/s 217609 (215717)	Loss/tok 3.2509 (3.3771)	Learning Rate [0.0003125]
0: VALIDATION [0][20/80]	Time 0.022 (0.027)	Data 0.00166 (0.00176)	Tok/s 210526 (215536)	Loss/tok 3.2572 (3.3512)	Learning Rate [0.0003125]
0: VALIDATION [0][30/80]	Time 0.019 (0.025)	Data 0.00162 (0.00172)	Tok/s 195155 (214974)	Loss/tok 3.2857 (3.3235)	Learning Rate [0.0003125]
0: VALIDATION [0][40/80]	Time 0.015 (0.023)	Data 0.00158 (0.00169)	Tok/s 205044 (211746)	Loss/tok 3.2567 (3.3069)	Learning Rate [0.0003125]
0: VALIDATION [0][50/80]	Time 0.014 (0.021)	Data 0.00155 (0.00167)	Tok/s 190617 (208500)	Loss/tok 3.1201 (3.2907)	Learning Rate [0.0003125]
0: VALIDATION [0][60/80]	Time 0.015 (0.020)	Data 0.00155 (0.00165)	Tok/s 143063 (203118)	Loss/tok 3.3094 (3.2839)	Learning Rate [0.0003125]
0: VALIDATION [0][70/80]	Time 0.014 (0.019)	Data 0.00152 (0.00164)	Tok/s 111799 (192017)	Loss/tok 3.1605 (3.2758)	Learning Rate [0.0003125]
:::MLPv0.5.0 gnmt 1560836664.414294720 (train.py:459) eval_start: 0
0: Running evaluation on test set
0: TEST [0][0/6]	Time 2.298 (2.298)	Decoder iters 149.0 (149.0)	Tok/s 12911 (12911)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560836681.410265923 (train.py:464) eval_accuracy: {"epoch": 0, "value": 20.18000030517578}
:::MLPv0.5.0 gnmt 1560836681.410775900 (train.py:466) eval_target: 21.8
:::MLPv0.5.0 gnmt 1560836681.411283255 (train.py:467) eval_stop
0: Summary: Epoch: 0	Training Loss: 4.0170	Validation Loss: 3.2653	Test BLEU: 20.18
0: Performance: Epoch: 0	Training: 74065 Tok/s	Validation: 181199 Tok/s
0: Finished epoch 0
0: Starting epoch 1
:::MLPv0.5.0 gnmt 1560836681.412154436 (train.py:443) train_epoch: 1
/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:182: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
  self.num_layers, self.dropout, self.training, self.bidirectional)
:::MLPv0.5.0 gnmt 1560836681.995931149 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 2037452816
:::MLPv0.5.0 gnmt 1560836682.083052874 (seq2seq/data/sampler.py:66) input_shard: 40960
0: TRAIN [1][0/6832]	Time 1.234 (0.000)	Data 0.94045 (0.00000)	Tok/s 17834 (0)	Loss/tok 3.3828 (0.0000)	Learning Rate [0.0003125]
0: TRAIN [1][10/6832]	Time 0.479 (0.346)	Data 0.00110 (0.00103)	Tok/s 97214 (75090)	Loss/tok 3.2845 (3.4164)	Learning Rate [0.0003125]
0: TRAIN [1][20/6832]	Time 0.377 (0.359)	Data 0.00104 (0.00103)	Tok/s 67857 (72724)	Loss/tok 3.4793 (3.4388)	Learning Rate [0.0003125]
0: TRAIN [1][30/6832]	Time 0.227 (0.337)	Data 0.00101 (0.00104)	Tok/s 72223 (73266)	Loss/tok 3.1702 (3.4235)	Learning Rate [0.0003125]
0: TRAIN [1][40/6832]	Time 0.481 (0.334)	Data 0.00106 (0.00106)	Tok/s 79501 (74453)	Loss/tok 3.4672 (3.4018)	Learning Rate [0.0003125]
0: TRAIN [1][50/6832]	Time 0.284 (0.330)	Data 0.00100 (0.00105)	Tok/s 70295 (74838)	Loss/tok 3.3380 (3.3949)	Learning Rate [0.0003125]
0: TRAIN [1][60/6832]	Time 0.348 (0.326)	Data 0.00105 (0.00105)	Tok/s 69205 (74094)	Loss/tok 3.4402 (3.3957)	Learning Rate [0.0003125]
0: TRAIN [1][70/6832]	Time 0.478 (0.321)	Data 0.00107 (0.00105)	Tok/s 71528 (74392)	Loss/tok 3.5934 (3.3932)	Learning Rate [0.0003125]
0: TRAIN [1][80/6832]	Time 0.110 (0.328)	Data 0.00106 (0.00105)	Tok/s 76136 (74055)	Loss/tok 2.5366 (3.4031)	Learning Rate [0.0003125]
0: TRAIN [1][90/6832]	Time 0.165 (0.326)	Data 0.00112 (0.00105)	Tok/s 78242 (74568)	Loss/tok 2.9879 (3.3923)	Learning Rate [0.0003125]
0: TRAIN [1][100/6832]	Time 0.318 (0.329)	Data 0.00104 (0.00105)	Tok/s 74435 (74526)	Loss/tok 3.4084 (3.3945)	Learning Rate [0.0003125]
0: TRAIN [1][110/6832]	Time 0.600 (0.331)	Data 0.11540 (0.00209)	Tok/s 58690 (74444)	Loss/tok 3.5104 (3.3932)	Learning Rate [0.0003125]
0: TRAIN [1][120/6832]	Time 0.221 (0.334)	Data 0.00103 (0.00201)	Tok/s 74055 (74458)	Loss/tok 3.2535 (3.3985)	Learning Rate [0.0003125]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][130/6832]	Time 0.321 (0.332)	Data 0.00118 (0.00194)	Tok/s 70258 (74433)	Loss/tok 3.4212 (3.3990)	Learning Rate [0.0003125]
0: TRAIN [1][140/6832]	Time 0.343 (0.331)	Data 0.00107 (0.00187)	Tok/s 69079 (74187)	Loss/tok 3.4569 (3.3984)	Learning Rate [0.0003125]
0: TRAIN [1][150/6832]	Time 0.469 (0.335)	Data 0.00108 (0.00182)	Tok/s 71304 (73964)	Loss/tok 3.5268 (3.4051)	Learning Rate [0.0003125]
0: TRAIN [1][160/6832]	Time 0.474 (0.336)	Data 0.00107 (0.00177)	Tok/s 71111 (74019)	Loss/tok 3.4986 (3.4044)	Learning Rate [0.0003125]
0: TRAIN [1][170/6832]	Time 0.148 (0.341)	Data 0.00106 (0.00173)	Tok/s 84584 (74057)	Loss/tok 3.0070 (3.4101)	Learning Rate [0.0003125]
0: TRAIN [1][180/6832]	Time 0.426 (0.341)	Data 0.00101 (0.00169)	Tok/s 68014 (73936)	Loss/tok 3.5171 (3.4120)	Learning Rate [0.00015625]
0: TRAIN [1][190/6832]	Time 0.311 (0.341)	Data 0.00104 (0.00166)	Tok/s 69595 (73950)	Loss/tok 3.3565 (3.4139)	Learning Rate [0.00015625]
0: TRAIN [1][200/6832]	Time 0.485 (0.345)	Data 0.00114 (0.00163)	Tok/s 96104 (74272)	Loss/tok 3.3208 (3.4138)	Learning Rate [0.00015625]
0: TRAIN [1][210/6832]	Time 0.457 (0.345)	Data 0.00110 (0.00160)	Tok/s 106686 (74526)	Loss/tok 3.2833 (3.4096)	Learning Rate [0.00015625]
0: TRAIN [1][220/6832]	Time 0.414 (0.346)	Data 0.00103 (0.00158)	Tok/s 66039 (74541)	Loss/tok 3.4382 (3.4076)	Learning Rate [0.00015625]
0: TRAIN [1][230/6832]	Time 0.311 (0.346)	Data 0.00110 (0.00156)	Tok/s 70883 (74542)	Loss/tok 3.3050 (3.4058)	Learning Rate [0.00015625]
0: TRAIN [1][240/6832]	Time 0.140 (0.346)	Data 0.00109 (0.00154)	Tok/s 81421 (74422)	Loss/tok 2.8044 (3.4071)	Learning Rate [0.00015625]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][250/6832]	Time 0.318 (0.347)	Data 0.00108 (0.00427)	Tok/s 71169 (74122)	Loss/tok 3.3302 (3.4054)	Learning Rate [0.00015625]
0: TRAIN [1][260/6832]	Time 0.402 (0.346)	Data 0.00107 (0.00415)	Tok/s 64992 (73941)	Loss/tok 3.3974 (3.4060)	Learning Rate [0.00015625]
0: TRAIN [1][270/6832]	Time 0.487 (0.345)	Data 0.00108 (0.00404)	Tok/s 99885 (73932)	Loss/tok 3.2629 (3.4028)	Learning Rate [0.00015625]
0: TRAIN [1][280/6832]	Time 0.222 (0.344)	Data 0.00107 (0.00393)	Tok/s 75277 (73904)	Loss/tok 3.1089 (3.4029)	Learning Rate [0.00015625]
0: TRAIN [1][290/6832]	Time 0.434 (0.345)	Data 0.00106 (0.00383)	Tok/s 66153 (73758)	Loss/tok 3.5581 (3.4063)	Learning Rate [0.00015625]
0: TRAIN [1][300/6832]	Time 0.339 (0.344)	Data 0.00106 (0.00374)	Tok/s 70998 (73739)	Loss/tok 3.4400 (3.4055)	Learning Rate [0.00015625]
0: TRAIN [1][310/6832]	Time 0.361 (0.345)	Data 0.00105 (0.00366)	Tok/s 67981 (73819)	Loss/tok 3.4820 (3.4081)	Learning Rate [0.00015625]
0: TRAIN [1][320/6832]	Time 0.485 (0.347)	Data 0.00105 (0.00357)	Tok/s 79207 (74068)	Loss/tok 3.4326 (3.4061)	Learning Rate [0.00015625]
0: TRAIN [1][330/6832]	Time 0.195 (0.347)	Data 0.00117 (0.00350)	Tok/s 77865 (74195)	Loss/tok 3.2534 (3.4056)	Learning Rate [0.00015625]
0: TRAIN [1][340/6832]	Time 0.395 (0.348)	Data 0.00103 (0.00343)	Tok/s 69982 (74159)	Loss/tok 3.4483 (3.4074)	Learning Rate [0.00015625]
0: TRAIN [1][350/6832]	Time 0.391 (0.348)	Data 0.00102 (0.00336)	Tok/s 69067 (74111)	Loss/tok 3.4651 (3.4072)	Learning Rate [0.00015625]
0: TRAIN [1][360/6832]	Time 0.382 (0.347)	Data 0.00105 (0.00329)	Tok/s 66942 (74300)	Loss/tok 3.5041 (3.4046)	Learning Rate [0.00015625]
0: TRAIN [1][370/6832]	Time 0.228 (0.348)	Data 0.00104 (0.00323)	Tok/s 74779 (74294)	Loss/tok 3.2218 (3.4053)	Learning Rate [0.00015625]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][380/6832]	Time 0.464 (0.349)	Data 0.00103 (0.00396)	Tok/s 95310 (74235)	Loss/tok 3.3049 (3.4043)	Learning Rate [0.00015625]
0: TRAIN [1][390/6832]	Time 0.463 (0.349)	Data 0.00103 (0.00388)	Tok/s 66226 (74177)	Loss/tok 3.4736 (3.4038)	Learning Rate [0.00015625]
0: TRAIN [1][400/6832]	Time 0.399 (0.348)	Data 0.00118 (0.00381)	Tok/s 67650 (74144)	Loss/tok 3.4598 (3.4039)	Learning Rate [0.00015625]
0: TRAIN [1][410/6832]	Time 0.181 (0.347)	Data 0.00105 (0.00374)	Tok/s 76802 (74108)	Loss/tok 3.1203 (3.4031)	Learning Rate [0.00015625]
0: TRAIN [1][420/6832]	Time 0.099 (0.348)	Data 0.00107 (0.00368)	Tok/s 57842 (74083)	Loss/tok 2.1124 (3.4034)	Learning Rate [0.00015625]
0: TRAIN [1][430/6832]	Time 0.484 (0.349)	Data 0.00105 (0.00362)	Tok/s 85470 (74063)	Loss/tok 3.4457 (3.4041)	Learning Rate [0.00015625]
0: TRAIN [1][440/6832]	Time 0.300 (0.349)	Data 0.00108 (0.00356)	Tok/s 69920 (74126)	Loss/tok 3.3256 (3.4044)	Learning Rate [0.00015625]
0: TRAIN [1][450/6832]	Time 0.284 (0.349)	Data 0.00102 (0.00350)	Tok/s 73020 (74200)	Loss/tok 3.3245 (3.4029)	Learning Rate [0.00015625]
0: TRAIN [1][460/6832]	Time 0.481 (0.350)	Data 0.00106 (0.00345)	Tok/s 69966 (74146)	Loss/tok 3.5779 (3.4038)	Learning Rate [0.00015625]
0: TRAIN [1][470/6832]	Time 0.248 (0.351)	Data 0.00119 (0.00340)	Tok/s 74192 (74155)	Loss/tok 3.2786 (3.4042)	Learning Rate [0.00015625]
0: TRAIN [1][480/6832]	Time 0.110 (0.350)	Data 0.00103 (0.00335)	Tok/s 76443 (74181)	Loss/tok 2.5246 (3.4029)	Learning Rate [0.00015625]
0: TRAIN [1][490/6832]	Time 0.461 (0.351)	Data 0.00109 (0.00331)	Tok/s 72124 (74255)	Loss/tok 3.5122 (3.4034)	Learning Rate [0.00015625]
0: TRAIN [1][500/6832]	Time 0.479 (0.352)	Data 0.00105 (0.00326)	Tok/s 67677 (74151)	Loss/tok 3.5135 (3.4041)	Learning Rate [0.00015625]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][510/6832]	Time 0.402 (0.352)	Data 0.00025 (0.00407)	Tok/s 68832 (74030)	Loss/tok 3.3571 (3.4038)	Learning Rate [0.00015625]
0: TRAIN [1][520/6832]	Time 0.479 (0.353)	Data 0.00108 (0.00402)	Tok/s 72341 (74020)	Loss/tok 3.5298 (3.4034)	Learning Rate [0.00015625]
0: TRAIN [1][530/6832]	Time 0.304 (0.353)	Data 0.00107 (0.00396)	Tok/s 70652 (74012)	Loss/tok 3.4064 (3.4040)	Learning Rate [0.00015625]
0: TRAIN [1][540/6832]	Time 0.420 (0.352)	Data 0.00125 (0.00391)	Tok/s 65039 (74006)	Loss/tok 3.6003 (3.4030)	Learning Rate [0.00015625]
0: TRAIN [1][550/6832]	Time 0.232 (0.351)	Data 0.00101 (0.00385)	Tok/s 70656 (73971)	Loss/tok 3.2007 (3.4016)	Learning Rate [0.00015625]
0: TRAIN [1][560/6832]	Time 0.245 (0.351)	Data 0.00109 (0.00380)	Tok/s 73155 (73969)	Loss/tok 3.2474 (3.4013)	Learning Rate [0.00015625]
0: TRAIN [1][570/6832]	Time 0.465 (0.352)	Data 0.00100 (0.00376)	Tok/s 65694 (74000)	Loss/tok 3.5213 (3.4010)	Learning Rate [0.00015625]
0: TRAIN [1][580/6832]	Time 0.402 (0.352)	Data 0.00109 (0.00371)	Tok/s 67028 (74004)	Loss/tok 3.4339 (3.4002)	Learning Rate [0.00015625]
0: TRAIN [1][590/6832]	Time 0.134 (0.352)	Data 0.00112 (0.00366)	Tok/s 84206 (74005)	Loss/tok 2.8224 (3.4001)	Learning Rate [0.00015625]
0: TRAIN [1][600/6832]	Time 0.482 (0.352)	Data 0.00110 (0.00362)	Tok/s 78332 (74020)	Loss/tok 3.6010 (3.4005)	Learning Rate [0.00015625]
0: TRAIN [1][610/6832]	Time 0.319 (0.353)	Data 0.00105 (0.00358)	Tok/s 72221 (74063)	Loss/tok 3.3561 (3.3999)	Learning Rate [0.00015625]
0: TRAIN [1][620/6832]	Time 0.477 (0.353)	Data 0.00103 (0.00354)	Tok/s 75528 (74036)	Loss/tok 3.5782 (3.4004)	Learning Rate [0.00015625]
0: TRAIN [1][630/6832]	Time 0.421 (0.353)	Data 0.00106 (0.00350)	Tok/s 69343 (74024)	Loss/tok 3.4265 (3.4001)	Learning Rate [0.00015625]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][640/6832]	Time 0.285 (0.352)	Data 0.00115 (0.00346)	Tok/s 70955 (74006)	Loss/tok 3.3978 (3.3993)	Learning Rate [0.00015625]
0: TRAIN [1][650/6832]	Time 0.461 (0.352)	Data 0.00106 (0.00343)	Tok/s 70118 (74025)	Loss/tok 3.5151 (3.3999)	Learning Rate [0.00015625]
0: TRAIN [1][660/6832]	Time 0.237 (0.353)	Data 0.00110 (0.00339)	Tok/s 72242 (74096)	Loss/tok 3.1988 (3.3999)	Learning Rate [0.00015625]
0: TRAIN [1][670/6832]	Time 0.307 (0.353)	Data 0.00116 (0.00336)	Tok/s 71707 (74094)	Loss/tok 3.3753 (3.3993)	Learning Rate [0.00015625]
0: TRAIN [1][680/6832]	Time 0.485 (0.352)	Data 0.00104 (0.00332)	Tok/s 81684 (74123)	Loss/tok 3.4718 (3.3985)	Learning Rate [7.8125e-05]
0: TRAIN [1][690/6832]	Time 0.406 (0.353)	Data 0.00111 (0.00329)	Tok/s 64426 (74185)	Loss/tok 3.4905 (3.3976)	Learning Rate [7.8125e-05]
0: TRAIN [1][700/6832]	Time 0.483 (0.353)	Data 0.00103 (0.00326)	Tok/s 79710 (74188)	Loss/tok 3.5899 (3.3974)	Learning Rate [7.8125e-05]
0: TRAIN [1][710/6832]	Time 0.281 (0.353)	Data 0.00108 (0.00323)	Tok/s 72136 (74225)	Loss/tok 3.3063 (3.3971)	Learning Rate [7.8125e-05]
0: TRAIN [1][720/6832]	Time 0.203 (0.353)	Data 0.00105 (0.00320)	Tok/s 77285 (74204)	Loss/tok 3.1414 (3.3969)	Learning Rate [7.8125e-05]
0: TRAIN [1][730/6832]	Time 0.358 (0.352)	Data 0.00106 (0.00317)	Tok/s 67271 (74213)	Loss/tok 3.4305 (3.3958)	Learning Rate [7.8125e-05]
0: TRAIN [1][740/6832]	Time 0.237 (0.352)	Data 0.00107 (0.00314)	Tok/s 73593 (74230)	Loss/tok 3.2077 (3.3955)	Learning Rate [7.8125e-05]
0: TRAIN [1][750/6832]	Time 0.487 (0.352)	Data 0.00104 (0.00311)	Tok/s 95880 (74182)	Loss/tok 3.3063 (3.3953)	Learning Rate [7.8125e-05]
0: TRAIN [1][760/6832]	Time 0.160 (0.352)	Data 0.00105 (0.00308)	Tok/s 77639 (74167)	Loss/tok 2.9223 (3.3953)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][770/6832]	Time 0.482 (0.352)	Data 0.00104 (0.00306)	Tok/s 67902 (74200)	Loss/tok 3.4606 (3.3951)	Learning Rate [7.8125e-05]
0: TRAIN [1][780/6832]	Time 0.484 (0.353)	Data 0.00108 (0.00303)	Tok/s 70523 (74212)	Loss/tok 3.6349 (3.3958)	Learning Rate [7.8125e-05]
0: TRAIN [1][790/6832]	Time 0.184 (0.353)	Data 0.00110 (0.00301)	Tok/s 82396 (74257)	Loss/tok 3.1955 (3.3958)	Learning Rate [7.8125e-05]
0: TRAIN [1][800/6832]	Time 0.253 (0.352)	Data 0.00107 (0.00298)	Tok/s 71787 (74297)	Loss/tok 3.2724 (3.3954)	Learning Rate [7.8125e-05]
0: TRAIN [1][810/6832]	Time 0.480 (0.352)	Data 0.00102 (0.00296)	Tok/s 78465 (74313)	Loss/tok 3.4570 (3.3948)	Learning Rate [7.8125e-05]
0: TRAIN [1][820/6832]	Time 0.095 (0.352)	Data 0.00101 (0.00294)	Tok/s 60176 (74361)	Loss/tok 2.1326 (3.3944)	Learning Rate [7.8125e-05]
0: TRAIN [1][830/6832]	Time 0.484 (0.352)	Data 0.00104 (0.00291)	Tok/s 81922 (74353)	Loss/tok 3.3604 (3.3944)	Learning Rate [7.8125e-05]
0: TRAIN [1][840/6832]	Time 0.151 (0.353)	Data 0.00109 (0.00289)	Tok/s 79474 (74384)	Loss/tok 2.9497 (3.3940)	Learning Rate [7.8125e-05]
0: TRAIN [1][850/6832]	Time 0.400 (0.352)	Data 0.00103 (0.00287)	Tok/s 68105 (74375)	Loss/tok 3.3411 (3.3931)	Learning Rate [7.8125e-05]
0: TRAIN [1][860/6832]	Time 0.483 (0.353)	Data 0.00107 (0.00285)	Tok/s 76618 (74353)	Loss/tok 3.4114 (3.3935)	Learning Rate [7.8125e-05]
0: TRAIN [1][870/6832]	Time 0.362 (0.352)	Data 0.00103 (0.00283)	Tok/s 68307 (74371)	Loss/tok 3.4986 (3.3931)	Learning Rate [7.8125e-05]
0: TRAIN [1][880/6832]	Time 0.278 (0.352)	Data 0.00108 (0.00281)	Tok/s 73649 (74353)	Loss/tok 3.2420 (3.3934)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][890/6832]	Time 0.141 (0.352)	Data 0.00115 (0.00279)	Tok/s 79559 (74385)	Loss/tok 2.8621 (3.3928)	Learning Rate [7.8125e-05]
0: TRAIN [1][900/6832]	Time 0.480 (0.352)	Data 0.00098 (0.00277)	Tok/s 69508 (74358)	Loss/tok 3.6052 (3.3928)	Learning Rate [7.8125e-05]
0: TRAIN [1][910/6832]	Time 0.479 (0.351)	Data 0.00102 (0.00275)	Tok/s 73555 (74375)	Loss/tok 3.4261 (3.3919)	Learning Rate [7.8125e-05]
0: TRAIN [1][920/6832]	Time 0.294 (0.351)	Data 0.00106 (0.00273)	Tok/s 69002 (74350)	Loss/tok 3.3074 (3.3921)	Learning Rate [7.8125e-05]
0: TRAIN [1][930/6832]	Time 0.159 (0.350)	Data 0.00105 (0.00271)	Tok/s 81377 (74406)	Loss/tok 2.9622 (3.3907)	Learning Rate [7.8125e-05]
0: TRAIN [1][940/6832]	Time 0.197 (0.350)	Data 0.00105 (0.00269)	Tok/s 74763 (74391)	Loss/tok 3.0826 (3.3902)	Learning Rate [7.8125e-05]
0: TRAIN [1][950/6832]	Time 0.224 (0.350)	Data 0.00105 (0.00268)	Tok/s 74458 (74390)	Loss/tok 3.2073 (3.3900)	Learning Rate [7.8125e-05]
0: TRAIN [1][960/6832]	Time 0.200 (0.350)	Data 0.00107 (0.00266)	Tok/s 77652 (74402)	Loss/tok 3.0663 (3.3894)	Learning Rate [7.8125e-05]
0: TRAIN [1][970/6832]	Time 0.188 (0.349)	Data 0.00103 (0.00264)	Tok/s 74177 (74425)	Loss/tok 3.0650 (3.3888)	Learning Rate [7.8125e-05]
0: TRAIN [1][980/6832]	Time 0.253 (0.349)	Data 0.00106 (0.00263)	Tok/s 72900 (74417)	Loss/tok 3.3887 (3.3879)	Learning Rate [7.8125e-05]
0: TRAIN [1][990/6832]	Time 0.484 (0.349)	Data 0.00103 (0.00261)	Tok/s 85134 (74446)	Loss/tok 3.4047 (3.3876)	Learning Rate [7.8125e-05]
0: TRAIN [1][1000/6832]	Time 0.213 (0.349)	Data 0.00105 (0.00260)	Tok/s 75347 (74472)	Loss/tok 3.0517 (3.3874)	Learning Rate [7.8125e-05]
0: TRAIN [1][1010/6832]	Time 0.434 (0.348)	Data 0.00105 (0.00258)	Tok/s 64831 (74461)	Loss/tok 3.3610 (3.3867)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1020/6832]	Time 0.479 (0.348)	Data 0.00101 (0.00257)	Tok/s 79991 (74460)	Loss/tok 3.4978 (3.3864)	Learning Rate [7.8125e-05]
0: TRAIN [1][1030/6832]	Time 0.481 (0.347)	Data 0.00097 (0.00255)	Tok/s 77007 (74457)	Loss/tok 3.5230 (3.3861)	Learning Rate [7.8125e-05]
0: TRAIN [1][1040/6832]	Time 0.467 (0.348)	Data 0.00105 (0.00254)	Tok/s 78209 (74480)	Loss/tok 3.4863 (3.3862)	Learning Rate [7.8125e-05]
0: TRAIN [1][1050/6832]	Time 0.448 (0.348)	Data 0.00104 (0.00252)	Tok/s 63775 (74437)	Loss/tok 3.4361 (3.3864)	Learning Rate [7.8125e-05]
0: TRAIN [1][1060/6832]	Time 0.284 (0.348)	Data 0.00109 (0.00251)	Tok/s 72166 (74418)	Loss/tok 3.3307 (3.3866)	Learning Rate [7.8125e-05]
0: TRAIN [1][1070/6832]	Time 0.205 (0.348)	Data 0.00101 (0.00249)	Tok/s 74132 (74403)	Loss/tok 3.1765 (3.3862)	Learning Rate [7.8125e-05]
0: TRAIN [1][1080/6832]	Time 0.158 (0.348)	Data 0.00105 (0.00248)	Tok/s 78751 (74395)	Loss/tok 3.0048 (3.3864)	Learning Rate [7.8125e-05]
0: TRAIN [1][1090/6832]	Time 0.463 (0.348)	Data 0.00101 (0.00247)	Tok/s 84197 (74418)	Loss/tok 3.4006 (3.3861)	Learning Rate [7.8125e-05]
0: TRAIN [1][1100/6832]	Time 0.482 (0.348)	Data 0.00102 (0.00245)	Tok/s 84246 (74424)	Loss/tok 3.3630 (3.3864)	Learning Rate [7.8125e-05]
0: TRAIN [1][1110/6832]	Time 0.122 (0.349)	Data 0.00099 (0.00244)	Tok/s 86209 (74427)	Loss/tok 2.8004 (3.3863)	Learning Rate [7.8125e-05]
0: TRAIN [1][1120/6832]	Time 0.482 (0.349)	Data 0.00106 (0.00243)	Tok/s 68502 (74400)	Loss/tok 3.5837 (3.3863)	Learning Rate [7.8125e-05]
0: TRAIN [1][1130/6832]	Time 0.190 (0.348)	Data 0.00102 (0.00242)	Tok/s 78111 (74414)	Loss/tok 3.1660 (3.3853)	Learning Rate [7.8125e-05]
0: TRAIN [1][1140/6832]	Time 0.454 (0.348)	Data 0.00106 (0.00240)	Tok/s 64462 (74401)	Loss/tok 3.4825 (3.3854)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1150/6832]	Time 0.146 (0.348)	Data 0.00097 (0.00239)	Tok/s 76477 (74368)	Loss/tok 2.7517 (3.3858)	Learning Rate [7.8125e-05]
0: TRAIN [1][1160/6832]	Time 0.287 (0.349)	Data 0.00099 (0.00238)	Tok/s 73250 (74383)	Loss/tok 3.3189 (3.3859)	Learning Rate [7.8125e-05]
0: TRAIN [1][1170/6832]	Time 0.465 (0.349)	Data 0.00026 (0.00237)	Tok/s 66675 (74346)	Loss/tok 3.4415 (3.3858)	Learning Rate [7.8125e-05]
0: TRAIN [1][1180/6832]	Time 0.279 (0.349)	Data 0.00104 (0.00236)	Tok/s 74004 (74394)	Loss/tok 3.3144 (3.3853)	Learning Rate [7.8125e-05]
0: TRAIN [1][1190/6832]	Time 0.483 (0.349)	Data 0.00110 (0.00235)	Tok/s 70678 (74365)	Loss/tok 3.4820 (3.3856)	Learning Rate [7.8125e-05]
0: TRAIN [1][1200/6832]	Time 0.483 (0.349)	Data 0.00107 (0.00234)	Tok/s 77708 (74370)	Loss/tok 3.4196 (3.3851)	Learning Rate [7.8125e-05]
0: TRAIN [1][1210/6832]	Time 0.375 (0.349)	Data 0.00104 (0.00233)	Tok/s 66982 (74332)	Loss/tok 3.4403 (3.3850)	Learning Rate [7.8125e-05]
0: TRAIN [1][1220/6832]	Time 0.484 (0.349)	Data 0.00125 (0.00232)	Tok/s 85408 (74329)	Loss/tok 3.3875 (3.3850)	Learning Rate [7.8125e-05]
0: TRAIN [1][1230/6832]	Time 0.283 (0.349)	Data 0.00108 (0.00230)	Tok/s 75986 (74305)	Loss/tok 3.2825 (3.3844)	Learning Rate [7.8125e-05]
0: TRAIN [1][1240/6832]	Time 0.482 (0.348)	Data 0.00106 (0.00230)	Tok/s 72414 (74330)	Loss/tok 3.5272 (3.3839)	Learning Rate [7.8125e-05]
0: TRAIN [1][1250/6832]	Time 0.294 (0.348)	Data 0.00104 (0.00228)	Tok/s 73042 (74322)	Loss/tok 3.3084 (3.3837)	Learning Rate [7.8125e-05]
0: TRAIN [1][1260/6832]	Time 0.199 (0.348)	Data 0.00101 (0.00227)	Tok/s 79921 (74323)	Loss/tok 3.1312 (3.3835)	Learning Rate [7.8125e-05]
0: TRAIN [1][1270/6832]	Time 0.340 (0.348)	Data 0.00107 (0.00227)	Tok/s 68490 (74330)	Loss/tok 3.3296 (3.3840)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1280/6832]	Time 0.454 (0.348)	Data 0.00104 (0.00226)	Tok/s 64348 (74338)	Loss/tok 3.5153 (3.3837)	Learning Rate [7.8125e-05]
0: TRAIN [1][1290/6832]	Time 0.240 (0.348)	Data 0.00107 (0.00225)	Tok/s 71685 (74319)	Loss/tok 3.1425 (3.3832)	Learning Rate [7.8125e-05]
0: TRAIN [1][1300/6832]	Time 0.186 (0.347)	Data 0.00181 (0.00224)	Tok/s 77248 (74324)	Loss/tok 3.0469 (3.3826)	Learning Rate [7.8125e-05]
0: TRAIN [1][1310/6832]	Time 0.373 (0.347)	Data 0.00114 (0.00223)	Tok/s 69522 (74300)	Loss/tok 3.3861 (3.3824)	Learning Rate [7.8125e-05]
0: TRAIN [1][1320/6832]	Time 0.457 (0.347)	Data 0.00105 (0.00222)	Tok/s 66161 (74290)	Loss/tok 3.5369 (3.3820)	Learning Rate [7.8125e-05]
0: TRAIN [1][1330/6832]	Time 0.414 (0.347)	Data 0.00100 (0.00221)	Tok/s 70534 (74285)	Loss/tok 3.4473 (3.3817)	Learning Rate [7.8125e-05]
0: TRAIN [1][1340/6832]	Time 0.422 (0.347)	Data 0.00108 (0.00220)	Tok/s 67885 (74257)	Loss/tok 3.4907 (3.3822)	Learning Rate [7.8125e-05]
0: TRAIN [1][1350/6832]	Time 0.483 (0.347)	Data 0.00102 (0.00219)	Tok/s 91206 (74284)	Loss/tok 3.4541 (3.3819)	Learning Rate [7.8125e-05]
0: TRAIN [1][1360/6832]	Time 0.281 (0.347)	Data 0.00102 (0.00219)	Tok/s 71793 (74283)	Loss/tok 3.2698 (3.3815)	Learning Rate [7.8125e-05]
0: TRAIN [1][1370/6832]	Time 0.205 (0.346)	Data 0.00099 (0.00218)	Tok/s 76210 (74291)	Loss/tok 3.0970 (3.3812)	Learning Rate [7.8125e-05]
0: TRAIN [1][1380/6832]	Time 0.334 (0.346)	Data 0.00100 (0.00217)	Tok/s 73162 (74309)	Loss/tok 3.4543 (3.3812)	Learning Rate [7.8125e-05]
0: TRAIN [1][1390/6832]	Time 0.459 (0.346)	Data 0.00104 (0.00216)	Tok/s 72128 (74326)	Loss/tok 3.5224 (3.3806)	Learning Rate [7.8125e-05]
0: TRAIN [1][1400/6832]	Time 0.367 (0.346)	Data 0.00104 (0.00215)	Tok/s 67813 (74341)	Loss/tok 3.3266 (3.3803)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1410/6832]	Time 0.312 (0.345)	Data 0.00106 (0.00214)	Tok/s 70520 (74322)	Loss/tok 3.2236 (3.3801)	Learning Rate [7.8125e-05]
0: TRAIN [1][1420/6832]	Time 0.483 (0.346)	Data 0.00102 (0.00214)	Tok/s 82163 (74330)	Loss/tok 3.5885 (3.3802)	Learning Rate [7.8125e-05]
0: TRAIN [1][1430/6832]	Time 0.483 (0.346)	Data 0.00111 (0.00213)	Tok/s 86993 (74339)	Loss/tok 3.3444 (3.3799)	Learning Rate [7.8125e-05]
0: TRAIN [1][1440/6832]	Time 0.113 (0.346)	Data 0.00108 (0.00212)	Tok/s 75140 (74346)	Loss/tok 2.5221 (3.3802)	Learning Rate [7.8125e-05]
0: TRAIN [1][1450/6832]	Time 0.324 (0.346)	Data 0.00107 (0.00212)	Tok/s 68668 (74329)	Loss/tok 3.3355 (3.3800)	Learning Rate [7.8125e-05]
0: TRAIN [1][1460/6832]	Time 0.140 (0.345)	Data 0.00103 (0.00211)	Tok/s 69124 (74334)	Loss/tok 2.6767 (3.3795)	Learning Rate [7.8125e-05]
0: TRAIN [1][1470/6832]	Time 0.427 (0.346)	Data 0.00106 (0.00210)	Tok/s 66002 (74320)	Loss/tok 3.4317 (3.3793)	Learning Rate [7.8125e-05]
0: TRAIN [1][1480/6832]	Time 0.480 (0.346)	Data 0.00108 (0.00209)	Tok/s 77119 (74324)	Loss/tok 3.4207 (3.3793)	Learning Rate [7.8125e-05]
0: TRAIN [1][1490/6832]	Time 0.414 (0.346)	Data 0.00107 (0.00209)	Tok/s 67038 (74350)	Loss/tok 3.4253 (3.3789)	Learning Rate [7.8125e-05]
0: TRAIN [1][1500/6832]	Time 0.485 (0.347)	Data 0.00107 (0.00208)	Tok/s 86798 (74365)	Loss/tok 3.3904 (3.3789)	Learning Rate [7.8125e-05]
0: TRAIN [1][1510/6832]	Time 0.448 (0.347)	Data 0.00122 (0.00207)	Tok/s 69417 (74353)	Loss/tok 3.4790 (3.3790)	Learning Rate [7.8125e-05]
0: TRAIN [1][1520/6832]	Time 0.480 (0.347)	Data 0.00110 (0.00207)	Tok/s 82719 (74358)	Loss/tok 3.3948 (3.3786)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1530/6832]	Time 0.220 (0.347)	Data 0.00129 (0.00206)	Tok/s 75693 (74345)	Loss/tok 3.1647 (3.3786)	Learning Rate [7.8125e-05]
0: TRAIN [1][1540/6832]	Time 0.141 (0.347)	Data 0.00102 (0.00205)	Tok/s 79339 (74365)	Loss/tok 2.8312 (3.3784)	Learning Rate [7.8125e-05]
0: TRAIN [1][1550/6832]	Time 0.349 (0.347)	Data 0.00113 (0.00205)	Tok/s 69009 (74380)	Loss/tok 3.4004 (3.3784)	Learning Rate [7.8125e-05]
0: TRAIN [1][1560/6832]	Time 0.120 (0.347)	Data 0.00114 (0.00204)	Tok/s 69736 (74351)	Loss/tok 2.5270 (3.3784)	Learning Rate [7.8125e-05]
0: TRAIN [1][1570/6832]	Time 0.481 (0.348)	Data 0.00108 (0.00204)	Tok/s 101235 (74372)	Loss/tok 3.1874 (3.3782)	Learning Rate [7.8125e-05]
0: TRAIN [1][1580/6832]	Time 0.482 (0.348)	Data 0.00106 (0.00203)	Tok/s 71179 (74349)	Loss/tok 3.4692 (3.3784)	Learning Rate [7.8125e-05]
0: TRAIN [1][1590/6832]	Time 0.461 (0.348)	Data 0.00106 (0.00202)	Tok/s 75322 (74385)	Loss/tok 3.4774 (3.3782)	Learning Rate [7.8125e-05]
0: TRAIN [1][1600/6832]	Time 0.258 (0.348)	Data 0.00107 (0.00202)	Tok/s 73521 (74408)	Loss/tok 3.2593 (3.3778)	Learning Rate [7.8125e-05]
0: TRAIN [1][1610/6832]	Time 0.455 (0.348)	Data 0.00123 (0.00201)	Tok/s 70189 (74410)	Loss/tok 3.4992 (3.3775)	Learning Rate [7.8125e-05]
0: TRAIN [1][1620/6832]	Time 0.111 (0.348)	Data 0.00108 (0.00201)	Tok/s 75268 (74393)	Loss/tok 2.4663 (3.3771)	Learning Rate [7.8125e-05]
0: TRAIN [1][1630/6832]	Time 0.236 (0.348)	Data 0.00104 (0.00200)	Tok/s 78206 (74403)	Loss/tok 3.2626 (3.3770)	Learning Rate [7.8125e-05]
0: TRAIN [1][1640/6832]	Time 0.330 (0.348)	Data 0.00112 (0.00200)	Tok/s 70591 (74370)	Loss/tok 3.3491 (3.3770)	Learning Rate [7.8125e-05]
0: TRAIN [1][1650/6832]	Time 0.185 (0.349)	Data 0.00106 (0.00199)	Tok/s 79768 (74386)	Loss/tok 3.1067 (3.3769)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1660/6832]	Time 0.196 (0.349)	Data 0.00113 (0.00198)	Tok/s 77123 (74369)	Loss/tok 3.1008 (3.3771)	Learning Rate [7.8125e-05]
0: TRAIN [1][1670/6832]	Time 0.467 (0.349)	Data 0.00107 (0.00198)	Tok/s 90102 (74418)	Loss/tok 3.3863 (3.3767)	Learning Rate [7.8125e-05]
0: TRAIN [1][1680/6832]	Time 0.168 (0.348)	Data 0.00102 (0.00197)	Tok/s 77254 (74424)	Loss/tok 2.9987 (3.3763)	Learning Rate [7.8125e-05]
0: TRAIN [1][1690/6832]	Time 0.345 (0.349)	Data 0.00100 (0.00197)	Tok/s 70653 (74411)	Loss/tok 3.3204 (3.3762)	Learning Rate [7.8125e-05]
0: TRAIN [1][1700/6832]	Time 0.427 (0.348)	Data 0.00114 (0.00196)	Tok/s 66550 (74392)	Loss/tok 3.4176 (3.3759)	Learning Rate [7.8125e-05]
0: TRAIN [1][1710/6832]	Time 0.449 (0.348)	Data 0.00105 (0.00196)	Tok/s 67986 (74411)	Loss/tok 3.3816 (3.3752)	Learning Rate [7.8125e-05]
0: TRAIN [1][1720/6832]	Time 0.208 (0.349)	Data 0.00115 (0.00195)	Tok/s 75002 (74406)	Loss/tok 3.1947 (3.3755)	Learning Rate [7.8125e-05]
0: TRAIN [1][1730/6832]	Time 0.147 (0.349)	Data 0.00106 (0.00195)	Tok/s 75643 (74407)	Loss/tok 2.8264 (3.3751)	Learning Rate [7.8125e-05]
0: TRAIN [1][1740/6832]	Time 0.265 (0.349)	Data 0.00109 (0.00194)	Tok/s 73540 (74397)	Loss/tok 3.3022 (3.3749)	Learning Rate [7.8125e-05]
0: TRAIN [1][1750/6832]	Time 0.488 (0.349)	Data 0.00109 (0.00194)	Tok/s 99897 (74403)	Loss/tok 3.2396 (3.3747)	Learning Rate [7.8125e-05]
0: TRAIN [1][1760/6832]	Time 0.479 (0.349)	Data 0.00106 (0.00193)	Tok/s 67779 (74390)	Loss/tok 3.4325 (3.3748)	Learning Rate [7.8125e-05]
0: TRAIN [1][1770/6832]	Time 0.399 (0.349)	Data 0.00107 (0.00193)	Tok/s 68510 (74374)	Loss/tok 3.3254 (3.3743)	Learning Rate [7.8125e-05]
0: TRAIN [1][1780/6832]	Time 0.379 (0.348)	Data 0.00113 (0.00192)	Tok/s 67954 (74361)	Loss/tok 3.3277 (3.3739)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1790/6832]	Time 0.463 (0.349)	Data 0.00108 (0.00192)	Tok/s 84250 (74363)	Loss/tok 3.4629 (3.3739)	Learning Rate [7.8125e-05]
0: TRAIN [1][1800/6832]	Time 0.218 (0.348)	Data 0.00105 (0.00191)	Tok/s 75315 (74349)	Loss/tok 3.1477 (3.3739)	Learning Rate [7.8125e-05]
0: TRAIN [1][1810/6832]	Time 0.486 (0.349)	Data 0.00107 (0.00191)	Tok/s 83389 (74370)	Loss/tok 3.3745 (3.3738)	Learning Rate [7.8125e-05]
0: TRAIN [1][1820/6832]	Time 0.484 (0.349)	Data 0.00114 (0.00190)	Tok/s 87149 (74375)	Loss/tok 3.4258 (3.3735)	Learning Rate [7.8125e-05]
0: TRAIN [1][1830/6832]	Time 0.298 (0.349)	Data 0.00115 (0.00190)	Tok/s 70395 (74359)	Loss/tok 3.3440 (3.3736)	Learning Rate [7.8125e-05]
0: TRAIN [1][1840/6832]	Time 0.415 (0.349)	Data 0.00110 (0.00190)	Tok/s 66616 (74350)	Loss/tok 3.4596 (3.3735)	Learning Rate [7.8125e-05]
0: TRAIN [1][1850/6832]	Time 0.471 (0.348)	Data 0.00103 (0.00189)	Tok/s 70389 (74348)	Loss/tok 3.5958 (3.3731)	Learning Rate [7.8125e-05]
0: TRAIN [1][1860/6832]	Time 0.157 (0.348)	Data 0.00108 (0.00189)	Tok/s 75570 (74367)	Loss/tok 2.8205 (3.3725)	Learning Rate [7.8125e-05]
0: TRAIN [1][1870/6832]	Time 0.290 (0.348)	Data 0.00116 (0.00188)	Tok/s 77119 (74372)	Loss/tok 3.4069 (3.3723)	Learning Rate [7.8125e-05]
0: TRAIN [1][1880/6832]	Time 0.147 (0.348)	Data 0.00109 (0.00188)	Tok/s 76158 (74362)	Loss/tok 2.8259 (3.3721)	Learning Rate [7.8125e-05]
0: TRAIN [1][1890/6832]	Time 0.481 (0.348)	Data 0.00122 (0.00187)	Tok/s 79504 (74378)	Loss/tok 3.4296 (3.3720)	Learning Rate [7.8125e-05]
0: TRAIN [1][1900/6832]	Time 0.476 (0.348)	Data 0.00100 (0.00187)	Tok/s 61910 (74349)	Loss/tok 3.4945 (3.3722)	Learning Rate [7.8125e-05]
0: TRAIN [1][1910/6832]	Time 0.315 (0.348)	Data 0.00109 (0.00187)	Tok/s 70637 (74336)	Loss/tok 3.2458 (3.3720)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][1920/6832]	Time 0.197 (0.348)	Data 0.00104 (0.00186)	Tok/s 76971 (74327)	Loss/tok 3.1022 (3.3715)	Learning Rate [7.8125e-05]
0: TRAIN [1][1930/6832]	Time 0.233 (0.348)	Data 0.00105 (0.00186)	Tok/s 70372 (74307)	Loss/tok 3.1872 (3.3713)	Learning Rate [7.8125e-05]
0: TRAIN [1][1940/6832]	Time 0.389 (0.348)	Data 0.00108 (0.00185)	Tok/s 67285 (74306)	Loss/tok 3.3223 (3.3710)	Learning Rate [7.8125e-05]
0: TRAIN [1][1950/6832]	Time 0.141 (0.348)	Data 0.00104 (0.00185)	Tok/s 79671 (74309)	Loss/tok 2.7864 (3.3708)	Learning Rate [7.8125e-05]
0: TRAIN [1][1960/6832]	Time 0.337 (0.347)	Data 0.00102 (0.00186)	Tok/s 69491 (74307)	Loss/tok 3.2802 (3.3705)	Learning Rate [7.8125e-05]
0: TRAIN [1][1970/6832]	Time 0.375 (0.348)	Data 0.00107 (0.00186)	Tok/s 68184 (74308)	Loss/tok 3.3140 (3.3702)	Learning Rate [7.8125e-05]
0: TRAIN [1][1980/6832]	Time 0.461 (0.347)	Data 0.00100 (0.00185)	Tok/s 78209 (74343)	Loss/tok 3.3860 (3.3694)	Learning Rate [7.8125e-05]
0: TRAIN [1][1990/6832]	Time 0.156 (0.347)	Data 0.00101 (0.00185)	Tok/s 79939 (74345)	Loss/tok 2.8825 (3.3692)	Learning Rate [7.8125e-05]
0: TRAIN [1][2000/6832]	Time 0.400 (0.347)	Data 0.00110 (0.00184)	Tok/s 67542 (74335)	Loss/tok 3.3960 (3.3692)	Learning Rate [7.8125e-05]
0: TRAIN [1][2010/6832]	Time 0.144 (0.347)	Data 0.00099 (0.00184)	Tok/s 77081 (74353)	Loss/tok 2.7831 (3.3688)	Learning Rate [7.8125e-05]
0: TRAIN [1][2020/6832]	Time 0.467 (0.347)	Data 0.00101 (0.00184)	Tok/s 63628 (74335)	Loss/tok 3.4761 (3.3684)	Learning Rate [7.8125e-05]
0: TRAIN [1][2030/6832]	Time 0.404 (0.347)	Data 0.00108 (0.00183)	Tok/s 65851 (74326)	Loss/tok 3.4527 (3.3687)	Learning Rate [7.8125e-05]
0: TRAIN [1][2040/6832]	Time 0.206 (0.347)	Data 0.00102 (0.00183)	Tok/s 73916 (74334)	Loss/tok 3.1341 (3.3683)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2050/6832]	Time 0.201 (0.347)	Data 0.00110 (0.00182)	Tok/s 76057 (74334)	Loss/tok 3.0750 (3.3682)	Learning Rate [7.8125e-05]
0: TRAIN [1][2060/6832]	Time 0.399 (0.347)	Data 0.00109 (0.00182)	Tok/s 67984 (74338)	Loss/tok 3.4299 (3.3682)	Learning Rate [7.8125e-05]
0: TRAIN [1][2070/6832]	Time 0.339 (0.347)	Data 0.00104 (0.00182)	Tok/s 67202 (74328)	Loss/tok 3.4001 (3.3681)	Learning Rate [7.8125e-05]
0: TRAIN [1][2080/6832]	Time 0.270 (0.347)	Data 0.00103 (0.00181)	Tok/s 71090 (74314)	Loss/tok 3.2946 (3.3679)	Learning Rate [7.8125e-05]
0: TRAIN [1][2090/6832]	Time 0.557 (0.347)	Data 0.07478 (0.00184)	Tok/s 87457 (74317)	Loss/tok 3.2122 (3.3676)	Learning Rate [7.8125e-05]
0: TRAIN [1][2100/6832]	Time 0.407 (0.347)	Data 0.00102 (0.00184)	Tok/s 67956 (74301)	Loss/tok 3.4623 (3.3674)	Learning Rate [7.8125e-05]
0: TRAIN [1][2110/6832]	Time 0.255 (0.347)	Data 0.00111 (0.00184)	Tok/s 71650 (74292)	Loss/tok 3.1810 (3.3677)	Learning Rate [7.8125e-05]
0: TRAIN [1][2120/6832]	Time 0.400 (0.347)	Data 0.00103 (0.00183)	Tok/s 69352 (74270)	Loss/tok 3.4534 (3.3674)	Learning Rate [7.8125e-05]
0: TRAIN [1][2130/6832]	Time 0.273 (0.347)	Data 0.00100 (0.00183)	Tok/s 73275 (74266)	Loss/tok 3.2529 (3.3671)	Learning Rate [7.8125e-05]
0: TRAIN [1][2140/6832]	Time 0.464 (0.347)	Data 0.00106 (0.00183)	Tok/s 76013 (74264)	Loss/tok 3.4634 (3.3669)	Learning Rate [7.8125e-05]
0: TRAIN [1][2150/6832]	Time 0.407 (0.347)	Data 0.00104 (0.00182)	Tok/s 70089 (74253)	Loss/tok 3.3935 (3.3670)	Learning Rate [7.8125e-05]
0: TRAIN [1][2160/6832]	Time 0.482 (0.347)	Data 0.00113 (0.00182)	Tok/s 74908 (74248)	Loss/tok 3.4839 (3.3668)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2170/6832]	Time 0.481 (0.347)	Data 0.00110 (0.00182)	Tok/s 81449 (74255)	Loss/tok 3.4785 (3.3668)	Learning Rate [7.8125e-05]
0: TRAIN [1][2180/6832]	Time 0.257 (0.347)	Data 0.00102 (0.00181)	Tok/s 74606 (74262)	Loss/tok 3.1891 (3.3665)	Learning Rate [7.8125e-05]
0: TRAIN [1][2190/6832]	Time 0.348 (0.347)	Data 0.00102 (0.00181)	Tok/s 69121 (74258)	Loss/tok 3.3049 (3.3662)	Learning Rate [7.8125e-05]
0: TRAIN [1][2200/6832]	Time 0.182 (0.347)	Data 0.00105 (0.00181)	Tok/s 78664 (74269)	Loss/tok 3.0923 (3.3661)	Learning Rate [7.8125e-05]
0: TRAIN [1][2210/6832]	Time 0.448 (0.347)	Data 0.00111 (0.00180)	Tok/s 64681 (74259)	Loss/tok 3.3856 (3.3661)	Learning Rate [7.8125e-05]
0: TRAIN [1][2220/6832]	Time 0.280 (0.347)	Data 0.00109 (0.00180)	Tok/s 68488 (74256)	Loss/tok 3.1837 (3.3658)	Learning Rate [7.8125e-05]
0: TRAIN [1][2230/6832]	Time 0.434 (0.347)	Data 0.00109 (0.00180)	Tok/s 69249 (74243)	Loss/tok 3.4597 (3.3660)	Learning Rate [7.8125e-05]
0: TRAIN [1][2240/6832]	Time 0.135 (0.347)	Data 0.00134 (0.00179)	Tok/s 77881 (74242)	Loss/tok 2.7502 (3.3661)	Learning Rate [7.8125e-05]
0: TRAIN [1][2250/6832]	Time 0.456 (0.347)	Data 0.00101 (0.00179)	Tok/s 70729 (74255)	Loss/tok 3.5163 (3.3659)	Learning Rate [7.8125e-05]
0: TRAIN [1][2260/6832]	Time 0.300 (0.347)	Data 0.00102 (0.00179)	Tok/s 73395 (74243)	Loss/tok 3.2494 (3.3655)	Learning Rate [7.8125e-05]
0: TRAIN [1][2270/6832]	Time 0.130 (0.347)	Data 0.00104 (0.00178)	Tok/s 81342 (74254)	Loss/tok 2.8310 (3.3650)	Learning Rate [7.8125e-05]
0: TRAIN [1][2280/6832]	Time 0.186 (0.347)	Data 0.00116 (0.00178)	Tok/s 77136 (74245)	Loss/tok 3.0143 (3.3651)	Learning Rate [7.8125e-05]
0: TRAIN [1][2290/6832]	Time 0.323 (0.347)	Data 0.00103 (0.00178)	Tok/s 70175 (74238)	Loss/tok 3.3354 (3.3651)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2300/6832]	Time 0.475 (0.347)	Data 0.00106 (0.00177)	Tok/s 67537 (74268)	Loss/tok 3.4279 (3.3646)	Learning Rate [7.8125e-05]
0: TRAIN [1][2310/6832]	Time 0.227 (0.347)	Data 0.00098 (0.00177)	Tok/s 74992 (74253)	Loss/tok 3.1613 (3.3644)	Learning Rate [7.8125e-05]
0: TRAIN [1][2320/6832]	Time 0.478 (0.347)	Data 0.00121 (0.00177)	Tok/s 71586 (74258)	Loss/tok 3.3964 (3.3642)	Learning Rate [7.8125e-05]
0: TRAIN [1][2330/6832]	Time 0.263 (0.347)	Data 0.00103 (0.00176)	Tok/s 73939 (74266)	Loss/tok 3.1660 (3.3640)	Learning Rate [7.8125e-05]
0: TRAIN [1][2340/6832]	Time 0.193 (0.347)	Data 0.00104 (0.00176)	Tok/s 76919 (74279)	Loss/tok 3.1184 (3.3638)	Learning Rate [7.8125e-05]
0: TRAIN [1][2350/6832]	Time 0.456 (0.347)	Data 0.00108 (0.00176)	Tok/s 64581 (74279)	Loss/tok 3.4210 (3.3636)	Learning Rate [7.8125e-05]
0: TRAIN [1][2360/6832]	Time 0.355 (0.347)	Data 0.00102 (0.00176)	Tok/s 67778 (74267)	Loss/tok 3.3693 (3.3634)	Learning Rate [7.8125e-05]
0: TRAIN [1][2370/6832]	Time 0.248 (0.347)	Data 0.00117 (0.00175)	Tok/s 72169 (74265)	Loss/tok 3.1488 (3.3631)	Learning Rate [7.8125e-05]
0: TRAIN [1][2380/6832]	Time 0.351 (0.347)	Data 0.00102 (0.00175)	Tok/s 66740 (74280)	Loss/tok 3.3061 (3.3628)	Learning Rate [7.8125e-05]
0: TRAIN [1][2390/6832]	Time 0.109 (0.347)	Data 0.00112 (0.00175)	Tok/s 75910 (74275)	Loss/tok 2.4136 (3.3626)	Learning Rate [7.8125e-05]
0: TRAIN [1][2400/6832]	Time 0.148 (0.347)	Data 0.00104 (0.00174)	Tok/s 80408 (74281)	Loss/tok 2.8623 (3.3623)	Learning Rate [7.8125e-05]
0: TRAIN [1][2410/6832]	Time 0.313 (0.347)	Data 0.00105 (0.00174)	Tok/s 70328 (74269)	Loss/tok 3.1767 (3.3621)	Learning Rate [7.8125e-05]
0: TRAIN [1][2420/6832]	Time 0.379 (0.347)	Data 0.00103 (0.00174)	Tok/s 70295 (74270)	Loss/tok 3.2968 (3.3620)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2430/6832]	Time 0.381 (0.347)	Data 0.00102 (0.00174)	Tok/s 69472 (74252)	Loss/tok 3.3660 (3.3622)	Learning Rate [7.8125e-05]
0: TRAIN [1][2440/6832]	Time 0.396 (0.347)	Data 0.00107 (0.00173)	Tok/s 65287 (74253)	Loss/tok 3.4043 (3.3619)	Learning Rate [7.8125e-05]
0: TRAIN [1][2450/6832]	Time 0.332 (0.347)	Data 0.00105 (0.00173)	Tok/s 69490 (74248)	Loss/tok 3.3087 (3.3616)	Learning Rate [7.8125e-05]
0: TRAIN [1][2460/6832]	Time 0.451 (0.347)	Data 0.00103 (0.00173)	Tok/s 64108 (74255)	Loss/tok 3.3490 (3.3614)	Learning Rate [7.8125e-05]
0: TRAIN [1][2470/6832]	Time 0.397 (0.347)	Data 0.00104 (0.00173)	Tok/s 68408 (74261)	Loss/tok 3.3501 (3.3614)	Learning Rate [7.8125e-05]
0: TRAIN [1][2480/6832]	Time 0.477 (0.347)	Data 0.00108 (0.00172)	Tok/s 65848 (74258)	Loss/tok 3.4218 (3.3614)	Learning Rate [7.8125e-05]
0: TRAIN [1][2490/6832]	Time 0.475 (0.347)	Data 0.00110 (0.00172)	Tok/s 67989 (74257)	Loss/tok 3.5366 (3.3616)	Learning Rate [7.8125e-05]
0: TRAIN [1][2500/6832]	Time 0.485 (0.347)	Data 0.00108 (0.00172)	Tok/s 88835 (74257)	Loss/tok 3.3559 (3.3614)	Learning Rate [7.8125e-05]
0: TRAIN [1][2510/6832]	Time 0.485 (0.347)	Data 0.00100 (0.00172)	Tok/s 91250 (74253)	Loss/tok 3.3147 (3.3614)	Learning Rate [7.8125e-05]
0: TRAIN [1][2520/6832]	Time 0.265 (0.347)	Data 0.00100 (0.00171)	Tok/s 73701 (74245)	Loss/tok 3.1327 (3.3610)	Learning Rate [7.8125e-05]
0: TRAIN [1][2530/6832]	Time 0.484 (0.347)	Data 0.00111 (0.00171)	Tok/s 77889 (74250)	Loss/tok 3.4067 (3.3609)	Learning Rate [7.8125e-05]
0: TRAIN [1][2540/6832]	Time 0.482 (0.347)	Data 0.00103 (0.00171)	Tok/s 81199 (74282)	Loss/tok 3.4008 (3.3606)	Learning Rate [7.8125e-05]
0: TRAIN [1][2550/6832]	Time 0.466 (0.347)	Data 0.00107 (0.00170)	Tok/s 64809 (74263)	Loss/tok 3.4573 (3.3606)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2560/6832]	Time 0.484 (0.348)	Data 0.00099 (0.00170)	Tok/s 93395 (74271)	Loss/tok 3.3231 (3.3604)	Learning Rate [7.8125e-05]
0: TRAIN [1][2570/6832]	Time 0.271 (0.347)	Data 0.00101 (0.00170)	Tok/s 70537 (74265)	Loss/tok 3.2510 (3.3600)	Learning Rate [7.8125e-05]
0: TRAIN [1][2580/6832]	Time 0.421 (0.347)	Data 0.00101 (0.00170)	Tok/s 67590 (74255)	Loss/tok 3.4177 (3.3601)	Learning Rate [7.8125e-05]
0: TRAIN [1][2590/6832]	Time 0.485 (0.347)	Data 0.00104 (0.00169)	Tok/s 85365 (74248)	Loss/tok 3.3817 (3.3599)	Learning Rate [7.8125e-05]
0: TRAIN [1][2600/6832]	Time 0.308 (0.347)	Data 0.00105 (0.00169)	Tok/s 70202 (74248)	Loss/tok 3.2930 (3.3596)	Learning Rate [7.8125e-05]
0: TRAIN [1][2610/6832]	Time 0.433 (0.347)	Data 0.00100 (0.00169)	Tok/s 66097 (74230)	Loss/tok 3.4222 (3.3594)	Learning Rate [7.8125e-05]
0: TRAIN [1][2620/6832]	Time 0.225 (0.347)	Data 0.00101 (0.00169)	Tok/s 73954 (74239)	Loss/tok 3.0533 (3.3590)	Learning Rate [7.8125e-05]
0: TRAIN [1][2630/6832]	Time 0.407 (0.347)	Data 0.00101 (0.00169)	Tok/s 67949 (74232)	Loss/tok 3.3955 (3.3587)	Learning Rate [7.8125e-05]
0: TRAIN [1][2640/6832]	Time 0.478 (0.347)	Data 0.00106 (0.00168)	Tok/s 84322 (74248)	Loss/tok 3.4033 (3.3586)	Learning Rate [7.8125e-05]
0: TRAIN [1][2650/6832]	Time 0.480 (0.347)	Data 0.00100 (0.00168)	Tok/s 74947 (74262)	Loss/tok 3.3995 (3.3586)	Learning Rate [7.8125e-05]
0: TRAIN [1][2660/6832]	Time 0.482 (0.347)	Data 0.00104 (0.00168)	Tok/s 80971 (74264)	Loss/tok 3.3851 (3.3585)	Learning Rate [7.8125e-05]
0: TRAIN [1][2670/6832]	Time 0.253 (0.347)	Data 0.00111 (0.00168)	Tok/s 74732 (74252)	Loss/tok 3.2354 (3.3585)	Learning Rate [7.8125e-05]
0: TRAIN [1][2680/6832]	Time 0.404 (0.347)	Data 0.00111 (0.00167)	Tok/s 65839 (74256)	Loss/tok 3.3833 (3.3583)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2690/6832]	Time 0.355 (0.347)	Data 0.00105 (0.00167)	Tok/s 71055 (74255)	Loss/tok 3.2903 (3.3578)	Learning Rate [7.8125e-05]
0: TRAIN [1][2700/6832]	Time 0.475 (0.347)	Data 0.00105 (0.00167)	Tok/s 70154 (74253)	Loss/tok 3.3788 (3.3577)	Learning Rate [7.8125e-05]
0: TRAIN [1][2710/6832]	Time 0.293 (0.347)	Data 0.00107 (0.00167)	Tok/s 73547 (74259)	Loss/tok 3.2711 (3.3573)	Learning Rate [7.8125e-05]
0: TRAIN [1][2720/6832]	Time 0.405 (0.347)	Data 0.00099 (0.00166)	Tok/s 69469 (74259)	Loss/tok 3.3911 (3.3571)	Learning Rate [7.8125e-05]
0: TRAIN [1][2730/6832]	Time 0.228 (0.347)	Data 0.00104 (0.00166)	Tok/s 75311 (74252)	Loss/tok 3.1320 (3.3569)	Learning Rate [7.8125e-05]
0: TRAIN [1][2740/6832]	Time 0.404 (0.347)	Data 0.00100 (0.00166)	Tok/s 66643 (74244)	Loss/tok 3.4164 (3.3567)	Learning Rate [7.8125e-05]
0: TRAIN [1][2750/6832]	Time 0.387 (0.347)	Data 0.00108 (0.00166)	Tok/s 68836 (74246)	Loss/tok 3.4063 (3.3565)	Learning Rate [7.8125e-05]
0: TRAIN [1][2760/6832]	Time 0.470 (0.347)	Data 0.00107 (0.00166)	Tok/s 70710 (74239)	Loss/tok 3.4577 (3.3563)	Learning Rate [7.8125e-05]
0: TRAIN [1][2770/6832]	Time 0.481 (0.347)	Data 0.00106 (0.00165)	Tok/s 75676 (74232)	Loss/tok 3.5071 (3.3564)	Learning Rate [7.8125e-05]
0: TRAIN [1][2780/6832]	Time 0.171 (0.347)	Data 0.00107 (0.00165)	Tok/s 78612 (74229)	Loss/tok 3.0578 (3.3564)	Learning Rate [7.8125e-05]
0: TRAIN [1][2790/6832]	Time 0.374 (0.347)	Data 0.00104 (0.00165)	Tok/s 68887 (74223)	Loss/tok 3.2954 (3.3561)	Learning Rate [7.8125e-05]
0: TRAIN [1][2800/6832]	Time 0.421 (0.347)	Data 0.00106 (0.00165)	Tok/s 68628 (74228)	Loss/tok 3.3499 (3.3558)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2810/6832]	Time 0.489 (0.347)	Data 0.00115 (0.00165)	Tok/s 90242 (74242)	Loss/tok 3.3523 (3.3555)	Learning Rate [7.8125e-05]
0: TRAIN [1][2820/6832]	Time 0.183 (0.347)	Data 0.00106 (0.00164)	Tok/s 78788 (74228)	Loss/tok 2.9933 (3.3554)	Learning Rate [7.8125e-05]
0: TRAIN [1][2830/6832]	Time 0.483 (0.347)	Data 0.00107 (0.00164)	Tok/s 87122 (74230)	Loss/tok 3.3620 (3.3553)	Learning Rate [7.8125e-05]
0: TRAIN [1][2840/6832]	Time 0.400 (0.346)	Data 0.00107 (0.00164)	Tok/s 65474 (74231)	Loss/tok 3.3766 (3.3548)	Learning Rate [7.8125e-05]
0: TRAIN [1][2850/6832]	Time 0.368 (0.346)	Data 0.00113 (0.00164)	Tok/s 67231 (74221)	Loss/tok 3.3713 (3.3547)	Learning Rate [7.8125e-05]
0: TRAIN [1][2860/6832]	Time 0.343 (0.346)	Data 0.00106 (0.00164)	Tok/s 70085 (74227)	Loss/tok 3.4558 (3.3544)	Learning Rate [7.8125e-05]
0: TRAIN [1][2870/6832]	Time 0.464 (0.347)	Data 0.00136 (0.00163)	Tok/s 62932 (74214)	Loss/tok 3.3219 (3.3543)	Learning Rate [7.8125e-05]
0: TRAIN [1][2880/6832]	Time 0.316 (0.347)	Data 0.00107 (0.00163)	Tok/s 69724 (74202)	Loss/tok 3.3670 (3.3542)	Learning Rate [7.8125e-05]
0: TRAIN [1][2890/6832]	Time 0.220 (0.346)	Data 0.00111 (0.00163)	Tok/s 72803 (74200)	Loss/tok 3.1247 (3.3540)	Learning Rate [7.8125e-05]
0: TRAIN [1][2900/6832]	Time 0.109 (0.346)	Data 0.00103 (0.00163)	Tok/s 77153 (74186)	Loss/tok 2.4867 (3.3539)	Learning Rate [7.8125e-05]
0: TRAIN [1][2910/6832]	Time 0.410 (0.347)	Data 0.00105 (0.00163)	Tok/s 66727 (74186)	Loss/tok 3.3423 (3.3539)	Learning Rate [7.8125e-05]
0: TRAIN [1][2920/6832]	Time 0.386 (0.347)	Data 0.00100 (0.00162)	Tok/s 67670 (74175)	Loss/tok 3.2339 (3.3537)	Learning Rate [7.8125e-05]
0: TRAIN [1][2930/6832]	Time 0.465 (0.347)	Data 0.00099 (0.00162)	Tok/s 72410 (74174)	Loss/tok 3.3970 (3.3537)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][2940/6832]	Time 0.483 (0.347)	Data 0.00098 (0.00162)	Tok/s 82544 (74194)	Loss/tok 3.3446 (3.3533)	Learning Rate [7.8125e-05]
0: TRAIN [1][2950/6832]	Time 0.482 (0.347)	Data 0.00100 (0.00162)	Tok/s 77111 (74194)	Loss/tok 3.3834 (3.3528)	Learning Rate [7.8125e-05]
0: TRAIN [1][2960/6832]	Time 0.463 (0.346)	Data 0.00105 (0.00162)	Tok/s 76255 (74202)	Loss/tok 3.4916 (3.3528)	Learning Rate [7.8125e-05]
0: TRAIN [1][2970/6832]	Time 0.432 (0.347)	Data 0.00101 (0.00161)	Tok/s 66414 (74204)	Loss/tok 3.4317 (3.3527)	Learning Rate [7.8125e-05]
0: TRAIN [1][2980/6832]	Time 0.470 (0.347)	Data 0.00106 (0.00161)	Tok/s 67442 (74202)	Loss/tok 3.3802 (3.3525)	Learning Rate [7.8125e-05]
0: TRAIN [1][2990/6832]	Time 0.274 (0.346)	Data 0.00095 (0.00161)	Tok/s 71536 (74196)	Loss/tok 3.1937 (3.3522)	Learning Rate [7.8125e-05]
0: TRAIN [1][3000/6832]	Time 0.468 (0.346)	Data 0.00097 (0.00161)	Tok/s 66324 (74189)	Loss/tok 3.3799 (3.3520)	Learning Rate [7.8125e-05]
0: TRAIN [1][3010/6832]	Time 0.238 (0.346)	Data 0.00106 (0.00161)	Tok/s 73001 (74186)	Loss/tok 3.1626 (3.3517)	Learning Rate [7.8125e-05]
0: TRAIN [1][3020/6832]	Time 0.218 (0.346)	Data 0.00100 (0.00161)	Tok/s 73023 (74214)	Loss/tok 3.0454 (3.3512)	Learning Rate [7.8125e-05]
0: TRAIN [1][3030/6832]	Time 0.421 (0.346)	Data 0.00114 (0.00160)	Tok/s 67845 (74220)	Loss/tok 3.3538 (3.3511)	Learning Rate [7.8125e-05]
0: TRAIN [1][3040/6832]	Time 0.344 (0.346)	Data 0.00129 (0.00160)	Tok/s 69896 (74216)	Loss/tok 3.2339 (3.3509)	Learning Rate [7.8125e-05]
0: TRAIN [1][3050/6832]	Time 0.263 (0.346)	Data 0.00102 (0.00160)	Tok/s 74481 (74222)	Loss/tok 3.2315 (3.3507)	Learning Rate [7.8125e-05]
0: TRAIN [1][3060/6832]	Time 0.425 (0.346)	Data 0.00100 (0.00160)	Tok/s 66003 (74225)	Loss/tok 3.3406 (3.3504)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3070/6832]	Time 0.481 (0.346)	Data 0.00099 (0.00160)	Tok/s 70263 (74239)	Loss/tok 3.3860 (3.3503)	Learning Rate [7.8125e-05]
0: TRAIN [1][3080/6832]	Time 0.293 (0.347)	Data 0.00107 (0.00160)	Tok/s 73034 (74240)	Loss/tok 3.2117 (3.3504)	Learning Rate [7.8125e-05]
0: TRAIN [1][3090/6832]	Time 0.474 (0.347)	Data 0.00101 (0.00159)	Tok/s 72229 (74244)	Loss/tok 3.3601 (3.3502)	Learning Rate [7.8125e-05]
0: TRAIN [1][3100/6832]	Time 0.474 (0.346)	Data 0.00108 (0.00159)	Tok/s 72173 (74242)	Loss/tok 3.4054 (3.3500)	Learning Rate [7.8125e-05]
0: TRAIN [1][3110/6832]	Time 0.475 (0.347)	Data 0.00112 (0.00159)	Tok/s 78123 (74236)	Loss/tok 3.4407 (3.3500)	Learning Rate [7.8125e-05]
0: TRAIN [1][3120/6832]	Time 0.474 (0.346)	Data 0.00100 (0.00159)	Tok/s 65381 (74224)	Loss/tok 3.4628 (3.3499)	Learning Rate [7.8125e-05]
0: TRAIN [1][3130/6832]	Time 0.469 (0.347)	Data 0.00100 (0.00159)	Tok/s 69927 (74221)	Loss/tok 3.3681 (3.3498)	Learning Rate [7.8125e-05]
0: TRAIN [1][3140/6832]	Time 0.465 (0.347)	Data 0.00099 (0.00159)	Tok/s 84159 (74225)	Loss/tok 3.3613 (3.3496)	Learning Rate [7.8125e-05]
0: TRAIN [1][3150/6832]	Time 0.300 (0.347)	Data 0.00022 (0.00185)	Tok/s 70073 (74214)	Loss/tok 3.3016 (3.3493)	Learning Rate [7.8125e-05]
0: TRAIN [1][3160/6832]	Time 0.461 (0.347)	Data 0.00105 (0.00185)	Tok/s 66005 (74208)	Loss/tok 3.3664 (3.3491)	Learning Rate [7.8125e-05]
0: TRAIN [1][3170/6832]	Time 0.483 (0.347)	Data 0.00100 (0.00185)	Tok/s 87417 (74215)	Loss/tok 3.3665 (3.3488)	Learning Rate [7.8125e-05]
0: TRAIN [1][3180/6832]	Time 0.479 (0.347)	Data 0.00106 (0.00185)	Tok/s 74814 (74211)	Loss/tok 3.4258 (3.3488)	Learning Rate [7.8125e-05]
0: TRAIN [1][3190/6832]	Time 0.467 (0.347)	Data 0.00110 (0.00184)	Tok/s 82142 (74213)	Loss/tok 3.4131 (3.3489)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3200/6832]	Time 0.379 (0.347)	Data 0.00106 (0.00184)	Tok/s 66125 (74206)	Loss/tok 3.3994 (3.3486)	Learning Rate [7.8125e-05]
0: TRAIN [1][3210/6832]	Time 0.487 (0.347)	Data 0.00116 (0.00184)	Tok/s 95576 (74217)	Loss/tok 3.2224 (3.3483)	Learning Rate [7.8125e-05]
0: TRAIN [1][3220/6832]	Time 0.363 (0.347)	Data 0.00098 (0.00184)	Tok/s 71836 (74223)	Loss/tok 3.3607 (3.3480)	Learning Rate [7.8125e-05]
0: TRAIN [1][3230/6832]	Time 0.463 (0.347)	Data 0.00100 (0.00184)	Tok/s 95409 (74240)	Loss/tok 3.2769 (3.3476)	Learning Rate [7.8125e-05]
0: TRAIN [1][3240/6832]	Time 0.356 (0.347)	Data 0.00104 (0.00183)	Tok/s 68983 (74244)	Loss/tok 3.2860 (3.3475)	Learning Rate [7.8125e-05]
0: TRAIN [1][3250/6832]	Time 0.272 (0.347)	Data 0.00104 (0.00183)	Tok/s 71424 (74238)	Loss/tok 3.0466 (3.3473)	Learning Rate [7.8125e-05]
0: TRAIN [1][3260/6832]	Time 0.213 (0.347)	Data 0.00105 (0.00183)	Tok/s 72738 (74245)	Loss/tok 3.0294 (3.3471)	Learning Rate [7.8125e-05]
0: TRAIN [1][3270/6832]	Time 0.454 (0.347)	Data 0.00109 (0.00183)	Tok/s 65247 (74235)	Loss/tok 3.3489 (3.3471)	Learning Rate [7.8125e-05]
0: TRAIN [1][3280/6832]	Time 0.334 (0.347)	Data 0.00112 (0.00190)	Tok/s 72138 (74227)	Loss/tok 3.2996 (3.3468)	Learning Rate [7.8125e-05]
0: TRAIN [1][3290/6832]	Time 0.175 (0.347)	Data 0.00111 (0.00190)	Tok/s 79015 (74226)	Loss/tok 2.9415 (3.3467)	Learning Rate [7.8125e-05]
0: TRAIN [1][3300/6832]	Time 0.133 (0.347)	Data 0.00104 (0.00190)	Tok/s 79143 (74226)	Loss/tok 2.6982 (3.3464)	Learning Rate [7.8125e-05]
0: TRAIN [1][3310/6832]	Time 0.478 (0.347)	Data 0.00111 (0.00190)	Tok/s 67670 (74228)	Loss/tok 3.3467 (3.3464)	Learning Rate [7.8125e-05]
0: TRAIN [1][3320/6832]	Time 0.347 (0.347)	Data 0.00112 (0.00189)	Tok/s 67971 (74222)	Loss/tok 3.2557 (3.3464)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3330/6832]	Time 0.203 (0.347)	Data 0.00102 (0.00189)	Tok/s 74357 (74221)	Loss/tok 3.1458 (3.3461)	Learning Rate [7.8125e-05]
0: TRAIN [1][3340/6832]	Time 0.222 (0.347)	Data 0.00102 (0.00189)	Tok/s 73863 (74230)	Loss/tok 3.0895 (3.3459)	Learning Rate [7.8125e-05]
0: TRAIN [1][3350/6832]	Time 0.194 (0.347)	Data 0.00109 (0.00189)	Tok/s 76429 (74223)	Loss/tok 3.0085 (3.3456)	Learning Rate [7.8125e-05]
0: TRAIN [1][3360/6832]	Time 0.277 (0.346)	Data 0.00104 (0.00188)	Tok/s 72108 (74218)	Loss/tok 3.2196 (3.3454)	Learning Rate [7.8125e-05]
0: TRAIN [1][3370/6832]	Time 0.377 (0.346)	Data 0.00102 (0.00188)	Tok/s 68757 (74212)	Loss/tok 3.4273 (3.3452)	Learning Rate [7.8125e-05]
0: TRAIN [1][3380/6832]	Time 0.307 (0.347)	Data 0.00100 (0.00188)	Tok/s 73011 (74202)	Loss/tok 3.2108 (3.3453)	Learning Rate [7.8125e-05]
0: TRAIN [1][3390/6832]	Time 0.481 (0.346)	Data 0.00110 (0.00188)	Tok/s 72695 (74190)	Loss/tok 3.3888 (3.3449)	Learning Rate [7.8125e-05]
0: TRAIN [1][3400/6832]	Time 0.276 (0.346)	Data 0.00109 (0.00187)	Tok/s 72153 (74187)	Loss/tok 3.2519 (3.3448)	Learning Rate [7.8125e-05]
0: TRAIN [1][3410/6832]	Time 0.461 (0.346)	Data 0.00149 (0.00187)	Tok/s 68298 (74189)	Loss/tok 3.4884 (3.3446)	Learning Rate [7.8125e-05]
0: TRAIN [1][3420/6832]	Time 0.245 (0.346)	Data 0.00138 (0.00187)	Tok/s 73114 (74196)	Loss/tok 3.0873 (3.3442)	Learning Rate [7.8125e-05]
0: TRAIN [1][3430/6832]	Time 0.099 (0.346)	Data 0.00099 (0.00187)	Tok/s 57767 (74195)	Loss/tok 2.1789 (3.3440)	Learning Rate [7.8125e-05]
0: TRAIN [1][3440/6832]	Time 0.256 (0.346)	Data 0.00101 (0.00187)	Tok/s 74008 (74193)	Loss/tok 3.1948 (3.3438)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3450/6832]	Time 0.203 (0.346)	Data 0.00117 (0.00186)	Tok/s 74892 (74202)	Loss/tok 3.1507 (3.3435)	Learning Rate [7.8125e-05]
0: TRAIN [1][3460/6832]	Time 0.306 (0.346)	Data 0.00102 (0.00186)	Tok/s 70451 (74200)	Loss/tok 3.1950 (3.3434)	Learning Rate [7.8125e-05]
0: TRAIN [1][3470/6832]	Time 0.354 (0.346)	Data 0.00107 (0.00186)	Tok/s 67976 (74204)	Loss/tok 3.3293 (3.3432)	Learning Rate [7.8125e-05]
0: TRAIN [1][3480/6832]	Time 0.465 (0.346)	Data 0.00105 (0.00186)	Tok/s 72977 (74201)	Loss/tok 3.3326 (3.3431)	Learning Rate [7.8125e-05]
0: TRAIN [1][3490/6832]	Time 0.412 (0.346)	Data 0.00110 (0.00185)	Tok/s 68824 (74190)	Loss/tok 3.3957 (3.3429)	Learning Rate [7.8125e-05]
0: TRAIN [1][3500/6832]	Time 0.480 (0.346)	Data 0.00127 (0.00185)	Tok/s 78485 (74190)	Loss/tok 3.3803 (3.3428)	Learning Rate [7.8125e-05]
0: TRAIN [1][3510/6832]	Time 0.095 (0.346)	Data 0.00107 (0.00185)	Tok/s 62203 (74187)	Loss/tok 2.1595 (3.3425)	Learning Rate [7.8125e-05]
0: TRAIN [1][3520/6832]	Time 0.265 (0.346)	Data 0.00107 (0.00185)	Tok/s 73804 (74177)	Loss/tok 3.0702 (3.3421)	Learning Rate [7.8125e-05]
0: TRAIN [1][3530/6832]	Time 0.460 (0.346)	Data 0.00104 (0.00185)	Tok/s 66771 (74176)	Loss/tok 3.3362 (3.3420)	Learning Rate [7.8125e-05]
0: TRAIN [1][3540/6832]	Time 0.475 (0.346)	Data 0.00108 (0.00184)	Tok/s 64343 (74175)	Loss/tok 3.3704 (3.3418)	Learning Rate [7.8125e-05]
0: TRAIN [1][3550/6832]	Time 0.230 (0.346)	Data 0.00111 (0.00184)	Tok/s 73004 (74172)	Loss/tok 3.0549 (3.3416)	Learning Rate [7.8125e-05]
0: TRAIN [1][3560/6832]	Time 0.447 (0.346)	Data 0.00105 (0.00184)	Tok/s 70441 (74173)	Loss/tok 3.3836 (3.3415)	Learning Rate [7.8125e-05]
0: TRAIN [1][3570/6832]	Time 0.340 (0.346)	Data 0.00112 (0.00184)	Tok/s 69712 (74170)	Loss/tok 3.2632 (3.3413)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3580/6832]	Time 0.411 (0.346)	Data 0.00110 (0.00184)	Tok/s 72394 (74176)	Loss/tok 3.3228 (3.3412)	Learning Rate [7.8125e-05]
0: TRAIN [1][3590/6832]	Time 0.485 (0.346)	Data 0.00111 (0.00183)	Tok/s 69510 (74172)	Loss/tok 3.3984 (3.3411)	Learning Rate [7.8125e-05]
0: TRAIN [1][3600/6832]	Time 0.459 (0.347)	Data 0.00110 (0.00183)	Tok/s 66795 (74176)	Loss/tok 3.4143 (3.3410)	Learning Rate [7.8125e-05]
0: TRAIN [1][3610/6832]	Time 0.483 (0.347)	Data 0.00108 (0.00183)	Tok/s 77964 (74172)	Loss/tok 3.3922 (3.3409)	Learning Rate [7.8125e-05]
0: TRAIN [1][3620/6832]	Time 0.374 (0.347)	Data 0.00106 (0.00183)	Tok/s 70066 (74165)	Loss/tok 3.3118 (3.3410)	Learning Rate [7.8125e-05]
0: TRAIN [1][3630/6832]	Time 0.404 (0.347)	Data 0.00101 (0.00183)	Tok/s 68549 (74166)	Loss/tok 3.3015 (3.3408)	Learning Rate [7.8125e-05]
0: TRAIN [1][3640/6832]	Time 0.156 (0.347)	Data 0.00108 (0.00182)	Tok/s 79954 (74166)	Loss/tok 2.8896 (3.3406)	Learning Rate [7.8125e-05]
0: TRAIN [1][3650/6832]	Time 0.482 (0.347)	Data 0.00104 (0.00182)	Tok/s 70063 (74166)	Loss/tok 3.3879 (3.3404)	Learning Rate [7.8125e-05]
0: TRAIN [1][3660/6832]	Time 0.482 (0.347)	Data 0.00107 (0.00182)	Tok/s 71123 (74172)	Loss/tok 3.3547 (3.3402)	Learning Rate [7.8125e-05]
0: TRAIN [1][3670/6832]	Time 0.487 (0.347)	Data 0.00101 (0.00182)	Tok/s 78777 (74174)	Loss/tok 3.3842 (3.3401)	Learning Rate [7.8125e-05]
0: TRAIN [1][3680/6832]	Time 0.146 (0.347)	Data 0.00104 (0.00182)	Tok/s 81025 (74185)	Loss/tok 2.8393 (3.3397)	Learning Rate [7.8125e-05]
0: TRAIN [1][3690/6832]	Time 0.152 (0.347)	Data 0.00100 (0.00181)	Tok/s 74785 (74178)	Loss/tok 2.7519 (3.3393)	Learning Rate [7.8125e-05]
0: TRAIN [1][3700/6832]	Time 0.467 (0.347)	Data 0.00106 (0.00181)	Tok/s 69087 (74177)	Loss/tok 3.3721 (3.3390)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3710/6832]	Time 0.464 (0.346)	Data 0.00101 (0.00181)	Tok/s 100495 (74181)	Loss/tok 3.2018 (3.3388)	Learning Rate [7.8125e-05]
0: TRAIN [1][3720/6832]	Time 0.181 (0.346)	Data 0.00100 (0.00181)	Tok/s 79358 (74181)	Loss/tok 3.0154 (3.3385)	Learning Rate [7.8125e-05]
0: TRAIN [1][3730/6832]	Time 0.487 (0.347)	Data 0.00106 (0.00181)	Tok/s 80083 (74186)	Loss/tok 3.3977 (3.3385)	Learning Rate [7.8125e-05]
0: TRAIN [1][3740/6832]	Time 0.244 (0.347)	Data 0.00109 (0.00180)	Tok/s 75044 (74187)	Loss/tok 3.1608 (3.3384)	Learning Rate [7.8125e-05]
0: TRAIN [1][3750/6832]	Time 0.242 (0.347)	Data 0.00104 (0.00180)	Tok/s 71437 (74186)	Loss/tok 3.1527 (3.3382)	Learning Rate [7.8125e-05]
0: TRAIN [1][3760/6832]	Time 0.174 (0.347)	Data 0.00106 (0.00180)	Tok/s 77122 (74193)	Loss/tok 2.9020 (3.3378)	Learning Rate [7.8125e-05]
0: TRAIN [1][3770/6832]	Time 0.345 (0.347)	Data 0.00100 (0.00180)	Tok/s 72618 (74194)	Loss/tok 3.2453 (3.3377)	Learning Rate [7.8125e-05]
0: TRAIN [1][3780/6832]	Time 0.370 (0.346)	Data 0.00099 (0.00180)	Tok/s 66946 (74189)	Loss/tok 3.2855 (3.3376)	Learning Rate [7.8125e-05]
0: TRAIN [1][3790/6832]	Time 0.481 (0.346)	Data 0.00102 (0.00179)	Tok/s 77182 (74196)	Loss/tok 3.3424 (3.3372)	Learning Rate [7.8125e-05]
0: TRAIN [1][3800/6832]	Time 0.376 (0.346)	Data 0.00101 (0.00179)	Tok/s 68604 (74187)	Loss/tok 3.3465 (3.3372)	Learning Rate [7.8125e-05]
0: TRAIN [1][3810/6832]	Time 0.444 (0.346)	Data 0.00024 (0.00179)	Tok/s 68093 (74180)	Loss/tok 3.3891 (3.3371)	Learning Rate [7.8125e-05]
0: TRAIN [1][3820/6832]	Time 0.244 (0.346)	Data 0.00103 (0.00179)	Tok/s 71776 (74182)	Loss/tok 3.1407 (3.3369)	Learning Rate [7.8125e-05]
0: TRAIN [1][3830/6832]	Time 0.268 (0.346)	Data 0.00098 (0.00179)	Tok/s 71623 (74183)	Loss/tok 3.1601 (3.3366)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3840/6832]	Time 0.471 (0.346)	Data 0.00099 (0.00178)	Tok/s 67551 (74173)	Loss/tok 3.4522 (3.3365)	Learning Rate [7.8125e-05]
0: TRAIN [1][3850/6832]	Time 0.473 (0.346)	Data 0.00103 (0.00178)	Tok/s 72412 (74173)	Loss/tok 3.3718 (3.3364)	Learning Rate [7.8125e-05]
0: TRAIN [1][3860/6832]	Time 0.251 (0.346)	Data 0.00097 (0.00178)	Tok/s 72747 (74186)	Loss/tok 3.1430 (3.3360)	Learning Rate [7.8125e-05]
0: TRAIN [1][3870/6832]	Time 0.468 (0.346)	Data 0.00102 (0.00178)	Tok/s 66987 (74183)	Loss/tok 3.3047 (3.3357)	Learning Rate [7.8125e-05]
0: TRAIN [1][3880/6832]	Time 0.479 (0.346)	Data 0.00098 (0.00178)	Tok/s 68696 (74177)	Loss/tok 3.4722 (3.3355)	Learning Rate [7.8125e-05]
0: TRAIN [1][3890/6832]	Time 0.277 (0.346)	Data 0.00096 (0.00177)	Tok/s 70608 (74176)	Loss/tok 3.1667 (3.3352)	Learning Rate [7.8125e-05]
0: TRAIN [1][3900/6832]	Time 0.334 (0.346)	Data 0.00096 (0.00177)	Tok/s 69613 (74172)	Loss/tok 3.2520 (3.3349)	Learning Rate [7.8125e-05]
0: TRAIN [1][3910/6832]	Time 0.146 (0.346)	Data 0.00105 (0.00177)	Tok/s 77221 (74171)	Loss/tok 2.7277 (3.3346)	Learning Rate [7.8125e-05]
0: TRAIN [1][3920/6832]	Time 0.485 (0.346)	Data 0.00099 (0.00177)	Tok/s 76858 (74176)	Loss/tok 3.3652 (3.3345)	Learning Rate [7.8125e-05]
0: TRAIN [1][3930/6832]	Time 0.222 (0.346)	Data 0.00102 (0.00177)	Tok/s 73856 (74169)	Loss/tok 3.0113 (3.3343)	Learning Rate [7.8125e-05]
0: TRAIN [1][3940/6832]	Time 0.485 (0.346)	Data 0.00100 (0.00177)	Tok/s 96058 (74180)	Loss/tok 3.1055 (3.3341)	Learning Rate [7.8125e-05]
0: TRAIN [1][3950/6832]	Time 0.207 (0.346)	Data 0.00101 (0.00176)	Tok/s 75669 (74188)	Loss/tok 3.0987 (3.3338)	Learning Rate [7.8125e-05]
0: TRAIN [1][3960/6832]	Time 0.365 (0.346)	Data 0.00102 (0.00176)	Tok/s 68697 (74193)	Loss/tok 3.3384 (3.3337)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][3970/6832]	Time 0.482 (0.346)	Data 0.00102 (0.00176)	Tok/s 78142 (74188)	Loss/tok 3.3848 (3.3336)	Learning Rate [7.8125e-05]
0: TRAIN [1][3980/6832]	Time 0.473 (0.346)	Data 0.00098 (0.00176)	Tok/s 64605 (74180)	Loss/tok 3.3744 (3.3337)	Learning Rate [7.8125e-05]
0: TRAIN [1][3990/6832]	Time 0.272 (0.346)	Data 0.00102 (0.00176)	Tok/s 70582 (74173)	Loss/tok 3.1831 (3.3334)	Learning Rate [7.8125e-05]
0: TRAIN [1][4000/6832]	Time 0.425 (0.346)	Data 0.00116 (0.00176)	Tok/s 64980 (74168)	Loss/tok 3.2844 (3.3332)	Learning Rate [7.8125e-05]
0: TRAIN [1][4010/6832]	Time 0.485 (0.346)	Data 0.00098 (0.00175)	Tok/s 76421 (74174)	Loss/tok 3.3199 (3.3329)	Learning Rate [7.8125e-05]
0: TRAIN [1][4020/6832]	Time 0.352 (0.346)	Data 0.00104 (0.00175)	Tok/s 66273 (74168)	Loss/tok 3.2333 (3.3326)	Learning Rate [7.8125e-05]
0: TRAIN [1][4030/6832]	Time 0.465 (0.346)	Data 0.00101 (0.00175)	Tok/s 76868 (74167)	Loss/tok 3.3471 (3.3325)	Learning Rate [7.8125e-05]
0: TRAIN [1][4040/6832]	Time 0.465 (0.346)	Data 0.00106 (0.00175)	Tok/s 69473 (74171)	Loss/tok 3.4503 (3.3324)	Learning Rate [7.8125e-05]
0: TRAIN [1][4050/6832]	Time 0.200 (0.346)	Data 0.00105 (0.00175)	Tok/s 76277 (74169)	Loss/tok 3.0774 (3.3320)	Learning Rate [7.8125e-05]
0: TRAIN [1][4060/6832]	Time 0.454 (0.346)	Data 0.00101 (0.00174)	Tok/s 72107 (74163)	Loss/tok 3.3674 (3.3320)	Learning Rate [7.8125e-05]
0: TRAIN [1][4070/6832]	Time 0.476 (0.346)	Data 0.00154 (0.00174)	Tok/s 65470 (74158)	Loss/tok 3.3724 (3.3318)	Learning Rate [7.8125e-05]
0: TRAIN [1][4080/6832]	Time 0.325 (0.346)	Data 0.00101 (0.00174)	Tok/s 70897 (74154)	Loss/tok 3.2448 (3.3317)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4090/6832]	Time 0.471 (0.346)	Data 0.00127 (0.00174)	Tok/s 64014 (74154)	Loss/tok 3.4366 (3.3316)	Learning Rate [7.8125e-05]
0: TRAIN [1][4100/6832]	Time 0.476 (0.346)	Data 0.00099 (0.00174)	Tok/s 66968 (74145)	Loss/tok 3.4054 (3.3315)	Learning Rate [7.8125e-05]
0: TRAIN [1][4110/6832]	Time 0.266 (0.346)	Data 0.00100 (0.00174)	Tok/s 74935 (74141)	Loss/tok 3.0835 (3.3313)	Learning Rate [7.8125e-05]
0: TRAIN [1][4120/6832]	Time 0.482 (0.346)	Data 0.00108 (0.00174)	Tok/s 69238 (74144)	Loss/tok 3.3989 (3.3311)	Learning Rate [7.8125e-05]
0: TRAIN [1][4130/6832]	Time 0.325 (0.346)	Data 0.00127 (0.00173)	Tok/s 70871 (74138)	Loss/tok 3.1606 (3.3309)	Learning Rate [7.8125e-05]
0: TRAIN [1][4140/6832]	Time 0.480 (0.346)	Data 0.00098 (0.00173)	Tok/s 71435 (74132)	Loss/tok 3.4513 (3.3307)	Learning Rate [7.8125e-05]
0: TRAIN [1][4150/6832]	Time 0.374 (0.346)	Data 0.00101 (0.00173)	Tok/s 68125 (74126)	Loss/tok 3.2702 (3.3306)	Learning Rate [7.8125e-05]
0: TRAIN [1][4160/6832]	Time 0.142 (0.346)	Data 0.00100 (0.00173)	Tok/s 83924 (74123)	Loss/tok 2.8408 (3.3305)	Learning Rate [7.8125e-05]
0: TRAIN [1][4170/6832]	Time 0.139 (0.346)	Data 0.00101 (0.00173)	Tok/s 81470 (74118)	Loss/tok 2.8252 (3.3304)	Learning Rate [7.8125e-05]
0: TRAIN [1][4180/6832]	Time 0.142 (0.346)	Data 0.00099 (0.00173)	Tok/s 79506 (74120)	Loss/tok 2.7169 (3.3301)	Learning Rate [7.8125e-05]
0: TRAIN [1][4190/6832]	Time 0.228 (0.346)	Data 0.00105 (0.00172)	Tok/s 73473 (74117)	Loss/tok 3.0102 (3.3300)	Learning Rate [7.8125e-05]
0: TRAIN [1][4200/6832]	Time 0.235 (0.346)	Data 0.00131 (0.00172)	Tok/s 74002 (74115)	Loss/tok 3.0490 (3.3300)	Learning Rate [7.8125e-05]
0: TRAIN [1][4210/6832]	Time 0.452 (0.346)	Data 0.00108 (0.00172)	Tok/s 68357 (74108)	Loss/tok 3.2975 (3.3299)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4220/6832]	Time 0.481 (0.346)	Data 0.00102 (0.00172)	Tok/s 66182 (74102)	Loss/tok 3.3360 (3.3297)	Learning Rate [7.8125e-05]
0: TRAIN [1][4230/6832]	Time 0.484 (0.346)	Data 0.00100 (0.00172)	Tok/s 87282 (74104)	Loss/tok 3.3030 (3.3293)	Learning Rate [7.8125e-05]
0: TRAIN [1][4240/6832]	Time 0.298 (0.346)	Data 0.00100 (0.00172)	Tok/s 72406 (74103)	Loss/tok 3.2443 (3.3292)	Learning Rate [7.8125e-05]
0: TRAIN [1][4250/6832]	Time 0.197 (0.346)	Data 0.00098 (0.00172)	Tok/s 75279 (74098)	Loss/tok 3.0650 (3.3291)	Learning Rate [7.8125e-05]
0: TRAIN [1][4260/6832]	Time 0.466 (0.346)	Data 0.00097 (0.00171)	Tok/s 77826 (74096)	Loss/tok 3.3601 (3.3289)	Learning Rate [7.8125e-05]
0: TRAIN [1][4270/6832]	Time 0.431 (0.346)	Data 0.00103 (0.00171)	Tok/s 66064 (74094)	Loss/tok 3.3396 (3.3287)	Learning Rate [7.8125e-05]
0: TRAIN [1][4280/6832]	Time 0.198 (0.346)	Data 0.00100 (0.00171)	Tok/s 76418 (74092)	Loss/tok 2.9612 (3.3285)	Learning Rate [7.8125e-05]
0: TRAIN [1][4290/6832]	Time 0.416 (0.346)	Data 0.00103 (0.00171)	Tok/s 65669 (74089)	Loss/tok 3.2137 (3.3284)	Learning Rate [7.8125e-05]
0: TRAIN [1][4300/6832]	Time 0.447 (0.346)	Data 0.00101 (0.00171)	Tok/s 68264 (74085)	Loss/tok 3.3008 (3.3282)	Learning Rate [7.8125e-05]
0: TRAIN [1][4310/6832]	Time 0.315 (0.346)	Data 0.00104 (0.00171)	Tok/s 72039 (74080)	Loss/tok 3.1624 (3.3281)	Learning Rate [7.8125e-05]
0: TRAIN [1][4320/6832]	Time 0.481 (0.347)	Data 0.00105 (0.00170)	Tok/s 86166 (74089)	Loss/tok 3.2597 (3.3278)	Learning Rate [7.8125e-05]
0: TRAIN [1][4330/6832]	Time 0.243 (0.346)	Data 0.00098 (0.00170)	Tok/s 74502 (74087)	Loss/tok 3.1014 (3.3276)	Learning Rate [7.8125e-05]
0: TRAIN [1][4340/6832]	Time 0.307 (0.347)	Data 0.00110 (0.00170)	Tok/s 71822 (74084)	Loss/tok 3.2288 (3.3276)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4350/6832]	Time 0.208 (0.347)	Data 0.00102 (0.00170)	Tok/s 74984 (74089)	Loss/tok 2.9228 (3.3273)	Learning Rate [7.8125e-05]
0: TRAIN [1][4360/6832]	Time 0.115 (0.347)	Data 0.00107 (0.00170)	Tok/s 73147 (74088)	Loss/tok 2.4168 (3.3272)	Learning Rate [7.8125e-05]
0: TRAIN [1][4370/6832]	Time 0.238 (0.346)	Data 0.00101 (0.00170)	Tok/s 73316 (74085)	Loss/tok 3.0975 (3.3269)	Learning Rate [7.8125e-05]
0: TRAIN [1][4380/6832]	Time 0.481 (0.347)	Data 0.00108 (0.00170)	Tok/s 96832 (74094)	Loss/tok 3.1205 (3.3268)	Learning Rate [7.8125e-05]
0: TRAIN [1][4390/6832]	Time 0.139 (0.347)	Data 0.00100 (0.00169)	Tok/s 75767 (74107)	Loss/tok 2.5979 (3.3264)	Learning Rate [7.8125e-05]
0: TRAIN [1][4400/6832]	Time 0.478 (0.347)	Data 0.00105 (0.00169)	Tok/s 65893 (74120)	Loss/tok 3.3490 (3.3260)	Learning Rate [7.8125e-05]
0: TRAIN [1][4410/6832]	Time 0.222 (0.347)	Data 0.00107 (0.00169)	Tok/s 76067 (74123)	Loss/tok 3.1289 (3.3258)	Learning Rate [7.8125e-05]
0: TRAIN [1][4420/6832]	Time 0.473 (0.346)	Data 0.00101 (0.00169)	Tok/s 69547 (74119)	Loss/tok 3.4178 (3.3256)	Learning Rate [7.8125e-05]
0: TRAIN [1][4430/6832]	Time 0.379 (0.346)	Data 0.00104 (0.00169)	Tok/s 68359 (74122)	Loss/tok 3.1871 (3.3253)	Learning Rate [7.8125e-05]
0: TRAIN [1][4440/6832]	Time 0.486 (0.347)	Data 0.00108 (0.00169)	Tok/s 90834 (74119)	Loss/tok 3.2457 (3.3251)	Learning Rate [7.8125e-05]
0: TRAIN [1][4450/6832]	Time 0.479 (0.346)	Data 0.00110 (0.00169)	Tok/s 73710 (74127)	Loss/tok 3.3754 (3.3248)	Learning Rate [7.8125e-05]
0: TRAIN [1][4460/6832]	Time 0.480 (0.346)	Data 0.00114 (0.00168)	Tok/s 70248 (74127)	Loss/tok 3.3260 (3.3246)	Learning Rate [7.8125e-05]
0: TRAIN [1][4470/6832]	Time 0.475 (0.347)	Data 0.00105 (0.00168)	Tok/s 75495 (74131)	Loss/tok 3.3754 (3.3243)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4480/6832]	Time 0.479 (0.346)	Data 0.00103 (0.00168)	Tok/s 81676 (74133)	Loss/tok 3.2524 (3.3241)	Learning Rate [7.8125e-05]
0: TRAIN [1][4490/6832]	Time 0.165 (0.346)	Data 0.00101 (0.00168)	Tok/s 78911 (74150)	Loss/tok 2.8680 (3.3237)	Learning Rate [7.8125e-05]
0: TRAIN [1][4500/6832]	Time 0.484 (0.346)	Data 0.00098 (0.00168)	Tok/s 75380 (74148)	Loss/tok 3.4618 (3.3235)	Learning Rate [7.8125e-05]
0: TRAIN [1][4510/6832]	Time 0.165 (0.346)	Data 0.00105 (0.00168)	Tok/s 78401 (74151)	Loss/tok 2.9164 (3.3234)	Learning Rate [7.8125e-05]
0: TRAIN [1][4520/6832]	Time 0.341 (0.346)	Data 0.00105 (0.00168)	Tok/s 68661 (74155)	Loss/tok 3.1431 (3.3232)	Learning Rate [7.8125e-05]
0: TRAIN [1][4530/6832]	Time 0.470 (0.346)	Data 0.00105 (0.00167)	Tok/s 65197 (74151)	Loss/tok 3.2586 (3.3230)	Learning Rate [7.8125e-05]
0: TRAIN [1][4540/6832]	Time 0.256 (0.346)	Data 0.00101 (0.00167)	Tok/s 75997 (74158)	Loss/tok 3.1256 (3.3227)	Learning Rate [7.8125e-05]
0: TRAIN [1][4550/6832]	Time 0.441 (0.346)	Data 0.00104 (0.00167)	Tok/s 66527 (74154)	Loss/tok 3.2814 (3.3226)	Learning Rate [7.8125e-05]
0: TRAIN [1][4560/6832]	Time 0.402 (0.346)	Data 0.00103 (0.00167)	Tok/s 67984 (74150)	Loss/tok 3.2738 (3.3225)	Learning Rate [7.8125e-05]
0: TRAIN [1][4570/6832]	Time 0.477 (0.346)	Data 0.00106 (0.00167)	Tok/s 76342 (74149)	Loss/tok 3.3121 (3.3223)	Learning Rate [7.8125e-05]
0: TRAIN [1][4580/6832]	Time 0.370 (0.346)	Data 0.00098 (0.00167)	Tok/s 67851 (74147)	Loss/tok 3.2795 (3.3220)	Learning Rate [7.8125e-05]
0: TRAIN [1][4590/6832]	Time 0.433 (0.346)	Data 0.00102 (0.00167)	Tok/s 66135 (74151)	Loss/tok 3.2857 (3.3218)	Learning Rate [7.8125e-05]
0: TRAIN [1][4600/6832]	Time 0.320 (0.347)	Data 0.00103 (0.00167)	Tok/s 71956 (74155)	Loss/tok 3.1809 (3.3216)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4610/6832]	Time 0.110 (0.346)	Data 0.00104 (0.00166)	Tok/s 76862 (74153)	Loss/tok 2.4012 (3.3214)	Learning Rate [7.8125e-05]
0: TRAIN [1][4620/6832]	Time 0.202 (0.346)	Data 0.00097 (0.00166)	Tok/s 77690 (74149)	Loss/tok 3.0100 (3.3211)	Learning Rate [7.8125e-05]
0: TRAIN [1][4630/6832]	Time 0.476 (0.346)	Data 0.00096 (0.00166)	Tok/s 75244 (74148)	Loss/tok 3.2888 (3.3209)	Learning Rate [7.8125e-05]
0: TRAIN [1][4640/6832]	Time 0.489 (0.346)	Data 0.00104 (0.00166)	Tok/s 79372 (74148)	Loss/tok 3.3014 (3.3207)	Learning Rate [7.8125e-05]
0: TRAIN [1][4650/6832]	Time 0.449 (0.346)	Data 0.00102 (0.00166)	Tok/s 69297 (74152)	Loss/tok 3.3453 (3.3205)	Learning Rate [7.8125e-05]
0: TRAIN [1][4660/6832]	Time 0.133 (0.346)	Data 0.00099 (0.00166)	Tok/s 83757 (74166)	Loss/tok 2.6919 (3.3201)	Learning Rate [7.8125e-05]
0: TRAIN [1][4670/6832]	Time 0.432 (0.346)	Data 0.00106 (0.00166)	Tok/s 66723 (74164)	Loss/tok 3.2551 (3.3199)	Learning Rate [7.8125e-05]
0: TRAIN [1][4680/6832]	Time 0.312 (0.346)	Data 0.00109 (0.00166)	Tok/s 71634 (74168)	Loss/tok 3.2014 (3.3196)	Learning Rate [7.8125e-05]
0: TRAIN [1][4690/6832]	Time 0.230 (0.346)	Data 0.00103 (0.00165)	Tok/s 74164 (74165)	Loss/tok 3.0391 (3.3194)	Learning Rate [7.8125e-05]
0: TRAIN [1][4700/6832]	Time 0.375 (0.346)	Data 0.00127 (0.00165)	Tok/s 69834 (74159)	Loss/tok 3.1447 (3.3191)	Learning Rate [7.8125e-05]
0: TRAIN [1][4710/6832]	Time 0.310 (0.346)	Data 0.00105 (0.00165)	Tok/s 68785 (74158)	Loss/tok 3.1061 (3.3189)	Learning Rate [7.8125e-05]
0: TRAIN [1][4720/6832]	Time 0.420 (0.346)	Data 0.00107 (0.00165)	Tok/s 67103 (74150)	Loss/tok 3.3611 (3.3188)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4730/6832]	Time 0.264 (0.346)	Data 0.00156 (0.00165)	Tok/s 71652 (74145)	Loss/tok 3.1078 (3.3185)	Learning Rate [7.8125e-05]
0: TRAIN [1][4740/6832]	Time 0.229 (0.346)	Data 0.00104 (0.00165)	Tok/s 74388 (74151)	Loss/tok 3.0205 (3.3182)	Learning Rate [7.8125e-05]
0: TRAIN [1][4750/6832]	Time 0.479 (0.347)	Data 0.00103 (0.00165)	Tok/s 62792 (74154)	Loss/tok 3.3877 (3.3180)	Learning Rate [7.8125e-05]
0: TRAIN [1][4760/6832]	Time 0.269 (0.347)	Data 0.00125 (0.00165)	Tok/s 74261 (74149)	Loss/tok 3.0729 (3.3179)	Learning Rate [7.8125e-05]
0: TRAIN [1][4770/6832]	Time 0.314 (0.347)	Data 0.00112 (0.00165)	Tok/s 72004 (74147)	Loss/tok 3.1526 (3.3176)	Learning Rate [7.8125e-05]
0: TRAIN [1][4780/6832]	Time 0.465 (0.347)	Data 0.00101 (0.00164)	Tok/s 68546 (74144)	Loss/tok 3.2881 (3.3174)	Learning Rate [7.8125e-05]
0: TRAIN [1][4790/6832]	Time 0.480 (0.347)	Data 0.00096 (0.00164)	Tok/s 90122 (74144)	Loss/tok 3.2270 (3.3173)	Learning Rate [7.8125e-05]
0: TRAIN [1][4800/6832]	Time 0.213 (0.347)	Data 0.00100 (0.00164)	Tok/s 75032 (74139)	Loss/tok 3.0083 (3.3170)	Learning Rate [7.8125e-05]
0: TRAIN [1][4810/6832]	Time 0.228 (0.346)	Data 0.00100 (0.00164)	Tok/s 72179 (74142)	Loss/tok 3.0406 (3.3167)	Learning Rate [7.8125e-05]
0: TRAIN [1][4820/6832]	Time 0.248 (0.346)	Data 0.00096 (0.00164)	Tok/s 74969 (74140)	Loss/tok 3.0346 (3.3164)	Learning Rate [7.8125e-05]
0: TRAIN [1][4830/6832]	Time 0.379 (0.346)	Data 0.00102 (0.00164)	Tok/s 70139 (74143)	Loss/tok 3.2624 (3.3161)	Learning Rate [7.8125e-05]
0: TRAIN [1][4840/6832]	Time 0.293 (0.346)	Data 0.00098 (0.00164)	Tok/s 69077 (74141)	Loss/tok 3.1473 (3.3159)	Learning Rate [7.8125e-05]
0: TRAIN [1][4850/6832]	Time 0.249 (0.346)	Data 0.00096 (0.00164)	Tok/s 71741 (74137)	Loss/tok 3.0175 (3.3158)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4860/6832]	Time 0.395 (0.347)	Data 0.00099 (0.00163)	Tok/s 69567 (74135)	Loss/tok 3.2240 (3.3156)	Learning Rate [7.8125e-05]
0: TRAIN [1][4870/6832]	Time 0.437 (0.347)	Data 0.00098 (0.00163)	Tok/s 65405 (74133)	Loss/tok 3.2203 (3.3154)	Learning Rate [7.8125e-05]
0: TRAIN [1][4880/6832]	Time 0.461 (0.347)	Data 0.00098 (0.00163)	Tok/s 97995 (74139)	Loss/tok 3.2018 (3.3151)	Learning Rate [7.8125e-05]
0: TRAIN [1][4890/6832]	Time 0.304 (0.347)	Data 0.00099 (0.00163)	Tok/s 74078 (74139)	Loss/tok 3.1121 (3.3149)	Learning Rate [7.8125e-05]
0: TRAIN [1][4900/6832]	Time 0.473 (0.347)	Data 0.00098 (0.00163)	Tok/s 67579 (74136)	Loss/tok 3.2986 (3.3146)	Learning Rate [7.8125e-05]
0: TRAIN [1][4910/6832]	Time 0.200 (0.347)	Data 0.00095 (0.00163)	Tok/s 75524 (74149)	Loss/tok 2.9630 (3.3143)	Learning Rate [7.8125e-05]
0: TRAIN [1][4920/6832]	Time 0.316 (0.347)	Data 0.00104 (0.00163)	Tok/s 71895 (74146)	Loss/tok 3.1740 (3.3141)	Learning Rate [7.8125e-05]
0: TRAIN [1][4930/6832]	Time 0.234 (0.347)	Data 0.00100 (0.00163)	Tok/s 74469 (74141)	Loss/tok 3.0874 (3.3138)	Learning Rate [7.8125e-05]
0: TRAIN [1][4940/6832]	Time 0.462 (0.347)	Data 0.00096 (0.00162)	Tok/s 68333 (74142)	Loss/tok 3.3230 (3.3135)	Learning Rate [7.8125e-05]
0: TRAIN [1][4950/6832]	Time 0.358 (0.346)	Data 0.00101 (0.00162)	Tok/s 68592 (74139)	Loss/tok 3.1676 (3.3132)	Learning Rate [7.8125e-05]
0: TRAIN [1][4960/6832]	Time 0.225 (0.346)	Data 0.00096 (0.00162)	Tok/s 69071 (74136)	Loss/tok 2.9953 (3.3130)	Learning Rate [7.8125e-05]
0: TRAIN [1][4970/6832]	Time 0.144 (0.346)	Data 0.00095 (0.00162)	Tok/s 82512 (74148)	Loss/tok 2.8416 (3.3127)	Learning Rate [7.8125e-05]
0: TRAIN [1][4980/6832]	Time 0.111 (0.346)	Data 0.00106 (0.00162)	Tok/s 76357 (74153)	Loss/tok 2.4252 (3.3124)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][4990/6832]	Time 0.155 (0.346)	Data 0.00104 (0.00162)	Tok/s 79747 (74155)	Loss/tok 2.7863 (3.3122)	Learning Rate [7.8125e-05]
0: TRAIN [1][5000/6832]	Time 0.291 (0.346)	Data 0.00100 (0.00162)	Tok/s 70850 (74150)	Loss/tok 3.1569 (3.3120)	Learning Rate [7.8125e-05]
0: TRAIN [1][5010/6832]	Time 0.278 (0.346)	Data 0.00103 (0.00162)	Tok/s 72757 (74152)	Loss/tok 3.1165 (3.3119)	Learning Rate [7.8125e-05]
0: TRAIN [1][5020/6832]	Time 0.381 (0.346)	Data 0.00097 (0.00162)	Tok/s 68584 (74146)	Loss/tok 3.2513 (3.3116)	Learning Rate [7.8125e-05]
0: TRAIN [1][5030/6832]	Time 0.460 (0.346)	Data 0.00100 (0.00161)	Tok/s 86258 (74140)	Loss/tok 3.2436 (3.3114)	Learning Rate [7.8125e-05]
0: TRAIN [1][5040/6832]	Time 0.480 (0.346)	Data 0.00099 (0.00161)	Tok/s 94071 (74140)	Loss/tok 3.1556 (3.3111)	Learning Rate [7.8125e-05]
0: TRAIN [1][5050/6832]	Time 0.320 (0.346)	Data 0.00101 (0.00161)	Tok/s 68810 (74139)	Loss/tok 3.1522 (3.3108)	Learning Rate [7.8125e-05]
0: TRAIN [1][5060/6832]	Time 0.337 (0.346)	Data 0.00097 (0.00161)	Tok/s 70511 (74134)	Loss/tok 3.1624 (3.3106)	Learning Rate [7.8125e-05]
0: TRAIN [1][5070/6832]	Time 0.340 (0.346)	Data 0.00101 (0.00161)	Tok/s 69244 (74129)	Loss/tok 3.1995 (3.3104)	Learning Rate [7.8125e-05]
0: TRAIN [1][5080/6832]	Time 0.485 (0.346)	Data 0.00098 (0.00161)	Tok/s 79103 (74129)	Loss/tok 3.2155 (3.3101)	Learning Rate [7.8125e-05]
0: TRAIN [1][5090/6832]	Time 0.413 (0.346)	Data 0.00096 (0.00161)	Tok/s 66968 (74125)	Loss/tok 3.1603 (3.3099)	Learning Rate [7.8125e-05]
0: TRAIN [1][5100/6832]	Time 0.350 (0.346)	Data 0.00100 (0.00161)	Tok/s 68825 (74124)	Loss/tok 3.1402 (3.3097)	Learning Rate [7.8125e-05]
0: TRAIN [1][5110/6832]	Time 0.301 (0.346)	Data 0.00100 (0.00161)	Tok/s 72635 (74127)	Loss/tok 3.2015 (3.3093)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][5120/6832]	Time 0.485 (0.346)	Data 0.00099 (0.00160)	Tok/s 96033 (74128)	Loss/tok 3.1717 (3.3090)	Learning Rate [7.8125e-05]
0: TRAIN [1][5130/6832]	Time 0.480 (0.346)	Data 0.00025 (0.00160)	Tok/s 82647 (74127)	Loss/tok 3.2015 (3.3087)	Learning Rate [7.8125e-05]
0: TRAIN [1][5140/6832]	Time 0.481 (0.346)	Data 0.00103 (0.00160)	Tok/s 70155 (74120)	Loss/tok 3.2886 (3.3085)	Learning Rate [7.8125e-05]
0: TRAIN [1][5150/6832]	Time 0.483 (0.346)	Data 0.00101 (0.00160)	Tok/s 80963 (74118)	Loss/tok 3.2813 (3.3083)	Learning Rate [7.8125e-05]
0: TRAIN [1][5160/6832]	Time 0.397 (0.346)	Data 0.00103 (0.00160)	Tok/s 69592 (74117)	Loss/tok 3.3580 (3.3082)	Learning Rate [7.8125e-05]
0: TRAIN [1][5170/6832]	Time 0.255 (0.346)	Data 0.00097 (0.00160)	Tok/s 75589 (74123)	Loss/tok 3.0908 (3.3080)	Learning Rate [7.8125e-05]
0: TRAIN [1][5180/6832]	Time 0.485 (0.346)	Data 0.00103 (0.00160)	Tok/s 77560 (74131)	Loss/tok 3.3187 (3.3076)	Learning Rate [7.8125e-05]
0: TRAIN [1][5190/6832]	Time 0.102 (0.346)	Data 0.00119 (0.00160)	Tok/s 56968 (74132)	Loss/tok 2.0572 (3.3073)	Learning Rate [7.8125e-05]
0: TRAIN [1][5200/6832]	Time 0.117 (0.346)	Data 0.00100 (0.00160)	Tok/s 82377 (74142)	Loss/tok 2.5968 (3.3070)	Learning Rate [7.8125e-05]
0: TRAIN [1][5210/6832]	Time 0.455 (0.346)	Data 0.00102 (0.00160)	Tok/s 65330 (74135)	Loss/tok 3.3273 (3.3068)	Learning Rate [7.8125e-05]
0: TRAIN [1][5220/6832]	Time 0.483 (0.346)	Data 0.00103 (0.00159)	Tok/s 100698 (74137)	Loss/tok 2.9917 (3.3065)	Learning Rate [7.8125e-05]
0: TRAIN [1][5230/6832]	Time 0.183 (0.346)	Data 0.00099 (0.00159)	Tok/s 78266 (74135)	Loss/tok 2.8860 (3.3062)	Learning Rate [7.8125e-05]
0: TRAIN [1][5240/6832]	Time 0.427 (0.346)	Data 0.00096 (0.00159)	Tok/s 66682 (74136)	Loss/tok 3.1613 (3.3060)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][5250/6832]	Time 0.362 (0.346)	Data 0.00107 (0.00159)	Tok/s 67605 (74136)	Loss/tok 3.2024 (3.3057)	Learning Rate [7.8125e-05]
0: TRAIN [1][5260/6832]	Time 0.401 (0.346)	Data 0.00101 (0.00159)	Tok/s 67197 (74136)	Loss/tok 3.2499 (3.3054)	Learning Rate [7.8125e-05]
0: TRAIN [1][5270/6832]	Time 0.282 (0.346)	Data 0.00095 (0.00159)	Tok/s 70867 (74143)	Loss/tok 3.1378 (3.3051)	Learning Rate [7.8125e-05]
0: TRAIN [1][5280/6832]	Time 0.479 (0.346)	Data 0.00098 (0.00159)	Tok/s 76239 (74137)	Loss/tok 3.2886 (3.3049)	Learning Rate [7.8125e-05]
0: TRAIN [1][5290/6832]	Time 0.324 (0.346)	Data 0.00099 (0.00159)	Tok/s 73505 (74136)	Loss/tok 3.1650 (3.3047)	Learning Rate [7.8125e-05]
0: TRAIN [1][5300/6832]	Time 0.234 (0.346)	Data 0.00098 (0.00159)	Tok/s 74335 (74143)	Loss/tok 3.1003 (3.3043)	Learning Rate [7.8125e-05]
0: TRAIN [1][5310/6832]	Time 0.183 (0.346)	Data 0.00100 (0.00158)	Tok/s 78640 (74150)	Loss/tok 2.8559 (3.3040)	Learning Rate [7.8125e-05]
0: TRAIN [1][5320/6832]	Time 0.295 (0.346)	Data 0.00104 (0.00158)	Tok/s 68875 (74146)	Loss/tok 3.0839 (3.3038)	Learning Rate [7.8125e-05]
0: TRAIN [1][5330/6832]	Time 0.481 (0.346)	Data 0.00098 (0.00158)	Tok/s 100942 (74158)	Loss/tok 3.0420 (3.3034)	Learning Rate [7.8125e-05]
0: TRAIN [1][5340/6832]	Time 0.239 (0.346)	Data 0.00095 (0.00158)	Tok/s 70498 (74160)	Loss/tok 2.9858 (3.3032)	Learning Rate [7.8125e-05]
0: TRAIN [1][5350/6832]	Time 0.326 (0.346)	Data 0.00098 (0.00158)	Tok/s 72685 (74161)	Loss/tok 3.1440 (3.3029)	Learning Rate [7.8125e-05]
0: TRAIN [1][5360/6832]	Time 0.432 (0.346)	Data 0.00099 (0.00158)	Tok/s 66130 (74157)	Loss/tok 3.2942 (3.3026)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][5370/6832]	Time 0.465 (0.346)	Data 0.00109 (0.00158)	Tok/s 104773 (74162)	Loss/tok 3.0371 (3.3023)	Learning Rate [7.8125e-05]
0: TRAIN [1][5380/6832]	Time 0.488 (0.346)	Data 0.00100 (0.00158)	Tok/s 86185 (74163)	Loss/tok 3.1574 (3.3020)	Learning Rate [7.8125e-05]
0: TRAIN [1][5390/6832]	Time 0.281 (0.346)	Data 0.00167 (0.00158)	Tok/s 71747 (74162)	Loss/tok 3.0775 (3.3017)	Learning Rate [7.8125e-05]
0: TRAIN [1][5400/6832]	Time 0.343 (0.346)	Data 0.00110 (0.00158)	Tok/s 73668 (74168)	Loss/tok 3.1482 (3.3014)	Learning Rate [7.8125e-05]
0: TRAIN [1][5410/6832]	Time 0.194 (0.346)	Data 0.00103 (0.00157)	Tok/s 78465 (74166)	Loss/tok 2.9831 (3.3012)	Learning Rate [7.8125e-05]
0: TRAIN [1][5420/6832]	Time 0.465 (0.346)	Data 0.00105 (0.00157)	Tok/s 67619 (74164)	Loss/tok 3.2531 (3.3009)	Learning Rate [7.8125e-05]
0: TRAIN [1][5430/6832]	Time 0.352 (0.346)	Data 0.00102 (0.00157)	Tok/s 68522 (74163)	Loss/tok 3.1751 (3.3007)	Learning Rate [7.8125e-05]
0: TRAIN [1][5440/6832]	Time 0.480 (0.346)	Data 0.00104 (0.00157)	Tok/s 101329 (74162)	Loss/tok 3.0726 (3.3004)	Learning Rate [7.8125e-05]
0: TRAIN [1][5450/6832]	Time 0.484 (0.346)	Data 0.00100 (0.00157)	Tok/s 85508 (74166)	Loss/tok 3.1865 (3.3001)	Learning Rate [7.8125e-05]
0: TRAIN [1][5460/6832]	Time 0.480 (0.346)	Data 0.00107 (0.00157)	Tok/s 69126 (74166)	Loss/tok 3.2704 (3.2998)	Learning Rate [7.8125e-05]
0: TRAIN [1][5470/6832]	Time 0.340 (0.346)	Data 0.00102 (0.00157)	Tok/s 69179 (74163)	Loss/tok 3.0478 (3.2996)	Learning Rate [7.8125e-05]
0: TRAIN [1][5480/6832]	Time 0.212 (0.346)	Data 0.00104 (0.00157)	Tok/s 75009 (74170)	Loss/tok 2.9603 (3.2993)	Learning Rate [7.8125e-05]
0: TRAIN [1][5490/6832]	Time 0.132 (0.346)	Data 0.00101 (0.00157)	Tok/s 79873 (74173)	Loss/tok 2.6066 (3.2991)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][5500/6832]	Time 0.260 (0.346)	Data 0.00103 (0.00157)	Tok/s 72812 (74172)	Loss/tok 3.0039 (3.2988)	Learning Rate [7.8125e-05]
0: TRAIN [1][5510/6832]	Time 0.107 (0.346)	Data 0.00106 (0.00157)	Tok/s 77984 (74177)	Loss/tok 2.3770 (3.2985)	Learning Rate [7.8125e-05]
0: TRAIN [1][5520/6832]	Time 0.468 (0.346)	Data 0.00106 (0.00156)	Tok/s 86292 (74176)	Loss/tok 3.1900 (3.2982)	Learning Rate [7.8125e-05]
0: TRAIN [1][5530/6832]	Time 0.216 (0.346)	Data 0.00119 (0.00156)	Tok/s 77561 (74181)	Loss/tok 2.9936 (3.2980)	Learning Rate [7.8125e-05]
0: TRAIN [1][5540/6832]	Time 0.116 (0.346)	Data 0.00108 (0.00156)	Tok/s 73842 (74180)	Loss/tok 2.3710 (3.2976)	Learning Rate [7.8125e-05]
0: TRAIN [1][5550/6832]	Time 0.257 (0.346)	Data 0.00108 (0.00156)	Tok/s 72125 (74177)	Loss/tok 3.0314 (3.2974)	Learning Rate [7.8125e-05]
0: TRAIN [1][5560/6832]	Time 0.120 (0.346)	Data 0.00102 (0.00156)	Tok/s 80440 (74175)	Loss/tok 2.5562 (3.2971)	Learning Rate [7.8125e-05]
0: TRAIN [1][5570/6832]	Time 0.446 (0.346)	Data 0.00098 (0.00156)	Tok/s 68547 (74170)	Loss/tok 3.2074 (3.2969)	Learning Rate [7.8125e-05]
0: TRAIN [1][5580/6832]	Time 0.464 (0.346)	Data 0.00101 (0.00156)	Tok/s 100386 (74173)	Loss/tok 3.0740 (3.2965)	Learning Rate [7.8125e-05]
0: TRAIN [1][5590/6832]	Time 0.480 (0.346)	Data 0.00109 (0.00156)	Tok/s 73015 (74176)	Loss/tok 3.2252 (3.2962)	Learning Rate [7.8125e-05]
0: TRAIN [1][5600/6832]	Time 0.326 (0.346)	Data 0.00103 (0.00156)	Tok/s 70744 (74178)	Loss/tok 3.1359 (3.2959)	Learning Rate [7.8125e-05]
0: TRAIN [1][5610/6832]	Time 0.312 (0.346)	Data 0.00098 (0.00156)	Tok/s 73809 (74176)	Loss/tok 3.0257 (3.2956)	Learning Rate [7.8125e-05]
0: TRAIN [1][5620/6832]	Time 0.483 (0.346)	Data 0.00100 (0.00156)	Tok/s 91342 (74180)	Loss/tok 3.0669 (3.2953)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][5630/6832]	Time 0.266 (0.346)	Data 0.00107 (0.00155)	Tok/s 74822 (74179)	Loss/tok 3.0664 (3.2951)	Learning Rate [7.8125e-05]
0: TRAIN [1][5640/6832]	Time 0.127 (0.346)	Data 0.00107 (0.00155)	Tok/s 76200 (74174)	Loss/tok 2.5311 (3.2948)	Learning Rate [7.8125e-05]
0: TRAIN [1][5650/6832]	Time 0.356 (0.346)	Data 0.00103 (0.00155)	Tok/s 68779 (74169)	Loss/tok 3.1716 (3.2946)	Learning Rate [7.8125e-05]
0: TRAIN [1][5660/6832]	Time 0.402 (0.346)	Data 0.00106 (0.00155)	Tok/s 68284 (74169)	Loss/tok 3.1996 (3.2944)	Learning Rate [7.8125e-05]
0: TRAIN [1][5670/6832]	Time 0.435 (0.346)	Data 0.00112 (0.00155)	Tok/s 64801 (74168)	Loss/tok 3.1859 (3.2941)	Learning Rate [7.8125e-05]
0: TRAIN [1][5680/6832]	Time 0.452 (0.346)	Data 0.00102 (0.00155)	Tok/s 69485 (74162)	Loss/tok 3.2504 (3.2938)	Learning Rate [7.8125e-05]
0: TRAIN [1][5690/6832]	Time 0.153 (0.346)	Data 0.00104 (0.00155)	Tok/s 77925 (74169)	Loss/tok 2.7465 (3.2934)	Learning Rate [7.8125e-05]
0: TRAIN [1][5700/6832]	Time 0.221 (0.346)	Data 0.00102 (0.00155)	Tok/s 75934 (74180)	Loss/tok 2.9348 (3.2930)	Learning Rate [7.8125e-05]
0: TRAIN [1][5710/6832]	Time 0.381 (0.347)	Data 0.00101 (0.00155)	Tok/s 70667 (74185)	Loss/tok 3.1110 (3.2927)	Learning Rate [7.8125e-05]
0: TRAIN [1][5720/6832]	Time 0.476 (0.347)	Data 0.00104 (0.00155)	Tok/s 66220 (74185)	Loss/tok 3.2095 (3.2924)	Learning Rate [7.8125e-05]
0: TRAIN [1][5730/6832]	Time 0.252 (0.347)	Data 0.00101 (0.00155)	Tok/s 75079 (74183)	Loss/tok 3.0950 (3.2921)	Learning Rate [7.8125e-05]
0: TRAIN [1][5740/6832]	Time 0.160 (0.347)	Data 0.00101 (0.00154)	Tok/s 77865 (74178)	Loss/tok 2.8391 (3.2918)	Learning Rate [7.8125e-05]
0: TRAIN [1][5750/6832]	Time 0.424 (0.347)	Data 0.00104 (0.00154)	Tok/s 67379 (74169)	Loss/tok 3.1980 (3.2916)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][5760/6832]	Time 0.479 (0.347)	Data 0.00107 (0.00154)	Tok/s 67571 (74161)	Loss/tok 3.2291 (3.2913)	Learning Rate [7.8125e-05]
0: TRAIN [1][5770/6832]	Time 0.145 (0.347)	Data 0.00099 (0.00154)	Tok/s 72797 (74162)	Loss/tok 2.6543 (3.2911)	Learning Rate [7.8125e-05]
0: TRAIN [1][5780/6832]	Time 0.164 (0.347)	Data 0.00106 (0.00154)	Tok/s 75567 (74162)	Loss/tok 2.7766 (3.2908)	Learning Rate [7.8125e-05]
0: TRAIN [1][5790/6832]	Time 0.356 (0.347)	Data 0.00103 (0.00154)	Tok/s 74693 (74163)	Loss/tok 3.1103 (3.2903)	Learning Rate [7.8125e-05]
0: TRAIN [1][5800/6832]	Time 0.485 (0.347)	Data 0.00104 (0.00154)	Tok/s 81859 (74170)	Loss/tok 3.2331 (3.2899)	Learning Rate [7.8125e-05]
0: TRAIN [1][5810/6832]	Time 0.180 (0.347)	Data 0.00101 (0.00154)	Tok/s 77259 (74171)	Loss/tok 2.7985 (3.2895)	Learning Rate [7.8125e-05]
0: TRAIN [1][5820/6832]	Time 0.457 (0.347)	Data 0.00105 (0.00154)	Tok/s 68052 (74166)	Loss/tok 3.1891 (3.2892)	Learning Rate [7.8125e-05]
0: TRAIN [1][5830/6832]	Time 0.480 (0.346)	Data 0.00104 (0.00154)	Tok/s 79821 (74164)	Loss/tok 3.2215 (3.2889)	Learning Rate [7.8125e-05]
0: TRAIN [1][5840/6832]	Time 0.481 (0.346)	Data 0.00101 (0.00154)	Tok/s 78375 (74161)	Loss/tok 3.1666 (3.2886)	Learning Rate [7.8125e-05]
0: TRAIN [1][5850/6832]	Time 0.440 (0.347)	Data 0.00102 (0.00154)	Tok/s 65572 (74157)	Loss/tok 3.1618 (3.2884)	Learning Rate [7.8125e-05]
0: TRAIN [1][5860/6832]	Time 0.438 (0.347)	Data 0.00107 (0.00154)	Tok/s 67143 (74166)	Loss/tok 3.1488 (3.2880)	Learning Rate [7.8125e-05]
0: TRAIN [1][5870/6832]	Time 0.124 (0.347)	Data 0.00103 (0.00153)	Tok/s 77814 (74165)	Loss/tok 2.5671 (3.2876)	Learning Rate [7.8125e-05]
0: TRAIN [1][5880/6832]	Time 0.298 (0.347)	Data 0.00104 (0.00153)	Tok/s 70362 (74166)	Loss/tok 3.1603 (3.2874)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][5890/6832]	Time 0.471 (0.347)	Data 0.00098 (0.00153)	Tok/s 71760 (74164)	Loss/tok 3.2571 (3.2870)	Learning Rate [7.8125e-05]
0: TRAIN [1][5900/6832]	Time 0.483 (0.347)	Data 0.00102 (0.00153)	Tok/s 69847 (74161)	Loss/tok 3.2429 (3.2867)	Learning Rate [7.8125e-05]
0: TRAIN [1][5910/6832]	Time 0.459 (0.347)	Data 0.00098 (0.00153)	Tok/s 94116 (74164)	Loss/tok 3.0605 (3.2864)	Learning Rate [7.8125e-05]
0: TRAIN [1][5920/6832]	Time 0.479 (0.347)	Data 0.00108 (0.00153)	Tok/s 76107 (74171)	Loss/tok 3.2372 (3.2860)	Learning Rate [7.8125e-05]
0: TRAIN [1][5930/6832]	Time 0.338 (0.347)	Data 0.00104 (0.00153)	Tok/s 69283 (74164)	Loss/tok 3.1573 (3.2858)	Learning Rate [7.8125e-05]
0: TRAIN [1][5940/6832]	Time 0.486 (0.347)	Data 0.00111 (0.00153)	Tok/s 88753 (74173)	Loss/tok 3.1739 (3.2854)	Learning Rate [7.8125e-05]
0: TRAIN [1][5950/6832]	Time 0.479 (0.347)	Data 0.00100 (0.00153)	Tok/s 72749 (74174)	Loss/tok 3.2115 (3.2851)	Learning Rate [7.8125e-05]
0: TRAIN [1][5960/6832]	Time 0.273 (0.347)	Data 0.00101 (0.00153)	Tok/s 73207 (74172)	Loss/tok 2.9433 (3.2847)	Learning Rate [7.8125e-05]
0: TRAIN [1][5970/6832]	Time 0.285 (0.347)	Data 0.00098 (0.00153)	Tok/s 71499 (74172)	Loss/tok 3.0201 (3.2843)	Learning Rate [7.8125e-05]
0: TRAIN [1][5980/6832]	Time 0.481 (0.347)	Data 0.00100 (0.00153)	Tok/s 67703 (74168)	Loss/tok 3.2097 (3.2840)	Learning Rate [7.8125e-05]
0: TRAIN [1][5990/6832]	Time 0.488 (0.347)	Data 0.00100 (0.00153)	Tok/s 80083 (74175)	Loss/tok 3.1887 (3.2837)	Learning Rate [7.8125e-05]
0: TRAIN [1][6000/6832]	Time 0.483 (0.347)	Data 0.00099 (0.00152)	Tok/s 75292 (74176)	Loss/tok 3.2707 (3.2834)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][6010/6832]	Time 0.139 (0.347)	Data 0.00149 (0.00152)	Tok/s 80412 (74172)	Loss/tok 2.7181 (3.2832)	Learning Rate [7.8125e-05]
0: TRAIN [1][6020/6832]	Time 0.479 (0.347)	Data 0.00125 (0.00152)	Tok/s 69509 (74173)	Loss/tok 3.3523 (3.2831)	Learning Rate [7.8125e-05]
0: TRAIN [1][6030/6832]	Time 0.347 (0.347)	Data 0.00101 (0.00152)	Tok/s 69380 (74169)	Loss/tok 3.1822 (3.2830)	Learning Rate [7.8125e-05]
0: TRAIN [1][6040/6832]	Time 0.458 (0.347)	Data 0.00105 (0.00152)	Tok/s 74640 (74171)	Loss/tok 3.2661 (3.2828)	Learning Rate [7.8125e-05]
0: TRAIN [1][6050/6832]	Time 0.466 (0.347)	Data 0.00140 (0.00152)	Tok/s 63918 (74175)	Loss/tok 3.3059 (3.2827)	Learning Rate [7.8125e-05]
0: TRAIN [1][6060/6832]	Time 0.487 (0.347)	Data 0.00098 (0.00152)	Tok/s 88314 (74181)	Loss/tok 3.2329 (3.2825)	Learning Rate [7.8125e-05]
0: TRAIN [1][6070/6832]	Time 0.221 (0.347)	Data 0.00103 (0.00152)	Tok/s 76293 (74186)	Loss/tok 2.9693 (3.2824)	Learning Rate [7.8125e-05]
0: TRAIN [1][6080/6832]	Time 0.148 (0.347)	Data 0.00101 (0.00152)	Tok/s 80985 (74185)	Loss/tok 2.7271 (3.2822)	Learning Rate [7.8125e-05]
0: TRAIN [1][6090/6832]	Time 0.472 (0.347)	Data 0.00106 (0.00152)	Tok/s 66453 (74186)	Loss/tok 3.2723 (3.2820)	Learning Rate [7.8125e-05]
0: TRAIN [1][6100/6832]	Time 0.480 (0.347)	Data 0.00103 (0.00152)	Tok/s 81212 (74189)	Loss/tok 3.1913 (3.2818)	Learning Rate [7.8125e-05]
0: TRAIN [1][6110/6832]	Time 0.457 (0.347)	Data 0.00097 (0.00152)	Tok/s 63190 (74186)	Loss/tok 3.2695 (3.2817)	Learning Rate [7.8125e-05]
0: TRAIN [1][6120/6832]	Time 0.482 (0.347)	Data 0.00101 (0.00152)	Tok/s 74383 (74181)	Loss/tok 3.2188 (3.2816)	Learning Rate [7.8125e-05]
0: TRAIN [1][6130/6832]	Time 0.155 (0.347)	Data 0.00098 (0.00151)	Tok/s 68161 (74176)	Loss/tok 2.6096 (3.2813)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][6140/6832]	Time 0.472 (0.347)	Data 0.00099 (0.00151)	Tok/s 67816 (74173)	Loss/tok 3.3554 (3.2812)	Learning Rate [7.8125e-05]
0: TRAIN [1][6150/6832]	Time 0.448 (0.347)	Data 0.00099 (0.00151)	Tok/s 76594 (74172)	Loss/tok 3.3134 (3.2811)	Learning Rate [7.8125e-05]
0: TRAIN [1][6160/6832]	Time 0.487 (0.347)	Data 0.00108 (0.00151)	Tok/s 88462 (74170)	Loss/tok 3.1731 (3.2811)	Learning Rate [7.8125e-05]
0: TRAIN [1][6170/6832]	Time 0.373 (0.347)	Data 0.00100 (0.00151)	Tok/s 65695 (74171)	Loss/tok 3.1704 (3.2809)	Learning Rate [7.8125e-05]
0: TRAIN [1][6180/6832]	Time 0.443 (0.347)	Data 0.00106 (0.00151)	Tok/s 66992 (74170)	Loss/tok 3.3343 (3.2807)	Learning Rate [7.8125e-05]
0: TRAIN [1][6190/6832]	Time 0.464 (0.348)	Data 0.00109 (0.00151)	Tok/s 65075 (74165)	Loss/tok 3.1924 (3.2805)	Learning Rate [7.8125e-05]
0: TRAIN [1][6200/6832]	Time 0.201 (0.348)	Data 0.00100 (0.00151)	Tok/s 73123 (74161)	Loss/tok 2.9427 (3.2803)	Learning Rate [7.8125e-05]
0: TRAIN [1][6210/6832]	Time 0.245 (0.347)	Data 0.00102 (0.00151)	Tok/s 72922 (74160)	Loss/tok 3.0429 (3.2802)	Learning Rate [7.8125e-05]
0: TRAIN [1][6220/6832]	Time 0.485 (0.347)	Data 0.00103 (0.00151)	Tok/s 78765 (74162)	Loss/tok 3.2619 (3.2800)	Learning Rate [7.8125e-05]
0: TRAIN [1][6230/6832]	Time 0.300 (0.347)	Data 0.00104 (0.00151)	Tok/s 71209 (74167)	Loss/tok 3.1653 (3.2797)	Learning Rate [7.8125e-05]
0: TRAIN [1][6240/6832]	Time 0.224 (0.347)	Data 0.00094 (0.00151)	Tok/s 77715 (74166)	Loss/tok 3.0753 (3.2795)	Learning Rate [7.8125e-05]
0: TRAIN [1][6250/6832]	Time 0.409 (0.347)	Data 0.00102 (0.00151)	Tok/s 65923 (74160)	Loss/tok 3.2401 (3.2793)	Learning Rate [7.8125e-05]
0: TRAIN [1][6260/6832]	Time 0.409 (0.347)	Data 0.00100 (0.00151)	Tok/s 67753 (74159)	Loss/tok 3.1907 (3.2791)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][6270/6832]	Time 0.481 (0.347)	Data 0.00105 (0.00150)	Tok/s 87924 (74163)	Loss/tok 3.2516 (3.2790)	Learning Rate [7.8125e-05]
0: TRAIN [1][6280/6832]	Time 0.211 (0.347)	Data 0.00118 (0.00150)	Tok/s 75325 (74162)	Loss/tok 3.0123 (3.2789)	Learning Rate [7.8125e-05]
0: TRAIN [1][6290/6832]	Time 0.484 (0.347)	Data 0.00102 (0.00150)	Tok/s 88721 (74165)	Loss/tok 3.1853 (3.2787)	Learning Rate [7.8125e-05]
0: TRAIN [1][6300/6832]	Time 0.310 (0.347)	Data 0.00105 (0.00150)	Tok/s 69378 (74162)	Loss/tok 3.0726 (3.2785)	Learning Rate [7.8125e-05]
0: TRAIN [1][6310/6832]	Time 0.236 (0.347)	Data 0.00101 (0.00150)	Tok/s 76082 (74163)	Loss/tok 2.9746 (3.2783)	Learning Rate [7.8125e-05]
0: TRAIN [1][6320/6832]	Time 0.350 (0.347)	Data 0.00105 (0.00150)	Tok/s 69369 (74162)	Loss/tok 3.2454 (3.2782)	Learning Rate [7.8125e-05]
0: TRAIN [1][6330/6832]	Time 0.185 (0.347)	Data 0.00102 (0.00150)	Tok/s 77999 (74166)	Loss/tok 2.9328 (3.2780)	Learning Rate [7.8125e-05]
0: TRAIN [1][6340/6832]	Time 0.281 (0.347)	Data 0.00102 (0.00150)	Tok/s 72842 (74164)	Loss/tok 3.1033 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [1][6350/6832]	Time 0.344 (0.347)	Data 0.00102 (0.00150)	Tok/s 69930 (74163)	Loss/tok 3.2055 (3.2776)	Learning Rate [7.8125e-05]
0: TRAIN [1][6360/6832]	Time 0.122 (0.347)	Data 0.00105 (0.00150)	Tok/s 79381 (74162)	Loss/tok 2.5578 (3.2774)	Learning Rate [7.8125e-05]
0: TRAIN [1][6370/6832]	Time 0.283 (0.347)	Data 0.00103 (0.00150)	Tok/s 72439 (74160)	Loss/tok 3.1203 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [1][6380/6832]	Time 0.476 (0.347)	Data 0.00102 (0.00150)	Tok/s 73145 (74162)	Loss/tok 3.3146 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [1][6390/6832]	Time 0.278 (0.347)	Data 0.00107 (0.00150)	Tok/s 73414 (74162)	Loss/tok 3.1224 (3.2769)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][6400/6832]	Time 0.416 (0.347)	Data 0.00101 (0.00150)	Tok/s 66733 (74164)	Loss/tok 3.2527 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [1][6410/6832]	Time 0.439 (0.347)	Data 0.00102 (0.00149)	Tok/s 67664 (74166)	Loss/tok 3.2001 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [1][6420/6832]	Time 0.430 (0.348)	Data 0.00102 (0.00149)	Tok/s 65628 (74167)	Loss/tok 3.1892 (3.2764)	Learning Rate [7.8125e-05]
0: TRAIN [1][6430/6832]	Time 0.318 (0.348)	Data 0.00106 (0.00149)	Tok/s 70189 (74165)	Loss/tok 3.1631 (3.2762)	Learning Rate [7.8125e-05]
0: TRAIN [1][6440/6832]	Time 0.428 (0.348)	Data 0.00116 (0.00149)	Tok/s 67438 (74159)	Loss/tok 3.2241 (3.2761)	Learning Rate [7.8125e-05]
0: TRAIN [1][6450/6832]	Time 0.278 (0.348)	Data 0.00107 (0.00149)	Tok/s 70268 (74159)	Loss/tok 3.0692 (3.2759)	Learning Rate [7.8125e-05]
0: TRAIN [1][6460/6832]	Time 0.418 (0.348)	Data 0.00104 (0.00149)	Tok/s 68457 (74158)	Loss/tok 3.2998 (3.2758)	Learning Rate [7.8125e-05]
0: TRAIN [1][6470/6832]	Time 0.197 (0.347)	Data 0.00100 (0.00149)	Tok/s 77073 (74154)	Loss/tok 3.0168 (3.2756)	Learning Rate [7.8125e-05]
0: TRAIN [1][6480/6832]	Time 0.487 (0.347)	Data 0.00105 (0.00149)	Tok/s 86827 (74156)	Loss/tok 3.2871 (3.2753)	Learning Rate [7.8125e-05]
0: TRAIN [1][6490/6832]	Time 0.481 (0.347)	Data 0.00102 (0.00149)	Tok/s 72241 (74155)	Loss/tok 3.1600 (3.2752)	Learning Rate [7.8125e-05]
0: TRAIN [1][6500/6832]	Time 0.299 (0.347)	Data 0.00102 (0.00149)	Tok/s 69274 (74150)	Loss/tok 3.0907 (3.2751)	Learning Rate [7.8125e-05]
0: TRAIN [1][6510/6832]	Time 0.261 (0.347)	Data 0.00107 (0.00149)	Tok/s 74801 (74146)	Loss/tok 3.1401 (3.2750)	Learning Rate [7.8125e-05]
0: TRAIN [1][6520/6832]	Time 0.229 (0.347)	Data 0.00105 (0.00149)	Tok/s 73518 (74149)	Loss/tok 3.0000 (3.2748)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][6530/6832]	Time 0.464 (0.347)	Data 0.00109 (0.00149)	Tok/s 65999 (74141)	Loss/tok 3.3872 (3.2749)	Learning Rate [7.8125e-05]
0: TRAIN [1][6540/6832]	Time 0.112 (0.347)	Data 0.00101 (0.00149)	Tok/s 74103 (74144)	Loss/tok 2.3670 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [1][6550/6832]	Time 0.376 (0.347)	Data 0.00117 (0.00149)	Tok/s 66184 (74136)	Loss/tok 3.2695 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [1][6560/6832]	Time 0.332 (0.347)	Data 0.00110 (0.00149)	Tok/s 69419 (74137)	Loss/tok 3.3204 (3.2748)	Learning Rate [7.8125e-05]
0: TRAIN [1][6570/6832]	Time 0.298 (0.347)	Data 0.00111 (0.00148)	Tok/s 70113 (74134)	Loss/tok 3.3356 (3.2748)	Learning Rate [7.8125e-05]
0: TRAIN [1][6580/6832]	Time 0.434 (0.347)	Data 0.00114 (0.00148)	Tok/s 64953 (74133)	Loss/tok 3.3469 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [1][6590/6832]	Time 0.463 (0.347)	Data 0.00113 (0.00148)	Tok/s 66821 (74127)	Loss/tok 3.3366 (3.2748)	Learning Rate [7.8125e-05]
0: TRAIN [1][6600/6832]	Time 0.456 (0.348)	Data 0.00106 (0.00148)	Tok/s 65423 (74125)	Loss/tok 3.3233 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [1][6610/6832]	Time 0.487 (0.348)	Data 0.00109 (0.00148)	Tok/s 92858 (74129)	Loss/tok 3.1212 (3.2746)	Learning Rate [7.8125e-05]
0: TRAIN [1][6620/6832]	Time 0.167 (0.347)	Data 0.00111 (0.00148)	Tok/s 75304 (74128)	Loss/tok 2.9001 (3.2745)	Learning Rate [7.8125e-05]
0: TRAIN [1][6630/6832]	Time 0.166 (0.347)	Data 0.00112 (0.00148)	Tok/s 78567 (74124)	Loss/tok 2.8643 (3.2745)	Learning Rate [7.8125e-05]
0: TRAIN [1][6640/6832]	Time 0.432 (0.348)	Data 0.00109 (0.00148)	Tok/s 67957 (74126)	Loss/tok 3.3229 (3.2744)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][6650/6832]	Time 0.167 (0.347)	Data 0.00143 (0.00148)	Tok/s 77464 (74127)	Loss/tok 2.8578 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [1][6660/6832]	Time 0.485 (0.347)	Data 0.00106 (0.00148)	Tok/s 90905 (74131)	Loss/tok 3.2189 (3.2742)	Learning Rate [7.8125e-05]
0: TRAIN [1][6670/6832]	Time 0.480 (0.347)	Data 0.00105 (0.00148)	Tok/s 68297 (74124)	Loss/tok 3.3678 (3.2742)	Learning Rate [7.8125e-05]
0: TRAIN [1][6680/6832]	Time 0.266 (0.347)	Data 0.00115 (0.00148)	Tok/s 69544 (74123)	Loss/tok 3.1180 (3.2741)	Learning Rate [7.8125e-05]
0: TRAIN [1][6690/6832]	Time 0.385 (0.347)	Data 0.00108 (0.00148)	Tok/s 66990 (74127)	Loss/tok 3.3010 (3.2740)	Learning Rate [7.8125e-05]
0: TRAIN [1][6700/6832]	Time 0.485 (0.347)	Data 0.00112 (0.00148)	Tok/s 82009 (74123)	Loss/tok 3.2860 (3.2740)	Learning Rate [7.8125e-05]
0: TRAIN [1][6710/6832]	Time 0.140 (0.347)	Data 0.00159 (0.00148)	Tok/s 79908 (74119)	Loss/tok 2.7438 (3.2740)	Learning Rate [7.8125e-05]
0: TRAIN [1][6720/6832]	Time 0.483 (0.347)	Data 0.00111 (0.00148)	Tok/s 85519 (74125)	Loss/tok 3.2308 (3.2739)	Learning Rate [7.8125e-05]
0: TRAIN [1][6730/6832]	Time 0.317 (0.347)	Data 0.00106 (0.00148)	Tok/s 70651 (74128)	Loss/tok 3.1985 (3.2737)	Learning Rate [7.8125e-05]
0: TRAIN [1][6740/6832]	Time 0.473 (0.347)	Data 0.00107 (0.00147)	Tok/s 75564 (74130)	Loss/tok 3.3085 (3.2737)	Learning Rate [7.8125e-05]
0: TRAIN [1][6750/6832]	Time 0.280 (0.347)	Data 0.00105 (0.00147)	Tok/s 73540 (74137)	Loss/tok 3.1764 (3.2735)	Learning Rate [7.8125e-05]
0: TRAIN [1][6760/6832]	Time 0.410 (0.347)	Data 0.00107 (0.00147)	Tok/s 65640 (74133)	Loss/tok 3.2837 (3.2735)	Learning Rate [7.8125e-05]
0: TRAIN [1][6770/6832]	Time 0.459 (0.347)	Data 0.00111 (0.00147)	Tok/s 65939 (74126)	Loss/tok 3.3780 (3.2735)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [1][6780/6832]	Time 0.168 (0.347)	Data 0.00112 (0.00147)	Tok/s 82120 (74128)	Loss/tok 2.9992 (3.2734)	Learning Rate [7.8125e-05]
0: TRAIN [1][6790/6832]	Time 0.113 (0.347)	Data 0.00107 (0.00147)	Tok/s 74233 (74123)	Loss/tok 2.5019 (3.2734)	Learning Rate [7.8125e-05]
0: TRAIN [1][6800/6832]	Time 0.301 (0.347)	Data 0.00113 (0.00147)	Tok/s 73960 (74118)	Loss/tok 3.1771 (3.2735)	Learning Rate [7.8125e-05]
0: TRAIN [1][6810/6832]	Time 0.467 (0.347)	Data 0.00106 (0.00147)	Tok/s 92096 (74125)	Loss/tok 3.2250 (3.2733)	Learning Rate [7.8125e-05]
0: TRAIN [1][6820/6832]	Time 0.480 (0.347)	Data 0.00103 (0.00147)	Tok/s 78345 (74129)	Loss/tok 3.4023 (3.2733)	Learning Rate [7.8125e-05]
0: TRAIN [1][6830/6832]	Time 0.482 (0.347)	Data 0.00097 (0.00148)	Tok/s 75609 (74132)	Loss/tok 3.3465 (3.2733)	Learning Rate [7.8125e-05]
0: Running validation on dev set
0: VALIDATION [1][0/80]	Time 0.064 (0.000)	Data 0.00231 (0.00000)	Tok/s 159006 (0)	Loss/tok 3.4035 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [1][10/80]	Time 0.026 (0.031)	Data 0.00174 (0.00180)	Tok/s 216719 (215457)	Loss/tok 3.1685 (3.2808)	Learning Rate [7.8125e-05]
0: VALIDATION [1][20/80]	Time 0.022 (0.027)	Data 0.00174 (0.00176)	Tok/s 209470 (214919)	Loss/tok 3.1716 (3.2564)	Learning Rate [7.8125e-05]
0: VALIDATION [1][30/80]	Time 0.019 (0.025)	Data 0.00161 (0.00172)	Tok/s 194498 (214388)	Loss/tok 3.2121 (3.2302)	Learning Rate [7.8125e-05]
0: VALIDATION [1][40/80]	Time 0.015 (0.023)	Data 0.00158 (0.00170)	Tok/s 204572 (211225)	Loss/tok 3.1782 (3.2145)	Learning Rate [7.8125e-05]
0: VALIDATION [1][50/80]	Time 0.014 (0.021)	Data 0.00155 (0.00167)	Tok/s 189808 (207942)	Loss/tok 3.0230 (3.1991)	Learning Rate [7.8125e-05]
0: VALIDATION [1][60/80]	Time 0.015 (0.020)	Data 0.00155 (0.00165)	Tok/s 144142 (202568)	Loss/tok 3.2497 (3.1933)	Learning Rate [7.8125e-05]
0: VALIDATION [1][70/80]	Time 0.014 (0.019)	Data 0.00151 (0.00164)	Tok/s 111173 (191537)	Loss/tok 3.0976 (3.1861)	Learning Rate [7.8125e-05]
:::MLPv0.5.0 gnmt 1560839058.712155581 (train.py:459) eval_start: 1
0: Running evaluation on test set
0: TEST [1][0/6]	Time 2.097 (2.097)	Decoder iters 149.0 (149.0)	Tok/s 14205 (14205)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560839074.433934927 (train.py:464) eval_accuracy: {"epoch": 1, "value": 21.15999984741211}
:::MLPv0.5.0 gnmt 1560839074.434462786 (train.py:466) eval_target: 21.8
:::MLPv0.5.0 gnmt 1560839074.434887648 (train.py:467) eval_stop
0: Summary: Epoch: 1	Training Loss: 3.2732	Validation Loss: 3.1765	Test BLEU: 21.16
0: Performance: Epoch: 1	Training: 74133 Tok/s	Validation: 180788 Tok/s
0: Finished epoch 1
0: Starting epoch 2
:::MLPv0.5.0 gnmt 1560839074.435738802 (train.py:443) train_epoch: 2
/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:182: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
  self.num_layers, self.dropout, self.training, self.bidirectional)
:::MLPv0.5.0 gnmt 1560839075.037923574 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 2037452816
:::MLPv0.5.0 gnmt 1560839075.121918440 (seq2seq/data/sampler.py:66) input_shard: 40960
0: TRAIN [2][0/6832]	Time 1.277 (0.000)	Data 0.98125 (0.00000)	Tok/s 17237 (0)	Loss/tok 3.2029 (0.0000)	Learning Rate [7.8125e-05]
0: TRAIN [2][10/6832]	Time 0.483 (0.346)	Data 0.00129 (0.00128)	Tok/s 96476 (75020)	Loss/tok 3.1090 (3.2345)	Learning Rate [7.8125e-05]
0: TRAIN [2][20/6832]	Time 0.376 (0.360)	Data 0.00113 (0.00125)	Tok/s 68085 (72665)	Loss/tok 3.2874 (3.2528)	Learning Rate [7.8125e-05]
0: TRAIN [2][30/6832]	Time 0.230 (0.337)	Data 0.00102 (0.00120)	Tok/s 71213 (73274)	Loss/tok 3.0168 (3.2416)	Learning Rate [7.8125e-05]
0: TRAIN [2][40/6832]	Time 0.484 (0.334)	Data 0.00107 (0.00118)	Tok/s 79018 (74485)	Loss/tok 3.2676 (3.2206)	Learning Rate [7.8125e-05]
0: TRAIN [2][50/6832]	Time 0.283 (0.330)	Data 0.00105 (0.00117)	Tok/s 70567 (74831)	Loss/tok 3.1766 (3.2147)	Learning Rate [7.8125e-05]
0: TRAIN [2][60/6832]	Time 0.348 (0.326)	Data 0.00110 (0.00116)	Tok/s 69058 (74063)	Loss/tok 3.2641 (3.2158)	Learning Rate [7.8125e-05]
0: TRAIN [2][70/6832]	Time 0.479 (0.322)	Data 0.00140 (0.00116)	Tok/s 71321 (74353)	Loss/tok 3.4071 (3.2139)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][80/6832]	Time 0.110 (0.329)	Data 0.00108 (0.00115)	Tok/s 76389 (74022)	Loss/tok 2.4347 (3.2229)	Learning Rate [7.8125e-05]
0: TRAIN [2][90/6832]	Time 0.165 (0.326)	Data 0.00112 (0.00115)	Tok/s 78231 (74567)	Loss/tok 2.8518 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [2][100/6832]	Time 0.321 (0.329)	Data 0.00113 (0.00114)	Tok/s 73618 (74502)	Loss/tok 3.2193 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [2][110/6832]	Time 0.484 (0.335)	Data 0.00108 (0.00549)	Tok/s 72751 (73908)	Loss/tok 3.3060 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [2][120/6832]	Time 0.219 (0.338)	Data 0.00105 (0.00512)	Tok/s 74843 (73969)	Loss/tok 3.0960 (3.2179)	Learning Rate [7.8125e-05]
0: TRAIN [2][130/6832]	Time 0.319 (0.336)	Data 0.00105 (0.00481)	Tok/s 70684 (73994)	Loss/tok 3.2388 (3.2183)	Learning Rate [7.8125e-05]
0: TRAIN [2][140/6832]	Time 0.345 (0.334)	Data 0.00109 (0.00455)	Tok/s 68739 (73786)	Loss/tok 3.2808 (3.2181)	Learning Rate [7.8125e-05]
0: TRAIN [2][150/6832]	Time 0.468 (0.338)	Data 0.00103 (0.00432)	Tok/s 71438 (73592)	Loss/tok 3.3288 (3.2243)	Learning Rate [7.8125e-05]
0: TRAIN [2][160/6832]	Time 0.473 (0.338)	Data 0.00106 (0.00412)	Tok/s 71220 (73679)	Loss/tok 3.3213 (3.2241)	Learning Rate [7.8125e-05]
0: TRAIN [2][170/6832]	Time 0.148 (0.343)	Data 0.00119 (0.00394)	Tok/s 84154 (73717)	Loss/tok 2.8835 (3.2304)	Learning Rate [7.8125e-05]
0: TRAIN [2][180/6832]	Time 0.429 (0.343)	Data 0.00106 (0.00378)	Tok/s 67502 (73604)	Loss/tok 3.3861 (3.2347)	Learning Rate [7.8125e-05]
0: TRAIN [2][190/6832]	Time 0.312 (0.343)	Data 0.00105 (0.00364)	Tok/s 69414 (73633)	Loss/tok 3.2377 (3.2395)	Learning Rate [7.8125e-05]
0: TRAIN [2][200/6832]	Time 0.486 (0.347)	Data 0.00107 (0.00352)	Tok/s 95857 (73977)	Loss/tok 3.1929 (3.2423)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][210/6832]	Time 0.460 (0.347)	Data 0.00103 (0.00340)	Tok/s 105866 (74243)	Loss/tok 3.1577 (3.2408)	Learning Rate [7.8125e-05]
0: TRAIN [2][220/6832]	Time 0.416 (0.348)	Data 0.00106 (0.00330)	Tok/s 65876 (74273)	Loss/tok 3.3096 (3.2410)	Learning Rate [7.8125e-05]
0: TRAIN [2][230/6832]	Time 0.313 (0.348)	Data 0.00115 (0.00321)	Tok/s 70415 (74304)	Loss/tok 3.1905 (3.2412)	Learning Rate [7.8125e-05]
0: TRAIN [2][240/6832]	Time 0.139 (0.348)	Data 0.00109 (0.00312)	Tok/s 82212 (74190)	Loss/tok 2.7206 (3.2442)	Learning Rate [7.8125e-05]
0: TRAIN [2][250/6832]	Time 0.318 (0.346)	Data 0.00101 (0.00304)	Tok/s 71082 (74169)	Loss/tok 3.2176 (3.2440)	Learning Rate [7.8125e-05]
0: TRAIN [2][260/6832]	Time 0.396 (0.345)	Data 0.00109 (0.00297)	Tok/s 66063 (73981)	Loss/tok 3.2803 (3.2461)	Learning Rate [7.8125e-05]
0: TRAIN [2][270/6832]	Time 0.487 (0.344)	Data 0.00105 (0.00290)	Tok/s 99978 (73971)	Loss/tok 3.1464 (3.2444)	Learning Rate [7.8125e-05]
0: TRAIN [2][280/6832]	Time 0.223 (0.343)	Data 0.00104 (0.00283)	Tok/s 74937 (73950)	Loss/tok 3.0030 (3.2458)	Learning Rate [7.8125e-05]
0: TRAIN [2][290/6832]	Time 0.435 (0.345)	Data 0.00108 (0.00300)	Tok/s 65895 (73744)	Loss/tok 3.4359 (3.2504)	Learning Rate [7.8125e-05]
0: TRAIN [2][300/6832]	Time 0.337 (0.343)	Data 0.00114 (0.00294)	Tok/s 71430 (73724)	Loss/tok 3.3144 (3.2508)	Learning Rate [7.8125e-05]
0: TRAIN [2][310/6832]	Time 0.359 (0.345)	Data 0.00131 (0.00288)	Tok/s 68184 (73790)	Loss/tok 3.3679 (3.2545)	Learning Rate [7.8125e-05]
0: TRAIN [2][320/6832]	Time 0.488 (0.346)	Data 0.00156 (0.00283)	Tok/s 78704 (74035)	Loss/tok 3.3064 (3.2539)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][330/6832]	Time 0.197 (0.346)	Data 0.00129 (0.00279)	Tok/s 77244 (74157)	Loss/tok 3.1329 (3.2544)	Learning Rate [7.8125e-05]
0: TRAIN [2][340/6832]	Time 0.398 (0.347)	Data 0.00140 (0.00274)	Tok/s 69491 (74123)	Loss/tok 3.3312 (3.2571)	Learning Rate [7.8125e-05]
0: TRAIN [2][350/6832]	Time 0.392 (0.348)	Data 0.00102 (0.00270)	Tok/s 68874 (74075)	Loss/tok 3.3458 (3.2578)	Learning Rate [7.8125e-05]
0: TRAIN [2][360/6832]	Time 0.383 (0.347)	Data 0.00128 (0.00266)	Tok/s 66887 (74264)	Loss/tok 3.3845 (3.2562)	Learning Rate [7.8125e-05]
0: TRAIN [2][370/6832]	Time 0.228 (0.348)	Data 0.00107 (0.00262)	Tok/s 74895 (74258)	Loss/tok 3.1133 (3.2577)	Learning Rate [7.8125e-05]
0: TRAIN [2][380/6832]	Time 0.464 (0.348)	Data 0.00103 (0.00259)	Tok/s 95354 (74316)	Loss/tok 3.1930 (3.2575)	Learning Rate [7.8125e-05]
0: TRAIN [2][390/6832]	Time 0.468 (0.348)	Data 0.00104 (0.00256)	Tok/s 65513 (74257)	Loss/tok 3.3449 (3.2578)	Learning Rate [7.8125e-05]
0: TRAIN [2][400/6832]	Time 0.400 (0.347)	Data 0.00122 (0.00252)	Tok/s 67630 (74220)	Loss/tok 3.3404 (3.2586)	Learning Rate [7.8125e-05]
0: TRAIN [2][410/6832]	Time 0.180 (0.346)	Data 0.00128 (0.00249)	Tok/s 77320 (74177)	Loss/tok 3.0207 (3.2585)	Learning Rate [7.8125e-05]
0: TRAIN [2][420/6832]	Time 0.100 (0.347)	Data 0.00133 (0.00246)	Tok/s 57404 (74143)	Loss/tok 2.0655 (3.2595)	Learning Rate [7.8125e-05]
0: TRAIN [2][430/6832]	Time 0.490 (0.348)	Data 0.00138 (0.00243)	Tok/s 84507 (74115)	Loss/tok 3.3211 (3.2608)	Learning Rate [7.8125e-05]
0: TRAIN [2][440/6832]	Time 0.301 (0.348)	Data 0.00151 (0.00241)	Tok/s 69842 (74169)	Loss/tok 3.2121 (3.2617)	Learning Rate [7.8125e-05]
0: TRAIN [2][450/6832]	Time 0.286 (0.348)	Data 0.00134 (0.00239)	Tok/s 72420 (74233)	Loss/tok 3.2138 (3.2609)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][460/6832]	Time 0.482 (0.349)	Data 0.00135 (0.00236)	Tok/s 69853 (74173)	Loss/tok 3.4488 (3.2623)	Learning Rate [7.8125e-05]
0: TRAIN [2][470/6832]	Time 0.245 (0.350)	Data 0.00132 (0.00234)	Tok/s 75100 (74183)	Loss/tok 3.1752 (3.2634)	Learning Rate [7.8125e-05]
0: TRAIN [2][480/6832]	Time 0.111 (0.349)	Data 0.00107 (0.00232)	Tok/s 75997 (74208)	Loss/tok 2.4566 (3.2627)	Learning Rate [7.8125e-05]
0: TRAIN [2][490/6832]	Time 0.463 (0.350)	Data 0.00135 (0.00230)	Tok/s 71808 (74279)	Loss/tok 3.3945 (3.2637)	Learning Rate [7.8125e-05]
0: TRAIN [2][500/6832]	Time 0.482 (0.351)	Data 0.00134 (0.00228)	Tok/s 67243 (74171)	Loss/tok 3.3966 (3.2649)	Learning Rate [7.8125e-05]
0: TRAIN [2][510/6832]	Time 0.406 (0.351)	Data 0.00140 (0.00226)	Tok/s 68064 (74146)	Loss/tok 3.2371 (3.2651)	Learning Rate [7.8125e-05]
0: TRAIN [2][520/6832]	Time 0.477 (0.351)	Data 0.00141 (0.00224)	Tok/s 72651 (74136)	Loss/tok 3.4140 (3.2653)	Learning Rate [7.8125e-05]
0: TRAIN [2][530/6832]	Time 0.305 (0.352)	Data 0.00139 (0.00223)	Tok/s 70508 (74124)	Loss/tok 3.2954 (3.2663)	Learning Rate [7.8125e-05]
0: TRAIN [2][540/6832]	Time 0.416 (0.351)	Data 0.00168 (0.00221)	Tok/s 65594 (74115)	Loss/tok 3.4797 (3.2657)	Learning Rate [7.8125e-05]
0: TRAIN [2][550/6832]	Time 0.234 (0.349)	Data 0.00151 (0.00219)	Tok/s 70148 (74075)	Loss/tok 3.0974 (3.2647)	Learning Rate [7.8125e-05]
0: TRAIN [2][560/6832]	Time 0.245 (0.350)	Data 0.00134 (0.00218)	Tok/s 73162 (74066)	Loss/tok 3.1431 (3.2650)	Learning Rate [7.8125e-05]
0: TRAIN [2][570/6832]	Time 0.464 (0.351)	Data 0.00116 (0.00216)	Tok/s 65854 (74096)	Loss/tok 3.3977 (3.2651)	Learning Rate [7.8125e-05]
0: TRAIN [2][580/6832]	Time 0.404 (0.350)	Data 0.00111 (0.00215)	Tok/s 66558 (74100)	Loss/tok 3.3155 (3.2647)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][590/6832]	Time 0.133 (0.351)	Data 0.00120 (0.00213)	Tok/s 85110 (74104)	Loss/tok 2.7512 (3.2650)	Learning Rate [7.8125e-05]
0: TRAIN [2][600/6832]	Time 0.486 (0.351)	Data 0.00106 (0.00211)	Tok/s 77814 (74114)	Loss/tok 3.4843 (3.2657)	Learning Rate [7.8125e-05]
0: TRAIN [2][610/6832]	Time 0.321 (0.351)	Data 0.00110 (0.00210)	Tok/s 71864 (74155)	Loss/tok 3.2397 (3.2656)	Learning Rate [7.8125e-05]
0: TRAIN [2][620/6832]	Time 0.477 (0.352)	Data 0.00112 (0.00208)	Tok/s 75466 (74121)	Loss/tok 3.4492 (3.2664)	Learning Rate [7.8125e-05]
0: TRAIN [2][630/6832]	Time 0.423 (0.352)	Data 0.00104 (0.00206)	Tok/s 68978 (74101)	Loss/tok 3.3095 (3.2664)	Learning Rate [7.8125e-05]
0: TRAIN [2][640/6832]	Time 0.286 (0.351)	Data 0.00108 (0.00205)	Tok/s 70805 (74085)	Loss/tok 3.2929 (3.2659)	Learning Rate [7.8125e-05]
0: TRAIN [2][650/6832]	Time 0.464 (0.351)	Data 0.00121 (0.00204)	Tok/s 69644 (74101)	Loss/tok 3.3920 (3.2669)	Learning Rate [7.8125e-05]
0: TRAIN [2][660/6832]	Time 0.240 (0.352)	Data 0.00113 (0.00202)	Tok/s 71272 (74168)	Loss/tok 3.1056 (3.2672)	Learning Rate [7.8125e-05]
0: TRAIN [2][670/6832]	Time 0.309 (0.352)	Data 0.00117 (0.00201)	Tok/s 71148 (74163)	Loss/tok 3.2781 (3.2671)	Learning Rate [7.8125e-05]
0: TRAIN [2][680/6832]	Time 0.484 (0.352)	Data 0.00108 (0.00200)	Tok/s 81849 (74186)	Loss/tok 3.3802 (3.2669)	Learning Rate [7.8125e-05]
0: TRAIN [2][690/6832]	Time 0.403 (0.352)	Data 0.00105 (0.00198)	Tok/s 64992 (74247)	Loss/tok 3.4031 (3.2668)	Learning Rate [7.8125e-05]
0: TRAIN [2][700/6832]	Time 0.483 (0.352)	Data 0.00125 (0.00197)	Tok/s 79677 (74249)	Loss/tok 3.5005 (3.2673)	Learning Rate [7.8125e-05]
0: TRAIN [2][710/6832]	Time 0.280 (0.352)	Data 0.00109 (0.00196)	Tok/s 72420 (74286)	Loss/tok 3.2268 (3.2678)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][720/6832]	Time 0.202 (0.352)	Data 0.00111 (0.00195)	Tok/s 77513 (74263)	Loss/tok 3.0664 (3.2681)	Learning Rate [7.8125e-05]
0: TRAIN [2][730/6832]	Time 0.357 (0.351)	Data 0.00100 (0.00194)	Tok/s 67353 (74273)	Loss/tok 3.3515 (3.2676)	Learning Rate [7.8125e-05]
0: TRAIN [2][740/6832]	Time 0.239 (0.351)	Data 0.00113 (0.00192)	Tok/s 72932 (74287)	Loss/tok 3.1195 (3.2681)	Learning Rate [7.8125e-05]
0: TRAIN [2][750/6832]	Time 0.481 (0.351)	Data 0.00103 (0.00191)	Tok/s 97038 (74238)	Loss/tok 3.2227 (3.2685)	Learning Rate [7.8125e-05]
0: TRAIN [2][760/6832]	Time 0.159 (0.351)	Data 0.00120 (0.00190)	Tok/s 78128 (74223)	Loss/tok 2.8623 (3.2692)	Learning Rate [7.8125e-05]
0: TRAIN [2][770/6832]	Time 0.483 (0.352)	Data 0.00104 (0.00189)	Tok/s 67771 (74252)	Loss/tok 3.3848 (3.2696)	Learning Rate [7.8125e-05]
0: TRAIN [2][780/6832]	Time 0.482 (0.352)	Data 0.00107 (0.00188)	Tok/s 70779 (74265)	Loss/tok 3.5450 (3.2709)	Learning Rate [7.8125e-05]
0: TRAIN [2][790/6832]	Time 0.185 (0.352)	Data 0.00114 (0.00187)	Tok/s 82087 (74309)	Loss/tok 3.1312 (3.2715)	Learning Rate [7.8125e-05]
0: TRAIN [2][800/6832]	Time 0.253 (0.352)	Data 0.00109 (0.00186)	Tok/s 71736 (74347)	Loss/tok 3.1953 (3.2716)	Learning Rate [7.8125e-05]
0: TRAIN [2][810/6832]	Time 0.483 (0.351)	Data 0.00112 (0.00185)	Tok/s 77948 (74362)	Loss/tok 3.3757 (3.2714)	Learning Rate [7.8125e-05]
0: TRAIN [2][820/6832]	Time 0.095 (0.351)	Data 0.00105 (0.00184)	Tok/s 60085 (74409)	Loss/tok 2.0953 (3.2716)	Learning Rate [7.8125e-05]
0: TRAIN [2][830/6832]	Time 0.485 (0.352)	Data 0.00110 (0.00184)	Tok/s 81848 (74396)	Loss/tok 3.2755 (3.2722)	Learning Rate [7.8125e-05]
0: TRAIN [2][840/6832]	Time 0.150 (0.352)	Data 0.00111 (0.00183)	Tok/s 79677 (74424)	Loss/tok 2.8983 (3.2723)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][850/6832]	Time 0.403 (0.351)	Data 0.00106 (0.00182)	Tok/s 67568 (74417)	Loss/tok 3.2709 (3.2719)	Learning Rate [7.8125e-05]
0: TRAIN [2][860/6832]	Time 0.480 (0.352)	Data 0.00109 (0.00182)	Tok/s 77055 (74391)	Loss/tok 3.3292 (3.2728)	Learning Rate [7.8125e-05]
0: TRAIN [2][870/6832]	Time 0.365 (0.351)	Data 0.00111 (0.00181)	Tok/s 67701 (74406)	Loss/tok 3.4294 (3.2729)	Learning Rate [7.8125e-05]
0: TRAIN [2][880/6832]	Time 0.279 (0.352)	Data 0.00140 (0.00181)	Tok/s 73379 (74385)	Loss/tok 3.1753 (3.2736)	Learning Rate [7.8125e-05]
0: TRAIN [2][890/6832]	Time 0.143 (0.351)	Data 0.00100 (0.00180)	Tok/s 78341 (74415)	Loss/tok 2.8134 (3.2735)	Learning Rate [7.8125e-05]
0: TRAIN [2][900/6832]	Time 0.478 (0.351)	Data 0.00106 (0.00179)	Tok/s 69808 (74384)	Loss/tok 3.5199 (3.2740)	Learning Rate [7.8125e-05]
0: TRAIN [2][910/6832]	Time 0.481 (0.351)	Data 0.00103 (0.00178)	Tok/s 73196 (74403)	Loss/tok 3.3419 (3.2735)	Learning Rate [7.8125e-05]
0: TRAIN [2][920/6832]	Time 0.292 (0.351)	Data 0.00109 (0.00178)	Tok/s 69615 (74376)	Loss/tok 3.2415 (3.2741)	Learning Rate [7.8125e-05]
0: TRAIN [2][930/6832]	Time 0.159 (0.350)	Data 0.00110 (0.00177)	Tok/s 81590 (74432)	Loss/tok 2.9039 (3.2731)	Learning Rate [7.8125e-05]
0: TRAIN [2][940/6832]	Time 0.199 (0.349)	Data 0.00106 (0.00176)	Tok/s 74363 (74415)	Loss/tok 3.0269 (3.2731)	Learning Rate [7.8125e-05]
0: TRAIN [2][950/6832]	Time 0.226 (0.349)	Data 0.00108 (0.00175)	Tok/s 74074 (74412)	Loss/tok 3.1440 (3.2732)	Learning Rate [7.8125e-05]
0: TRAIN [2][960/6832]	Time 0.199 (0.349)	Data 0.00108 (0.00175)	Tok/s 77957 (74423)	Loss/tok 3.0001 (3.2731)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][970/6832]	Time 0.186 (0.349)	Data 0.00122 (0.00174)	Tok/s 75162 (74445)	Loss/tok 2.9941 (3.2728)	Learning Rate [7.8125e-05]
0: TRAIN [2][980/6832]	Time 0.252 (0.348)	Data 0.00106 (0.00174)	Tok/s 73204 (74436)	Loss/tok 3.3104 (3.2722)	Learning Rate [7.8125e-05]
0: TRAIN [2][990/6832]	Time 0.487 (0.348)	Data 0.00105 (0.00173)	Tok/s 84628 (74462)	Loss/tok 3.3219 (3.2724)	Learning Rate [7.8125e-05]
0: TRAIN [2][1000/6832]	Time 0.211 (0.348)	Data 0.00107 (0.00172)	Tok/s 75789 (74486)	Loss/tok 2.9847 (3.2725)	Learning Rate [7.8125e-05]
0: TRAIN [2][1010/6832]	Time 0.432 (0.348)	Data 0.00107 (0.00172)	Tok/s 65174 (74473)	Loss/tok 3.2866 (3.2721)	Learning Rate [7.8125e-05]
0: TRAIN [2][1020/6832]	Time 0.484 (0.347)	Data 0.00104 (0.00171)	Tok/s 79304 (74474)	Loss/tok 3.4157 (3.2722)	Learning Rate [7.8125e-05]
0: TRAIN [2][1030/6832]	Time 0.487 (0.347)	Data 0.00111 (0.00171)	Tok/s 76166 (74474)	Loss/tok 3.4411 (3.2722)	Learning Rate [7.8125e-05]
0: TRAIN [2][1040/6832]	Time 0.470 (0.347)	Data 0.00111 (0.00170)	Tok/s 77652 (74495)	Loss/tok 3.3985 (3.2727)	Learning Rate [7.8125e-05]
0: TRAIN [2][1050/6832]	Time 0.452 (0.348)	Data 0.00115 (0.00170)	Tok/s 63298 (74451)	Loss/tok 3.3665 (3.2733)	Learning Rate [7.8125e-05]
0: TRAIN [2][1060/6832]	Time 0.286 (0.348)	Data 0.00107 (0.00169)	Tok/s 71685 (74431)	Loss/tok 3.2622 (3.2738)	Learning Rate [7.8125e-05]
0: TRAIN [2][1070/6832]	Time 0.203 (0.347)	Data 0.00107 (0.00168)	Tok/s 75008 (74415)	Loss/tok 3.1139 (3.2737)	Learning Rate [7.8125e-05]
0: TRAIN [2][1080/6832]	Time 0.157 (0.348)	Data 0.00112 (0.00168)	Tok/s 79542 (74406)	Loss/tok 2.9453 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [2][1090/6832]	Time 0.463 (0.348)	Data 0.00107 (0.00167)	Tok/s 84074 (74427)	Loss/tok 3.3108 (3.2743)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][1100/6832]	Time 0.481 (0.348)	Data 0.00111 (0.00167)	Tok/s 84375 (74432)	Loss/tok 3.2819 (3.2749)	Learning Rate [7.8125e-05]
0: TRAIN [2][1110/6832]	Time 0.123 (0.348)	Data 0.00107 (0.00167)	Tok/s 85763 (74435)	Loss/tok 2.7495 (3.2751)	Learning Rate [7.8125e-05]
0: TRAIN [2][1120/6832]	Time 0.479 (0.348)	Data 0.00107 (0.00166)	Tok/s 68954 (74406)	Loss/tok 3.4999 (3.2754)	Learning Rate [7.8125e-05]
0: TRAIN [2][1130/6832]	Time 0.190 (0.347)	Data 0.00114 (0.00166)	Tok/s 78091 (74421)	Loss/tok 3.1057 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [2][1140/6832]	Time 0.458 (0.348)	Data 0.00112 (0.00165)	Tok/s 63961 (74406)	Loss/tok 3.4010 (3.2751)	Learning Rate [7.8125e-05]
0: TRAIN [2][1150/6832]	Time 0.146 (0.348)	Data 0.00111 (0.00165)	Tok/s 76124 (74372)	Loss/tok 2.6959 (3.2758)	Learning Rate [7.8125e-05]
0: TRAIN [2][1160/6832]	Time 0.289 (0.348)	Data 0.00105 (0.00164)	Tok/s 72710 (74385)	Loss/tok 3.2521 (3.2763)	Learning Rate [7.8125e-05]
0: TRAIN [2][1170/6832]	Time 0.472 (0.348)	Data 0.00118 (0.00164)	Tok/s 65695 (74349)	Loss/tok 3.3551 (3.2764)	Learning Rate [7.8125e-05]
0: TRAIN [2][1180/6832]	Time 0.281 (0.348)	Data 0.00107 (0.00163)	Tok/s 73482 (74397)	Loss/tok 3.2436 (3.2762)	Learning Rate [7.8125e-05]
0: TRAIN [2][1190/6832]	Time 0.477 (0.349)	Data 0.00109 (0.00163)	Tok/s 71548 (74368)	Loss/tok 3.4043 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [2][1200/6832]	Time 0.487 (0.349)	Data 0.00105 (0.00163)	Tok/s 77052 (74371)	Loss/tok 3.3304 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [2][1210/6832]	Time 0.378 (0.349)	Data 0.00103 (0.00162)	Tok/s 66444 (74332)	Loss/tok 3.3722 (3.2768)	Learning Rate [7.8125e-05]
0: TRAIN [2][1220/6832]	Time 0.483 (0.349)	Data 0.00106 (0.00162)	Tok/s 85492 (74326)	Loss/tok 3.3124 (3.2771)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][1230/6832]	Time 0.281 (0.348)	Data 0.00113 (0.00161)	Tok/s 76447 (74303)	Loss/tok 3.2126 (3.2768)	Learning Rate [7.8125e-05]
0: TRAIN [2][1240/6832]	Time 0.479 (0.348)	Data 0.00106 (0.00161)	Tok/s 72755 (74326)	Loss/tok 3.4478 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [2][1250/6832]	Time 0.293 (0.348)	Data 0.00115 (0.00161)	Tok/s 73339 (74320)	Loss/tok 3.2349 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [2][1260/6832]	Time 0.199 (0.348)	Data 0.00105 (0.00160)	Tok/s 80070 (74321)	Loss/tok 3.0690 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [2][1270/6832]	Time 0.337 (0.348)	Data 0.00107 (0.00160)	Tok/s 69141 (74329)	Loss/tok 3.2570 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [2][1280/6832]	Time 0.451 (0.348)	Data 0.00110 (0.00159)	Tok/s 64718 (74338)	Loss/tok 3.4385 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [2][1290/6832]	Time 0.243 (0.348)	Data 0.00106 (0.00159)	Tok/s 70592 (74317)	Loss/tok 3.0776 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [2][1300/6832]	Time 0.184 (0.347)	Data 0.00111 (0.00159)	Tok/s 78071 (74325)	Loss/tok 2.9830 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [2][1310/6832]	Time 0.367 (0.347)	Data 0.00121 (0.00158)	Tok/s 70578 (74301)	Loss/tok 3.3169 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [2][1320/6832]	Time 0.454 (0.346)	Data 0.00105 (0.00158)	Tok/s 66471 (74291)	Loss/tok 3.4606 (3.2765)	Learning Rate [7.8125e-05]
0: TRAIN [2][1330/6832]	Time 0.420 (0.346)	Data 0.00132 (0.00158)	Tok/s 69621 (74285)	Loss/tok 3.3778 (3.2765)	Learning Rate [7.8125e-05]
0: TRAIN [2][1340/6832]	Time 0.422 (0.346)	Data 0.00108 (0.00157)	Tok/s 67973 (74256)	Loss/tok 3.4130 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [2][1350/6832]	Time 0.486 (0.346)	Data 0.00108 (0.00157)	Tok/s 90716 (74283)	Loss/tok 3.3696 (3.2771)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][1360/6832]	Time 0.281 (0.346)	Data 0.00106 (0.00157)	Tok/s 71788 (74282)	Loss/tok 3.1961 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [2][1370/6832]	Time 0.206 (0.346)	Data 0.00116 (0.00156)	Tok/s 75731 (74290)	Loss/tok 3.0365 (3.2768)	Learning Rate [7.8125e-05]
0: TRAIN [2][1380/6832]	Time 0.333 (0.346)	Data 0.00108 (0.00156)	Tok/s 73350 (74306)	Loss/tok 3.3828 (3.2770)	Learning Rate [7.8125e-05]
0: TRAIN [2][1390/6832]	Time 0.468 (0.345)	Data 0.00115 (0.00156)	Tok/s 70787 (74320)	Loss/tok 3.4452 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [2][1400/6832]	Time 0.367 (0.345)	Data 0.00108 (0.00155)	Tok/s 67899 (74335)	Loss/tok 3.2538 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [2][1410/6832]	Time 0.314 (0.345)	Data 0.00105 (0.00155)	Tok/s 70163 (74315)	Loss/tok 3.1565 (3.2765)	Learning Rate [7.8125e-05]
0: TRAIN [2][1420/6832]	Time 0.485 (0.345)	Data 0.00105 (0.00155)	Tok/s 81809 (74322)	Loss/tok 3.5101 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [2][1430/6832]	Time 0.484 (0.345)	Data 0.00110 (0.00154)	Tok/s 86832 (74330)	Loss/tok 3.2681 (3.2767)	Learning Rate [7.8125e-05]
0: TRAIN [2][1440/6832]	Time 0.113 (0.346)	Data 0.00116 (0.00154)	Tok/s 75424 (74337)	Loss/tok 2.4778 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [2][1450/6832]	Time 0.326 (0.346)	Data 0.00117 (0.00154)	Tok/s 68255 (74321)	Loss/tok 3.2654 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [2][1460/6832]	Time 0.139 (0.345)	Data 0.00104 (0.00154)	Tok/s 69470 (74326)	Loss/tok 2.6245 (3.2770)	Learning Rate [7.8125e-05]
0: TRAIN [2][1470/6832]	Time 0.424 (0.345)	Data 0.00105 (0.00153)	Tok/s 66414 (74311)	Loss/tok 3.3518 (3.2770)	Learning Rate [7.8125e-05]
0: TRAIN [2][1480/6832]	Time 0.483 (0.346)	Data 0.00108 (0.00153)	Tok/s 76664 (74316)	Loss/tok 3.3434 (3.2773)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][1490/6832]	Time 0.420 (0.346)	Data 0.00111 (0.00153)	Tok/s 66036 (74341)	Loss/tok 3.3568 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [2][1500/6832]	Time 0.486 (0.346)	Data 0.00112 (0.00152)	Tok/s 86513 (74353)	Loss/tok 3.3097 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [2][1510/6832]	Time 0.446 (0.347)	Data 0.00115 (0.00152)	Tok/s 69770 (74341)	Loss/tok 3.4019 (3.2776)	Learning Rate [7.8125e-05]
0: TRAIN [2][1520/6832]	Time 0.482 (0.347)	Data 0.00107 (0.00152)	Tok/s 82452 (74346)	Loss/tok 3.3213 (3.2774)	Learning Rate [7.8125e-05]
0: TRAIN [2][1530/6832]	Time 0.221 (0.347)	Data 0.00110 (0.00152)	Tok/s 75316 (74333)	Loss/tok 3.1025 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [2][1540/6832]	Time 0.140 (0.347)	Data 0.00117 (0.00151)	Tok/s 80047 (74355)	Loss/tok 2.7870 (3.2775)	Learning Rate [7.8125e-05]
0: TRAIN [2][1550/6832]	Time 0.349 (0.347)	Data 0.00113 (0.00151)	Tok/s 69018 (74368)	Loss/tok 3.3250 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [2][1560/6832]	Time 0.120 (0.347)	Data 0.00107 (0.00151)	Tok/s 70008 (74338)	Loss/tok 2.4858 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [2][1570/6832]	Time 0.490 (0.347)	Data 0.00106 (0.00151)	Tok/s 99381 (74360)	Loss/tok 3.1125 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [2][1580/6832]	Time 0.481 (0.348)	Data 0.00110 (0.00151)	Tok/s 71428 (74336)	Loss/tok 3.3940 (3.2783)	Learning Rate [7.8125e-05]
0: TRAIN [2][1590/6832]	Time 0.465 (0.348)	Data 0.00109 (0.00150)	Tok/s 74681 (74369)	Loss/tok 3.3989 (3.2783)	Learning Rate [7.8125e-05]
0: TRAIN [2][1600/6832]	Time 0.260 (0.348)	Data 0.00110 (0.00150)	Tok/s 72954 (74391)	Loss/tok 3.1935 (3.2780)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][1610/6832]	Time 0.458 (0.348)	Data 0.00125 (0.00150)	Tok/s 69685 (74393)	Loss/tok 3.4159 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [2][1620/6832]	Time 0.112 (0.348)	Data 0.00116 (0.00150)	Tok/s 74603 (74374)	Loss/tok 2.4183 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [2][1630/6832]	Time 0.236 (0.348)	Data 0.00105 (0.00149)	Tok/s 78052 (74385)	Loss/tok 3.2011 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [2][1640/6832]	Time 0.333 (0.348)	Data 0.00109 (0.00149)	Tok/s 69932 (74352)	Loss/tok 3.2749 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [2][1650/6832]	Time 0.184 (0.348)	Data 0.00111 (0.00149)	Tok/s 80134 (74367)	Loss/tok 3.0508 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [2][1660/6832]	Time 0.194 (0.349)	Data 0.00107 (0.00149)	Tok/s 77859 (74353)	Loss/tok 3.0346 (3.2783)	Learning Rate [7.8125e-05]
0: TRAIN [2][1670/6832]	Time 0.464 (0.349)	Data 0.00109 (0.00148)	Tok/s 90618 (74402)	Loss/tok 3.3032 (3.2781)	Learning Rate [7.8125e-05]
0: TRAIN [2][1680/6832]	Time 0.168 (0.348)	Data 0.00099 (0.00148)	Tok/s 77594 (74407)	Loss/tok 2.9414 (3.2778)	Learning Rate [7.8125e-05]
0: TRAIN [2][1690/6832]	Time 0.347 (0.348)	Data 0.00106 (0.00148)	Tok/s 70115 (74395)	Loss/tok 3.2542 (3.2779)	Learning Rate [7.8125e-05]
0: TRAIN [2][1700/6832]	Time 0.429 (0.348)	Data 0.00105 (0.00148)	Tok/s 66273 (74377)	Loss/tok 3.3453 (3.2777)	Learning Rate [7.8125e-05]
0: TRAIN [2][1710/6832]	Time 0.457 (0.348)	Data 0.00102 (0.00147)	Tok/s 66852 (74397)	Loss/tok 3.3060 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [2][1720/6832]	Time 0.207 (0.349)	Data 0.00111 (0.00147)	Tok/s 75231 (74392)	Loss/tok 3.1323 (3.2776)	Learning Rate [7.8125e-05]
0: TRAIN [2][1730/6832]	Time 0.147 (0.349)	Data 0.00109 (0.00147)	Tok/s 75848 (74395)	Loss/tok 2.7703 (3.2774)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][1740/6832]	Time 0.264 (0.348)	Data 0.00106 (0.00147)	Tok/s 73956 (74385)	Loss/tok 3.2330 (3.2774)	Learning Rate [7.8125e-05]
0: TRAIN [2][1750/6832]	Time 0.485 (0.349)	Data 0.00105 (0.00147)	Tok/s 100459 (74390)	Loss/tok 3.1695 (3.2774)	Learning Rate [7.8125e-05]
0: TRAIN [2][1760/6832]	Time 0.482 (0.349)	Data 0.00112 (0.00146)	Tok/s 67319 (74376)	Loss/tok 3.3549 (3.2776)	Learning Rate [7.8125e-05]
0: TRAIN [2][1770/6832]	Time 0.400 (0.349)	Data 0.00106 (0.00146)	Tok/s 68396 (74361)	Loss/tok 3.2525 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [2][1780/6832]	Time 0.381 (0.348)	Data 0.00109 (0.00146)	Tok/s 67700 (74351)	Loss/tok 3.2591 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [2][1790/6832]	Time 0.468 (0.348)	Data 0.00115 (0.00146)	Tok/s 83461 (74351)	Loss/tok 3.3915 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [2][1800/6832]	Time 0.218 (0.348)	Data 0.00117 (0.00146)	Tok/s 75042 (74339)	Loss/tok 3.0919 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [2][1810/6832]	Time 0.487 (0.349)	Data 0.00110 (0.00145)	Tok/s 83210 (74361)	Loss/tok 3.2972 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [2][1820/6832]	Time 0.486 (0.348)	Data 0.00110 (0.00145)	Tok/s 86800 (74365)	Loss/tok 3.3480 (3.2772)	Learning Rate [7.8125e-05]
0: TRAIN [2][1830/6832]	Time 0.300 (0.348)	Data 0.00119 (0.00145)	Tok/s 69856 (74350)	Loss/tok 3.2777 (3.2773)	Learning Rate [7.8125e-05]
0: TRAIN [2][1840/6832]	Time 0.416 (0.348)	Data 0.00104 (0.00145)	Tok/s 66403 (74341)	Loss/tok 3.3927 (3.2774)	Learning Rate [7.8125e-05]
0: TRAIN [2][1850/6832]	Time 0.473 (0.348)	Data 0.00105 (0.00145)	Tok/s 70179 (74339)	Loss/tok 3.5108 (3.2771)	Learning Rate [7.8125e-05]
0: TRAIN [2][1860/6832]	Time 0.156 (0.348)	Data 0.00104 (0.00145)	Tok/s 75778 (74360)	Loss/tok 2.7744 (3.2766)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][1870/6832]	Time 0.291 (0.348)	Data 0.00104 (0.00144)	Tok/s 76893 (74365)	Loss/tok 3.3305 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [2][1880/6832]	Time 0.146 (0.348)	Data 0.00109 (0.00144)	Tok/s 76427 (74355)	Loss/tok 2.7700 (3.2765)	Learning Rate [7.8125e-05]
0: TRAIN [2][1890/6832]	Time 0.486 (0.348)	Data 0.00109 (0.00144)	Tok/s 78690 (74370)	Loss/tok 3.3474 (3.2766)	Learning Rate [7.8125e-05]
0: TRAIN [2][1900/6832]	Time 0.475 (0.348)	Data 0.00106 (0.00144)	Tok/s 62005 (74341)	Loss/tok 3.4197 (3.2769)	Learning Rate [7.8125e-05]
0: TRAIN [2][1910/6832]	Time 0.313 (0.348)	Data 0.00105 (0.00144)	Tok/s 71078 (74326)	Loss/tok 3.1801 (3.2768)	Learning Rate [7.8125e-05]
0: TRAIN [2][1920/6832]	Time 0.196 (0.348)	Data 0.00099 (0.00143)	Tok/s 77625 (74319)	Loss/tok 3.0432 (3.2764)	Learning Rate [7.8125e-05]
0: TRAIN [2][1930/6832]	Time 0.231 (0.348)	Data 0.00103 (0.00143)	Tok/s 70971 (74296)	Loss/tok 3.1216 (3.2764)	Learning Rate [7.8125e-05]
0: TRAIN [2][1940/6832]	Time 0.382 (0.348)	Data 0.00106 (0.00143)	Tok/s 68434 (74297)	Loss/tok 3.2507 (3.2761)	Learning Rate [7.8125e-05]
0: TRAIN [2][1950/6832]	Time 0.141 (0.348)	Data 0.00111 (0.00143)	Tok/s 79880 (74300)	Loss/tok 2.7494 (3.2761)	Learning Rate [7.8125e-05]
0: TRAIN [2][1960/6832]	Time 0.337 (0.347)	Data 0.00121 (0.00143)	Tok/s 69549 (74300)	Loss/tok 3.2173 (3.2759)	Learning Rate [7.8125e-05]
0: TRAIN [2][1970/6832]	Time 0.376 (0.347)	Data 0.00100 (0.00143)	Tok/s 67953 (74301)	Loss/tok 3.2461 (3.2757)	Learning Rate [7.8125e-05]
0: TRAIN [2][1980/6832]	Time 0.467 (0.347)	Data 0.00103 (0.00142)	Tok/s 77311 (74335)	Loss/tok 3.3015 (3.2751)	Learning Rate [7.8125e-05]
0: TRAIN [2][1990/6832]	Time 0.157 (0.347)	Data 0.00102 (0.00142)	Tok/s 79443 (74337)	Loss/tok 2.8210 (3.2750)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2000/6832]	Time 0.406 (0.347)	Data 0.00101 (0.00142)	Tok/s 66429 (74324)	Loss/tok 3.3318 (3.2750)	Learning Rate [7.8125e-05]
0: TRAIN [2][2010/6832]	Time 0.149 (0.347)	Data 0.00101 (0.00142)	Tok/s 74549 (74339)	Loss/tok 2.7249 (3.2748)	Learning Rate [7.8125e-05]
0: TRAIN [2][2020/6832]	Time 0.472 (0.347)	Data 0.00098 (0.00142)	Tok/s 62962 (74321)	Loss/tok 3.3979 (3.2745)	Learning Rate [7.8125e-05]
0: TRAIN [2][2030/6832]	Time 0.403 (0.347)	Data 0.00100 (0.00142)	Tok/s 65992 (74312)	Loss/tok 3.3864 (3.2749)	Learning Rate [7.8125e-05]
0: TRAIN [2][2040/6832]	Time 0.208 (0.347)	Data 0.00097 (0.00141)	Tok/s 73108 (74320)	Loss/tok 3.0795 (3.2746)	Learning Rate [7.8125e-05]
0: TRAIN [2][2050/6832]	Time 0.207 (0.347)	Data 0.00115 (0.00141)	Tok/s 73984 (74317)	Loss/tok 3.0177 (3.2746)	Learning Rate [7.8125e-05]
0: TRAIN [2][2060/6832]	Time 0.403 (0.347)	Data 0.00102 (0.00141)	Tok/s 67345 (74319)	Loss/tok 3.3571 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [2][2070/6832]	Time 0.339 (0.347)	Data 0.00116 (0.00141)	Tok/s 67133 (74308)	Loss/tok 3.3334 (3.2747)	Learning Rate [7.8125e-05]
0: TRAIN [2][2080/6832]	Time 0.271 (0.347)	Data 0.00100 (0.00141)	Tok/s 70744 (74292)	Loss/tok 3.2357 (3.2746)	Learning Rate [7.8125e-05]
0: TRAIN [2][2090/6832]	Time 0.487 (0.347)	Data 0.00098 (0.00141)	Tok/s 100063 (74300)	Loss/tok 3.1467 (3.2745)	Learning Rate [7.8125e-05]
0: TRAIN [2][2100/6832]	Time 0.407 (0.347)	Data 0.00099 (0.00141)	Tok/s 67901 (74284)	Loss/tok 3.3907 (3.2744)	Learning Rate [7.8125e-05]
0: TRAIN [2][2110/6832]	Time 0.254 (0.347)	Data 0.00102 (0.00140)	Tok/s 71946 (74276)	Loss/tok 3.1200 (3.2748)	Learning Rate [7.8125e-05]
0: TRAIN [2][2120/6832]	Time 0.399 (0.347)	Data 0.00096 (0.00140)	Tok/s 69499 (74255)	Loss/tok 3.3784 (3.2746)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2130/6832]	Time 0.276 (0.347)	Data 0.00103 (0.00140)	Tok/s 72371 (74251)	Loss/tok 3.1922 (3.2744)	Learning Rate [7.8125e-05]
0: TRAIN [2][2140/6832]	Time 0.463 (0.347)	Data 0.00095 (0.00140)	Tok/s 76070 (74250)	Loss/tok 3.3862 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [2][2150/6832]	Time 0.408 (0.347)	Data 0.00109 (0.00140)	Tok/s 69971 (74240)	Loss/tok 3.3240 (3.2746)	Learning Rate [7.8125e-05]
0: TRAIN [2][2160/6832]	Time 0.485 (0.347)	Data 0.00114 (0.00140)	Tok/s 74424 (74234)	Loss/tok 3.4060 (3.2744)	Learning Rate [7.8125e-05]
0: TRAIN [2][2170/6832]	Time 0.481 (0.347)	Data 0.00107 (0.00139)	Tok/s 81513 (74241)	Loss/tok 3.4025 (3.2745)	Learning Rate [7.8125e-05]
0: TRAIN [2][2180/6832]	Time 0.257 (0.347)	Data 0.00103 (0.00139)	Tok/s 74767 (74248)	Loss/tok 3.1254 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [2][2190/6832]	Time 0.348 (0.347)	Data 0.00101 (0.00139)	Tok/s 69120 (74245)	Loss/tok 3.2357 (3.2742)	Learning Rate [7.8125e-05]
0: TRAIN [2][2200/6832]	Time 0.184 (0.347)	Data 0.00109 (0.00139)	Tok/s 77981 (74254)	Loss/tok 3.0289 (3.2742)	Learning Rate [7.8125e-05]
0: TRAIN [2][2210/6832]	Time 0.446 (0.347)	Data 0.00103 (0.00139)	Tok/s 65055 (74243)	Loss/tok 3.3208 (3.2743)	Learning Rate [7.8125e-05]
0: TRAIN [2][2220/6832]	Time 0.277 (0.347)	Data 0.00118 (0.00139)	Tok/s 69368 (74240)	Loss/tok 3.1204 (3.2741)	Learning Rate [7.8125e-05]
0: TRAIN [2][2230/6832]	Time 0.432 (0.347)	Data 0.00102 (0.00139)	Tok/s 69629 (74227)	Loss/tok 3.3866 (3.2744)	Learning Rate [7.8125e-05]
0: TRAIN [2][2240/6832]	Time 0.136 (0.347)	Data 0.00111 (0.00139)	Tok/s 77569 (74225)	Loss/tok 2.7054 (3.2745)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2250/6832]	Time 0.459 (0.347)	Data 0.00122 (0.00138)	Tok/s 70335 (74238)	Loss/tok 3.4455 (3.2744)	Learning Rate [7.8125e-05]
0: TRAIN [2][2260/6832]	Time 0.301 (0.347)	Data 0.00105 (0.00138)	Tok/s 73068 (74225)	Loss/tok 3.1861 (3.2741)	Learning Rate [7.8125e-05]
0: TRAIN [2][2270/6832]	Time 0.130 (0.347)	Data 0.00105 (0.00138)	Tok/s 81204 (74236)	Loss/tok 2.7830 (3.2737)	Learning Rate [7.8125e-05]
0: TRAIN [2][2280/6832]	Time 0.186 (0.347)	Data 0.00109 (0.00138)	Tok/s 77222 (74228)	Loss/tok 2.9589 (3.2739)	Learning Rate [7.8125e-05]
0: TRAIN [2][2290/6832]	Time 0.321 (0.347)	Data 0.00104 (0.00138)	Tok/s 70576 (74220)	Loss/tok 3.2738 (3.2740)	Learning Rate [7.8125e-05]
0: TRAIN [2][2300/6832]	Time 0.476 (0.347)	Data 0.00110 (0.00138)	Tok/s 67310 (74251)	Loss/tok 3.3562 (3.2736)	Learning Rate [7.8125e-05]
0: TRAIN [2][2310/6832]	Time 0.228 (0.347)	Data 0.00102 (0.00138)	Tok/s 74731 (74236)	Loss/tok 3.1062 (3.2735)	Learning Rate [7.8125e-05]
0: TRAIN [2][2320/6832]	Time 0.477 (0.347)	Data 0.00106 (0.00138)	Tok/s 71777 (74241)	Loss/tok 3.3249 (3.2734)	Learning Rate [7.8125e-05]
0: TRAIN [2][2330/6832]	Time 0.264 (0.347)	Data 0.00103 (0.00137)	Tok/s 73866 (74249)	Loss/tok 3.1097 (3.2733)	Learning Rate [7.8125e-05]
0: TRAIN [2][2340/6832]	Time 0.193 (0.347)	Data 0.00114 (0.00137)	Tok/s 76936 (74263)	Loss/tok 3.0513 (3.2732)	Learning Rate [7.8125e-05]
0: TRAIN [2][2350/6832]	Time 0.452 (0.347)	Data 0.00109 (0.00137)	Tok/s 65167 (74262)	Loss/tok 3.3518 (3.2731)	Learning Rate [7.8125e-05]
0: TRAIN [2][2360/6832]	Time 0.352 (0.347)	Data 0.00107 (0.00137)	Tok/s 68345 (74250)	Loss/tok 3.2956 (3.2731)	Learning Rate [7.8125e-05]
0: TRAIN [2][2370/6832]	Time 0.247 (0.347)	Data 0.00107 (0.00137)	Tok/s 72210 (74249)	Loss/tok 3.0971 (3.2729)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2380/6832]	Time 0.355 (0.347)	Data 0.00102 (0.00137)	Tok/s 66112 (74263)	Loss/tok 3.2372 (3.2726)	Learning Rate [7.8125e-05]
0: TRAIN [2][2390/6832]	Time 0.109 (0.347)	Data 0.00108 (0.00137)	Tok/s 75848 (74258)	Loss/tok 2.3756 (3.2725)	Learning Rate [7.8125e-05]
0: TRAIN [2][2400/6832]	Time 0.149 (0.347)	Data 0.00111 (0.00137)	Tok/s 79776 (74263)	Loss/tok 2.8178 (3.2723)	Learning Rate [7.8125e-05]
0: TRAIN [2][2410/6832]	Time 0.312 (0.346)	Data 0.00104 (0.00137)	Tok/s 70590 (74253)	Loss/tok 3.1152 (3.2721)	Learning Rate [7.8125e-05]
0: TRAIN [2][2420/6832]	Time 0.382 (0.347)	Data 0.00103 (0.00136)	Tok/s 69772 (74253)	Loss/tok 3.2318 (3.2722)	Learning Rate [7.8125e-05]
0: TRAIN [2][2430/6832]	Time 0.382 (0.347)	Data 0.00109 (0.00136)	Tok/s 69292 (74236)	Loss/tok 3.2892 (3.2724)	Learning Rate [7.8125e-05]
0: TRAIN [2][2440/6832]	Time 0.393 (0.347)	Data 0.00135 (0.00136)	Tok/s 65752 (74236)	Loss/tok 3.3366 (3.2722)	Learning Rate [7.8125e-05]
0: TRAIN [2][2450/6832]	Time 0.330 (0.347)	Data 0.00107 (0.00136)	Tok/s 69732 (74231)	Loss/tok 3.2474 (3.2720)	Learning Rate [7.8125e-05]
0: TRAIN [2][2460/6832]	Time 0.450 (0.347)	Data 0.00109 (0.00136)	Tok/s 64186 (74238)	Loss/tok 3.2797 (3.2719)	Learning Rate [7.8125e-05]
0: TRAIN [2][2470/6832]	Time 0.397 (0.347)	Data 0.00109 (0.00136)	Tok/s 68307 (74243)	Loss/tok 3.2808 (3.2721)	Learning Rate [7.8125e-05]
0: TRAIN [2][2480/6832]	Time 0.473 (0.347)	Data 0.00111 (0.00136)	Tok/s 66446 (74239)	Loss/tok 3.3470 (3.2720)	Learning Rate [7.8125e-05]
0: TRAIN [2][2490/6832]	Time 0.478 (0.347)	Data 0.00111 (0.00136)	Tok/s 67563 (74238)	Loss/tok 3.4650 (3.2724)	Learning Rate [7.8125e-05]
0: TRAIN [2][2500/6832]	Time 0.481 (0.347)	Data 0.00109 (0.00136)	Tok/s 89561 (74239)	Loss/tok 3.2874 (3.2723)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2510/6832]	Time 0.485 (0.347)	Data 0.00112 (0.00136)	Tok/s 91155 (74235)	Loss/tok 3.2416 (3.2724)	Learning Rate [7.8125e-05]
0: TRAIN [2][2520/6832]	Time 0.265 (0.347)	Data 0.00108 (0.00136)	Tok/s 73669 (74228)	Loss/tok 3.0735 (3.2721)	Learning Rate [7.8125e-05]
0: TRAIN [2][2530/6832]	Time 0.482 (0.347)	Data 0.00104 (0.00135)	Tok/s 78238 (74233)	Loss/tok 3.3329 (3.2720)	Learning Rate [7.8125e-05]
0: TRAIN [2][2540/6832]	Time 0.490 (0.347)	Data 0.00112 (0.00135)	Tok/s 79954 (74265)	Loss/tok 3.3268 (3.2718)	Learning Rate [7.8125e-05]
0: TRAIN [2][2550/6832]	Time 0.469 (0.347)	Data 0.00114 (0.00135)	Tok/s 64357 (74246)	Loss/tok 3.3896 (3.2719)	Learning Rate [7.8125e-05]
0: TRAIN [2][2560/6832]	Time 0.482 (0.348)	Data 0.00103 (0.00135)	Tok/s 93659 (74253)	Loss/tok 3.2547 (3.2718)	Learning Rate [7.8125e-05]
0: TRAIN [2][2570/6832]	Time 0.269 (0.347)	Data 0.00102 (0.00135)	Tok/s 71062 (74247)	Loss/tok 3.1811 (3.2715)	Learning Rate [7.8125e-05]
0: TRAIN [2][2580/6832]	Time 0.425 (0.347)	Data 0.00110 (0.00135)	Tok/s 66931 (74236)	Loss/tok 3.3497 (3.2716)	Learning Rate [7.8125e-05]
0: TRAIN [2][2590/6832]	Time 0.487 (0.347)	Data 0.00138 (0.00135)	Tok/s 85109 (74228)	Loss/tok 3.3139 (3.2715)	Learning Rate [7.8125e-05]
0: TRAIN [2][2600/6832]	Time 0.311 (0.347)	Data 0.00107 (0.00135)	Tok/s 69664 (74228)	Loss/tok 3.2315 (3.2714)	Learning Rate [7.8125e-05]
0: TRAIN [2][2610/6832]	Time 0.436 (0.347)	Data 0.00113 (0.00135)	Tok/s 65616 (74211)	Loss/tok 3.3515 (3.2712)	Learning Rate [7.8125e-05]
0: TRAIN [2][2620/6832]	Time 0.226 (0.347)	Data 0.00103 (0.00135)	Tok/s 73733 (74220)	Loss/tok 2.9915 (3.2709)	Learning Rate [7.8125e-05]
0: TRAIN [2][2630/6832]	Time 0.408 (0.347)	Data 0.00111 (0.00135)	Tok/s 67750 (74211)	Loss/tok 3.3264 (3.2707)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2640/6832]	Time 0.480 (0.347)	Data 0.00104 (0.00134)	Tok/s 83928 (74227)	Loss/tok 3.3300 (3.2706)	Learning Rate [7.8125e-05]
0: TRAIN [2][2650/6832]	Time 0.480 (0.347)	Data 0.00103 (0.00134)	Tok/s 75048 (74240)	Loss/tok 3.3260 (3.2707)	Learning Rate [7.8125e-05]
0: TRAIN [2][2660/6832]	Time 0.480 (0.347)	Data 0.00105 (0.00134)	Tok/s 81244 (74241)	Loss/tok 3.3079 (3.2707)	Learning Rate [7.8125e-05]
0: TRAIN [2][2670/6832]	Time 0.254 (0.347)	Data 0.00107 (0.00134)	Tok/s 74489 (74229)	Loss/tok 3.1728 (3.2708)	Learning Rate [7.8125e-05]
0: TRAIN [2][2680/6832]	Time 0.406 (0.347)	Data 0.00106 (0.00134)	Tok/s 65601 (74233)	Loss/tok 3.3206 (3.2706)	Learning Rate [7.8125e-05]
0: TRAIN [2][2690/6832]	Time 0.357 (0.347)	Data 0.00103 (0.00134)	Tok/s 70560 (74232)	Loss/tok 3.2243 (3.2702)	Learning Rate [7.8125e-05]
0: TRAIN [2][2700/6832]	Time 0.472 (0.347)	Data 0.00098 (0.00134)	Tok/s 70543 (74230)	Loss/tok 3.3109 (3.2702)	Learning Rate [7.8125e-05]
0: TRAIN [2][2710/6832]	Time 0.294 (0.347)	Data 0.00109 (0.00134)	Tok/s 73404 (74237)	Loss/tok 3.2014 (3.2699)	Learning Rate [7.8125e-05]
0: TRAIN [2][2720/6832]	Time 0.405 (0.347)	Data 0.00105 (0.00134)	Tok/s 69457 (74238)	Loss/tok 3.3280 (3.2698)	Learning Rate [7.8125e-05]
0: TRAIN [2][2730/6832]	Time 0.227 (0.347)	Data 0.00109 (0.00134)	Tok/s 75725 (74232)	Loss/tok 3.0733 (3.2696)	Learning Rate [7.8125e-05]
0: TRAIN [2][2740/6832]	Time 0.404 (0.347)	Data 0.00100 (0.00133)	Tok/s 66593 (74224)	Loss/tok 3.3470 (3.2695)	Learning Rate [7.8125e-05]
0: TRAIN [2][2750/6832]	Time 0.389 (0.347)	Data 0.00102 (0.00133)	Tok/s 68437 (74225)	Loss/tok 3.3417 (3.2694)	Learning Rate [7.8125e-05]
0: TRAIN [2][2760/6832]	Time 0.469 (0.347)	Data 0.00104 (0.00133)	Tok/s 70893 (74220)	Loss/tok 3.3859 (3.2693)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2770/6832]	Time 0.480 (0.347)	Data 0.00101 (0.00133)	Tok/s 75750 (74213)	Loss/tok 3.4344 (3.2694)	Learning Rate [7.8125e-05]
0: TRAIN [2][2780/6832]	Time 0.172 (0.347)	Data 0.00109 (0.00133)	Tok/s 78386 (74209)	Loss/tok 2.9930 (3.2695)	Learning Rate [7.8125e-05]
0: TRAIN [2][2790/6832]	Time 0.372 (0.347)	Data 0.00098 (0.00133)	Tok/s 69298 (74205)	Loss/tok 3.2275 (3.2693)	Learning Rate [7.8125e-05]
0: TRAIN [2][2800/6832]	Time 0.425 (0.347)	Data 0.00107 (0.00133)	Tok/s 68008 (74210)	Loss/tok 3.2867 (3.2691)	Learning Rate [7.8125e-05]
0: TRAIN [2][2810/6832]	Time 0.486 (0.347)	Data 0.00109 (0.00133)	Tok/s 90708 (74223)	Loss/tok 3.2762 (3.2688)	Learning Rate [7.8125e-05]
0: TRAIN [2][2820/6832]	Time 0.182 (0.347)	Data 0.00106 (0.00133)	Tok/s 79221 (74209)	Loss/tok 2.9372 (3.2688)	Learning Rate [7.8125e-05]
0: TRAIN [2][2830/6832]	Time 0.482 (0.347)	Data 0.00108 (0.00133)	Tok/s 87294 (74212)	Loss/tok 3.2943 (3.2687)	Learning Rate [7.8125e-05]
0: TRAIN [2][2840/6832]	Time 0.398 (0.346)	Data 0.00107 (0.00132)	Tok/s 65688 (74215)	Loss/tok 3.3194 (3.2683)	Learning Rate [7.8125e-05]
0: TRAIN [2][2850/6832]	Time 0.367 (0.346)	Data 0.00111 (0.00132)	Tok/s 67412 (74206)	Loss/tok 3.3038 (3.2683)	Learning Rate [7.8125e-05]
0: TRAIN [2][2860/6832]	Time 0.343 (0.346)	Data 0.00100 (0.00132)	Tok/s 70192 (74212)	Loss/tok 3.3900 (3.2681)	Learning Rate [7.8125e-05]
0: TRAIN [2][2870/6832]	Time 0.465 (0.347)	Data 0.00112 (0.00132)	Tok/s 62803 (74198)	Loss/tok 3.2534 (3.2681)	Learning Rate [7.8125e-05]
0: TRAIN [2][2880/6832]	Time 0.313 (0.347)	Data 0.00102 (0.00132)	Tok/s 70262 (74187)	Loss/tok 3.3023 (3.2680)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][2890/6832]	Time 0.219 (0.346)	Data 0.00108 (0.00132)	Tok/s 73024 (74186)	Loss/tok 3.0621 (3.2679)	Learning Rate [7.8125e-05]
0: TRAIN [2][2900/6832]	Time 0.108 (0.346)	Data 0.00104 (0.00132)	Tok/s 77677 (74171)	Loss/tok 2.4534 (3.2678)	Learning Rate [7.8125e-05]
0: TRAIN [2][2910/6832]	Time 0.415 (0.347)	Data 0.00102 (0.00132)	Tok/s 65948 (74172)	Loss/tok 3.2744 (3.2679)	Learning Rate [7.8125e-05]
0: TRAIN [2][2920/6832]	Time 0.391 (0.347)	Data 0.00104 (0.00132)	Tok/s 66803 (74162)	Loss/tok 3.1686 (3.2678)	Learning Rate [7.8125e-05]
0: TRAIN [2][2930/6832]	Time 0.466 (0.347)	Data 0.00109 (0.00132)	Tok/s 72232 (74161)	Loss/tok 3.3291 (3.2679)	Learning Rate [7.8125e-05]
0: TRAIN [2][2940/6832]	Time 0.490 (0.347)	Data 0.00105 (0.00132)	Tok/s 81322 (74182)	Loss/tok 3.2753 (3.2675)	Learning Rate [7.8125e-05]
0: TRAIN [2][2950/6832]	Time 0.486 (0.347)	Data 0.00102 (0.00131)	Tok/s 76518 (74183)	Loss/tok 3.3102 (3.2672)	Learning Rate [7.8125e-05]
0: TRAIN [2][2960/6832]	Time 0.468 (0.346)	Data 0.00110 (0.00131)	Tok/s 75495 (74191)	Loss/tok 3.4214 (3.2671)	Learning Rate [7.8125e-05]
0: TRAIN [2][2970/6832]	Time 0.433 (0.347)	Data 0.00104 (0.00131)	Tok/s 66275 (74192)	Loss/tok 3.3644 (3.2672)	Learning Rate [7.8125e-05]
0: TRAIN [2][2980/6832]	Time 0.469 (0.347)	Data 0.00103 (0.00131)	Tok/s 67556 (74191)	Loss/tok 3.3008 (3.2670)	Learning Rate [7.8125e-05]
0: TRAIN [2][2990/6832]	Time 0.271 (0.346)	Data 0.00100 (0.00131)	Tok/s 72266 (74185)	Loss/tok 3.1324 (3.2667)	Learning Rate [7.8125e-05]
0: TRAIN [2][3000/6832]	Time 0.466 (0.346)	Data 0.00101 (0.00131)	Tok/s 66595 (74178)	Loss/tok 3.3136 (3.2666)	Learning Rate [7.8125e-05]
0: TRAIN [2][3010/6832]	Time 0.235 (0.346)	Data 0.00121 (0.00131)	Tok/s 73966 (74176)	Loss/tok 3.1011 (3.2664)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3020/6832]	Time 0.217 (0.346)	Data 0.00108 (0.00131)	Tok/s 73223 (74204)	Loss/tok 2.9917 (3.2660)	Learning Rate [7.8125e-05]
0: TRAIN [2][3030/6832]	Time 0.424 (0.346)	Data 0.00105 (0.00131)	Tok/s 67279 (74210)	Loss/tok 3.2863 (3.2659)	Learning Rate [7.8125e-05]
0: TRAIN [2][3040/6832]	Time 0.344 (0.346)	Data 0.00104 (0.00131)	Tok/s 70005 (74207)	Loss/tok 3.1674 (3.2658)	Learning Rate [7.8125e-05]
0: TRAIN [2][3050/6832]	Time 0.266 (0.346)	Data 0.00110 (0.00131)	Tok/s 73570 (74213)	Loss/tok 3.1670 (3.2657)	Learning Rate [7.8125e-05]
0: TRAIN [2][3060/6832]	Time 0.420 (0.346)	Data 0.00101 (0.00131)	Tok/s 66688 (74218)	Loss/tok 3.2719 (3.2654)	Learning Rate [7.8125e-05]
0: TRAIN [2][3070/6832]	Time 0.478 (0.346)	Data 0.00107 (0.00131)	Tok/s 70681 (74232)	Loss/tok 3.3159 (3.2654)	Learning Rate [7.8125e-05]
0: TRAIN [2][3080/6832]	Time 0.296 (0.347)	Data 0.00110 (0.00130)	Tok/s 72224 (74233)	Loss/tok 3.1571 (3.2656)	Learning Rate [7.8125e-05]
0: TRAIN [2][3090/6832]	Time 0.480 (0.347)	Data 0.00108 (0.00130)	Tok/s 71293 (74236)	Loss/tok 3.2936 (3.2655)	Learning Rate [7.8125e-05]
0: TRAIN [2][3100/6832]	Time 0.480 (0.346)	Data 0.00105 (0.00130)	Tok/s 71312 (74234)	Loss/tok 3.3396 (3.2653)	Learning Rate [7.8125e-05]
0: TRAIN [2][3110/6832]	Time 0.481 (0.347)	Data 0.00104 (0.00130)	Tok/s 77100 (74228)	Loss/tok 3.3701 (3.2654)	Learning Rate [7.8125e-05]
0: TRAIN [2][3120/6832]	Time 0.472 (0.346)	Data 0.00101 (0.00130)	Tok/s 65732 (74217)	Loss/tok 3.3879 (3.2654)	Learning Rate [7.8125e-05]
0: TRAIN [2][3130/6832]	Time 0.471 (0.347)	Data 0.00097 (0.00130)	Tok/s 69529 (74213)	Loss/tok 3.2994 (3.2653)	Learning Rate [7.8125e-05]
0: TRAIN [2][3140/6832]	Time 0.463 (0.347)	Data 0.00120 (0.00130)	Tok/s 84493 (74217)	Loss/tok 3.2941 (3.2652)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3150/6832]	Time 0.300 (0.347)	Data 0.00108 (0.00130)	Tok/s 69949 (74220)	Loss/tok 3.2418 (3.2650)	Learning Rate [7.8125e-05]
0: TRAIN [2][3160/6832]	Time 0.462 (0.346)	Data 0.00111 (0.00130)	Tok/s 65865 (74214)	Loss/tok 3.2948 (3.2648)	Learning Rate [7.8125e-05]
0: TRAIN [2][3170/6832]	Time 0.483 (0.346)	Data 0.00100 (0.00132)	Tok/s 87341 (74215)	Loss/tok 3.2934 (3.2646)	Learning Rate [7.8125e-05]
0: TRAIN [2][3180/6832]	Time 0.480 (0.346)	Data 0.00110 (0.00132)	Tok/s 74747 (74212)	Loss/tok 3.3555 (3.2647)	Learning Rate [7.8125e-05]
0: TRAIN [2][3190/6832]	Time 0.468 (0.347)	Data 0.00109 (0.00132)	Tok/s 81948 (74213)	Loss/tok 3.3474 (3.2648)	Learning Rate [7.8125e-05]
0: TRAIN [2][3200/6832]	Time 0.379 (0.346)	Data 0.00103 (0.00131)	Tok/s 66195 (74207)	Loss/tok 3.3342 (3.2646)	Learning Rate [7.8125e-05]
0: TRAIN [2][3210/6832]	Time 0.486 (0.346)	Data 0.00104 (0.00131)	Tok/s 95716 (74218)	Loss/tok 3.1567 (3.2643)	Learning Rate [7.8125e-05]
0: TRAIN [2][3220/6832]	Time 0.363 (0.346)	Data 0.00126 (0.00131)	Tok/s 71978 (74225)	Loss/tok 3.2970 (3.2640)	Learning Rate [7.8125e-05]
0: TRAIN [2][3230/6832]	Time 0.460 (0.346)	Data 0.00107 (0.00131)	Tok/s 96003 (74241)	Loss/tok 3.2090 (3.2638)	Learning Rate [7.8125e-05]
0: TRAIN [2][3240/6832]	Time 0.356 (0.346)	Data 0.00103 (0.00131)	Tok/s 69058 (74246)	Loss/tok 3.2260 (3.2638)	Learning Rate [7.8125e-05]
0: TRAIN [2][3250/6832]	Time 0.272 (0.346)	Data 0.00103 (0.00131)	Tok/s 71460 (74239)	Loss/tok 2.9951 (3.2636)	Learning Rate [7.8125e-05]
0: TRAIN [2][3260/6832]	Time 0.210 (0.346)	Data 0.00102 (0.00131)	Tok/s 73976 (74247)	Loss/tok 2.9675 (3.2635)	Learning Rate [7.8125e-05]
0: TRAIN [2][3270/6832]	Time 0.454 (0.347)	Data 0.00103 (0.00131)	Tok/s 65323 (74236)	Loss/tok 3.2822 (3.2635)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3280/6832]	Time 0.335 (0.346)	Data 0.00109 (0.00131)	Tok/s 71829 (74237)	Loss/tok 3.2400 (3.2632)	Learning Rate [7.8125e-05]
0: TRAIN [2][3290/6832]	Time 0.173 (0.346)	Data 0.00103 (0.00131)	Tok/s 79971 (74236)	Loss/tok 2.8938 (3.2632)	Learning Rate [7.8125e-05]
0: TRAIN [2][3300/6832]	Time 0.133 (0.346)	Data 0.00102 (0.00131)	Tok/s 79243 (74235)	Loss/tok 2.6489 (3.2630)	Learning Rate [7.8125e-05]
0: TRAIN [2][3310/6832]	Time 0.479 (0.346)	Data 0.00104 (0.00131)	Tok/s 67610 (74238)	Loss/tok 3.2769 (3.2630)	Learning Rate [7.8125e-05]
0: TRAIN [2][3320/6832]	Time 0.344 (0.347)	Data 0.00110 (0.00131)	Tok/s 68494 (74232)	Loss/tok 3.1978 (3.2631)	Learning Rate [7.8125e-05]
0: TRAIN [2][3330/6832]	Time 0.202 (0.346)	Data 0.00111 (0.00131)	Tok/s 74941 (74231)	Loss/tok 3.0912 (3.2629)	Learning Rate [7.8125e-05]
0: TRAIN [2][3340/6832]	Time 0.216 (0.346)	Data 0.00109 (0.00130)	Tok/s 75938 (74240)	Loss/tok 3.0332 (3.2627)	Learning Rate [7.8125e-05]
0: TRAIN [2][3350/6832]	Time 0.193 (0.346)	Data 0.00104 (0.00130)	Tok/s 76747 (74234)	Loss/tok 2.9534 (3.2625)	Learning Rate [7.8125e-05]
0: TRAIN [2][3360/6832]	Time 0.276 (0.346)	Data 0.00100 (0.00130)	Tok/s 72139 (74228)	Loss/tok 3.1690 (3.2623)	Learning Rate [7.8125e-05]
0: TRAIN [2][3370/6832]	Time 0.381 (0.346)	Data 0.00118 (0.00130)	Tok/s 68187 (74222)	Loss/tok 3.3655 (3.2622)	Learning Rate [7.8125e-05]
0: TRAIN [2][3380/6832]	Time 0.308 (0.346)	Data 0.00105 (0.00130)	Tok/s 72673 (74212)	Loss/tok 3.1495 (3.2624)	Learning Rate [7.8125e-05]
0: TRAIN [2][3390/6832]	Time 0.477 (0.346)	Data 0.00103 (0.00130)	Tok/s 73214 (74199)	Loss/tok 3.3204 (3.2621)	Learning Rate [7.8125e-05]
0: TRAIN [2][3400/6832]	Time 0.275 (0.346)	Data 0.00109 (0.00130)	Tok/s 72458 (74195)	Loss/tok 3.1872 (3.2619)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3410/6832]	Time 0.462 (0.346)	Data 0.00106 (0.00130)	Tok/s 68157 (74196)	Loss/tok 3.4229 (3.2619)	Learning Rate [7.8125e-05]
0: TRAIN [2][3420/6832]	Time 0.246 (0.346)	Data 0.00108 (0.00130)	Tok/s 72949 (74205)	Loss/tok 3.0312 (3.2615)	Learning Rate [7.8125e-05]
0: TRAIN [2][3430/6832]	Time 0.099 (0.346)	Data 0.00111 (0.00130)	Tok/s 57989 (74204)	Loss/tok 2.1490 (3.2613)	Learning Rate [7.8125e-05]
0: TRAIN [2][3440/6832]	Time 0.258 (0.346)	Data 0.00105 (0.00130)	Tok/s 73455 (74204)	Loss/tok 3.1355 (3.2612)	Learning Rate [7.8125e-05]
0: TRAIN [2][3450/6832]	Time 0.202 (0.346)	Data 0.00105 (0.00130)	Tok/s 75276 (74212)	Loss/tok 3.0945 (3.2610)	Learning Rate [7.8125e-05]
0: TRAIN [2][3460/6832]	Time 0.306 (0.346)	Data 0.00107 (0.00130)	Tok/s 70455 (74209)	Loss/tok 3.1330 (3.2609)	Learning Rate [7.8125e-05]
0: TRAIN [2][3470/6832]	Time 0.357 (0.346)	Data 0.00107 (0.00130)	Tok/s 67337 (74212)	Loss/tok 3.2725 (3.2608)	Learning Rate [7.8125e-05]
0: TRAIN [2][3480/6832]	Time 0.462 (0.346)	Data 0.00104 (0.00130)	Tok/s 73579 (74210)	Loss/tok 3.2688 (3.2608)	Learning Rate [7.8125e-05]
0: TRAIN [2][3490/6832]	Time 0.415 (0.346)	Data 0.00106 (0.00130)	Tok/s 68334 (74199)	Loss/tok 3.3324 (3.2606)	Learning Rate [7.8125e-05]
0: TRAIN [2][3500/6832]	Time 0.485 (0.346)	Data 0.00104 (0.00129)	Tok/s 77793 (74199)	Loss/tok 3.3066 (3.2605)	Learning Rate [7.8125e-05]
0: TRAIN [2][3510/6832]	Time 0.095 (0.346)	Data 0.00110 (0.00129)	Tok/s 62224 (74197)	Loss/tok 2.1280 (3.2603)	Learning Rate [7.8125e-05]
0: TRAIN [2][3520/6832]	Time 0.265 (0.346)	Data 0.00110 (0.00129)	Tok/s 73723 (74186)	Loss/tok 3.0183 (3.2600)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3530/6832]	Time 0.463 (0.346)	Data 0.00133 (0.00129)	Tok/s 66361 (74186)	Loss/tok 3.2758 (3.2599)	Learning Rate [7.8125e-05]
0: TRAIN [2][3540/6832]	Time 0.478 (0.346)	Data 0.00103 (0.00129)	Tok/s 63889 (74185)	Loss/tok 3.3041 (3.2598)	Learning Rate [7.8125e-05]
0: TRAIN [2][3550/6832]	Time 0.230 (0.346)	Data 0.00105 (0.00129)	Tok/s 72843 (74183)	Loss/tok 3.0025 (3.2597)	Learning Rate [7.8125e-05]
0: TRAIN [2][3560/6832]	Time 0.450 (0.346)	Data 0.00111 (0.00129)	Tok/s 69939 (74183)	Loss/tok 3.3201 (3.2597)	Learning Rate [7.8125e-05]
0: TRAIN [2][3570/6832]	Time 0.338 (0.346)	Data 0.00108 (0.00129)	Tok/s 70015 (74182)	Loss/tok 3.1995 (3.2595)	Learning Rate [7.8125e-05]
0: TRAIN [2][3580/6832]	Time 0.414 (0.346)	Data 0.00111 (0.00129)	Tok/s 71902 (74187)	Loss/tok 3.2588 (3.2594)	Learning Rate [7.8125e-05]
0: TRAIN [2][3590/6832]	Time 0.481 (0.346)	Data 0.00111 (0.00129)	Tok/s 70132 (74184)	Loss/tok 3.3369 (3.2594)	Learning Rate [7.8125e-05]
0: TRAIN [2][3600/6832]	Time 0.459 (0.346)	Data 0.00106 (0.00129)	Tok/s 66689 (74188)	Loss/tok 3.3483 (3.2594)	Learning Rate [7.8125e-05]
0: TRAIN [2][3610/6832]	Time 0.480 (0.346)	Data 0.00103 (0.00129)	Tok/s 78535 (74185)	Loss/tok 3.3241 (3.2594)	Learning Rate [7.8125e-05]
0: TRAIN [2][3620/6832]	Time 0.373 (0.347)	Data 0.00105 (0.00129)	Tok/s 70333 (74178)	Loss/tok 3.2490 (3.2595)	Learning Rate [7.8125e-05]
0: TRAIN [2][3630/6832]	Time 0.408 (0.347)	Data 0.00104 (0.00129)	Tok/s 67923 (74179)	Loss/tok 3.2455 (3.2593)	Learning Rate [7.8125e-05]
0: TRAIN [2][3640/6832]	Time 0.156 (0.347)	Data 0.00111 (0.00129)	Tok/s 79847 (74179)	Loss/tok 2.8398 (3.2592)	Learning Rate [7.8125e-05]
0: TRAIN [2][3650/6832]	Time 0.475 (0.347)	Data 0.00107 (0.00129)	Tok/s 71047 (74178)	Loss/tok 3.3263 (3.2591)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3660/6832]	Time 0.481 (0.347)	Data 0.00107 (0.00129)	Tok/s 71145 (74185)	Loss/tok 3.2927 (3.2589)	Learning Rate [7.8125e-05]
0: TRAIN [2][3670/6832]	Time 0.486 (0.347)	Data 0.00106 (0.00129)	Tok/s 78830 (74187)	Loss/tok 3.3146 (3.2588)	Learning Rate [7.8125e-05]
0: TRAIN [2][3680/6832]	Time 0.146 (0.347)	Data 0.00108 (0.00129)	Tok/s 81138 (74199)	Loss/tok 2.7951 (3.2585)	Learning Rate [7.8125e-05]
0: TRAIN [2][3690/6832]	Time 0.151 (0.346)	Data 0.00107 (0.00128)	Tok/s 75320 (74192)	Loss/tok 2.7056 (3.2582)	Learning Rate [7.8125e-05]
0: TRAIN [2][3700/6832]	Time 0.471 (0.346)	Data 0.00112 (0.00128)	Tok/s 68535 (74190)	Loss/tok 3.3124 (3.2580)	Learning Rate [7.8125e-05]
0: TRAIN [2][3710/6832]	Time 0.459 (0.346)	Data 0.00102 (0.00128)	Tok/s 101529 (74194)	Loss/tok 3.1364 (3.2577)	Learning Rate [7.8125e-05]
0: TRAIN [2][3720/6832]	Time 0.180 (0.346)	Data 0.00102 (0.00128)	Tok/s 79568 (74195)	Loss/tok 2.9635 (3.2575)	Learning Rate [7.8125e-05]
0: TRAIN [2][3730/6832]	Time 0.487 (0.346)	Data 0.00113 (0.00128)	Tok/s 80154 (74200)	Loss/tok 3.3332 (3.2575)	Learning Rate [7.8125e-05]
0: TRAIN [2][3740/6832]	Time 0.244 (0.346)	Data 0.00105 (0.00128)	Tok/s 75114 (74201)	Loss/tok 3.1150 (3.2575)	Learning Rate [7.8125e-05]
0: TRAIN [2][3750/6832]	Time 0.241 (0.346)	Data 0.00103 (0.00128)	Tok/s 71507 (74199)	Loss/tok 3.1008 (3.2573)	Learning Rate [7.8125e-05]
0: TRAIN [2][3760/6832]	Time 0.173 (0.346)	Data 0.00108 (0.00128)	Tok/s 77671 (74208)	Loss/tok 2.8584 (3.2571)	Learning Rate [7.8125e-05]
0: TRAIN [2][3770/6832]	Time 0.346 (0.346)	Data 0.00101 (0.00128)	Tok/s 72422 (74209)	Loss/tok 3.1934 (3.2570)	Learning Rate [7.8125e-05]
0: TRAIN [2][3780/6832]	Time 0.371 (0.346)	Data 0.00105 (0.00128)	Tok/s 66792 (74203)	Loss/tok 3.2251 (3.2569)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3790/6832]	Time 0.485 (0.346)	Data 0.00107 (0.00128)	Tok/s 76450 (74209)	Loss/tok 3.2738 (3.2566)	Learning Rate [7.8125e-05]
0: TRAIN [2][3800/6832]	Time 0.376 (0.346)	Data 0.00104 (0.00128)	Tok/s 68555 (74200)	Loss/tok 3.2825 (3.2566)	Learning Rate [7.8125e-05]
0: TRAIN [2][3810/6832]	Time 0.446 (0.346)	Data 0.00109 (0.00128)	Tok/s 67689 (74193)	Loss/tok 3.3235 (3.2566)	Learning Rate [7.8125e-05]
0: TRAIN [2][3820/6832]	Time 0.243 (0.346)	Data 0.00115 (0.00128)	Tok/s 72142 (74196)	Loss/tok 3.0964 (3.2565)	Learning Rate [7.8125e-05]
0: TRAIN [2][3830/6832]	Time 0.272 (0.346)	Data 0.00101 (0.00128)	Tok/s 70739 (74196)	Loss/tok 3.1032 (3.2562)	Learning Rate [7.8125e-05]
0: TRAIN [2][3840/6832]	Time 0.471 (0.346)	Data 0.00108 (0.00128)	Tok/s 67575 (74187)	Loss/tok 3.3820 (3.2562)	Learning Rate [7.8125e-05]
0: TRAIN [2][3850/6832]	Time 0.468 (0.346)	Data 0.00130 (0.00128)	Tok/s 73124 (74187)	Loss/tok 3.3084 (3.2561)	Learning Rate [7.8125e-05]
0: TRAIN [2][3860/6832]	Time 0.250 (0.346)	Data 0.00101 (0.00128)	Tok/s 72924 (74200)	Loss/tok 3.0862 (3.2558)	Learning Rate [7.8125e-05]
0: TRAIN [2][3870/6832]	Time 0.469 (0.346)	Data 0.00104 (0.00128)	Tok/s 66787 (74198)	Loss/tok 3.2473 (3.2556)	Learning Rate [7.8125e-05]
0: TRAIN [2][3880/6832]	Time 0.477 (0.346)	Data 0.00099 (0.00128)	Tok/s 68890 (74193)	Loss/tok 3.4070 (3.2554)	Learning Rate [7.8125e-05]
0: TRAIN [2][3890/6832]	Time 0.275 (0.346)	Data 0.00102 (0.00127)	Tok/s 71121 (74190)	Loss/tok 3.1086 (3.2551)	Learning Rate [7.8125e-05]
0: TRAIN [2][3900/6832]	Time 0.335 (0.346)	Data 0.00106 (0.00127)	Tok/s 69451 (74186)	Loss/tok 3.1946 (3.2549)	Learning Rate [7.8125e-05]
0: TRAIN [2][3910/6832]	Time 0.144 (0.345)	Data 0.00112 (0.00127)	Tok/s 78060 (74185)	Loss/tok 2.6789 (3.2546)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][3920/6832]	Time 0.481 (0.345)	Data 0.00109 (0.00127)	Tok/s 77422 (74191)	Loss/tok 3.3015 (3.2546)	Learning Rate [7.8125e-05]
0: TRAIN [2][3930/6832]	Time 0.219 (0.346)	Data 0.00104 (0.00127)	Tok/s 74663 (74184)	Loss/tok 2.9646 (3.2544)	Learning Rate [7.8125e-05]
0: TRAIN [2][3940/6832]	Time 0.482 (0.346)	Data 0.00102 (0.00127)	Tok/s 96640 (74195)	Loss/tok 3.0466 (3.2543)	Learning Rate [7.8125e-05]
0: TRAIN [2][3950/6832]	Time 0.207 (0.346)	Data 0.00107 (0.00127)	Tok/s 75904 (74203)	Loss/tok 3.0478 (3.2540)	Learning Rate [7.8125e-05]
0: TRAIN [2][3960/6832]	Time 0.364 (0.346)	Data 0.00110 (0.00127)	Tok/s 68927 (74208)	Loss/tok 3.2799 (3.2540)	Learning Rate [7.8125e-05]
0: TRAIN [2][3970/6832]	Time 0.486 (0.346)	Data 0.00102 (0.00127)	Tok/s 77467 (74203)	Loss/tok 3.3197 (3.2540)	Learning Rate [7.8125e-05]
0: TRAIN [2][3980/6832]	Time 0.475 (0.346)	Data 0.00112 (0.00127)	Tok/s 64430 (74196)	Loss/tok 3.3118 (3.2541)	Learning Rate [7.8125e-05]
0: TRAIN [2][3990/6832]	Time 0.273 (0.346)	Data 0.00112 (0.00127)	Tok/s 70338 (74189)	Loss/tok 3.1253 (3.2539)	Learning Rate [7.8125e-05]
0: TRAIN [2][4000/6832]	Time 0.422 (0.346)	Data 0.00105 (0.00127)	Tok/s 65550 (74184)	Loss/tok 3.2230 (3.2537)	Learning Rate [7.8125e-05]
0: TRAIN [2][4010/6832]	Time 0.485 (0.346)	Data 0.00102 (0.00127)	Tok/s 76459 (74189)	Loss/tok 3.2562 (3.2534)	Learning Rate [7.8125e-05]
0: TRAIN [2][4020/6832]	Time 0.351 (0.346)	Data 0.00107 (0.00127)	Tok/s 66395 (74183)	Loss/tok 3.1814 (3.2532)	Learning Rate [7.8125e-05]
0: TRAIN [2][4030/6832]	Time 0.467 (0.346)	Data 0.00110 (0.00127)	Tok/s 76666 (74183)	Loss/tok 3.2857 (3.2532)	Learning Rate [7.8125e-05]
0: TRAIN [2][4040/6832]	Time 0.466 (0.346)	Data 0.00102 (0.00127)	Tok/s 69211 (74186)	Loss/tok 3.3867 (3.2531)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4050/6832]	Time 0.199 (0.346)	Data 0.00101 (0.00127)	Tok/s 76474 (74184)	Loss/tok 3.0292 (3.2527)	Learning Rate [7.8125e-05]
0: TRAIN [2][4060/6832]	Time 0.455 (0.346)	Data 0.00108 (0.00127)	Tok/s 71949 (74178)	Loss/tok 3.3005 (3.2528)	Learning Rate [7.8125e-05]
0: TRAIN [2][4070/6832]	Time 0.471 (0.346)	Data 0.00103 (0.00127)	Tok/s 66147 (74173)	Loss/tok 3.3116 (3.2527)	Learning Rate [7.8125e-05]
0: TRAIN [2][4080/6832]	Time 0.323 (0.346)	Data 0.00102 (0.00127)	Tok/s 71371 (74169)	Loss/tok 3.1940 (3.2526)	Learning Rate [7.8125e-05]
0: TRAIN [2][4090/6832]	Time 0.469 (0.346)	Data 0.00105 (0.00127)	Tok/s 64330 (74170)	Loss/tok 3.3759 (3.2525)	Learning Rate [7.8125e-05]
0: TRAIN [2][4100/6832]	Time 0.477 (0.346)	Data 0.00106 (0.00127)	Tok/s 66807 (74161)	Loss/tok 3.3417 (3.2525)	Learning Rate [7.8125e-05]
0: TRAIN [2][4110/6832]	Time 0.264 (0.346)	Data 0.00097 (0.00126)	Tok/s 75713 (74157)	Loss/tok 3.0327 (3.2523)	Learning Rate [7.8125e-05]
0: TRAIN [2][4120/6832]	Time 0.481 (0.346)	Data 0.00108 (0.00126)	Tok/s 69380 (74160)	Loss/tok 3.3382 (3.2522)	Learning Rate [7.8125e-05]
0: TRAIN [2][4130/6832]	Time 0.326 (0.346)	Data 0.00106 (0.00126)	Tok/s 70679 (74154)	Loss/tok 3.0986 (3.2520)	Learning Rate [7.8125e-05]
0: TRAIN [2][4140/6832]	Time 0.479 (0.346)	Data 0.00105 (0.00126)	Tok/s 71638 (74149)	Loss/tok 3.3873 (3.2519)	Learning Rate [7.8125e-05]
0: TRAIN [2][4150/6832]	Time 0.375 (0.346)	Data 0.00107 (0.00126)	Tok/s 67910 (74143)	Loss/tok 3.2089 (3.2518)	Learning Rate [7.8125e-05]
0: TRAIN [2][4160/6832]	Time 0.143 (0.346)	Data 0.00106 (0.00126)	Tok/s 83236 (74140)	Loss/tok 2.7964 (3.2518)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4170/6832]	Time 0.139 (0.346)	Data 0.00116 (0.00126)	Tok/s 81512 (74136)	Loss/tok 2.7699 (3.2517)	Learning Rate [7.8125e-05]
0: TRAIN [2][4180/6832]	Time 0.140 (0.346)	Data 0.00106 (0.00126)	Tok/s 80962 (74138)	Loss/tok 2.6717 (3.2515)	Learning Rate [7.8125e-05]
0: TRAIN [2][4190/6832]	Time 0.227 (0.346)	Data 0.00109 (0.00126)	Tok/s 73677 (74136)	Loss/tok 2.9591 (3.2515)	Learning Rate [7.8125e-05]
0: TRAIN [2][4200/6832]	Time 0.233 (0.346)	Data 0.00102 (0.00126)	Tok/s 74736 (74134)	Loss/tok 3.0042 (3.2515)	Learning Rate [7.8125e-05]
0: TRAIN [2][4210/6832]	Time 0.455 (0.346)	Data 0.00105 (0.00126)	Tok/s 67926 (74128)	Loss/tok 3.2371 (3.2514)	Learning Rate [7.8125e-05]
0: TRAIN [2][4220/6832]	Time 0.483 (0.346)	Data 0.00111 (0.00126)	Tok/s 65992 (74121)	Loss/tok 3.2740 (3.2513)	Learning Rate [7.8125e-05]
0: TRAIN [2][4230/6832]	Time 0.486 (0.346)	Data 0.00106 (0.00126)	Tok/s 86892 (74124)	Loss/tok 3.2373 (3.2509)	Learning Rate [7.8125e-05]
0: TRAIN [2][4240/6832]	Time 0.295 (0.346)	Data 0.00107 (0.00126)	Tok/s 73062 (74123)	Loss/tok 3.1853 (3.2509)	Learning Rate [7.8125e-05]
0: TRAIN [2][4250/6832]	Time 0.194 (0.346)	Data 0.00103 (0.00126)	Tok/s 76638 (74117)	Loss/tok 3.0159 (3.2508)	Learning Rate [7.8125e-05]
0: TRAIN [2][4260/6832]	Time 0.465 (0.346)	Data 0.00109 (0.00126)	Tok/s 78021 (74115)	Loss/tok 3.2932 (3.2507)	Learning Rate [7.8125e-05]
0: TRAIN [2][4270/6832]	Time 0.431 (0.346)	Data 0.00112 (0.00126)	Tok/s 66008 (74113)	Loss/tok 3.2785 (3.2506)	Learning Rate [7.8125e-05]
0: TRAIN [2][4280/6832]	Time 0.197 (0.346)	Data 0.00105 (0.00126)	Tok/s 76850 (74112)	Loss/tok 2.9112 (3.2504)	Learning Rate [7.8125e-05]
0: TRAIN [2][4290/6832]	Time 0.415 (0.346)	Data 0.00105 (0.00126)	Tok/s 65820 (74109)	Loss/tok 3.1516 (3.2503)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4300/6832]	Time 0.444 (0.346)	Data 0.00109 (0.00126)	Tok/s 68800 (74104)	Loss/tok 3.2473 (3.2502)	Learning Rate [7.8125e-05]
0: TRAIN [2][4310/6832]	Time 0.316 (0.346)	Data 0.00115 (0.00126)	Tok/s 71771 (74098)	Loss/tok 3.1106 (3.2501)	Learning Rate [7.8125e-05]
0: TRAIN [2][4320/6832]	Time 0.491 (0.346)	Data 0.00111 (0.00126)	Tok/s 84370 (74106)	Loss/tok 3.1980 (3.2498)	Learning Rate [7.8125e-05]
0: TRAIN [2][4330/6832]	Time 0.244 (0.346)	Data 0.00106 (0.00126)	Tok/s 74181 (74104)	Loss/tok 3.0537 (3.2497)	Learning Rate [7.8125e-05]
0: TRAIN [2][4340/6832]	Time 0.311 (0.346)	Data 0.00111 (0.00126)	Tok/s 70904 (74101)	Loss/tok 3.1707 (3.2498)	Learning Rate [7.8125e-05]
0: TRAIN [2][4350/6832]	Time 0.208 (0.346)	Data 0.00109 (0.00126)	Tok/s 74884 (74107)	Loss/tok 2.8741 (3.2496)	Learning Rate [7.8125e-05]
0: TRAIN [2][4360/6832]	Time 0.115 (0.346)	Data 0.00104 (0.00126)	Tok/s 73457 (74107)	Loss/tok 2.3958 (3.2495)	Learning Rate [7.8125e-05]
0: TRAIN [2][4370/6832]	Time 0.238 (0.346)	Data 0.00105 (0.00125)	Tok/s 73262 (74103)	Loss/tok 3.0504 (3.2492)	Learning Rate [7.8125e-05]
0: TRAIN [2][4380/6832]	Time 0.481 (0.346)	Data 0.00114 (0.00125)	Tok/s 96916 (74112)	Loss/tok 3.0567 (3.2491)	Learning Rate [7.8125e-05]
0: TRAIN [2][4390/6832]	Time 0.136 (0.346)	Data 0.00099 (0.00125)	Tok/s 77372 (74126)	Loss/tok 2.5522 (3.2488)	Learning Rate [7.8125e-05]
0: TRAIN [2][4400/6832]	Time 0.479 (0.346)	Data 0.00104 (0.00125)	Tok/s 65855 (74138)	Loss/tok 3.2873 (3.2485)	Learning Rate [7.8125e-05]
0: TRAIN [2][4410/6832]	Time 0.220 (0.346)	Data 0.00102 (0.00125)	Tok/s 76547 (74142)	Loss/tok 3.0783 (3.2483)	Learning Rate [7.8125e-05]
0: TRAIN [2][4420/6832]	Time 0.470 (0.346)	Data 0.00111 (0.00125)	Tok/s 69879 (74138)	Loss/tok 3.3584 (3.2481)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4430/6832]	Time 0.378 (0.346)	Data 0.00103 (0.00125)	Tok/s 68607 (74142)	Loss/tok 3.1440 (3.2479)	Learning Rate [7.8125e-05]
0: TRAIN [2][4440/6832]	Time 0.486 (0.346)	Data 0.00124 (0.00125)	Tok/s 90834 (74139)	Loss/tok 3.1833 (3.2478)	Learning Rate [7.8125e-05]
0: TRAIN [2][4450/6832]	Time 0.479 (0.346)	Data 0.00114 (0.00125)	Tok/s 73756 (74147)	Loss/tok 3.3113 (3.2475)	Learning Rate [7.8125e-05]
0: TRAIN [2][4460/6832]	Time 0.480 (0.346)	Data 0.00109 (0.00125)	Tok/s 70233 (74148)	Loss/tok 3.2698 (3.2474)	Learning Rate [7.8125e-05]
0: TRAIN [2][4470/6832]	Time 0.476 (0.346)	Data 0.00104 (0.00125)	Tok/s 75491 (74151)	Loss/tok 3.3159 (3.2472)	Learning Rate [7.8125e-05]
0: TRAIN [2][4480/6832]	Time 0.482 (0.346)	Data 0.00127 (0.00125)	Tok/s 81198 (74154)	Loss/tok 3.1881 (3.2470)	Learning Rate [7.8125e-05]
0: TRAIN [2][4490/6832]	Time 0.167 (0.346)	Data 0.00114 (0.00125)	Tok/s 78158 (74171)	Loss/tok 2.8296 (3.2466)	Learning Rate [7.8125e-05]
0: TRAIN [2][4500/6832]	Time 0.486 (0.346)	Data 0.00106 (0.00125)	Tok/s 75038 (74169)	Loss/tok 3.4064 (3.2465)	Learning Rate [7.8125e-05]
0: TRAIN [2][4510/6832]	Time 0.165 (0.346)	Data 0.00108 (0.00125)	Tok/s 78472 (74171)	Loss/tok 2.8718 (3.2464)	Learning Rate [7.8125e-05]
0: TRAIN [2][4520/6832]	Time 0.344 (0.346)	Data 0.00111 (0.00125)	Tok/s 68142 (74173)	Loss/tok 3.0888 (3.2462)	Learning Rate [7.8125e-05]
0: TRAIN [2][4530/6832]	Time 0.473 (0.346)	Data 0.00129 (0.00125)	Tok/s 64778 (74169)	Loss/tok 3.2055 (3.2461)	Learning Rate [7.8125e-05]
0: TRAIN [2][4540/6832]	Time 0.258 (0.346)	Data 0.00108 (0.00125)	Tok/s 75316 (74175)	Loss/tok 3.0720 (3.2459)	Learning Rate [7.8125e-05]
0: TRAIN [2][4550/6832]	Time 0.446 (0.346)	Data 0.00114 (0.00125)	Tok/s 65753 (74171)	Loss/tok 3.2222 (3.2458)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4560/6832]	Time 0.404 (0.346)	Data 0.00103 (0.00125)	Tok/s 67532 (74168)	Loss/tok 3.2204 (3.2457)	Learning Rate [7.8125e-05]
0: TRAIN [2][4570/6832]	Time 0.482 (0.346)	Data 0.00107 (0.00125)	Tok/s 75651 (74166)	Loss/tok 3.2527 (3.2456)	Learning Rate [7.8125e-05]
0: TRAIN [2][4580/6832]	Time 0.371 (0.346)	Data 0.00108 (0.00125)	Tok/s 67602 (74163)	Loss/tok 3.2275 (3.2454)	Learning Rate [7.8125e-05]
0: TRAIN [2][4590/6832]	Time 0.429 (0.346)	Data 0.00110 (0.00125)	Tok/s 66747 (74168)	Loss/tok 3.2314 (3.2452)	Learning Rate [7.8125e-05]
0: TRAIN [2][4600/6832]	Time 0.322 (0.346)	Data 0.00108 (0.00125)	Tok/s 71562 (74171)	Loss/tok 3.1270 (3.2451)	Learning Rate [7.8125e-05]
0: TRAIN [2][4610/6832]	Time 0.110 (0.346)	Data 0.00116 (0.00125)	Tok/s 76799 (74169)	Loss/tok 2.3757 (3.2449)	Learning Rate [7.8125e-05]
0: TRAIN [2][4620/6832]	Time 0.204 (0.346)	Data 0.00120 (0.00125)	Tok/s 77048 (74165)	Loss/tok 2.9616 (3.2447)	Learning Rate [7.8125e-05]
0: TRAIN [2][4630/6832]	Time 0.472 (0.346)	Data 0.00101 (0.00125)	Tok/s 75783 (74164)	Loss/tok 3.2316 (3.2445)	Learning Rate [7.8125e-05]
0: TRAIN [2][4640/6832]	Time 0.485 (0.346)	Data 0.00106 (0.00125)	Tok/s 80100 (74164)	Loss/tok 3.2412 (3.2444)	Learning Rate [7.8125e-05]
0: TRAIN [2][4650/6832]	Time 0.452 (0.346)	Data 0.00109 (0.00125)	Tok/s 68733 (74168)	Loss/tok 3.2885 (3.2442)	Learning Rate [7.8125e-05]
0: TRAIN [2][4660/6832]	Time 0.133 (0.346)	Data 0.00103 (0.00125)	Tok/s 84006 (74182)	Loss/tok 2.6389 (3.2439)	Learning Rate [7.8125e-05]
0: TRAIN [2][4670/6832]	Time 0.432 (0.346)	Data 0.00101 (0.00125)	Tok/s 66673 (74179)	Loss/tok 3.2053 (3.2437)	Learning Rate [7.8125e-05]
0: TRAIN [2][4680/6832]	Time 0.310 (0.346)	Data 0.00103 (0.00125)	Tok/s 72040 (74183)	Loss/tok 3.1475 (3.2435)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4690/6832]	Time 0.227 (0.346)	Data 0.00103 (0.00125)	Tok/s 75015 (74181)	Loss/tok 2.9912 (3.2433)	Learning Rate [7.8125e-05]
0: TRAIN [2][4700/6832]	Time 0.376 (0.346)	Data 0.00109 (0.00124)	Tok/s 69610 (74175)	Loss/tok 3.1061 (3.2431)	Learning Rate [7.8125e-05]
0: TRAIN [2][4710/6832]	Time 0.307 (0.346)	Data 0.00101 (0.00124)	Tok/s 69448 (74176)	Loss/tok 3.0614 (3.2429)	Learning Rate [7.8125e-05]
0: TRAIN [2][4720/6832]	Time 0.416 (0.346)	Data 0.00107 (0.00124)	Tok/s 67732 (74170)	Loss/tok 3.3069 (3.2429)	Learning Rate [7.8125e-05]
0: TRAIN [2][4730/6832]	Time 0.258 (0.346)	Data 0.00109 (0.00124)	Tok/s 73395 (74168)	Loss/tok 3.0597 (3.2426)	Learning Rate [7.8125e-05]
0: TRAIN [2][4740/6832]	Time 0.222 (0.346)	Data 0.00101 (0.00124)	Tok/s 76605 (74177)	Loss/tok 2.9716 (3.2424)	Learning Rate [7.8125e-05]
0: TRAIN [2][4750/6832]	Time 0.477 (0.346)	Data 0.00105 (0.00124)	Tok/s 63034 (74182)	Loss/tok 3.3382 (3.2422)	Learning Rate [7.8125e-05]
0: TRAIN [2][4760/6832]	Time 0.263 (0.346)	Data 0.00103 (0.00124)	Tok/s 75970 (74179)	Loss/tok 3.0275 (3.2421)	Learning Rate [7.8125e-05]
0: TRAIN [2][4770/6832]	Time 0.311 (0.346)	Data 0.00102 (0.00124)	Tok/s 72818 (74179)	Loss/tok 3.0993 (3.2420)	Learning Rate [7.8125e-05]
0: TRAIN [2][4780/6832]	Time 0.466 (0.346)	Data 0.00108 (0.00124)	Tok/s 68399 (74178)	Loss/tok 3.2366 (3.2418)	Learning Rate [7.8125e-05]
0: TRAIN [2][4790/6832]	Time 0.481 (0.346)	Data 0.00107 (0.00124)	Tok/s 89850 (74177)	Loss/tok 3.1742 (3.2417)	Learning Rate [7.8125e-05]
0: TRAIN [2][4800/6832]	Time 0.215 (0.346)	Data 0.00123 (0.00124)	Tok/s 74352 (74172)	Loss/tok 2.9649 (3.2414)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4810/6832]	Time 0.226 (0.346)	Data 0.00112 (0.00124)	Tok/s 72821 (74175)	Loss/tok 2.9926 (3.2412)	Learning Rate [7.8125e-05]
0: TRAIN [2][4820/6832]	Time 0.247 (0.346)	Data 0.00106 (0.00124)	Tok/s 75227 (74173)	Loss/tok 2.9914 (3.2409)	Learning Rate [7.8125e-05]
0: TRAIN [2][4830/6832]	Time 0.381 (0.346)	Data 0.00104 (0.00124)	Tok/s 69684 (74176)	Loss/tok 3.2078 (3.2407)	Learning Rate [7.8125e-05]
0: TRAIN [2][4840/6832]	Time 0.294 (0.346)	Data 0.00108 (0.00124)	Tok/s 68828 (74173)	Loss/tok 3.0940 (3.2405)	Learning Rate [7.8125e-05]
0: TRAIN [2][4850/6832]	Time 0.247 (0.346)	Data 0.00101 (0.00124)	Tok/s 72188 (74169)	Loss/tok 2.9630 (3.2405)	Learning Rate [7.8125e-05]
0: TRAIN [2][4860/6832]	Time 0.391 (0.346)	Data 0.00099 (0.00124)	Tok/s 70139 (74167)	Loss/tok 3.1745 (3.2404)	Learning Rate [7.8125e-05]
0: TRAIN [2][4870/6832]	Time 0.437 (0.346)	Data 0.00102 (0.00124)	Tok/s 65465 (74165)	Loss/tok 3.1701 (3.2402)	Learning Rate [7.8125e-05]
0: TRAIN [2][4880/6832]	Time 0.463 (0.346)	Data 0.00109 (0.00124)	Tok/s 97618 (74172)	Loss/tok 3.1452 (3.2400)	Learning Rate [7.8125e-05]
0: TRAIN [2][4890/6832]	Time 0.304 (0.346)	Data 0.00120 (0.00124)	Tok/s 74218 (74172)	Loss/tok 3.0630 (3.2397)	Learning Rate [7.8125e-05]
0: TRAIN [2][4900/6832]	Time 0.477 (0.346)	Data 0.00103 (0.00124)	Tok/s 66956 (74169)	Loss/tok 3.2500 (3.2396)	Learning Rate [7.8125e-05]
0: TRAIN [2][4910/6832]	Time 0.201 (0.346)	Data 0.00100 (0.00124)	Tok/s 75160 (74181)	Loss/tok 2.9293 (3.2393)	Learning Rate [7.8125e-05]
0: TRAIN [2][4920/6832]	Time 0.316 (0.346)	Data 0.00108 (0.00124)	Tok/s 71831 (74179)	Loss/tok 3.1248 (3.2391)	Learning Rate [7.8125e-05]
0: TRAIN [2][4930/6832]	Time 0.236 (0.346)	Data 0.00100 (0.00124)	Tok/s 73672 (74174)	Loss/tok 3.0424 (3.2389)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][4940/6832]	Time 0.463 (0.346)	Data 0.00115 (0.00124)	Tok/s 68278 (74174)	Loss/tok 3.2698 (3.2387)	Learning Rate [7.8125e-05]
0: TRAIN [2][4950/6832]	Time 0.356 (0.346)	Data 0.00104 (0.00124)	Tok/s 68993 (74171)	Loss/tok 3.1080 (3.2384)	Learning Rate [7.8125e-05]
0: TRAIN [2][4960/6832]	Time 0.225 (0.346)	Data 0.00106 (0.00124)	Tok/s 69069 (74167)	Loss/tok 2.9511 (3.2383)	Learning Rate [7.8125e-05]
0: TRAIN [2][4970/6832]	Time 0.145 (0.346)	Data 0.00101 (0.00124)	Tok/s 81830 (74179)	Loss/tok 2.8084 (3.2379)	Learning Rate [7.8125e-05]
0: TRAIN [2][4980/6832]	Time 0.112 (0.346)	Data 0.00110 (0.00124)	Tok/s 76220 (74184)	Loss/tok 2.3998 (3.2377)	Learning Rate [7.8125e-05]
0: TRAIN [2][4990/6832]	Time 0.155 (0.346)	Data 0.00104 (0.00124)	Tok/s 79926 (74185)	Loss/tok 2.7534 (3.2375)	Learning Rate [7.8125e-05]
0: TRAIN [2][5000/6832]	Time 0.291 (0.346)	Data 0.00104 (0.00124)	Tok/s 70793 (74180)	Loss/tok 3.1128 (3.2374)	Learning Rate [7.8125e-05]
0: TRAIN [2][5010/6832]	Time 0.278 (0.346)	Data 0.00104 (0.00124)	Tok/s 72775 (74182)	Loss/tok 3.0704 (3.2374)	Learning Rate [7.8125e-05]
0: TRAIN [2][5020/6832]	Time 0.380 (0.346)	Data 0.00100 (0.00123)	Tok/s 68719 (74175)	Loss/tok 3.2083 (3.2371)	Learning Rate [7.8125e-05]
0: TRAIN [2][5030/6832]	Time 0.465 (0.346)	Data 0.00104 (0.00123)	Tok/s 85229 (74169)	Loss/tok 3.1887 (3.2370)	Learning Rate [7.8125e-05]
0: TRAIN [2][5040/6832]	Time 0.485 (0.346)	Data 0.00107 (0.00123)	Tok/s 93061 (74169)	Loss/tok 3.1022 (3.2367)	Learning Rate [7.8125e-05]
0: TRAIN [2][5050/6832]	Time 0.319 (0.346)	Data 0.00102 (0.00123)	Tok/s 69078 (74168)	Loss/tok 3.1158 (3.2365)	Learning Rate [7.8125e-05]
0: TRAIN [2][5060/6832]	Time 0.334 (0.346)	Data 0.00103 (0.00123)	Tok/s 71201 (74163)	Loss/tok 3.1204 (3.2363)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5070/6832]	Time 0.341 (0.346)	Data 0.00106 (0.00123)	Tok/s 69069 (74158)	Loss/tok 3.1454 (3.2362)	Learning Rate [7.8125e-05]
0: TRAIN [2][5080/6832]	Time 0.487 (0.346)	Data 0.00113 (0.00123)	Tok/s 78782 (74156)	Loss/tok 3.1607 (3.2359)	Learning Rate [7.8125e-05]
0: TRAIN [2][5090/6832]	Time 0.421 (0.346)	Data 0.00105 (0.00123)	Tok/s 65669 (74152)	Loss/tok 3.1233 (3.2358)	Learning Rate [7.8125e-05]
0: TRAIN [2][5100/6832]	Time 0.352 (0.346)	Data 0.00144 (0.00123)	Tok/s 68437 (74151)	Loss/tok 3.0941 (3.2356)	Learning Rate [7.8125e-05]
0: TRAIN [2][5110/6832]	Time 0.300 (0.346)	Data 0.00129 (0.00123)	Tok/s 72981 (74155)	Loss/tok 3.1620 (3.2353)	Learning Rate [7.8125e-05]
0: TRAIN [2][5120/6832]	Time 0.485 (0.346)	Data 0.00105 (0.00123)	Tok/s 96036 (74155)	Loss/tok 3.1153 (3.2351)	Learning Rate [7.8125e-05]
0: TRAIN [2][5130/6832]	Time 0.484 (0.346)	Data 0.00103 (0.00123)	Tok/s 81847 (74154)	Loss/tok 3.1490 (3.2348)	Learning Rate [7.8125e-05]
0: TRAIN [2][5140/6832]	Time 0.479 (0.346)	Data 0.00105 (0.00123)	Tok/s 70445 (74147)	Loss/tok 3.2362 (3.2347)	Learning Rate [7.8125e-05]
0: TRAIN [2][5150/6832]	Time 0.481 (0.346)	Data 0.00110 (0.00123)	Tok/s 81183 (74145)	Loss/tok 3.2276 (3.2344)	Learning Rate [7.8125e-05]
0: TRAIN [2][5160/6832]	Time 0.396 (0.346)	Data 0.00109 (0.00123)	Tok/s 69731 (74143)	Loss/tok 3.3171 (3.2344)	Learning Rate [7.8125e-05]
0: TRAIN [2][5170/6832]	Time 0.254 (0.346)	Data 0.00102 (0.00123)	Tok/s 75787 (74149)	Loss/tok 3.0509 (3.2343)	Learning Rate [7.8125e-05]
0: TRAIN [2][5180/6832]	Time 0.480 (0.346)	Data 0.00101 (0.00123)	Tok/s 78357 (74157)	Loss/tok 3.2648 (3.2340)	Learning Rate [7.8125e-05]
0: TRAIN [2][5190/6832]	Time 0.101 (0.346)	Data 0.00107 (0.00123)	Tok/s 57316 (74159)	Loss/tok 2.0310 (3.2337)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5200/6832]	Time 0.117 (0.346)	Data 0.00110 (0.00123)	Tok/s 82722 (74169)	Loss/tok 2.5595 (3.2334)	Learning Rate [7.8125e-05]
0: TRAIN [2][5210/6832]	Time 0.451 (0.346)	Data 0.00105 (0.00123)	Tok/s 65855 (74162)	Loss/tok 3.2819 (3.2333)	Learning Rate [7.8125e-05]
0: TRAIN [2][5220/6832]	Time 0.486 (0.346)	Data 0.00106 (0.00123)	Tok/s 100087 (74163)	Loss/tok 2.9441 (3.2331)	Learning Rate [7.8125e-05]
0: TRAIN [2][5230/6832]	Time 0.184 (0.346)	Data 0.00105 (0.00123)	Tok/s 77871 (74162)	Loss/tok 2.8495 (3.2329)	Learning Rate [7.8125e-05]
0: TRAIN [2][5240/6832]	Time 0.426 (0.346)	Data 0.00101 (0.00123)	Tok/s 66765 (74162)	Loss/tok 3.1127 (3.2327)	Learning Rate [7.8125e-05]
0: TRAIN [2][5250/6832]	Time 0.365 (0.346)	Data 0.00103 (0.00123)	Tok/s 67147 (74162)	Loss/tok 3.1581 (3.2324)	Learning Rate [7.8125e-05]
0: TRAIN [2][5260/6832]	Time 0.399 (0.346)	Data 0.00101 (0.00123)	Tok/s 67660 (74162)	Loss/tok 3.2000 (3.2322)	Learning Rate [7.8125e-05]
0: TRAIN [2][5270/6832]	Time 0.282 (0.346)	Data 0.00111 (0.00123)	Tok/s 70726 (74170)	Loss/tok 3.0880 (3.2320)	Learning Rate [7.8125e-05]
0: TRAIN [2][5280/6832]	Time 0.479 (0.346)	Data 0.00105 (0.00123)	Tok/s 76143 (74163)	Loss/tok 3.2428 (3.2318)	Learning Rate [7.8125e-05]
0: TRAIN [2][5290/6832]	Time 0.324 (0.346)	Data 0.00116 (0.00123)	Tok/s 73529 (74163)	Loss/tok 3.1130 (3.2317)	Learning Rate [7.8125e-05]
0: TRAIN [2][5300/6832]	Time 0.231 (0.346)	Data 0.00102 (0.00123)	Tok/s 75363 (74170)	Loss/tok 3.0543 (3.2314)	Learning Rate [7.8125e-05]
0: TRAIN [2][5310/6832]	Time 0.185 (0.346)	Data 0.00099 (0.00123)	Tok/s 77883 (74177)	Loss/tok 2.8176 (3.2311)	Learning Rate [7.8125e-05]
0: TRAIN [2][5320/6832]	Time 0.294 (0.346)	Data 0.00106 (0.00123)	Tok/s 68966 (74174)	Loss/tok 3.0437 (3.2309)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5330/6832]	Time 0.487 (0.346)	Data 0.00108 (0.00123)	Tok/s 99628 (74184)	Loss/tok 2.9924 (3.2306)	Learning Rate [7.8125e-05]
0: TRAIN [2][5340/6832]	Time 0.239 (0.346)	Data 0.00099 (0.00123)	Tok/s 70512 (74185)	Loss/tok 2.9476 (3.2304)	Learning Rate [7.8125e-05]
0: TRAIN [2][5350/6832]	Time 0.321 (0.346)	Data 0.00104 (0.00123)	Tok/s 73710 (74187)	Loss/tok 3.1103 (3.2302)	Learning Rate [7.8125e-05]
0: TRAIN [2][5360/6832]	Time 0.430 (0.346)	Data 0.00103 (0.00123)	Tok/s 66375 (74183)	Loss/tok 3.2519 (3.2300)	Learning Rate [7.8125e-05]
0: TRAIN [2][5370/6832]	Time 0.459 (0.346)	Data 0.00103 (0.00123)	Tok/s 106183 (74188)	Loss/tok 2.9894 (3.2297)	Learning Rate [7.8125e-05]
0: TRAIN [2][5380/6832]	Time 0.482 (0.346)	Data 0.00103 (0.00123)	Tok/s 87311 (74190)	Loss/tok 3.1091 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [2][5390/6832]	Time 0.279 (0.346)	Data 0.00101 (0.00122)	Tok/s 72330 (74189)	Loss/tok 3.0414 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [2][5400/6832]	Time 0.346 (0.346)	Data 0.00105 (0.00122)	Tok/s 73025 (74194)	Loss/tok 3.1002 (3.2290)	Learning Rate [7.8125e-05]
0: TRAIN [2][5410/6832]	Time 0.195 (0.346)	Data 0.00108 (0.00122)	Tok/s 78282 (74192)	Loss/tok 2.9442 (3.2288)	Learning Rate [7.8125e-05]
0: TRAIN [2][5420/6832]	Time 0.462 (0.346)	Data 0.00100 (0.00122)	Tok/s 68071 (74190)	Loss/tok 3.2141 (3.2286)	Learning Rate [7.8125e-05]
0: TRAIN [2][5430/6832]	Time 0.350 (0.346)	Data 0.00103 (0.00122)	Tok/s 69005 (74189)	Loss/tok 3.1313 (3.2284)	Learning Rate [7.8125e-05]
0: TRAIN [2][5440/6832]	Time 0.485 (0.346)	Data 0.00107 (0.00122)	Tok/s 100284 (74188)	Loss/tok 3.0249 (3.2282)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5450/6832]	Time 0.487 (0.346)	Data 0.00147 (0.00122)	Tok/s 85031 (74192)	Loss/tok 3.1369 (3.2279)	Learning Rate [7.8125e-05]
0: TRAIN [2][5460/6832]	Time 0.479 (0.346)	Data 0.00103 (0.00122)	Tok/s 69283 (74191)	Loss/tok 3.2238 (3.2277)	Learning Rate [7.8125e-05]
0: TRAIN [2][5470/6832]	Time 0.340 (0.346)	Data 0.00105 (0.00122)	Tok/s 69188 (74188)	Loss/tok 3.0137 (3.2276)	Learning Rate [7.8125e-05]
0: TRAIN [2][5480/6832]	Time 0.214 (0.346)	Data 0.00101 (0.00122)	Tok/s 74212 (74194)	Loss/tok 2.9298 (3.2273)	Learning Rate [7.8125e-05]
0: TRAIN [2][5490/6832]	Time 0.134 (0.346)	Data 0.00104 (0.00122)	Tok/s 79022 (74197)	Loss/tok 2.5831 (3.2271)	Learning Rate [7.8125e-05]
0: TRAIN [2][5500/6832]	Time 0.259 (0.346)	Data 0.00111 (0.00122)	Tok/s 73244 (74197)	Loss/tok 2.9675 (3.2269)	Learning Rate [7.8125e-05]
0: TRAIN [2][5510/6832]	Time 0.107 (0.346)	Data 0.00107 (0.00122)	Tok/s 77983 (74202)	Loss/tok 2.3534 (3.2266)	Learning Rate [7.8125e-05]
0: TRAIN [2][5520/6832]	Time 0.463 (0.346)	Data 0.00105 (0.00122)	Tok/s 87302 (74201)	Loss/tok 3.1423 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [2][5530/6832]	Time 0.213 (0.346)	Data 0.00105 (0.00122)	Tok/s 78667 (74206)	Loss/tok 2.9631 (3.2263)	Learning Rate [7.8125e-05]
0: TRAIN [2][5540/6832]	Time 0.115 (0.346)	Data 0.00112 (0.00122)	Tok/s 74590 (74206)	Loss/tok 2.3506 (3.2260)	Learning Rate [7.8125e-05]
0: TRAIN [2][5550/6832]	Time 0.254 (0.346)	Data 0.00105 (0.00122)	Tok/s 72937 (74202)	Loss/tok 3.0031 (3.2258)	Learning Rate [7.8125e-05]
0: TRAIN [2][5560/6832]	Time 0.121 (0.346)	Data 0.00110 (0.00122)	Tok/s 80230 (74200)	Loss/tok 2.5167 (3.2256)	Learning Rate [7.8125e-05]
0: TRAIN [2][5570/6832]	Time 0.452 (0.346)	Data 0.00112 (0.00122)	Tok/s 67642 (74195)	Loss/tok 3.1689 (3.2254)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5580/6832]	Time 0.463 (0.346)	Data 0.00120 (0.00122)	Tok/s 100645 (74197)	Loss/tok 3.0192 (3.2251)	Learning Rate [7.8125e-05]
0: TRAIN [2][5590/6832]	Time 0.482 (0.346)	Data 0.00102 (0.00122)	Tok/s 72680 (74200)	Loss/tok 3.1896 (3.2249)	Learning Rate [7.8125e-05]
0: TRAIN [2][5600/6832]	Time 0.329 (0.346)	Data 0.00111 (0.00122)	Tok/s 70101 (74201)	Loss/tok 3.1020 (3.2247)	Learning Rate [7.8125e-05]
0: TRAIN [2][5610/6832]	Time 0.312 (0.346)	Data 0.00106 (0.00122)	Tok/s 73764 (74199)	Loss/tok 2.9969 (3.2244)	Learning Rate [7.8125e-05]
0: TRAIN [2][5620/6832]	Time 0.481 (0.346)	Data 0.00106 (0.00122)	Tok/s 91801 (74204)	Loss/tok 3.0289 (3.2242)	Learning Rate [7.8125e-05]
0: TRAIN [2][5630/6832]	Time 0.266 (0.346)	Data 0.00123 (0.00122)	Tok/s 74870 (74202)	Loss/tok 3.0394 (3.2240)	Learning Rate [7.8125e-05]
0: TRAIN [2][5640/6832]	Time 0.126 (0.346)	Data 0.00102 (0.00122)	Tok/s 76850 (74197)	Loss/tok 2.5139 (3.2238)	Learning Rate [7.8125e-05]
0: TRAIN [2][5650/6832]	Time 0.357 (0.346)	Data 0.00104 (0.00122)	Tok/s 68629 (74191)	Loss/tok 3.1454 (3.2236)	Learning Rate [7.8125e-05]
0: TRAIN [2][5660/6832]	Time 0.407 (0.346)	Data 0.00107 (0.00122)	Tok/s 67497 (74192)	Loss/tok 3.1685 (3.2235)	Learning Rate [7.8125e-05]
0: TRAIN [2][5670/6832]	Time 0.434 (0.346)	Data 0.00102 (0.00122)	Tok/s 64847 (74191)	Loss/tok 3.1574 (3.2232)	Learning Rate [7.8125e-05]
0: TRAIN [2][5680/6832]	Time 0.446 (0.346)	Data 0.00104 (0.00122)	Tok/s 70309 (74185)	Loss/tok 3.2253 (3.2230)	Learning Rate [7.8125e-05]
0: TRAIN [2][5690/6832]	Time 0.151 (0.346)	Data 0.00109 (0.00122)	Tok/s 78523 (74191)	Loss/tok 2.7200 (3.2227)	Learning Rate [7.8125e-05]
0: TRAIN [2][5700/6832]	Time 0.217 (0.346)	Data 0.00105 (0.00122)	Tok/s 77077 (74203)	Loss/tok 2.9083 (3.2224)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5710/6832]	Time 0.382 (0.346)	Data 0.00104 (0.00122)	Tok/s 70336 (74209)	Loss/tok 3.0773 (3.2221)	Learning Rate [7.8125e-05]
0: TRAIN [2][5720/6832]	Time 0.477 (0.346)	Data 0.00116 (0.00122)	Tok/s 66161 (74209)	Loss/tok 3.1730 (3.2219)	Learning Rate [7.8125e-05]
0: TRAIN [2][5730/6832]	Time 0.251 (0.346)	Data 0.00102 (0.00122)	Tok/s 75447 (74206)	Loss/tok 3.0651 (3.2217)	Learning Rate [7.8125e-05]
0: TRAIN [2][5740/6832]	Time 0.158 (0.346)	Data 0.00123 (0.00122)	Tok/s 78616 (74200)	Loss/tok 2.8207 (3.2215)	Learning Rate [7.8125e-05]
0: TRAIN [2][5750/6832]	Time 0.426 (0.346)	Data 0.00110 (0.00122)	Tok/s 66989 (74192)	Loss/tok 3.1709 (3.2213)	Learning Rate [7.8125e-05]
0: TRAIN [2][5760/6832]	Time 0.479 (0.346)	Data 0.00102 (0.00122)	Tok/s 67631 (74184)	Loss/tok 3.1922 (3.2211)	Learning Rate [7.8125e-05]
0: TRAIN [2][5770/6832]	Time 0.146 (0.347)	Data 0.00106 (0.00122)	Tok/s 72549 (74185)	Loss/tok 2.6302 (3.2209)	Learning Rate [7.8125e-05]
0: TRAIN [2][5780/6832]	Time 0.166 (0.346)	Data 0.00107 (0.00122)	Tok/s 74639 (74185)	Loss/tok 2.7644 (3.2207)	Learning Rate [7.8125e-05]
0: TRAIN [2][5790/6832]	Time 0.362 (0.346)	Data 0.00101 (0.00122)	Tok/s 73456 (74185)	Loss/tok 3.0809 (3.2203)	Learning Rate [7.8125e-05]
0: TRAIN [2][5800/6832]	Time 0.485 (0.346)	Data 0.00108 (0.00122)	Tok/s 81859 (74192)	Loss/tok 3.1984 (3.2200)	Learning Rate [7.8125e-05]
0: TRAIN [2][5810/6832]	Time 0.179 (0.346)	Data 0.00109 (0.00122)	Tok/s 77425 (74194)	Loss/tok 2.7760 (3.2196)	Learning Rate [7.8125e-05]
0: TRAIN [2][5820/6832]	Time 0.457 (0.346)	Data 0.00102 (0.00121)	Tok/s 68009 (74189)	Loss/tok 3.1674 (3.2194)	Learning Rate [7.8125e-05]
0: TRAIN [2][5830/6832]	Time 0.482 (0.346)	Data 0.00110 (0.00121)	Tok/s 79405 (74187)	Loss/tok 3.1867 (3.2192)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5840/6832]	Time 0.482 (0.346)	Data 0.00104 (0.00121)	Tok/s 78188 (74184)	Loss/tok 3.1360 (3.2190)	Learning Rate [7.8125e-05]
0: TRAIN [2][5850/6832]	Time 0.443 (0.346)	Data 0.00104 (0.00121)	Tok/s 65120 (74179)	Loss/tok 3.1367 (3.2188)	Learning Rate [7.8125e-05]
0: TRAIN [2][5860/6832]	Time 0.436 (0.346)	Data 0.00113 (0.00121)	Tok/s 67483 (74187)	Loss/tok 3.1219 (3.2185)	Learning Rate [7.8125e-05]
0: TRAIN [2][5870/6832]	Time 0.123 (0.346)	Data 0.00104 (0.00121)	Tok/s 78158 (74187)	Loss/tok 2.5546 (3.2182)	Learning Rate [7.8125e-05]
0: TRAIN [2][5880/6832]	Time 0.300 (0.346)	Data 0.00108 (0.00121)	Tok/s 70075 (74188)	Loss/tok 3.1344 (3.2180)	Learning Rate [7.8125e-05]
0: TRAIN [2][5890/6832]	Time 0.473 (0.346)	Data 0.00100 (0.00121)	Tok/s 71430 (74186)	Loss/tok 3.2265 (3.2178)	Learning Rate [7.8125e-05]
0: TRAIN [2][5900/6832]	Time 0.478 (0.346)	Data 0.00106 (0.00121)	Tok/s 70517 (74183)	Loss/tok 3.2188 (3.2175)	Learning Rate [7.8125e-05]
0: TRAIN [2][5910/6832]	Time 0.462 (0.346)	Data 0.00100 (0.00121)	Tok/s 93421 (74185)	Loss/tok 3.0339 (3.2173)	Learning Rate [7.8125e-05]
0: TRAIN [2][5920/6832]	Time 0.485 (0.347)	Data 0.00105 (0.00121)	Tok/s 75272 (74191)	Loss/tok 3.2061 (3.2170)	Learning Rate [7.8125e-05]
0: TRAIN [2][5930/6832]	Time 0.336 (0.347)	Data 0.00102 (0.00121)	Tok/s 69608 (74185)	Loss/tok 3.1414 (3.2168)	Learning Rate [7.8125e-05]
0: TRAIN [2][5940/6832]	Time 0.481 (0.347)	Data 0.00097 (0.00121)	Tok/s 89745 (74195)	Loss/tok 3.1346 (3.2166)	Learning Rate [7.8125e-05]
0: TRAIN [2][5950/6832]	Time 0.478 (0.347)	Data 0.00105 (0.00121)	Tok/s 72903 (74196)	Loss/tok 3.1916 (3.2163)	Learning Rate [7.8125e-05]
0: TRAIN [2][5960/6832]	Time 0.273 (0.347)	Data 0.00104 (0.00121)	Tok/s 73084 (74194)	Loss/tok 2.9244 (3.2160)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][5970/6832]	Time 0.283 (0.347)	Data 0.00105 (0.00121)	Tok/s 72089 (74193)	Loss/tok 3.0081 (3.2157)	Learning Rate [7.8125e-05]
0: TRAIN [2][5980/6832]	Time 0.477 (0.347)	Data 0.00102 (0.00121)	Tok/s 68297 (74191)	Loss/tok 3.1863 (3.2155)	Learning Rate [7.8125e-05]
0: TRAIN [2][5990/6832]	Time 0.486 (0.347)	Data 0.00103 (0.00121)	Tok/s 80368 (74197)	Loss/tok 3.1616 (3.2152)	Learning Rate [7.8125e-05]
0: TRAIN [2][6000/6832]	Time 0.479 (0.347)	Data 0.00101 (0.00121)	Tok/s 75982 (74199)	Loss/tok 3.2429 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [2][6010/6832]	Time 0.139 (0.347)	Data 0.00100 (0.00121)	Tok/s 80667 (74195)	Loss/tok 2.6841 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [2][6020/6832]	Time 0.483 (0.347)	Data 0.00102 (0.00121)	Tok/s 68935 (74196)	Loss/tok 3.3140 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][6030/6832]	Time 0.346 (0.347)	Data 0.00102 (0.00121)	Tok/s 69609 (74192)	Loss/tok 3.1505 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [2][6040/6832]	Time 0.461 (0.347)	Data 0.00108 (0.00121)	Tok/s 74186 (74194)	Loss/tok 3.2289 (3.2146)	Learning Rate [7.8125e-05]
0: TRAIN [2][6050/6832]	Time 0.463 (0.347)	Data 0.00105 (0.00121)	Tok/s 64337 (74198)	Loss/tok 3.2755 (3.2146)	Learning Rate [7.8125e-05]
0: TRAIN [2][6060/6832]	Time 0.487 (0.347)	Data 0.00102 (0.00121)	Tok/s 88210 (74204)	Loss/tok 3.1935 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [2][6070/6832]	Time 0.222 (0.347)	Data 0.00103 (0.00121)	Tok/s 75904 (74209)	Loss/tok 2.9409 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [2][6080/6832]	Time 0.147 (0.347)	Data 0.00104 (0.00121)	Tok/s 81642 (74208)	Loss/tok 2.6991 (3.2143)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][6090/6832]	Time 0.475 (0.347)	Data 0.00133 (0.00121)	Tok/s 66082 (74209)	Loss/tok 3.2433 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [2][6100/6832]	Time 0.478 (0.347)	Data 0.00102 (0.00121)	Tok/s 81526 (74212)	Loss/tok 3.1547 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [2][6110/6832]	Time 0.459 (0.347)	Data 0.00111 (0.00121)	Tok/s 62810 (74209)	Loss/tok 3.2354 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [2][6120/6832]	Time 0.481 (0.347)	Data 0.00104 (0.00121)	Tok/s 74536 (74204)	Loss/tok 3.1829 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [2][6130/6832]	Time 0.154 (0.347)	Data 0.00103 (0.00121)	Tok/s 68560 (74200)	Loss/tok 2.5886 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [2][6140/6832]	Time 0.468 (0.347)	Data 0.00103 (0.00121)	Tok/s 68373 (74197)	Loss/tok 3.3179 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][6150/6832]	Time 0.450 (0.347)	Data 0.00111 (0.00121)	Tok/s 76360 (74195)	Loss/tok 3.2736 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][6160/6832]	Time 0.486 (0.347)	Data 0.00102 (0.00121)	Tok/s 88570 (74194)	Loss/tok 3.1361 (3.2136)	Learning Rate [7.8125e-05]
0: TRAIN [2][6170/6832]	Time 0.373 (0.347)	Data 0.00103 (0.00121)	Tok/s 65774 (74194)	Loss/tok 3.1436 (3.2135)	Learning Rate [7.8125e-05]
0: TRAIN [2][6180/6832]	Time 0.441 (0.347)	Data 0.00103 (0.00121)	Tok/s 67363 (74194)	Loss/tok 3.2989 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [2][6190/6832]	Time 0.463 (0.347)	Data 0.00112 (0.00121)	Tok/s 65253 (74189)	Loss/tok 3.1567 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [2][6200/6832]	Time 0.201 (0.347)	Data 0.00101 (0.00121)	Tok/s 73222 (74185)	Loss/tok 2.9215 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [2][6210/6832]	Time 0.244 (0.347)	Data 0.00108 (0.00121)	Tok/s 73215 (74184)	Loss/tok 3.0159 (3.2131)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][6220/6832]	Time 0.486 (0.347)	Data 0.00108 (0.00121)	Tok/s 78590 (74186)	Loss/tok 3.2254 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [2][6230/6832]	Time 0.301 (0.347)	Data 0.00101 (0.00121)	Tok/s 71123 (74190)	Loss/tok 3.1436 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [2][6240/6832]	Time 0.225 (0.347)	Data 0.00103 (0.00121)	Tok/s 77396 (74189)	Loss/tok 3.0451 (3.2125)	Learning Rate [7.8125e-05]
0: TRAIN [2][6250/6832]	Time 0.410 (0.347)	Data 0.00111 (0.00121)	Tok/s 65790 (74182)	Loss/tok 3.2112 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][6260/6832]	Time 0.410 (0.347)	Data 0.00101 (0.00121)	Tok/s 67486 (74182)	Loss/tok 3.1642 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [2][6270/6832]	Time 0.482 (0.347)	Data 0.00107 (0.00121)	Tok/s 87595 (74186)	Loss/tok 3.2162 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [2][6280/6832]	Time 0.210 (0.347)	Data 0.00110 (0.00121)	Tok/s 75513 (74185)	Loss/tok 2.9834 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][6290/6832]	Time 0.484 (0.347)	Data 0.00103 (0.00121)	Tok/s 88745 (74188)	Loss/tok 3.1580 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [2][6300/6832]	Time 0.313 (0.347)	Data 0.00109 (0.00120)	Tok/s 68915 (74185)	Loss/tok 3.0571 (3.2119)	Learning Rate [7.8125e-05]
0: TRAIN [2][6310/6832]	Time 0.234 (0.347)	Data 0.00101 (0.00120)	Tok/s 76435 (74187)	Loss/tok 2.9534 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6320/6832]	Time 0.350 (0.347)	Data 0.00101 (0.00120)	Tok/s 69323 (74186)	Loss/tok 3.2180 (3.2117)	Learning Rate [7.8125e-05]
0: TRAIN [2][6330/6832]	Time 0.185 (0.347)	Data 0.00106 (0.00120)	Tok/s 78020 (74190)	Loss/tok 2.9183 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [2][6340/6832]	Time 0.279 (0.347)	Data 0.00099 (0.00120)	Tok/s 73492 (74188)	Loss/tok 3.0753 (3.2114)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][6350/6832]	Time 0.343 (0.347)	Data 0.00106 (0.00120)	Tok/s 70085 (74187)	Loss/tok 3.1771 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [2][6360/6832]	Time 0.121 (0.347)	Data 0.00099 (0.00120)	Tok/s 80010 (74186)	Loss/tok 2.5476 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][6370/6832]	Time 0.285 (0.347)	Data 0.00129 (0.00120)	Tok/s 72010 (74184)	Loss/tok 3.1014 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [2][6380/6832]	Time 0.476 (0.347)	Data 0.00102 (0.00120)	Tok/s 73158 (74186)	Loss/tok 3.2843 (3.2110)	Learning Rate [7.8125e-05]
0: TRAIN [2][6390/6832]	Time 0.276 (0.347)	Data 0.00101 (0.00120)	Tok/s 74027 (74186)	Loss/tok 3.1021 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [2][6400/6832]	Time 0.417 (0.347)	Data 0.00105 (0.00120)	Tok/s 66525 (74188)	Loss/tok 3.2319 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [2][6410/6832]	Time 0.436 (0.347)	Data 0.00102 (0.00120)	Tok/s 68138 (74190)	Loss/tok 3.1716 (3.2106)	Learning Rate [7.8125e-05]
0: TRAIN [2][6420/6832]	Time 0.432 (0.347)	Data 0.00103 (0.00120)	Tok/s 65375 (74192)	Loss/tok 3.1676 (3.2105)	Learning Rate [7.8125e-05]
0: TRAIN [2][6430/6832]	Time 0.316 (0.347)	Data 0.00103 (0.00120)	Tok/s 70783 (74189)	Loss/tok 3.1422 (3.2104)	Learning Rate [7.8125e-05]
0: TRAIN [2][6440/6832]	Time 0.427 (0.347)	Data 0.00112 (0.00120)	Tok/s 67498 (74183)	Loss/tok 3.2026 (3.2103)	Learning Rate [7.8125e-05]
0: TRAIN [2][6450/6832]	Time 0.275 (0.347)	Data 0.00099 (0.00120)	Tok/s 71115 (74184)	Loss/tok 3.0415 (3.2102)	Learning Rate [7.8125e-05]
0: TRAIN [2][6460/6832]	Time 0.417 (0.347)	Data 0.00109 (0.00120)	Tok/s 68662 (74183)	Loss/tok 3.2780 (3.2101)	Learning Rate [7.8125e-05]
0: TRAIN [2][6470/6832]	Time 0.195 (0.347)	Data 0.00106 (0.00120)	Tok/s 77966 (74179)	Loss/tok 3.0018 (3.2100)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][6480/6832]	Time 0.478 (0.347)	Data 0.00099 (0.00120)	Tok/s 88349 (74181)	Loss/tok 3.2598 (3.2098)	Learning Rate [7.8125e-05]
0: TRAIN [2][6490/6832]	Time 0.480 (0.347)	Data 0.00110 (0.00120)	Tok/s 72374 (74181)	Loss/tok 3.1347 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [2][6500/6832]	Time 0.297 (0.347)	Data 0.00101 (0.00120)	Tok/s 69700 (74175)	Loss/tok 3.0608 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [2][6510/6832]	Time 0.260 (0.347)	Data 0.00106 (0.00120)	Tok/s 75125 (74172)	Loss/tok 3.1105 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6520/6832]	Time 0.228 (0.347)	Data 0.00097 (0.00120)	Tok/s 73766 (74175)	Loss/tok 2.9676 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][6530/6832]	Time 0.465 (0.347)	Data 0.00115 (0.00120)	Tok/s 65844 (74167)	Loss/tok 3.3444 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6540/6832]	Time 0.112 (0.347)	Data 0.00106 (0.00120)	Tok/s 74090 (74171)	Loss/tok 2.3447 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][6550/6832]	Time 0.373 (0.347)	Data 0.00107 (0.00120)	Tok/s 66665 (74163)	Loss/tok 3.2347 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][6560/6832]	Time 0.334 (0.347)	Data 0.00116 (0.00120)	Tok/s 69038 (74164)	Loss/tok 3.2809 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6570/6832]	Time 0.298 (0.347)	Data 0.00103 (0.00120)	Tok/s 70026 (74161)	Loss/tok 3.2924 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6580/6832]	Time 0.435 (0.347)	Data 0.00099 (0.00120)	Tok/s 64745 (74160)	Loss/tok 3.3131 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6590/6832]	Time 0.463 (0.347)	Data 0.00103 (0.00120)	Tok/s 66789 (74153)	Loss/tok 3.2932 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [2][6600/6832]	Time 0.454 (0.347)	Data 0.00105 (0.00120)	Tok/s 65735 (74152)	Loss/tok 3.2827 (3.2097)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][6610/6832]	Time 0.484 (0.347)	Data 0.00111 (0.00120)	Tok/s 93376 (74157)	Loss/tok 3.0824 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [2][6620/6832]	Time 0.166 (0.347)	Data 0.00111 (0.00120)	Tok/s 75674 (74156)	Loss/tok 2.8629 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6630/6832]	Time 0.165 (0.347)	Data 0.00113 (0.00120)	Tok/s 78753 (74151)	Loss/tok 2.8351 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6640/6832]	Time 0.429 (0.347)	Data 0.00112 (0.00120)	Tok/s 68370 (74154)	Loss/tok 3.2858 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [2][6650/6832]	Time 0.165 (0.347)	Data 0.00101 (0.00120)	Tok/s 78467 (74154)	Loss/tok 2.8264 (3.2095)	Learning Rate [7.8125e-05]
0: TRAIN [2][6660/6832]	Time 0.482 (0.347)	Data 0.00104 (0.00120)	Tok/s 91600 (74158)	Loss/tok 3.1732 (3.2094)	Learning Rate [7.8125e-05]
0: TRAIN [2][6670/6832]	Time 0.481 (0.347)	Data 0.00102 (0.00120)	Tok/s 68265 (74151)	Loss/tok 3.3265 (3.2094)	Learning Rate [7.8125e-05]
0: TRAIN [2][6680/6832]	Time 0.264 (0.347)	Data 0.00109 (0.00120)	Tok/s 70000 (74151)	Loss/tok 3.0901 (3.2094)	Learning Rate [7.8125e-05]
0: TRAIN [2][6690/6832]	Time 0.388 (0.347)	Data 0.00106 (0.00120)	Tok/s 66551 (74154)	Loss/tok 3.2604 (3.2093)	Learning Rate [7.8125e-05]
0: TRAIN [2][6700/6832]	Time 0.482 (0.347)	Data 0.00106 (0.00120)	Tok/s 82524 (74151)	Loss/tok 3.2371 (3.2094)	Learning Rate [7.8125e-05]
0: TRAIN [2][6710/6832]	Time 0.138 (0.347)	Data 0.00109 (0.00120)	Tok/s 80899 (74148)	Loss/tok 2.7121 (3.2093)	Learning Rate [7.8125e-05]
0: TRAIN [2][6720/6832]	Time 0.485 (0.347)	Data 0.00114 (0.00120)	Tok/s 85305 (74154)	Loss/tok 3.1950 (3.2093)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [2][6730/6832]	Time 0.319 (0.347)	Data 0.00120 (0.00120)	Tok/s 70190 (74157)	Loss/tok 3.1570 (3.2092)	Learning Rate [7.8125e-05]
0: TRAIN [2][6740/6832]	Time 0.474 (0.347)	Data 0.00103 (0.00120)	Tok/s 75330 (74159)	Loss/tok 3.2712 (3.2092)	Learning Rate [7.8125e-05]
0: TRAIN [2][6750/6832]	Time 0.280 (0.347)	Data 0.00109 (0.00120)	Tok/s 73421 (74166)	Loss/tok 3.1318 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][6760/6832]	Time 0.409 (0.347)	Data 0.00107 (0.00120)	Tok/s 65877 (74163)	Loss/tok 3.2445 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][6770/6832]	Time 0.460 (0.347)	Data 0.00108 (0.00120)	Tok/s 65757 (74156)	Loss/tok 3.3380 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][6780/6832]	Time 0.166 (0.347)	Data 0.00101 (0.00120)	Tok/s 83288 (74158)	Loss/tok 2.9654 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][6790/6832]	Time 0.114 (0.347)	Data 0.00104 (0.00120)	Tok/s 74061 (74153)	Loss/tok 2.4859 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][6800/6832]	Time 0.302 (0.347)	Data 0.00104 (0.00120)	Tok/s 73786 (74148)	Loss/tok 3.1314 (3.2092)	Learning Rate [7.8125e-05]
0: TRAIN [2][6810/6832]	Time 0.466 (0.347)	Data 0.00106 (0.00120)	Tok/s 92267 (74155)	Loss/tok 3.1820 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][6820/6832]	Time 0.479 (0.347)	Data 0.00103 (0.00120)	Tok/s 78419 (74159)	Loss/tok 3.3625 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [2][6830/6832]	Time 0.484 (0.347)	Data 0.00094 (0.00121)	Tok/s 75181 (74162)	Loss/tok 3.3046 (3.2091)	Learning Rate [7.8125e-05]
0: Running validation on dev set
0: VALIDATION [2][0/80]	Time 0.064 (0.000)	Data 0.00227 (0.00000)	Tok/s 159367 (0)	Loss/tok 3.3683 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [2][10/80]	Time 0.026 (0.031)	Data 0.00174 (0.00181)	Tok/s 217427 (216456)	Loss/tok 3.1413 (3.2459)	Learning Rate [7.8125e-05]
0: VALIDATION [2][20/80]	Time 0.022 (0.027)	Data 0.00166 (0.00176)	Tok/s 210284 (215700)	Loss/tok 3.1380 (3.2215)	Learning Rate [7.8125e-05]
0: VALIDATION [2][30/80]	Time 0.019 (0.025)	Data 0.00164 (0.00172)	Tok/s 194997 (214994)	Loss/tok 3.1844 (3.1953)	Learning Rate [7.8125e-05]
0: VALIDATION [2][40/80]	Time 0.015 (0.023)	Data 0.00160 (0.00169)	Tok/s 204471 (211703)	Loss/tok 3.1441 (3.1797)	Learning Rate [7.8125e-05]
0: VALIDATION [2][50/80]	Time 0.014 (0.021)	Data 0.00154 (0.00167)	Tok/s 190261 (208245)	Loss/tok 2.9892 (3.1644)	Learning Rate [7.8125e-05]
0: VALIDATION [2][60/80]	Time 0.015 (0.020)	Data 0.00155 (0.00166)	Tok/s 143828 (202868)	Loss/tok 3.2255 (3.1589)	Learning Rate [7.8125e-05]
0: VALIDATION [2][70/80]	Time 0.014 (0.019)	Data 0.00150 (0.00164)	Tok/s 111305 (191839)	Loss/tok 3.0542 (3.1518)	Learning Rate [7.8125e-05]
:::MLPv0.5.0 gnmt 1560841450.463948965 (train.py:459) eval_start: 2
0: Running evaluation on test set
0: TEST [2][0/6]	Time 2.105 (2.105)	Decoder iters 149.0 (149.0)	Tok/s 14151 (14151)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560841465.800910473 (train.py:464) eval_accuracy: {"epoch": 2, "value": 21.670000076293945}
:::MLPv0.5.0 gnmt 1560841465.801377296 (train.py:466) eval_target: 21.8
:::MLPv0.5.0 gnmt 1560841465.801831722 (train.py:467) eval_stop
0: Summary: Epoch: 2	Training Loss: 3.2091	Validation Loss: 3.1424	Test BLEU: 21.67
0: Performance: Epoch: 2	Training: 74163 Tok/s	Validation: 181120 Tok/s
0: Finished epoch 2
0: Starting epoch 3
:::MLPv0.5.0 gnmt 1560841465.802674294 (train.py:443) train_epoch: 3
/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:182: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
  self.num_layers, self.dropout, self.training, self.bidirectional)
:::MLPv0.5.0 gnmt 1560841466.396161556 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 2037452816
:::MLPv0.5.0 gnmt 1560841466.478666306 (seq2seq/data/sampler.py:66) input_shard: 40960
0: TRAIN [3][0/6832]	Time 1.158 (0.000)	Data 0.86659 (0.00000)	Tok/s 19012 (0)	Loss/tok 3.1662 (0.0000)	Learning Rate [7.8125e-05]
0: TRAIN [3][10/6832]	Time 0.484 (0.347)	Data 0.00142 (0.00136)	Tok/s 96182 (74915)	Loss/tok 3.0662 (3.1951)	Learning Rate [7.8125e-05]
0: TRAIN [3][20/6832]	Time 0.376 (0.360)	Data 0.00115 (0.00135)	Tok/s 68038 (72598)	Loss/tok 3.2471 (3.2133)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][30/6832]	Time 0.225 (0.337)	Data 0.00104 (0.00124)	Tok/s 72673 (73362)	Loss/tok 2.9882 (3.2035)	Learning Rate [7.8125e-05]
0: TRAIN [3][40/6832]	Time 0.483 (0.333)	Data 0.00097 (0.00119)	Tok/s 79112 (74598)	Loss/tok 3.2251 (3.1829)	Learning Rate [7.8125e-05]
0: TRAIN [3][50/6832]	Time 0.282 (0.329)	Data 0.00097 (0.00117)	Tok/s 70650 (74988)	Loss/tok 3.1411 (3.1770)	Learning Rate [7.8125e-05]
0: TRAIN [3][60/6832]	Time 0.346 (0.325)	Data 0.00098 (0.00115)	Tok/s 69492 (74252)	Loss/tok 3.2304 (3.1781)	Learning Rate [7.8125e-05]
0: TRAIN [3][70/6832]	Time 0.471 (0.321)	Data 0.00097 (0.00113)	Tok/s 72595 (74618)	Loss/tok 3.3635 (3.1761)	Learning Rate [7.8125e-05]
0: TRAIN [3][80/6832]	Time 0.117 (0.328)	Data 0.00109 (0.00113)	Tok/s 71572 (74193)	Loss/tok 2.4168 (3.1847)	Learning Rate [7.8125e-05]
0: TRAIN [3][90/6832]	Time 0.171 (0.326)	Data 0.00107 (0.00113)	Tok/s 75784 (74654)	Loss/tok 2.8256 (3.1747)	Learning Rate [7.8125e-05]
0: TRAIN [3][100/6832]	Time 0.323 (0.328)	Data 0.00119 (0.00113)	Tok/s 73108 (74587)	Loss/tok 3.1845 (3.1765)	Learning Rate [7.8125e-05]
0: TRAIN [3][110/6832]	Time 0.485 (0.331)	Data 0.00122 (0.00278)	Tok/s 72591 (74479)	Loss/tok 3.2688 (3.1753)	Learning Rate [7.8125e-05]
0: TRAIN [3][120/6832]	Time 0.215 (0.334)	Data 0.00121 (0.00266)	Tok/s 76099 (74502)	Loss/tok 3.0621 (3.1801)	Learning Rate [7.8125e-05]
0: TRAIN [3][130/6832]	Time 0.320 (0.333)	Data 0.00127 (0.00256)	Tok/s 70452 (74501)	Loss/tok 3.2026 (3.1807)	Learning Rate [7.8125e-05]
0: TRAIN [3][140/6832]	Time 0.347 (0.331)	Data 0.00123 (0.00248)	Tok/s 68343 (74260)	Loss/tok 3.2481 (3.1806)	Learning Rate [7.8125e-05]
0: TRAIN [3][150/6832]	Time 0.465 (0.335)	Data 0.00123 (0.00241)	Tok/s 71933 (74031)	Loss/tok 3.2897 (3.1867)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][160/6832]	Time 0.470 (0.336)	Data 0.00126 (0.00236)	Tok/s 71618 (74074)	Loss/tok 3.2909 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [3][170/6832]	Time 0.147 (0.341)	Data 0.00140 (0.00230)	Tok/s 84843 (74105)	Loss/tok 2.8432 (3.1926)	Learning Rate [7.8125e-05]
0: TRAIN [3][180/6832]	Time 0.424 (0.341)	Data 0.00126 (0.00226)	Tok/s 68301 (73995)	Loss/tok 3.3361 (3.1964)	Learning Rate [7.8125e-05]
0: TRAIN [3][190/6832]	Time 0.312 (0.341)	Data 0.00154 (0.00222)	Tok/s 69258 (74001)	Loss/tok 3.1925 (3.2006)	Learning Rate [7.8125e-05]
0: TRAIN [3][200/6832]	Time 0.485 (0.345)	Data 0.00109 (0.00217)	Tok/s 96098 (74330)	Loss/tok 3.1478 (3.2029)	Learning Rate [7.8125e-05]
0: TRAIN [3][210/6832]	Time 0.462 (0.345)	Data 0.00104 (0.00212)	Tok/s 105518 (74594)	Loss/tok 3.1103 (3.2009)	Learning Rate [7.8125e-05]
0: TRAIN [3][220/6832]	Time 0.418 (0.346)	Data 0.00106 (0.00208)	Tok/s 65502 (74601)	Loss/tok 3.2518 (3.2007)	Learning Rate [7.8125e-05]
0: TRAIN [3][230/6832]	Time 0.307 (0.346)	Data 0.00125 (0.00204)	Tok/s 71600 (74619)	Loss/tok 3.1440 (3.2005)	Learning Rate [7.8125e-05]
0: TRAIN [3][240/6832]	Time 0.140 (0.347)	Data 0.00110 (0.00276)	Tok/s 81699 (74414)	Loss/tok 2.6845 (3.2032)	Learning Rate [7.8125e-05]
0: TRAIN [3][250/6832]	Time 0.317 (0.344)	Data 0.00103 (0.00269)	Tok/s 71353 (74396)	Loss/tok 3.1705 (3.2028)	Learning Rate [7.8125e-05]
0: TRAIN [3][260/6832]	Time 0.395 (0.344)	Data 0.00110 (0.00263)	Tok/s 66235 (74214)	Loss/tok 3.2346 (3.2046)	Learning Rate [7.8125e-05]
0: TRAIN [3][270/6832]	Time 0.485 (0.343)	Data 0.00126 (0.00258)	Tok/s 100227 (74203)	Loss/tok 3.0973 (3.2027)	Learning Rate [7.8125e-05]
0: TRAIN [3][280/6832]	Time 0.222 (0.342)	Data 0.00106 (0.00253)	Tok/s 75512 (74169)	Loss/tok 2.9609 (3.2039)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][290/6832]	Time 0.433 (0.343)	Data 0.00146 (0.00249)	Tok/s 66295 (74008)	Loss/tok 3.3871 (3.2083)	Learning Rate [7.8125e-05]
0: TRAIN [3][300/6832]	Time 0.337 (0.342)	Data 0.00147 (0.00246)	Tok/s 71436 (73975)	Loss/tok 3.2658 (3.2085)	Learning Rate [7.8125e-05]
0: TRAIN [3][310/6832]	Time 0.358 (0.343)	Data 0.00130 (0.00242)	Tok/s 68419 (74045)	Loss/tok 3.3213 (3.2120)	Learning Rate [7.8125e-05]
0: TRAIN [3][320/6832]	Time 0.485 (0.345)	Data 0.00126 (0.00239)	Tok/s 79215 (74292)	Loss/tok 3.2557 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [3][330/6832]	Time 0.195 (0.345)	Data 0.00112 (0.00236)	Tok/s 77986 (74417)	Loss/tok 3.0957 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [3][340/6832]	Time 0.397 (0.346)	Data 0.00148 (0.00233)	Tok/s 69675 (74378)	Loss/tok 3.2795 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [3][350/6832]	Time 0.391 (0.346)	Data 0.00121 (0.00230)	Tok/s 69027 (74324)	Loss/tok 3.3000 (3.2148)	Learning Rate [7.8125e-05]
0: TRAIN [3][360/6832]	Time 0.385 (0.345)	Data 0.00115 (0.00227)	Tok/s 66518 (74505)	Loss/tok 3.3435 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [3][370/6832]	Time 0.231 (0.347)	Data 0.00022 (0.00247)	Tok/s 73824 (74454)	Loss/tok 3.0730 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [3][380/6832]	Time 0.467 (0.347)	Data 0.00109 (0.00243)	Tok/s 94698 (74512)	Loss/tok 3.1435 (3.2142)	Learning Rate [7.8125e-05]
0: TRAIN [3][390/6832]	Time 0.466 (0.347)	Data 0.00104 (0.00240)	Tok/s 65872 (74451)	Loss/tok 3.2964 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [3][400/6832]	Time 0.398 (0.347)	Data 0.00129 (0.00238)	Tok/s 67855 (74411)	Loss/tok 3.2923 (3.2151)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][410/6832]	Time 0.181 (0.345)	Data 0.00139 (0.00235)	Tok/s 76869 (74365)	Loss/tok 2.9884 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [3][420/6832]	Time 0.099 (0.346)	Data 0.00157 (0.00233)	Tok/s 57684 (74337)	Loss/tok 2.0552 (3.2158)	Learning Rate [7.8125e-05]
0: TRAIN [3][430/6832]	Time 0.480 (0.347)	Data 0.00121 (0.00231)	Tok/s 86242 (74314)	Loss/tok 3.2670 (3.2170)	Learning Rate [7.8125e-05]
0: TRAIN [3][440/6832]	Time 0.299 (0.347)	Data 0.00126 (0.00228)	Tok/s 70150 (74373)	Loss/tok 3.1736 (3.2178)	Learning Rate [7.8125e-05]
0: TRAIN [3][450/6832]	Time 0.286 (0.347)	Data 0.00115 (0.00226)	Tok/s 72554 (74437)	Loss/tok 3.1725 (3.2169)	Learning Rate [7.8125e-05]
0: TRAIN [3][460/6832]	Time 0.479 (0.348)	Data 0.00125 (0.00224)	Tok/s 70346 (74379)	Loss/tok 3.4016 (3.2183)	Learning Rate [7.8125e-05]
0: TRAIN [3][470/6832]	Time 0.247 (0.349)	Data 0.00126 (0.00222)	Tok/s 74573 (74384)	Loss/tok 3.1356 (3.2192)	Learning Rate [7.8125e-05]
0: TRAIN [3][480/6832]	Time 0.110 (0.348)	Data 0.00135 (0.00220)	Tok/s 76397 (74405)	Loss/tok 2.4315 (3.2184)	Learning Rate [7.8125e-05]
0: TRAIN [3][490/6832]	Time 0.457 (0.349)	Data 0.00105 (0.00218)	Tok/s 72623 (74464)	Loss/tok 3.3427 (3.2193)	Learning Rate [7.8125e-05]
0: TRAIN [3][500/6832]	Time 0.482 (0.350)	Data 0.00154 (0.00242)	Tok/s 67257 (74316)	Loss/tok 3.3471 (3.2204)	Learning Rate [7.8125e-05]
0: TRAIN [3][510/6832]	Time 0.403 (0.350)	Data 0.00126 (0.00240)	Tok/s 68584 (74289)	Loss/tok 3.1834 (3.2206)	Learning Rate [7.8125e-05]
0: TRAIN [3][520/6832]	Time 0.475 (0.350)	Data 0.00145 (0.00237)	Tok/s 72997 (74280)	Loss/tok 3.3675 (3.2207)	Learning Rate [7.8125e-05]
0: TRAIN [3][530/6832]	Time 0.306 (0.351)	Data 0.00105 (0.00235)	Tok/s 70267 (74267)	Loss/tok 3.2499 (3.2217)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][540/6832]	Time 0.418 (0.350)	Data 0.00102 (0.00233)	Tok/s 65309 (74259)	Loss/tok 3.4316 (3.2211)	Learning Rate [7.8125e-05]
0: TRAIN [3][550/6832]	Time 0.231 (0.349)	Data 0.00117 (0.00231)	Tok/s 70813 (74218)	Loss/tok 3.0585 (3.2202)	Learning Rate [7.8125e-05]
0: TRAIN [3][560/6832]	Time 0.244 (0.349)	Data 0.00106 (0.00229)	Tok/s 73372 (74211)	Loss/tok 3.1043 (3.2204)	Learning Rate [7.8125e-05]
0: TRAIN [3][570/6832]	Time 0.465 (0.350)	Data 0.00115 (0.00227)	Tok/s 65730 (74244)	Loss/tok 3.3483 (3.2204)	Learning Rate [7.8125e-05]
0: TRAIN [3][580/6832]	Time 0.399 (0.350)	Data 0.00099 (0.00225)	Tok/s 67430 (74247)	Loss/tok 3.2755 (3.2200)	Learning Rate [7.8125e-05]
0: TRAIN [3][590/6832]	Time 0.134 (0.350)	Data 0.00128 (0.00223)	Tok/s 84479 (74247)	Loss/tok 2.7140 (3.2203)	Learning Rate [7.8125e-05]
0: TRAIN [3][600/6832]	Time 0.478 (0.350)	Data 0.00105 (0.00221)	Tok/s 79119 (74260)	Loss/tok 3.4341 (3.2210)	Learning Rate [7.8125e-05]
0: TRAIN [3][610/6832]	Time 0.320 (0.351)	Data 0.00106 (0.00220)	Tok/s 72066 (74301)	Loss/tok 3.1956 (3.2208)	Learning Rate [7.8125e-05]
0: TRAIN [3][620/6832]	Time 0.476 (0.352)	Data 0.00109 (0.00218)	Tok/s 75581 (74267)	Loss/tok 3.4025 (3.2216)	Learning Rate [7.8125e-05]
0: TRAIN [3][630/6832]	Time 0.834 (0.352)	Data 0.41490 (0.00282)	Tok/s 34987 (74190)	Loss/tok 3.2663 (3.2216)	Learning Rate [7.8125e-05]
0: TRAIN [3][640/6832]	Time 0.285 (0.351)	Data 0.00115 (0.00280)	Tok/s 70927 (74174)	Loss/tok 3.2514 (3.2212)	Learning Rate [7.8125e-05]
0: TRAIN [3][650/6832]	Time 0.464 (0.351)	Data 0.00151 (0.00277)	Tok/s 69718 (74191)	Loss/tok 3.3394 (3.2221)	Learning Rate [7.8125e-05]
0: TRAIN [3][660/6832]	Time 0.239 (0.352)	Data 0.00126 (0.00275)	Tok/s 71565 (74256)	Loss/tok 3.0638 (3.2224)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][670/6832]	Time 0.310 (0.352)	Data 0.00129 (0.00273)	Tok/s 71089 (74251)	Loss/tok 3.2313 (3.2223)	Learning Rate [7.8125e-05]
0: TRAIN [3][680/6832]	Time 0.486 (0.351)	Data 0.00114 (0.00271)	Tok/s 81608 (74275)	Loss/tok 3.3314 (3.2220)	Learning Rate [7.8125e-05]
0: TRAIN [3][690/6832]	Time 0.408 (0.352)	Data 0.00121 (0.00269)	Tok/s 64091 (74333)	Loss/tok 3.3521 (3.2218)	Learning Rate [7.8125e-05]
0: TRAIN [3][700/6832]	Time 0.484 (0.352)	Data 0.00114 (0.00267)	Tok/s 79588 (74331)	Loss/tok 3.4455 (3.2222)	Learning Rate [7.8125e-05]
0: TRAIN [3][710/6832]	Time 0.283 (0.352)	Data 0.00159 (0.00265)	Tok/s 71729 (74369)	Loss/tok 3.1858 (3.2226)	Learning Rate [7.8125e-05]
0: TRAIN [3][720/6832]	Time 0.203 (0.352)	Data 0.00111 (0.00263)	Tok/s 77182 (74345)	Loss/tok 3.0283 (3.2228)	Learning Rate [7.8125e-05]
0: TRAIN [3][730/6832]	Time 0.359 (0.351)	Data 0.00132 (0.00261)	Tok/s 67061 (74356)	Loss/tok 3.3056 (3.2223)	Learning Rate [7.8125e-05]
0: TRAIN [3][740/6832]	Time 0.237 (0.351)	Data 0.00118 (0.00260)	Tok/s 73741 (74371)	Loss/tok 3.0787 (3.2227)	Learning Rate [7.8125e-05]
0: TRAIN [3][750/6832]	Time 0.484 (0.351)	Data 0.00101 (0.00258)	Tok/s 96346 (74322)	Loss/tok 3.1675 (3.2231)	Learning Rate [7.8125e-05]
0: TRAIN [3][760/6832]	Time 0.159 (0.351)	Data 0.00101 (0.00256)	Tok/s 78406 (74308)	Loss/tok 2.8194 (3.2236)	Learning Rate [7.8125e-05]
0: TRAIN [3][770/6832]	Time 0.475 (0.353)	Data 0.00104 (0.00355)	Tok/s 68874 (74279)	Loss/tok 3.3240 (3.2239)	Learning Rate [7.8125e-05]
0: TRAIN [3][780/6832]	Time 0.480 (0.353)	Data 0.00104 (0.00351)	Tok/s 71178 (74293)	Loss/tok 3.4918 (3.2252)	Learning Rate [7.8125e-05]
0: TRAIN [3][790/6832]	Time 0.184 (0.353)	Data 0.00103 (0.00348)	Tok/s 82639 (74337)	Loss/tok 3.0790 (3.2256)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][800/6832]	Time 0.252 (0.353)	Data 0.00101 (0.00345)	Tok/s 72071 (74377)	Loss/tok 3.1448 (3.2257)	Learning Rate [7.8125e-05]
0: TRAIN [3][810/6832]	Time 0.483 (0.352)	Data 0.00105 (0.00343)	Tok/s 77977 (74394)	Loss/tok 3.3144 (3.2254)	Learning Rate [7.8125e-05]
0: TRAIN [3][820/6832]	Time 0.093 (0.352)	Data 0.00102 (0.00340)	Tok/s 61172 (74447)	Loss/tok 2.0695 (3.2255)	Learning Rate [7.8125e-05]
0: TRAIN [3][830/6832]	Time 0.482 (0.352)	Data 0.00109 (0.00337)	Tok/s 82250 (74439)	Loss/tok 3.2215 (3.2260)	Learning Rate [7.8125e-05]
0: TRAIN [3][840/6832]	Time 0.150 (0.353)	Data 0.00103 (0.00334)	Tok/s 80001 (74468)	Loss/tok 2.8638 (3.2261)	Learning Rate [7.8125e-05]
0: TRAIN [3][850/6832]	Time 0.403 (0.352)	Data 0.00101 (0.00332)	Tok/s 67562 (74455)	Loss/tok 3.2118 (3.2256)	Learning Rate [7.8125e-05]
0: TRAIN [3][860/6832]	Time 0.480 (0.353)	Data 0.00105 (0.00329)	Tok/s 77174 (74426)	Loss/tok 3.2729 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][870/6832]	Time 0.364 (0.352)	Data 0.00106 (0.00326)	Tok/s 67894 (74441)	Loss/tok 3.3811 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][880/6832]	Time 0.277 (0.352)	Data 0.00132 (0.00324)	Tok/s 73913 (74422)	Loss/tok 3.1298 (3.2272)	Learning Rate [7.8125e-05]
0: TRAIN [3][890/6832]	Time 0.141 (0.352)	Data 0.00113 (0.00322)	Tok/s 79848 (74455)	Loss/tok 2.7792 (3.2270)	Learning Rate [7.8125e-05]
0: TRAIN [3][900/6832]	Time 0.478 (0.352)	Data 0.00102 (0.00368)	Tok/s 69839 (74383)	Loss/tok 3.4719 (3.2274)	Learning Rate [7.8125e-05]
0: TRAIN [3][910/6832]	Time 0.480 (0.352)	Data 0.00171 (0.00365)	Tok/s 73416 (74401)	Loss/tok 3.2916 (3.2270)	Learning Rate [7.8125e-05]
0: TRAIN [3][920/6832]	Time 0.292 (0.352)	Data 0.00112 (0.00362)	Tok/s 69708 (74378)	Loss/tok 3.1917 (3.2275)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][930/6832]	Time 0.157 (0.351)	Data 0.00104 (0.00360)	Tok/s 82271 (74439)	Loss/tok 2.8516 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][940/6832]	Time 0.196 (0.351)	Data 0.00105 (0.00357)	Tok/s 75306 (74428)	Loss/tok 2.9825 (3.2264)	Learning Rate [7.8125e-05]
0: TRAIN [3][950/6832]	Time 0.225 (0.350)	Data 0.00100 (0.00354)	Tok/s 74386 (74427)	Loss/tok 3.0906 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][960/6832]	Time 0.199 (0.350)	Data 0.00123 (0.00352)	Tok/s 77764 (74441)	Loss/tok 2.9566 (3.2263)	Learning Rate [7.8125e-05]
0: TRAIN [3][970/6832]	Time 0.186 (0.350)	Data 0.00108 (0.00349)	Tok/s 74941 (74466)	Loss/tok 2.9451 (3.2260)	Learning Rate [7.8125e-05]
0: TRAIN [3][980/6832]	Time 0.252 (0.349)	Data 0.00099 (0.00347)	Tok/s 73151 (74459)	Loss/tok 3.2671 (3.2255)	Learning Rate [7.8125e-05]
0: TRAIN [3][990/6832]	Time 0.480 (0.349)	Data 0.00119 (0.00344)	Tok/s 85876 (74489)	Loss/tok 3.2614 (3.2255)	Learning Rate [7.8125e-05]
0: TRAIN [3][1000/6832]	Time 0.212 (0.349)	Data 0.00108 (0.00342)	Tok/s 75705 (74518)	Loss/tok 2.9494 (3.2257)	Learning Rate [7.8125e-05]
0: TRAIN [3][1010/6832]	Time 0.429 (0.349)	Data 0.00108 (0.00340)	Tok/s 65704 (74508)	Loss/tok 3.2317 (3.2253)	Learning Rate [7.8125e-05]
0: TRAIN [3][1020/6832]	Time 0.482 (0.348)	Data 0.00111 (0.00338)	Tok/s 79516 (74507)	Loss/tok 3.3650 (3.2253)	Learning Rate [7.8125e-05]
0: TRAIN [3][1030/6832]	Time 0.482 (0.348)	Data 0.00027 (0.00358)	Tok/s 76904 (74483)	Loss/tok 3.3876 (3.2253)	Learning Rate [7.8125e-05]
0: TRAIN [3][1040/6832]	Time 0.466 (0.348)	Data 0.00108 (0.00356)	Tok/s 78308 (74506)	Loss/tok 3.3424 (3.2258)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1050/6832]	Time 0.447 (0.349)	Data 0.00154 (0.00353)	Tok/s 63969 (74464)	Loss/tok 3.3136 (3.2264)	Learning Rate [7.8125e-05]
0: TRAIN [3][1060/6832]	Time 0.281 (0.349)	Data 0.00100 (0.00351)	Tok/s 72766 (74444)	Loss/tok 3.2146 (3.2268)	Learning Rate [7.8125e-05]
0: TRAIN [3][1070/6832]	Time 0.204 (0.348)	Data 0.00100 (0.00349)	Tok/s 74662 (74433)	Loss/tok 3.0672 (3.2267)	Learning Rate [7.8125e-05]
0: TRAIN [3][1080/6832]	Time 0.156 (0.349)	Data 0.00099 (0.00347)	Tok/s 79911 (74427)	Loss/tok 2.9029 (3.2272)	Learning Rate [7.8125e-05]
0: TRAIN [3][1090/6832]	Time 0.461 (0.349)	Data 0.00103 (0.00344)	Tok/s 84576 (74451)	Loss/tok 3.2560 (3.2272)	Learning Rate [7.8125e-05]
0: TRAIN [3][1100/6832]	Time 0.476 (0.349)	Data 0.00102 (0.00342)	Tok/s 85144 (74459)	Loss/tok 3.2239 (3.2278)	Learning Rate [7.8125e-05]
0: TRAIN [3][1110/6832]	Time 0.123 (0.349)	Data 0.00111 (0.00340)	Tok/s 85941 (74464)	Loss/tok 2.7142 (3.2280)	Learning Rate [7.8125e-05]
0: TRAIN [3][1120/6832]	Time 0.477 (0.349)	Data 0.00100 (0.00338)	Tok/s 69194 (74440)	Loss/tok 3.4440 (3.2282)	Learning Rate [7.8125e-05]
0: TRAIN [3][1130/6832]	Time 0.188 (0.348)	Data 0.00102 (0.00336)	Tok/s 78795 (74457)	Loss/tok 3.0684 (3.2275)	Learning Rate [7.8125e-05]
0: TRAIN [3][1140/6832]	Time 0.456 (0.348)	Data 0.00100 (0.00334)	Tok/s 64255 (74445)	Loss/tok 3.3437 (3.2279)	Learning Rate [7.8125e-05]
0: TRAIN [3][1150/6832]	Time 0.145 (0.349)	Data 0.00101 (0.00332)	Tok/s 76867 (74414)	Loss/tok 2.6692 (3.2286)	Learning Rate [7.8125e-05]
0: TRAIN [3][1160/6832]	Time 0.286 (0.349)	Data 0.00101 (0.00330)	Tok/s 73513 (74430)	Loss/tok 3.1962 (3.2290)	Learning Rate [7.8125e-05]
0: TRAIN [3][1170/6832]	Time 0.469 (0.349)	Data 0.00101 (0.00328)	Tok/s 66002 (74394)	Loss/tok 3.3035 (3.2291)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1180/6832]	Time 0.277 (0.349)	Data 0.00102 (0.00326)	Tok/s 74609 (74443)	Loss/tok 3.1917 (3.2289)	Learning Rate [7.8125e-05]
0: TRAIN [3][1190/6832]	Time 0.482 (0.349)	Data 0.00101 (0.00324)	Tok/s 70882 (74417)	Loss/tok 3.3484 (3.2295)	Learning Rate [7.8125e-05]
0: TRAIN [3][1200/6832]	Time 0.482 (0.349)	Data 0.00098 (0.00323)	Tok/s 77887 (74423)	Loss/tok 3.2735 (3.2293)	Learning Rate [7.8125e-05]
0: TRAIN [3][1210/6832]	Time 0.372 (0.349)	Data 0.00105 (0.00321)	Tok/s 67485 (74386)	Loss/tok 3.3259 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1220/6832]	Time 0.480 (0.349)	Data 0.00109 (0.00319)	Tok/s 86054 (74384)	Loss/tok 3.2549 (3.2297)	Learning Rate [7.8125e-05]
0: TRAIN [3][1230/6832]	Time 0.279 (0.349)	Data 0.00111 (0.00317)	Tok/s 77005 (74363)	Loss/tok 3.1637 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1240/6832]	Time 0.480 (0.349)	Data 0.00102 (0.00316)	Tok/s 72675 (74386)	Loss/tok 3.3966 (3.2291)	Learning Rate [7.8125e-05]
0: TRAIN [3][1250/6832]	Time 0.290 (0.348)	Data 0.00096 (0.00314)	Tok/s 74153 (74381)	Loss/tok 3.1804 (3.2291)	Learning Rate [7.8125e-05]
0: TRAIN [3][1260/6832]	Time 0.199 (0.348)	Data 0.00107 (0.00312)	Tok/s 80098 (74383)	Loss/tok 3.0246 (3.2291)	Learning Rate [7.8125e-05]
0: TRAIN [3][1270/6832]	Time 0.337 (0.349)	Data 0.00100 (0.00311)	Tok/s 69094 (74390)	Loss/tok 3.2150 (3.2298)	Learning Rate [7.8125e-05]
0: TRAIN [3][1280/6832]	Time 0.450 (0.349)	Data 0.00103 (0.00309)	Tok/s 64876 (74399)	Loss/tok 3.3870 (3.2298)	Learning Rate [7.8125e-05]
0: TRAIN [3][1290/6832]	Time 0.240 (0.348)	Data 0.00153 (0.00308)	Tok/s 71578 (74381)	Loss/tok 3.0314 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1300/6832]	Time 0.182 (0.348)	Data 0.00118 (0.00316)	Tok/s 78970 (74361)	Loss/tok 2.9398 (3.2291)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1310/6832]	Time 0.370 (0.348)	Data 0.00095 (0.00314)	Tok/s 69979 (74339)	Loss/tok 3.2696 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [3][1320/6832]	Time 0.456 (0.347)	Data 0.00096 (0.00312)	Tok/s 66202 (74331)	Loss/tok 3.4089 (3.2290)	Learning Rate [7.8125e-05]
0: TRAIN [3][1330/6832]	Time 0.413 (0.347)	Data 0.00099 (0.00311)	Tok/s 70802 (74328)	Loss/tok 3.3271 (3.2290)	Learning Rate [7.8125e-05]
0: TRAIN [3][1340/6832]	Time 0.420 (0.347)	Data 0.00105 (0.00309)	Tok/s 68236 (74301)	Loss/tok 3.3634 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1350/6832]	Time 0.483 (0.347)	Data 0.00102 (0.00308)	Tok/s 91218 (74329)	Loss/tok 3.3170 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1360/6832]	Time 0.285 (0.347)	Data 0.00101 (0.00306)	Tok/s 70819 (74328)	Loss/tok 3.1572 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1370/6832]	Time 0.204 (0.346)	Data 0.00108 (0.00305)	Tok/s 76523 (74338)	Loss/tok 2.9974 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [3][1380/6832]	Time 0.334 (0.347)	Data 0.00102 (0.00303)	Tok/s 73289 (74356)	Loss/tok 3.3367 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1390/6832]	Time 0.465 (0.346)	Data 0.00102 (0.00302)	Tok/s 71278 (74374)	Loss/tok 3.3905 (3.2290)	Learning Rate [7.8125e-05]
0: TRAIN [3][1400/6832]	Time 0.365 (0.346)	Data 0.00104 (0.00301)	Tok/s 68311 (74389)	Loss/tok 3.1998 (3.2290)	Learning Rate [7.8125e-05]
0: TRAIN [3][1410/6832]	Time 0.313 (0.346)	Data 0.00113 (0.00299)	Tok/s 70260 (74368)	Loss/tok 3.1035 (3.2289)	Learning Rate [7.8125e-05]
0: TRAIN [3][1420/6832]	Time 0.482 (0.346)	Data 0.00105 (0.00298)	Tok/s 82236 (74379)	Loss/tok 3.4575 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [3][1430/6832]	Time 0.487 (0.346)	Data 0.00109 (0.00305)	Tok/s 86347 (74365)	Loss/tok 3.2116 (3.2291)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1440/6832]	Time 0.112 (0.346)	Data 0.00119 (0.00303)	Tok/s 76155 (74375)	Loss/tok 2.4476 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1450/6832]	Time 0.324 (0.346)	Data 0.00112 (0.00302)	Tok/s 68665 (74360)	Loss/tok 3.2178 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1460/6832]	Time 0.138 (0.346)	Data 0.00098 (0.00301)	Tok/s 69828 (74367)	Loss/tok 2.5895 (3.2293)	Learning Rate [7.8125e-05]
0: TRAIN [3][1470/6832]	Time 0.419 (0.346)	Data 0.00107 (0.00299)	Tok/s 67273 (74354)	Loss/tok 3.2971 (3.2293)	Learning Rate [7.8125e-05]
0: TRAIN [3][1480/6832]	Time 0.488 (0.346)	Data 0.00105 (0.00298)	Tok/s 75922 (74359)	Loss/tok 3.2895 (3.2295)	Learning Rate [7.8125e-05]
0: TRAIN [3][1490/6832]	Time 0.413 (0.346)	Data 0.00104 (0.00297)	Tok/s 67198 (74386)	Loss/tok 3.3004 (3.2293)	Learning Rate [7.8125e-05]
0: TRAIN [3][1500/6832]	Time 0.482 (0.347)	Data 0.00105 (0.00296)	Tok/s 87220 (74401)	Loss/tok 3.2535 (3.2295)	Learning Rate [7.8125e-05]
0: TRAIN [3][1510/6832]	Time 0.450 (0.347)	Data 0.00105 (0.00294)	Tok/s 69089 (74387)	Loss/tok 3.3459 (3.2298)	Learning Rate [7.8125e-05]
0: TRAIN [3][1520/6832]	Time 0.482 (0.347)	Data 0.00107 (0.00293)	Tok/s 82487 (74392)	Loss/tok 3.2728 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1530/6832]	Time 0.223 (0.347)	Data 0.00112 (0.00292)	Tok/s 74676 (74373)	Loss/tok 3.0576 (3.2297)	Learning Rate [7.8125e-05]
0: TRAIN [3][1540/6832]	Time 0.146 (0.347)	Data 0.00101 (0.00291)	Tok/s 76605 (74391)	Loss/tok 2.7502 (3.2297)	Learning Rate [7.8125e-05]
0: TRAIN [3][1550/6832]	Time 0.345 (0.347)	Data 0.00110 (0.00290)	Tok/s 69787 (74406)	Loss/tok 3.2785 (3.2298)	Learning Rate [7.8125e-05]
0: TRAIN [3][1560/6832]	Time 0.119 (0.348)	Data 0.00113 (0.00291)	Tok/s 70362 (74374)	Loss/tok 2.4587 (3.2300)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1570/6832]	Time 0.483 (0.348)	Data 0.00100 (0.00290)	Tok/s 100752 (74397)	Loss/tok 3.0642 (3.2300)	Learning Rate [7.8125e-05]
0: TRAIN [3][1580/6832]	Time 0.480 (0.348)	Data 0.00104 (0.00289)	Tok/s 71451 (74374)	Loss/tok 3.3400 (3.2304)	Learning Rate [7.8125e-05]
0: TRAIN [3][1590/6832]	Time 0.462 (0.349)	Data 0.00104 (0.00288)	Tok/s 75217 (74409)	Loss/tok 3.3400 (3.2304)	Learning Rate [7.8125e-05]
0: TRAIN [3][1600/6832]	Time 0.258 (0.349)	Data 0.00109 (0.00287)	Tok/s 73510 (74433)	Loss/tok 3.1469 (3.2301)	Learning Rate [7.8125e-05]
0: TRAIN [3][1610/6832]	Time 0.452 (0.348)	Data 0.00101 (0.00286)	Tok/s 70728 (74438)	Loss/tok 3.3633 (3.2300)	Learning Rate [7.8125e-05]
0: TRAIN [3][1620/6832]	Time 0.111 (0.348)	Data 0.00101 (0.00285)	Tok/s 75442 (74421)	Loss/tok 2.3986 (3.2297)	Learning Rate [7.8125e-05]
0: TRAIN [3][1630/6832]	Time 0.235 (0.348)	Data 0.00099 (0.00284)	Tok/s 78556 (74435)	Loss/tok 3.1510 (3.2298)	Learning Rate [7.8125e-05]
0: TRAIN [3][1640/6832]	Time 0.330 (0.349)	Data 0.00099 (0.00282)	Tok/s 70517 (74403)	Loss/tok 3.2347 (3.2300)	Learning Rate [7.8125e-05]
0: TRAIN [3][1650/6832]	Time 0.184 (0.349)	Data 0.00099 (0.00281)	Tok/s 80281 (74419)	Loss/tok 3.0010 (3.2300)	Learning Rate [7.8125e-05]
0: TRAIN [3][1660/6832]	Time 0.196 (0.349)	Data 0.00104 (0.00280)	Tok/s 77243 (74403)	Loss/tok 2.9902 (3.2303)	Learning Rate [7.8125e-05]
0: TRAIN [3][1670/6832]	Time 0.465 (0.349)	Data 0.00099 (0.00279)	Tok/s 90557 (74452)	Loss/tok 3.2529 (3.2301)	Learning Rate [7.8125e-05]
0: TRAIN [3][1680/6832]	Time 0.167 (0.349)	Data 0.00119 (0.00278)	Tok/s 78016 (74459)	Loss/tok 2.9032 (3.2298)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1690/6832]	Time 0.343 (0.349)	Data 0.00033 (0.00297)	Tok/s 71020 (74432)	Loss/tok 3.2060 (3.2299)	Learning Rate [7.8125e-05]
0: TRAIN [3][1700/6832]	Time 0.427 (0.349)	Data 0.00110 (0.00296)	Tok/s 66548 (74414)	Loss/tok 3.2959 (3.2297)	Learning Rate [7.8125e-05]
0: TRAIN [3][1710/6832]	Time 0.455 (0.349)	Data 0.00106 (0.00294)	Tok/s 67150 (74434)	Loss/tok 3.2577 (3.2293)	Learning Rate [7.8125e-05]
0: TRAIN [3][1720/6832]	Time 0.206 (0.349)	Data 0.00109 (0.00293)	Tok/s 75623 (74431)	Loss/tok 3.0889 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1730/6832]	Time 0.146 (0.349)	Data 0.00106 (0.00292)	Tok/s 76443 (74434)	Loss/tok 2.7319 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1740/6832]	Time 0.261 (0.349)	Data 0.00102 (0.00291)	Tok/s 74570 (74426)	Loss/tok 3.1807 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1750/6832]	Time 0.480 (0.349)	Data 0.00101 (0.00290)	Tok/s 101393 (74434)	Loss/tok 3.1192 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1760/6832]	Time 0.477 (0.349)	Data 0.00102 (0.00289)	Tok/s 67996 (74421)	Loss/tok 3.3052 (3.2296)	Learning Rate [7.8125e-05]
0: TRAIN [3][1770/6832]	Time 0.401 (0.349)	Data 0.00098 (0.00288)	Tok/s 68130 (74406)	Loss/tok 3.2065 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [3][1780/6832]	Time 0.376 (0.349)	Data 0.00103 (0.00287)	Tok/s 68510 (74396)	Loss/tok 3.2110 (3.2290)	Learning Rate [7.8125e-05]
0: TRAIN [3][1790/6832]	Time 0.460 (0.349)	Data 0.00099 (0.00286)	Tok/s 84850 (74398)	Loss/tok 3.3369 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [3][1800/6832]	Time 0.216 (0.349)	Data 0.00112 (0.00285)	Tok/s 75847 (74386)	Loss/tok 3.0478 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [3][1810/6832]	Time 0.484 (0.349)	Data 0.00107 (0.00284)	Tok/s 83712 (74409)	Loss/tok 3.2418 (3.2293)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1820/6832]	Time 0.481 (0.349)	Data 0.00171 (0.00305)	Tok/s 87684 (74396)	Loss/tok 3.2964 (3.2292)	Learning Rate [7.8125e-05]
0: TRAIN [3][1830/6832]	Time 0.296 (0.349)	Data 0.00109 (0.00304)	Tok/s 70794 (74381)	Loss/tok 3.2279 (3.2293)	Learning Rate [7.8125e-05]
0: TRAIN [3][1840/6832]	Time 0.413 (0.349)	Data 0.00105 (0.00303)	Tok/s 66987 (74373)	Loss/tok 3.3441 (3.2294)	Learning Rate [7.8125e-05]
0: TRAIN [3][1850/6832]	Time 0.471 (0.349)	Data 0.00108 (0.00302)	Tok/s 70393 (74372)	Loss/tok 3.4562 (3.2291)	Learning Rate [7.8125e-05]
0: TRAIN [3][1860/6832]	Time 0.155 (0.348)	Data 0.00114 (0.00301)	Tok/s 76317 (74392)	Loss/tok 2.7432 (3.2286)	Learning Rate [7.8125e-05]
0: TRAIN [3][1870/6832]	Time 0.288 (0.348)	Data 0.00102 (0.00300)	Tok/s 77710 (74398)	Loss/tok 3.2915 (3.2286)	Learning Rate [7.8125e-05]
0: TRAIN [3][1880/6832]	Time 0.146 (0.348)	Data 0.00100 (0.00299)	Tok/s 76256 (74388)	Loss/tok 2.7509 (3.2285)	Learning Rate [7.8125e-05]
0: TRAIN [3][1890/6832]	Time 0.481 (0.349)	Data 0.00104 (0.00298)	Tok/s 79539 (74407)	Loss/tok 3.2965 (3.2286)	Learning Rate [7.8125e-05]
0: TRAIN [3][1900/6832]	Time 0.475 (0.349)	Data 0.00097 (0.00297)	Tok/s 62062 (74378)	Loss/tok 3.3745 (3.2289)	Learning Rate [7.8125e-05]
0: TRAIN [3][1910/6832]	Time 0.315 (0.349)	Data 0.00112 (0.00296)	Tok/s 70773 (74364)	Loss/tok 3.1301 (3.2288)	Learning Rate [7.8125e-05]
0: TRAIN [3][1920/6832]	Time 0.194 (0.348)	Data 0.00105 (0.00295)	Tok/s 78142 (74358)	Loss/tok 2.9981 (3.2284)	Learning Rate [7.8125e-05]
0: TRAIN [3][1930/6832]	Time 0.231 (0.348)	Data 0.00102 (0.00294)	Tok/s 71009 (74338)	Loss/tok 3.0827 (3.2284)	Learning Rate [7.8125e-05]
0: TRAIN [3][1940/6832]	Time 0.383 (0.348)	Data 0.00097 (0.00293)	Tok/s 68361 (74339)	Loss/tok 3.1990 (3.2282)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][1950/6832]	Time 0.141 (0.348)	Data 0.00134 (0.00292)	Tok/s 79913 (74341)	Loss/tok 2.7131 (3.2281)	Learning Rate [7.8125e-05]
0: TRAIN [3][1960/6832]	Time 0.337 (0.348)	Data 0.00105 (0.00291)	Tok/s 69510 (74342)	Loss/tok 3.1747 (3.2279)	Learning Rate [7.8125e-05]
0: TRAIN [3][1970/6832]	Time 0.375 (0.348)	Data 0.00108 (0.00290)	Tok/s 68113 (74343)	Loss/tok 3.2026 (3.2277)	Learning Rate [7.8125e-05]
0: TRAIN [3][1980/6832]	Time 0.465 (0.348)	Data 0.00101 (0.00289)	Tok/s 77600 (74374)	Loss/tok 3.2481 (3.2271)	Learning Rate [7.8125e-05]
0: TRAIN [3][1990/6832]	Time 0.163 (0.348)	Data 0.00104 (0.00288)	Tok/s 76444 (74374)	Loss/tok 2.7858 (3.2271)	Learning Rate [7.8125e-05]
0: TRAIN [3][2000/6832]	Time 0.405 (0.348)	Data 0.00103 (0.00287)	Tok/s 66660 (74361)	Loss/tok 3.2771 (3.2271)	Learning Rate [7.8125e-05]
0: TRAIN [3][2010/6832]	Time 0.144 (0.348)	Data 0.00099 (0.00286)	Tok/s 77242 (74378)	Loss/tok 2.6936 (3.2269)	Learning Rate [7.8125e-05]
0: TRAIN [3][2020/6832]	Time 0.468 (0.347)	Data 0.00101 (0.00285)	Tok/s 63442 (74362)	Loss/tok 3.3456 (3.2266)	Learning Rate [7.8125e-05]
0: TRAIN [3][2030/6832]	Time 0.405 (0.348)	Data 0.00104 (0.00285)	Tok/s 65792 (74353)	Loss/tok 3.3374 (3.2269)	Learning Rate [7.8125e-05]
0: TRAIN [3][2040/6832]	Time 0.206 (0.347)	Data 0.00102 (0.00284)	Tok/s 74043 (74364)	Loss/tok 3.0382 (3.2267)	Learning Rate [7.8125e-05]
0: TRAIN [3][2050/6832]	Time 0.200 (0.347)	Data 0.00106 (0.00283)	Tok/s 76362 (74363)	Loss/tok 2.9690 (3.2267)	Learning Rate [7.8125e-05]
0: TRAIN [3][2060/6832]	Time 0.396 (0.347)	Data 0.00111 (0.00282)	Tok/s 68457 (74367)	Loss/tok 3.3104 (3.2268)	Learning Rate [7.8125e-05]
0: TRAIN [3][2070/6832]	Time 0.338 (0.347)	Data 0.00102 (0.00281)	Tok/s 67231 (74358)	Loss/tok 3.2854 (3.2268)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2080/6832]	Time 0.274 (0.347)	Data 0.00102 (0.00280)	Tok/s 70052 (74343)	Loss/tok 3.1888 (3.2267)	Learning Rate [7.8125e-05]
0: TRAIN [3][2090/6832]	Time 0.481 (0.347)	Data 0.00105 (0.00279)	Tok/s 101314 (74351)	Loss/tok 3.1000 (3.2266)	Learning Rate [7.8125e-05]
0: TRAIN [3][2100/6832]	Time 0.410 (0.347)	Data 0.00101 (0.00279)	Tok/s 67467 (74334)	Loss/tok 3.3442 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][2110/6832]	Time 0.255 (0.348)	Data 0.00102 (0.00278)	Tok/s 71688 (74325)	Loss/tok 3.0786 (3.2269)	Learning Rate [7.8125e-05]
0: TRAIN [3][2120/6832]	Time 0.399 (0.348)	Data 0.00107 (0.00277)	Tok/s 69535 (74303)	Loss/tok 3.3310 (3.2268)	Learning Rate [7.8125e-05]
0: TRAIN [3][2130/6832]	Time 0.277 (0.348)	Data 0.00100 (0.00276)	Tok/s 72138 (74296)	Loss/tok 3.1516 (3.2266)	Learning Rate [7.8125e-05]
0: TRAIN [3][2140/6832]	Time 0.458 (0.347)	Data 0.00103 (0.00275)	Tok/s 76954 (74292)	Loss/tok 3.3395 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][2150/6832]	Time 0.406 (0.348)	Data 0.00103 (0.00275)	Tok/s 70249 (74282)	Loss/tok 3.2806 (3.2267)	Learning Rate [7.8125e-05]
0: TRAIN [3][2160/6832]	Time 0.478 (0.347)	Data 0.00115 (0.00274)	Tok/s 75565 (74275)	Loss/tok 3.3558 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][2170/6832]	Time 0.486 (0.348)	Data 0.00110 (0.00273)	Tok/s 80617 (74281)	Loss/tok 3.3459 (3.2266)	Learning Rate [7.8125e-05]
0: TRAIN [3][2180/6832]	Time 0.257 (0.347)	Data 0.00107 (0.00272)	Tok/s 74837 (74286)	Loss/tok 3.0839 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][2190/6832]	Time 0.347 (0.347)	Data 0.00103 (0.00272)	Tok/s 69317 (74282)	Loss/tok 3.1835 (3.2263)	Learning Rate [7.8125e-05]
0: TRAIN [3][2200/6832]	Time 0.183 (0.347)	Data 0.00108 (0.00271)	Tok/s 78489 (74292)	Loss/tok 2.9845 (3.2263)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2210/6832]	Time 0.445 (0.348)	Data 0.00104 (0.00270)	Tok/s 65185 (74283)	Loss/tok 3.2692 (3.2264)	Learning Rate [7.8125e-05]
0: TRAIN [3][2220/6832]	Time 0.277 (0.347)	Data 0.00101 (0.00269)	Tok/s 69396 (74281)	Loss/tok 3.0838 (3.2262)	Learning Rate [7.8125e-05]
0: TRAIN [3][2230/6832]	Time 0.434 (0.348)	Data 0.00108 (0.00269)	Tok/s 69261 (74268)	Loss/tok 3.3431 (3.2265)	Learning Rate [7.8125e-05]
0: TRAIN [3][2240/6832]	Time 0.135 (0.348)	Data 0.00104 (0.00268)	Tok/s 77943 (74267)	Loss/tok 2.6819 (3.2266)	Learning Rate [7.8125e-05]
0: TRAIN [3][2250/6832]	Time 0.456 (0.348)	Data 0.00101 (0.00267)	Tok/s 70718 (74282)	Loss/tok 3.3969 (3.2266)	Learning Rate [7.8125e-05]
0: TRAIN [3][2260/6832]	Time 0.299 (0.347)	Data 0.00103 (0.00266)	Tok/s 73596 (74269)	Loss/tok 3.1404 (3.2263)	Learning Rate [7.8125e-05]
0: TRAIN [3][2270/6832]	Time 0.130 (0.347)	Data 0.00110 (0.00266)	Tok/s 81437 (74280)	Loss/tok 2.7519 (3.2259)	Learning Rate [7.8125e-05]
0: TRAIN [3][2280/6832]	Time 0.185 (0.347)	Data 0.00102 (0.00265)	Tok/s 77632 (74273)	Loss/tok 2.9232 (3.2261)	Learning Rate [7.8125e-05]
0: TRAIN [3][2290/6832]	Time 0.321 (0.347)	Data 0.00100 (0.00264)	Tok/s 70678 (74267)	Loss/tok 3.2162 (3.2261)	Learning Rate [7.8125e-05]
0: TRAIN [3][2300/6832]	Time 0.477 (0.348)	Data 0.00106 (0.00264)	Tok/s 67223 (74297)	Loss/tok 3.3099 (3.2258)	Learning Rate [7.8125e-05]
0: TRAIN [3][2310/6832]	Time 0.227 (0.347)	Data 0.00117 (0.00263)	Tok/s 75292 (74283)	Loss/tok 3.0687 (3.2257)	Learning Rate [7.8125e-05]
0: TRAIN [3][2320/6832]	Time 0.472 (0.347)	Data 0.00103 (0.00262)	Tok/s 72556 (74289)	Loss/tok 3.2763 (3.2256)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2330/6832]	Time 0.266 (0.347)	Data 0.00120 (0.00262)	Tok/s 73292 (74297)	Loss/tok 3.0621 (3.2255)	Learning Rate [7.8125e-05]
0: TRAIN [3][2340/6832]	Time 0.191 (0.347)	Data 0.00103 (0.00261)	Tok/s 77747 (74312)	Loss/tok 3.0187 (3.2254)	Learning Rate [7.8125e-05]
0: TRAIN [3][2350/6832]	Time 0.453 (0.347)	Data 0.00108 (0.00260)	Tok/s 64999 (74312)	Loss/tok 3.3053 (3.2253)	Learning Rate [7.8125e-05]
0: TRAIN [3][2360/6832]	Time 0.352 (0.347)	Data 0.00113 (0.00260)	Tok/s 68321 (74299)	Loss/tok 3.2451 (3.2253)	Learning Rate [7.8125e-05]
0: TRAIN [3][2370/6832]	Time 0.246 (0.347)	Data 0.00111 (0.00259)	Tok/s 72539 (74299)	Loss/tok 3.0565 (3.2251)	Learning Rate [7.8125e-05]
0: TRAIN [3][2380/6832]	Time 0.354 (0.347)	Data 0.00103 (0.00259)	Tok/s 66321 (74314)	Loss/tok 3.1939 (3.2248)	Learning Rate [7.8125e-05]
0: TRAIN [3][2390/6832]	Time 0.109 (0.347)	Data 0.00105 (0.00258)	Tok/s 75863 (74309)	Loss/tok 2.3635 (3.2247)	Learning Rate [7.8125e-05]
0: TRAIN [3][2400/6832]	Time 0.147 (0.347)	Data 0.00106 (0.00257)	Tok/s 80993 (74316)	Loss/tok 2.7832 (3.2245)	Learning Rate [7.8125e-05]
0: TRAIN [3][2410/6832]	Time 0.311 (0.347)	Data 0.00105 (0.00257)	Tok/s 70787 (74306)	Loss/tok 3.0693 (3.2244)	Learning Rate [7.8125e-05]
0: TRAIN [3][2420/6832]	Time 0.379 (0.347)	Data 0.00104 (0.00256)	Tok/s 70237 (74308)	Loss/tok 3.1841 (3.2244)	Learning Rate [7.8125e-05]
0: TRAIN [3][2430/6832]	Time 0.381 (0.347)	Data 0.00108 (0.00255)	Tok/s 69449 (74291)	Loss/tok 3.2423 (3.2247)	Learning Rate [7.8125e-05]
0: TRAIN [3][2440/6832]	Time 0.391 (0.347)	Data 0.00103 (0.00255)	Tok/s 66074 (74291)	Loss/tok 3.2833 (3.2245)	Learning Rate [7.8125e-05]
0: TRAIN [3][2450/6832]	Time 0.327 (0.347)	Data 0.00107 (0.00254)	Tok/s 70372 (74286)	Loss/tok 3.2015 (3.2243)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2460/6832]	Time 0.448 (0.347)	Data 0.00107 (0.00254)	Tok/s 64448 (74294)	Loss/tok 3.2354 (3.2242)	Learning Rate [7.8125e-05]
0: TRAIN [3][2470/6832]	Time 0.394 (0.347)	Data 0.00104 (0.00253)	Tok/s 68847 (74300)	Loss/tok 3.2348 (3.2243)	Learning Rate [7.8125e-05]
0: TRAIN [3][2480/6832]	Time 0.474 (0.347)	Data 0.00115 (0.00253)	Tok/s 66284 (74297)	Loss/tok 3.3000 (3.2243)	Learning Rate [7.8125e-05]
0: TRAIN [3][2490/6832]	Time 0.475 (0.348)	Data 0.00106 (0.00252)	Tok/s 67994 (74296)	Loss/tok 3.4128 (3.2246)	Learning Rate [7.8125e-05]
0: TRAIN [3][2500/6832]	Time 0.485 (0.348)	Data 0.00103 (0.00251)	Tok/s 88836 (74296)	Loss/tok 3.2397 (3.2246)	Learning Rate [7.8125e-05]
0: TRAIN [3][2510/6832]	Time 0.483 (0.348)	Data 0.00114 (0.00251)	Tok/s 91641 (74293)	Loss/tok 3.1980 (3.2247)	Learning Rate [7.8125e-05]
0: TRAIN [3][2520/6832]	Time 0.264 (0.347)	Data 0.00103 (0.00250)	Tok/s 74054 (74286)	Loss/tok 3.0224 (3.2244)	Learning Rate [7.8125e-05]
0: TRAIN [3][2530/6832]	Time 0.486 (0.347)	Data 0.00106 (0.00250)	Tok/s 77617 (74291)	Loss/tok 3.2839 (3.2243)	Learning Rate [7.8125e-05]
0: TRAIN [3][2540/6832]	Time 0.480 (0.348)	Data 0.00110 (0.00249)	Tok/s 81539 (74324)	Loss/tok 3.2818 (3.2241)	Learning Rate [7.8125e-05]
0: TRAIN [3][2550/6832]	Time 0.467 (0.348)	Data 0.00108 (0.00249)	Tok/s 64664 (74305)	Loss/tok 3.3443 (3.2242)	Learning Rate [7.8125e-05]
0: TRAIN [3][2560/6832]	Time 0.480 (0.348)	Data 0.00113 (0.00248)	Tok/s 94134 (74314)	Loss/tok 3.2102 (3.2241)	Learning Rate [7.8125e-05]
0: TRAIN [3][2570/6832]	Time 0.270 (0.348)	Data 0.00105 (0.00248)	Tok/s 70781 (74309)	Loss/tok 3.1434 (3.2238)	Learning Rate [7.8125e-05]
0: TRAIN [3][2580/6832]	Time 0.423 (0.348)	Data 0.00105 (0.00247)	Tok/s 67218 (74299)	Loss/tok 3.3027 (3.2240)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2590/6832]	Time 0.488 (0.348)	Data 0.00106 (0.00247)	Tok/s 84931 (74292)	Loss/tok 3.2616 (3.2239)	Learning Rate [7.8125e-05]
0: TRAIN [3][2600/6832]	Time 0.307 (0.347)	Data 0.00104 (0.00246)	Tok/s 70588 (74292)	Loss/tok 3.1975 (3.2237)	Learning Rate [7.8125e-05]
0: TRAIN [3][2610/6832]	Time 0.433 (0.347)	Data 0.00148 (0.00246)	Tok/s 66047 (74274)	Loss/tok 3.3109 (3.2236)	Learning Rate [7.8125e-05]
0: TRAIN [3][2620/6832]	Time 0.223 (0.347)	Data 0.00103 (0.00245)	Tok/s 74535 (74284)	Loss/tok 2.9637 (3.2233)	Learning Rate [7.8125e-05]
0: TRAIN [3][2630/6832]	Time 0.407 (0.347)	Data 0.00102 (0.00245)	Tok/s 67984 (74276)	Loss/tok 3.2745 (3.2231)	Learning Rate [7.8125e-05]
0: TRAIN [3][2640/6832]	Time 0.483 (0.347)	Data 0.00106 (0.00244)	Tok/s 83535 (74292)	Loss/tok 3.2805 (3.2230)	Learning Rate [7.8125e-05]
0: TRAIN [3][2650/6832]	Time 0.487 (0.347)	Data 0.00104 (0.00244)	Tok/s 73962 (74305)	Loss/tok 3.2782 (3.2231)	Learning Rate [7.8125e-05]
0: TRAIN [3][2660/6832]	Time 0.483 (0.347)	Data 0.00108 (0.00243)	Tok/s 80839 (74306)	Loss/tok 3.2525 (3.2231)	Learning Rate [7.8125e-05]
0: TRAIN [3][2670/6832]	Time 0.255 (0.347)	Data 0.00106 (0.00243)	Tok/s 74403 (74294)	Loss/tok 3.1326 (3.2232)	Learning Rate [7.8125e-05]
0: TRAIN [3][2680/6832]	Time 0.404 (0.347)	Data 0.00107 (0.00242)	Tok/s 65978 (74298)	Loss/tok 3.2701 (3.2230)	Learning Rate [7.8125e-05]
0: TRAIN [3][2690/6832]	Time 0.355 (0.347)	Data 0.00105 (0.00242)	Tok/s 71109 (74299)	Loss/tok 3.1802 (3.2226)	Learning Rate [7.8125e-05]
0: TRAIN [3][2700/6832]	Time 0.469 (0.347)	Data 0.00102 (0.00241)	Tok/s 70956 (74297)	Loss/tok 3.2603 (3.2226)	Learning Rate [7.8125e-05]
0: TRAIN [3][2710/6832]	Time 0.295 (0.347)	Data 0.00101 (0.00241)	Tok/s 73038 (74304)	Loss/tok 3.1564 (3.2224)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2720/6832]	Time 0.403 (0.347)	Data 0.00102 (0.00240)	Tok/s 69913 (74304)	Loss/tok 3.2881 (3.2222)	Learning Rate [7.8125e-05]
0: TRAIN [3][2730/6832]	Time 0.229 (0.347)	Data 0.00101 (0.00240)	Tok/s 74998 (74297)	Loss/tok 3.0350 (3.2220)	Learning Rate [7.8125e-05]
0: TRAIN [3][2740/6832]	Time 0.408 (0.347)	Data 0.00096 (0.00239)	Tok/s 65989 (74290)	Loss/tok 3.2951 (3.2220)	Learning Rate [7.8125e-05]
0: TRAIN [3][2750/6832]	Time 0.381 (0.347)	Data 0.00104 (0.00239)	Tok/s 69859 (74292)	Loss/tok 3.2974 (3.2219)	Learning Rate [7.8125e-05]
0: TRAIN [3][2760/6832]	Time 0.474 (0.347)	Data 0.00104 (0.00238)	Tok/s 70107 (74286)	Loss/tok 3.3339 (3.2218)	Learning Rate [7.8125e-05]
0: TRAIN [3][2770/6832]	Time 0.482 (0.347)	Data 0.00105 (0.00238)	Tok/s 75443 (74280)	Loss/tok 3.3841 (3.2219)	Learning Rate [7.8125e-05]
0: TRAIN [3][2780/6832]	Time 0.171 (0.347)	Data 0.00101 (0.00237)	Tok/s 78550 (74277)	Loss/tok 2.9568 (3.2220)	Learning Rate [7.8125e-05]
0: TRAIN [3][2790/6832]	Time 0.369 (0.347)	Data 0.00097 (0.00237)	Tok/s 69801 (74273)	Loss/tok 3.1905 (3.2217)	Learning Rate [7.8125e-05]
0: TRAIN [3][2800/6832]	Time 0.416 (0.347)	Data 0.00099 (0.00236)	Tok/s 69424 (74278)	Loss/tok 3.2341 (3.2216)	Learning Rate [7.8125e-05]
0: TRAIN [3][2810/6832]	Time 0.488 (0.347)	Data 0.00101 (0.00236)	Tok/s 90431 (74292)	Loss/tok 3.2317 (3.2213)	Learning Rate [7.8125e-05]
0: TRAIN [3][2820/6832]	Time 0.180 (0.347)	Data 0.00103 (0.00236)	Tok/s 79945 (74279)	Loss/tok 2.8962 (3.2213)	Learning Rate [7.8125e-05]
0: TRAIN [3][2830/6832]	Time 0.482 (0.347)	Data 0.00116 (0.00235)	Tok/s 87256 (74281)	Loss/tok 3.2425 (3.2213)	Learning Rate [7.8125e-05]
0: TRAIN [3][2840/6832]	Time 0.398 (0.347)	Data 0.00101 (0.00235)	Tok/s 65730 (74283)	Loss/tok 3.2726 (3.2209)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2850/6832]	Time 0.365 (0.347)	Data 0.00104 (0.00234)	Tok/s 67853 (74275)	Loss/tok 3.2642 (3.2209)	Learning Rate [7.8125e-05]
0: TRAIN [3][2860/6832]	Time 0.341 (0.347)	Data 0.00097 (0.00234)	Tok/s 70550 (74281)	Loss/tok 3.3433 (3.2207)	Learning Rate [7.8125e-05]
0: TRAIN [3][2870/6832]	Time 0.464 (0.347)	Data 0.00107 (0.00233)	Tok/s 62855 (74268)	Loss/tok 3.1987 (3.2206)	Learning Rate [7.8125e-05]
0: TRAIN [3][2880/6832]	Time 0.315 (0.347)	Data 0.00099 (0.00233)	Tok/s 69995 (74257)	Loss/tok 3.2616 (3.2206)	Learning Rate [7.8125e-05]
0: TRAIN [3][2890/6832]	Time 0.220 (0.347)	Data 0.00120 (0.00232)	Tok/s 72868 (74252)	Loss/tok 3.0242 (3.2205)	Learning Rate [7.8125e-05]
0: TRAIN [3][2900/6832]	Time 0.109 (0.347)	Data 0.00109 (0.00232)	Tok/s 77164 (74238)	Loss/tok 2.4242 (3.2204)	Learning Rate [7.8125e-05]
0: TRAIN [3][2910/6832]	Time 0.415 (0.347)	Data 0.00106 (0.00232)	Tok/s 65903 (74239)	Loss/tok 3.2370 (3.2205)	Learning Rate [7.8125e-05]
0: TRAIN [3][2920/6832]	Time 0.388 (0.347)	Data 0.00103 (0.00231)	Tok/s 67390 (74228)	Loss/tok 3.1283 (3.2204)	Learning Rate [7.8125e-05]
0: TRAIN [3][2930/6832]	Time 0.463 (0.347)	Data 0.00103 (0.00231)	Tok/s 72676 (74227)	Loss/tok 3.2763 (3.2205)	Learning Rate [7.8125e-05]
0: TRAIN [3][2940/6832]	Time 0.484 (0.347)	Data 0.00123 (0.00230)	Tok/s 82414 (74248)	Loss/tok 3.2264 (3.2202)	Learning Rate [7.8125e-05]
0: TRAIN [3][2950/6832]	Time 0.481 (0.347)	Data 0.00102 (0.00230)	Tok/s 77269 (74249)	Loss/tok 3.2644 (3.2198)	Learning Rate [7.8125e-05]
0: TRAIN [3][2960/6832]	Time 0.467 (0.347)	Data 0.00103 (0.00230)	Tok/s 75654 (74257)	Loss/tok 3.3704 (3.2198)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][2970/6832]	Time 0.436 (0.347)	Data 0.00121 (0.00229)	Tok/s 65811 (74258)	Loss/tok 3.3211 (3.2198)	Learning Rate [7.8125e-05]
0: TRAIN [3][2980/6832]	Time 0.468 (0.347)	Data 0.00103 (0.00229)	Tok/s 67716 (74257)	Loss/tok 3.2601 (3.2197)	Learning Rate [7.8125e-05]
0: TRAIN [3][2990/6832]	Time 0.270 (0.347)	Data 0.00099 (0.00228)	Tok/s 72571 (74252)	Loss/tok 3.0991 (3.2194)	Learning Rate [7.8125e-05]
0: TRAIN [3][3000/6832]	Time 0.463 (0.347)	Data 0.00102 (0.00228)	Tok/s 67144 (74244)	Loss/tok 3.2659 (3.2193)	Learning Rate [7.8125e-05]
0: TRAIN [3][3010/6832]	Time 0.236 (0.346)	Data 0.00103 (0.00228)	Tok/s 73695 (74240)	Loss/tok 3.0579 (3.2191)	Learning Rate [7.8125e-05]
0: TRAIN [3][3020/6832]	Time 0.218 (0.346)	Data 0.00107 (0.00227)	Tok/s 73060 (74268)	Loss/tok 2.9531 (3.2188)	Learning Rate [7.8125e-05]
0: TRAIN [3][3030/6832]	Time 0.420 (0.347)	Data 0.00103 (0.00227)	Tok/s 67909 (74274)	Loss/tok 3.2411 (3.2187)	Learning Rate [7.8125e-05]
0: TRAIN [3][3040/6832]	Time 0.341 (0.346)	Data 0.00106 (0.00226)	Tok/s 70507 (74271)	Loss/tok 3.1259 (3.2186)	Learning Rate [7.8125e-05]
0: TRAIN [3][3050/6832]	Time 0.263 (0.346)	Data 0.00108 (0.00226)	Tok/s 74416 (74278)	Loss/tok 3.1275 (3.2184)	Learning Rate [7.8125e-05]
0: TRAIN [3][3060/6832]	Time 0.419 (0.346)	Data 0.00107 (0.00226)	Tok/s 66817 (74283)	Loss/tok 3.2283 (3.2182)	Learning Rate [7.8125e-05]
0: TRAIN [3][3070/6832]	Time 0.479 (0.347)	Data 0.00101 (0.00225)	Tok/s 70586 (74296)	Loss/tok 3.2725 (3.2182)	Learning Rate [7.8125e-05]
0: TRAIN [3][3080/6832]	Time 0.295 (0.347)	Data 0.00103 (0.00225)	Tok/s 72387 (74297)	Loss/tok 3.1168 (3.2184)	Learning Rate [7.8125e-05]
0: TRAIN [3][3090/6832]	Time 0.478 (0.347)	Data 0.00115 (0.00225)	Tok/s 71620 (74299)	Loss/tok 3.2409 (3.2182)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][3100/6832]	Time 0.474 (0.347)	Data 0.00107 (0.00224)	Tok/s 72093 (74297)	Loss/tok 3.2904 (3.2181)	Learning Rate [7.8125e-05]
0: TRAIN [3][3110/6832]	Time 0.482 (0.347)	Data 0.00117 (0.00224)	Tok/s 77001 (74291)	Loss/tok 3.3172 (3.2182)	Learning Rate [7.8125e-05]
0: TRAIN [3][3120/6832]	Time 0.471 (0.347)	Data 0.00107 (0.00223)	Tok/s 65855 (74280)	Loss/tok 3.3400 (3.2181)	Learning Rate [7.8125e-05]
0: TRAIN [3][3130/6832]	Time 0.469 (0.347)	Data 0.00103 (0.00223)	Tok/s 69840 (74277)	Loss/tok 3.2566 (3.2181)	Learning Rate [7.8125e-05]
0: TRAIN [3][3140/6832]	Time 0.463 (0.347)	Data 0.00100 (0.00223)	Tok/s 84502 (74282)	Loss/tok 3.2471 (3.2180)	Learning Rate [7.8125e-05]
0: TRAIN [3][3150/6832]	Time 0.301 (0.347)	Data 0.00105 (0.00222)	Tok/s 69709 (74285)	Loss/tok 3.2057 (3.2178)	Learning Rate [7.8125e-05]
0: TRAIN [3][3160/6832]	Time 0.457 (0.346)	Data 0.00105 (0.00222)	Tok/s 66548 (74280)	Loss/tok 3.2482 (3.2176)	Learning Rate [7.8125e-05]
0: TRAIN [3][3170/6832]	Time 0.482 (0.346)	Data 0.00102 (0.00222)	Tok/s 87623 (74287)	Loss/tok 3.2513 (3.2174)	Learning Rate [7.8125e-05]
0: TRAIN [3][3180/6832]	Time 0.475 (0.346)	Data 0.00106 (0.00221)	Tok/s 75513 (74283)	Loss/tok 3.3096 (3.2175)	Learning Rate [7.8125e-05]
0: TRAIN [3][3190/6832]	Time 0.468 (0.347)	Data 0.00127 (0.00221)	Tok/s 81910 (74285)	Loss/tok 3.2955 (3.2176)	Learning Rate [7.8125e-05]
0: TRAIN [3][3200/6832]	Time 0.379 (0.347)	Data 0.00098 (0.00221)	Tok/s 66231 (74278)	Loss/tok 3.2854 (3.2174)	Learning Rate [7.8125e-05]
0: TRAIN [3][3210/6832]	Time 0.486 (0.346)	Data 0.00110 (0.00220)	Tok/s 95700 (74290)	Loss/tok 3.1174 (3.2172)	Learning Rate [7.8125e-05]
0: TRAIN [3][3220/6832]	Time 0.364 (0.346)	Data 0.00104 (0.00220)	Tok/s 71827 (74297)	Loss/tok 3.2563 (3.2169)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][3230/6832]	Time 0.459 (0.346)	Data 0.00106 (0.00220)	Tok/s 96191 (74314)	Loss/tok 3.1632 (3.2167)	Learning Rate [7.8125e-05]
0: TRAIN [3][3240/6832]	Time 0.353 (0.347)	Data 0.00108 (0.00219)	Tok/s 69533 (74318)	Loss/tok 3.1812 (3.2166)	Learning Rate [7.8125e-05]
0: TRAIN [3][3250/6832]	Time 0.271 (0.346)	Data 0.00104 (0.00219)	Tok/s 71795 (74311)	Loss/tok 2.9590 (3.2165)	Learning Rate [7.8125e-05]
0: TRAIN [3][3260/6832]	Time 0.208 (0.347)	Data 0.00101 (0.00219)	Tok/s 74471 (74319)	Loss/tok 2.9320 (3.2164)	Learning Rate [7.8125e-05]
0: TRAIN [3][3270/6832]	Time 0.452 (0.347)	Data 0.00160 (0.00218)	Tok/s 65550 (74308)	Loss/tok 3.2369 (3.2164)	Learning Rate [7.8125e-05]
0: TRAIN [3][3280/6832]	Time 0.333 (0.346)	Data 0.00104 (0.00218)	Tok/s 72316 (74309)	Loss/tok 3.1939 (3.2161)	Learning Rate [7.8125e-05]
0: TRAIN [3][3290/6832]	Time 0.175 (0.346)	Data 0.00106 (0.00218)	Tok/s 79129 (74308)	Loss/tok 2.8673 (3.2161)	Learning Rate [7.8125e-05]
0: TRAIN [3][3300/6832]	Time 0.134 (0.346)	Data 0.00103 (0.00217)	Tok/s 78446 (74308)	Loss/tok 2.6283 (3.2159)	Learning Rate [7.8125e-05]
0: TRAIN [3][3310/6832]	Time 0.478 (0.346)	Data 0.00105 (0.00217)	Tok/s 67707 (74310)	Loss/tok 3.2294 (3.2160)	Learning Rate [7.8125e-05]
0: TRAIN [3][3320/6832]	Time 0.344 (0.347)	Data 0.00107 (0.00217)	Tok/s 68419 (74305)	Loss/tok 3.1618 (3.2160)	Learning Rate [7.8125e-05]
0: TRAIN [3][3330/6832]	Time 0.201 (0.346)	Data 0.00107 (0.00216)	Tok/s 75050 (74304)	Loss/tok 3.0555 (3.2158)	Learning Rate [7.8125e-05]
0: TRAIN [3][3340/6832]	Time 0.218 (0.346)	Data 0.00102 (0.00216)	Tok/s 75026 (74314)	Loss/tok 2.9969 (3.2157)	Learning Rate [7.8125e-05]
0: TRAIN [3][3350/6832]	Time 0.194 (0.346)	Data 0.00101 (0.00216)	Tok/s 76429 (74307)	Loss/tok 2.9150 (3.2155)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][3360/6832]	Time 0.277 (0.346)	Data 0.00097 (0.00215)	Tok/s 72004 (74302)	Loss/tok 3.1238 (3.2153)	Learning Rate [7.8125e-05]
0: TRAIN [3][3370/6832]	Time 0.376 (0.346)	Data 0.00101 (0.00215)	Tok/s 69065 (74296)	Loss/tok 3.3171 (3.2152)	Learning Rate [7.8125e-05]
0: TRAIN [3][3380/6832]	Time 0.309 (0.346)	Data 0.00104 (0.00215)	Tok/s 72410 (74286)	Loss/tok 3.1122 (3.2154)	Learning Rate [7.8125e-05]
0: TRAIN [3][3390/6832]	Time 0.480 (0.346)	Data 0.00097 (0.00214)	Tok/s 72823 (74274)	Loss/tok 3.2722 (3.2151)	Learning Rate [7.8125e-05]
0: TRAIN [3][3400/6832]	Time 0.274 (0.346)	Data 0.00100 (0.00214)	Tok/s 72692 (74271)	Loss/tok 3.1442 (3.2150)	Learning Rate [7.8125e-05]
0: TRAIN [3][3410/6832]	Time 0.460 (0.346)	Data 0.00104 (0.00214)	Tok/s 68453 (74274)	Loss/tok 3.3741 (3.2149)	Learning Rate [7.8125e-05]
0: TRAIN [3][3420/6832]	Time 0.244 (0.346)	Data 0.00101 (0.00214)	Tok/s 73342 (74281)	Loss/tok 2.9910 (3.2145)	Learning Rate [7.8125e-05]
0: TRAIN [3][3430/6832]	Time 0.101 (0.346)	Data 0.00101 (0.00213)	Tok/s 56852 (74280)	Loss/tok 2.1372 (3.2144)	Learning Rate [7.8125e-05]
0: TRAIN [3][3440/6832]	Time 0.256 (0.346)	Data 0.00101 (0.00213)	Tok/s 73953 (74281)	Loss/tok 3.0976 (3.2143)	Learning Rate [7.8125e-05]
0: TRAIN [3][3450/6832]	Time 0.201 (0.346)	Data 0.00103 (0.00213)	Tok/s 75767 (74290)	Loss/tok 3.0502 (3.2141)	Learning Rate [7.8125e-05]
0: TRAIN [3][3460/6832]	Time 0.309 (0.346)	Data 0.00123 (0.00212)	Tok/s 69732 (74287)	Loss/tok 3.0882 (3.2140)	Learning Rate [7.8125e-05]
0: TRAIN [3][3470/6832]	Time 0.354 (0.346)	Data 0.00100 (0.00212)	Tok/s 67893 (74290)	Loss/tok 3.2271 (3.2139)	Learning Rate [7.8125e-05]
0: TRAIN [3][3480/6832]	Time 0.465 (0.346)	Data 0.00112 (0.00212)	Tok/s 73096 (74287)	Loss/tok 3.2213 (3.2139)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][3490/6832]	Time 0.411 (0.346)	Data 0.00103 (0.00211)	Tok/s 69096 (74277)	Loss/tok 3.2860 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [3][3500/6832]	Time 0.481 (0.346)	Data 0.00098 (0.00211)	Tok/s 78393 (74278)	Loss/tok 3.2625 (3.2137)	Learning Rate [7.8125e-05]
0: TRAIN [3][3510/6832]	Time 0.095 (0.346)	Data 0.00107 (0.00211)	Tok/s 62441 (74276)	Loss/tok 2.1114 (3.2134)	Learning Rate [7.8125e-05]
0: TRAIN [3][3520/6832]	Time 0.263 (0.346)	Data 0.00101 (0.00211)	Tok/s 74526 (74267)	Loss/tok 2.9808 (3.2132)	Learning Rate [7.8125e-05]
0: TRAIN [3][3530/6832]	Time 0.459 (0.346)	Data 0.00102 (0.00210)	Tok/s 66930 (74266)	Loss/tok 3.2287 (3.2131)	Learning Rate [7.8125e-05]
0: TRAIN [3][3540/6832]	Time 0.472 (0.346)	Data 0.00104 (0.00210)	Tok/s 64755 (74266)	Loss/tok 3.2622 (3.2130)	Learning Rate [7.8125e-05]
0: TRAIN [3][3550/6832]	Time 0.230 (0.346)	Data 0.00110 (0.00210)	Tok/s 73025 (74264)	Loss/tok 2.9669 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [3][3560/6832]	Time 0.447 (0.346)	Data 0.00106 (0.00210)	Tok/s 70355 (74265)	Loss/tok 3.2735 (3.2129)	Learning Rate [7.8125e-05]
0: TRAIN [3][3570/6832]	Time 0.340 (0.346)	Data 0.00129 (0.00209)	Tok/s 69722 (74264)	Loss/tok 3.1593 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [3][3580/6832]	Time 0.410 (0.346)	Data 0.00109 (0.00209)	Tok/s 72505 (74270)	Loss/tok 3.2192 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [3][3590/6832]	Time 0.479 (0.346)	Data 0.00102 (0.00209)	Tok/s 70424 (74267)	Loss/tok 3.2901 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [3][3600/6832]	Time 0.460 (0.346)	Data 0.00116 (0.00208)	Tok/s 66651 (74270)	Loss/tok 3.3051 (3.2126)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][3610/6832]	Time 0.478 (0.346)	Data 0.00123 (0.00208)	Tok/s 78883 (74267)	Loss/tok 3.2816 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [3][3620/6832]	Time 0.372 (0.347)	Data 0.00104 (0.00208)	Tok/s 70364 (74260)	Loss/tok 3.2128 (3.2127)	Learning Rate [7.8125e-05]
0: TRAIN [3][3630/6832]	Time 0.403 (0.347)	Data 0.00104 (0.00208)	Tok/s 68720 (74262)	Loss/tok 3.2010 (3.2126)	Learning Rate [7.8125e-05]
0: TRAIN [3][3640/6832]	Time 0.157 (0.347)	Data 0.00103 (0.00207)	Tok/s 79290 (74262)	Loss/tok 2.8139 (3.2124)	Learning Rate [7.8125e-05]
0: TRAIN [3][3650/6832]	Time 0.480 (0.347)	Data 0.00105 (0.00207)	Tok/s 70285 (74262)	Loss/tok 3.2746 (3.2123)	Learning Rate [7.8125e-05]
0: TRAIN [3][3660/6832]	Time 0.476 (0.347)	Data 0.00105 (0.00207)	Tok/s 71923 (74270)	Loss/tok 3.2417 (3.2122)	Learning Rate [7.8125e-05]
0: TRAIN [3][3670/6832]	Time 0.482 (0.347)	Data 0.00021 (0.00207)	Tok/s 79492 (74271)	Loss/tok 3.2654 (3.2121)	Learning Rate [7.8125e-05]
0: TRAIN [3][3680/6832]	Time 0.146 (0.347)	Data 0.00105 (0.00206)	Tok/s 81263 (74283)	Loss/tok 2.7657 (3.2118)	Learning Rate [7.8125e-05]
0: TRAIN [3][3690/6832]	Time 0.151 (0.346)	Data 0.00101 (0.00206)	Tok/s 75553 (74277)	Loss/tok 2.6785 (3.2115)	Learning Rate [7.8125e-05]
0: TRAIN [3][3700/6832]	Time 0.469 (0.346)	Data 0.00108 (0.00206)	Tok/s 68892 (74276)	Loss/tok 3.2709 (3.2113)	Learning Rate [7.8125e-05]
0: TRAIN [3][3710/6832]	Time 0.463 (0.346)	Data 0.00099 (0.00205)	Tok/s 100560 (74280)	Loss/tok 3.0982 (3.2111)	Learning Rate [7.8125e-05]
0: TRAIN [3][3720/6832]	Time 0.181 (0.346)	Data 0.00104 (0.00205)	Tok/s 79379 (74280)	Loss/tok 2.9304 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [3][3730/6832]	Time 0.485 (0.346)	Data 0.00108 (0.00205)	Tok/s 80459 (74286)	Loss/tok 3.2794 (3.2109)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][3740/6832]	Time 0.243 (0.346)	Data 0.00104 (0.00205)	Tok/s 75244 (74287)	Loss/tok 3.0699 (3.2109)	Learning Rate [7.8125e-05]
0: TRAIN [3][3750/6832]	Time 0.242 (0.346)	Data 0.00107 (0.00204)	Tok/s 71336 (74286)	Loss/tok 3.0574 (3.2107)	Learning Rate [7.8125e-05]
0: TRAIN [3][3760/6832]	Time 0.170 (0.346)	Data 0.00108 (0.00204)	Tok/s 78949 (74295)	Loss/tok 2.8257 (3.2105)	Learning Rate [7.8125e-05]
0: TRAIN [3][3770/6832]	Time 0.347 (0.346)	Data 0.00102 (0.00204)	Tok/s 72363 (74297)	Loss/tok 3.1427 (3.2104)	Learning Rate [7.8125e-05]
0: TRAIN [3][3780/6832]	Time 0.369 (0.346)	Data 0.00105 (0.00204)	Tok/s 67239 (74292)	Loss/tok 3.1805 (3.2103)	Learning Rate [7.8125e-05]
0: TRAIN [3][3790/6832]	Time 0.483 (0.346)	Data 0.00102 (0.00203)	Tok/s 76877 (74300)	Loss/tok 3.2299 (3.2100)	Learning Rate [7.8125e-05]
0: TRAIN [3][3800/6832]	Time 0.373 (0.346)	Data 0.00117 (0.00203)	Tok/s 69084 (74291)	Loss/tok 3.2479 (3.2100)	Learning Rate [7.8125e-05]
0: TRAIN [3][3810/6832]	Time 0.448 (0.346)	Data 0.00103 (0.00203)	Tok/s 67479 (74285)	Loss/tok 3.2823 (3.2100)	Learning Rate [7.8125e-05]
0: TRAIN [3][3820/6832]	Time 0.243 (0.346)	Data 0.00105 (0.00203)	Tok/s 72080 (74287)	Loss/tok 3.0488 (3.2099)	Learning Rate [7.8125e-05]
0: TRAIN [3][3830/6832]	Time 0.266 (0.346)	Data 0.00100 (0.00202)	Tok/s 72333 (74287)	Loss/tok 3.0690 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [3][3840/6832]	Time 0.469 (0.346)	Data 0.00106 (0.00202)	Tok/s 67906 (74278)	Loss/tok 3.3348 (3.2097)	Learning Rate [7.8125e-05]
0: TRAIN [3][3850/6832]	Time 0.472 (0.346)	Data 0.00100 (0.00202)	Tok/s 72535 (74278)	Loss/tok 3.2584 (3.2096)	Learning Rate [7.8125e-05]
0: TRAIN [3][3860/6832]	Time 0.253 (0.346)	Data 0.00103 (0.00202)	Tok/s 72098 (74291)	Loss/tok 3.0479 (3.2093)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][3870/6832]	Time 0.465 (0.346)	Data 0.00106 (0.00201)	Tok/s 67375 (74290)	Loss/tok 3.2010 (3.2091)	Learning Rate [7.8125e-05]
0: TRAIN [3][3880/6832]	Time 0.477 (0.346)	Data 0.00110 (0.00201)	Tok/s 68926 (74284)	Loss/tok 3.3630 (3.2089)	Learning Rate [7.8125e-05]
0: TRAIN [3][3890/6832]	Time 0.275 (0.346)	Data 0.00105 (0.00201)	Tok/s 71082 (74282)	Loss/tok 3.0700 (3.2086)	Learning Rate [7.8125e-05]
0: TRAIN [3][3900/6832]	Time 0.335 (0.345)	Data 0.00104 (0.00201)	Tok/s 69483 (74278)	Loss/tok 3.1621 (3.2085)	Learning Rate [7.8125e-05]
0: TRAIN [3][3910/6832]	Time 0.146 (0.345)	Data 0.00105 (0.00200)	Tok/s 77198 (74277)	Loss/tok 2.6592 (3.2082)	Learning Rate [7.8125e-05]
0: TRAIN [3][3920/6832]	Time 0.487 (0.345)	Data 0.00104 (0.00200)	Tok/s 76566 (74282)	Loss/tok 3.2520 (3.2081)	Learning Rate [7.8125e-05]
0: TRAIN [3][3930/6832]	Time 0.220 (0.345)	Data 0.00148 (0.00200)	Tok/s 74587 (74275)	Loss/tok 2.9272 (3.2080)	Learning Rate [7.8125e-05]
0: TRAIN [3][3940/6832]	Time 0.485 (0.346)	Data 0.00106 (0.00200)	Tok/s 96177 (74286)	Loss/tok 3.0048 (3.2079)	Learning Rate [7.8125e-05]
0: TRAIN [3][3950/6832]	Time 0.206 (0.346)	Data 0.00103 (0.00200)	Tok/s 76033 (74295)	Loss/tok 3.0120 (3.2077)	Learning Rate [7.8125e-05]
0: TRAIN [3][3960/6832]	Time 0.365 (0.346)	Data 0.00104 (0.00199)	Tok/s 68802 (74301)	Loss/tok 3.2356 (3.2076)	Learning Rate [7.8125e-05]
0: TRAIN [3][3970/6832]	Time 0.477 (0.346)	Data 0.00105 (0.00199)	Tok/s 78893 (74296)	Loss/tok 3.2736 (3.2076)	Learning Rate [7.8125e-05]
0: TRAIN [3][3980/6832]	Time 0.475 (0.346)	Data 0.00103 (0.00199)	Tok/s 64382 (74289)	Loss/tok 3.2662 (3.2077)	Learning Rate [7.8125e-05]
0: TRAIN [3][3990/6832]	Time 0.272 (0.346)	Data 0.00104 (0.00199)	Tok/s 70645 (74282)	Loss/tok 3.0883 (3.2075)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4000/6832]	Time 0.420 (0.346)	Data 0.00106 (0.00198)	Tok/s 65848 (74277)	Loss/tok 3.1794 (3.2074)	Learning Rate [7.8125e-05]
0: TRAIN [3][4010/6832]	Time 0.484 (0.346)	Data 0.00103 (0.00198)	Tok/s 76666 (74281)	Loss/tok 3.2134 (3.2071)	Learning Rate [7.8125e-05]
0: TRAIN [3][4020/6832]	Time 0.353 (0.346)	Data 0.00101 (0.00198)	Tok/s 66158 (74276)	Loss/tok 3.1373 (3.2069)	Learning Rate [7.8125e-05]
0: TRAIN [3][4030/6832]	Time 0.466 (0.346)	Data 0.00107 (0.00198)	Tok/s 76751 (74276)	Loss/tok 3.2388 (3.2069)	Learning Rate [7.8125e-05]
0: TRAIN [3][4040/6832]	Time 0.464 (0.346)	Data 0.00104 (0.00198)	Tok/s 69610 (74279)	Loss/tok 3.3386 (3.2068)	Learning Rate [7.8125e-05]
0: TRAIN [3][4050/6832]	Time 0.200 (0.346)	Data 0.00102 (0.00197)	Tok/s 76348 (74277)	Loss/tok 2.9931 (3.2065)	Learning Rate [7.8125e-05]
0: TRAIN [3][4060/6832]	Time 0.450 (0.346)	Data 0.00106 (0.00197)	Tok/s 72868 (74272)	Loss/tok 3.2503 (3.2065)	Learning Rate [7.8125e-05]
0: TRAIN [3][4070/6832]	Time 0.474 (0.346)	Data 0.00101 (0.00197)	Tok/s 65756 (74266)	Loss/tok 3.2662 (3.2064)	Learning Rate [7.8125e-05]
0: TRAIN [3][4080/6832]	Time 0.325 (0.346)	Data 0.00099 (0.00197)	Tok/s 70935 (74262)	Loss/tok 3.1572 (3.2064)	Learning Rate [7.8125e-05]
0: TRAIN [3][4090/6832]	Time 0.467 (0.346)	Data 0.00103 (0.00196)	Tok/s 64646 (74263)	Loss/tok 3.3317 (3.2063)	Learning Rate [7.8125e-05]
0: TRAIN [3][4100/6832]	Time 0.476 (0.346)	Data 0.00104 (0.00196)	Tok/s 66926 (74254)	Loss/tok 3.2979 (3.2062)	Learning Rate [7.8125e-05]
0: TRAIN [3][4110/6832]	Time 0.268 (0.346)	Data 0.00111 (0.00196)	Tok/s 74541 (74250)	Loss/tok 2.9911 (3.2061)	Learning Rate [7.8125e-05]
0: TRAIN [3][4120/6832]	Time 0.480 (0.346)	Data 0.00103 (0.00196)	Tok/s 69505 (74253)	Loss/tok 3.2898 (3.2060)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4130/6832]	Time 0.325 (0.346)	Data 0.00099 (0.00196)	Tok/s 70950 (74247)	Loss/tok 3.0603 (3.2058)	Learning Rate [7.8125e-05]
0: TRAIN [3][4140/6832]	Time 0.475 (0.346)	Data 0.00104 (0.00195)	Tok/s 72126 (74242)	Loss/tok 3.3411 (3.2058)	Learning Rate [7.8125e-05]
0: TRAIN [3][4150/6832]	Time 0.376 (0.346)	Data 0.00117 (0.00195)	Tok/s 67807 (74235)	Loss/tok 3.1750 (3.2057)	Learning Rate [7.8125e-05]
0: TRAIN [3][4160/6832]	Time 0.141 (0.346)	Data 0.00104 (0.00195)	Tok/s 84065 (74232)	Loss/tok 2.7698 (3.2057)	Learning Rate [7.8125e-05]
0: TRAIN [3][4170/6832]	Time 0.139 (0.346)	Data 0.00108 (0.00195)	Tok/s 81209 (74227)	Loss/tok 2.7418 (3.2056)	Learning Rate [7.8125e-05]
0: TRAIN [3][4180/6832]	Time 0.141 (0.346)	Data 0.00102 (0.00195)	Tok/s 80569 (74229)	Loss/tok 2.6566 (3.2054)	Learning Rate [7.8125e-05]
0: TRAIN [3][4190/6832]	Time 0.228 (0.346)	Data 0.00103 (0.00194)	Tok/s 73497 (74227)	Loss/tok 2.9232 (3.2054)	Learning Rate [7.8125e-05]
0: TRAIN [3][4200/6832]	Time 0.232 (0.346)	Data 0.00125 (0.00194)	Tok/s 75121 (74225)	Loss/tok 2.9599 (3.2054)	Learning Rate [7.8125e-05]
0: TRAIN [3][4210/6832]	Time 0.456 (0.346)	Data 0.00107 (0.00194)	Tok/s 67793 (74219)	Loss/tok 3.1917 (3.2053)	Learning Rate [7.8125e-05]
0: TRAIN [3][4220/6832]	Time 0.481 (0.346)	Data 0.00101 (0.00194)	Tok/s 66278 (74212)	Loss/tok 3.2382 (3.2052)	Learning Rate [7.8125e-05]
0: TRAIN [3][4230/6832]	Time 0.487 (0.346)	Data 0.00109 (0.00194)	Tok/s 86791 (74215)	Loss/tok 3.1938 (3.2049)	Learning Rate [7.8125e-05]
0: TRAIN [3][4240/6832]	Time 0.295 (0.346)	Data 0.00110 (0.00193)	Tok/s 73047 (74214)	Loss/tok 3.1497 (3.2049)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4250/6832]	Time 0.195 (0.346)	Data 0.00117 (0.00193)	Tok/s 76122 (74209)	Loss/tok 2.9787 (3.2048)	Learning Rate [7.8125e-05]
0: TRAIN [3][4260/6832]	Time 0.466 (0.346)	Data 0.00101 (0.00193)	Tok/s 77952 (74206)	Loss/tok 3.2485 (3.2047)	Learning Rate [7.8125e-05]
0: TRAIN [3][4270/6832]	Time 0.431 (0.346)	Data 0.00104 (0.00193)	Tok/s 65949 (74205)	Loss/tok 3.2379 (3.2046)	Learning Rate [7.8125e-05]
0: TRAIN [3][4280/6832]	Time 0.197 (0.346)	Data 0.00110 (0.00193)	Tok/s 76900 (74204)	Loss/tok 2.8753 (3.2044)	Learning Rate [7.8125e-05]
0: TRAIN [3][4290/6832]	Time 0.416 (0.346)	Data 0.00104 (0.00192)	Tok/s 65666 (74201)	Loss/tok 3.1154 (3.2044)	Learning Rate [7.8125e-05]
0: TRAIN [3][4300/6832]	Time 0.444 (0.346)	Data 0.00109 (0.00192)	Tok/s 68737 (74197)	Loss/tok 3.1960 (3.2043)	Learning Rate [7.8125e-05]
0: TRAIN [3][4310/6832]	Time 0.315 (0.346)	Data 0.00104 (0.00192)	Tok/s 71898 (74192)	Loss/tok 3.0776 (3.2042)	Learning Rate [7.8125e-05]
0: TRAIN [3][4320/6832]	Time 0.480 (0.346)	Data 0.00113 (0.00192)	Tok/s 86276 (74201)	Loss/tok 3.1586 (3.2039)	Learning Rate [7.8125e-05]
0: TRAIN [3][4330/6832]	Time 0.243 (0.346)	Data 0.00103 (0.00192)	Tok/s 74592 (74198)	Loss/tok 3.0204 (3.2038)	Learning Rate [7.8125e-05]
0: TRAIN [3][4340/6832]	Time 0.308 (0.346)	Data 0.00108 (0.00192)	Tok/s 71400 (74196)	Loss/tok 3.1335 (3.2039)	Learning Rate [7.8125e-05]
0: TRAIN [3][4350/6832]	Time 0.207 (0.346)	Data 0.00113 (0.00191)	Tok/s 75328 (74202)	Loss/tok 2.8374 (3.2037)	Learning Rate [7.8125e-05]
0: TRAIN [3][4360/6832]	Time 0.115 (0.346)	Data 0.00116 (0.00191)	Tok/s 73071 (74201)	Loss/tok 2.3746 (3.2036)	Learning Rate [7.8125e-05]
0: TRAIN [3][4370/6832]	Time 0.235 (0.346)	Data 0.00101 (0.00191)	Tok/s 74222 (74198)	Loss/tok 3.0128 (3.2034)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4380/6832]	Time 0.483 (0.346)	Data 0.00111 (0.00191)	Tok/s 96336 (74207)	Loss/tok 3.0171 (3.2033)	Learning Rate [7.8125e-05]
0: TRAIN [3][4390/6832]	Time 0.137 (0.346)	Data 0.00105 (0.00191)	Tok/s 77050 (74221)	Loss/tok 2.5302 (3.2030)	Learning Rate [7.8125e-05]
0: TRAIN [3][4400/6832]	Time 0.475 (0.346)	Data 0.00102 (0.00190)	Tok/s 66309 (74233)	Loss/tok 3.2500 (3.2027)	Learning Rate [7.8125e-05]
0: TRAIN [3][4410/6832]	Time 0.217 (0.346)	Data 0.00104 (0.00190)	Tok/s 77741 (74237)	Loss/tok 3.0353 (3.2025)	Learning Rate [7.8125e-05]
0: TRAIN [3][4420/6832]	Time 0.476 (0.346)	Data 0.00121 (0.00190)	Tok/s 69115 (74233)	Loss/tok 3.3121 (3.2024)	Learning Rate [7.8125e-05]
0: TRAIN [3][4430/6832]	Time 0.378 (0.346)	Data 0.00100 (0.00190)	Tok/s 68541 (74237)	Loss/tok 3.1025 (3.2021)	Learning Rate [7.8125e-05]
0: TRAIN [3][4440/6832]	Time 0.483 (0.346)	Data 0.00102 (0.00190)	Tok/s 91261 (74234)	Loss/tok 3.1431 (3.2020)	Learning Rate [7.8125e-05]
0: TRAIN [3][4450/6832]	Time 0.482 (0.346)	Data 0.00107 (0.00190)	Tok/s 73225 (74242)	Loss/tok 3.2691 (3.2017)	Learning Rate [7.8125e-05]
0: TRAIN [3][4460/6832]	Time 0.480 (0.346)	Data 0.00105 (0.00189)	Tok/s 70160 (74243)	Loss/tok 3.2329 (3.2017)	Learning Rate [7.8125e-05]
0: TRAIN [3][4470/6832]	Time 0.476 (0.346)	Data 0.00100 (0.00189)	Tok/s 75427 (74247)	Loss/tok 3.2697 (3.2014)	Learning Rate [7.8125e-05]
0: TRAIN [3][4480/6832]	Time 0.485 (0.346)	Data 0.00102 (0.00189)	Tok/s 80639 (74250)	Loss/tok 3.1493 (3.2013)	Learning Rate [7.8125e-05]
0: TRAIN [3][4490/6832]	Time 0.164 (0.346)	Data 0.00106 (0.00189)	Tok/s 79251 (74267)	Loss/tok 2.8092 (3.2009)	Learning Rate [7.8125e-05]
0: TRAIN [3][4500/6832]	Time 0.481 (0.346)	Data 0.00103 (0.00189)	Tok/s 75799 (74266)	Loss/tok 3.3576 (3.2008)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4510/6832]	Time 0.166 (0.346)	Data 0.00104 (0.00188)	Tok/s 78201 (74269)	Loss/tok 2.8452 (3.2007)	Learning Rate [7.8125e-05]
0: TRAIN [3][4520/6832]	Time 0.341 (0.346)	Data 0.00103 (0.00188)	Tok/s 68649 (74272)	Loss/tok 3.0513 (3.2006)	Learning Rate [7.8125e-05]
0: TRAIN [3][4530/6832]	Time 0.467 (0.346)	Data 0.00109 (0.00188)	Tok/s 65553 (74268)	Loss/tok 3.1667 (3.2005)	Learning Rate [7.8125e-05]
0: TRAIN [3][4540/6832]	Time 0.256 (0.346)	Data 0.00105 (0.00188)	Tok/s 75973 (74275)	Loss/tok 3.0429 (3.2003)	Learning Rate [7.8125e-05]
0: TRAIN [3][4550/6832]	Time 0.447 (0.346)	Data 0.00104 (0.00188)	Tok/s 65612 (74271)	Loss/tok 3.1861 (3.2002)	Learning Rate [7.8125e-05]
0: TRAIN [3][4560/6832]	Time 0.399 (0.346)	Data 0.00103 (0.00188)	Tok/s 68497 (74268)	Loss/tok 3.1822 (3.2001)	Learning Rate [7.8125e-05]
0: TRAIN [3][4570/6832]	Time 0.481 (0.346)	Data 0.00101 (0.00187)	Tok/s 75795 (74266)	Loss/tok 3.2114 (3.2000)	Learning Rate [7.8125e-05]
0: TRAIN [3][4580/6832]	Time 0.369 (0.346)	Data 0.00101 (0.00187)	Tok/s 68043 (74264)	Loss/tok 3.1916 (3.1998)	Learning Rate [7.8125e-05]
0: TRAIN [3][4590/6832]	Time 0.430 (0.346)	Data 0.00143 (0.00187)	Tok/s 66621 (74268)	Loss/tok 3.1964 (3.1996)	Learning Rate [7.8125e-05]
0: TRAIN [3][4600/6832]	Time 0.320 (0.346)	Data 0.00112 (0.00187)	Tok/s 72035 (74272)	Loss/tok 3.0899 (3.1996)	Learning Rate [7.8125e-05]
0: TRAIN [3][4610/6832]	Time 0.109 (0.346)	Data 0.00107 (0.00187)	Tok/s 77213 (74270)	Loss/tok 2.3476 (3.1994)	Learning Rate [7.8125e-05]
0: TRAIN [3][4620/6832]	Time 0.201 (0.346)	Data 0.00101 (0.00187)	Tok/s 77943 (74266)	Loss/tok 2.9351 (3.1992)	Learning Rate [7.8125e-05]
0: TRAIN [3][4630/6832]	Time 0.469 (0.346)	Data 0.00105 (0.00186)	Tok/s 76275 (74265)	Loss/tok 3.1887 (3.1991)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4640/6832]	Time 0.483 (0.346)	Data 0.00122 (0.00186)	Tok/s 80437 (74265)	Loss/tok 3.2014 (3.1989)	Learning Rate [7.8125e-05]
0: TRAIN [3][4650/6832]	Time 0.451 (0.346)	Data 0.00103 (0.00186)	Tok/s 68953 (74270)	Loss/tok 3.2469 (3.1988)	Learning Rate [7.8125e-05]
0: TRAIN [3][4660/6832]	Time 0.133 (0.346)	Data 0.00103 (0.00186)	Tok/s 83934 (74284)	Loss/tok 2.6152 (3.1985)	Learning Rate [7.8125e-05]
0: TRAIN [3][4670/6832]	Time 0.427 (0.346)	Data 0.00108 (0.00186)	Tok/s 67520 (74282)	Loss/tok 3.1675 (3.1983)	Learning Rate [7.8125e-05]
0: TRAIN [3][4680/6832]	Time 0.311 (0.346)	Data 0.00113 (0.00186)	Tok/s 71826 (74286)	Loss/tok 3.1157 (3.1981)	Learning Rate [7.8125e-05]
0: TRAIN [3][4690/6832]	Time 0.227 (0.346)	Data 0.00110 (0.00185)	Tok/s 75001 (74284)	Loss/tok 2.9613 (3.1980)	Learning Rate [7.8125e-05]
0: TRAIN [3][4700/6832]	Time 0.373 (0.346)	Data 0.00112 (0.00185)	Tok/s 70223 (74278)	Loss/tok 3.0612 (3.1977)	Learning Rate [7.8125e-05]
0: TRAIN [3][4710/6832]	Time 0.303 (0.346)	Data 0.00100 (0.00185)	Tok/s 70379 (74279)	Loss/tok 3.0208 (3.1976)	Learning Rate [7.8125e-05]
0: TRAIN [3][4720/6832]	Time 0.414 (0.346)	Data 0.00112 (0.00185)	Tok/s 68047 (74273)	Loss/tok 3.2643 (3.1975)	Learning Rate [7.8125e-05]
0: TRAIN [3][4730/6832]	Time 0.259 (0.346)	Data 0.00121 (0.00185)	Tok/s 72939 (74271)	Loss/tok 3.0307 (3.1973)	Learning Rate [7.8125e-05]
0: TRAIN [3][4740/6832]	Time 0.225 (0.346)	Data 0.00109 (0.00185)	Tok/s 75872 (74280)	Loss/tok 2.9364 (3.1971)	Learning Rate [7.8125e-05]
0: TRAIN [3][4750/6832]	Time 0.473 (0.346)	Data 0.00111 (0.00185)	Tok/s 63547 (74285)	Loss/tok 3.3018 (3.1970)	Learning Rate [7.8125e-05]
0: TRAIN [3][4760/6832]	Time 0.264 (0.346)	Data 0.00107 (0.00184)	Tok/s 75757 (74282)	Loss/tok 2.9859 (3.1969)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4770/6832]	Time 0.307 (0.346)	Data 0.00102 (0.00184)	Tok/s 73664 (74283)	Loss/tok 3.0629 (3.1967)	Learning Rate [7.8125e-05]
0: TRAIN [3][4780/6832]	Time 0.472 (0.346)	Data 0.00117 (0.00184)	Tok/s 67614 (74282)	Loss/tok 3.1991 (3.1966)	Learning Rate [7.8125e-05]
0: TRAIN [3][4790/6832]	Time 0.484 (0.346)	Data 0.00105 (0.00184)	Tok/s 89333 (74282)	Loss/tok 3.1319 (3.1965)	Learning Rate [7.8125e-05]
0: TRAIN [3][4800/6832]	Time 0.213 (0.346)	Data 0.00110 (0.00184)	Tok/s 74984 (74277)	Loss/tok 2.9286 (3.1962)	Learning Rate [7.8125e-05]
0: TRAIN [3][4810/6832]	Time 0.223 (0.346)	Data 0.00109 (0.00184)	Tok/s 73901 (74280)	Loss/tok 2.9700 (3.1960)	Learning Rate [7.8125e-05]
0: TRAIN [3][4820/6832]	Time 0.247 (0.346)	Data 0.00120 (0.00183)	Tok/s 75233 (74278)	Loss/tok 2.9598 (3.1958)	Learning Rate [7.8125e-05]
0: TRAIN [3][4830/6832]	Time 0.379 (0.346)	Data 0.00124 (0.00183)	Tok/s 70046 (74282)	Loss/tok 3.1807 (3.1956)	Learning Rate [7.8125e-05]
0: TRAIN [3][4840/6832]	Time 0.295 (0.346)	Data 0.00103 (0.00183)	Tok/s 68653 (74280)	Loss/tok 3.0637 (3.1954)	Learning Rate [7.8125e-05]
0: TRAIN [3][4850/6832]	Time 0.247 (0.346)	Data 0.00105 (0.00183)	Tok/s 72235 (74276)	Loss/tok 2.9343 (3.1954)	Learning Rate [7.8125e-05]
0: TRAIN [3][4860/6832]	Time 0.393 (0.346)	Data 0.00099 (0.00183)	Tok/s 69804 (74274)	Loss/tok 3.1389 (3.1953)	Learning Rate [7.8125e-05]
0: TRAIN [3][4870/6832]	Time 0.437 (0.346)	Data 0.00102 (0.00183)	Tok/s 65521 (74272)	Loss/tok 3.1361 (3.1951)	Learning Rate [7.8125e-05]
0: TRAIN [3][4880/6832]	Time 0.459 (0.346)	Data 0.00101 (0.00183)	Tok/s 98362 (74279)	Loss/tok 3.1050 (3.1949)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][4890/6832]	Time 0.301 (0.346)	Data 0.00118 (0.00182)	Tok/s 74766 (74279)	Loss/tok 3.0326 (3.1948)	Learning Rate [7.8125e-05]
0: TRAIN [3][4900/6832]	Time 0.470 (0.346)	Data 0.00101 (0.00182)	Tok/s 67912 (74277)	Loss/tok 3.2056 (3.1946)	Learning Rate [7.8125e-05]
0: TRAIN [3][4910/6832]	Time 0.200 (0.346)	Data 0.00107 (0.00182)	Tok/s 75419 (74289)	Loss/tok 2.8954 (3.1943)	Learning Rate [7.8125e-05]
0: TRAIN [3][4920/6832]	Time 0.316 (0.346)	Data 0.00103 (0.00182)	Tok/s 71786 (74286)	Loss/tok 3.0893 (3.1942)	Learning Rate [7.8125e-05]
0: TRAIN [3][4930/6832]	Time 0.234 (0.346)	Data 0.00105 (0.00182)	Tok/s 74368 (74282)	Loss/tok 3.0143 (3.1939)	Learning Rate [7.8125e-05]
0: TRAIN [3][4940/6832]	Time 0.465 (0.346)	Data 0.00110 (0.00182)	Tok/s 67946 (74282)	Loss/tok 3.2368 (3.1938)	Learning Rate [7.8125e-05]
0: TRAIN [3][4950/6832]	Time 0.353 (0.346)	Data 0.00102 (0.00181)	Tok/s 69574 (74280)	Loss/tok 3.0778 (3.1936)	Learning Rate [7.8125e-05]
0: TRAIN [3][4960/6832]	Time 0.224 (0.346)	Data 0.00102 (0.00181)	Tok/s 69295 (74276)	Loss/tok 2.9189 (3.1934)	Learning Rate [7.8125e-05]
0: TRAIN [3][4970/6832]	Time 0.146 (0.346)	Data 0.00100 (0.00181)	Tok/s 81432 (74288)	Loss/tok 2.7790 (3.1931)	Learning Rate [7.8125e-05]
0: TRAIN [3][4980/6832]	Time 0.112 (0.346)	Data 0.00107 (0.00181)	Tok/s 76207 (74293)	Loss/tok 2.3762 (3.1929)	Learning Rate [7.8125e-05]
0: TRAIN [3][4990/6832]	Time 0.155 (0.346)	Data 0.00025 (0.00181)	Tok/s 79879 (74294)	Loss/tok 2.7286 (3.1927)	Learning Rate [7.8125e-05]
0: TRAIN [3][5000/6832]	Time 0.289 (0.346)	Data 0.00106 (0.00181)	Tok/s 71310 (74289)	Loss/tok 3.0824 (3.1926)	Learning Rate [7.8125e-05]
0: TRAIN [3][5010/6832]	Time 0.274 (0.346)	Data 0.00101 (0.00181)	Tok/s 73794 (74292)	Loss/tok 3.0379 (3.1926)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5020/6832]	Time 0.380 (0.346)	Data 0.00097 (0.00180)	Tok/s 68689 (74285)	Loss/tok 3.1699 (3.1924)	Learning Rate [7.8125e-05]
0: TRAIN [3][5030/6832]	Time 0.460 (0.346)	Data 0.00103 (0.00180)	Tok/s 86290 (74279)	Loss/tok 3.1513 (3.1923)	Learning Rate [7.8125e-05]
0: TRAIN [3][5040/6832]	Time 0.482 (0.346)	Data 0.00101 (0.00180)	Tok/s 93582 (74279)	Loss/tok 3.0672 (3.1920)	Learning Rate [7.8125e-05]
0: TRAIN [3][5050/6832]	Time 0.318 (0.346)	Data 0.00104 (0.00180)	Tok/s 69281 (74278)	Loss/tok 3.0719 (3.1918)	Learning Rate [7.8125e-05]
0: TRAIN [3][5060/6832]	Time 0.338 (0.346)	Data 0.00104 (0.00180)	Tok/s 70407 (74272)	Loss/tok 3.0843 (3.1916)	Learning Rate [7.8125e-05]
0: TRAIN [3][5070/6832]	Time 0.339 (0.346)	Data 0.00110 (0.00180)	Tok/s 69559 (74267)	Loss/tok 3.1158 (3.1916)	Learning Rate [7.8125e-05]
0: TRAIN [3][5080/6832]	Time 0.485 (0.346)	Data 0.00102 (0.00180)	Tok/s 79093 (74267)	Loss/tok 3.1279 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [3][5090/6832]	Time 0.413 (0.346)	Data 0.00104 (0.00179)	Tok/s 66940 (74263)	Loss/tok 3.0873 (3.1912)	Learning Rate [7.8125e-05]
0: TRAIN [3][5100/6832]	Time 0.343 (0.346)	Data 0.00105 (0.00179)	Tok/s 70112 (74263)	Loss/tok 3.0629 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [3][5110/6832]	Time 0.300 (0.346)	Data 0.00100 (0.00179)	Tok/s 72937 (74267)	Loss/tok 3.1366 (3.1907)	Learning Rate [7.8125e-05]
0: TRAIN [3][5120/6832]	Time 0.482 (0.346)	Data 0.00123 (0.00179)	Tok/s 96526 (74267)	Loss/tok 3.0800 (3.1905)	Learning Rate [7.8125e-05]
0: TRAIN [3][5130/6832]	Time 0.481 (0.346)	Data 0.00104 (0.00179)	Tok/s 82509 (74267)	Loss/tok 3.1142 (3.1903)	Learning Rate [7.8125e-05]
0: TRAIN [3][5140/6832]	Time 0.481 (0.346)	Data 0.00104 (0.00179)	Tok/s 70105 (74259)	Loss/tok 3.2034 (3.1902)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5150/6832]	Time 0.485 (0.346)	Data 0.00112 (0.00179)	Tok/s 80571 (74257)	Loss/tok 3.1887 (3.1900)	Learning Rate [7.8125e-05]
0: TRAIN [3][5160/6832]	Time 0.395 (0.346)	Data 0.00101 (0.00178)	Tok/s 69962 (74255)	Loss/tok 3.2777 (3.1900)	Learning Rate [7.8125e-05]
0: TRAIN [3][5170/6832]	Time 0.254 (0.346)	Data 0.00105 (0.00178)	Tok/s 75655 (74261)	Loss/tok 3.0123 (3.1898)	Learning Rate [7.8125e-05]
0: TRAIN [3][5180/6832]	Time 0.483 (0.346)	Data 0.00115 (0.00178)	Tok/s 77824 (74269)	Loss/tok 3.2272 (3.1896)	Learning Rate [7.8125e-05]
0: TRAIN [3][5190/6832]	Time 0.101 (0.346)	Data 0.00102 (0.00178)	Tok/s 57261 (74270)	Loss/tok 2.0186 (3.1893)	Learning Rate [7.8125e-05]
0: TRAIN [3][5200/6832]	Time 0.116 (0.346)	Data 0.00110 (0.00178)	Tok/s 82752 (74281)	Loss/tok 2.5441 (3.1891)	Learning Rate [7.8125e-05]
0: TRAIN [3][5210/6832]	Time 0.455 (0.346)	Data 0.00103 (0.00178)	Tok/s 65303 (74273)	Loss/tok 3.2479 (3.1890)	Learning Rate [7.8125e-05]
0: TRAIN [3][5220/6832]	Time 0.486 (0.346)	Data 0.00102 (0.00178)	Tok/s 100194 (74275)	Loss/tok 2.9068 (3.1888)	Learning Rate [7.8125e-05]
0: TRAIN [3][5230/6832]	Time 0.182 (0.346)	Data 0.00102 (0.00177)	Tok/s 78683 (74274)	Loss/tok 2.8258 (3.1886)	Learning Rate [7.8125e-05]
0: TRAIN [3][5240/6832]	Time 0.428 (0.346)	Data 0.00101 (0.00177)	Tok/s 66457 (74274)	Loss/tok 3.0827 (3.1884)	Learning Rate [7.8125e-05]
0: TRAIN [3][5250/6832]	Time 0.363 (0.346)	Data 0.00145 (0.00177)	Tok/s 67422 (74274)	Loss/tok 3.1317 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [3][5260/6832]	Time 0.397 (0.346)	Data 0.00098 (0.00177)	Tok/s 67981 (74274)	Loss/tok 3.1734 (3.1880)	Learning Rate [7.8125e-05]
0: TRAIN [3][5270/6832]	Time 0.284 (0.346)	Data 0.00100 (0.00177)	Tok/s 70248 (74282)	Loss/tok 3.0632 (3.1878)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5280/6832]	Time 0.474 (0.346)	Data 0.00108 (0.00177)	Tok/s 77020 (74275)	Loss/tok 3.2069 (3.1876)	Learning Rate [7.8125e-05]
0: TRAIN [3][5290/6832]	Time 0.326 (0.346)	Data 0.00111 (0.00177)	Tok/s 73171 (74275)	Loss/tok 3.0851 (3.1875)	Learning Rate [7.8125e-05]
0: TRAIN [3][5300/6832]	Time 0.232 (0.346)	Data 0.00112 (0.00177)	Tok/s 75165 (74281)	Loss/tok 3.0253 (3.1872)	Learning Rate [7.8125e-05]
0: TRAIN [3][5310/6832]	Time 0.182 (0.346)	Data 0.00105 (0.00176)	Tok/s 79047 (74288)	Loss/tok 2.7901 (3.1870)	Learning Rate [7.8125e-05]
0: TRAIN [3][5320/6832]	Time 0.292 (0.346)	Data 0.00113 (0.00176)	Tok/s 69428 (74283)	Loss/tok 3.0152 (3.1868)	Learning Rate [7.8125e-05]
0: TRAIN [3][5330/6832]	Time 0.485 (0.346)	Data 0.00105 (0.00176)	Tok/s 100205 (74293)	Loss/tok 2.9623 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [3][5340/6832]	Time 0.240 (0.346)	Data 0.00101 (0.00176)	Tok/s 70299 (74293)	Loss/tok 2.9205 (3.1864)	Learning Rate [7.8125e-05]
0: TRAIN [3][5350/6832]	Time 0.320 (0.346)	Data 0.00102 (0.00176)	Tok/s 73841 (74294)	Loss/tok 3.0845 (3.1862)	Learning Rate [7.8125e-05]
0: TRAIN [3][5360/6832]	Time 0.431 (0.346)	Data 0.00106 (0.00176)	Tok/s 66170 (74290)	Loss/tok 3.2194 (3.1860)	Learning Rate [7.8125e-05]
0: TRAIN [3][5370/6832]	Time 0.461 (0.346)	Data 0.00106 (0.00176)	Tok/s 105672 (74295)	Loss/tok 2.9533 (3.1858)	Learning Rate [7.8125e-05]
0: TRAIN [3][5380/6832]	Time 0.484 (0.346)	Data 0.00104 (0.00176)	Tok/s 86928 (74296)	Loss/tok 3.0745 (3.1855)	Learning Rate [7.8125e-05]
0: TRAIN [3][5390/6832]	Time 0.279 (0.346)	Data 0.00102 (0.00175)	Tok/s 72181 (74295)	Loss/tok 3.0102 (3.1853)	Learning Rate [7.8125e-05]
0: TRAIN [3][5400/6832]	Time 0.340 (0.346)	Data 0.00103 (0.00175)	Tok/s 74357 (74300)	Loss/tok 3.0759 (3.1851)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5410/6832]	Time 0.194 (0.346)	Data 0.00105 (0.00175)	Tok/s 78419 (74297)	Loss/tok 2.9123 (3.1849)	Learning Rate [7.8125e-05]
0: TRAIN [3][5420/6832]	Time 0.457 (0.345)	Data 0.00103 (0.00175)	Tok/s 68751 (74296)	Loss/tok 3.1856 (3.1847)	Learning Rate [7.8125e-05]
0: TRAIN [3][5430/6832]	Time 0.348 (0.345)	Data 0.00102 (0.00175)	Tok/s 69307 (74295)	Loss/tok 3.1043 (3.1846)	Learning Rate [7.8125e-05]
0: TRAIN [3][5440/6832]	Time 0.484 (0.345)	Data 0.00110 (0.00175)	Tok/s 100563 (74294)	Loss/tok 2.9903 (3.1844)	Learning Rate [7.8125e-05]
0: TRAIN [3][5450/6832]	Time 0.481 (0.345)	Data 0.00097 (0.00175)	Tok/s 85989 (74297)	Loss/tok 3.1014 (3.1841)	Learning Rate [7.8125e-05]
0: TRAIN [3][5460/6832]	Time 0.476 (0.346)	Data 0.00130 (0.00175)	Tok/s 69849 (74298)	Loss/tok 3.1895 (3.1839)	Learning Rate [7.8125e-05]
0: TRAIN [3][5470/6832]	Time 0.338 (0.346)	Data 0.00111 (0.00174)	Tok/s 69614 (74294)	Loss/tok 2.9789 (3.1839)	Learning Rate [7.8125e-05]
0: TRAIN [3][5480/6832]	Time 0.210 (0.346)	Data 0.00101 (0.00174)	Tok/s 75781 (74301)	Loss/tok 2.9053 (3.1836)	Learning Rate [7.8125e-05]
0: TRAIN [3][5490/6832]	Time 0.135 (0.346)	Data 0.00105 (0.00174)	Tok/s 78446 (74304)	Loss/tok 2.5657 (3.1835)	Learning Rate [7.8125e-05]
0: TRAIN [3][5500/6832]	Time 0.260 (0.346)	Data 0.00117 (0.00174)	Tok/s 72975 (74303)	Loss/tok 2.9408 (3.1833)	Learning Rate [7.8125e-05]
0: TRAIN [3][5510/6832]	Time 0.107 (0.346)	Data 0.00108 (0.00174)	Tok/s 78024 (74307)	Loss/tok 2.3415 (3.1831)	Learning Rate [7.8125e-05]
0: TRAIN [3][5520/6832]	Time 0.467 (0.346)	Data 0.00108 (0.00174)	Tok/s 86538 (74306)	Loss/tok 3.1145 (3.1829)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5530/6832]	Time 0.215 (0.346)	Data 0.00118 (0.00174)	Tok/s 77803 (74311)	Loss/tok 2.9348 (3.1827)	Learning Rate [7.8125e-05]
0: TRAIN [3][5540/6832]	Time 0.114 (0.346)	Data 0.00110 (0.00174)	Tok/s 75001 (74310)	Loss/tok 2.3356 (3.1825)	Learning Rate [7.8125e-05]
0: TRAIN [3][5550/6832]	Time 0.253 (0.346)	Data 0.00105 (0.00174)	Tok/s 73161 (74307)	Loss/tok 2.9771 (3.1823)	Learning Rate [7.8125e-05]
0: TRAIN [3][5560/6832]	Time 0.121 (0.346)	Data 0.00105 (0.00173)	Tok/s 80208 (74304)	Loss/tok 2.5039 (3.1821)	Learning Rate [7.8125e-05]
0: TRAIN [3][5570/6832]	Time 0.447 (0.346)	Data 0.00112 (0.00173)	Tok/s 68409 (74300)	Loss/tok 3.1445 (3.1819)	Learning Rate [7.8125e-05]
0: TRAIN [3][5580/6832]	Time 0.463 (0.346)	Data 0.00108 (0.00173)	Tok/s 100533 (74302)	Loss/tok 2.9829 (3.1817)	Learning Rate [7.8125e-05]
0: TRAIN [3][5590/6832]	Time 0.481 (0.346)	Data 0.00115 (0.00173)	Tok/s 72779 (74306)	Loss/tok 3.1640 (3.1815)	Learning Rate [7.8125e-05]
0: TRAIN [3][5600/6832]	Time 0.325 (0.346)	Data 0.00102 (0.00173)	Tok/s 70828 (74308)	Loss/tok 3.0810 (3.1813)	Learning Rate [7.8125e-05]
0: TRAIN [3][5610/6832]	Time 0.310 (0.346)	Data 0.00099 (0.00173)	Tok/s 74371 (74306)	Loss/tok 2.9642 (3.1811)	Learning Rate [7.8125e-05]
0: TRAIN [3][5620/6832]	Time 0.481 (0.346)	Data 0.00107 (0.00173)	Tok/s 91817 (74310)	Loss/tok 2.9980 (3.1809)	Learning Rate [7.8125e-05]
0: TRAIN [3][5630/6832]	Time 0.266 (0.346)	Data 0.00107 (0.00173)	Tok/s 74906 (74308)	Loss/tok 3.0101 (3.1808)	Learning Rate [7.8125e-05]
0: TRAIN [3][5640/6832]	Time 0.129 (0.346)	Data 0.00114 (0.00172)	Tok/s 75048 (74303)	Loss/tok 2.4964 (3.1806)	Learning Rate [7.8125e-05]
0: TRAIN [3][5650/6832]	Time 0.356 (0.346)	Data 0.00026 (0.00172)	Tok/s 68815 (74298)	Loss/tok 3.1227 (3.1804)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5660/6832]	Time 0.404 (0.346)	Data 0.00107 (0.00172)	Tok/s 68054 (74298)	Loss/tok 3.1472 (3.1803)	Learning Rate [7.8125e-05]
0: TRAIN [3][5670/6832]	Time 0.435 (0.346)	Data 0.00107 (0.00172)	Tok/s 64714 (74297)	Loss/tok 3.1318 (3.1801)	Learning Rate [7.8125e-05]
0: TRAIN [3][5680/6832]	Time 0.449 (0.346)	Data 0.00103 (0.00172)	Tok/s 69808 (74292)	Loss/tok 3.1999 (3.1799)	Learning Rate [7.8125e-05]
0: TRAIN [3][5690/6832]	Time 0.151 (0.346)	Data 0.00107 (0.00172)	Tok/s 78588 (74298)	Loss/tok 2.7078 (3.1797)	Learning Rate [7.8125e-05]
0: TRAIN [3][5700/6832]	Time 0.219 (0.346)	Data 0.00106 (0.00172)	Tok/s 76627 (74310)	Loss/tok 2.8901 (3.1794)	Learning Rate [7.8125e-05]
0: TRAIN [3][5710/6832]	Time 0.383 (0.346)	Data 0.00103 (0.00172)	Tok/s 70284 (74315)	Loss/tok 3.0561 (3.1792)	Learning Rate [7.8125e-05]
0: TRAIN [3][5720/6832]	Time 0.478 (0.346)	Data 0.00104 (0.00172)	Tok/s 65952 (74315)	Loss/tok 3.1491 (3.1789)	Learning Rate [7.8125e-05]
0: TRAIN [3][5730/6832]	Time 0.253 (0.346)	Data 0.00103 (0.00171)	Tok/s 74891 (74313)	Loss/tok 3.0395 (3.1788)	Learning Rate [7.8125e-05]
0: TRAIN [3][5740/6832]	Time 0.157 (0.346)	Data 0.00108 (0.00171)	Tok/s 79133 (74307)	Loss/tok 2.7976 (3.1786)	Learning Rate [7.8125e-05]
0: TRAIN [3][5750/6832]	Time 0.423 (0.346)	Data 0.00104 (0.00171)	Tok/s 67560 (74299)	Loss/tok 3.1477 (3.1785)	Learning Rate [7.8125e-05]
0: TRAIN [3][5760/6832]	Time 0.474 (0.346)	Data 0.00102 (0.00171)	Tok/s 68263 (74291)	Loss/tok 3.1717 (3.1783)	Learning Rate [7.8125e-05]
0: TRAIN [3][5770/6832]	Time 0.145 (0.346)	Data 0.00102 (0.00171)	Tok/s 72822 (74292)	Loss/tok 2.6213 (3.1782)	Learning Rate [7.8125e-05]
0: TRAIN [3][5780/6832]	Time 0.165 (0.346)	Data 0.00112 (0.00171)	Tok/s 75470 (74291)	Loss/tok 2.7498 (3.1779)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5790/6832]	Time 0.356 (0.346)	Data 0.00099 (0.00171)	Tok/s 74800 (74293)	Loss/tok 3.0662 (3.1776)	Learning Rate [7.8125e-05]
0: TRAIN [3][5800/6832]	Time 0.480 (0.346)	Data 0.00101 (0.00171)	Tok/s 82726 (74300)	Loss/tok 3.1678 (3.1773)	Learning Rate [7.8125e-05]
0: TRAIN [3][5810/6832]	Time 0.179 (0.346)	Data 0.00104 (0.00171)	Tok/s 77669 (74301)	Loss/tok 2.7564 (3.1770)	Learning Rate [7.8125e-05]
0: TRAIN [3][5820/6832]	Time 0.455 (0.346)	Data 0.00108 (0.00170)	Tok/s 68349 (74296)	Loss/tok 3.1439 (3.1768)	Learning Rate [7.8125e-05]
0: TRAIN [3][5830/6832]	Time 0.477 (0.346)	Data 0.00103 (0.00170)	Tok/s 80238 (74294)	Loss/tok 3.1623 (3.1766)	Learning Rate [7.8125e-05]
0: TRAIN [3][5840/6832]	Time 0.486 (0.346)	Data 0.00115 (0.00170)	Tok/s 77527 (74291)	Loss/tok 3.1083 (3.1764)	Learning Rate [7.8125e-05]
0: TRAIN [3][5850/6832]	Time 0.442 (0.346)	Data 0.00112 (0.00170)	Tok/s 65362 (74287)	Loss/tok 3.1164 (3.1763)	Learning Rate [7.8125e-05]
0: TRAIN [3][5860/6832]	Time 0.435 (0.346)	Data 0.00129 (0.00170)	Tok/s 67533 (74295)	Loss/tok 3.1102 (3.1760)	Learning Rate [7.8125e-05]
0: TRAIN [3][5870/6832]	Time 0.123 (0.346)	Data 0.00108 (0.00170)	Tok/s 78326 (74295)	Loss/tok 2.5366 (3.1758)	Learning Rate [7.8125e-05]
0: TRAIN [3][5880/6832]	Time 0.300 (0.346)	Data 0.00112 (0.00170)	Tok/s 69864 (74296)	Loss/tok 3.1221 (3.1756)	Learning Rate [7.8125e-05]
0: TRAIN [3][5890/6832]	Time 0.474 (0.346)	Data 0.00103 (0.00170)	Tok/s 71340 (74294)	Loss/tok 3.2131 (3.1754)	Learning Rate [7.8125e-05]
0: TRAIN [3][5900/6832]	Time 0.479 (0.346)	Data 0.00115 (0.00170)	Tok/s 70401 (74291)	Loss/tok 3.2019 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [3][5910/6832]	Time 0.466 (0.346)	Data 0.00144 (0.00170)	Tok/s 92761 (74294)	Loss/tok 3.0021 (3.1750)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][5920/6832]	Time 0.487 (0.346)	Data 0.00112 (0.00169)	Tok/s 74931 (74300)	Loss/tok 3.1776 (3.1748)	Learning Rate [7.8125e-05]
0: TRAIN [3][5930/6832]	Time 0.337 (0.346)	Data 0.00102 (0.00169)	Tok/s 69406 (74294)	Loss/tok 3.1241 (3.1746)	Learning Rate [7.8125e-05]
0: TRAIN [3][5940/6832]	Time 0.480 (0.346)	Data 0.00101 (0.00169)	Tok/s 89774 (74302)	Loss/tok 3.1078 (3.1744)	Learning Rate [7.8125e-05]
0: TRAIN [3][5950/6832]	Time 0.479 (0.346)	Data 0.00106 (0.00169)	Tok/s 72788 (74304)	Loss/tok 3.1761 (3.1742)	Learning Rate [7.8125e-05]
0: TRAIN [3][5960/6832]	Time 0.273 (0.346)	Data 0.00111 (0.00169)	Tok/s 73043 (74302)	Loss/tok 2.9177 (3.1740)	Learning Rate [7.8125e-05]
0: TRAIN [3][5970/6832]	Time 0.285 (0.346)	Data 0.00101 (0.00169)	Tok/s 71529 (74301)	Loss/tok 2.9920 (3.1737)	Learning Rate [7.8125e-05]
0: TRAIN [3][5980/6832]	Time 0.479 (0.346)	Data 0.00105 (0.00169)	Tok/s 67930 (74298)	Loss/tok 3.1654 (3.1735)	Learning Rate [7.8125e-05]
0: TRAIN [3][5990/6832]	Time 0.489 (0.346)	Data 0.00111 (0.00169)	Tok/s 79906 (74304)	Loss/tok 3.1433 (3.1733)	Learning Rate [7.8125e-05]
0: TRAIN [3][6000/6832]	Time 0.481 (0.346)	Data 0.00101 (0.00169)	Tok/s 75684 (74305)	Loss/tok 3.2139 (3.1731)	Learning Rate [7.8125e-05]
0: TRAIN [3][6010/6832]	Time 0.138 (0.346)	Data 0.00107 (0.00168)	Tok/s 80925 (74302)	Loss/tok 2.6638 (3.1730)	Learning Rate [7.8125e-05]
0: TRAIN [3][6020/6832]	Time 0.480 (0.346)	Data 0.00103 (0.00168)	Tok/s 69314 (74302)	Loss/tok 3.2860 (3.1730)	Learning Rate [7.8125e-05]
0: TRAIN [3][6030/6832]	Time 0.349 (0.346)	Data 0.00103 (0.00168)	Tok/s 69025 (74298)	Loss/tok 3.1218 (3.1729)	Learning Rate [7.8125e-05]
0: TRAIN [3][6040/6832]	Time 0.458 (0.346)	Data 0.00111 (0.00168)	Tok/s 74715 (74300)	Loss/tok 3.1956 (3.1728)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][6050/6832]	Time 0.463 (0.347)	Data 0.00106 (0.00168)	Tok/s 64371 (74305)	Loss/tok 3.2437 (3.1728)	Learning Rate [7.8125e-05]
0: TRAIN [3][6060/6832]	Time 0.487 (0.347)	Data 0.00098 (0.00168)	Tok/s 88281 (74311)	Loss/tok 3.1538 (3.1728)	Learning Rate [7.8125e-05]
0: TRAIN [3][6070/6832]	Time 0.219 (0.347)	Data 0.00108 (0.00168)	Tok/s 76990 (74316)	Loss/tok 2.9187 (3.1727)	Learning Rate [7.8125e-05]
0: TRAIN [3][6080/6832]	Time 0.146 (0.347)	Data 0.00102 (0.00168)	Tok/s 81980 (74315)	Loss/tok 2.6815 (3.1726)	Learning Rate [7.8125e-05]
0: TRAIN [3][6090/6832]	Time 0.478 (0.347)	Data 0.00130 (0.00168)	Tok/s 65650 (74316)	Loss/tok 3.2146 (3.1725)	Learning Rate [7.8125e-05]
0: TRAIN [3][6100/6832]	Time 0.485 (0.347)	Data 0.00104 (0.00168)	Tok/s 80462 (74319)	Loss/tok 3.1186 (3.1723)	Learning Rate [7.8125e-05]
0: TRAIN [3][6110/6832]	Time 0.457 (0.347)	Data 0.00109 (0.00167)	Tok/s 63079 (74316)	Loss/tok 3.2101 (3.1723)	Learning Rate [7.8125e-05]
0: TRAIN [3][6120/6832]	Time 0.480 (0.347)	Data 0.00102 (0.00167)	Tok/s 74609 (74311)	Loss/tok 3.1556 (3.1722)	Learning Rate [7.8125e-05]
0: TRAIN [3][6130/6832]	Time 0.154 (0.347)	Data 0.00102 (0.00167)	Tok/s 68309 (74306)	Loss/tok 2.5625 (3.1721)	Learning Rate [7.8125e-05]
0: TRAIN [3][6140/6832]	Time 0.467 (0.347)	Data 0.00106 (0.00167)	Tok/s 68611 (74303)	Loss/tok 3.2813 (3.1720)	Learning Rate [7.8125e-05]
0: TRAIN [3][6150/6832]	Time 0.456 (0.347)	Data 0.00109 (0.00167)	Tok/s 75393 (74302)	Loss/tok 3.2476 (3.1721)	Learning Rate [7.8125e-05]
0: TRAIN [3][6160/6832]	Time 0.486 (0.347)	Data 0.00107 (0.00167)	Tok/s 88570 (74301)	Loss/tok 3.0981 (3.1721)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][6170/6832]	Time 0.374 (0.347)	Data 0.00117 (0.00167)	Tok/s 65590 (74301)	Loss/tok 3.1220 (3.1719)	Learning Rate [7.8125e-05]
0: TRAIN [3][6180/6832]	Time 0.445 (0.347)	Data 0.00102 (0.00167)	Tok/s 66748 (74301)	Loss/tok 3.2755 (3.1719)	Learning Rate [7.8125e-05]
0: TRAIN [3][6190/6832]	Time 0.465 (0.347)	Data 0.00109 (0.00167)	Tok/s 64888 (74296)	Loss/tok 3.1301 (3.1718)	Learning Rate [7.8125e-05]
0: TRAIN [3][6200/6832]	Time 0.203 (0.347)	Data 0.00101 (0.00167)	Tok/s 72590 (74292)	Loss/tok 2.8951 (3.1717)	Learning Rate [7.8125e-05]
0: TRAIN [3][6210/6832]	Time 0.242 (0.347)	Data 0.00099 (0.00167)	Tok/s 73933 (74291)	Loss/tok 2.9912 (3.1716)	Learning Rate [7.8125e-05]
0: TRAIN [3][6220/6832]	Time 0.485 (0.347)	Data 0.00103 (0.00166)	Tok/s 78751 (74293)	Loss/tok 3.1979 (3.1715)	Learning Rate [7.8125e-05]
0: TRAIN [3][6230/6832]	Time 0.301 (0.347)	Data 0.00102 (0.00166)	Tok/s 71066 (74297)	Loss/tok 3.1108 (3.1713)	Learning Rate [7.8125e-05]
0: TRAIN [3][6240/6832]	Time 0.224 (0.347)	Data 0.00100 (0.00166)	Tok/s 77791 (74296)	Loss/tok 3.0196 (3.1712)	Learning Rate [7.8125e-05]
0: TRAIN [3][6250/6832]	Time 0.410 (0.347)	Data 0.00111 (0.00166)	Tok/s 65791 (74290)	Loss/tok 3.1860 (3.1710)	Learning Rate [7.8125e-05]
0: TRAIN [3][6260/6832]	Time 0.411 (0.347)	Data 0.00102 (0.00166)	Tok/s 67435 (74290)	Loss/tok 3.1337 (3.1710)	Learning Rate [7.8125e-05]
0: TRAIN [3][6270/6832]	Time 0.480 (0.347)	Data 0.00109 (0.00166)	Tok/s 87978 (74293)	Loss/tok 3.1795 (3.1709)	Learning Rate [7.8125e-05]
0: TRAIN [3][6280/6832]	Time 0.210 (0.347)	Data 0.00105 (0.00166)	Tok/s 75746 (74292)	Loss/tok 2.9576 (3.1709)	Learning Rate [7.8125e-05]
0: TRAIN [3][6290/6832]	Time 0.485 (0.347)	Data 0.00115 (0.00166)	Tok/s 88606 (74295)	Loss/tok 3.1279 (3.1708)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][6300/6832]	Time 0.311 (0.347)	Data 0.00112 (0.00166)	Tok/s 69304 (74292)	Loss/tok 3.0334 (3.1707)	Learning Rate [7.8125e-05]
0: TRAIN [3][6310/6832]	Time 0.235 (0.347)	Data 0.00022 (0.00166)	Tok/s 76343 (74292)	Loss/tok 2.9286 (3.1706)	Learning Rate [7.8125e-05]
0: TRAIN [3][6320/6832]	Time 0.347 (0.347)	Data 0.00107 (0.00166)	Tok/s 69864 (74292)	Loss/tok 3.1906 (3.1706)	Learning Rate [7.8125e-05]
0: TRAIN [3][6330/6832]	Time 0.182 (0.347)	Data 0.00104 (0.00165)	Tok/s 79196 (74296)	Loss/tok 2.8971 (3.1704)	Learning Rate [7.8125e-05]
0: TRAIN [3][6340/6832]	Time 0.278 (0.347)	Data 0.00104 (0.00165)	Tok/s 73683 (74294)	Loss/tok 3.0462 (3.1702)	Learning Rate [7.8125e-05]
0: TRAIN [3][6350/6832]	Time 0.342 (0.347)	Data 0.00111 (0.00165)	Tok/s 70354 (74293)	Loss/tok 3.1547 (3.1702)	Learning Rate [7.8125e-05]
0: TRAIN [3][6360/6832]	Time 0.120 (0.347)	Data 0.00099 (0.00165)	Tok/s 80547 (74292)	Loss/tok 2.5381 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [3][6370/6832]	Time 0.284 (0.347)	Data 0.00102 (0.00165)	Tok/s 72391 (74290)	Loss/tok 3.0660 (3.1700)	Learning Rate [7.8125e-05]
0: TRAIN [3][6380/6832]	Time 0.476 (0.347)	Data 0.00103 (0.00165)	Tok/s 73184 (74292)	Loss/tok 3.2566 (3.1700)	Learning Rate [7.8125e-05]
0: TRAIN [3][6390/6832]	Time 0.277 (0.347)	Data 0.00107 (0.00165)	Tok/s 73734 (74292)	Loss/tok 3.0822 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [3][6400/6832]	Time 0.417 (0.347)	Data 0.00103 (0.00165)	Tok/s 66574 (74293)	Loss/tok 3.2008 (3.1697)	Learning Rate [7.8125e-05]
0: TRAIN [3][6410/6832]	Time 0.434 (0.347)	Data 0.00111 (0.00165)	Tok/s 68441 (74296)	Loss/tok 3.1538 (3.1697)	Learning Rate [7.8125e-05]
0: TRAIN [3][6420/6832]	Time 0.429 (0.347)	Data 0.00112 (0.00165)	Tok/s 65805 (74298)	Loss/tok 3.1440 (3.1696)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][6430/6832]	Time 0.316 (0.347)	Data 0.00108 (0.00165)	Tok/s 70825 (74295)	Loss/tok 3.1207 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][6440/6832]	Time 0.423 (0.347)	Data 0.00110 (0.00164)	Tok/s 68107 (74290)	Loss/tok 3.1803 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [3][6450/6832]	Time 0.275 (0.347)	Data 0.00100 (0.00164)	Tok/s 71045 (74289)	Loss/tok 3.0185 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [3][6460/6832]	Time 0.421 (0.347)	Data 0.00107 (0.00164)	Tok/s 67923 (74288)	Loss/tok 3.2522 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [3][6470/6832]	Time 0.196 (0.347)	Data 0.00102 (0.00164)	Tok/s 77777 (74284)	Loss/tok 2.9755 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [3][6480/6832]	Time 0.484 (0.347)	Data 0.00101 (0.00164)	Tok/s 87262 (74286)	Loss/tok 3.2303 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6490/6832]	Time 0.479 (0.347)	Data 0.00104 (0.00164)	Tok/s 72552 (74286)	Loss/tok 3.1060 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6500/6832]	Time 0.297 (0.347)	Data 0.00104 (0.00164)	Tok/s 69827 (74281)	Loss/tok 3.0392 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6510/6832]	Time 0.259 (0.347)	Data 0.00108 (0.00164)	Tok/s 75195 (74277)	Loss/tok 3.0760 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6520/6832]	Time 0.226 (0.347)	Data 0.00105 (0.00164)	Tok/s 74384 (74280)	Loss/tok 2.9334 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6530/6832]	Time 0.466 (0.347)	Data 0.00115 (0.00164)	Tok/s 65702 (74272)	Loss/tok 3.3078 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6540/6832]	Time 0.112 (0.347)	Data 0.00100 (0.00164)	Tok/s 74173 (74275)	Loss/tok 2.3224 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6550/6832]	Time 0.374 (0.347)	Data 0.00104 (0.00163)	Tok/s 66468 (74267)	Loss/tok 3.1994 (3.1689)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][6560/6832]	Time 0.332 (0.347)	Data 0.00104 (0.00163)	Tok/s 69370 (74269)	Loss/tok 3.2475 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6570/6832]	Time 0.297 (0.347)	Data 0.00132 (0.00163)	Tok/s 70450 (74266)	Loss/tok 3.2634 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6580/6832]	Time 0.430 (0.347)	Data 0.00103 (0.00163)	Tok/s 65595 (74265)	Loss/tok 3.2755 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6590/6832]	Time 0.461 (0.347)	Data 0.00110 (0.00163)	Tok/s 67139 (74259)	Loss/tok 3.2612 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][6600/6832]	Time 0.453 (0.347)	Data 0.00103 (0.00163)	Tok/s 65809 (74258)	Loss/tok 3.2505 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][6610/6832]	Time 0.483 (0.347)	Data 0.00109 (0.00163)	Tok/s 93455 (74263)	Loss/tok 3.0474 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [3][6620/6832]	Time 0.165 (0.347)	Data 0.00102 (0.00163)	Tok/s 76188 (74262)	Loss/tok 2.8415 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6630/6832]	Time 0.165 (0.347)	Data 0.00119 (0.00163)	Tok/s 78840 (74257)	Loss/tok 2.8038 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6640/6832]	Time 0.428 (0.347)	Data 0.00107 (0.00163)	Tok/s 68547 (74259)	Loss/tok 3.2524 (3.1690)	Learning Rate [7.8125e-05]
0: TRAIN [3][6650/6832]	Time 0.166 (0.347)	Data 0.00102 (0.00163)	Tok/s 78055 (74260)	Loss/tok 2.8074 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6660/6832]	Time 0.480 (0.347)	Data 0.00104 (0.00162)	Tok/s 91977 (74264)	Loss/tok 3.1390 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6670/6832]	Time 0.482 (0.347)	Data 0.00102 (0.00162)	Tok/s 68140 (74257)	Loss/tok 3.2861 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6680/6832]	Time 0.265 (0.347)	Data 0.00111 (0.00162)	Tok/s 69900 (74257)	Loss/tok 3.0631 (3.1689)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][6690/6832]	Time 0.388 (0.347)	Data 0.00106 (0.00162)	Tok/s 66542 (74260)	Loss/tok 3.2195 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6700/6832]	Time 0.485 (0.347)	Data 0.00104 (0.00162)	Tok/s 82054 (74257)	Loss/tok 3.1964 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6710/6832]	Time 0.139 (0.347)	Data 0.00113 (0.00162)	Tok/s 80763 (74254)	Loss/tok 2.6957 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [3][6720/6832]	Time 0.485 (0.347)	Data 0.00130 (0.00162)	Tok/s 85282 (74260)	Loss/tok 3.1623 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6730/6832]	Time 0.320 (0.347)	Data 0.00110 (0.00162)	Tok/s 69871 (74263)	Loss/tok 3.1175 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6740/6832]	Time 0.469 (0.347)	Data 0.00113 (0.00162)	Tok/s 76163 (74265)	Loss/tok 3.2363 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][6750/6832]	Time 0.282 (0.347)	Data 0.00102 (0.00162)	Tok/s 72886 (74272)	Loss/tok 3.1089 (3.1686)	Learning Rate [7.8125e-05]
0: TRAIN [3][6760/6832]	Time 0.407 (0.347)	Data 0.00104 (0.00162)	Tok/s 66226 (74269)	Loss/tok 3.2149 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][6770/6832]	Time 0.456 (0.347)	Data 0.00104 (0.00162)	Tok/s 66294 (74262)	Loss/tok 3.2979 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][6780/6832]	Time 0.167 (0.347)	Data 0.00103 (0.00162)	Tok/s 82812 (74264)	Loss/tok 2.9431 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][6790/6832]	Time 0.114 (0.347)	Data 0.00113 (0.00161)	Tok/s 74057 (74258)	Loss/tok 2.4659 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [3][6800/6832]	Time 0.302 (0.347)	Data 0.00111 (0.00161)	Tok/s 73817 (74254)	Loss/tok 3.1076 (3.1688)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [3][6810/6832]	Time 0.466 (0.347)	Data 0.00126 (0.00161)	Tok/s 92394 (74261)	Loss/tok 3.1517 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6820/6832]	Time 0.480 (0.347)	Data 0.00098 (0.00161)	Tok/s 78248 (74266)	Loss/tok 3.3283 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [3][6830/6832]	Time 0.484 (0.347)	Data 0.00094 (0.00162)	Tok/s 75247 (74269)	Loss/tok 3.2732 (3.1688)	Learning Rate [7.8125e-05]
0: Running validation on dev set
0: VALIDATION [3][0/80]	Time 0.064 (0.000)	Data 0.00221 (0.00000)	Tok/s 159662 (0)	Loss/tok 3.3467 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [3][10/80]	Time 0.026 (0.031)	Data 0.00173 (0.00182)	Tok/s 217561 (216502)	Loss/tok 3.1206 (3.2220)	Learning Rate [7.8125e-05]
0: VALIDATION [3][20/80]	Time 0.022 (0.027)	Data 0.00167 (0.00178)	Tok/s 210369 (215673)	Loss/tok 3.1142 (3.1976)	Learning Rate [7.8125e-05]
0: VALIDATION [3][30/80]	Time 0.019 (0.025)	Data 0.00167 (0.00174)	Tok/s 194536 (214996)	Loss/tok 3.1638 (3.1713)	Learning Rate [7.8125e-05]
0: VALIDATION [3][40/80]	Time 0.015 (0.023)	Data 0.00158 (0.00171)	Tok/s 205410 (211744)	Loss/tok 3.1191 (3.1557)	Learning Rate [7.8125e-05]
0: VALIDATION [3][50/80]	Time 0.014 (0.021)	Data 0.00156 (0.00169)	Tok/s 190777 (208428)	Loss/tok 2.9607 (3.1404)	Learning Rate [7.8125e-05]
0: VALIDATION [3][60/80]	Time 0.015 (0.020)	Data 0.00155 (0.00167)	Tok/s 143168 (203067)	Loss/tok 3.1988 (3.1349)	Learning Rate [7.8125e-05]
0: VALIDATION [3][70/80]	Time 0.014 (0.019)	Data 0.00153 (0.00165)	Tok/s 111648 (192024)	Loss/tok 3.0349 (3.1279)	Learning Rate [7.8125e-05]
:::MLPv0.5.0 gnmt 1560843839.475121260 (train.py:459) eval_start: 3
0: Running evaluation on test set
0: TEST [3][0/6]	Time 2.071 (2.071)	Decoder iters 149.0 (149.0)	Tok/s 14356 (14356)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560843854.445973396 (train.py:464) eval_accuracy: {"epoch": 3, "value": 21.729999542236328}
:::MLPv0.5.0 gnmt 1560843854.446554422 (train.py:466) eval_target: 21.8
:::MLPv0.5.0 gnmt 1560843854.447076321 (train.py:467) eval_stop
0: Summary: Epoch: 3	Training Loss: 3.1688	Validation Loss: 3.1186	Test BLEU: 21.73
0: Performance: Epoch: 3	Training: 74270 Tok/s	Validation: 181282 Tok/s
0: Finished epoch 3
0: Starting epoch 4
:::MLPv0.5.0 gnmt 1560843854.448043823 (train.py:443) train_epoch: 4
/opt/conda/lib/python3.6/site-packages/torch/nn/modules/rnn.py:182: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().
  self.num_layers, self.dropout, self.training, self.bidirectional)
:::MLPv0.5.0 gnmt 1560843855.051449060 (seq2seq/data/sampler.py:47) input_order
0: Sampler for epoch 0 uses seed 2037452816
:::MLPv0.5.0 gnmt 1560843855.135061026 (seq2seq/data/sampler.py:66) input_shard: 40960
0: TRAIN [4][0/6832]	Time 1.196 (0.000)	Data 0.90261 (0.00000)	Tok/s 18407 (0)	Loss/tok 3.1364 (0.0000)	Learning Rate [7.8125e-05]
0: TRAIN [4][10/6832]	Time 0.484 (0.346)	Data 0.00131 (0.00123)	Tok/s 96293 (75086)	Loss/tok 3.0316 (3.1644)	Learning Rate [7.8125e-05]
0: TRAIN [4][20/6832]	Time 0.377 (0.360)	Data 0.00138 (0.00130)	Tok/s 67849 (72589)	Loss/tok 3.2166 (3.1825)	Learning Rate [7.8125e-05]
0: TRAIN [4][30/6832]	Time 0.230 (0.337)	Data 0.00114 (0.00128)	Tok/s 71362 (73236)	Loss/tok 2.9553 (3.1721)	Learning Rate [7.8125e-05]
0: TRAIN [4][40/6832]	Time 0.483 (0.334)	Data 0.00119 (0.00128)	Tok/s 79102 (74544)	Loss/tok 3.1886 (3.1512)	Learning Rate [7.8125e-05]
0: TRAIN [4][50/6832]	Time 0.283 (0.330)	Data 0.00127 (0.00126)	Tok/s 70559 (74912)	Loss/tok 3.1102 (3.1454)	Learning Rate [7.8125e-05]
0: TRAIN [4][60/6832]	Time 0.346 (0.325)	Data 0.00098 (0.00124)	Tok/s 69596 (74163)	Loss/tok 3.1924 (3.1465)	Learning Rate [7.8125e-05]
0: TRAIN [4][70/6832]	Time 0.473 (0.321)	Data 0.00103 (0.00121)	Tok/s 72352 (74491)	Loss/tok 3.3286 (3.1444)	Learning Rate [7.8125e-05]
0: TRAIN [4][80/6832]	Time 0.110 (0.328)	Data 0.00098 (0.00119)	Tok/s 76395 (74163)	Loss/tok 2.3932 (3.1528)	Learning Rate [7.8125e-05]
0: TRAIN [4][90/6832]	Time 0.164 (0.326)	Data 0.00104 (0.00118)	Tok/s 78660 (74695)	Loss/tok 2.7930 (3.1426)	Learning Rate [7.8125e-05]
0: TRAIN [4][100/6832]	Time 0.321 (0.328)	Data 0.00095 (0.00116)	Tok/s 73569 (74649)	Loss/tok 3.1527 (3.1442)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][110/6832]	Time 0.482 (0.339)	Data 0.00105 (0.01113)	Tok/s 72971 (73880)	Loss/tok 3.2317 (3.1428)	Learning Rate [7.8125e-05]
0: TRAIN [4][120/6832]	Time 0.220 (0.342)	Data 0.00100 (0.01029)	Tok/s 74313 (73956)	Loss/tok 3.0333 (3.1478)	Learning Rate [7.8125e-05]
0: TRAIN [4][130/6832]	Time 0.320 (0.339)	Data 0.00099 (0.00957)	Tok/s 70420 (73991)	Loss/tok 3.1726 (3.1485)	Learning Rate [7.8125e-05]
0: TRAIN [4][140/6832]	Time 0.344 (0.337)	Data 0.00121 (0.00897)	Tok/s 68858 (73810)	Loss/tok 3.2164 (3.1485)	Learning Rate [7.8125e-05]
0: TRAIN [4][150/6832]	Time 0.467 (0.341)	Data 0.00108 (0.00844)	Tok/s 71538 (73621)	Loss/tok 3.2571 (3.1545)	Learning Rate [7.8125e-05]
0: TRAIN [4][160/6832]	Time 0.472 (0.341)	Data 0.00099 (0.00798)	Tok/s 71294 (73704)	Loss/tok 3.2528 (3.1543)	Learning Rate [7.8125e-05]
0: TRAIN [4][170/6832]	Time 0.148 (0.346)	Data 0.00101 (0.00757)	Tok/s 84612 (73753)	Loss/tok 2.8133 (3.1602)	Learning Rate [7.8125e-05]
0: TRAIN [4][180/6832]	Time 0.425 (0.346)	Data 0.00102 (0.00720)	Tok/s 68113 (73653)	Loss/tok 3.3006 (3.1637)	Learning Rate [7.8125e-05]
0: TRAIN [4][190/6832]	Time 0.313 (0.346)	Data 0.00101 (0.00688)	Tok/s 69101 (73686)	Loss/tok 3.1576 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [4][200/6832]	Time 0.480 (0.349)	Data 0.00102 (0.00659)	Tok/s 97122 (74022)	Loss/tok 3.1127 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [4][210/6832]	Time 0.456 (0.349)	Data 0.00103 (0.00633)	Tok/s 106968 (74304)	Loss/tok 3.0708 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [4][220/6832]	Time 0.417 (0.350)	Data 0.00101 (0.00609)	Tok/s 65599 (74337)	Loss/tok 3.2225 (3.1668)	Learning Rate [7.8125e-05]
0: TRAIN [4][230/6832]	Time 0.308 (0.350)	Data 0.00101 (0.00587)	Tok/s 71497 (74373)	Loss/tok 3.1112 (3.1663)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][240/6832]	Time 0.140 (0.350)	Data 0.00102 (0.00637)	Tok/s 81765 (74185)	Loss/tok 2.6528 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [4][250/6832]	Time 0.314 (0.348)	Data 0.00099 (0.00616)	Tok/s 71935 (74173)	Loss/tok 3.1389 (3.1683)	Learning Rate [7.8125e-05]
0: TRAIN [4][260/6832]	Time 0.397 (0.348)	Data 0.00106 (0.00596)	Tok/s 65891 (73994)	Loss/tok 3.1955 (3.1700)	Learning Rate [7.8125e-05]
0: TRAIN [4][270/6832]	Time 0.485 (0.346)	Data 0.00103 (0.00578)	Tok/s 100208 (73998)	Loss/tok 3.0606 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [4][280/6832]	Time 0.223 (0.345)	Data 0.00100 (0.00562)	Tok/s 75054 (73968)	Loss/tok 2.9268 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [4][290/6832]	Time 0.431 (0.346)	Data 0.00111 (0.00546)	Tok/s 66523 (73823)	Loss/tok 3.3492 (3.1733)	Learning Rate [7.8125e-05]
0: TRAIN [4][300/6832]	Time 0.336 (0.345)	Data 0.00101 (0.00531)	Tok/s 71558 (73805)	Loss/tok 3.2219 (3.1734)	Learning Rate [7.8125e-05]
0: TRAIN [4][310/6832]	Time 0.359 (0.346)	Data 0.00102 (0.00517)	Tok/s 68204 (73882)	Loss/tok 3.2790 (3.1767)	Learning Rate [7.8125e-05]
0: TRAIN [4][320/6832]	Time 0.483 (0.347)	Data 0.00105 (0.00505)	Tok/s 79659 (74138)	Loss/tok 3.2141 (3.1757)	Learning Rate [7.8125e-05]
0: TRAIN [4][330/6832]	Time 0.195 (0.348)	Data 0.00110 (0.00493)	Tok/s 77762 (74265)	Loss/tok 3.0617 (3.1760)	Learning Rate [7.8125e-05]
0: TRAIN [4][340/6832]	Time 0.395 (0.349)	Data 0.00101 (0.00481)	Tok/s 70078 (74233)	Loss/tok 3.2500 (3.1784)	Learning Rate [7.8125e-05]
0: TRAIN [4][350/6832]	Time 0.390 (0.349)	Data 0.00098 (0.00470)	Tok/s 69230 (74185)	Loss/tok 3.2656 (3.1790)	Learning Rate [7.8125e-05]
0: TRAIN [4][360/6832]	Time 0.383 (0.348)	Data 0.00106 (0.00460)	Tok/s 66884 (74375)	Loss/tok 3.3042 (3.1773)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][370/6832]	Time 0.227 (0.349)	Data 0.00024 (0.00451)	Tok/s 75341 (74364)	Loss/tok 3.0376 (3.1785)	Learning Rate [7.8125e-05]
0: TRAIN [4][380/6832]	Time 0.465 (0.349)	Data 0.00103 (0.00442)	Tok/s 95061 (74419)	Loss/tok 3.1095 (3.1782)	Learning Rate [7.8125e-05]
0: TRAIN [4][390/6832]	Time 0.463 (0.349)	Data 0.00112 (0.00434)	Tok/s 66261 (74363)	Loss/tok 3.2622 (3.1784)	Learning Rate [7.8125e-05]
0: TRAIN [4][400/6832]	Time 0.396 (0.348)	Data 0.00108 (0.00426)	Tok/s 68256 (74325)	Loss/tok 3.2572 (3.1790)	Learning Rate [7.8125e-05]
0: TRAIN [4][410/6832]	Time 0.180 (0.347)	Data 0.00104 (0.00418)	Tok/s 77228 (74283)	Loss/tok 2.9563 (3.1789)	Learning Rate [7.8125e-05]
0: TRAIN [4][420/6832]	Time 0.100 (0.347)	Data 0.00101 (0.00411)	Tok/s 57620 (74250)	Loss/tok 2.0360 (3.1797)	Learning Rate [7.8125e-05]
0: TRAIN [4][430/6832]	Time 0.487 (0.348)	Data 0.00109 (0.00404)	Tok/s 84942 (74223)	Loss/tok 3.2262 (3.1809)	Learning Rate [7.8125e-05]
0: TRAIN [4][440/6832]	Time 0.298 (0.349)	Data 0.00109 (0.00397)	Tok/s 70411 (74275)	Loss/tok 3.1385 (3.1816)	Learning Rate [7.8125e-05]
0: TRAIN [4][450/6832]	Time 0.284 (0.349)	Data 0.00101 (0.00391)	Tok/s 73006 (74342)	Loss/tok 3.1369 (3.1807)	Learning Rate [7.8125e-05]
0: TRAIN [4][460/6832]	Time 0.477 (0.350)	Data 0.00122 (0.00385)	Tok/s 70615 (74290)	Loss/tok 3.3548 (3.1820)	Learning Rate [7.8125e-05]
0: TRAIN [4][470/6832]	Time 0.245 (0.351)	Data 0.00107 (0.00379)	Tok/s 75219 (74300)	Loss/tok 3.1022 (3.1830)	Learning Rate [7.8125e-05]
0: TRAIN [4][480/6832]	Time 0.111 (0.350)	Data 0.00105 (0.00373)	Tok/s 75926 (74322)	Loss/tok 2.4133 (3.1822)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][490/6832]	Time 0.455 (0.351)	Data 0.00129 (0.00368)	Tok/s 72934 (74399)	Loss/tok 3.3029 (3.1831)	Learning Rate [7.8125e-05]
0: TRAIN [4][500/6832]	Time 0.480 (0.351)	Data 0.00106 (0.00363)	Tok/s 67463 (74288)	Loss/tok 3.3073 (3.1843)	Learning Rate [7.8125e-05]
0: TRAIN [4][510/6832]	Time 0.406 (0.351)	Data 0.00111 (0.00358)	Tok/s 68125 (74264)	Loss/tok 3.1511 (3.1844)	Learning Rate [7.8125e-05]
0: TRAIN [4][520/6832]	Time 0.473 (0.352)	Data 0.00104 (0.00353)	Tok/s 73198 (74254)	Loss/tok 3.3258 (3.1845)	Learning Rate [7.8125e-05]
0: TRAIN [4][530/6832]	Time 0.304 (0.352)	Data 0.00112 (0.00348)	Tok/s 70653 (74240)	Loss/tok 3.2145 (3.1854)	Learning Rate [7.8125e-05]
0: TRAIN [4][540/6832]	Time 0.416 (0.351)	Data 0.00107 (0.00344)	Tok/s 65592 (74227)	Loss/tok 3.3952 (3.1849)	Learning Rate [7.8125e-05]
0: TRAIN [4][550/6832]	Time 0.233 (0.350)	Data 0.00106 (0.00340)	Tok/s 70368 (74182)	Loss/tok 3.0247 (3.1839)	Learning Rate [7.8125e-05]
0: TRAIN [4][560/6832]	Time 0.243 (0.350)	Data 0.00109 (0.00336)	Tok/s 73774 (74175)	Loss/tok 3.0621 (3.1841)	Learning Rate [7.8125e-05]
0: TRAIN [4][570/6832]	Time 0.465 (0.351)	Data 0.00104 (0.00332)	Tok/s 65703 (74204)	Loss/tok 3.3084 (3.1841)	Learning Rate [7.8125e-05]
0: TRAIN [4][580/6832]	Time 0.404 (0.351)	Data 0.00104 (0.00328)	Tok/s 66614 (74209)	Loss/tok 3.2299 (3.1837)	Learning Rate [7.8125e-05]
0: TRAIN [4][590/6832]	Time 0.133 (0.351)	Data 0.00108 (0.00324)	Tok/s 84852 (74213)	Loss/tok 2.6946 (3.1840)	Learning Rate [7.8125e-05]
0: TRAIN [4][600/6832]	Time 0.484 (0.351)	Data 0.00113 (0.00321)	Tok/s 78143 (74223)	Loss/tok 3.3938 (3.1847)	Learning Rate [7.8125e-05]
0: TRAIN [4][610/6832]	Time 0.322 (0.352)	Data 0.00105 (0.00317)	Tok/s 71628 (74267)	Loss/tok 3.1535 (3.1845)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][620/6832]	Time 0.473 (0.353)	Data 0.00106 (0.00314)	Tok/s 76156 (74233)	Loss/tok 3.3612 (3.1852)	Learning Rate [7.8125e-05]
0: TRAIN [4][630/6832]	Time 0.422 (0.352)	Data 0.00159 (0.00311)	Tok/s 69171 (74215)	Loss/tok 3.2153 (3.1852)	Learning Rate [7.8125e-05]
0: TRAIN [4][640/6832]	Time 0.286 (0.351)	Data 0.00106 (0.00308)	Tok/s 70794 (74197)	Loss/tok 3.2193 (3.1848)	Learning Rate [7.8125e-05]
0: TRAIN [4][650/6832]	Time 0.464 (0.352)	Data 0.00106 (0.00305)	Tok/s 69680 (74212)	Loss/tok 3.2976 (3.1856)	Learning Rate [7.8125e-05]
0: TRAIN [4][660/6832]	Time 0.239 (0.352)	Data 0.00104 (0.00302)	Tok/s 71815 (74279)	Loss/tok 3.0321 (3.1859)	Learning Rate [7.8125e-05]
0: TRAIN [4][670/6832]	Time 0.308 (0.352)	Data 0.00105 (0.00299)	Tok/s 71389 (74275)	Loss/tok 3.1954 (3.1857)	Learning Rate [7.8125e-05]
0: TRAIN [4][680/6832]	Time 0.484 (0.352)	Data 0.00103 (0.00296)	Tok/s 81830 (74300)	Loss/tok 3.2838 (3.1854)	Learning Rate [7.8125e-05]
0: TRAIN [4][690/6832]	Time 0.405 (0.352)	Data 0.00100 (0.00293)	Tok/s 64620 (74358)	Loss/tok 3.3099 (3.1851)	Learning Rate [7.8125e-05]
0: TRAIN [4][700/6832]	Time 0.485 (0.352)	Data 0.00102 (0.00290)	Tok/s 79407 (74355)	Loss/tok 3.4058 (3.1854)	Learning Rate [7.8125e-05]
0: TRAIN [4][710/6832]	Time 0.282 (0.352)	Data 0.00104 (0.00288)	Tok/s 71930 (74393)	Loss/tok 3.1405 (3.1857)	Learning Rate [7.8125e-05]
0: TRAIN [4][720/6832]	Time 0.205 (0.352)	Data 0.00107 (0.00285)	Tok/s 76479 (74371)	Loss/tok 2.9951 (3.1860)	Learning Rate [7.8125e-05]
0: TRAIN [4][730/6832]	Time 0.358 (0.351)	Data 0.00103 (0.00283)	Tok/s 67249 (74379)	Loss/tok 3.2595 (3.1854)	Learning Rate [7.8125e-05]
0: TRAIN [4][740/6832]	Time 0.238 (0.351)	Data 0.00107 (0.00281)	Tok/s 73200 (74393)	Loss/tok 3.0420 (3.1857)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][750/6832]	Time 0.485 (0.351)	Data 0.00105 (0.00278)	Tok/s 96156 (74342)	Loss/tok 3.1279 (3.1860)	Learning Rate [7.8125e-05]
0: TRAIN [4][760/6832]	Time 0.161 (0.352)	Data 0.00106 (0.00276)	Tok/s 77457 (74327)	Loss/tok 2.7946 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [4][770/6832]	Time 0.478 (0.352)	Data 0.00132 (0.00300)	Tok/s 68465 (74322)	Loss/tok 3.2827 (3.1868)	Learning Rate [7.8125e-05]
0: TRAIN [4][780/6832]	Time 0.478 (0.352)	Data 0.00105 (0.00298)	Tok/s 71491 (74338)	Loss/tok 3.4467 (3.1880)	Learning Rate [7.8125e-05]
0: TRAIN [4][790/6832]	Time 0.185 (0.353)	Data 0.00111 (0.00295)	Tok/s 81920 (74382)	Loss/tok 3.0453 (3.1883)	Learning Rate [7.8125e-05]
0: TRAIN [4][800/6832]	Time 0.252 (0.352)	Data 0.00101 (0.00293)	Tok/s 72290 (74421)	Loss/tok 3.1073 (3.1884)	Learning Rate [7.8125e-05]
0: TRAIN [4][810/6832]	Time 0.485 (0.352)	Data 0.00112 (0.00291)	Tok/s 77562 (74435)	Loss/tok 3.2745 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][820/6832]	Time 0.095 (0.352)	Data 0.00107 (0.00288)	Tok/s 60198 (74483)	Loss/tok 2.0580 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][830/6832]	Time 0.480 (0.352)	Data 0.00104 (0.00286)	Tok/s 82675 (74474)	Loss/tok 3.1804 (3.1886)	Learning Rate [7.8125e-05]
0: TRAIN [4][840/6832]	Time 0.150 (0.352)	Data 0.00109 (0.00284)	Tok/s 79799 (74501)	Loss/tok 2.8341 (3.1886)	Learning Rate [7.8125e-05]
0: TRAIN [4][850/6832]	Time 0.399 (0.352)	Data 0.00109 (0.00282)	Tok/s 68147 (74498)	Loss/tok 3.1706 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][860/6832]	Time 0.480 (0.352)	Data 0.00108 (0.00280)	Tok/s 77098 (74474)	Loss/tok 3.2318 (3.1890)	Learning Rate [7.8125e-05]
0: TRAIN [4][870/6832]	Time 0.364 (0.352)	Data 0.00108 (0.00278)	Tok/s 67975 (74489)	Loss/tok 3.3367 (3.1890)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][880/6832]	Time 0.278 (0.352)	Data 0.00103 (0.00276)	Tok/s 73762 (74469)	Loss/tok 3.0871 (3.1896)	Learning Rate [7.8125e-05]
0: TRAIN [4][890/6832]	Time 0.141 (0.352)	Data 0.00097 (0.00274)	Tok/s 79790 (74500)	Loss/tok 2.7503 (3.1894)	Learning Rate [7.8125e-05]
0: TRAIN [4][900/6832]	Time 0.476 (0.351)	Data 0.00106 (0.00272)	Tok/s 70165 (74472)	Loss/tok 3.4201 (3.1898)	Learning Rate [7.8125e-05]
0: TRAIN [4][910/6832]	Time 0.475 (0.351)	Data 0.00102 (0.00271)	Tok/s 74171 (74489)	Loss/tok 3.2484 (3.1894)	Learning Rate [7.8125e-05]
0: TRAIN [4][920/6832]	Time 0.294 (0.351)	Data 0.00101 (0.00269)	Tok/s 69178 (74465)	Loss/tok 3.1494 (3.1899)	Learning Rate [7.8125e-05]
0: TRAIN [4][930/6832]	Time 0.159 (0.350)	Data 0.00100 (0.00267)	Tok/s 81373 (74522)	Loss/tok 2.8215 (3.1888)	Learning Rate [7.8125e-05]
0: TRAIN [4][940/6832]	Time 0.198 (0.350)	Data 0.00105 (0.00265)	Tok/s 74719 (74507)	Loss/tok 2.9442 (3.1887)	Learning Rate [7.8125e-05]
0: TRAIN [4][950/6832]	Time 0.224 (0.350)	Data 0.00101 (0.00264)	Tok/s 74562 (74504)	Loss/tok 3.0646 (3.1888)	Learning Rate [7.8125e-05]
0: TRAIN [4][960/6832]	Time 0.200 (0.349)	Data 0.00102 (0.00262)	Tok/s 77454 (74517)	Loss/tok 2.9220 (3.1886)	Learning Rate [7.8125e-05]
0: TRAIN [4][970/6832]	Time 0.186 (0.349)	Data 0.00114 (0.00260)	Tok/s 75004 (74539)	Loss/tok 2.9206 (3.1883)	Learning Rate [7.8125e-05]
0: TRAIN [4][980/6832]	Time 0.250 (0.348)	Data 0.00103 (0.00259)	Tok/s 73832 (74532)	Loss/tok 3.2323 (3.1877)	Learning Rate [7.8125e-05]
0: TRAIN [4][990/6832]	Time 0.485 (0.348)	Data 0.00106 (0.00257)	Tok/s 84953 (74560)	Loss/tok 3.2255 (3.1878)	Learning Rate [7.8125e-05]
0: TRAIN [4][1000/6832]	Time 0.213 (0.348)	Data 0.00106 (0.00256)	Tok/s 75275 (74583)	Loss/tok 2.9115 (3.1879)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1010/6832]	Time 0.435 (0.348)	Data 0.00112 (0.00254)	Tok/s 64719 (74573)	Loss/tok 3.1907 (3.1875)	Learning Rate [7.8125e-05]
0: TRAIN [4][1020/6832]	Time 0.481 (0.347)	Data 0.00107 (0.00253)	Tok/s 79733 (74572)	Loss/tok 3.3174 (3.1875)	Learning Rate [7.8125e-05]
0: TRAIN [4][1030/6832]	Time 0.482 (0.347)	Data 0.00022 (0.00253)	Tok/s 76993 (74567)	Loss/tok 3.3490 (3.1875)	Learning Rate [7.8125e-05]
0: TRAIN [4][1040/6832]	Time 0.464 (0.347)	Data 0.00111 (0.00252)	Tok/s 78578 (74590)	Loss/tok 3.2933 (3.1879)	Learning Rate [7.8125e-05]
0: TRAIN [4][1050/6832]	Time 0.448 (0.348)	Data 0.00105 (0.00251)	Tok/s 63846 (74547)	Loss/tok 3.2745 (3.1884)	Learning Rate [7.8125e-05]
0: TRAIN [4][1060/6832]	Time 0.284 (0.348)	Data 0.00105 (0.00249)	Tok/s 72147 (74527)	Loss/tok 3.1735 (3.1889)	Learning Rate [7.8125e-05]
0: TRAIN [4][1070/6832]	Time 0.203 (0.347)	Data 0.00105 (0.00248)	Tok/s 74973 (74511)	Loss/tok 3.0406 (3.1888)	Learning Rate [7.8125e-05]
0: TRAIN [4][1080/6832]	Time 0.157 (0.348)	Data 0.00103 (0.00247)	Tok/s 79340 (74503)	Loss/tok 2.8795 (3.1893)	Learning Rate [7.8125e-05]
0: TRAIN [4][1090/6832]	Time 0.462 (0.348)	Data 0.00101 (0.00245)	Tok/s 84273 (74525)	Loss/tok 3.2123 (3.1892)	Learning Rate [7.8125e-05]
0: TRAIN [4][1100/6832]	Time 0.478 (0.348)	Data 0.00103 (0.00244)	Tok/s 84790 (74531)	Loss/tok 3.1843 (3.1898)	Learning Rate [7.8125e-05]
0: TRAIN [4][1110/6832]	Time 0.123 (0.348)	Data 0.00102 (0.00243)	Tok/s 86016 (74534)	Loss/tok 2.6925 (3.1900)	Learning Rate [7.8125e-05]
0: TRAIN [4][1120/6832]	Time 0.480 (0.348)	Data 0.00106 (0.00242)	Tok/s 68724 (74506)	Loss/tok 3.4029 (3.1902)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1130/6832]	Time 0.189 (0.347)	Data 0.00182 (0.00240)	Tok/s 78288 (74521)	Loss/tok 3.0341 (3.1895)	Learning Rate [7.8125e-05]
0: TRAIN [4][1140/6832]	Time 0.454 (0.348)	Data 0.00101 (0.00239)	Tok/s 64523 (74504)	Loss/tok 3.3007 (3.1899)	Learning Rate [7.8125e-05]
0: TRAIN [4][1150/6832]	Time 0.146 (0.348)	Data 0.00100 (0.00238)	Tok/s 76251 (74466)	Loss/tok 2.6381 (3.1905)	Learning Rate [7.8125e-05]
0: TRAIN [4][1160/6832]	Time 0.286 (0.348)	Data 0.00119 (0.00237)	Tok/s 73284 (74476)	Loss/tok 3.1597 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1170/6832]	Time 0.468 (0.348)	Data 0.00104 (0.00236)	Tok/s 66135 (74440)	Loss/tok 3.2593 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1180/6832]	Time 0.280 (0.348)	Data 0.00102 (0.00235)	Tok/s 73632 (74487)	Loss/tok 3.1549 (3.1908)	Learning Rate [7.8125e-05]
0: TRAIN [4][1190/6832]	Time 0.483 (0.349)	Data 0.00116 (0.00234)	Tok/s 70660 (74457)	Loss/tok 3.3054 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1200/6832]	Time 0.481 (0.349)	Data 0.00103 (0.00233)	Tok/s 77908 (74461)	Loss/tok 3.2374 (3.1911)	Learning Rate [7.8125e-05]
0: TRAIN [4][1210/6832]	Time 0.374 (0.349)	Data 0.00105 (0.00232)	Tok/s 67242 (74422)	Loss/tok 3.2812 (3.1912)	Learning Rate [7.8125e-05]
0: TRAIN [4][1220/6832]	Time 0.484 (0.349)	Data 0.00102 (0.00231)	Tok/s 85459 (74419)	Loss/tok 3.2250 (3.1915)	Learning Rate [7.8125e-05]
0: TRAIN [4][1230/6832]	Time 0.279 (0.348)	Data 0.00107 (0.00230)	Tok/s 76919 (74394)	Loss/tok 3.1240 (3.1912)	Learning Rate [7.8125e-05]
0: TRAIN [4][1240/6832]	Time 0.479 (0.348)	Data 0.00108 (0.00229)	Tok/s 72729 (74418)	Loss/tok 3.3516 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1250/6832]	Time 0.293 (0.348)	Data 0.00104 (0.00228)	Tok/s 73493 (74410)	Loss/tok 3.1501 (3.1909)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1260/6832]	Time 0.199 (0.348)	Data 0.00103 (0.00227)	Tok/s 79823 (74411)	Loss/tok 2.9960 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1270/6832]	Time 0.341 (0.348)	Data 0.00108 (0.00226)	Tok/s 68391 (74418)	Loss/tok 3.1713 (3.1916)	Learning Rate [7.8125e-05]
0: TRAIN [4][1280/6832]	Time 0.453 (0.348)	Data 0.00106 (0.00225)	Tok/s 64491 (74425)	Loss/tok 3.3393 (3.1916)	Learning Rate [7.8125e-05]
0: TRAIN [4][1290/6832]	Time 0.241 (0.348)	Data 0.00154 (0.00224)	Tok/s 71268 (74405)	Loss/tok 3.0015 (3.1914)	Learning Rate [7.8125e-05]
0: TRAIN [4][1300/6832]	Time 0.183 (0.347)	Data 0.00103 (0.00223)	Tok/s 78194 (74411)	Loss/tok 2.9129 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1310/6832]	Time 0.369 (0.347)	Data 0.00102 (0.00222)	Tok/s 70244 (74387)	Loss/tok 3.2352 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1320/6832]	Time 0.456 (0.346)	Data 0.00099 (0.00221)	Tok/s 66184 (74375)	Loss/tok 3.3641 (3.1908)	Learning Rate [7.8125e-05]
0: TRAIN [4][1330/6832]	Time 0.413 (0.346)	Data 0.00102 (0.00221)	Tok/s 70733 (74370)	Loss/tok 3.2822 (3.1907)	Learning Rate [7.8125e-05]
0: TRAIN [4][1340/6832]	Time 0.421 (0.346)	Data 0.00108 (0.00220)	Tok/s 68074 (74342)	Loss/tok 3.3201 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1350/6832]	Time 0.484 (0.346)	Data 0.00101 (0.00219)	Tok/s 91108 (74367)	Loss/tok 3.2808 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1360/6832]	Time 0.283 (0.346)	Data 0.00103 (0.00218)	Tok/s 71200 (74365)	Loss/tok 3.1227 (3.1911)	Learning Rate [7.8125e-05]
0: TRAIN [4][1370/6832]	Time 0.205 (0.346)	Data 0.00099 (0.00217)	Tok/s 76063 (74375)	Loss/tok 2.9636 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1380/6832]	Time 0.334 (0.346)	Data 0.00099 (0.00216)	Tok/s 73189 (74393)	Loss/tok 3.2989 (3.1912)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1390/6832]	Time 0.466 (0.345)	Data 0.00106 (0.00216)	Tok/s 71121 (74410)	Loss/tok 3.3489 (3.1908)	Learning Rate [7.8125e-05]
0: TRAIN [4][1400/6832]	Time 0.370 (0.345)	Data 0.00135 (0.00215)	Tok/s 67328 (74424)	Loss/tok 3.1648 (3.1907)	Learning Rate [7.8125e-05]
0: TRAIN [4][1410/6832]	Time 0.311 (0.345)	Data 0.00105 (0.00214)	Tok/s 70739 (74405)	Loss/tok 3.0724 (3.1907)	Learning Rate [7.8125e-05]
0: TRAIN [4][1420/6832]	Time 0.486 (0.345)	Data 0.00106 (0.00213)	Tok/s 81628 (74413)	Loss/tok 3.4180 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1430/6832]	Time 0.486 (0.345)	Data 0.00110 (0.00213)	Tok/s 86482 (74420)	Loss/tok 3.1741 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1440/6832]	Time 0.113 (0.346)	Data 0.00106 (0.00212)	Tok/s 75454 (74427)	Loss/tok 2.4223 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1450/6832]	Time 0.321 (0.345)	Data 0.00113 (0.00211)	Tok/s 69378 (74412)	Loss/tok 3.1772 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1460/6832]	Time 0.140 (0.345)	Data 0.00100 (0.00211)	Tok/s 69030 (74418)	Loss/tok 2.5699 (3.1911)	Learning Rate [7.8125e-05]
0: TRAIN [4][1470/6832]	Time 0.421 (0.345)	Data 0.00104 (0.00210)	Tok/s 66910 (74404)	Loss/tok 3.2623 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1480/6832]	Time 0.485 (0.346)	Data 0.00106 (0.00209)	Tok/s 76309 (74407)	Loss/tok 3.2491 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1490/6832]	Time 0.415 (0.346)	Data 0.00105 (0.00208)	Tok/s 66871 (74433)	Loss/tok 3.2571 (3.1911)	Learning Rate [7.8125e-05]
0: TRAIN [4][1500/6832]	Time 0.483 (0.346)	Data 0.00106 (0.00208)	Tok/s 87128 (74447)	Loss/tok 3.2123 (3.1912)	Learning Rate [7.8125e-05]
0: TRAIN [4][1510/6832]	Time 0.447 (0.346)	Data 0.00108 (0.00207)	Tok/s 69526 (74435)	Loss/tok 3.3077 (3.1915)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1520/6832]	Time 0.483 (0.347)	Data 0.00110 (0.00207)	Tok/s 82186 (74439)	Loss/tok 3.2325 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1530/6832]	Time 0.221 (0.346)	Data 0.00107 (0.00206)	Tok/s 75254 (74425)	Loss/tok 3.0206 (3.1914)	Learning Rate [7.8125e-05]
0: TRAIN [4][1540/6832]	Time 0.142 (0.347)	Data 0.00101 (0.00205)	Tok/s 79007 (74446)	Loss/tok 2.7295 (3.1914)	Learning Rate [7.8125e-05]
0: TRAIN [4][1550/6832]	Time 0.347 (0.347)	Data 0.00106 (0.00205)	Tok/s 69382 (74459)	Loss/tok 3.2325 (3.1915)	Learning Rate [7.8125e-05]
0: TRAIN [4][1560/6832]	Time 0.119 (0.347)	Data 0.00113 (0.00204)	Tok/s 70383 (74431)	Loss/tok 2.4368 (3.1917)	Learning Rate [7.8125e-05]
0: TRAIN [4][1570/6832]	Time 0.485 (0.347)	Data 0.00109 (0.00204)	Tok/s 100221 (74453)	Loss/tok 3.0254 (3.1917)	Learning Rate [7.8125e-05]
0: TRAIN [4][1580/6832]	Time 0.476 (0.348)	Data 0.00105 (0.00203)	Tok/s 72095 (74430)	Loss/tok 3.3021 (3.1920)	Learning Rate [7.8125e-05]
0: TRAIN [4][1590/6832]	Time 0.465 (0.348)	Data 0.00121 (0.00202)	Tok/s 74648 (74462)	Loss/tok 3.2985 (3.1920)	Learning Rate [7.8125e-05]
0: TRAIN [4][1600/6832]	Time 0.259 (0.348)	Data 0.00108 (0.00202)	Tok/s 73275 (74485)	Loss/tok 3.1164 (3.1917)	Learning Rate [7.8125e-05]
0: TRAIN [4][1610/6832]	Time 0.457 (0.348)	Data 0.00110 (0.00201)	Tok/s 69855 (74487)	Loss/tok 3.3205 (3.1916)	Learning Rate [7.8125e-05]
0: TRAIN [4][1620/6832]	Time 0.112 (0.348)	Data 0.00106 (0.00201)	Tok/s 74711 (74468)	Loss/tok 2.3749 (3.1914)	Learning Rate [7.8125e-05]
0: TRAIN [4][1630/6832]	Time 0.236 (0.348)	Data 0.00103 (0.00200)	Tok/s 78056 (74480)	Loss/tok 3.1146 (3.1914)	Learning Rate [7.8125e-05]
0: TRAIN [4][1640/6832]	Time 0.329 (0.348)	Data 0.00115 (0.00199)	Tok/s 70608 (74446)	Loss/tok 3.1878 (3.1916)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1650/6832]	Time 0.184 (0.348)	Data 0.00110 (0.00199)	Tok/s 80206 (74461)	Loss/tok 2.9723 (3.1916)	Learning Rate [7.8125e-05]
0: TRAIN [4][1660/6832]	Time 0.195 (0.348)	Data 0.00107 (0.00198)	Tok/s 77367 (74446)	Loss/tok 2.9593 (3.1919)	Learning Rate [7.8125e-05]
0: TRAIN [4][1670/6832]	Time 0.464 (0.348)	Data 0.00107 (0.00198)	Tok/s 90780 (74494)	Loss/tok 3.2060 (3.1917)	Learning Rate [7.8125e-05]
0: TRAIN [4][1680/6832]	Time 0.168 (0.348)	Data 0.00101 (0.00197)	Tok/s 77467 (74498)	Loss/tok 2.8708 (3.1914)	Learning Rate [7.8125e-05]
0: TRAIN [4][1690/6832]	Time 0.347 (0.348)	Data 0.00024 (0.00197)	Tok/s 70261 (74485)	Loss/tok 3.1681 (3.1915)	Learning Rate [7.8125e-05]
0: TRAIN [4][1700/6832]	Time 0.430 (0.348)	Data 0.00111 (0.00196)	Tok/s 66117 (74466)	Loss/tok 3.2562 (3.1913)	Learning Rate [7.8125e-05]
0: TRAIN [4][1710/6832]	Time 0.455 (0.348)	Data 0.00105 (0.00196)	Tok/s 67109 (74485)	Loss/tok 3.2130 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1720/6832]	Time 0.207 (0.349)	Data 0.00108 (0.00195)	Tok/s 75433 (74480)	Loss/tok 3.0537 (3.1912)	Learning Rate [7.8125e-05]
0: TRAIN [4][1730/6832]	Time 0.146 (0.348)	Data 0.00112 (0.00195)	Tok/s 76165 (74482)	Loss/tok 2.7071 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1740/6832]	Time 0.265 (0.348)	Data 0.00109 (0.00194)	Tok/s 73629 (74473)	Loss/tok 3.1491 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1750/6832]	Time 0.488 (0.349)	Data 0.00112 (0.00194)	Tok/s 99779 (74478)	Loss/tok 3.0792 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1760/6832]	Time 0.478 (0.349)	Data 0.00112 (0.00193)	Tok/s 67813 (74465)	Loss/tok 3.2614 (3.1912)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1770/6832]	Time 0.397 (0.348)	Data 0.00128 (0.00193)	Tok/s 68913 (74450)	Loss/tok 3.1685 (3.1908)	Learning Rate [7.8125e-05]
0: TRAIN [4][1780/6832]	Time 0.379 (0.348)	Data 0.00108 (0.00193)	Tok/s 67962 (74438)	Loss/tok 3.1784 (3.1906)	Learning Rate [7.8125e-05]
0: TRAIN [4][1790/6832]	Time 0.466 (0.348)	Data 0.00114 (0.00192)	Tok/s 83738 (74439)	Loss/tok 3.2904 (3.1907)	Learning Rate [7.8125e-05]
0: TRAIN [4][1800/6832]	Time 0.221 (0.348)	Data 0.00109 (0.00192)	Tok/s 74275 (74426)	Loss/tok 3.0170 (3.1908)	Learning Rate [7.8125e-05]
0: TRAIN [4][1810/6832]	Time 0.482 (0.348)	Data 0.00109 (0.00191)	Tok/s 84108 (74449)	Loss/tok 3.1980 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1820/6832]	Time 0.483 (0.348)	Data 0.00119 (0.00191)	Tok/s 87454 (74452)	Loss/tok 3.2577 (3.1907)	Learning Rate [7.8125e-05]
0: TRAIN [4][1830/6832]	Time 0.298 (0.348)	Data 0.00112 (0.00190)	Tok/s 70351 (74435)	Loss/tok 3.1984 (3.1909)	Learning Rate [7.8125e-05]
0: TRAIN [4][1840/6832]	Time 0.414 (0.348)	Data 0.00112 (0.00190)	Tok/s 66760 (74426)	Loss/tok 3.3031 (3.1910)	Learning Rate [7.8125e-05]
0: TRAIN [4][1850/6832]	Time 0.471 (0.348)	Data 0.00102 (0.00190)	Tok/s 70374 (74424)	Loss/tok 3.4235 (3.1907)	Learning Rate [7.8125e-05]
0: TRAIN [4][1860/6832]	Time 0.158 (0.348)	Data 0.00104 (0.00189)	Tok/s 75118 (74444)	Loss/tok 2.7162 (3.1902)	Learning Rate [7.8125e-05]
0: TRAIN [4][1870/6832]	Time 0.290 (0.348)	Data 0.00107 (0.00189)	Tok/s 77157 (74448)	Loss/tok 3.2487 (3.1902)	Learning Rate [7.8125e-05]
0: TRAIN [4][1880/6832]	Time 0.147 (0.348)	Data 0.00104 (0.00188)	Tok/s 75949 (74436)	Loss/tok 2.7278 (3.1901)	Learning Rate [7.8125e-05]
0: TRAIN [4][1890/6832]	Time 0.484 (0.348)	Data 0.00107 (0.00188)	Tok/s 78978 (74451)	Loss/tok 3.2606 (3.1902)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][1900/6832]	Time 0.476 (0.348)	Data 0.00121 (0.00187)	Tok/s 61924 (74422)	Loss/tok 3.3355 (3.1905)	Learning Rate [7.8125e-05]
0: TRAIN [4][1910/6832]	Time 0.319 (0.348)	Data 0.00113 (0.00187)	Tok/s 69954 (74402)	Loss/tok 3.0947 (3.1904)	Learning Rate [7.8125e-05]
0: TRAIN [4][1920/6832]	Time 0.201 (0.348)	Data 0.00106 (0.00187)	Tok/s 75684 (74386)	Loss/tok 2.9690 (3.1900)	Learning Rate [7.8125e-05]
0: TRAIN [4][1930/6832]	Time 0.235 (0.348)	Data 0.00111 (0.00186)	Tok/s 69676 (74358)	Loss/tok 3.0440 (3.1900)	Learning Rate [7.8125e-05]
0: TRAIN [4][1940/6832]	Time 0.387 (0.347)	Data 0.00120 (0.00186)	Tok/s 67582 (74352)	Loss/tok 3.1642 (3.1898)	Learning Rate [7.8125e-05]
0: TRAIN [4][1950/6832]	Time 0.148 (0.348)	Data 0.00143 (0.00186)	Tok/s 76095 (74346)	Loss/tok 2.6943 (3.1897)	Learning Rate [7.8125e-05]
0: TRAIN [4][1960/6832]	Time 0.343 (0.347)	Data 0.00106 (0.00185)	Tok/s 68336 (74337)	Loss/tok 3.1274 (3.1896)	Learning Rate [7.8125e-05]
0: TRAIN [4][1970/6832]	Time 0.378 (0.347)	Data 0.00113 (0.00185)	Tok/s 67524 (74333)	Loss/tok 3.1666 (3.1894)	Learning Rate [7.8125e-05]
0: TRAIN [4][1980/6832]	Time 0.463 (0.347)	Data 0.00111 (0.00184)	Tok/s 77931 (74365)	Loss/tok 3.2043 (3.1888)	Learning Rate [7.8125e-05]
0: TRAIN [4][1990/6832]	Time 0.157 (0.347)	Data 0.00107 (0.00184)	Tok/s 79746 (74369)	Loss/tok 2.7619 (3.1887)	Learning Rate [7.8125e-05]
0: TRAIN [4][2000/6832]	Time 0.403 (0.347)	Data 0.00107 (0.00184)	Tok/s 67018 (74358)	Loss/tok 3.2392 (3.1887)	Learning Rate [7.8125e-05]
0: TRAIN [4][2010/6832]	Time 0.144 (0.347)	Data 0.00107 (0.00183)	Tok/s 77200 (74373)	Loss/tok 2.6695 (3.1885)	Learning Rate [7.8125e-05]
0: TRAIN [4][2020/6832]	Time 0.468 (0.347)	Data 0.00104 (0.00183)	Tok/s 63447 (74357)	Loss/tok 3.3035 (3.1882)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2030/6832]	Time 0.411 (0.347)	Data 0.00128 (0.00183)	Tok/s 64856 (74348)	Loss/tok 3.2982 (3.1886)	Learning Rate [7.8125e-05]
0: TRAIN [4][2040/6832]	Time 0.207 (0.347)	Data 0.00107 (0.00182)	Tok/s 73495 (74357)	Loss/tok 2.9912 (3.1883)	Learning Rate [7.8125e-05]
0: TRAIN [4][2050/6832]	Time 0.201 (0.347)	Data 0.00109 (0.00182)	Tok/s 76170 (74356)	Loss/tok 2.9373 (3.1883)	Learning Rate [7.8125e-05]
0: TRAIN [4][2060/6832]	Time 0.395 (0.347)	Data 0.00115 (0.00182)	Tok/s 68590 (74361)	Loss/tok 3.2723 (3.1885)	Learning Rate [7.8125e-05]
0: TRAIN [4][2070/6832]	Time 0.338 (0.347)	Data 0.00109 (0.00181)	Tok/s 67389 (74350)	Loss/tok 3.2438 (3.1885)	Learning Rate [7.8125e-05]
0: TRAIN [4][2080/6832]	Time 0.272 (0.347)	Data 0.00109 (0.00181)	Tok/s 70405 (74334)	Loss/tok 3.1463 (3.1884)	Learning Rate [7.8125e-05]
0: TRAIN [4][2090/6832]	Time 0.481 (0.347)	Data 0.00104 (0.00181)	Tok/s 101285 (74344)	Loss/tok 3.0620 (3.1883)	Learning Rate [7.8125e-05]
0: TRAIN [4][2100/6832]	Time 0.406 (0.347)	Data 0.00106 (0.00180)	Tok/s 68044 (74327)	Loss/tok 3.3088 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][2110/6832]	Time 0.253 (0.347)	Data 0.00104 (0.00180)	Tok/s 72155 (74318)	Loss/tok 3.0377 (3.1886)	Learning Rate [7.8125e-05]
0: TRAIN [4][2120/6832]	Time 0.400 (0.347)	Data 0.00103 (0.00180)	Tok/s 69299 (74297)	Loss/tok 3.2907 (3.1884)	Learning Rate [7.8125e-05]
0: TRAIN [4][2130/6832]	Time 0.273 (0.347)	Data 0.00107 (0.00179)	Tok/s 73071 (74292)	Loss/tok 3.1135 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][2140/6832]	Time 0.465 (0.347)	Data 0.00102 (0.00179)	Tok/s 75815 (74291)	Loss/tok 3.3040 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][2150/6832]	Time 0.406 (0.347)	Data 0.00107 (0.00179)	Tok/s 70354 (74281)	Loss/tok 3.2350 (3.1884)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2160/6832]	Time 0.482 (0.347)	Data 0.00105 (0.00178)	Tok/s 74852 (74276)	Loss/tok 3.3178 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][2170/6832]	Time 0.482 (0.347)	Data 0.00106 (0.00178)	Tok/s 81189 (74282)	Loss/tok 3.3024 (3.1883)	Learning Rate [7.8125e-05]
0: TRAIN [4][2180/6832]	Time 0.258 (0.347)	Data 0.00104 (0.00178)	Tok/s 74372 (74291)	Loss/tok 3.0467 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][2190/6832]	Time 0.347 (0.347)	Data 0.00106 (0.00177)	Tok/s 69263 (74287)	Loss/tok 3.1488 (3.1880)	Learning Rate [7.8125e-05]
0: TRAIN [4][2200/6832]	Time 0.183 (0.347)	Data 0.00111 (0.00177)	Tok/s 78230 (74297)	Loss/tok 2.9574 (3.1880)	Learning Rate [7.8125e-05]
0: TRAIN [4][2210/6832]	Time 0.447 (0.347)	Data 0.00119 (0.00177)	Tok/s 64932 (74286)	Loss/tok 3.2296 (3.1881)	Learning Rate [7.8125e-05]
0: TRAIN [4][2220/6832]	Time 0.277 (0.347)	Data 0.00110 (0.00177)	Tok/s 69339 (74283)	Loss/tok 3.0510 (3.1879)	Learning Rate [7.8125e-05]
0: TRAIN [4][2230/6832]	Time 0.434 (0.347)	Data 0.00108 (0.00176)	Tok/s 69316 (74270)	Loss/tok 3.2947 (3.1882)	Learning Rate [7.8125e-05]
0: TRAIN [4][2240/6832]	Time 0.135 (0.347)	Data 0.00106 (0.00176)	Tok/s 77768 (74268)	Loss/tok 2.6517 (3.1884)	Learning Rate [7.8125e-05]
0: TRAIN [4][2250/6832]	Time 0.457 (0.347)	Data 0.00107 (0.00176)	Tok/s 70629 (74281)	Loss/tok 3.3538 (3.1883)	Learning Rate [7.8125e-05]
0: TRAIN [4][2260/6832]	Time 0.301 (0.347)	Data 0.00106 (0.00175)	Tok/s 73203 (74267)	Loss/tok 3.1055 (3.1880)	Learning Rate [7.8125e-05]
0: TRAIN [4][2270/6832]	Time 0.130 (0.347)	Data 0.00126 (0.00175)	Tok/s 80971 (74278)	Loss/tok 2.7252 (3.1876)	Learning Rate [7.8125e-05]
0: TRAIN [4][2280/6832]	Time 0.185 (0.347)	Data 0.00123 (0.00175)	Tok/s 77614 (74269)	Loss/tok 2.8929 (3.1878)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2290/6832]	Time 0.323 (0.347)	Data 0.00106 (0.00174)	Tok/s 70042 (74262)	Loss/tok 3.1856 (3.1879)	Learning Rate [7.8125e-05]
0: TRAIN [4][2300/6832]	Time 0.473 (0.347)	Data 0.00111 (0.00174)	Tok/s 67786 (74293)	Loss/tok 3.2717 (3.1875)	Learning Rate [7.8125e-05]
0: TRAIN [4][2310/6832]	Time 0.228 (0.347)	Data 0.00102 (0.00174)	Tok/s 74947 (74278)	Loss/tok 3.0325 (3.1874)	Learning Rate [7.8125e-05]
0: TRAIN [4][2320/6832]	Time 0.479 (0.347)	Data 0.00112 (0.00174)	Tok/s 71486 (74282)	Loss/tok 3.2409 (3.1874)	Learning Rate [7.8125e-05]
0: TRAIN [4][2330/6832]	Time 0.263 (0.347)	Data 0.00104 (0.00173)	Tok/s 74106 (74289)	Loss/tok 3.0278 (3.1873)	Learning Rate [7.8125e-05]
0: TRAIN [4][2340/6832]	Time 0.192 (0.347)	Data 0.00111 (0.00173)	Tok/s 77234 (74302)	Loss/tok 2.9833 (3.1871)	Learning Rate [7.8125e-05]
0: TRAIN [4][2350/6832]	Time 0.457 (0.347)	Data 0.00112 (0.00173)	Tok/s 64472 (74302)	Loss/tok 3.2695 (3.1871)	Learning Rate [7.8125e-05]
0: TRAIN [4][2360/6832]	Time 0.354 (0.347)	Data 0.00109 (0.00173)	Tok/s 67922 (74289)	Loss/tok 3.2109 (3.1870)	Learning Rate [7.8125e-05]
0: TRAIN [4][2370/6832]	Time 0.246 (0.347)	Data 0.00108 (0.00172)	Tok/s 72541 (74288)	Loss/tok 3.0253 (3.1868)	Learning Rate [7.8125e-05]
0: TRAIN [4][2380/6832]	Time 0.352 (0.347)	Data 0.00103 (0.00172)	Tok/s 66706 (74302)	Loss/tok 3.1586 (3.1866)	Learning Rate [7.8125e-05]
0: TRAIN [4][2390/6832]	Time 0.109 (0.347)	Data 0.00129 (0.00172)	Tok/s 76158 (74296)	Loss/tok 2.3413 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [4][2400/6832]	Time 0.147 (0.346)	Data 0.00107 (0.00171)	Tok/s 80728 (74302)	Loss/tok 2.7667 (3.1863)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2410/6832]	Time 0.312 (0.346)	Data 0.00124 (0.00171)	Tok/s 70665 (74292)	Loss/tok 3.0395 (3.1862)	Learning Rate [7.8125e-05]
0: TRAIN [4][2420/6832]	Time 0.381 (0.347)	Data 0.00108 (0.00171)	Tok/s 69867 (74292)	Loss/tok 3.1398 (3.1862)	Learning Rate [7.8125e-05]
0: TRAIN [4][2430/6832]	Time 0.381 (0.347)	Data 0.00104 (0.00171)	Tok/s 69447 (74275)	Loss/tok 3.2091 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [4][2440/6832]	Time 0.392 (0.347)	Data 0.00105 (0.00170)	Tok/s 65864 (74275)	Loss/tok 3.2412 (3.1863)	Learning Rate [7.8125e-05]
0: TRAIN [4][2450/6832]	Time 0.330 (0.347)	Data 0.00110 (0.00170)	Tok/s 69897 (74270)	Loss/tok 3.1673 (3.1861)	Learning Rate [7.8125e-05]
0: TRAIN [4][2460/6832]	Time 0.448 (0.347)	Data 0.00103 (0.00170)	Tok/s 64469 (74278)	Loss/tok 3.1939 (3.1860)	Learning Rate [7.8125e-05]
0: TRAIN [4][2470/6832]	Time 0.395 (0.347)	Data 0.00129 (0.00170)	Tok/s 68630 (74283)	Loss/tok 3.1998 (3.1861)	Learning Rate [7.8125e-05]
0: TRAIN [4][2480/6832]	Time 0.475 (0.347)	Data 0.00115 (0.00170)	Tok/s 66075 (74278)	Loss/tok 3.2587 (3.1861)	Learning Rate [7.8125e-05]
0: TRAIN [4][2490/6832]	Time 0.481 (0.347)	Data 0.00112 (0.00169)	Tok/s 67138 (74277)	Loss/tok 3.3764 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [4][2500/6832]	Time 0.486 (0.347)	Data 0.00105 (0.00169)	Tok/s 88692 (74277)	Loss/tok 3.2024 (3.1864)	Learning Rate [7.8125e-05]
0: TRAIN [4][2510/6832]	Time 0.479 (0.347)	Data 0.00107 (0.00169)	Tok/s 92324 (74274)	Loss/tok 3.1591 (3.1865)	Learning Rate [7.8125e-05]
0: TRAIN [4][2520/6832]	Time 0.262 (0.347)	Data 0.00104 (0.00169)	Tok/s 74634 (74266)	Loss/tok 2.9879 (3.1862)	Learning Rate [7.8125e-05]
0: TRAIN [4][2530/6832]	Time 0.484 (0.347)	Data 0.00104 (0.00168)	Tok/s 77962 (74271)	Loss/tok 3.2433 (3.1862)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2540/6832]	Time 0.480 (0.347)	Data 0.00114 (0.00168)	Tok/s 81555 (74304)	Loss/tok 3.2443 (3.1859)	Learning Rate [7.8125e-05]
0: TRAIN [4][2550/6832]	Time 0.466 (0.347)	Data 0.00106 (0.00168)	Tok/s 64801 (74285)	Loss/tok 3.3036 (3.1861)	Learning Rate [7.8125e-05]
0: TRAIN [4][2560/6832]	Time 0.486 (0.347)	Data 0.00105 (0.00168)	Tok/s 92961 (74293)	Loss/tok 3.1740 (3.1860)	Learning Rate [7.8125e-05]
0: TRAIN [4][2570/6832]	Time 0.271 (0.347)	Data 0.00106 (0.00167)	Tok/s 70650 (74287)	Loss/tok 3.1070 (3.1857)	Learning Rate [7.8125e-05]
0: TRAIN [4][2580/6832]	Time 0.417 (0.347)	Data 0.00110 (0.00167)	Tok/s 68132 (74277)	Loss/tok 3.2640 (3.1858)	Learning Rate [7.8125e-05]
0: TRAIN [4][2590/6832]	Time 0.483 (0.347)	Data 0.00107 (0.00167)	Tok/s 85782 (74269)	Loss/tok 3.2198 (3.1858)	Learning Rate [7.8125e-05]
0: TRAIN [4][2600/6832]	Time 0.310 (0.347)	Data 0.00112 (0.00167)	Tok/s 69822 (74268)	Loss/tok 3.1670 (3.1856)	Learning Rate [7.8125e-05]
0: TRAIN [4][2610/6832]	Time 0.438 (0.347)	Data 0.00153 (0.00167)	Tok/s 65290 (74250)	Loss/tok 3.2756 (3.1855)	Learning Rate [7.8125e-05]
0: TRAIN [4][2620/6832]	Time 0.224 (0.347)	Data 0.00104 (0.00166)	Tok/s 74384 (74260)	Loss/tok 2.9202 (3.1852)	Learning Rate [7.8125e-05]
0: TRAIN [4][2630/6832]	Time 0.407 (0.347)	Data 0.00108 (0.00166)	Tok/s 67876 (74253)	Loss/tok 3.2423 (3.1850)	Learning Rate [7.8125e-05]
0: TRAIN [4][2640/6832]	Time 0.480 (0.347)	Data 0.00110 (0.00166)	Tok/s 84083 (74269)	Loss/tok 3.2398 (3.1849)	Learning Rate [7.8125e-05]
0: TRAIN [4][2650/6832]	Time 0.480 (0.347)	Data 0.00112 (0.00166)	Tok/s 74996 (74281)	Loss/tok 3.2387 (3.1850)	Learning Rate [7.8125e-05]
0: TRAIN [4][2660/6832]	Time 0.481 (0.347)	Data 0.00134 (0.00166)	Tok/s 81187 (74283)	Loss/tok 3.2150 (3.1850)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2670/6832]	Time 0.253 (0.347)	Data 0.00110 (0.00165)	Tok/s 74737 (74272)	Loss/tok 3.0942 (3.1851)	Learning Rate [7.8125e-05]
0: TRAIN [4][2680/6832]	Time 0.407 (0.347)	Data 0.00111 (0.00165)	Tok/s 65420 (74275)	Loss/tok 3.2359 (3.1849)	Learning Rate [7.8125e-05]
0: TRAIN [4][2690/6832]	Time 0.356 (0.347)	Data 0.00110 (0.00165)	Tok/s 70881 (74275)	Loss/tok 3.1423 (3.1845)	Learning Rate [7.8125e-05]
0: TRAIN [4][2700/6832]	Time 0.474 (0.347)	Data 0.00103 (0.00165)	Tok/s 70237 (74272)	Loss/tok 3.2271 (3.1845)	Learning Rate [7.8125e-05]
0: TRAIN [4][2710/6832]	Time 0.294 (0.347)	Data 0.00107 (0.00165)	Tok/s 73330 (74278)	Loss/tok 3.1195 (3.1843)	Learning Rate [7.8125e-05]
0: TRAIN [4][2720/6832]	Time 0.405 (0.347)	Data 0.00104 (0.00164)	Tok/s 69585 (74279)	Loss/tok 3.2448 (3.1841)	Learning Rate [7.8125e-05]
0: TRAIN [4][2730/6832]	Time 0.227 (0.347)	Data 0.00108 (0.00164)	Tok/s 75604 (74272)	Loss/tok 3.0013 (3.1840)	Learning Rate [7.8125e-05]
0: TRAIN [4][2740/6832]	Time 0.405 (0.347)	Data 0.00104 (0.00164)	Tok/s 66476 (74264)	Loss/tok 3.2539 (3.1839)	Learning Rate [7.8125e-05]
0: TRAIN [4][2750/6832]	Time 0.388 (0.347)	Data 0.00110 (0.00164)	Tok/s 68745 (74265)	Loss/tok 3.2535 (3.1838)	Learning Rate [7.8125e-05]
0: TRAIN [4][2760/6832]	Time 0.468 (0.347)	Data 0.00108 (0.00164)	Tok/s 71000 (74259)	Loss/tok 3.2900 (3.1837)	Learning Rate [7.8125e-05]
0: TRAIN [4][2770/6832]	Time 0.484 (0.347)	Data 0.00106 (0.00163)	Tok/s 75081 (74253)	Loss/tok 3.3434 (3.1838)	Learning Rate [7.8125e-05]
0: TRAIN [4][2780/6832]	Time 0.171 (0.347)	Data 0.00106 (0.00163)	Tok/s 78519 (74250)	Loss/tok 2.9348 (3.1840)	Learning Rate [7.8125e-05]
0: TRAIN [4][2790/6832]	Time 0.372 (0.347)	Data 0.00114 (0.00163)	Tok/s 69276 (74245)	Loss/tok 3.1540 (3.1837)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2800/6832]	Time 0.419 (0.347)	Data 0.00105 (0.00163)	Tok/s 68860 (74250)	Loss/tok 3.2004 (3.1836)	Learning Rate [7.8125e-05]
0: TRAIN [4][2810/6832]	Time 0.481 (0.347)	Data 0.00108 (0.00163)	Tok/s 91687 (74265)	Loss/tok 3.1951 (3.1833)	Learning Rate [7.8125e-05]
0: TRAIN [4][2820/6832]	Time 0.183 (0.347)	Data 0.00105 (0.00162)	Tok/s 78772 (74251)	Loss/tok 2.8728 (3.1833)	Learning Rate [7.8125e-05]
0: TRAIN [4][2830/6832]	Time 0.487 (0.347)	Data 0.00108 (0.00162)	Tok/s 86362 (74254)	Loss/tok 3.2046 (3.1833)	Learning Rate [7.8125e-05]
0: TRAIN [4][2840/6832]	Time 0.403 (0.346)	Data 0.00108 (0.00162)	Tok/s 64926 (74255)	Loss/tok 3.2376 (3.1829)	Learning Rate [7.8125e-05]
0: TRAIN [4][2850/6832]	Time 0.372 (0.346)	Data 0.00105 (0.00162)	Tok/s 66459 (74246)	Loss/tok 3.2270 (3.1829)	Learning Rate [7.8125e-05]
0: TRAIN [4][2860/6832]	Time 0.344 (0.346)	Data 0.00105 (0.00162)	Tok/s 69912 (74251)	Loss/tok 3.3125 (3.1827)	Learning Rate [7.8125e-05]
0: TRAIN [4][2870/6832]	Time 0.463 (0.346)	Data 0.00116 (0.00162)	Tok/s 63028 (74237)	Loss/tok 3.1584 (3.1827)	Learning Rate [7.8125e-05]
0: TRAIN [4][2880/6832]	Time 0.315 (0.346)	Data 0.00107 (0.00161)	Tok/s 69817 (74225)	Loss/tok 3.2254 (3.1827)	Learning Rate [7.8125e-05]
0: TRAIN [4][2890/6832]	Time 0.220 (0.346)	Data 0.00116 (0.00161)	Tok/s 72663 (74222)	Loss/tok 2.9909 (3.1826)	Learning Rate [7.8125e-05]
0: TRAIN [4][2900/6832]	Time 0.108 (0.346)	Data 0.00107 (0.00161)	Tok/s 77739 (74208)	Loss/tok 2.3993 (3.1825)	Learning Rate [7.8125e-05]
0: TRAIN [4][2910/6832]	Time 0.415 (0.346)	Data 0.00107 (0.00161)	Tok/s 65874 (74208)	Loss/tok 3.2017 (3.1826)	Learning Rate [7.8125e-05]
0: TRAIN [4][2920/6832]	Time 0.391 (0.346)	Data 0.00105 (0.00161)	Tok/s 66801 (74197)	Loss/tok 3.0940 (3.1825)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][2930/6832]	Time 0.463 (0.346)	Data 0.00108 (0.00161)	Tok/s 72767 (74196)	Loss/tok 3.2424 (3.1826)	Learning Rate [7.8125e-05]
0: TRAIN [4][2940/6832]	Time 0.485 (0.347)	Data 0.00104 (0.00160)	Tok/s 82098 (74217)	Loss/tok 3.1862 (3.1823)	Learning Rate [7.8125e-05]
0: TRAIN [4][2950/6832]	Time 0.482 (0.346)	Data 0.00108 (0.00160)	Tok/s 77074 (74217)	Loss/tok 3.2269 (3.1819)	Learning Rate [7.8125e-05]
0: TRAIN [4][2960/6832]	Time 0.467 (0.346)	Data 0.00113 (0.00160)	Tok/s 75630 (74225)	Loss/tok 3.3309 (3.1819)	Learning Rate [7.8125e-05]
0: TRAIN [4][2970/6832]	Time 0.430 (0.346)	Data 0.00106 (0.00160)	Tok/s 66721 (74227)	Loss/tok 3.2826 (3.1819)	Learning Rate [7.8125e-05]
0: TRAIN [4][2980/6832]	Time 0.465 (0.347)	Data 0.00114 (0.00160)	Tok/s 68269 (74227)	Loss/tok 3.2207 (3.1818)	Learning Rate [7.8125e-05]
0: TRAIN [4][2990/6832]	Time 0.271 (0.346)	Data 0.00108 (0.00160)	Tok/s 72235 (74221)	Loss/tok 3.0627 (3.1816)	Learning Rate [7.8125e-05]
0: TRAIN [4][3000/6832]	Time 0.466 (0.346)	Data 0.00114 (0.00159)	Tok/s 66673 (74214)	Loss/tok 3.2252 (3.1815)	Learning Rate [7.8125e-05]
0: TRAIN [4][3010/6832]	Time 0.237 (0.346)	Data 0.00111 (0.00159)	Tok/s 73593 (74210)	Loss/tok 3.0292 (3.1812)	Learning Rate [7.8125e-05]
0: TRAIN [4][3020/6832]	Time 0.219 (0.346)	Data 0.00108 (0.00159)	Tok/s 72695 (74237)	Loss/tok 2.9214 (3.1809)	Learning Rate [7.8125e-05]
0: TRAIN [4][3030/6832]	Time 0.421 (0.346)	Data 0.00118 (0.00159)	Tok/s 67749 (74244)	Loss/tok 3.2013 (3.1808)	Learning Rate [7.8125e-05]
0: TRAIN [4][3040/6832]	Time 0.343 (0.346)	Data 0.00117 (0.00159)	Tok/s 70190 (74240)	Loss/tok 3.0933 (3.1808)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3050/6832]	Time 0.263 (0.346)	Data 0.00119 (0.00159)	Tok/s 74444 (74246)	Loss/tok 3.0896 (3.1806)	Learning Rate [7.8125e-05]
0: TRAIN [4][3060/6832]	Time 0.420 (0.346)	Data 0.00106 (0.00159)	Tok/s 66692 (74251)	Loss/tok 3.1955 (3.1804)	Learning Rate [7.8125e-05]
0: TRAIN [4][3070/6832]	Time 0.476 (0.346)	Data 0.00108 (0.00158)	Tok/s 71011 (74264)	Loss/tok 3.2246 (3.1804)	Learning Rate [7.8125e-05]
0: TRAIN [4][3080/6832]	Time 0.296 (0.346)	Data 0.00111 (0.00158)	Tok/s 72159 (74265)	Loss/tok 3.0786 (3.1806)	Learning Rate [7.8125e-05]
0: TRAIN [4][3090/6832]	Time 0.480 (0.346)	Data 0.00109 (0.00158)	Tok/s 71302 (74267)	Loss/tok 3.2036 (3.1804)	Learning Rate [7.8125e-05]
0: TRAIN [4][3100/6832]	Time 0.475 (0.346)	Data 0.00107 (0.00158)	Tok/s 71947 (74265)	Loss/tok 3.2528 (3.1803)	Learning Rate [7.8125e-05]
0: TRAIN [4][3110/6832]	Time 0.483 (0.346)	Data 0.00107 (0.00158)	Tok/s 76856 (74259)	Loss/tok 3.2807 (3.1804)	Learning Rate [7.8125e-05]
0: TRAIN [4][3120/6832]	Time 0.471 (0.346)	Data 0.00105 (0.00158)	Tok/s 65871 (74248)	Loss/tok 3.3066 (3.1803)	Learning Rate [7.8125e-05]
0: TRAIN [4][3130/6832]	Time 0.469 (0.346)	Data 0.00103 (0.00158)	Tok/s 69819 (74245)	Loss/tok 3.2142 (3.1803)	Learning Rate [7.8125e-05]
0: TRAIN [4][3140/6832]	Time 0.466 (0.346)	Data 0.00106 (0.00157)	Tok/s 83888 (74250)	Loss/tok 3.2025 (3.1802)	Learning Rate [7.8125e-05]
0: TRAIN [4][3150/6832]	Time 0.300 (0.346)	Data 0.00109 (0.00157)	Tok/s 69980 (74253)	Loss/tok 3.1644 (3.1800)	Learning Rate [7.8125e-05]
0: TRAIN [4][3160/6832]	Time 0.457 (0.346)	Data 0.00103 (0.00157)	Tok/s 66486 (74247)	Loss/tok 3.2145 (3.1798)	Learning Rate [7.8125e-05]
0: TRAIN [4][3170/6832]	Time 0.480 (0.346)	Data 0.00109 (0.00157)	Tok/s 87876 (74253)	Loss/tok 3.2135 (3.1796)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3180/6832]	Time 0.477 (0.346)	Data 0.00132 (0.00157)	Tok/s 75215 (74249)	Loss/tok 3.2648 (3.1798)	Learning Rate [7.8125e-05]
0: TRAIN [4][3190/6832]	Time 0.462 (0.346)	Data 0.00107 (0.00157)	Tok/s 83088 (74251)	Loss/tok 3.2481 (3.1799)	Learning Rate [7.8125e-05]
0: TRAIN [4][3200/6832]	Time 0.379 (0.346)	Data 0.00105 (0.00156)	Tok/s 66217 (74243)	Loss/tok 3.2549 (3.1797)	Learning Rate [7.8125e-05]
0: TRAIN [4][3210/6832]	Time 0.489 (0.346)	Data 0.00109 (0.00156)	Tok/s 95057 (74254)	Loss/tok 3.0835 (3.1794)	Learning Rate [7.8125e-05]
0: TRAIN [4][3220/6832]	Time 0.364 (0.346)	Data 0.00107 (0.00156)	Tok/s 71797 (74261)	Loss/tok 3.2186 (3.1792)	Learning Rate [7.8125e-05]
0: TRAIN [4][3230/6832]	Time 0.463 (0.346)	Data 0.00108 (0.00156)	Tok/s 95454 (74278)	Loss/tok 3.1263 (3.1789)	Learning Rate [7.8125e-05]
0: TRAIN [4][3240/6832]	Time 0.355 (0.346)	Data 0.00108 (0.00156)	Tok/s 69323 (74283)	Loss/tok 3.1463 (3.1789)	Learning Rate [7.8125e-05]
0: TRAIN [4][3250/6832]	Time 0.273 (0.346)	Data 0.00108 (0.00156)	Tok/s 71363 (74276)	Loss/tok 2.9274 (3.1788)	Learning Rate [7.8125e-05]
0: TRAIN [4][3260/6832]	Time 0.213 (0.346)	Data 0.00104 (0.00156)	Tok/s 72911 (74284)	Loss/tok 2.9010 (3.1787)	Learning Rate [7.8125e-05]
0: TRAIN [4][3270/6832]	Time 0.452 (0.346)	Data 0.00147 (0.00156)	Tok/s 65592 (74274)	Loss/tok 3.1998 (3.1787)	Learning Rate [7.8125e-05]
0: TRAIN [4][3280/6832]	Time 0.336 (0.346)	Data 0.00108 (0.00155)	Tok/s 71581 (74274)	Loss/tok 3.1657 (3.1784)	Learning Rate [7.8125e-05]
0: TRAIN [4][3290/6832]	Time 0.176 (0.346)	Data 0.00132 (0.00155)	Tok/s 78641 (74273)	Loss/tok 2.8320 (3.1784)	Learning Rate [7.8125e-05]
0: TRAIN [4][3300/6832]	Time 0.134 (0.346)	Data 0.00105 (0.00155)	Tok/s 78888 (74272)	Loss/tok 2.6037 (3.1783)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3310/6832]	Time 0.478 (0.346)	Data 0.00107 (0.00155)	Tok/s 67648 (74275)	Loss/tok 3.1917 (3.1783)	Learning Rate [7.8125e-05]
0: TRAIN [4][3320/6832]	Time 0.344 (0.346)	Data 0.00114 (0.00155)	Tok/s 68399 (74269)	Loss/tok 3.1232 (3.1784)	Learning Rate [7.8125e-05]
0: TRAIN [4][3330/6832]	Time 0.203 (0.346)	Data 0.00111 (0.00155)	Tok/s 74570 (74267)	Loss/tok 3.0189 (3.1782)	Learning Rate [7.8125e-05]
0: TRAIN [4][3340/6832]	Time 0.218 (0.346)	Data 0.00112 (0.00155)	Tok/s 75244 (74276)	Loss/tok 2.9622 (3.1780)	Learning Rate [7.8125e-05]
0: TRAIN [4][3350/6832]	Time 0.194 (0.346)	Data 0.00107 (0.00154)	Tok/s 76572 (74270)	Loss/tok 2.8903 (3.1779)	Learning Rate [7.8125e-05]
0: TRAIN [4][3360/6832]	Time 0.278 (0.346)	Data 0.00105 (0.00154)	Tok/s 71702 (74263)	Loss/tok 3.0893 (3.1777)	Learning Rate [7.8125e-05]
0: TRAIN [4][3370/6832]	Time 0.376 (0.346)	Data 0.00109 (0.00154)	Tok/s 68941 (74257)	Loss/tok 3.2817 (3.1776)	Learning Rate [7.8125e-05]
0: TRAIN [4][3380/6832]	Time 0.306 (0.346)	Data 0.00111 (0.00154)	Tok/s 73025 (74246)	Loss/tok 3.0790 (3.1778)	Learning Rate [7.8125e-05]
0: TRAIN [4][3390/6832]	Time 0.474 (0.346)	Data 0.00104 (0.00154)	Tok/s 73687 (74234)	Loss/tok 3.2354 (3.1775)	Learning Rate [7.8125e-05]
0: TRAIN [4][3400/6832]	Time 0.276 (0.346)	Data 0.00104 (0.00154)	Tok/s 72182 (74231)	Loss/tok 3.1068 (3.1774)	Learning Rate [7.8125e-05]
0: TRAIN [4][3410/6832]	Time 0.460 (0.346)	Data 0.00110 (0.00154)	Tok/s 68437 (74232)	Loss/tok 3.3439 (3.1773)	Learning Rate [7.8125e-05]
0: TRAIN [4][3420/6832]	Time 0.245 (0.346)	Data 0.00104 (0.00154)	Tok/s 73245 (74239)	Loss/tok 2.9660 (3.1770)	Learning Rate [7.8125e-05]
0: TRAIN [4][3430/6832]	Time 0.098 (0.346)	Data 0.00104 (0.00153)	Tok/s 58317 (74239)	Loss/tok 2.1232 (3.1768)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3440/6832]	Time 0.258 (0.346)	Data 0.00105 (0.00153)	Tok/s 73430 (74239)	Loss/tok 3.0611 (3.1768)	Learning Rate [7.8125e-05]
0: TRAIN [4][3450/6832]	Time 0.201 (0.346)	Data 0.00113 (0.00153)	Tok/s 75536 (74248)	Loss/tok 3.0220 (3.1765)	Learning Rate [7.8125e-05]
0: TRAIN [4][3460/6832]	Time 0.307 (0.346)	Data 0.00114 (0.00153)	Tok/s 70351 (74244)	Loss/tok 3.0598 (3.1765)	Learning Rate [7.8125e-05]
0: TRAIN [4][3470/6832]	Time 0.354 (0.346)	Data 0.00113 (0.00153)	Tok/s 67941 (74247)	Loss/tok 3.1864 (3.1764)	Learning Rate [7.8125e-05]
0: TRAIN [4][3480/6832]	Time 0.459 (0.346)	Data 0.00111 (0.00153)	Tok/s 74042 (74244)	Loss/tok 3.1864 (3.1764)	Learning Rate [7.8125e-05]
0: TRAIN [4][3490/6832]	Time 0.415 (0.346)	Data 0.00112 (0.00153)	Tok/s 68380 (74234)	Loss/tok 3.2512 (3.1762)	Learning Rate [7.8125e-05]
0: TRAIN [4][3500/6832]	Time 0.485 (0.346)	Data 0.00104 (0.00153)	Tok/s 77778 (74233)	Loss/tok 3.2210 (3.1762)	Learning Rate [7.8125e-05]
0: TRAIN [4][3510/6832]	Time 0.096 (0.346)	Data 0.00105 (0.00152)	Tok/s 61875 (74231)	Loss/tok 2.0936 (3.1759)	Learning Rate [7.8125e-05]
0: TRAIN [4][3520/6832]	Time 0.266 (0.346)	Data 0.00115 (0.00152)	Tok/s 73592 (74221)	Loss/tok 2.9468 (3.1757)	Learning Rate [7.8125e-05]
0: TRAIN [4][3530/6832]	Time 0.460 (0.346)	Data 0.00111 (0.00152)	Tok/s 66840 (74220)	Loss/tok 3.1942 (3.1756)	Learning Rate [7.8125e-05]
0: TRAIN [4][3540/6832]	Time 0.478 (0.346)	Data 0.00105 (0.00152)	Tok/s 63952 (74219)	Loss/tok 3.2280 (3.1755)	Learning Rate [7.8125e-05]
0: TRAIN [4][3550/6832]	Time 0.229 (0.346)	Data 0.00105 (0.00152)	Tok/s 73142 (74217)	Loss/tok 2.9416 (3.1754)	Learning Rate [7.8125e-05]
0: TRAIN [4][3560/6832]	Time 0.448 (0.346)	Data 0.00112 (0.00152)	Tok/s 70152 (74217)	Loss/tok 3.2339 (3.1754)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3570/6832]	Time 0.340 (0.346)	Data 0.00111 (0.00152)	Tok/s 69745 (74215)	Loss/tok 3.1325 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [4][3580/6832]	Time 0.411 (0.346)	Data 0.00111 (0.00152)	Tok/s 72312 (74221)	Loss/tok 3.1754 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [4][3590/6832]	Time 0.482 (0.346)	Data 0.00114 (0.00151)	Tok/s 69931 (74218)	Loss/tok 3.2529 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [4][3600/6832]	Time 0.458 (0.346)	Data 0.00110 (0.00151)	Tok/s 66841 (74221)	Loss/tok 3.2727 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [4][3610/6832]	Time 0.479 (0.346)	Data 0.00104 (0.00151)	Tok/s 78743 (74218)	Loss/tok 3.2386 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [4][3620/6832]	Time 0.375 (0.346)	Data 0.00111 (0.00151)	Tok/s 69853 (74211)	Loss/tok 3.1803 (3.1753)	Learning Rate [7.8125e-05]
0: TRAIN [4][3630/6832]	Time 0.402 (0.346)	Data 0.00106 (0.00151)	Tok/s 68810 (74212)	Loss/tok 3.1643 (3.1752)	Learning Rate [7.8125e-05]
0: TRAIN [4][3640/6832]	Time 0.156 (0.346)	Data 0.00112 (0.00151)	Tok/s 79753 (74212)	Loss/tok 2.7853 (3.1750)	Learning Rate [7.8125e-05]
0: TRAIN [4][3650/6832]	Time 0.482 (0.346)	Data 0.00109 (0.00151)	Tok/s 70102 (74212)	Loss/tok 3.2409 (3.1750)	Learning Rate [7.8125e-05]
0: TRAIN [4][3660/6832]	Time 0.479 (0.347)	Data 0.00112 (0.00151)	Tok/s 71459 (74218)	Loss/tok 3.2110 (3.1748)	Learning Rate [7.8125e-05]
0: TRAIN [4][3670/6832]	Time 0.488 (0.347)	Data 0.00027 (0.00151)	Tok/s 78595 (74218)	Loss/tok 3.2267 (3.1747)	Learning Rate [7.8125e-05]
0: TRAIN [4][3680/6832]	Time 0.147 (0.347)	Data 0.00106 (0.00151)	Tok/s 80726 (74230)	Loss/tok 2.7336 (3.1745)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3690/6832]	Time 0.154 (0.346)	Data 0.00125 (0.00150)	Tok/s 74079 (74222)	Loss/tok 2.6477 (3.1741)	Learning Rate [7.8125e-05]
0: TRAIN [4][3700/6832]	Time 0.468 (0.346)	Data 0.00107 (0.00150)	Tok/s 68998 (74221)	Loss/tok 3.2382 (3.1740)	Learning Rate [7.8125e-05]
0: TRAIN [4][3710/6832]	Time 0.461 (0.346)	Data 0.00111 (0.00150)	Tok/s 101071 (74225)	Loss/tok 3.0676 (3.1737)	Learning Rate [7.8125e-05]
0: TRAIN [4][3720/6832]	Time 0.180 (0.346)	Data 0.00105 (0.00150)	Tok/s 79830 (74225)	Loss/tok 2.9037 (3.1735)	Learning Rate [7.8125e-05]
0: TRAIN [4][3730/6832]	Time 0.486 (0.346)	Data 0.00108 (0.00150)	Tok/s 80372 (74230)	Loss/tok 3.2407 (3.1736)	Learning Rate [7.8125e-05]
0: TRAIN [4][3740/6832]	Time 0.244 (0.346)	Data 0.00112 (0.00150)	Tok/s 74921 (74231)	Loss/tok 3.0392 (3.1736)	Learning Rate [7.8125e-05]
0: TRAIN [4][3750/6832]	Time 0.240 (0.346)	Data 0.00111 (0.00150)	Tok/s 72054 (74230)	Loss/tok 3.0293 (3.1734)	Learning Rate [7.8125e-05]
0: TRAIN [4][3760/6832]	Time 0.174 (0.346)	Data 0.00114 (0.00150)	Tok/s 77046 (74238)	Loss/tok 2.7960 (3.1732)	Learning Rate [7.8125e-05]
0: TRAIN [4][3770/6832]	Time 0.347 (0.346)	Data 0.00104 (0.00150)	Tok/s 72226 (74238)	Loss/tok 3.1180 (3.1731)	Learning Rate [7.8125e-05]
0: TRAIN [4][3780/6832]	Time 0.369 (0.346)	Data 0.00107 (0.00150)	Tok/s 67164 (74232)	Loss/tok 3.1449 (3.1731)	Learning Rate [7.8125e-05]
0: TRAIN [4][3790/6832]	Time 0.481 (0.346)	Data 0.00107 (0.00149)	Tok/s 77096 (74239)	Loss/tok 3.1925 (3.1728)	Learning Rate [7.8125e-05]
0: TRAIN [4][3800/6832]	Time 0.375 (0.346)	Data 0.00118 (0.00149)	Tok/s 68775 (74230)	Loss/tok 3.2128 (3.1728)	Learning Rate [7.8125e-05]
0: TRAIN [4][3810/6832]	Time 0.444 (0.346)	Data 0.00108 (0.00149)	Tok/s 68001 (74224)	Loss/tok 3.2506 (3.1728)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3820/6832]	Time 0.242 (0.346)	Data 0.00106 (0.00149)	Tok/s 72475 (74226)	Loss/tok 3.0221 (3.1727)	Learning Rate [7.8125e-05]
0: TRAIN [4][3830/6832]	Time 0.268 (0.346)	Data 0.00115 (0.00149)	Tok/s 71591 (74226)	Loss/tok 3.0424 (3.1725)	Learning Rate [7.8125e-05]
0: TRAIN [4][3840/6832]	Time 0.472 (0.346)	Data 0.00105 (0.00149)	Tok/s 67372 (74216)	Loss/tok 3.3004 (3.1725)	Learning Rate [7.8125e-05]
0: TRAIN [4][3850/6832]	Time 0.472 (0.346)	Data 0.00108 (0.00149)	Tok/s 72527 (74216)	Loss/tok 3.2255 (3.1724)	Learning Rate [7.8125e-05]
0: TRAIN [4][3860/6832]	Time 0.252 (0.346)	Data 0.00109 (0.00149)	Tok/s 72318 (74229)	Loss/tok 3.0130 (3.1721)	Learning Rate [7.8125e-05]
0: TRAIN [4][3870/6832]	Time 0.470 (0.346)	Data 0.00107 (0.00149)	Tok/s 66659 (74226)	Loss/tok 3.1639 (3.1719)	Learning Rate [7.8125e-05]
0: TRAIN [4][3880/6832]	Time 0.480 (0.346)	Data 0.00110 (0.00149)	Tok/s 68534 (74220)	Loss/tok 3.3184 (3.1717)	Learning Rate [7.8125e-05]
0: TRAIN [4][3890/6832]	Time 0.278 (0.346)	Data 0.00107 (0.00148)	Tok/s 70333 (74218)	Loss/tok 3.0396 (3.1715)	Learning Rate [7.8125e-05]
0: TRAIN [4][3900/6832]	Time 0.335 (0.345)	Data 0.00109 (0.00148)	Tok/s 69470 (74214)	Loss/tok 3.1239 (3.1713)	Learning Rate [7.8125e-05]
0: TRAIN [4][3910/6832]	Time 0.147 (0.345)	Data 0.00111 (0.00148)	Tok/s 76748 (74212)	Loss/tok 2.6380 (3.1711)	Learning Rate [7.8125e-05]
0: TRAIN [4][3920/6832]	Time 0.482 (0.345)	Data 0.00130 (0.00148)	Tok/s 77335 (74218)	Loss/tok 3.2197 (3.1710)	Learning Rate [7.8125e-05]
0: TRAIN [4][3930/6832]	Time 0.221 (0.345)	Data 0.00145 (0.00148)	Tok/s 74118 (74210)	Loss/tok 2.8965 (3.1709)	Learning Rate [7.8125e-05]
0: TRAIN [4][3940/6832]	Time 0.484 (0.346)	Data 0.00113 (0.00148)	Tok/s 96327 (74221)	Loss/tok 2.9707 (3.1708)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][3950/6832]	Time 0.208 (0.346)	Data 0.00109 (0.00148)	Tok/s 75454 (74230)	Loss/tok 2.9831 (3.1706)	Learning Rate [7.8125e-05]
0: TRAIN [4][3960/6832]	Time 0.363 (0.346)	Data 0.00114 (0.00148)	Tok/s 69078 (74235)	Loss/tok 3.2112 (3.1705)	Learning Rate [7.8125e-05]
0: TRAIN [4][3970/6832]	Time 0.483 (0.346)	Data 0.00112 (0.00148)	Tok/s 78049 (74230)	Loss/tok 3.2303 (3.1705)	Learning Rate [7.8125e-05]
0: TRAIN [4][3980/6832]	Time 0.472 (0.346)	Data 0.00114 (0.00148)	Tok/s 64859 (74222)	Loss/tok 3.2291 (3.1706)	Learning Rate [7.8125e-05]
0: TRAIN [4][3990/6832]	Time 0.275 (0.346)	Data 0.00112 (0.00148)	Tok/s 69832 (74215)	Loss/tok 3.0589 (3.1705)	Learning Rate [7.8125e-05]
0: TRAIN [4][4000/6832]	Time 0.424 (0.346)	Data 0.00111 (0.00147)	Tok/s 65184 (74210)	Loss/tok 3.1447 (3.1704)	Learning Rate [7.8125e-05]
0: TRAIN [4][4010/6832]	Time 0.484 (0.346)	Data 0.00103 (0.00147)	Tok/s 76584 (74215)	Loss/tok 3.1745 (3.1701)	Learning Rate [7.8125e-05]
0: TRAIN [4][4020/6832]	Time 0.353 (0.346)	Data 0.00110 (0.00147)	Tok/s 66189 (74210)	Loss/tok 3.1059 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [4][4030/6832]	Time 0.467 (0.346)	Data 0.00106 (0.00147)	Tok/s 76523 (74209)	Loss/tok 3.2079 (3.1699)	Learning Rate [7.8125e-05]
0: TRAIN [4][4040/6832]	Time 0.468 (0.346)	Data 0.00129 (0.00147)	Tok/s 69046 (74212)	Loss/tok 3.3059 (3.1698)	Learning Rate [7.8125e-05]
0: TRAIN [4][4050/6832]	Time 0.200 (0.346)	Data 0.00105 (0.00147)	Tok/s 76248 (74210)	Loss/tok 2.9717 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [4][4060/6832]	Time 0.453 (0.346)	Data 0.00108 (0.00147)	Tok/s 72358 (74205)	Loss/tok 3.2187 (3.1695)	Learning Rate [7.8125e-05]
0: TRAIN [4][4070/6832]	Time 0.473 (0.346)	Data 0.00105 (0.00147)	Tok/s 65882 (74199)	Loss/tok 3.2410 (3.1694)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4080/6832]	Time 0.325 (0.346)	Data 0.00109 (0.00147)	Tok/s 70970 (74195)	Loss/tok 3.1194 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [4][4090/6832]	Time 0.469 (0.346)	Data 0.00102 (0.00147)	Tok/s 64344 (74196)	Loss/tok 3.2991 (3.1694)	Learning Rate [7.8125e-05]
0: TRAIN [4][4100/6832]	Time 0.476 (0.346)	Data 0.00103 (0.00147)	Tok/s 66927 (74187)	Loss/tok 3.2627 (3.1693)	Learning Rate [7.8125e-05]
0: TRAIN [4][4110/6832]	Time 0.265 (0.346)	Data 0.00108 (0.00147)	Tok/s 75239 (74183)	Loss/tok 2.9597 (3.1692)	Learning Rate [7.8125e-05]
0: TRAIN [4][4120/6832]	Time 0.482 (0.346)	Data 0.00103 (0.00146)	Tok/s 69213 (74186)	Loss/tok 3.2547 (3.1691)	Learning Rate [7.8125e-05]
0: TRAIN [4][4130/6832]	Time 0.327 (0.346)	Data 0.00108 (0.00146)	Tok/s 70504 (74180)	Loss/tok 3.0318 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [4][4140/6832]	Time 0.478 (0.346)	Data 0.00103 (0.00146)	Tok/s 71686 (74174)	Loss/tok 3.3131 (3.1689)	Learning Rate [7.8125e-05]
0: TRAIN [4][4150/6832]	Time 0.374 (0.346)	Data 0.00106 (0.00146)	Tok/s 68082 (74167)	Loss/tok 3.1346 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [4][4160/6832]	Time 0.144 (0.346)	Data 0.00104 (0.00146)	Tok/s 82714 (74164)	Loss/tok 2.7451 (3.1688)	Learning Rate [7.8125e-05]
0: TRAIN [4][4170/6832]	Time 0.139 (0.346)	Data 0.00107 (0.00146)	Tok/s 81496 (74159)	Loss/tok 2.7204 (3.1687)	Learning Rate [7.8125e-05]
0: TRAIN [4][4180/6832]	Time 0.141 (0.346)	Data 0.00103 (0.00146)	Tok/s 80292 (74161)	Loss/tok 2.6242 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [4][4190/6832]	Time 0.230 (0.346)	Data 0.00113 (0.00146)	Tok/s 72704 (74159)	Loss/tok 2.8949 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [4][4200/6832]	Time 0.231 (0.346)	Data 0.00103 (0.00146)	Tok/s 75441 (74158)	Loss/tok 2.9362 (3.1686)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4210/6832]	Time 0.459 (0.346)	Data 0.00106 (0.00146)	Tok/s 67395 (74151)	Loss/tok 3.1613 (3.1685)	Learning Rate [7.8125e-05]
0: TRAIN [4][4220/6832]	Time 0.477 (0.346)	Data 0.00099 (0.00146)	Tok/s 66796 (74144)	Loss/tok 3.2075 (3.1684)	Learning Rate [7.8125e-05]
0: TRAIN [4][4230/6832]	Time 0.480 (0.346)	Data 0.00112 (0.00145)	Tok/s 88042 (74147)	Loss/tok 3.1640 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [4][4240/6832]	Time 0.297 (0.346)	Data 0.00128 (0.00145)	Tok/s 72514 (74146)	Loss/tok 3.1200 (3.1681)	Learning Rate [7.8125e-05]
0: TRAIN [4][4250/6832]	Time 0.195 (0.346)	Data 0.00099 (0.00145)	Tok/s 76150 (74140)	Loss/tok 2.9574 (3.1680)	Learning Rate [7.8125e-05]
0: TRAIN [4][4260/6832]	Time 0.463 (0.346)	Data 0.00100 (0.00145)	Tok/s 78373 (74138)	Loss/tok 3.2092 (3.1679)	Learning Rate [7.8125e-05]
0: TRAIN [4][4270/6832]	Time 0.431 (0.346)	Data 0.00118 (0.00145)	Tok/s 66021 (74136)	Loss/tok 3.2086 (3.1678)	Learning Rate [7.8125e-05]
0: TRAIN [4][4280/6832]	Time 0.198 (0.346)	Data 0.00119 (0.00145)	Tok/s 76453 (74135)	Loss/tok 2.8506 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [4][4290/6832]	Time 0.417 (0.346)	Data 0.00107 (0.00145)	Tok/s 65569 (74132)	Loss/tok 3.0846 (3.1676)	Learning Rate [7.8125e-05]
0: TRAIN [4][4300/6832]	Time 0.442 (0.346)	Data 0.00106 (0.00145)	Tok/s 69141 (74128)	Loss/tok 3.1592 (3.1675)	Learning Rate [7.8125e-05]
0: TRAIN [4][4310/6832]	Time 0.313 (0.346)	Data 0.00102 (0.00145)	Tok/s 72436 (74123)	Loss/tok 3.0520 (3.1674)	Learning Rate [7.8125e-05]
0: TRAIN [4][4320/6832]	Time 0.484 (0.346)	Data 0.00103 (0.00145)	Tok/s 85642 (74132)	Loss/tok 3.1204 (3.1672)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4330/6832]	Time 0.245 (0.346)	Data 0.00120 (0.00145)	Tok/s 73986 (74130)	Loss/tok 2.9889 (3.1671)	Learning Rate [7.8125e-05]
0: TRAIN [4][4340/6832]	Time 0.310 (0.346)	Data 0.00108 (0.00145)	Tok/s 70967 (74127)	Loss/tok 3.1088 (3.1672)	Learning Rate [7.8125e-05]
0: TRAIN [4][4350/6832]	Time 0.206 (0.346)	Data 0.00112 (0.00144)	Tok/s 75467 (74132)	Loss/tok 2.8198 (3.1670)	Learning Rate [7.8125e-05]
0: TRAIN [4][4360/6832]	Time 0.116 (0.346)	Data 0.00104 (0.00144)	Tok/s 72821 (74132)	Loss/tok 2.3632 (3.1670)	Learning Rate [7.8125e-05]
0: TRAIN [4][4370/6832]	Time 0.237 (0.346)	Data 0.00106 (0.00144)	Tok/s 73585 (74129)	Loss/tok 2.9889 (3.1667)	Learning Rate [7.8125e-05]
0: TRAIN [4][4380/6832]	Time 0.480 (0.346)	Data 0.00105 (0.00144)	Tok/s 96930 (74138)	Loss/tok 2.9862 (3.1667)	Learning Rate [7.8125e-05]
0: TRAIN [4][4390/6832]	Time 0.137 (0.346)	Data 0.00102 (0.00144)	Tok/s 76886 (74152)	Loss/tok 2.5087 (3.1664)	Learning Rate [7.8125e-05]
0: TRAIN [4][4400/6832]	Time 0.477 (0.346)	Data 0.00105 (0.00144)	Tok/s 66097 (74164)	Loss/tok 3.2110 (3.1661)	Learning Rate [7.8125e-05]
0: TRAIN [4][4410/6832]	Time 0.220 (0.346)	Data 0.00100 (0.00144)	Tok/s 76666 (74168)	Loss/tok 3.0052 (3.1659)	Learning Rate [7.8125e-05]
0: TRAIN [4][4420/6832]	Time 0.473 (0.346)	Data 0.00103 (0.00144)	Tok/s 69511 (74164)	Loss/tok 3.2815 (3.1658)	Learning Rate [7.8125e-05]
0: TRAIN [4][4430/6832]	Time 0.378 (0.346)	Data 0.00108 (0.00144)	Tok/s 68542 (74167)	Loss/tok 3.0745 (3.1656)	Learning Rate [7.8125e-05]
0: TRAIN [4][4440/6832]	Time 0.486 (0.346)	Data 0.00105 (0.00144)	Tok/s 90778 (74164)	Loss/tok 3.1094 (3.1655)	Learning Rate [7.8125e-05]
0: TRAIN [4][4450/6832]	Time 0.478 (0.346)	Data 0.00105 (0.00144)	Tok/s 73872 (74172)	Loss/tok 3.2341 (3.1652)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4460/6832]	Time 0.479 (0.346)	Data 0.00111 (0.00144)	Tok/s 70303 (74172)	Loss/tok 3.1972 (3.1652)	Learning Rate [7.8125e-05]
0: TRAIN [4][4470/6832]	Time 0.474 (0.346)	Data 0.00101 (0.00144)	Tok/s 75698 (74176)	Loss/tok 3.2342 (3.1649)	Learning Rate [7.8125e-05]
0: TRAIN [4][4480/6832]	Time 0.484 (0.346)	Data 0.00106 (0.00143)	Tok/s 80873 (74178)	Loss/tok 3.1147 (3.1648)	Learning Rate [7.8125e-05]
0: TRAIN [4][4490/6832]	Time 0.165 (0.346)	Data 0.00114 (0.00143)	Tok/s 78965 (74195)	Loss/tok 2.7867 (3.1644)	Learning Rate [7.8125e-05]
0: TRAIN [4][4500/6832]	Time 0.480 (0.346)	Data 0.00105 (0.00143)	Tok/s 75961 (74194)	Loss/tok 3.3304 (3.1643)	Learning Rate [7.8125e-05]
0: TRAIN [4][4510/6832]	Time 0.165 (0.346)	Data 0.00105 (0.00143)	Tok/s 78330 (74196)	Loss/tok 2.8195 (3.1643)	Learning Rate [7.8125e-05]
0: TRAIN [4][4520/6832]	Time 0.343 (0.346)	Data 0.00106 (0.00143)	Tok/s 68421 (74199)	Loss/tok 3.0250 (3.1641)	Learning Rate [7.8125e-05]
0: TRAIN [4][4530/6832]	Time 0.471 (0.346)	Data 0.00112 (0.00143)	Tok/s 65008 (74195)	Loss/tok 3.1236 (3.1640)	Learning Rate [7.8125e-05]
0: TRAIN [4][4540/6832]	Time 0.257 (0.346)	Data 0.00104 (0.00143)	Tok/s 75740 (74202)	Loss/tok 3.0095 (3.1638)	Learning Rate [7.8125e-05]
0: TRAIN [4][4550/6832]	Time 0.443 (0.346)	Data 0.00131 (0.00143)	Tok/s 66147 (74198)	Loss/tok 3.1540 (3.1638)	Learning Rate [7.8125e-05]
0: TRAIN [4][4560/6832]	Time 0.397 (0.346)	Data 0.00103 (0.00143)	Tok/s 68740 (74195)	Loss/tok 3.1450 (3.1637)	Learning Rate [7.8125e-05]
0: TRAIN [4][4570/6832]	Time 0.478 (0.346)	Data 0.00108 (0.00143)	Tok/s 76130 (74194)	Loss/tok 3.1759 (3.1636)	Learning Rate [7.8125e-05]
0: TRAIN [4][4580/6832]	Time 0.369 (0.346)	Data 0.00105 (0.00143)	Tok/s 68004 (74191)	Loss/tok 3.1566 (3.1634)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4590/6832]	Time 0.430 (0.346)	Data 0.00140 (0.00143)	Tok/s 66567 (74196)	Loss/tok 3.1633 (3.1633)	Learning Rate [7.8125e-05]
0: TRAIN [4][4600/6832]	Time 0.321 (0.346)	Data 0.00115 (0.00143)	Tok/s 71838 (74199)	Loss/tok 3.0607 (3.1632)	Learning Rate [7.8125e-05]
0: TRAIN [4][4610/6832]	Time 0.111 (0.346)	Data 0.00107 (0.00142)	Tok/s 76192 (74197)	Loss/tok 2.3383 (3.1630)	Learning Rate [7.8125e-05]
0: TRAIN [4][4620/6832]	Time 0.202 (0.346)	Data 0.00104 (0.00142)	Tok/s 77703 (74193)	Loss/tok 2.9115 (3.1629)	Learning Rate [7.8125e-05]
0: TRAIN [4][4630/6832]	Time 0.476 (0.346)	Data 0.00100 (0.00142)	Tok/s 75145 (74192)	Loss/tok 3.1510 (3.1627)	Learning Rate [7.8125e-05]
0: TRAIN [4][4640/6832]	Time 0.481 (0.346)	Data 0.00106 (0.00142)	Tok/s 80767 (74193)	Loss/tok 3.1657 (3.1626)	Learning Rate [7.8125e-05]
0: TRAIN [4][4650/6832]	Time 0.449 (0.346)	Data 0.00108 (0.00142)	Tok/s 69307 (74197)	Loss/tok 3.2157 (3.1625)	Learning Rate [7.8125e-05]
0: TRAIN [4][4660/6832]	Time 0.133 (0.346)	Data 0.00104 (0.00142)	Tok/s 84347 (74212)	Loss/tok 2.5982 (3.1622)	Learning Rate [7.8125e-05]
0: TRAIN [4][4670/6832]	Time 0.430 (0.346)	Data 0.00102 (0.00142)	Tok/s 67001 (74210)	Loss/tok 3.1346 (3.1621)	Learning Rate [7.8125e-05]
0: TRAIN [4][4680/6832]	Time 0.312 (0.346)	Data 0.00117 (0.00142)	Tok/s 71678 (74214)	Loss/tok 3.0846 (3.1618)	Learning Rate [7.8125e-05]
0: TRAIN [4][4690/6832]	Time 0.227 (0.346)	Data 0.00106 (0.00142)	Tok/s 74944 (74212)	Loss/tok 2.9350 (3.1617)	Learning Rate [7.8125e-05]
0: TRAIN [4][4700/6832]	Time 0.374 (0.346)	Data 0.00106 (0.00142)	Tok/s 69938 (74206)	Loss/tok 3.0313 (3.1615)	Learning Rate [7.8125e-05]
0: TRAIN [4][4710/6832]	Time 0.303 (0.346)	Data 0.00114 (0.00142)	Tok/s 70512 (74208)	Loss/tok 2.9950 (3.1614)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4720/6832]	Time 0.417 (0.346)	Data 0.00107 (0.00142)	Tok/s 67474 (74201)	Loss/tok 3.2345 (3.1613)	Learning Rate [7.8125e-05]
0: TRAIN [4][4730/6832]	Time 0.258 (0.346)	Data 0.00107 (0.00142)	Tok/s 73408 (74199)	Loss/tok 2.9988 (3.1612)	Learning Rate [7.8125e-05]
0: TRAIN [4][4740/6832]	Time 0.223 (0.346)	Data 0.00104 (0.00142)	Tok/s 76467 (74208)	Loss/tok 2.9154 (3.1610)	Learning Rate [7.8125e-05]
0: TRAIN [4][4750/6832]	Time 0.473 (0.346)	Data 0.00108 (0.00142)	Tok/s 63493 (74213)	Loss/tok 3.2661 (3.1608)	Learning Rate [7.8125e-05]
0: TRAIN [4][4760/6832]	Time 0.264 (0.346)	Data 0.00111 (0.00141)	Tok/s 75515 (74211)	Loss/tok 2.9731 (3.1607)	Learning Rate [7.8125e-05]
0: TRAIN [4][4770/6832]	Time 0.307 (0.346)	Data 0.00116 (0.00141)	Tok/s 73589 (74212)	Loss/tok 3.0308 (3.1606)	Learning Rate [7.8125e-05]
0: TRAIN [4][4780/6832]	Time 0.469 (0.346)	Data 0.00106 (0.00141)	Tok/s 67960 (74210)	Loss/tok 3.1734 (3.1605)	Learning Rate [7.8125e-05]
0: TRAIN [4][4790/6832]	Time 0.481 (0.346)	Data 0.00106 (0.00141)	Tok/s 89943 (74210)	Loss/tok 3.0978 (3.1604)	Learning Rate [7.8125e-05]
0: TRAIN [4][4800/6832]	Time 0.213 (0.346)	Data 0.00108 (0.00141)	Tok/s 74980 (74205)	Loss/tok 2.9102 (3.1602)	Learning Rate [7.8125e-05]
0: TRAIN [4][4810/6832]	Time 0.224 (0.346)	Data 0.00103 (0.00141)	Tok/s 73439 (74208)	Loss/tok 2.9387 (3.1600)	Learning Rate [7.8125e-05]
0: TRAIN [4][4820/6832]	Time 0.248 (0.346)	Data 0.00104 (0.00141)	Tok/s 74915 (74206)	Loss/tok 2.9407 (3.1597)	Learning Rate [7.8125e-05]
0: TRAIN [4][4830/6832]	Time 0.379 (0.346)	Data 0.00107 (0.00141)	Tok/s 70101 (74210)	Loss/tok 3.1517 (3.1596)	Learning Rate [7.8125e-05]
0: TRAIN [4][4840/6832]	Time 0.292 (0.346)	Data 0.00115 (0.00141)	Tok/s 69241 (74207)	Loss/tok 3.0415 (3.1594)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4850/6832]	Time 0.247 (0.346)	Data 0.00103 (0.00141)	Tok/s 72419 (74202)	Loss/tok 2.9083 (3.1594)	Learning Rate [7.8125e-05]
0: TRAIN [4][4860/6832]	Time 0.393 (0.346)	Data 0.00110 (0.00141)	Tok/s 69803 (74201)	Loss/tok 3.1082 (3.1593)	Learning Rate [7.8125e-05]
0: TRAIN [4][4870/6832]	Time 0.437 (0.346)	Data 0.00111 (0.00141)	Tok/s 65481 (74198)	Loss/tok 3.1070 (3.1592)	Learning Rate [7.8125e-05]
0: TRAIN [4][4880/6832]	Time 0.465 (0.346)	Data 0.00109 (0.00141)	Tok/s 97090 (74204)	Loss/tok 3.0701 (3.1590)	Learning Rate [7.8125e-05]
0: TRAIN [4][4890/6832]	Time 0.303 (0.346)	Data 0.00106 (0.00141)	Tok/s 74434 (74204)	Loss/tok 3.0042 (3.1588)	Learning Rate [7.8125e-05]
0: TRAIN [4][4900/6832]	Time 0.474 (0.346)	Data 0.00103 (0.00141)	Tok/s 67395 (74202)	Loss/tok 3.1841 (3.1587)	Learning Rate [7.8125e-05]
0: TRAIN [4][4910/6832]	Time 0.201 (0.346)	Data 0.00103 (0.00141)	Tok/s 75327 (74214)	Loss/tok 2.8640 (3.1584)	Learning Rate [7.8125e-05]
0: TRAIN [4][4920/6832]	Time 0.316 (0.346)	Data 0.00104 (0.00141)	Tok/s 71897 (74211)	Loss/tok 3.0578 (3.1583)	Learning Rate [7.8125e-05]
0: TRAIN [4][4930/6832]	Time 0.237 (0.346)	Data 0.00101 (0.00140)	Tok/s 73547 (74207)	Loss/tok 2.9830 (3.1580)	Learning Rate [7.8125e-05]
0: TRAIN [4][4940/6832]	Time 0.467 (0.346)	Data 0.00108 (0.00140)	Tok/s 67650 (74207)	Loss/tok 3.2090 (3.1579)	Learning Rate [7.8125e-05]
0: TRAIN [4][4950/6832]	Time 0.355 (0.346)	Data 0.00121 (0.00140)	Tok/s 69199 (74204)	Loss/tok 3.0509 (3.1577)	Learning Rate [7.8125e-05]
0: TRAIN [4][4960/6832]	Time 0.226 (0.346)	Data 0.00104 (0.00140)	Tok/s 68901 (74200)	Loss/tok 2.8904 (3.1576)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][4970/6832]	Time 0.146 (0.346)	Data 0.00117 (0.00140)	Tok/s 81113 (74213)	Loss/tok 2.7605 (3.1573)	Learning Rate [7.8125e-05]
0: TRAIN [4][4980/6832]	Time 0.112 (0.346)	Data 0.00112 (0.00140)	Tok/s 75713 (74218)	Loss/tok 2.3676 (3.1571)	Learning Rate [7.8125e-05]
0: TRAIN [4][4990/6832]	Time 0.155 (0.346)	Data 0.00027 (0.00140)	Tok/s 79624 (74218)	Loss/tok 2.7112 (3.1570)	Learning Rate [7.8125e-05]
0: TRAIN [4][5000/6832]	Time 0.292 (0.346)	Data 0.00104 (0.00140)	Tok/s 70570 (74213)	Loss/tok 3.0542 (3.1568)	Learning Rate [7.8125e-05]
0: TRAIN [4][5010/6832]	Time 0.275 (0.346)	Data 0.00106 (0.00140)	Tok/s 73564 (74215)	Loss/tok 3.0182 (3.1568)	Learning Rate [7.8125e-05]
0: TRAIN [4][5020/6832]	Time 0.377 (0.346)	Data 0.00100 (0.00140)	Tok/s 69226 (74208)	Loss/tok 3.1428 (3.1566)	Learning Rate [7.8125e-05]
0: TRAIN [4][5030/6832]	Time 0.463 (0.346)	Data 0.00106 (0.00140)	Tok/s 85680 (74201)	Loss/tok 3.1214 (3.1565)	Learning Rate [7.8125e-05]
0: TRAIN [4][5040/6832]	Time 0.487 (0.346)	Data 0.00104 (0.00140)	Tok/s 92651 (74201)	Loss/tok 3.0383 (3.1563)	Learning Rate [7.8125e-05]
0: TRAIN [4][5050/6832]	Time 0.320 (0.346)	Data 0.00106 (0.00140)	Tok/s 68819 (74200)	Loss/tok 3.0487 (3.1561)	Learning Rate [7.8125e-05]
0: TRAIN [4][5060/6832]	Time 0.337 (0.346)	Data 0.00102 (0.00140)	Tok/s 70630 (74194)	Loss/tok 3.0627 (3.1560)	Learning Rate [7.8125e-05]
0: TRAIN [4][5070/6832]	Time 0.341 (0.346)	Data 0.00105 (0.00140)	Tok/s 69102 (74189)	Loss/tok 3.0875 (3.1559)	Learning Rate [7.8125e-05]
0: TRAIN [4][5080/6832]	Time 0.483 (0.346)	Data 0.00103 (0.00140)	Tok/s 79334 (74189)	Loss/tok 3.1021 (3.1557)	Learning Rate [7.8125e-05]
0: TRAIN [4][5090/6832]	Time 0.421 (0.346)	Data 0.00102 (0.00140)	Tok/s 65648 (74184)	Loss/tok 3.0576 (3.1556)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][5100/6832]	Time 0.348 (0.346)	Data 0.00105 (0.00139)	Tok/s 69134 (74183)	Loss/tok 3.0341 (3.1554)	Learning Rate [7.8125e-05]
0: TRAIN [4][5110/6832]	Time 0.302 (0.346)	Data 0.00108 (0.00139)	Tok/s 72471 (74187)	Loss/tok 3.1046 (3.1551)	Learning Rate [7.8125e-05]
0: TRAIN [4][5120/6832]	Time 0.481 (0.346)	Data 0.00113 (0.00139)	Tok/s 96766 (74187)	Loss/tok 3.0469 (3.1550)	Learning Rate [7.8125e-05]
0: TRAIN [4][5130/6832]	Time 0.482 (0.346)	Data 0.00106 (0.00139)	Tok/s 82225 (74186)	Loss/tok 3.0853 (3.1547)	Learning Rate [7.8125e-05]
0: TRAIN [4][5140/6832]	Time 0.484 (0.346)	Data 0.00107 (0.00139)	Tok/s 69752 (74179)	Loss/tok 3.1736 (3.1546)	Learning Rate [7.8125e-05]
0: TRAIN [4][5150/6832]	Time 0.487 (0.346)	Data 0.00112 (0.00139)	Tok/s 80334 (74177)	Loss/tok 3.1594 (3.1544)	Learning Rate [7.8125e-05]
0: TRAIN [4][5160/6832]	Time 0.394 (0.346)	Data 0.00116 (0.00139)	Tok/s 70150 (74176)	Loss/tok 3.2498 (3.1544)	Learning Rate [7.8125e-05]
0: TRAIN [4][5170/6832]	Time 0.255 (0.346)	Data 0.00107 (0.00139)	Tok/s 75572 (74182)	Loss/tok 2.9891 (3.1543)	Learning Rate [7.8125e-05]
0: TRAIN [4][5180/6832]	Time 0.481 (0.346)	Data 0.00125 (0.00139)	Tok/s 78056 (74189)	Loss/tok 3.1932 (3.1541)	Learning Rate [7.8125e-05]
0: TRAIN [4][5190/6832]	Time 0.102 (0.346)	Data 0.00108 (0.00139)	Tok/s 56664 (74190)	Loss/tok 2.0115 (3.1538)	Learning Rate [7.8125e-05]
0: TRAIN [4][5200/6832]	Time 0.117 (0.346)	Data 0.00105 (0.00139)	Tok/s 82398 (74201)	Loss/tok 2.5195 (3.1536)	Learning Rate [7.8125e-05]
0: TRAIN [4][5210/6832]	Time 0.452 (0.346)	Data 0.00108 (0.00139)	Tok/s 65705 (74194)	Loss/tok 3.2159 (3.1535)	Learning Rate [7.8125e-05]
0: TRAIN [4][5220/6832]	Time 0.488 (0.346)	Data 0.00111 (0.00139)	Tok/s 99840 (74196)	Loss/tok 2.8808 (3.1533)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][5230/6832]	Time 0.183 (0.346)	Data 0.00108 (0.00139)	Tok/s 78367 (74194)	Loss/tok 2.7989 (3.1532)	Learning Rate [7.8125e-05]
0: TRAIN [4][5240/6832]	Time 0.428 (0.346)	Data 0.00109 (0.00139)	Tok/s 66438 (74194)	Loss/tok 3.0562 (3.1530)	Learning Rate [7.8125e-05]
0: TRAIN [4][5250/6832]	Time 0.365 (0.346)	Data 0.00150 (0.00139)	Tok/s 67223 (74194)	Loss/tok 3.1052 (3.1528)	Learning Rate [7.8125e-05]
0: TRAIN [4][5260/6832]	Time 0.396 (0.346)	Data 0.00102 (0.00139)	Tok/s 68104 (74193)	Loss/tok 3.1455 (3.1526)	Learning Rate [7.8125e-05]
0: TRAIN [4][5270/6832]	Time 0.283 (0.346)	Data 0.00103 (0.00139)	Tok/s 70670 (74200)	Loss/tok 3.0442 (3.1524)	Learning Rate [7.8125e-05]
0: TRAIN [4][5280/6832]	Time 0.482 (0.346)	Data 0.00106 (0.00139)	Tok/s 75797 (74194)	Loss/tok 3.1817 (3.1523)	Learning Rate [7.8125e-05]
0: TRAIN [4][5290/6832]	Time 0.326 (0.346)	Data 0.00105 (0.00138)	Tok/s 73069 (74193)	Loss/tok 3.0619 (3.1522)	Learning Rate [7.8125e-05]
0: TRAIN [4][5300/6832]	Time 0.231 (0.346)	Data 0.00102 (0.00138)	Tok/s 75259 (74199)	Loss/tok 3.0099 (3.1520)	Learning Rate [7.8125e-05]
0: TRAIN [4][5310/6832]	Time 0.184 (0.346)	Data 0.00105 (0.00138)	Tok/s 78357 (74207)	Loss/tok 2.7669 (3.1517)	Learning Rate [7.8125e-05]
0: TRAIN [4][5320/6832]	Time 0.292 (0.346)	Data 0.00108 (0.00138)	Tok/s 69459 (74203)	Loss/tok 2.9929 (3.1516)	Learning Rate [7.8125e-05]
0: TRAIN [4][5330/6832]	Time 0.487 (0.346)	Data 0.00112 (0.00138)	Tok/s 99779 (74214)	Loss/tok 2.9335 (3.1513)	Learning Rate [7.8125e-05]
0: TRAIN [4][5340/6832]	Time 0.240 (0.346)	Data 0.00101 (0.00138)	Tok/s 70385 (74216)	Loss/tok 2.9121 (3.1512)	Learning Rate [7.8125e-05]
0: TRAIN [4][5350/6832]	Time 0.321 (0.346)	Data 0.00109 (0.00138)	Tok/s 73636 (74218)	Loss/tok 3.0606 (3.1510)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][5360/6832]	Time 0.429 (0.346)	Data 0.00107 (0.00138)	Tok/s 66518 (74214)	Loss/tok 3.1962 (3.1508)	Learning Rate [7.8125e-05]
0: TRAIN [4][5370/6832]	Time 0.462 (0.346)	Data 0.00101 (0.00138)	Tok/s 105327 (74219)	Loss/tok 2.9239 (3.1506)	Learning Rate [7.8125e-05]
0: TRAIN [4][5380/6832]	Time 0.484 (0.346)	Data 0.00108 (0.00138)	Tok/s 86877 (74220)	Loss/tok 3.0508 (3.1504)	Learning Rate [7.8125e-05]
0: TRAIN [4][5390/6832]	Time 0.278 (0.346)	Data 0.00105 (0.00138)	Tok/s 72460 (74219)	Loss/tok 2.9865 (3.1502)	Learning Rate [7.8125e-05]
0: TRAIN [4][5400/6832]	Time 0.342 (0.346)	Data 0.00104 (0.00138)	Tok/s 73926 (74225)	Loss/tok 3.0522 (3.1500)	Learning Rate [7.8125e-05]
0: TRAIN [4][5410/6832]	Time 0.196 (0.346)	Data 0.00111 (0.00138)	Tok/s 77936 (74222)	Loss/tok 2.8878 (3.1499)	Learning Rate [7.8125e-05]
0: TRAIN [4][5420/6832]	Time 0.459 (0.346)	Data 0.00107 (0.00138)	Tok/s 68529 (74221)	Loss/tok 3.1626 (3.1497)	Learning Rate [7.8125e-05]
0: TRAIN [4][5430/6832]	Time 0.350 (0.346)	Data 0.00109 (0.00138)	Tok/s 68985 (74220)	Loss/tok 3.0806 (3.1495)	Learning Rate [7.8125e-05]
0: TRAIN [4][5440/6832]	Time 0.482 (0.346)	Data 0.00107 (0.00138)	Tok/s 101043 (74218)	Loss/tok 2.9650 (3.1494)	Learning Rate [7.8125e-05]
0: TRAIN [4][5450/6832]	Time 0.482 (0.346)	Data 0.00104 (0.00138)	Tok/s 85939 (74223)	Loss/tok 3.0713 (3.1491)	Learning Rate [7.8125e-05]
0: TRAIN [4][5460/6832]	Time 0.479 (0.346)	Data 0.00108 (0.00138)	Tok/s 69374 (74223)	Loss/tok 3.1593 (3.1490)	Learning Rate [7.8125e-05]
0: TRAIN [4][5470/6832]	Time 0.341 (0.346)	Data 0.00107 (0.00137)	Tok/s 68995 (74219)	Loss/tok 2.9573 (3.1489)	Learning Rate [7.8125e-05]
0: TRAIN [4][5480/6832]	Time 0.212 (0.346)	Data 0.00102 (0.00137)	Tok/s 75245 (74225)	Loss/tok 2.8825 (3.1487)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][5490/6832]	Time 0.133 (0.346)	Data 0.00141 (0.00137)	Tok/s 79350 (74229)	Loss/tok 2.5474 (3.1486)	Learning Rate [7.8125e-05]
0: TRAIN [4][5500/6832]	Time 0.260 (0.346)	Data 0.00104 (0.00137)	Tok/s 72910 (74228)	Loss/tok 2.9224 (3.1484)	Learning Rate [7.8125e-05]
0: TRAIN [4][5510/6832]	Time 0.107 (0.346)	Data 0.00101 (0.00137)	Tok/s 78005 (74233)	Loss/tok 2.3262 (3.1482)	Learning Rate [7.8125e-05]
0: TRAIN [4][5520/6832]	Time 0.467 (0.346)	Data 0.00107 (0.00137)	Tok/s 86520 (74232)	Loss/tok 3.0808 (3.1480)	Learning Rate [7.8125e-05]
0: TRAIN [4][5530/6832]	Time 0.216 (0.346)	Data 0.00104 (0.00137)	Tok/s 77615 (74237)	Loss/tok 2.9160 (3.1479)	Learning Rate [7.8125e-05]
0: TRAIN [4][5540/6832]	Time 0.115 (0.346)	Data 0.00104 (0.00137)	Tok/s 74427 (74236)	Loss/tok 2.3271 (3.1477)	Learning Rate [7.8125e-05]
0: TRAIN [4][5550/6832]	Time 0.253 (0.346)	Data 0.00103 (0.00137)	Tok/s 73100 (74233)	Loss/tok 2.9561 (3.1475)	Learning Rate [7.8125e-05]
0: TRAIN [4][5560/6832]	Time 0.122 (0.346)	Data 0.00103 (0.00137)	Tok/s 79626 (74230)	Loss/tok 2.4895 (3.1473)	Learning Rate [7.8125e-05]
0: TRAIN [4][5570/6832]	Time 0.449 (0.346)	Data 0.00104 (0.00137)	Tok/s 68025 (74226)	Loss/tok 3.1287 (3.1472)	Learning Rate [7.8125e-05]
0: TRAIN [4][5580/6832]	Time 0.462 (0.346)	Data 0.00106 (0.00137)	Tok/s 100711 (74228)	Loss/tok 2.9519 (3.1470)	Learning Rate [7.8125e-05]
0: TRAIN [4][5590/6832]	Time 0.479 (0.346)	Data 0.00103 (0.00137)	Tok/s 73020 (74232)	Loss/tok 3.1441 (3.1468)	Learning Rate [7.8125e-05]
0: TRAIN [4][5600/6832]	Time 0.329 (0.346)	Data 0.00109 (0.00137)	Tok/s 70081 (74233)	Loss/tok 3.0565 (3.1466)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][5610/6832]	Time 0.313 (0.346)	Data 0.00125 (0.00137)	Tok/s 73615 (74231)	Loss/tok 2.9465 (3.1464)	Learning Rate [7.8125e-05]
0: TRAIN [4][5620/6832]	Time 0.487 (0.346)	Data 0.00118 (0.00137)	Tok/s 90642 (74235)	Loss/tok 2.9695 (3.1462)	Learning Rate [7.8125e-05]
0: TRAIN [4][5630/6832]	Time 0.265 (0.346)	Data 0.00109 (0.00137)	Tok/s 75074 (74233)	Loss/tok 2.9915 (3.1461)	Learning Rate [7.8125e-05]
0: TRAIN [4][5640/6832]	Time 0.127 (0.346)	Data 0.00109 (0.00137)	Tok/s 76364 (74229)	Loss/tok 2.4788 (3.1460)	Learning Rate [7.8125e-05]
0: TRAIN [4][5650/6832]	Time 0.358 (0.346)	Data 0.00026 (0.00137)	Tok/s 68480 (74223)	Loss/tok 3.1062 (3.1459)	Learning Rate [7.8125e-05]
0: TRAIN [4][5660/6832]	Time 0.403 (0.346)	Data 0.00105 (0.00137)	Tok/s 68149 (74224)	Loss/tok 3.1268 (3.1458)	Learning Rate [7.8125e-05]
0: TRAIN [4][5670/6832]	Time 0.433 (0.346)	Data 0.00113 (0.00136)	Tok/s 65035 (74223)	Loss/tok 3.1109 (3.1456)	Learning Rate [7.8125e-05]
0: TRAIN [4][5680/6832]	Time 0.447 (0.346)	Data 0.00103 (0.00136)	Tok/s 70263 (74217)	Loss/tok 3.1752 (3.1454)	Learning Rate [7.8125e-05]
0: TRAIN [4][5690/6832]	Time 0.152 (0.346)	Data 0.00104 (0.00136)	Tok/s 78133 (74223)	Loss/tok 2.6939 (3.1452)	Learning Rate [7.8125e-05]
0: TRAIN [4][5700/6832]	Time 0.218 (0.346)	Data 0.00114 (0.00136)	Tok/s 76941 (74235)	Loss/tok 2.8683 (3.1449)	Learning Rate [7.8125e-05]
0: TRAIN [4][5710/6832]	Time 0.383 (0.346)	Data 0.00112 (0.00136)	Tok/s 70186 (74241)	Loss/tok 3.0380 (3.1447)	Learning Rate [7.8125e-05]
0: TRAIN [4][5720/6832]	Time 0.476 (0.346)	Data 0.00109 (0.00136)	Tok/s 66287 (74241)	Loss/tok 3.1369 (3.1445)	Learning Rate [7.8125e-05]
0: TRAIN [4][5730/6832]	Time 0.251 (0.346)	Data 0.00115 (0.00136)	Tok/s 75481 (74239)	Loss/tok 3.0215 (3.1444)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][5740/6832]	Time 0.159 (0.346)	Data 0.00105 (0.00136)	Tok/s 78394 (74233)	Loss/tok 2.7888 (3.1443)	Learning Rate [7.8125e-05]
0: TRAIN [4][5750/6832]	Time 0.423 (0.346)	Data 0.00103 (0.00136)	Tok/s 67455 (74225)	Loss/tok 3.1236 (3.1442)	Learning Rate [7.8125e-05]
0: TRAIN [4][5760/6832]	Time 0.478 (0.346)	Data 0.00114 (0.00136)	Tok/s 67767 (74217)	Loss/tok 3.1482 (3.1440)	Learning Rate [7.8125e-05]
0: TRAIN [4][5770/6832]	Time 0.145 (0.346)	Data 0.00111 (0.00136)	Tok/s 73005 (74218)	Loss/tok 2.6005 (3.1439)	Learning Rate [7.8125e-05]
0: TRAIN [4][5780/6832]	Time 0.165 (0.346)	Data 0.00118 (0.00136)	Tok/s 75223 (74217)	Loss/tok 2.7355 (3.1437)	Learning Rate [7.8125e-05]
0: TRAIN [4][5790/6832]	Time 0.363 (0.346)	Data 0.00103 (0.00136)	Tok/s 73373 (74217)	Loss/tok 3.0471 (3.1434)	Learning Rate [7.8125e-05]
0: TRAIN [4][5800/6832]	Time 0.484 (0.346)	Data 0.00103 (0.00136)	Tok/s 82134 (74221)	Loss/tok 3.1383 (3.1431)	Learning Rate [7.8125e-05]
0: TRAIN [4][5810/6832]	Time 0.180 (0.346)	Data 0.00132 (0.00136)	Tok/s 77025 (74222)	Loss/tok 2.7473 (3.1428)	Learning Rate [7.8125e-05]
0: TRAIN [4][5820/6832]	Time 0.456 (0.346)	Data 0.00109 (0.00136)	Tok/s 68169 (74216)	Loss/tok 3.1248 (3.1426)	Learning Rate [7.8125e-05]
0: TRAIN [4][5830/6832]	Time 0.476 (0.346)	Data 0.00106 (0.00136)	Tok/s 80403 (74213)	Loss/tok 3.1319 (3.1425)	Learning Rate [7.8125e-05]
0: TRAIN [4][5840/6832]	Time 0.485 (0.346)	Data 0.00118 (0.00136)	Tok/s 77736 (74209)	Loss/tok 3.0841 (3.1423)	Learning Rate [7.8125e-05]
0: TRAIN [4][5850/6832]	Time 0.437 (0.346)	Data 0.00108 (0.00136)	Tok/s 66020 (74204)	Loss/tok 3.0972 (3.1422)	Learning Rate [7.8125e-05]
0: TRAIN [4][5860/6832]	Time 0.439 (0.346)	Data 0.00109 (0.00136)	Tok/s 67066 (74212)	Loss/tok 3.0860 (3.1420)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][5870/6832]	Time 0.125 (0.346)	Data 0.00107 (0.00136)	Tok/s 77225 (74211)	Loss/tok 2.5404 (3.1418)	Learning Rate [7.8125e-05]
0: TRAIN [4][5880/6832]	Time 0.300 (0.346)	Data 0.00105 (0.00136)	Tok/s 70007 (74212)	Loss/tok 3.1039 (3.1416)	Learning Rate [7.8125e-05]
0: TRAIN [4][5890/6832]	Time 0.470 (0.346)	Data 0.00107 (0.00136)	Tok/s 71867 (74209)	Loss/tok 3.1949 (3.1414)	Learning Rate [7.8125e-05]
0: TRAIN [4][5900/6832]	Time 0.479 (0.346)	Data 0.00102 (0.00135)	Tok/s 70406 (74205)	Loss/tok 3.1790 (3.1413)	Learning Rate [7.8125e-05]
0: TRAIN [4][5910/6832]	Time 0.465 (0.346)	Data 0.00160 (0.00135)	Tok/s 92850 (74206)	Loss/tok 2.9774 (3.1411)	Learning Rate [7.8125e-05]
0: TRAIN [4][5920/6832]	Time 0.485 (0.346)	Data 0.00105 (0.00135)	Tok/s 75157 (74212)	Loss/tok 3.1585 (3.1409)	Learning Rate [7.8125e-05]
0: TRAIN [4][5930/6832]	Time 0.336 (0.346)	Data 0.00106 (0.00135)	Tok/s 69765 (74205)	Loss/tok 3.1170 (3.1408)	Learning Rate [7.8125e-05]
0: TRAIN [4][5940/6832]	Time 0.486 (0.347)	Data 0.00107 (0.00135)	Tok/s 88778 (74214)	Loss/tok 3.0785 (3.1406)	Learning Rate [7.8125e-05]
0: TRAIN [4][5950/6832]	Time 0.476 (0.347)	Data 0.00106 (0.00135)	Tok/s 73169 (74216)	Loss/tok 3.1554 (3.1404)	Learning Rate [7.8125e-05]
0: TRAIN [4][5960/6832]	Time 0.277 (0.347)	Data 0.00111 (0.00135)	Tok/s 72179 (74213)	Loss/tok 2.9030 (3.1402)	Learning Rate [7.8125e-05]
0: TRAIN [4][5970/6832]	Time 0.284 (0.347)	Data 0.00103 (0.00135)	Tok/s 71864 (74213)	Loss/tok 2.9816 (3.1400)	Learning Rate [7.8125e-05]
0: TRAIN [4][5980/6832]	Time 0.477 (0.347)	Data 0.00101 (0.00135)	Tok/s 68280 (74210)	Loss/tok 3.1441 (3.1398)	Learning Rate [7.8125e-05]
0: TRAIN [4][5990/6832]	Time 0.487 (0.347)	Data 0.00115 (0.00135)	Tok/s 80297 (74217)	Loss/tok 3.1292 (3.1396)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][6000/6832]	Time 0.478 (0.346)	Data 0.00107 (0.00135)	Tok/s 76155 (74218)	Loss/tok 3.1916 (3.1394)	Learning Rate [7.8125e-05]
0: TRAIN [4][6010/6832]	Time 0.139 (0.347)	Data 0.00116 (0.00135)	Tok/s 80489 (74214)	Loss/tok 2.6451 (3.1394)	Learning Rate [7.8125e-05]
0: TRAIN [4][6020/6832]	Time 0.480 (0.347)	Data 0.00104 (0.00135)	Tok/s 69310 (74215)	Loss/tok 3.2572 (3.1394)	Learning Rate [7.8125e-05]
0: TRAIN [4][6030/6832]	Time 0.347 (0.347)	Data 0.00104 (0.00135)	Tok/s 69321 (74211)	Loss/tok 3.0972 (3.1393)	Learning Rate [7.8125e-05]
0: TRAIN [4][6040/6832]	Time 0.464 (0.347)	Data 0.00109 (0.00135)	Tok/s 73746 (74213)	Loss/tok 3.1688 (3.1393)	Learning Rate [7.8125e-05]
0: TRAIN [4][6050/6832]	Time 0.461 (0.347)	Data 0.00110 (0.00135)	Tok/s 64695 (74217)	Loss/tok 3.2210 (3.1393)	Learning Rate [7.8125e-05]
0: TRAIN [4][6060/6832]	Time 0.483 (0.347)	Data 0.00105 (0.00135)	Tok/s 89094 (74222)	Loss/tok 3.1229 (3.1392)	Learning Rate [7.8125e-05]
0: TRAIN [4][6070/6832]	Time 0.220 (0.347)	Data 0.00105 (0.00135)	Tok/s 76571 (74227)	Loss/tok 2.8981 (3.1391)	Learning Rate [7.8125e-05]
0: TRAIN [4][6080/6832]	Time 0.148 (0.347)	Data 0.00104 (0.00135)	Tok/s 81047 (74226)	Loss/tok 2.6619 (3.1390)	Learning Rate [7.8125e-05]
0: TRAIN [4][6090/6832]	Time 0.480 (0.347)	Data 0.00108 (0.00135)	Tok/s 65396 (74227)	Loss/tok 3.1832 (3.1390)	Learning Rate [7.8125e-05]
0: TRAIN [4][6100/6832]	Time 0.480 (0.347)	Data 0.00107 (0.00135)	Tok/s 81326 (74230)	Loss/tok 3.0883 (3.1388)	Learning Rate [7.8125e-05]
0: TRAIN [4][6110/6832]	Time 0.458 (0.347)	Data 0.00116 (0.00135)	Tok/s 62920 (74228)	Loss/tok 3.1834 (3.1388)	Learning Rate [7.8125e-05]
0: TRAIN [4][6120/6832]	Time 0.480 (0.347)	Data 0.00102 (0.00135)	Tok/s 74654 (74223)	Loss/tok 3.1337 (3.1388)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][6130/6832]	Time 0.155 (0.347)	Data 0.00104 (0.00135)	Tok/s 68150 (74218)	Loss/tok 2.5521 (3.1386)	Learning Rate [7.8125e-05]
0: TRAIN [4][6140/6832]	Time 0.468 (0.347)	Data 0.00102 (0.00135)	Tok/s 68396 (74215)	Loss/tok 3.2563 (3.1386)	Learning Rate [7.8125e-05]
0: TRAIN [4][6150/6832]	Time 0.450 (0.347)	Data 0.00100 (0.00134)	Tok/s 76250 (74214)	Loss/tok 3.2202 (3.1386)	Learning Rate [7.8125e-05]
0: TRAIN [4][6160/6832]	Time 0.488 (0.347)	Data 0.00110 (0.00134)	Tok/s 88206 (74212)	Loss/tok 3.0724 (3.1386)	Learning Rate [7.8125e-05]
0: TRAIN [4][6170/6832]	Time 0.376 (0.347)	Data 0.00105 (0.00134)	Tok/s 65326 (74212)	Loss/tok 3.0947 (3.1385)	Learning Rate [7.8125e-05]
0: TRAIN [4][6180/6832]	Time 0.448 (0.347)	Data 0.00104 (0.00134)	Tok/s 66314 (74212)	Loss/tok 3.2506 (3.1385)	Learning Rate [7.8125e-05]
0: TRAIN [4][6190/6832]	Time 0.460 (0.347)	Data 0.00106 (0.00134)	Tok/s 65553 (74207)	Loss/tok 3.1057 (3.1384)	Learning Rate [7.8125e-05]
0: TRAIN [4][6200/6832]	Time 0.202 (0.347)	Data 0.00102 (0.00134)	Tok/s 73008 (74203)	Loss/tok 2.8882 (3.1383)	Learning Rate [7.8125e-05]
0: TRAIN [4][6210/6832]	Time 0.244 (0.347)	Data 0.00102 (0.00134)	Tok/s 73443 (74202)	Loss/tok 2.9688 (3.1383)	Learning Rate [7.8125e-05]
0: TRAIN [4][6220/6832]	Time 0.483 (0.347)	Data 0.00108 (0.00134)	Tok/s 79030 (74204)	Loss/tok 3.1649 (3.1381)	Learning Rate [7.8125e-05]
0: TRAIN [4][6230/6832]	Time 0.300 (0.347)	Data 0.00104 (0.00134)	Tok/s 71368 (74208)	Loss/tok 3.0904 (3.1380)	Learning Rate [7.8125e-05]
0: TRAIN [4][6240/6832]	Time 0.224 (0.347)	Data 0.00100 (0.00134)	Tok/s 77563 (74208)	Loss/tok 2.9975 (3.1379)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][6250/6832]	Time 0.410 (0.347)	Data 0.00117 (0.00134)	Tok/s 65766 (74201)	Loss/tok 3.1716 (3.1377)	Learning Rate [7.8125e-05]
0: TRAIN [4][6260/6832]	Time 0.410 (0.347)	Data 0.00109 (0.00134)	Tok/s 67544 (74201)	Loss/tok 3.1137 (3.1377)	Learning Rate [7.8125e-05]
0: TRAIN [4][6270/6832]	Time 0.479 (0.347)	Data 0.00103 (0.00134)	Tok/s 88131 (74205)	Loss/tok 3.1495 (3.1377)	Learning Rate [7.8125e-05]
0: TRAIN [4][6280/6832]	Time 0.211 (0.347)	Data 0.00107 (0.00134)	Tok/s 75369 (74204)	Loss/tok 2.9345 (3.1377)	Learning Rate [7.8125e-05]
0: TRAIN [4][6290/6832]	Time 0.484 (0.347)	Data 0.00104 (0.00134)	Tok/s 88719 (74207)	Loss/tok 3.1032 (3.1376)	Learning Rate [7.8125e-05]
0: TRAIN [4][6300/6832]	Time 0.311 (0.347)	Data 0.00105 (0.00134)	Tok/s 69328 (74203)	Loss/tok 3.0083 (3.1375)	Learning Rate [7.8125e-05]
0: TRAIN [4][6310/6832]	Time 0.234 (0.347)	Data 0.00023 (0.00134)	Tok/s 76480 (74205)	Loss/tok 2.9095 (3.1374)	Learning Rate [7.8125e-05]
0: TRAIN [4][6320/6832]	Time 0.348 (0.347)	Data 0.00111 (0.00134)	Tok/s 69684 (74204)	Loss/tok 3.1728 (3.1374)	Learning Rate [7.8125e-05]
0: TRAIN [4][6330/6832]	Time 0.185 (0.347)	Data 0.00110 (0.00134)	Tok/s 77719 (74208)	Loss/tok 2.8737 (3.1372)	Learning Rate [7.8125e-05]
0: TRAIN [4][6340/6832]	Time 0.282 (0.347)	Data 0.00106 (0.00134)	Tok/s 72626 (74205)	Loss/tok 3.0347 (3.1371)	Learning Rate [7.8125e-05]
0: TRAIN [4][6350/6832]	Time 0.346 (0.347)	Data 0.00106 (0.00134)	Tok/s 69629 (74204)	Loss/tok 3.1351 (3.1371)	Learning Rate [7.8125e-05]
0: TRAIN [4][6360/6832]	Time 0.122 (0.347)	Data 0.00107 (0.00134)	Tok/s 79564 (74203)	Loss/tok 2.5226 (3.1370)	Learning Rate [7.8125e-05]
0: TRAIN [4][6370/6832]	Time 0.283 (0.347)	Data 0.00103 (0.00134)	Tok/s 72450 (74201)	Loss/tok 3.0469 (3.1369)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][6380/6832]	Time 0.478 (0.347)	Data 0.00110 (0.00134)	Tok/s 72870 (74203)	Loss/tok 3.2312 (3.1369)	Learning Rate [7.8125e-05]
0: TRAIN [4][6390/6832]	Time 0.278 (0.347)	Data 0.00104 (0.00133)	Tok/s 73413 (74203)	Loss/tok 3.0550 (3.1368)	Learning Rate [7.8125e-05]
0: TRAIN [4][6400/6832]	Time 0.418 (0.347)	Data 0.00111 (0.00133)	Tok/s 66409 (74205)	Loss/tok 3.1758 (3.1367)	Learning Rate [7.8125e-05]
0: TRAIN [4][6410/6832]	Time 0.433 (0.347)	Data 0.00109 (0.00133)	Tok/s 68515 (74207)	Loss/tok 3.1317 (3.1366)	Learning Rate [7.8125e-05]
0: TRAIN [4][6420/6832]	Time 0.429 (0.347)	Data 0.00105 (0.00133)	Tok/s 65866 (74209)	Loss/tok 3.1184 (3.1366)	Learning Rate [7.8125e-05]
0: TRAIN [4][6430/6832]	Time 0.318 (0.347)	Data 0.00108 (0.00133)	Tok/s 70258 (74206)	Loss/tok 3.1050 (3.1365)	Learning Rate [7.8125e-05]
0: TRAIN [4][6440/6832]	Time 0.423 (0.347)	Data 0.00128 (0.00133)	Tok/s 68129 (74200)	Loss/tok 3.1552 (3.1365)	Learning Rate [7.8125e-05]
0: TRAIN [4][6450/6832]	Time 0.275 (0.347)	Data 0.00108 (0.00133)	Tok/s 71120 (74200)	Loss/tok 3.0035 (3.1365)	Learning Rate [7.8125e-05]
0: TRAIN [4][6460/6832]	Time 0.417 (0.347)	Data 0.00106 (0.00133)	Tok/s 68637 (74199)	Loss/tok 3.2328 (3.1364)	Learning Rate [7.8125e-05]
0: TRAIN [4][6470/6832]	Time 0.196 (0.347)	Data 0.00103 (0.00133)	Tok/s 77688 (74195)	Loss/tok 2.9659 (3.1363)	Learning Rate [7.8125e-05]
0: TRAIN [4][6480/6832]	Time 0.481 (0.347)	Data 0.00111 (0.00133)	Tok/s 87883 (74197)	Loss/tok 3.2103 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6490/6832]	Time 0.481 (0.347)	Data 0.00112 (0.00133)	Tok/s 72141 (74197)	Loss/tok 3.0842 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6500/6832]	Time 0.300 (0.347)	Data 0.00105 (0.00133)	Tok/s 69203 (74191)	Loss/tok 3.0086 (3.1361)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][6510/6832]	Time 0.260 (0.347)	Data 0.00106 (0.00133)	Tok/s 75024 (74187)	Loss/tok 3.0454 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6520/6832]	Time 0.228 (0.347)	Data 0.00104 (0.00133)	Tok/s 73815 (74190)	Loss/tok 2.9020 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6530/6832]	Time 0.463 (0.347)	Data 0.00111 (0.00133)	Tok/s 66222 (74182)	Loss/tok 3.2708 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6540/6832]	Time 0.113 (0.347)	Data 0.00106 (0.00133)	Tok/s 73757 (74185)	Loss/tok 2.3119 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6550/6832]	Time 0.373 (0.347)	Data 0.00103 (0.00133)	Tok/s 66583 (74177)	Loss/tok 3.1690 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6560/6832]	Time 0.334 (0.347)	Data 0.00105 (0.00133)	Tok/s 69036 (74179)	Loss/tok 3.2170 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6570/6832]	Time 0.300 (0.347)	Data 0.00140 (0.00133)	Tok/s 69761 (74176)	Loss/tok 3.2322 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6580/6832]	Time 0.435 (0.347)	Data 0.00105 (0.00133)	Tok/s 64748 (74175)	Loss/tok 3.2471 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6590/6832]	Time 0.463 (0.347)	Data 0.00114 (0.00133)	Tok/s 66836 (74168)	Loss/tok 3.2254 (3.1363)	Learning Rate [7.8125e-05]
0: TRAIN [4][6600/6832]	Time 0.452 (0.347)	Data 0.00104 (0.00133)	Tok/s 66026 (74167)	Loss/tok 3.2224 (3.1363)	Learning Rate [7.8125e-05]
0: TRAIN [4][6610/6832]	Time 0.484 (0.347)	Data 0.00107 (0.00133)	Tok/s 93374 (74172)	Loss/tok 3.0167 (3.1363)	Learning Rate [7.8125e-05]
0: TRAIN [4][6620/6832]	Time 0.166 (0.347)	Data 0.00104 (0.00133)	Tok/s 75411 (74170)	Loss/tok 2.8083 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6630/6832]	Time 0.167 (0.347)	Data 0.00105 (0.00133)	Tok/s 77885 (74166)	Loss/tok 2.7817 (3.1362)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][6640/6832]	Time 0.427 (0.347)	Data 0.00102 (0.00133)	Tok/s 68638 (74168)	Loss/tok 3.2221 (3.1362)	Learning Rate [7.8125e-05]
0: TRAIN [4][6650/6832]	Time 0.167 (0.347)	Data 0.00105 (0.00133)	Tok/s 77841 (74169)	Loss/tok 2.7895 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6660/6832]	Time 0.483 (0.347)	Data 0.00105 (0.00132)	Tok/s 91365 (74173)	Loss/tok 3.1099 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6670/6832]	Time 0.480 (0.347)	Data 0.00103 (0.00132)	Tok/s 68400 (74166)	Loss/tok 3.2540 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6680/6832]	Time 0.265 (0.347)	Data 0.00108 (0.00132)	Tok/s 69858 (74165)	Loss/tok 3.0348 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6690/6832]	Time 0.387 (0.347)	Data 0.00112 (0.00132)	Tok/s 66743 (74169)	Loss/tok 3.1869 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6700/6832]	Time 0.486 (0.347)	Data 0.00108 (0.00132)	Tok/s 81759 (74166)	Loss/tok 3.1655 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6710/6832]	Time 0.139 (0.347)	Data 0.00108 (0.00132)	Tok/s 80529 (74162)	Loss/tok 2.6746 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6720/6832]	Time 0.487 (0.347)	Data 0.00109 (0.00132)	Tok/s 84912 (74168)	Loss/tok 3.1359 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6730/6832]	Time 0.320 (0.347)	Data 0.00115 (0.00132)	Tok/s 69902 (74171)	Loss/tok 3.1000 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6740/6832]	Time 0.473 (0.347)	Data 0.00105 (0.00132)	Tok/s 75597 (74173)	Loss/tok 3.2098 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6750/6832]	Time 0.280 (0.347)	Data 0.00107 (0.00132)	Tok/s 73592 (74180)	Loss/tok 3.0820 (3.1359)	Learning Rate [7.8125e-05]
0: TRAIN [4][6760/6832]	Time 0.412 (0.347)	Data 0.00112 (0.00132)	Tok/s 65348 (74176)	Loss/tok 3.1870 (3.1359)	Learning Rate [7.8125e-05]
0: Upscaling, new scale: 8192.0
0: TRAIN [4][6770/6832]	Time 0.457 (0.347)	Data 0.00104 (0.00132)	Tok/s 66224 (74170)	Loss/tok 3.2741 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6780/6832]	Time 0.167 (0.347)	Data 0.00104 (0.00132)	Tok/s 82532 (74171)	Loss/tok 2.9211 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6790/6832]	Time 0.114 (0.347)	Data 0.00104 (0.00132)	Tok/s 74081 (74166)	Loss/tok 2.4535 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6800/6832]	Time 0.304 (0.347)	Data 0.00103 (0.00132)	Tok/s 73364 (74162)	Loss/tok 3.0766 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6810/6832]	Time 0.463 (0.347)	Data 0.00112 (0.00132)	Tok/s 92934 (74169)	Loss/tok 3.1180 (3.1360)	Learning Rate [7.8125e-05]
0: TRAIN [4][6820/6832]	Time 0.481 (0.347)	Data 0.00100 (0.00132)	Tok/s 78116 (74173)	Loss/tok 3.2981 (3.1361)	Learning Rate [7.8125e-05]
0: TRAIN [4][6830/6832]	Time 0.477 (0.347)	Data 0.00095 (0.00133)	Tok/s 76354 (74177)	Loss/tok 3.2361 (3.1361)	Learning Rate [7.8125e-05]
0: Running validation on dev set
0: VALIDATION [4][0/80]	Time 0.064 (0.000)	Data 0.00243 (0.00000)	Tok/s 158540 (0)	Loss/tok 3.3269 (0.0000)	Learning Rate [7.8125e-05]
0: VALIDATION [4][10/80]	Time 0.026 (0.031)	Data 0.00173 (0.00187)	Tok/s 217535 (215274)	Loss/tok 3.1071 (3.2038)	Learning Rate [7.8125e-05]
0: VALIDATION [4][20/80]	Time 0.022 (0.027)	Data 0.00166 (0.00179)	Tok/s 210739 (215225)	Loss/tok 3.0974 (3.1795)	Learning Rate [7.8125e-05]
0: VALIDATION [4][30/80]	Time 0.019 (0.025)	Data 0.00160 (0.00174)	Tok/s 195006 (214807)	Loss/tok 3.1444 (3.1530)	Learning Rate [7.8125e-05]
0: VALIDATION [4][40/80]	Time 0.015 (0.023)	Data 0.00158 (0.00171)	Tok/s 205528 (211712)	Loss/tok 3.1038 (3.1376)	Learning Rate [7.8125e-05]
0: VALIDATION [4][50/80]	Time 0.014 (0.021)	Data 0.00154 (0.00168)	Tok/s 191011 (208446)	Loss/tok 2.9442 (3.1225)	Learning Rate [7.8125e-05]
0: VALIDATION [4][60/80]	Time 0.015 (0.020)	Data 0.00154 (0.00166)	Tok/s 143082 (203114)	Loss/tok 3.1893 (3.1174)	Learning Rate [7.8125e-05]
0: VALIDATION [4][70/80]	Time 0.014 (0.019)	Data 0.00152 (0.00165)	Tok/s 111139 (191994)	Loss/tok 3.0230 (3.1105)	Learning Rate [7.8125e-05]
:::MLPv0.5.0 gnmt 1560846229.539874315 (train.py:459) eval_start: 4
0: Running evaluation on test set
0: TEST [4][0/6]	Time 2.094 (2.094)	Decoder iters 149.0 (149.0)	Tok/s 14181 (14181)
0: Running detokenizer
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Target accuracy reached
0: Finished evaluation on test set
:::MLPv0.5.0 gnmt 1560846244.773347139 (train.py:464) eval_accuracy: {"epoch": 4, "value": 21.889999389648438}
:::MLPv0.5.0 gnmt 1560846244.773865700 (train.py:466) eval_target: 21.8
:::MLPv0.5.0 gnmt 1560846244.774461031 (train.py:467) eval_stop
0: Summary: Epoch: 4	Training Loss: 3.1361	Validation Loss: 3.1014	Test BLEU: 21.89
0: Performance: Epoch: 4	Training: 74178 Tok/s	Validation: 181248 Tok/s
0: Finished epoch 4
:::MLPv0.5.0 gnmt 1560846244.775292158 (train.py:488) run_stop: {"success": true}
:::MLPv0.5.0 gnmt 1560846244.775823116 (train.py:494) train_checkpoint
0: Saving model to results/gnmt_wmt16/model_best.pth
:::MLPv0.5.0 gnmt 1560846253.430095911 (train.py:498) run_final
+ ret_code=0
+ set +x
ENDING TIMING RUN AT 2019-06-18 08:24:18 AM
RESULT,RNN_TRANSLATOR,,11995,nvidia,2019-06-18 05:04:23 AM
